<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [nlin.AO](#nlin.AO) [Total: 3]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale](https://arxiv.org/abs/2505.23785)
*Cody Kommers,Drew Hemment,Maria Antoniak,Joel Z. Leibo,Hoyt Long,Emily Robinson,Adam Sobey*

Main category: cs.CL

TL;DR: 大型语言模型可通过厚描述捕捉文化背景的人类意义，在AI系统中实现规模化的意义表示。这一过程面临五大挑战，但有潜力成为解决文化表示难题的统一框架。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决AI系统中因标准化限制无法有效表示人类含义的问题，通过引入厚描述，使系统能够更好地捕捉文化背景和人类活动的意义。

Method: 本文通过采用“厚描述”的方法，探讨如何在AI系统中有效表示文化背景和人类意义。该方法允许用语言能力强的大型语言模型（LLMs）来生成和处理信息，以在规模上实现人类意义的解码。

Result: 大型语言模型的语言能力使得能够在规模上处理厚描述，这可能解决了人类意义解码的难题。本研究还指出应用生成型AI时需解决的五大挑战，包括保留上下文、保持解读的多元性、整合基于经验和批判性距离的观点、区分定性内容和定量数据、以及认识到意义的动态特征。

Conclusion: 厚描述这一方法可能成为解决在大型语言模型中表示文化难题的统一框架。

Abstract: This position paper argues that large language models (LLMs) can make
cultural context, and therefore human meaning, legible at an unprecedented
scale in AI-based sociotechnical systems. We argue that such systems have
previously been unable to represent human meaning because they rely on thin
descriptions: numerical representations that enforce standardization and
therefore strip human activity of the cultural context that gives it meaning.
By contrast, scholars in the humanities and qualitative social sciences have
developed frameworks for representing meaning through thick description: verbal
representations that accommodate heterogeneity and retain contextual
information needed to represent human meaning. While these methods can
effectively codify meaning, they are difficult to deploy at scale. However, the
verbal capabilities of LLMs now provide a means of (at least partially)
automating the generation and processing of thick descriptions, potentially
overcoming this bottleneck. We argue that the problem of rendering human
meaning legible is not just about selecting better metrics, but about
developing new representational formats (based on thick description). We frame
this as a crucial direction for the application of generative AI and identify
five key challenges: preserving context, maintaining interpretive pluralism,
integrating perspectives based on lived experience and critical distance,
distinguishing qualitative content from quantitative magnitude, and
acknowledging meaning as dynamic rather than static. Furthermore, we suggest
that thick description has the potential to serve as a unifying framework to
address a number of emerging concerns about the difficulties of representing
culture in (or using) LLMs.

</details>


### [2] [Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework](https://arxiv.org/abs/2505.23788)
*Aakash Sen Sharma,Debdeep Sanyal,Priyansh Srivastava,Sundar Atreya H.,Shirish Karande,Mohan Kankanhalli,Murari Mandal*

Main category: cs.CL

TL;DR: FUA-LLM framework aligns LLM outputs with fair-use doctrine using FairUseDB and DPO, leading to a 20% reduction in problematic outputs compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the ethical, legal, and practical concerns of copyright infringement by LLMs and to provide a solution that doesn't merely rely on refusal-based filters, which limit utility.

Method: The paper introduces FUA-LLM, which leverages a legally grounded framework and FairUseDB for fine-tuning open-source LLMs using Direct Preference Optimization (DPO). New evaluation metrics, Weighted Penalty Utility, and Compliance Aware Harmonic Mean (CAH), are proposed.

Result: FUA-LLM substantially reduces copyright infringement risks in LLM outputs while maintaining practical utility, as proven by extensive quantitative experiments and expert evaluations.

Conclusion: FUA-LLM can reduce problematic outputs by up to 20% compared to current state-of-the-art approaches while maintaining usability.

Abstract: Large language models (LLMs) commonly risk copyright infringement by
reproducing protected content verbatim or with insufficient transformative
modifications, posing significant ethical, legal, and practical concerns.
Current inference-time safeguards predominantly rely on restrictive
refusal-based filters, often compromising the practical utility of these
models. To address this, we collaborated closely with intellectual property
experts to develop FUA-LLM (Fair Use Aligned Language Models), a
legally-grounded framework explicitly designed to align LLM outputs with
fair-use doctrine. Central to our method is FairUseDB, a carefully constructed
dataset containing 18,000 expert-validated examples covering nine realistic
infringement scenarios. Leveraging this dataset, we apply Direct Preference
Optimization (DPO) to fine-tune open-source LLMs, encouraging them to produce
legally compliant and practically useful alternatives rather than resorting to
blunt refusal. Recognizing the shortcomings of traditional evaluation metrics,
we propose new measures: Weighted Penalty Utility and Compliance Aware Harmonic
Mean (CAH) to balance infringement risk against response utility. Extensive
quantitative experiments coupled with expert evaluations confirm that FUA-LLM
substantially reduces problematic outputs (up to 20\%) compared to
state-of-the-art approaches, while preserving real-world usability.

</details>


### [3] [Conversational Exploration of Literature Landscape with LitChat](https://arxiv.org/abs/2505.23789)
*Mingyu Huang,Shasha Zhou,Yuxuan Chen,Ke Li*

Main category: cs.CL

TL;DR: LitChat是一个增强版的大语言模型工具，利用数据驱动的发现技术帮助用户高效探索大量文献。


<details>
  <summary>Details</summary>
Motivation: 在数字化科学出版物爆炸性增长的时代，传统的人工审阅已不再可行，且现有大语言模型虽然在文献理解上表现出色，但由于上下文窗口限制及可信度问题（如幻觉），无法提供系统综述所需的全面、客观、开放和透明的视角。因此，需要一种新的工具来解决这些挑战。

Method: 文章介绍了一种新型互动对话文献代理工具——LitChat。LitChat增强了大语言模型(LLM)的能力，利用数据驱动的发现工具进行文献探索。它能够自动解释用户查询、检索相关来源、构建知识图谱，并运用多种数据挖掘技术生成基于证据的洞察。

Result: LitChat能够自动解读用户的查询、检索相关文献、生成知识图谱，并应用多种数据挖掘技术，提供针对用户需求的基于证据的洞察。通过AI4Health的案例研究证明，LitChat可以有效帮助用户在庞大的文献海洋中进行数据驱动的探索。

Conclusion: LitChat通过一个案例研究展示了它在AI4Health领域的有效性，强调其能够快速引导用户在大规模文献环境中找到基于数据的证据，这在传统方法中是难以实现的。

Abstract: We are living in an era of "big literature", where the volume of digital
scientific publications is growing exponentially. While offering new
opportunities, this also poses challenges for understanding literature
landscapes, as traditional manual reviewing is no longer feasible. Recent large
language models (LLMs) have shown strong capabilities for literature
comprehension, yet they are incapable of offering "comprehensive, objective,
open and transparent" views desired by systematic reviews due to their limited
context windows and trust issues like hallucinations. Here we present LitChat,
an end-to-end, interactive and conversational literature agent that augments
LLM agents with data-driven discovery tools to facilitate literature
exploration. LitChat automatically interprets user queries, retrieves relevant
sources, constructs knowledge graphs, and employs diverse data-mining
techniques to generate evidence-based insights addressing user needs. We
illustrate the effectiveness of LitChat via a case study on AI4Health,
highlighting its capacity to quickly navigate the users through large-scale
literature landscape with data-based evidence that is otherwise infeasible with
traditional means.

</details>


### [4] [Rethinking the Understanding Ability across LLMs through Mutual Information](https://arxiv.org/abs/2505.23790)
*Shaojie Wang,Sirui Ding,Na Zou*

Main category: cs.CL

TL;DR: 使用信息论框架通过互信息来评估语言模型的理解能力，编码器模型保持较高信息保真度，fine-tuning提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型的内在语言理解能力，该研究提出以互信息为基础的信息论框架来实现。

Method: 信息论框架，通过互信息(MI)来评估语言模型的内在语言理解能力，及基于Fano不等式理论计算token级MI下界，通过实施可恢复性任务来比较不同LLM的MI。

Result: 编码器模型比解码器模型能保持更高的信息保真度，而后者表现出独特的晚层“遗忘”模式；调整以最大化token级可恢复性能改进语言模型的理解能力。

Conclusion: 互信息可以作为基础来理解和提升语言模型的能力。通过最大化token级可恢复性，对LLM的理解能力进行改进，无需特定任务监督。

Abstract: Recent advances in large language models (LLMs) have revolutionized natural
language processing, yet evaluating their intrinsic linguistic understanding
remains challenging. Moving beyond specialized evaluation tasks, we propose an
information-theoretic framework grounded in mutual information (MI) to achieve
this. We formalize the understanding as MI between an input sentence and its
latent representation (sentence-level MI), measuring how effectively input
information is preserved in latent representation. Given that LLMs learn
embeddings for individual tokens, we decompose sentence-level MI into
token-level MI between tokens and sentence embeddings, establishing theoretical
bounds connecting these measures. Based on this foundation, we theoretically
derive a computable lower bound for token-level MI using Fano's inequality,
which directly relates to token-level recoverability-the ability to predict
original tokens from sentence embedding. We implement this recoverability task
to comparatively measure MI across different LLMs, revealing that encoder-only
models consistently maintain higher information fidelity than their
decoder-only counterparts, with the latter exhibiting a distinctive late-layer
"forgetting" pattern where mutual information is first enhanced and then
discarded. Moreover, fine-tuning to maximize token-level recoverability
consistently improves understanding ability of LLMs on tasks without
task-specific supervision, demonstrating that mutual information can serve as a
foundation for understanding and improving language model capabilities.

</details>


### [5] [Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations](https://arxiv.org/abs/2505.23846)
*Atanu Barai,Stephan Eidenbenz,Nandakishore Santhi*

Main category: cs.CL

TL;DR: 本文通过PDES方法，将AI和非AI智能体结合，提高了解决各种领域问题的准确性，达到68%，而单纯AI模型不足23%。


<details>
  <summary>Details</summary>
Motivation: 为了充分利用人工智能系统的潜力并确保其输出的可信度，有必要将多重AI和非AI系统无缝结合，以约束和保证输出的正确性。

Method: 引入了一种新颖的基于并行离散事件仿真（PDES）的方法，将多个AI和非AI系统结合在一起，以因果和规则为基础。这种方法将时间的概念紧密结合到PDES框架中，每个智能体被视为实体并响应其他智能体的先前请求。

Result: 通过解决四个不同领域的问题并将结果与单纯AI模型进行比较，我们的方法表现出更高的准确性，整体准确率达到68%，而单纯AI模型的准确率则低于23%。

Conclusion: 在涉及AI和非AI智能体的PDES中，将问题分解为结构化步骤，为AI智能体提供多种选择，并通过非AI智能体作为公正的审计者，检查AI智能体的每一步操作，从而在解决特定领域的问题上表现出显著的准确性提升。

Abstract: To fully leverage the potential of artificial intelligence (AI) systems in a
trustworthy manner, it is desirable to couple multiple AI and non-AI systems
together seamlessly for constraining and ensuring correctness of the output.
This paper introduces a novel parallel discrete event simulation (PDES) based
methodology to combine multiple AI and non-AI agents in a causal, rule-based
way. Our approach tightly integrates the concept of passage of time, with each
agent considered as an entity in the PDES framework and responding to prior
requests from other agents. Such coupling mechanism enables the agents to work
in a co-operative environment towards a common goal while many tasks run in
parallel throughout the simulation. It further enables setting up boundaries to
the outputs of the AI agents by applying necessary dynamic constraints using
non-AI agents while allowing for scalability through deployment of hundreds of
such agents in a larger compute cluster. Distributing smaller AI agents can
enable extremely scalable simulations in the future, addressing local memory
bottlenecks for model parameter storage. Within a PDES involving both AI and
non-AI agents, we break down the problem at hand into structured steps, when
necessary, providing a set of multiple choices to the AI agents, and then
progressively solve these steps towards a final goal. At each step, the non-AI
agents act as unbiased auditors, verifying each action by the AI agents so that
certain rules of engagement are followed. We evaluate our approach by solving
four problems from four different domains and comparing the results with those
from AI models alone. Our results show greater accuracy in solving problems
from various domains where the AI models struggle to solve the problems solely
by themselves. Results show that overall accuracy of our approach is 68% where
as the accuracy of vanilla models is less than 23%.

</details>


### [6] [R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning](https://arxiv.org/abs/2505.23794)
*Yuan Li,Qi Luo,Xiaonan Li,Bufan Li,Qinyuan Cheng,Bo Wang,Yining Zheng,Yuxin Wang,Zhangyue Yin,Xipeng Qiu*

Main category: cs.CL

TL;DR: R3-RAG通过强化学习提高RAG系统的推理和检索能力，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决稠密检索器在RAG系统中存在的限制，如参数比LLMs少和缺乏逐步推理能力。

Method: R3-RAG 分为两个阶段：首先，使用冷启动让模型学习逐步推理和检索的方式；然后，使用强化学习进一步利用其能力来更好地探索外部检索环境。

Result: 实验结果表明，R3-RAG显著优于基线，并能够很好地适应不同的检索器。

Conclusion: R3-RAG显著优于基线方法，并且能够很好地适应不同的检索器。

Abstract: Retrieval-Augmented Generation (RAG) integrates external knowledge with Large
Language Models (LLMs) to enhance factual correctness and mitigate
hallucination. However, dense retrievers often become the bottleneck of RAG
systems due to their limited parameters compared to LLMs and their inability to
perform step-by-step reasoning. While prompt-based iterative RAG attempts to
address these limitations, it is constrained by human-designed workflows. To
address these limitations, we propose $\textbf{R3-RAG}$, which uses
$\textbf{R}$einforcement learning to make the LLM learn how to
$\textbf{R}$eason and $\textbf{R}$etrieve step by step, thus retrieving
comprehensive external knowledge and leading to correct answers. R3-RAG is
divided into two stages. We first use cold start to make the model learn the
manner of iteratively interleaving reasoning and retrieval. Then we use
reinforcement learning to further harness its ability to better explore the
external retrieval environment. Specifically, we propose two rewards for
R3-RAG: 1) answer correctness for outcome reward, which judges whether the
trajectory leads to a correct answer; 2) relevance-based document verification
for process reward, encouraging the model to retrieve documents that are
relevant to the user question, through which we can let the model learn how to
iteratively reason and retrieve relevant documents to get the correct answer.
Experimental results show that R3-RAG significantly outperforms baselines and
can transfer well to different retrievers. We release R3-RAG at
https://github.com/Yuan-Li-FNLP/R3-RAG.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems](https://arxiv.org/abs/2505.23881)
*Christopher D. Rosin*

Main category: cs.AI

TL;DR: 构建协议CPro1使用具有推理能力的LLM，成功解决了组合设计研究领域中多个长期未解的实例，显示出其在数学和代码生成应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 在组合设计领域中，存在许多有待解决的开放实例，使用大规模语言模型进行代码生成和推理可以帮助寻找这些实例的解决方案。

Method: Constructive Protocol CPro1 利用带有推理能力的LLM生成搜索启发式，以构建小型开放实例的潜在解决方案，包括自动超参数调整和执行反馈。

Result: CPro1成功解决了16个组合设计问题中的7个长期未解决的实例，特别是在Bhaskar Rao Designs、Symmetric Weighing Matrices、Balanced Ternary Designs上取得重大进展，并解决了2025年近期文献中的多个问题。

Conclusion: 带有推理能力的大型语言模型能够在程序生成和数学领域中实现显著成果，特别是在组合设计领域中成功解开了多个长期未解决的实例。

Abstract: Large Language Models (LLMs) with reasoning are trained to iteratively
generate and refine their answers before finalizing them, which can help with
applications to mathematics and code generation. We apply code generation with
reasoning LLMs to a specific task in the mathematical field of combinatorial
design. This field studies diverse types of combinatorial designs, many of
which have lists of open instances for which existence has not yet been
determined. The Constructive Protocol CPro1 uses LLMs to generate search
heuristics that have the potential to construct solutions to small open
instances. Starting with a textual definition and a validity verifier for a
particular type of design, CPro1 guides LLMs to select and implement
strategies, while providing automated hyperparameter tuning and execution
feedback. CPro1 with reasoning LLMs successfully solves long-standing open
instances for 7 of 16 combinatorial design problems selected from the 2006
Handbook of Combinatorial Designs, including new solved instances for 3 of
these (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary
Designs) that were unsolved by CPro1 with non-reasoning LLMs. It also solves
open instances for several problems from recent (2025) literature, generating
new Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform
Nested Steiner Quadruple System.

</details>


### [8] [OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation](https://arxiv.org/abs/2505.23885)
*Mengkang Hu,Yuhang Zhou,Wendong Fan,Yuzhou Nie,Bowei Xia,Tao Sun,Ziyu Ye,Zhaoxuan Jin,Yingru Li,Qiguang Chen,Zeyu Zhang,Yifeng Wang,Qianshuo Ye,Bernard Ghanem,Ping Luo,Guohao Li*

Main category: cs.AI

TL;DR: Workforce是一种模块化多代理框架，通过分离战略规划和执行实现跨领域迁移，并在GAIA基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多代理系统无法跨领域迁移，需要重新设计架构和重新训练组件。

Method: 引入Workforce框架，采用分层架构，通过模块化设计实现跨领域迁移；使用强化学习优化领域无关的规划器。

Result: 实验结果显示Workforce在GAIA基准测试中实现了开源领域最先进的性能（69.70%），超过了OpenAI的Deep Research 2.34%。

Conclusion: 研究通过模块化架构实现可扩展的泛化和跨领域迁移，为下一代通用人工智能助手奠定基础。

Abstract: Large Language Model (LLM)-based multi-agent systems show promise for
automating real-world tasks but struggle to transfer across domains due to
their domain-specific nature. Current approaches face two critical
shortcomings: they require complete architectural redesign and full retraining
of all components when applied to new domains. We introduce Workforce, a
hierarchical multi-agent framework that decouples strategic planning from
specialized execution through a modular architecture comprising: (i) a
domain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask
management, and (iii) specialized Workers with domain-specific tool-calling
capabilities. This decoupling enables cross-domain transferability during both
inference and training phases: During inference, Workforce seamlessly adapts to
new domains by adding or modifying worker agents; For training, we introduce
Optimized Workforce Learning (OWL), which improves generalization across
domains by optimizing a domain-agnostic planner with reinforcement learning
from real-world feedback. To validate our approach, we evaluate Workforce on
the GAIA benchmark, covering various realistic, multi-domain agentic tasks.
Experimental results demonstrate Workforce achieves open-source
state-of-the-art performance (69.70%), outperforming commercial systems like
OpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model
achieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to
GPT-4o on challenging tasks. To summarize, by enabling scalable generalization
and modular domain transfer, our work establishes a foundation for the next
generation of general-purpose AI assistants.

</details>


### [9] [Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve](https://arxiv.org/abs/2505.23946)
*Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen*

Main category: cs.AI

TL;DR: 提出了一个让LLM相互学习以提高编码任务表现的协作框架，小型LLM组队后胜过大型LLM。


<details>
  <summary>Details</summary>
Motivation: 不同LLM在任务上的表现差异提示我们可以通过多LLM协作来提升任务解决能力。因此，需要一种方法来利用未明确知道它们互补优势的多个LLM。

Method: 通过设计课程征集、储存和选择机制的协作框架来实现LLM的协作学习。

Result: 实验表明，经过课程学习的小型LLM团队在解决编码问题时能够超过一个大型的LLM，以及其他多LLM协作方法。

Conclusion: 提出了一种基于课程的协作框架，使得多个小型LLM可以通过相互学习彼此的成功和失败，最终在编码问题的解决上超过单一大型LLM和其他多LLM协作方法。

Abstract: Recent studies show that LLMs possess different skills and specialize in
different tasks. In fact, we observe that their varied performance occur in
several levels of granularity. For example, in the code optimization task, code
LLMs excel at different optimization categories and no one dominates others.
This observation prompts the question of how one leverages multiple LLM agents
to solve a coding problem without knowing their complementary strengths a
priori. We argue that a team of agents can learn from each other's successes
and failures so as to improve their own performance. Thus, a lesson is the
knowledge produced by an agent and passed on to other agents in the collective
solution process. We propose a lesson-based collaboration framework, design the
lesson solicitation--banking--selection mechanism, and demonstrate that a team
of small LLMs with lessons learned can outperform a much larger LLM and other
multi-LLM collaboration methods.

</details>


### [10] [InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback](https://arxiv.org/abs/2505.23950)
*Boyuan Chen,Donghai Hong,Jiaming Ji,Jiacheng Zheng,Bowen Dong,Jiayi Zhou,Kaile Wang,Juntao Dai,Xuyao Wang,Wenqi Chen,Qirui Zheng,Wenxin Li,Sirui Han,Yike Guo,Yaodong Yang*

Main category: cs.AI

TL;DR: 论文探索并构建了一个支持多轮、多模态交互的MLLMs数据集和评估基准，强调通过人类反馈和专家标注来提升MLLMs的互动能力。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大模型（MLLMs）缺少与环境进行多轮、多模态对话的能力，而这对于接近人类水平的智能至关重要，因此需要研究对这项能力的增强。

Method: 作者设计了InterMT数据集和InterMT-Bench评估基准，通过工具增强的MLLMs构造多轮问答实例，并用人类偏好进行标注来评估模型的多轮多模态任务处理能力。

Result: InterMT数据集包含15,600个提示、52,600个多轮对话实例和32,400个人类标注的偏好对，且通过工具增强MLLMs构建多轮QA实例，证明数据集在法官调节等应用中的效用，揭示法官模型的多轮扩展规律。

Conclusion: 论文提出了一个新的数据集和评估基准来推动多轮、多模态交互能力的研究，尤其是在人类反馈的基础上进行专家标注，强调提升MLLMs的互动能力。

Abstract: As multimodal large models (MLLMs) continue to advance across challenging
tasks, a key question emerges: What essential capabilities are still missing? A
critical aspect of human learning is continuous interaction with the
environment -- not limited to language, but also involving multimodal
understanding and generation. To move closer to human-level intelligence,
models must similarly support multi-turn, multimodal interaction. In
particular, they should comprehend interleaved multimodal contexts and respond
coherently in ongoing exchanges. In this work, we present an initial
exploration through the InterMT -- the first preference dataset for multi-turn
multimodal interaction, grounded in real human feedback. In this exploration,
we particularly emphasize the importance of human oversight, introducing expert
annotations to guide the process, motivated by the fact that current MLLMs lack
such complex interactive capabilities. InterMT captures human preferences at
both global and local levels into nine sub-dimensions, consists of 15.6k
prompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled
preference pairs. To compensate for the lack of capability for multi-modal
understanding and generation, we introduce an agentic workflow that leverages
tool-augmented MLLMs to construct multi-turn QA instances. To further this
goal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting
judges with multi-turn, multimodal tasks. We demonstrate the utility of
\InterMT through applications such as judge moderation and further reveal the
multi-turn scaling law of judge model. We hope the open-source of our data can
help facilitate further research on aligning current MLLMs to the next step.
Our project website can be found at https://pku-intermt.github.io .

</details>


### [11] [MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge](https://arxiv.org/abs/2505.23982)
*Jerry Junyang Cheung,Shiyao Shen,Yuchen Zhuang,Yinghao Li,Rampi Ramprasad,Chao Zhang*

Main category: cs.AI

TL;DR: 引入了一个名为MSQA的评估基准，揭示了LLMs在材料科学领域性能中的差距。


<details>
  <summary>Details</summary>
Motivation: 为了填补材料科学领域中评估LLMs领域特定知识和复杂推理能力的空白。

Method: 通过设计一个包含1757道研究生水平材料科学问题的评估基准——MSQA，进行实验。

Result: 通过对10个先进的LLMs进行实验，发现当前LLMs性能中存在显著差距，API型专有LLMs达到84.5%的准确率，而开源LLMs仅达到60.5%，领域特定LLMs表现不佳。

Conclusion: MSQA是首个评估LLMs在高级材料科学中的事实和推理能力的基准。

Abstract: Despite recent advances in large language models (LLMs) for materials
science, there is a lack of benchmarks for evaluating their domain-specific
knowledge and complex reasoning abilities. To bridge this gap, we introduce
MSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials
science questions in two formats: detailed explanatory responses and binary
True/False assessments. MSQA distinctively challenges LLMs by requiring both
precise factual knowledge and multi-step reasoning across seven materials
science sub-fields, such as structure-property relationships, synthesis
processes, and computational modeling. Through experiments with 10
state-of-the-art LLMs, we identify significant gaps in current LLM performance.
While API-based proprietary LLMs achieve up to 84.5% accuracy, open-source
(OSS) LLMs peak around 60.5%, and domain-specific LLMs often underperform
significantly due to overfitting and distributional shifts. MSQA represents the
first benchmark to jointly evaluate the factual and reasoning capabilities of
LLMs crucial for LLMs in advanced materials science.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [12] [Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2505.24113)
*Pengcheng Dai,Yuanqiu Mo,Wenwu Yu,Wei Ren*

Main category: cs.MA

TL;DR: 研究了一种新的分布式神经政策梯度算法，以改进网络化多代理强化学习的效果，并证明了其在机器人路径规划环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在表达能力上表现不佳，受限于线性函数逼近，因此需要更优秀的分布式算法。

Method: 提出了一种分布式神经政策梯度算法，包含分布式评论步骤和分散的表演者步骤，通过时间变化的通信网络进行参数评估和更新。

Result: 通过全局收敛性证明展示了算法的有效性，尤其是在机器人路径规划场景中的表现。

Conclusion: 该算法在机器人路径规划环境下与集中算法的比较中展现了有效性。

Abstract: This paper studies the networked multi-agent reinforcement learning (NMARL)
problem, where the objective of agents is to collaboratively maximize the
discounted average cumulative rewards. Different from the existing methods that
suffer from poor expression due to linear function approximation, we propose a
distributed neural policy gradient algorithm that features two innovatively
designed neural networks, specifically for the approximate Q-functions and
policy functions of agents. This distributed neural policy gradient algorithm
consists of two key components: the distributed critic step and the
decentralized actor step. In the distributed critic step, agents receive the
approximate Q-function parameters from their neighboring agents via a
time-varying communication networks to collaboratively evaluate the joint
policy. In contrast, in the decentralized actor step, each agent updates its
local policy parameter solely based on its own approximate Q-function. In the
convergence analysis, we first establish the global convergence of agents for
the joint policy evaluation in the distributed critic step. Subsequently, we
rigorously demonstrate the global convergence of the overall distributed neural
policy gradient algorithm with respect to the objective function. Finally, the
effectiveness of the proposed algorithm is demonstrated by comparing it with a
centralized algorithm through simulation in the robot path planning
environment.

</details>


### [13] [An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring](https://arxiv.org/abs/2505.24239)
*Sana Ebrahimi,Mohsen Dehghankar,Abolfazl Asudeh*

Main category: cs.MA

TL;DR: 本文提出了一种基于可信评分的多智能体LLM框架，以增强系统对抗性代理的抵抗力，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统在各个领域展现了强大能力，但对于对抗性及低性能的代理非常脆弱。为了解决这一问题，我们提出了一种基于可信评分的通用且抗对抗的多智能体LLM框架。

Method: 我们将协作查询回答过程建模为迭代游戏，代理之间进行通信并贡献于最终的系统输出。系统引入了可信评分机制，在团队输出聚合时使用。可信评分是基于每个代理在查询回答中过去的贡献逐步学习得出的。

Result: 我们的实验表明，该系统在多任务和多设置下的表现有效，能够减轻对抗性影响，并增强多代理合作的韧性，即使在敌对方占多数的情况下。

Conclusion: 我们的系统在多个任务和设置中都显示出了有效性，不仅能够减轻对抗性代理的影响，还可以增强多代理合作的韧性，即使是在敌对方占多数的情况下。

Abstract: While multi-agent LLM systems show strong capabilities in various domains,
they are highly vulnerable to adversarial and low-performing agents. To resolve
this issue, in this paper, we introduce a general and adversary-resistant
multi-agent LLM framework based on credibility scoring. We model the
collaborative query-answering process as an iterative game, where the agents
communicate and contribute to a final system output. Our system associates a
credibility score that is used when aggregating the team outputs. The
credibility scores are learned gradually based on the past contributions of
each agent in query answering. Our experiments across multiple tasks and
settings demonstrate our system's effectiveness in mitigating adversarial
influence and enhancing the resilience of multi-agent cooperation, even in the
adversary-majority settings.

</details>


### [14] [R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning](https://arxiv.org/abs/2505.24265)
*Harsh Goel,Mohammad Omama,Behdad Chalaki,Vaishnav Tadiparthi,Ehsan Moradi Pari,Sandeep Chinchali*

Main category: cs.MA

TL;DR: 提出一种新的角色基础MARL框架R3DM，通过优化角色和轨迹来提高多智能体协作胜率。


<details>
  <summary>Details</summary>
Motivation: 现有角色基础多智能体强化学习方法过度依赖于智能体的过往经验来决定角色，忽视了角色对未来轨迹的影响。本文的动机在于提出一种方法，使得智能体的角色能够有效地影响其未来行为，促进协同工作。

Method: 本文提出了一种新的角色基础多智能体强化学习框架，称为R3DM。该框架通过最大化智能体角色、观察轨迹和预期未来行为之间的互信息来学习涌现角色。利用对比学习优化目标，以过去轨迹为基础推导中间角色，进而通过学习动态模型促进不同角色的未来行为多样性。

Result: 在SMAC和SMACv2环境上的基准测试表明，R3DM能够超越目前最先进的多智能体强化学习方法，将多智能体协作的胜率提高最多20%。

Conclusion: 本文通过新的角色基础MARL框架R3DM实现了通过优化智能体角色和轨迹来提高多智能体协作的效果。实验证明该方法显著增强了胜率。

Abstract: Multi-agent reinforcement learning (MARL) has achieved significant progress
in large-scale traffic control, autonomous vehicles, and robotics. Drawing
inspiration from biological systems where roles naturally emerge to enable
coordination, role-based MARL methods have been proposed to enhance cooperation
learning for complex tasks. However, existing methods exclusively derive roles
from an agent's past experience during training, neglecting their influence on
its future trajectories. This paper introduces a key insight: an agent's role
should shape its future behavior to enable effective coordination. Hence, we
propose Role Discovery and Diversity through Dynamics Models (R3DM), a novel
role-based MARL framework that learns emergent roles by maximizing the mutual
information between agents' roles, observed trajectories, and expected future
behaviors. R3DM optimizes the proposed objective through contrastive learning
on past trajectories to first derive intermediate roles that shape intrinsic
rewards to promote diversity in future behaviors across different roles through
a learned dynamics model. Benchmarking on SMAC and SMACv2 environments
demonstrates that R3DM outperforms state-of-the-art MARL approaches, improving
multi-agent coordination to increase win rates by up to 20%.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [15] [DATD3: Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient For Model Free Reinforcement Learning Under Output Feedback Control](https://arxiv.org/abs/2505.23857)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.LG

TL;DR: 引入了一种新的算法DATD3，在部分和完全可观测条件下的连续控制任务中表现优于其他算法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在现实应用中常常遇到输出反馈问题，即智能体只能获得部分状态信息。为了应对这一挑战，我们提出了输出反馈马尔科夫决策过程(OPMDP)，该过程基于观测历史进行决策。

Method: 我们提出一种新的actor-critic算法：Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient (DATD3)。该算法使用深度分离卷积和多头注意力机制来对历史观测进行编码。

Result: 通过在连续控制任务上的大量实验，我们证明了DATD3在部分和完全可观测条件下优于现有的基于记忆和循环的基线。

Conclusion: DATD3在部分和完全可观测条件下，在连续控制任务中优于现有的基于记忆和循环的基线。

Abstract: Reinforcement learning in real-world applications often involves
output-feedback settings, where the agent receives only partial state
information. To address this challenge, we propose the Output-Feedback Markov
Decision Process (OPMDP), which extends the standard MDP formulation to
accommodate decision-making based on observation histories. Building on this
framework, we introduce Depthwise Attention Twin Delayed Deep Deterministic
Policy Gradient (DATD3), a novel actor-critic algorithm that employs depthwise
separable convolution and multi-head attention to encode historical
observations. DATD3 maintains policy expressiveness while avoiding the
instability of recurrent models. Extensive experiments on continuous control
tasks demonstrate that DATD3 outperforms existing memory-based and recurrent
baselines under both partial and full observability.

</details>


### [16] [Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration](https://arxiv.org/abs/2505.23859)
*Wenju Sun,Qingyong Li,Wen Wang,Yang Liu,Yangli-ao Geng,Boyang Li*

Main category: cs.LG

TL;DR: 引入LOT Merging方法，通过减少特征漂移优化多任务模型合并，性能显著超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合多个任务特定专家为统一模型时，要么在参数级别存在显著性能差距，要么代价昂贵。鉴于性能下降与模型合并引起的特征漂移密切相关，故而提出了一种能有效减少特征漂移的新方法。

Method: 提出了一种称为Layer-wise Optimal Task Vector Merging（LOT Merging）的方法，通过分层分析减少模型合并过程中的特征漂移。这种方法可以被表述为凸二次优化问题，允许解析导出线性和归一化层的参数的闭式解。合并通过基本的矩阵运算实现高效的模型整合。

Result: 实验证明，LOT Merging在视觉和视觉-语言基准测试中明显优于现有方法，表现提升可达4.4%（ViT-B/32）。

Conclusion: 通过分层优化任务向量合并（LOT Merging）方法，显著减少了多任务模型合并过程中的特征漂移和性能下降。在多个视觉和视觉-语言基准上，LOT Merging表现优于基线方法，提升幅度可达4.4%。

Abstract: Multi-task model merging aims to consolidate knowledge from multiple
fine-tuned task-specific experts into a unified model while minimizing
performance degradation. Existing methods primarily approach this by minimizing
differences between task-specific experts and the unified model, either from a
parameter-level or a task-loss perspective. However, parameter-level methods
exhibit a significant performance gap compared to the upper bound, while
task-loss approaches entail costly secondary training procedures. In contrast,
we observe that performance degradation closely correlates with feature drift,
i.e., differences in feature representations of the same sample caused by model
merging. Motivated by this observation, we propose Layer-wise Optimal Task
Vector Merging (LOT Merging), a technique that explicitly minimizes feature
drift between task-specific experts and the unified model in a layer-by-layer
manner. LOT Merging can be formulated as a convex quadratic optimization
problem, enabling us to analytically derive closed-form solutions for the
parameters of linear and normalization layers. Consequently, LOT Merging
achieves efficient model consolidation through basic matrix operations.
Extensive experiments across vision and vision-language benchmarks demonstrate
that LOT Merging significantly outperforms baseline methods, achieving
improvements of up to 4.4% (ViT-B/32) over state-of-the-art approaches.

</details>


### [17] [BiBLDR: Bidirectional Behavior Learning for Drug Repositioning](https://arxiv.org/abs/2505.23861)
*Renye Zhang,Mengyun Yang,Qichang Zhao,Jianxin Wang*

Main category: cs.LG

TL;DR: 提出BiBLDR方法，通过双向行为学习策略，提高药物重新定位在冷启动情境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有药物重新定位方法在处理新药物的冷启动情境时效能有限，因此需要一种新的方法来有效捕捉药物-疾病的交互模式。

Method: 提出了一种双向行为学习策略，称为BiBLDR。首先构建双向行为序列，然后通过双阶段策略预测潜在的药物-疾病关联。

Result: 通过广泛实验验证，BiBLDR方法在基准数据集上达到了领先的性能，尤其是在冷启动情境中，表现出了显著优势。

Conclusion: BiBLDR方法在基准数据集上表现优异，特别是在冷启动情境下，性能显著超过之前的方法。

Abstract: Drug repositioning aims to identify potential new indications for existing
drugs to reduce the time and financial costs associated with developing new
drugs. Most existing deep learning-based drug repositioning methods
predominantly utilize graph-based representations. However, graph-based drug
repositioning methods struggle to perform effective inference in cold-start
scenarios involving novel drugs because of the lack of association information
with the diseases. Unlike traditional graph-based approaches, we propose a
bidirectional behavior learning strategy for drug repositioning, known as
BiBLDR. This innovative framework redefines drug repositioning as a behavior
sequential learning task to capture drug-disease interaction patterns. First,
we construct bidirectional behavioral sequences based on drug and disease
sides. The consideration of bidirectional information ensures a more meticulous
and rigorous characterization of the behavioral sequences. Subsequently, we
propose a two-stage strategy for drug repositioning. In the first stage, we
construct prototype spaces to characterize the representational attributes of
drugs and diseases. In the second stage, these refined prototypes and
bidirectional behavior sequence data are leveraged to predict potential
drug-disease associations. Based on this learning approach, the model can more
robustly and precisely capture the interactive relationships between drug and
disease features from bidirectional behavioral sequences. Extensive experiments
demonstrate that our method achieves state-of-the-art performance on benchmark
datasets. Meanwhile, BiBLDR demonstrates significantly superior performance
compared to previous methods in cold-start scenarios. Our code is published in
https://github.com/Renyeeah/BiBLDR.

</details>


### [18] [Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting](https://arxiv.org/abs/2505.23863)
*Chang Liu,Bohao Zhao,Jingtao Ding,Huandong Wang,Yong Li*

Main category: cs.LG

TL;DR: PhyxMamba通过创新的框架和训练方案，实现了在短期观察下对混沌系统的长期预测，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖长时间训练数据或者专注于短期序列相关性，但难以在长期预测中保持预测稳定性和动态一致性。因此，研究旨在应对这一挑战。

Method: 提出了一种名为PhyxMamba的框架，通过整合基于Mamba的状态空间模型与物理信息原则，使用时间延迟嵌入来重建吸引子流形，从而提取全球动态特征。

Result: 在多种模拟和现实世界的混沌系统中进行的广泛评估表明，PhyxMamba提供了更优的长期预测能力，并能够从短期数据中准确捕捉动态不变量。

Conclusion: PhyxMamba能够有效进行长时间的混沌系统预测，并在短期数据下忠实捕捉动态不变量。

Abstract: Long-term forecasting of chaotic systems from short-term observations remains
a fundamental and underexplored challenge due to the intrinsic sensitivity to
initial conditions and the complex geometry of strange attractors. Existing
approaches often rely on long-term training data or focus on short-term
sequence correlations, struggling to maintain predictive stability and
dynamical coherence over extended horizons. We propose PhyxMamba, a novel
framework that integrates a Mamba-based state-space model with physics-informed
principles to capture the underlying dynamics of chaotic systems. By
reconstructing the attractor manifold from brief observations using time-delay
embeddings, PhyxMamba extracts global dynamical features essential for accurate
forecasting. Our generative training scheme enables Mamba to replicate the
physical process, augmented by multi-token prediction and attractor geometry
regularization for physical constraints, enhancing prediction accuracy and
preserving key statistical invariants. Extensive evaluations on diverse
simulated and real-world chaotic systems demonstrate that PhyxMamba delivers
superior long-term forecasting and faithfully captures essential dynamical
invariants from short-term data. This framework opens new avenues for reliably
predicting chaotic systems under observation-scarce conditions, with broad
implications across climate science, neuroscience, epidemiology, and beyond.
Our code is open-source at https://github.com/tsinghua-fib-lab/PhyxMamba.

</details>


### [19] [Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections](https://arxiv.org/abs/2505.23864)
*Wei Zhuo,Zhaohuan Zhan,Ziduo Yang,Han Yu*

Main category: cs.LG

TL;DR: FedAux通过个性化子图联邦学习框架解决了联邦学习中的非IID问题，并在多项图基准上展现了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中由于每个客户端持有不同子图而导致的非独立同分布问题，提高个性化模型的性能。

Method: FedAux通过共同训练本地GNN和可学习的辅助投影向量，使得节点嵌入能够在有序空间中进行1D卷积优化。

Result: FedAux在多个图数据基准上均显著优于现有基线，在准确性和个性化表现上都有提升。

Conclusion: FedAux通过引入辅助投影和软排序技术，有效解决了图结构数据中的非独立同分布问题，提高了模型的准确性和个性化表现。

Abstract: Federated learning (FL) on graph-structured data typically faces non-IID
challenges, particularly in scenarios where each client holds a distinct
subgraph sampled from a global graph. In this paper, we introduce Federated
learning with Auxiliary projections (FedAux), a personalized subgraph FL
framework that learns to align, compare, and aggregate heterogeneously
distributed local models without sharing raw data or node embeddings. In
FedAux, each client jointly trains (i) a local GNN and (ii) a learnable
auxiliary projection vector (APV) that differentiably projects node embeddings
onto a 1D space. A soft-sorting operation followed by a lightweight 1D
convolution refines these embeddings in the ordered space, enabling the APV to
effectively capture client-specific information. After local training, these
APVs serve as compact signatures that the server uses to compute inter-client
similarities and perform similarity-weighted parameter mixing, yielding
personalized models while preserving cross-client knowledge transfer. Moreover,
we provide rigorous theoretical analysis to establish the convergence and
rationality of our design. Empirical evaluations across diverse graph
benchmarks demonstrate that FedAux substantially outperforms existing baselines
in both accuracy and personalization performance.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [20] [Rules, agents and order](https://arxiv.org/abs/2505.23985)
*Amalia Puente,Diego Radillo-Ochoa,C. A. Terrero-Escalante*

Main category: nlin.AO

TL;DR: 研究探讨了有限规模网络中，系统选择规则和功能性角色如何影响随机过程形成的全局秩序。


<details>
  <summary>Details</summary>
Motivation: 研究在不同系统选择规则和特殊代理的组合下，随机过程如何产生全局秩序，特别关注有限规模网络。

Method: 使用大规模的Erdos-Renyi模型作为基准，比较随机链接添加过程与目标导向动态过程，包括芯片激发模型和细胞内网络生长，通过运输效率驱动。通过仿真和结构探测（如k核分解和HITS中心性）进行研究。

Result: 纯粹的随机过程可以自发产生适度的功能结构，但显著偏离随机行为一般需要两个关键条件：临界的拓扑复杂性以及拓扑与功能性的动态对齐。

Conclusion: 功能性架构的出现不仅依赖于选择机制或专业角色的存在，还依赖于网络支持功能差异与反馈的能力。

Abstract: Complex systems often exhibit highly structured network topologies that
reflect functional constraints. In this work, we investigate how, under varying
combinations of system-wide selection rules and special agents, different
classes of random processes give rise to global order, with a focus restricted
to finite-size networks. Using the large-$N$ Erdos-Renyi model as a null
baseline, we contrast purely random link-adding processes with goal-directed
dynamics, including variants of the chip-firing model and intracellular network
growth, both driven by transport efficiency. Through simulations and structural
probes such as $k$-core decomposition and $HITS$ centrality, we show that
purely stochastic processes can spontaneously generate modest functional
structures, but that significant departures from random behavior generically
require two key conditions: critical topological complexity and dynamic
alignment between topology and functionality. Our results suggest that the
emergence of functional architectures depends not only on the presence of
selection mechanisms or specialized roles, but also on the network's capacity
to support differentiation and feedback. These findings provide insight into
how topology-functionality relationships emerge in natural and artificial
systems and offer a framework for using random graph baselines to diagnose the
rise of global order in evolving finite-size networks.

</details>


### [21] [Cascades on Constrained Multiplex Networks](https://arxiv.org/abs/2505.24631)
*Christian Kluge,Christian Kuehn*

Main category: nlin.AO

TL;DR: 研究了Watts级联模型在多路复用网络上的行为，引入了约束多路复用网络，并发现诱导模式的选择影响相变。


<details>
  <summary>Details</summary>
Motivation: 研究在多层网络中节点活动的诱导模式如何影响级联模型的相变。

Method: 使用方向多路复用配置模型网络版本的Watts级联模型，详细分析了级联大小、单种子级联概率和级联条件，并引入了一类更小的网络模型——约束多路复用网络。

Result: 诱导模式的选择影响了级联模型的相变。

Conclusion: 在约束多路复用网络中诱导模式的选择会以多种方式影响级联模型的相变。

Abstract: We consider a version of the Watts cascade model on directed multiplex
configuration model networks, and present a detailed analysis of the cascade
size, single-seed cascade probability and cascade condition. We then introduce
a smaller class of network models that we call constrained multiplex networks,
which allows us to induce patterns in the node activity, i.e. in the
participation of nodes on different layers. We find that the choice of induced
patterns affects the phase transitions of the cascade model in a variety of
ways.

</details>


### [22] [Symmetry breaking in minimum dissipation networks](https://arxiv.org/abs/2505.24818)
*Aarathi Parameswaran,Iva Bačić,Andrea Benigni,Dirk Witthaut*

Main category: nlin.AO

TL;DR: 研究表明，供给网络的优化结构受到波动影响，可能经历对称破缺和对称状态之间的转变。


<details>
  <summary>Details</summary>
Motivation: 理解供给网络中普遍存在的结构模式，并通过优化模型分析生物网络和技术网络的演化及设计。

Method: 分析最小化耗散网络结构中的自发对称破缺现象，并研究资源缩放的影响。

Result: 展示了资源缩放对网络结构的影响，以及波动如何导致复杂的结构变化。

Conclusion: 网络中的波动会影响网络结构，并可能导致从对称破缺状态到对称状态的重复转变。

Abstract: Both natural and man-made supply networks exhibit universal structural
patterns, such as the formation of loops. These patterns can be understood in
terms of optimization models, assuming that biological networks evolved to
optimal states and technical networks are designed to function optimally. In
this article, we analyze networks that minimize dissipation under a research
constraint. We demonstrate spontaneous symmetry breaking in optimal network
structures as a function of resource scaling. We show that fluctuations
intricately impact the structure and can lead to a reentrant transition from a
symmetry-broken state to a symmetric state and back again.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [23] [Synergistic motifs in linear Gaussian systems](https://arxiv.org/abs/2505.24686)
*Enrico Caprioglio,Luc Berthouze*

Main category: physics.soc-ph

TL;DR: 研究揭示线性系统中的成对作用如何生成协同信息，突出结构平衡理论对高阶依赖性研究的价值。


<details>
  <summary>Details</summary>
Motivation: 尽管复杂系统中的高阶相互依赖性至关重要，但其出现的机械解释仍不明确。该研究旨在通过数学模型探究协同优势的机制。

Method: 通过对任意维度的线性高斯系统，推导出在系统相关矩阵中的符号网络基元方面的协同-主导表达式。

Result: 在Ornstein-Uhlenbeck过程的二元交互矩阵中，证明了反平衡相关结构确保协同-主导，并且反平衡三元组对于协同-主导是必要的。

Conclusion: 成对的相互作用可以在没有显式高阶机制的情况下产生协同信息，结构平衡理论是研究高阶相互依赖性的重要概念框架。

Abstract: Higher-order interdependencies are central features of complex systems, yet a
mechanistic explanation for their emergence remains elusive. For linear
Gaussian systems of arbitrary dimension, we derive an expression for
synergy-dominance in terms of signed network motifs in the system's correlation
matrix. We prove that antibalanced correlational structures ensure
synergy-dominance and further show that antibalanced triads in the dyadic
interaction matrix of Ornstein-Uhlenbeck processes are necessary for
synergy-dominance. Our results demonstrate that pairwise interactions alone can
give rise to synergistic information in the absence of explicit higher-order
mechanisms, and highlight structural balance theory as an instrumental
conceptual framework to study higher-order interdependencies.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [24] [On the Parallels Between Evolutionary Theory and the State of AI](https://arxiv.org/abs/2505.23774)
*Zeki Doruk Erden,Boi Faltings*

Main category: q-bio.NC

TL;DR: 文章探讨了现代AI方法的局限性，并提出通过结合进化理论的新见解，来为AI设计出新的解决途径。


<details>
  <summary>Details</summary>
Motivation: 通过将现代AI领域与20世纪进化生物学的现代综合体进行比较，揭示进化理论的进步如何能够为AI的新设计范式提供启示。

Method: 文章通过批判性地审视现代AI方法的基本原则，探讨限制其潜力的因素。

Result: 通过综合AI和进化理论的发现，提出了克服现有局限性的新途径，使AI能够实现其抱负目标。

Conclusion: 现代AI的方法存在局限性，而借鉴进化发育生物学的进步可以为AI提供新的设计范式，从而克服这些局限性。

Abstract: This article critically examines the foundational principles of contemporary
AI methods, exploring the limitations that hinder its potential. We draw
parallels between the modern AI landscape and the 20th-century Modern Synthesis
in evolutionary biology, and highlight how advancements in evolutionary theory
that augmented the Modern Synthesis, particularly those of Evolutionary
Developmental Biology, offer insights that can inform a new design paradigm for
AI. By synthesizing findings across AI and evolutionary theory, we propose a
pathway to overcome existing limitations, enabling AI to achieve its
aspirational goals.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [25] [Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play](https://arxiv.org/abs/2505.18334)
*Jiaxun Cui,Chen Tang,Jarrett Holtz,Janice Nguyen,Alessandro G. Allievi,Hang Qiu,Peter Stone*

Main category: cs.RO

TL;DR: The paper proposes LLM+Debrief method, enabling autonomous vehicles to communicate in natural language for better coordination. It outperforms zero-shot LLMs in generating human-understandable messages, improving cooperation in driving scenarios.


<details>
  <summary>Details</summary>
Motivation: To facilitate autonomous vehicles in communicating in a human-understandable way, thus improving cooperative driving with both autonomous and human drivers.

Method: Introduces LLM+Debrief, a novel method for learning message generation and high-level decision-making policy through multi-agent discussion.

Result: LLM+Debrief outperforms zero-shot LLM agents in generating meaningful language messages for coordination among vehicles.

Conclusion: LLM+Debrief is more effective at generating meaningful and human-understandable natural language messages for vehicle coordination than a zero-shot LLM agent.

Abstract: Past work has demonstrated that autonomous vehicles can drive more safely if
they communicate with one another than if they do not. However, their
communication has often not been human-understandable. Using natural language
as a vehicle-to-vehicle (V2V) communication protocol offers the potential for
autonomous vehicles to drive cooperatively not only with each other but also
with human drivers. In this work, we propose a suite of traffic tasks in
autonomous driving where vehicles in a traffic scenario need to communicate in
natural language to facilitate coordination in order to avoid an imminent
collision and/or support efficient traffic flow. To this end, this paper
introduces a novel method, LLM+Debrief, to learn a message generation and
high-level decision-making policy for autonomous vehicles through multi-agent
discussion. To evaluate LLM agents for driving, we developed a gym-like
simulation environment that contains a range of driving scenarios. Our
experimental results demonstrate that LLM+Debrief is more effective at
generating meaningful and human-understandable natural language messages to
facilitate cooperation and coordination than a zero-shot LLM agent. Our code
and demo videos are available at https://talking-vehicles.github.io/.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [26] [Finite-time scaling on low-dimensional map bifurcations](https://arxiv.org/abs/2505.24673)
*Daniel A. Martin,Qian-Yuan Tang,Dante R. Chialvo*

Main category: cond-mat.dis-nn

TL;DR: 本研究扩展了有限时间尺度化方法，通过数值分析验证了1D和2D映射中的分岔行为，定义新指标并揭示时间和空间观测量的联系，为研究复杂系统提供新视角。


<details>
  <summary>Details</summary>
Motivation: 为了扩展有限时间尺度化方法的应用，该方法类似于在有限系统中研究临界行为的有限尺寸尺度化，应用于确定性离散动力系统的分岔图。

Method: 文章首先对1D映射进行数值分析，这些映射展示了周期加倍分岔和不连续的转变。然后，定义了有限时间易感性和有限时间Lyapunov指数两个观测量来研究分岔点附近的缩放行为。方法还被推广到包括2D Chialvo映射在内的2D映射的特殊情况。

Result: 数值结果证明了1D映射的周期加倍分岔和不连续转变，并展示了有限时间易感性和有限时间Lyapunov指数在分岔点附近的一致缩放行为。方法也成功应用于2D映射，包括捕获2D Chialvo映射中分岔从一个固定点到一个周期轨道的行为。

Conclusion: 通过有限时间尺度化方法，我们发现时间和空间观测量在复杂系统中存在基本联系，这为研究复杂动态行为提供了新的途径。

Abstract: Recent work has introduced the concept of finite-time scaling to characterize
bifurcation diagrams at finite times in deterministic discrete dynamical
systems, drawing an analogy with finite-size scaling used to study critical
behavior in finite systems. In this work, we extend the finite-time scaling
approach in several key directions. First, we present numerical results for 1D
maps exhibiting period-doubling bifurcations and discontinuous transitions,
analyzing selected paradigmatic examples. We then define two observables, the
finite-time susceptibility and the finite-time Lyapunov exponent, that also
display consistent scaling near bifurcation points. The method is further
generalized to special cases of 2D maps including the 2D Chialvo map, capturing
its bifurcation between a fixed point and a periodic orbit, while accounting
for discontinuities and asymmetric periodic orbits. These results underscore
fundamental connections between temporal and spatial observables in complex
systems, suggesting new avenues for studying complex dynamical behavior.

</details>
