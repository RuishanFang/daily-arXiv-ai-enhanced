{"id": "2506.00066", "pdf": "https://arxiv.org/pdf/2506.00066", "abs": "https://arxiv.org/abs/2506.00066", "authors": ["Arne Tillmann"], "title": "Literature Review Of Multi-Agent Debate For Problem-Solving", "categories": ["cs.MA", "cs.AI", "I.2.7"], "comment": "11 pages, 2 figures", "summary": "Multi-agent large language models (MA-LLMs) are a rapidly growing research\narea that leverages multiple interacting language agents to tackle complex\ntasks, outperforming single-agent large language models. This literature review\nsynthesizes the latest research on agent profiles, communication structures,\nand decision-making processes, drawing insights from both traditional\nmulti-agent systems and state-of-the-art MA-LLM studies. In doing so, it aims\nto address the lack of direct comparisons in the field, illustrating how\nfactors like scalability, communication structure, and decision-making\nprocesses influence MA-LLM performance. By examining frequent practices and\noutlining current challenges, the review reveals that multi-agent approaches\ncan yield superior results but also face elevated computational costs and\nunder-explored challenges unique to MA-LLM. Overall, these findings provide\nresearchers and practitioners with a roadmap for developing robust and\nefficient multi-agent AI solutions.", "AI": {"tldr": "\u8be5\u6587\u732e\u7efc\u8ff0\u7814\u7a76\u591a\u4ee3\u7406\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u6790\u5176\u4ee3\u7406\u7279\u6027\u3001\u901a\u8baf\u7ed3\u6784\u548c\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6307\u51fa\u8fd9\u4e9b\u6a21\u578b\u5728\u63d0\u4f9b\u4f18\u8d8a\u7ed3\u679c\u7684\u540c\u65f6\u4e5f\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u548c\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u9886\u57df\u4e2d\u7f3a\u4e4f\u76f4\u63a5\u6bd4\u8f83\u7684\u95ee\u9898\uff0c\u63ed\u793a\u56e0\u7d20\u5982\u53ef\u6269\u5c55\u6027\u3001\u901a\u8baf\u7ed3\u6784\u548c\u51b3\u7b56\u8fc7\u7a0b\u5982\u4f55\u5f71\u54cdMA-LLM\u6027\u80fd\u3002", "method": "\u8fd9\u7bc7\u6587\u732e\u7efc\u8ff0\u7efc\u5408\u4e86\u6709\u5173\u4ee3\u7406\u914d\u7f6e\u3001\u901a\u8baf\u7ed3\u6784\u548c\u51b3\u7b56\u8fc7\u7a0b\u7684\u6700\u65b0\u7814\u7a76\uff0c\u540c\u65f6\u501f\u9274\u4e86\u4f20\u7edf\u591a\u4ee3\u7406\u7cfb\u7edf\u548c\u6700\u5148\u8fdb\u7684MA-LLM\u7814\u7a76\u4e2d\u7684\u89c1\u89e3\u3002", "result": "\u901a\u8fc7\u5ba1\u89c6\u5e38\u89c1\u7684\u5b9e\u8df5\u5e76\u6982\u8ff0\u5f53\u524d\u7684\u6311\u6218\uff0c\u8fd9\u7bc7\u7efc\u8ff0\u8868\u660e\u591a\u4ee3\u7406\u65b9\u6cd5\u53ef\u4ee5\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u4e5f\u9762\u4e34\u7740\u66f4\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\u548cMA-LLM\u7279\u6709\u7684\u672a\u89e3\u51b3\u6311\u6218\u3002", "conclusion": "\u591a\u4ee3\u7406\u8bed\u8a00\u6a21\u578b\uff08MA-LLM\uff09\u80fd\u591f\u63d0\u4f9b\u4f18\u4e8e\u5355\u4e00\u4ee3\u7406\u6a21\u578b\u7684\u7ed3\u679c\uff0c\u4f46\u540c\u65f6\u4e5f\u9762\u4e34\u66f4\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\u548c\u5c1a\u5f85\u63a2\u7d22\u7684\u6311\u6218\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5f00\u53d1\u5f3a\u5927\u4e14\u9ad8\u6548\u7684\u591a\u4ee3\u7406AI\u89e3\u51b3\u65b9\u6848\u7684\u8def\u7ebf\u56fe\u3002"}}
{"id": "2506.00228", "pdf": "https://arxiv.org/pdf/2506.00228", "abs": "https://arxiv.org/abs/2506.00228", "authors": ["Rebekah A. Gelp\u00ed", "Yibing Ju", "Ethan C. Jackson", "Yikai Tang", "Shon Verch", "Claas Voelcker", "William A. Cunningham"], "title": "Sorrel: A simple and flexible framework for multi-agent reinforcement learning", "categories": ["cs.MA", "cs.LG"], "comment": null, "summary": "We introduce Sorrel (https://github.com/social-ai-uoft/sorrel), a simple\nPython interface for generating and testing new multi-agent reinforcement\nlearning environments. This interface places a high degree of emphasis on\nsimplicity and accessibility, and uses a more psychologically intuitive\nstructure for the basic agent-environment loop, making it a useful tool for\nsocial scientists to investigate how learning and social interaction leads to\nthe development and change of group dynamics. In this short paper, we outline\nthe basic design philosophy and features of Sorrel.", "AI": {"tldr": "Sorrel\u662f\u4e00\u4e2a\u7b80\u5316\u548c\u76f4\u89c2\u7684Python\u63a5\u53e3\uff0c\u9002\u7528\u4e8e\u521b\u5efa\u548c\u6d4b\u8bd5\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u7279\u522b\u5bf9\u793e\u4f1a\u79d1\u5b66\u5bb6\u6709\u7528\u3002", "motivation": "\u4e3a\u4e86\u4e3a\u793e\u4f1a\u79d1\u5b66\u5bb6\u63d0\u4f9b\u4e00\u4e2a\u76f4\u89c2\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u5de5\u5177\u6765\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u7fa4\u4f53\u52a8\u6001\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86Sorrel\u7684\u57fa\u672c\u8bbe\u8ba1\u7406\u5ff5\u548c\u529f\u80fd\uff0c\u5f3a\u8c03\u5176\u7b80\u5355\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u5e76\u4f7f\u7528\u66f4\u7b26\u5408\u5fc3\u7406\u5b66\u76f4\u89c9\u7684\u7ed3\u6784\u3002", "result": "\u672c\u6587\u6ca1\u6709\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u800c\u662f\u63cf\u8ff0\u4e86Sorrel\u63a5\u53e3\u7684\u8bbe\u8ba1\u7279\u8272\u3002", "conclusion": "Sorrel\u662f\u4e00\u4e2a\u6709\u52a9\u4e8e\u793e\u4f1a\u79d1\u5b66\u5bb6\u7814\u7a76\u5b66\u4e60\u548c\u793e\u4f1a\u4e92\u52a8\u5982\u4f55\u5bfc\u81f4\u7fa4\u4f53\u52a8\u6001\u53d1\u5c55\u548c\u53d8\u5316\u7684\u6709\u7528\u5de5\u5177\u3002"}}
{"id": "2506.00703", "pdf": "https://arxiv.org/pdf/2506.00703", "abs": "https://arxiv.org/abs/2506.00703", "authors": ["Anahita Jain", "Husni Idris", "John-Paul Clarke", "Daniel Delahaye"], "title": "Adaptive Traffic-Following Scheme for Orderly Distributed Control of Multi-Vehicle Systems", "categories": ["cs.MA", "cs.ET", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "We present an adaptive control scheme to enable the emergence of order within\ndistributed, autonomous multi-agent systems. Past studies showed that under\nhigh-density conditions, order generated from traffic-following behavior\nreduces travel times, while under low densities, choosing direct paths is more\nbeneficial. In this paper, we leveraged those findings to allow aircraft to\nindependently and dynamically adjust their degree of traffic-following behavior\nbased on the current state of the airspace. This enables aircraft to follow\nother traffic only when beneficial. Quantitative analyses revealed that dynamic\ntraffic-following behavior results in lower aircraft travel times at the cost\nof minimal levels of additional disorder to the airspace. The sensitivity of\nthese benefits to temporal and spatial horizons was also investigated. Overall,\nthis work highlights the benefits, and potential necessity, of incorporating\nself-organizing behavior in making distributed, autonomous multi-agent systems\nscalable.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u6027\u63a7\u5236\u65b9\u6848\uff0c\u901a\u8fc7\u8ba9\u98de\u673a\u6839\u636e\u5f53\u524d\u7a7a\u57df\u52a8\u6001\u8c03\u6574\u5176\u4ea4\u901a\u8ddf\u968f\u884c\u4e3a\uff0c\u5728\u4f4e\u98de\u884c\u65f6\u95f4\u548c\u8f83\u5c11\u7a7a\u57df\u5931\u5e8f\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u65e9\u671f\u7814\u7a76\u8868\u660e\uff0c\u9ad8\u5bc6\u5ea6\u6761\u4ef6\u4e0b\u7531\u4ea4\u901a\u8ddf\u968f\u884c\u4e3a\u751f\u6210\u7684\u79e9\u5e8f\u53ef\u51cf\u5c11\u65c5\u884c\u65f6\u95f4\uff0c\u800c\u5728\u4f4e\u5bc6\u5ea6\u4e0b\uff0c\u9009\u62e9\u76f4\u63a5\u8def\u5f84\u5219\u66f4\u5177\u4f18\u52bf\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63a2\u7d22\u5982\u4f55\u8ba9\u98de\u673a\u6839\u636e\u7a7a\u6c14\u6d41\u91cf\u81ea\u4e3b\u8c03\u6574\u5176\u4ea4\u901a\u8ddf\u968f\u884c\u4e3a\uff0c\u4ece\u800c\u4f18\u5316\u98de\u884c\u65f6\u95f4\u3002", "method": "\u901a\u8fc7\u8c03\u6574\u98de\u673a\u81ea\u8eab\u8ffd\u968f\u4ea4\u901a\u884c\u4e3a\u7684\u7a0b\u5ea6\uff0c\u4f7f\u5176\u80fd\u591f\u52a8\u6001\u9002\u5e94\u5f53\u524d\u7a7a\u57df\u72b6\u51b5\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u98de\u884c\u65f6\u95f4\u4e0e\u8f83\u5c11\u7684\u7a7a\u57df\u5931\u5e8f\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "result": "\u52a8\u6001\u4ea4\u901a\u8ddf\u968f\u884c\u4e3a\u80fd\u5728\u8f83\u4f4e\u98de\u884c\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\uff0c\u4fdd\u6301\u8f83\u4f4e\u7a0b\u5ea6\u7684\u7a7a\u57df\u5931\u5e8f\u3002", "conclusion": "\u7efc\u5408\u6765\u770b\uff0c\u5728\u5206\u5e03\u5f0f\u81ea\u6cbb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u52a0\u5165\u81ea\u7ec4\u7ec7\u884c\u4e3a\u6709\u663e\u8457\u76ca\u5904\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u662f\u5fc5\u8981\u7684\u3002\u8fd9\u79cd\u884c\u4e3a\u4f7f\u7cfb\u7edf\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.01463", "pdf": "https://arxiv.org/pdf/2506.01463", "abs": "https://arxiv.org/abs/2506.01463", "authors": ["V. Botti"], "title": "Agentic AI and Multiagentic: Are We Reinventing the Wheel?", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "The terms Agentic AI and Multiagentic AI have recently gained popularity in\ndiscussions on generative artificial intelligence, often used to describe\nautonomous software agents and systems composed of such agents. However, the\nuse of these terms confuses these buzzwords with well-established concepts in\nAI literature: intelligent agents and multi-agent systems. This article offers\na critical analysis of this conceptual misuse. We review the theoretical\norigins of \"agentic\" in the social sciences (Bandura, 1986) and philosophical\nnotions of intentionality (Dennett, 1971), and then summarise foundational\nworks on intelligent agents and multi-agent systems by Wooldridge, Jennings and\nothers. We examine classic agent architectures, from simple reactive agents to\nBelief-Desire-Intention (BDI) models, and highlight key properties (autonomy,\nreactivity, proactivity, social capability) that define agency in AI. We then\ndiscuss recent developments in large language models (LLMs) and agent platforms\nbased on LLMs, including the emergence of LLM-powered AI agents and open-source\nmulti-agent orchestration frameworks. We argue that the term AI Agentic is\noften used as a buzzword for what are essentially AI agents, and AI\nMultiagentic for what are multi-agent systems. This confusion overlooks decades\nof research in the field of autonomous agents and multi-agent systems. The\narticle advocates for scientific and technological rigour and the use of\nestablished terminology from the state of the art in AI, incorporating the\nwealth of existing knowledge, including standards for multi-agent system\nplatforms, communication languages and coordination and cooperation algorithms,\nagreement technologies (automated negotiation, argumentation, virtual\norganisations, trust, reputation, etc.), into the new and promising wave of\nLLM-based AI agents, so as not to end up reinventing the wheel.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Agentic AI\u548cMultiagentic AI\u7684\u6982\u5ff5\u8bef\u7528\uff0c\u547c\u5401\u6b63\u786e\u4f7f\u7528\u4f20\u7edfAI\u672f\u8bed\u4ee5\u907f\u514d\u77e5\u8bc6\u91cd\u5efa\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u7ea0\u6b63\u5f53\u524d\u5728AI\u672f\u8bed\u7279\u522b\u662fAgentic AI\u548cMultiagentic AI\u4f7f\u7528\u4e0a\u7684\u6982\u5ff5\u8bef\u7528\uff0c\u5e76\u5c55\u793a\u5176\u4e0e\u4f20\u7edfAI\u9886\u57df\u672f\u8bed\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u56de\u987e\u793e\u4ea4\u79d1\u5b66\u548c\u54f2\u5b66\u4e2d\u7684\u7406\u8bba\u8d77\u6e90\uff0c\u4ee5\u53ca\u5bf9\u5efa\u7acb\u5728\u6b64\u57fa\u7840\u4e0a\u7684\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7ecf\u5178\u4f5c\u54c1\u8fdb\u884c\u5206\u6790\u4e0e\u603b\u7ed3\u3002", "result": "\u53d1\u73b0\u8bb8\u591a\u4eba\u5c06\u672f\u8bedAgentic AI\u548cMultiagentic AI\u5bbd\u6cdb\u4f7f\u7528\u4e3a\u6d41\u884c\u8bcd\uff0c\u5b9e\u9645\u4e0a\u5b83\u4eec\u5206\u522b\u5bf9\u5e94\u4e8eAI\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5ffd\u89c6\u4e86\u8be5\u9886\u57df\u4e2d\u81ea\u4e3b\u6f14\u5458\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6570\u5341\u5e74\u7684\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u79d1\u5b66\u548c\u6280\u672f\u4e25\u683c\u6027\u7684\u91cd\u8981\u6027\uff0c\u547c\u5401\u5728\u65b0\u7684LLM\u65f6\u4ee3\u6b63\u786e\u4f7f\u7528AI\u672f\u8bed\uff0c\u4ee5\u907f\u514d\u91cd\u65b0\u53d1\u660e\u8f6e\u5b50\u7684\u95ee\u9898\u3002"}}
{"id": "2506.00019", "pdf": "https://arxiv.org/pdf/2506.00019", "abs": "https://arxiv.org/abs/2506.00019", "authors": ["William Alberto Cruz-Casta\u00f1eda", "Marcellus Amadeus"], "title": "Amadeus-Verbo Technical Report: The powerful Qwen2.5 family models trained in Portuguese", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This report introduces the experience of developing Amadeus Verbo, a family\nof large language models for Brazilian Portuguese. To handle diverse use cases,\nAmadeus Verbo includes base-tuned, merged, and instruction-tuned models in\nsizes of 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B parameters. Thus, the main\nobjective is to show how easy it is to fine-tune foundation models to\ndemocratize the open-source development of Brazilian Portuguese LLMs when data\nand resources are available. Amadeus-Verbo family models are all available at\nHuggingFace at\nhttps://huggingface.co/collections/amadeusai/amadeus-verbo-qwen25-67cf2e7aae69ce2b3bcdcfda.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Amadeus Verbo\uff0c\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u5217\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5fae\u8c03\u6a21\u578b\u5b9e\u73b0\u5f00\u6e90\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5b9e\u73b0\u5176\u5f00\u6e90\u5316\uff0c\u4ee5\u6ee1\u8db3\u591a\u6837\u5316\u7684\u4f7f\u7528\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u7cfb\u5217\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u57fa\u7840\u5fae\u8c03\u3001\u5408\u5e76\u548c\u6307\u4ee4\u5fae\u8c03\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u4e2a\u53c2\u6570\u89c4\u6a21\u7684\u5df4\u897f\u8461\u8404\u7259\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u5217\uff0c\u5e76\u5728HuggingFace\u4e0a\u5f00\u6e90\u3002", "conclusion": "\u5c55\u793a\u4e86\u5982\u4f55\u8f7b\u677e\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u6765\u5b9e\u73b0\u5df4\u897f\u8461\u8404\u7259\u8bed\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f00\u6e90\u5f00\u53d1\u3002"}}
{"id": "2506.00030", "pdf": "https://arxiv.org/pdf/2506.00030", "abs": "https://arxiv.org/abs/2506.00030", "authors": ["Xiang Shi", "Rui Zhang", "Jiawei Liu", "Yinpeng Liu", "Qikai Cheng", "Wei Lu"], "title": "Modality Equilibrium Matters: Minor-Modality-Aware Adaptive Alternating for Cross-Modal Memory Enhancement", "categories": ["cs.LG"], "comment": "work in progress", "summary": "Multimodal fusion is susceptible to modality imbalance, where dominant\nmodalities overshadow weak ones, easily leading to biased learning and\nsuboptimal fusion, especially for incomplete modality conditions. To address\nthis problem, we propose a Shapley-guided alternating training framework that\nadaptively prioritizes minor modalities to balance and thus enhance the fusion.\nOur method leverages Shapley Value-based scheduling to improve the training\nsequence adaptively, ensuring that under-optimized modalities receive\nsufficient learning. Additionally, we introduce the memory module to refine and\ninherit modality-specific representations with a cross-modal mapping mechanism\nto align features at both the feature and sample levels. To further validate\nthe adaptability of the proposed approach, the encoder module empirically\nadopts both conventional and LLM-based backbones. With building up a novel\nmultimodal equilibrium metric, namely, equilibrium deviation metric (EDM), we\nevaluate the performance in both balance and accuracy across four multimodal\nbenchmark datasets, where our method achieves state-of-the-art (SOTA) results.\nMeanwhile, robustness analysis under missing modalities highlights its strong\ngeneralization capabilities. Accordingly, our findings reveal the untapped\npotential of alternating training, demonstrating that strategic modality\nprioritization fundamentally balances and promotes multimodal learning,\noffering a new paradigm for optimizing multimodal training dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdShapley\u5f15\u5bfc\u7684\u4ea4\u66ff\u8bad\u7ec3\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u878d\u5408\u4e2d\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7ed3\u679c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u6210\u7ee9\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u9488\u5bf9\u591a\u6a21\u6001\u878d\u5408\u4e2d\u5bb9\u6613\u53d1\u751f\u7684\u6a21\u6001\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u6a21\u6001\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u4ee5\u6539\u5584\u878d\u5408\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdShapley\u5f15\u5bfc\u7684\u4ea4\u66ff\u8bad\u7ec3\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u57fa\u4e8eShapley\u4ef7\u503c\u7684\u8c03\u5ea6\u81ea\u9002\u5e94\u5730\u6539\u8fdb\u8bad\u7ec3\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u8bb0\u5fc6\u6a21\u5757\u548c\u8de8\u6a21\u6001\u6620\u5c04\u673a\u5236\uff0c\u5728\u7279\u5f81\u548c\u6837\u672c\u7ea7\u522b\u4e0a\u5bf9\u9f50\u7279\u5f81\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5e73\u8861\u548c\u51c6\u786e\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u65b0\u7684(SOTA)\u7ed3\u679c\u3002\u540c\u65f6\uff0c\u5176\u5728\u7f3a\u5931\u6a21\u6001\u4e0b\u7684\u9c81\u68d2\u6027\u5206\u6790\u7a81\u51fa\u4e86\u5176\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ea4\u66ff\u8bad\u7ec3\u4e2d\u7684\u6218\u7565\u6027\u6a21\u6001\u4f18\u5148\u6392\u5e8f\u53ef\u4ee5\u5e73\u8861\u5e76\u4fc3\u8fdb\u591a\u6a21\u6001\u5b66\u4e60\uff0c\u63d0\u51fa\u4e86\u4f18\u5316\u591a\u6a21\u6001\u8bad\u7ec3\u52a8\u6001\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2506.00056", "pdf": "https://arxiv.org/pdf/2506.00056", "abs": "https://arxiv.org/abs/2506.00056", "authors": ["Hugon Lee", "Hyeonbin Moon", "Junhyeong Lee", "Seunghwa RYu"], "title": "Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human-AI Synergy", "categories": ["cs.AI", "physics.comp-ph"], "comment": "26 pages, 4 figures", "summary": "Artificial intelligence (AI) is reshaping inverse design across manufacturing\ndomain, enabling high-performance discovery in materials, products, and\nprocesses. However, purely data-driven approaches often struggle in realistic\nsettings characterized by sparse data, high-dimensional design spaces, and\nnontrivial physical constraints. This perspective argues for a new generation\nof design systems that transcend black-box modeling by integrating domain\nknowledge, physics-informed learning, and intuitive human-AI interfaces. We\nfirst demonstrate how expert-guided sampling strategies enhance data efficiency\nand model generalization. Next, we discuss how physics-informed machine\nlearning enables physically consistent modeling in data-scarce regimes.\nFinally, we explore how large language models emerge as interactive design\nagents connecting user intent with simulation tools, optimization pipelines,\nand collaborative workflows. Through illustrative examples and conceptual\nframeworks, we advocate that inverse design in manufacturing should evolve into\na unified ecosystem, where domain knowledge, physical priors, and adaptive\nreasoning collectively enable scalable, interpretable, and accessible AI-driven\ndesign systems.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u5c06\u9886\u57df\u77e5\u8bc6\u3001\u7269\u7406\u542f\u53d1\u5b66\u4e60\u4e0e\u4eba\u673a\u4ea4\u4e92\u7ed3\u5408\uff0c\u63d0\u5347\u9006\u5411\u8bbe\u8ba1\u4e2d\u7684AI\u7cfb\u7edf\u6548\u7387\u548c\u667a\u80fd\u6c34\u5e73\u3002", "motivation": "\u5f53\u524d\u7684\u9006\u5411\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\uff0c\u5b8c\u5168\u4f9d\u8d56\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u5728\u7a00\u758f\u6570\u636e\u3001\u9ad8\u7ef4\u8bbe\u8ba1\u7a7a\u95f4\u4ee5\u53ca\u590d\u6742\u7269\u7406\u7ea6\u675f\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u4e13\u5bb6\u6307\u5bfc\u7684\u91c7\u6837\u7b56\u7565\u3001\u7269\u7406\u542f\u53d1\u7684\u673a\u5668\u5b66\u4e60\uff0c\u5e76\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4ea4\u4e92\u5f0f\u8bbe\u8ba1\u4ee3\u7406\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9006\u5411\u8bbe\u8ba1\u7cfb\u7edf\u6846\u67b6\uff0c\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u7269\u7406\u5148\u9a8c\u548c\u81ea\u9002\u5e94\u63a8\u7406\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u548c\u53ef\u8bbf\u95ee\u7684AI\u9a71\u52a8\u8bbe\u8ba1\u7cfb\u7edf\u3002", "conclusion": "\u9006\u5411\u8bbe\u8ba1\u5e94\u53d1\u5c55\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u6574\u5408\u9886\u57df\u77e5\u8bc6\u3001\u7269\u7406\u542f\u53d1\u548c\u4eba\u7c7b-AI\u4ea4\u4e92\uff0c\u4f7f\u8bbe\u8ba1\u7cfb\u7edf\u66f4\u9ad8\u6548\u548c\u667a\u80fd\u3002"}}
{"id": "2506.01839", "pdf": "https://arxiv.org/pdf/2506.01839", "abs": "https://arxiv.org/abs/2506.01839", "authors": ["Jennifer Haase", "Sebastian Pokutta"], "title": "Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research", "categories": ["cs.MA"], "comment": null, "summary": "As large language models (LLMs) transition from static tools to fully agentic\nsystems, their potential for transforming social science research has become\nincreasingly evident. This paper introduces a structured framework for\nunderstanding the diverse applications of LLM-based agents, ranging from simple\ndata processors to complex, multi-agent systems capable of simulating emergent\nsocial dynamics. By mapping this developmental continuum across six levels, the\npaper clarifies the technical and methodological boundaries between different\nagentic architectures, providing a comprehensive overview of current\ncapabilities and future potential. It highlights how lower-tier systems\nstreamline conventional tasks like text classification and data annotation,\nwhile higher-tier systems enable novel forms of inquiry, including the study of\ngroup dynamics, norm formation, and large-scale social processes. However,\nthese advancements also introduce significant challenges, including issues of\nreproducibility, ethical oversight, and the risk of emergent biases. The paper\ncritically examines these concerns, emphasizing the need for robust validation\nprotocols, interdisciplinary collaboration, and standardized evaluation\nmetrics. It argues that while LLM-based agents hold transformative potential\nfor the social sciences, realizing this promise will require careful,\ncontext-sensitive deployment and ongoing methodological refinement. The paper\nconcludes with a call for future research that balances technical innovation\nwith ethical responsibility, encouraging the development of agentic systems\nthat not only replicate but also extend the frontiers of social science,\noffering new insights into the complexities of human behavior.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4ece\u5de5\u5177\u5230\u4ee3\u7406\u7cfb\u7edf\u7684\u8f6c\u53d8\u8fc7\u7a0b\u53ca\u5176\u5bf9\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u4e0d\u540c\u4ee3\u7406\u67b6\u6784\u7684\u6846\u67b6\uff0c\u5e76\u8ba8\u8bba\u4e86\u76f8\u5173\u7684\u6280\u672f\u3001\u4f26\u7406\u6311\u6218\u548c\u7814\u7a76\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u9759\u6001\u5de5\u5177\u8f6c\u5411\u5b8c\u5168\u4ee3\u7406\u5316\u7cfb\u7edf\uff0c\u5176\u5bf9\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u8f6c\u578b\u6f5c\u529b\u65e5\u76ca\u663e\u8457\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u4e3a\u516d\u4e2a\u5c42\u6b21\u7684\u6846\u67b6\u6765\u7406\u89e3LLM\u4ee3\u7406\u7684\u5e94\u7528\uff0c\u4ece\u7b80\u5355\u7684\u6570\u636e\u5904\u7406\u5668\u5230\u590d\u6742\u7684\u3001\u591a\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u6a21\u62df\u793e\u4f1a\u52a8\u6001\uff0c\u9610\u660e\u4e0d\u540c\u4ee3\u7406\u67b6\u6784\u4e4b\u95f4\u7684\u6280\u672f\u548c\u65b9\u6cd5\u754c\u9650\uff0c\u63d0\u4f9b\u5f53\u524d\u80fd\u529b\u4e0e\u672a\u6765\u6f5c\u529b\u7684\u5168\u9762\u6982\u8ff0\u3002", "result": "\u672c\u6587\u5f3a\u8c03\u4e86\u4f4e\u7ea7\u7cfb\u7edf\u5982\u4f55\u7b80\u5316\u6587\u672c\u5206\u7c7b\u548c\u6570\u636e\u6807\u6ce8\u7b49\u4f20\u7edf\u4efb\u52a1\uff0c\u800c\u9ad8\u7ea7\u7cfb\u7edf\u5219\u5141\u8bb8\u65b0\u7684\u63a2\u7a76\u5f62\u5f0f\uff0c\u5305\u62ec\u7814\u7a76\u7fa4\u4f53\u52a8\u6001\u3001\u89c4\u8303\u5f62\u6210\u548c\u5927\u89c4\u6a21\u793e\u4f1a\u8fc7\u7a0b\u3002\u540c\u65f6\u4e5f\u63d0\u51fa\u4e86\u663e\u8457\u6311\u6218\uff0c\u5305\u62ec\u53ef\u91cd\u590d\u6027\u3001\u4f26\u7406\u76d1\u7763\u548c\u6f5c\u5728\u504f\u89c1\u7b49\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u5f3a\u6709\u529b\u7684\u9a8c\u8bc1\u534f\u8bae\u3001\u8de8\u5b66\u79d1\u5408\u4f5c\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u5c3d\u7ba1\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\u7cfb\u7edf\u5bf9\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u5177\u6709\u53d8\u9769\u6f5c\u529b\uff0c\u4f46\u5b9e\u73b0\u8fd9\u4e00\u627f\u8bfa\u9700\u8981\u4ed4\u7ec6\u3001\u60c5\u5883\u654f\u611f\u7684\u90e8\u7f72\u548c\u6301\u7eed\u7684\u65b9\u6cd5\u6539\u8fdb\u3002\u672c\u6587\u547c\u5401\u672a\u6765\u7684\u7814\u7a76\u5728\u6280\u672f\u521b\u65b0\u4e0e\u4f26\u7406\u8d23\u4efb\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u9f13\u52b1\u5f00\u53d1\u80fd\u591f\u4e0d\u4ec5\u4ec5\u590d\u5236\u800c\u4e14\u6269\u5c55\u793e\u4f1a\u79d1\u5b66\u8fb9\u754c\u7684\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ece\u800c\u63d0\u4f9b\u5173\u4e8e\u4eba\u7c7b\u884c\u4e3a\u590d\u6742\u6027\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2506.00022", "pdf": "https://arxiv.org/pdf/2506.00022", "abs": "https://arxiv.org/abs/2506.00022", "authors": ["Shenghe Zheng", "Qianjia Cheng", "Junchi Yao", "Mengsong Wu", "haonan he", "Ning Ding", "Yu Cheng", "Shuyue Hu", "Lei Bai", "Dongzhan Zhou", "Ganqu Cui", "Peng Ye"], "title": "Scaling Physical Reasoning with the PHYSICS Dataset", "categories": ["cs.CL", "cs.LG", "physics.ed-ph"], "comment": "Work on physical datasets", "summary": "Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86PHYSICS\u6570\u636e\u96c6\uff0c\u4e3aLLM\u5728\u7269\u7406\u9886\u57df\u7684\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u7269\u7406\u4efb\u52a1\u5904\u7406\u4e0a\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u7269\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u7406\u89e3\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u662f\u5728\u5b66\u672f\u548c\u5de5\u4e1a\u754c\u5374\u6ca1\u6709\u5f97\u5230\u8db3\u591f\u7684\u5173\u6ce8\u3002\u672c\u6587\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u540d\u4e3aPHYSICS\u7684\u6570\u636e\u96c6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4fc3\u8fdb\u6a21\u578b\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "\u6211\u4eec\u5c06\u6570\u636e\u96c6\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\uff0c\u5e76\u4e3a\u8bad\u7ec3\u6570\u636e\u63d0\u4f9b\u7531\u5f3a\u5927\u7684\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8def\u5f84\u4ee5\u652f\u6301\u6a21\u578b\u8bad\u7ec3\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u9488\u5bf9\u7269\u7406\u95ee\u9898\u7684Rule+Model\u8bc4\u4ef7\u6846\u67b6\uff0c\u4ee5\u5e73\u8861\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u8bc4\u4f30\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u548c\u4e13\u6709\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u7269\u7406\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002\u6240\u5f15\u5165\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u65b9\u6cd5\u5c55\u793a\u4e86\u5176\u5728\u7269\u7406\u9886\u57df\u63a8\u8fdbLLM\u53d1\u5c55\u7684\u6f5c\u529b\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u5904\u7406\u4e0e\u7269\u7406\u76f8\u5173\u7684\u4efb\u52a1\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e0c\u671b\u901a\u8fc7\u8fd9\u4e2a\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u65b9\u6cd5\u80fd\u63a8\u52a8LLM\u5728\u7269\u7406\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.00039", "pdf": "https://arxiv.org/pdf/2506.00039", "abs": "https://arxiv.org/abs/2506.00039", "authors": ["Behtom Adeli", "John Mclinden", "Pankaj Pandey", "Ming Shao", "Yalda Shahriari"], "title": "AbsoluteNet: A Deep Learning Neural Network to Classify Cerebral Hemodynamic Responses of Auditory Processing", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "In recent years, deep learning (DL) approaches have demonstrated promising\nresults in decoding hemodynamic responses captured by functional near-infrared\nspectroscopy (fNIRS), particularly in the context of brain-computer interface\n(BCI) applications. This work introduces AbsoluteNet, a novel deep learning\narchitecture designed to classify auditory event-related responses recorded\nusing fNIRS. The proposed network is built upon principles of spatio-temporal\nconvolution and customized activation functions. Our model was compared against\nseveral models, namely fNIRSNET, MDNN, DeepConvNet, and ShallowConvNet. The\nresults showed that AbsoluteNet outperforms existing models, reaching 87.0%\naccuracy, 84.8% sensitivity, and 89.2% specificity in binary classification,\nsurpassing fNIRSNET, the second-best model, by 3.8% in accuracy. These findings\nunderscore the effectiveness of our proposed deep learning model in decoding\nhemodynamic responses related to auditory processing and highlight the\nimportance of spatio-temporal feature aggregation and customized activation\nfunctions to better fit fNIRS dynamics.", "AI": {"tldr": "AbsoluteNet is a novel deep learning model that outperforms existing models in classifying auditory event-related responses in fNIRS data, showing improved accuracy and specificity.", "motivation": "To improve the classification accuracy of auditory event-related hemodynamic responses in brain-computer interface applications using fNIRS data.", "method": "The study introduces AbsoluteNet, which employs spatio-temporal convolution and customized activation functions for classifying auditory event-related responses recorded using fNIRS.", "result": "AbsoluteNet achieved 87.0% accuracy, 84.8% sensitivity, and 89.2% specificity in binary classification, outperforming the former leading model fNIRSNET by 3.8% in accuracy.", "conclusion": "AbsoluteNet, a novel deep learning architecture, significantly improves the classification of auditory event-related hemodynamic responses in fNIRS data, achieving higher performance than existing models."}}
{"id": "2506.00073", "pdf": "https://arxiv.org/pdf/2506.00073", "abs": "https://arxiv.org/abs/2506.00073", "authors": ["Shenzhe Zhu", "Jiao Sun", "Yi Nian", "Tobin South", "Alex Pentland", "Jiaxin Pei"], "title": "The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.MA"], "comment": null, "summary": "AI agents are increasingly used in consumer-facing applications to assist\nwith tasks such as product search, negotiation, and transaction execution. In\nthis paper, we explore a future scenario where both consumers and merchants\nauthorize AI agents to fully automate negotiations and transactions. We aim to\nanswer two key questions: (1) Do different LLM agents vary in their ability to\nsecure favorable deals for users? (2) What risks arise from fully automating\ndeal-making with AI agents in consumer markets? To address these questions, we\ndevelop an experimental framework that evaluates the performance of various LLM\nagents in real-world negotiation and transaction settings. Our findings reveal\nthat AI-mediated deal-making is an inherently imbalanced game -- different\nagents achieve significantly different outcomes for their users. Moreover,\nbehavioral anomalies in LLMs can result in financial losses for both consumers\nand merchants, such as overspending or accepting unreasonable deals. These\nresults underscore that while automation can improve efficiency, it also\nintroduces substantial risks. Users should exercise caution when delegating\nbusiness decisions to AI agents.", "AI": {"tldr": "AI\u4ee3\u7406\u5728\u6d88\u8d39\u5e02\u573a\u4e2d\u7684\u81ea\u52a8\u5316\u4ea4\u6613\u5b58\u5728\u98ce\u9669\u548c\u6548\u7387\u95ee\u9898\uff0c\u7528\u6237\u5e94\u8c28\u614e\u59d4\u6d3e\u51b3\u7b56\u3002", "motivation": "\u63a2\u8ba8\u672a\u6765\u60c5\u5883\u4e2d\u6d88\u8d39\u8005\u548c\u5546\u5bb6\u6388\u6743AI\u4ee3\u7406\u5b8c\u5168\u81ea\u52a8\u5316\u8c08\u5224\u548c\u4ea4\u6613\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u5b9e\u9a8c\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5404\u79cdLLM\u4ee3\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8c08\u5224\u548c\u4ea4\u6613\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "result": "AI\u4e2d\u4ecb\u7684\u4ea4\u6613\u5b58\u5728\u56fa\u6709\u7684\u4e0d\u5e73\u8861\uff0c\u4e0d\u540c\u4ee3\u7406\u4e3a\u7528\u6237\u5b9e\u73b0\u7684\u7ed3\u679c\u5dee\u5f02\u663e\u8457\u3002\u6b64\u5916\uff0cLLM\u4e2d\u7684\u884c\u4e3a\u5f02\u5e38\u53ef\u80fd\u5bfc\u81f4\u6d88\u8d39\u8005\u548c\u5546\u5bb6\u906d\u53d7\u8d22\u52a1\u635f\u5931\uff0c\u4f8b\u5982\u8fc7\u5ea6\u652f\u51fa\u6216\u63a5\u53d7\u4e0d\u5408\u7406\u7684\u4ea4\u6613\u3002", "conclusion": "\u867d\u7136\u81ea\u52a8\u5316\u53ef\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u663e\u8457\u98ce\u9669\uff0c\u7528\u6237\u5728\u5c06\u4e1a\u52a1\u51b3\u7b56\u59d4\u6d3e\u7ed9AI\u4ee3\u7406\u65f6\u5e94\u8c28\u614e\u3002"}}
{"id": "2506.00046", "pdf": "https://arxiv.org/pdf/2506.00046", "abs": "https://arxiv.org/abs/2506.00046", "authors": ["Yu Xia", "Alex McAvoy", "Qi Su"], "title": "Behavioral alignment in social networks", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "comment": null, "summary": "The orderly behaviors observed in large-scale groups, such as fish schooling\nand the organized movement of crowds, are both ubiquitous and essential for the\nsurvival and stability of these systems. Such complex collective behaviors\noften emerge from simple local interactions and strategy adjustments among\nindividuals. Understanding how these basic rules shape complex group dynamics\nhas long been a significant scientific challenge. Historically, research has\npredominantly focused on imitation and social learning, where individuals adopt\nthe strategies of more successful peers to refine their behavior. However, in\nrecent years, an alternative learning approach, self-exploration and\nintrospective learning, has garnered increasing attention. In this paradigm,\nindividuals assess their own circumstances and select strategies that best\nalign with their specific conditions. Two primary forms of this learning are\ncoordination and anti-coordination, where individuals align with and diverge\nfrom the local majority, respectively. In this study, we analyze networked\nsystems of coordinating and anti-coordinating individuals, exploring the\ncombined effects of system dynamics, network structure, and behavioral\npatterns. We address several practical questions, including the number of\nequilibria, their characteristics, the equilibrium time, and the resilience of\nsystems. We find that the number of equilibrium states can be extremely large,\neven increasing exponentially with minor alternations to the network structure.\nMoreover, the network structure has a significant impact on the average\nequilibrium time. Despite the complexity of these findings, variations can be\ncaptured by a single, simple network characteristic: the average path length.\nOur research offers valuable insights into how modifications to the interaction\nstructure can influence behavioral alignment in social networks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9c7c\u7fa4\u548c\u4eba\u7fa4\u7b49\u5927\u578b\u7fa4\u4f53\u7684\u6709\u5e8f\u884c\u4e3a\uff0c\u7814\u7a76\u4e86\u4e2a\u4f53\u7684\u81ea\u6211\u63a2\u7d22\u5b66\u4e60\u5bf9\u7fa4\u4f53\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7f51\u7edc\u7ed3\u6784\u5c24\u5176\u662f\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u5bf9\u7cfb\u7edf\u7684\u5747\u8861\u65f6\u95f4\u548c\u5747\u8861\u72b6\u6001\u6570\u91cf\u6709\u91cd\u5927\u5f71\u54cd\u3002", "motivation": "\u7406\u89e3\u7b80\u5355\u89c4\u5219\u5982\u4f55\u5851\u9020\u590d\u6742\u7fa4\u4f53\u52a8\u6001\u4e00\u76f4\u662f\u4e00\u4e2a\u91cd\u5927\u7684\u79d1\u5b66\u6311\u6218\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u81ea\u6211\u63a2\u7d22\u548c\u5185\u7701\u5b66\u4e60\u5728\u7fa4\u4f53\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u53ca\u7f51\u7edc\u7ed3\u6784\u5bf9\u884c\u4e3a\u6a21\u5f0f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7f51\u7edc\u5316\u7684\u7cfb\u7edf\uff0c\u7814\u7a76\u4e2a\u4f53\u7684\u534f\u8c03\u548c\u53cd\u534f\u8c03\u884c\u4e3a\u4e0e\u7f51\u7edc\u7ed3\u6784\u3001\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u884c\u4e3a\u6a21\u5f0f\u7684\u6574\u4f53\u6548\u5e94\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5747\u8861\u72b6\u6001\u7684\u6570\u91cf\u53ef\u80fd\u975e\u5e38\u5e9e\u5927\uff0c\u751a\u81f3\u968f\u7740\u7f51\u7edc\u7ed3\u6784\u7684\u5c0f\u53d8\u5316\u800c\u5448\u6307\u6570\u589e\u957f\u3002\u6b64\u5916\uff0c\u7f51\u7edc\u7ed3\u6784\u663e\u8457\u5f71\u54cd\u5e73\u5747\u5747\u8861\u65f6\u95f4\u3002\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u4e9b\u590d\u6742\u53d8\u5316\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u7f51\u7edc\u7279\u5f81\uff0c\u5373\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u6765\u6982\u62ec\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u7f51\u7edc\u7ed3\u6784\u5bf9\u4e2a\u4f53\u534f\u8c03\u548c\u53cd\u534f\u8c03\u884c\u4e3a\u5f71\u54cd\u7684\u91cd\u8981\u6027\uff0c\u5c24\u5176\u662f\u5e73\u5747\u8def\u5f84\u957f\u5ea6\u5bf9\u5747\u8861\u65f6\u95f4\u548c\u5747\u8861\u72b6\u6001\u6570\u91cf\u7684\u51b3\u5b9a\u6027\u4f5c\u7528\u3002"}}
{"id": "2506.00027", "pdf": "https://arxiv.org/pdf/2506.00027", "abs": "https://arxiv.org/abs/2506.00027", "authors": ["Zhengyu Chen", "Yudong Wang", "Teng Xiao", "Ruochen Zhou", "Xuesheng Yang", "Wei Wang", "Zhifang Sui", "Jingang Wang"], "title": "From Mathematical Reasoning to Code: Generalization of Process Reward Models in Test-Time Scaling", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in improving the reasoning capabilities of Large Language\nModels have underscored the efficacy of Process Reward Models (PRMs) in\naddressing intermediate errors through structured feedback mechanisms. This\nstudy analyzes PRMs from multiple perspectives, including training\nmethodologies, scalability, and generalization capabilities. We investigate the\ninterplay between pre-training and reward model training FLOPs to assess their\ninfluence on PRM efficiency and accuracy in complex reasoning tasks. Our\nanalysis reveals a pattern of diminishing returns in performance with\nincreasing PRM scale, highlighting the importance of balancing model size and\ncomputational cost. Furthermore, the diversity of training datasets\nsignificantly impacts PRM performance, emphasizing the importance of diverse\ndata to enhance both accuracy and efficiency. We further examine test-time\nscaling strategies, identifying Monte Carlo Tree Search as the most effective\nmethod when computational resources are abundant, while Best-of-N Sampling\nserves as a practical alternative under resource-limited conditions. Notably,\nour findings indicate that PRMs trained on mathematical datasets exhibit\nperformance comparable to those tailored for code generation, suggesting robust\ncross-domain generalization. Employing a gradient-based metric, we observe that\nPRMs exhibit a preference for selecting responses with similar underlying\npatterns, further informing their optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u7684\u8bad\u7ec3\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\uff0c\u53d1\u73b0\u968f\u7740\u89c4\u6a21\u589e\u5927\uff0c\u6027\u80fd\u589e\u76ca\u9012\u51cf\uff1b\u6570\u636e\u96c6\u591a\u6837\u6027\u63d0\u9ad8\u6548\u7387\uff1b\u6d4b\u8bd5\u4e2d\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6700\u6709\u6548\uff0cBest-of-N Sampling\u4e3a\u8d44\u6e90\u6709\u9650\u66ff\u4ee3\u65b9\u6848\u3002PRMs\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u663e\u793a\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u8fd1\u671f\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u8fdb\u5c55\u5f3a\u8c03\u4e86\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u673a\u5236\u6765\u89e3\u51b3\u4e2d\u95f4\u9519\u8bef\u3002", "method": "\u5206\u6790\u4e86PRMs\u7684\u8bad\u7ec3\u65b9\u6cd5\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u8c03\u67e5\u4e86\u9884\u8bad\u7ec3\u4e0e\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u7684FLOPs\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u53ca\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "result": "\u5373\u4f7fPRM\u89c4\u6a21\u589e\u52a0\uff0c\u6027\u80fd\u589e\u76ca\u4e5f\u4f1a\u5448\u73b0\u9012\u51cf\u6a21\u5f0f\uff0c\u5f3a\u8c03\u4e86\u5e73\u8861\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u6210\u672c\u7684\u91cd\u8981\u6027\u3002\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u591a\u6837\u6027\u663e\u8457\u5f71\u54cdPRM\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u591a\u6837\u5316\u6570\u636e\u5bf9\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u91cd\u8981\u6027\u3002\u6d4b\u8bd5\u65f6\u7684\u6269\u5c55\u7b56\u7565\u4e2d\uff0c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5728\u8ba1\u7b97\u8d44\u6e90\u5145\u88d5\u65f6\u6700\u6709\u6548\uff0c\u800cBest-of-N Sampling\u5728\u8d44\u6e90\u6709\u9650\u65f6\u63d0\u4f9b\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "PRMs\u5728\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4e0e\u4e3a\u4ee3\u7801\u751f\u6210\u91cf\u8eab\u5b9a\u5236\u7684\u6a21\u578b\u76f8\u5f53\uff0c\u5c55\u793a\u4e86\u8de8\u9886\u57df\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\uff0cPRMs\u503e\u5411\u4e8e\u9009\u62e9\u5177\u6709\u76f8\u4f3c\u57fa\u7840\u6a21\u5f0f\u7684\u54cd\u5e94\uff0c\u8fdb\u4e00\u6b65\u63a8\u52a8\u5176\u4f18\u5316\u3002"}}
{"id": "2506.00131", "pdf": "https://arxiv.org/pdf/2506.00131", "abs": "https://arxiv.org/abs/2506.00131", "authors": ["Simon Sinong Zhan", "Qingyuan Wu", "Frank Yang", "Xiangyu Shi", "Chao Huang", "Qi Zhu"], "title": "Adapting Offline Reinforcement Learning with Online Delays", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Offline-to-online deployment of reinforcement-learning (RL) agents must\nbridge two gaps: (1) the sim-to-real gap, where real systems add latency and\nother imperfections not present in simulation, and (2) the interaction gap,\nwhere policies trained purely offline face out-of-distribution states during\nonline execution because gathering new interaction data is costly or risky.\nAgents therefore have to generalize from static, delay-free datasets to\ndynamic, delay-prone environments. Standard offline RL learns from delay-free\nlogs yet must act under delays that break the Markov assumption and hurt\nperformance. We introduce DT-CORL (Delay-Transformer belief policy Constrained\nOffline RL), an offline-RL framework built to cope with delayed dynamics at\ndeployment. DT-CORL (i) produces delay-robust actions with a transformer-based\nbelief predictor even though it never sees delayed observations during\ntraining, and (ii) is markedly more sample-efficient than na\\\"ive\nhistory-augmentation baselines. Experiments on D4RL benchmarks with several\ndelay settings show that DT-CORL consistently outperforms both\nhistory-augmentation and vanilla belief-based methods, narrowing the\nsim-to-real latency gap while preserving data efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86DT-CORL\uff0c\u4f7f\u7528transformer\u751f\u6210\u7a33\u5065\u7684\u5ef6\u8fdf\u52a8\u4f5c\uff0c\u9ad8\u6548\u7f29\u5c0fsim-to-real\u5ef6\u8fdf\u5dee\u8ddd\u3002", "motivation": "\u89e3\u51b3\u79bb\u7ebfRL\u4ee3\u7406\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u9762\u4e34\u7684sim-to-real\u548c\u4ea4\u4e92\u5dee\u8ddd\u3002", "method": "DT-CORL\u6846\u67b6\u4f7f\u7528transformer-based\u4fe1\u4efb\u9884\u6d4b\u5668\u751f\u6210\u7a33\u5065\u7684\u5ef6\u8fdf\u52a8\u4f5c\uff0c\u65e0\u9700\u5728\u8bad\u7ec3\u671f\u95f4\u770b\u5230\u5ef6\u8fdf\u89c2\u6d4b\u3002", "result": "DT-CORL\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u7684\u591a\u79cd\u5ef6\u8fdf\u8bbe\u7f6e\u4e2d\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5386\u53f2\u589e\u5f3a\u548c\u666e\u901a\u4fe1\u4efb\u65b9\u6cd5\u3002", "conclusion": "DT-CORL\u7f29\u5c0f\u4e86sim-to-real\u5ef6\u8fdf\u5dee\u8ddd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6570\u636e\u6548\u7387\u3002"}}
{"id": "2506.00140", "pdf": "https://arxiv.org/pdf/2506.00140", "abs": "https://arxiv.org/abs/2506.00140", "authors": ["Jesse Thibodeau", "Hadi Nekoei", "Afaf Ta\u00efk", "Janarthanan Rajendran", "Golnoosh Farnadi"], "title": "Balancing Profit and Fairness in Risk-Based Pricing Markets", "categories": ["cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "comment": null, "summary": "Dynamic, risk-based pricing can systematically exclude vulnerable consumer\ngroups from essential resources such as health insurance and consumer credit.\nWe show that a regulator can realign private incentives with social objectives\nthrough a learned, interpretable tax schedule. First, we provide a formal\nproposition that bounding each firm's \\emph{local} demographic gap implicitly\nbounds the \\emph{global} opt-out disparity, motivating firm-level penalties.\nBuilding on this insight we introduce \\texttt{MarketSim} -- an open-source,\nscalable simulator of heterogeneous consumers and profit-maximizing firms --\nand train a reinforcement learning (RL) social planner (SP) that selects a\nbracketed fairness-tax while remaining close to a simple linear prior via an\n$\\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and\neasily interpretable. In two empirically calibrated markets, i.e., U.S.\nhealth-insurance and consumer-credit, our planner simultaneously raises\ndemand-fairness by up to $16\\%$ relative to unregulated Free Market while\noutperforming a fixed linear schedule in terms of social welfare without\nexplicit coordination. These results illustrate how AI-assisted regulation can\nconvert a competitive social dilemma into a win-win equilibrium, providing a\nprincipled and practical framework for fairness-aware market oversight.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u5b66\u4e60\u7684\u7a0e\u6536\u8ba1\u5212\u6765\u89e3\u51b3\u52a8\u6001\u5b9a\u4ef7\u5e26\u6765\u7684\u793e\u4f1a\u95ee\u9898\uff0c\u5c55\u793a\u4e86AI\u76d1\u7ba1\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u52a8\u6001\u548c\u98ce\u9669\u4e3a\u57fa\u7840\u7684\u5b9a\u4ef7\u53ef\u80fd\u5bfc\u81f4\u5f31\u52bf\u6d88\u8d39\u7fa4\u4f53\u88ab\u7cfb\u7edf\u6027\u5730\u6392\u9664\u5728\u57fa\u672c\u8d44\u6e90\u4e4b\u5916\uff0c\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u5b66\u4e60\u7684\u3001\u53ef\u89e3\u91ca\u7684\u7a0e\u6536\u8ba1\u5212\u5c06\u79c1\u4eba\u7684\u6fc0\u52b1\u4e0e\u793e\u4f1a\u76ee\u6807\u91cd\u65b0\u5bf9\u9f50\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u793e\u4f1a\u8ba1\u5212\u8005\u6765\u9009\u62e9\u5206\u7ea7\u7684\u516c\u5e73\u7a0e\uff0c\u5e76\u901a\u8fc7\\(\\mathcal{L}_1\\)\u6b63\u5219\u5316\u4fdd\u6301\u63a5\u8fd1\u7b80\u5355\u7ebf\u6027\u5148\u9a8c\u3002", "result": "\u5728\u4e24\u4e2a\u7ecf\u8fc7\u5b9e\u8bc1\u6821\u51c6\u7684\u5e02\u573a\u4e2d\uff08\u5373\u7f8e\u56fd\u5065\u5eb7\u4fdd\u9669\u548c\u6d88\u8d39\u8005\u4fe1\u8d37\uff09\uff0c\u8ba1\u5212\u8005\u5728\u4e0d\u660e\u786e\u534f\u8c03\u7684\u60c5\u51b5\u4e0b\u540c\u65f6\u63d0\u9ad8\u9700\u6c42\u516c\u5e73\u6027\u6700\u591a\u8fbe16%\uff0c\u793e\u4f1a\u798f\u5229\u8868\u73b0\u4f18\u4e8e\u56fa\u5b9a\u7ebf\u6027\u8ba1\u5212\u3002", "conclusion": "AI\u8f85\u52a9\u76d1\u7ba1\u53ef\u4ee5\u5728\u4e0d\u660e\u786e\u5408\u4f5c\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u793e\u4f1a\u798f\u5229\u548c\u9700\u6c42\u516c\u5e73\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u516c\u5e73\u5e02\u573a\u76d1\u7ba1\u7684\u539f\u5219\u6027\u548c\u5b9e\u7528\u6027\u6846\u67b6\u3002"}}
{"id": "2506.00052", "pdf": "https://arxiv.org/pdf/2506.00052", "abs": "https://arxiv.org/abs/2506.00052", "authors": ["Ilia Sucholutsky", "Katherine M. Collins", "Nori Jacoby", "Bill D. Thompson", "Robert D. Hawkins"], "title": "Using LLMs to Advance the Cognitive Science of Collectives", "categories": ["q-bio.NC", "cs.AI", "cs.HC", "cs.MA", "cs.SI"], "comment": null, "summary": "LLMs are already transforming the study of individual cognition, but their\napplication to studying collective cognition has been underexplored. We lay out\nhow LLMs may be able to address the complexity that has hindered the study of\ncollectives and raise possible risks that warrant new methods.", "AI": {"tldr": "LLMs\u5728\u96c6\u4f53\u8ba4\u77e5\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u4ee5\u53ca\u76f8\u5e94\u98ce\u9669\u3002", "motivation": "LLMs\u5728\u7814\u7a76\u4e2a\u4eba\u8ba4\u77e5\u65b9\u9762\u5df2\u7ecf\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4f46\u5728\u96c6\u4f53\u8ba4\u77e5\u9886\u57df\u7684\u5e94\u7528\u4ecd\u5f85\u5f00\u53d1\u3002", "method": "\u6587\u7ae0\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528LLMs\u6765\u7814\u7a76\u96c6\u4f53\u8ba4\u77e5\u7684\u590d\u6742\u6027\u3002", "result": "\u901a\u8fc7\u4ecb\u7ecdLLMs\u53ef\u80fd\u89e3\u51b3\u96c6\u4f53\u7814\u7a76\u4e2d\u7684\u590d\u6742\u6027\uff0c\u6587\u7ae0\u6307\u51fa\u5176\u5e94\u7528\u7684\u6f5c\u5728\u98ce\u9669\u3002", "conclusion": "\u8bba\u6587\u603b\u7ed3\u4e86LLMs\u5bf9\u96c6\u4f53\u8ba4\u77e5\u7684\u6f5c\u5728\u5f71\u54cd\u4ee5\u53ca\u4e9f\u9700\u53d1\u5c55\u65b0\u7684\u7814\u7a76\u65b9\u6cd5\u6765\u5e94\u5bf9\u76f8\u5173\u98ce\u9669\u3002"}}
{"id": "2506.00042", "pdf": "https://arxiv.org/pdf/2506.00042", "abs": "https://arxiv.org/abs/2506.00042", "authors": ["Yue Cui", "Liuyi Yao", "Shuchang Tao", "Weijie Shi", "Yaliang Li", "Bolin Ding", "Xiaofang Zhou"], "title": "Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have significantly advanced natural language\nprocessing, particularly through the integration of external tools and APIs.\nHowever, their effectiveness is frequently hampered by parameter mis-filling\nduring tool calling. In this paper, we propose the Hierarchical Tool Error\nChecklist (HiTEC) framework to systematically diagnose and mitigate\ntool-calling errors without relying on extensive real-world interactions. HiTEC\nintroduces a two-tiered approach: a global error checklist that identifies\ncommon, cross-tool issues, and a local error checklist that targets\ntool-specific and contextual failures. Building on this structure, we propose\ntwo deployments: HiTEC-In Context Learning (HiTEC-ICL) and\nHiTEC-Kahneman-Tversky Optimization (HiTEC-KTO). HiTEC-ICL embeds the global\nchecklist in the initial prompts and leverages a two-round conversational\ninteraction to dynamically refine parameter handling, while HiTEC-KTO generates\nhigh-quality negative examples to drive fine-tuning via preference-based\noptimization. Extensive experiments across five public datasets demonstrate\nthat our framework significantly improves parameter-filling accuracy and\ntool-calling success rates compared to baseline methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86HiTEC\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u7ea7\u9519\u8bef\u68c0\u67e5\u6e05\u5355\u63d0\u9ad8\u53c2\u6570\u586b\u5199\u51c6\u786e\u6027\uff0c\u663e\u8457\u6539\u5584\u5de5\u5177\u8c03\u7528\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c03\u7528\u5916\u90e8\u5de5\u5177\u548cAPI\u65f6\uff0c\u7531\u4e8e\u53c2\u6570\u586b\u5199\u9519\u8bef\u800c\u5f71\u54cd\u6548\u7387\u7684\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86HiTEC\u6846\u67b6\uff0c\u5305\u62ecHiTEC-In Context Learning\u548cHiTEC-Kahneman-Tversky Optimization\u4e24\u79cd\u90e8\u7f72\u65b9\u6cd5\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHiTEC\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u53c2\u6570\u586b\u5199\u51c6\u786e\u6027\u548c\u5de5\u5177\u8c03\u7528\u6210\u529f\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684HiTEC\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u53c2\u6570\u586b\u5199\u7684\u51c6\u786e\u6027\u548c\u5de5\u5177\u8c03\u7528\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2506.00135", "pdf": "https://arxiv.org/pdf/2506.00135", "abs": "https://arxiv.org/abs/2506.00135", "authors": ["Idan Attias", "Steve Hanneke", "Arvind Ramaswami"], "title": "Tradeoffs between Mistakes and ERM Oracle Calls in Online and Transductive Online Learning", "categories": ["cs.LG", "cs.DS", "stat.ML"], "comment": null, "summary": "We study online and transductive online learning when the learner interacts\nwith the concept class only via Empirical Risk Minimization (ERM) or weak\nconsistency oracles on arbitrary instance subsets. This contrasts with standard\nonline models, where the learner knows the entire class. The ERM oracle returns\na hypothesis minimizing loss on a given subset, while the weak consistency\noracle returns a binary signal indicating whether the subset is realizable by\nsome concept. The learner is evaluated by the number of mistakes and oracle\ncalls. In the standard online setting with ERM access, we prove tight lower\nbounds in both realizable and agnostic cases: $\\Omega(2^{d_{VC}})$ mistakes and\n$\\Omega(\\sqrt{T 2^{d_{LD}}})$ regret, where $T$ is the number of timesteps and\n$d_{LD}$ is the Littlestone dimension. We further show that existing online\nlearning results with ERM access carry over to the weak consistency setting,\nincurring an additional $O(T)$ in oracle calls. We then consider the\ntransductive online model, where the instance sequence is known but labels are\nrevealed sequentially. For general Littlestone classes, we show that optimal\nrealizable and agnostic mistake bounds can be achieved using $O(T^{d_{VC}+1})$\nweak consistency oracle calls. On the negative side, we show that limiting the\nlearner to $\\Omega(T)$ weak consistency queries is necessary for transductive\nonline learnability, and that restricting the learner to $\\Omega(T)$ ERM\nqueries is necessary to avoid exponential dependence on the Littlestone\ndimension. Finally, for certain concept classes, we reduce oracle calls via\nrandomized algorithms while maintaining similar mistake bounds. In particular,\nfor Thresholds on an unknown ordering, $O(\\log T)$ ERM queries suffice; for\n$k$-Intervals, $O(T^3 2^{2k})$ weak consistency queries suffice.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u7ebf\u5b66\u4e60\u4e2d\u901a\u8fc7ERM\u548c\u5f31\u4e00\u81f4\u6027\u9884\u8a00\u673a\u4e0e\u6982\u5ff5\u7c7b\u4ea4\u4e92\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u60c5\u51b5\u4e0b\u7684\u9519\u8bef\u4e0b\u754c\u53ca\u76f8\u5e94\u7684\u5b66\u4e60\u7ed3\u679c\u3002", "motivation": "\u63a2\u8ba8\u5728\u7ebf\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u5b66\u4e60\u8005\u5728\u4ec5\u901a\u8fc7\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u6216\u5f31\u4e00\u81f4\u6027\u9884\u8a00\u673a\u4e0e\u6982\u5ff5\u7c7b\u4ea4\u4e92\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u6709\u6548\u8fdb\u884c\u5b66\u4e60\u8bbe\u7f6e\u3002", "method": "\u4f7f\u7528ERM\u9884\u8a00\u673a\u83b7\u53d6\u5728\u7ed9\u5b9a\u96c6\u5408\u4e0a\u7684\u635f\u5931\u6700\u5c0f\u5316\u5047\u8bbe\uff0c\u4ee5\u53ca\u5f31\u4e00\u81f4\u6027\u9884\u8a00\u673a\u5224\u65ad\u96c6\u5408\u662f\u5426\u53ef\u5b9e\u73b0\u3002\u5206\u6790\u4e86\u5728\u8fd9\u4e9b\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u7684\u9519\u8bef\u6570\u548c\u9884\u8a00\u673a\u8c03\u7528\u6b21\u6570\u3002", "result": "\u5f97\u51fa\u4e86\u5728\u6807\u51c6\u5728\u7ebf\u6d4b\u4e0eERM\u8bbf\u95ee\u60c5\u51b5\u4e0b\u7684\u4e25\u683c\u4e0b\u754c\uff1b\u5728\u4f20\u9012\u5728\u7ebf\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u589e\u52a0\u5f31\u4e00\u81f4\u6027\u9884\u8a00\u673a\u8c03\u7528\uff0c\u53ef\u5b9e\u73b0\u6700\u4f73\u53ef\u5b9e\u73b0\u548c\u9c81\u68d2\u9519\u8bef\u754c\u3002\u9650\u5236\u67e5\u8be2\u53ef\u6839\u636e\u5177\u4f53\u6982\u5ff5\u7c7b\u4f7f\u7528\u968f\u673a\u7b97\u6cd5\u51cf\u5c11\u9884\u8a00\u673a\u8c03\u7528\u3002", "conclusion": "\u63d0\u51fa\u5728\u7ebf\u5b66\u4e60\u548c\u4f20\u9012\u5728\u7ebf\u5b66\u4e60\u4e2d\u4f7f\u7528ERM\u548c\u5f31\u4e00\u81f4\u6027\u9884\u8a00\u673a\u4e0e\u6982\u5ff5\u7c7b\u4ea4\u4e92\u7684\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\u7684\u9519\u8bef\u4e0b\u754c\uff0c\u5e76\u5c55\u793a\u4e86\u73b0\u6709\u5728\u7ebf\u5b66\u4e60\u7ed3\u679c\u5728\u5f31\u4e00\u81f4\u6027\u8bbe\u7f6e\u4e0b\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.00169", "pdf": "https://arxiv.org/pdf/2506.00169", "abs": "https://arxiv.org/abs/2506.00169", "authors": ["Aziida Nanyonga", "Graham Wild"], "title": "Utilizing AI for Aviation Post-Accident Analysis Classification", "categories": ["cs.AI"], "comment": null, "summary": "The volume of textual data available in aviation safety reports presents a\nchallenge for timely and accurate analysis. This paper examines how Artificial\nIntelligence (AI) and, specifically, Natural Language Processing (NLP) can\nautomate the process of extracting valuable insights from this data, ultimately\nenhancing aviation safety. The paper reviews ongoing efforts focused on the\napplication of NLP and deep learning to aviation safety reports, with the goal\nof classifying the level of damage to an aircraft and identifying the phase of\nflight during which safety occurrences happen. Additionally, the paper explores\nthe use of Topic Modeling (TM) to uncover latent thematic structures within\naviation incident reports, aiming to identify recurring patterns and potential\nareas for safety improvement. The paper compares and contrasts the performance\nof various deep learning models and TM techniques applied to datasets from the\nNational Transportation Safety Board (NTSB) and the Australian Transport Safety\nBureau (ATSB), as well as the Aviation Safety Network (ASN), discussing the\nimpact of dataset size and source on the accuracy of the analysis. The findings\ndemonstrate that both NLP and deep learning, as well as TM, can significantly\nimprove the efficiency and accuracy of aviation safety analysis, paving the way\nfor more proactive safety management and risk mitigation strategies.", "AI": {"tldr": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7NLP\u548c\u6df1\u5ea6\u5b66\u4e60\u63d0\u5347\u822a\u7a7a\u5b89\u5168\u62a5\u544a\u5206\u6790\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u6587\u672c\u6570\u636e\u91cf\u5e9e\u5927\u7684\u822a\u7a7a\u5b89\u5168\u62a5\u544a\u5728\u53ca\u65f6\u51c6\u786e\u5206\u6790\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u81ea\u52a8\u5316\u6570\u636e\u6d1e\u5bdf\u63d0\u53d6\uff0c\u4ee5\u589e\u8fdb\u822a\u7a7a\u5b89\u5168\u3002", "method": "\u5e94\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u3001\u6df1\u5ea6\u5b66\u4e60\u4ee5\u53ca\u4e3b\u9898\u5efa\u6a21\uff08TM\uff09\u6280\u672f\uff0c\u5bf9\u6765\u81ea\u4e0d\u540c\u5b89\u5168\u673a\u6784\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5206\u6790\u548c\u6bd4\u8f83\u3002", "result": "\u5e94\u7528NLP\u3001\u6df1\u5ea6\u5b66\u4e60\u548c\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u822a\u7a7a\u5b89\u5168\u5206\u6790\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u5728\u822a\u7a7a\u5b89\u5168\u5206\u6790\u4e2d\u5177\u6709\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u66f4\u4e3b\u52a8\u7684\u5b89\u5168\u7ba1\u7406\u548c\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2506.00061", "pdf": "https://arxiv.org/pdf/2506.00061", "abs": "https://arxiv.org/abs/2506.00061", "authors": ["Wiktoria Mieleszczenko-Kowszewicz", "Beata Bajcar", "Aleksander Szcz\u0119sny", "Maciej Markiewicz", "Jolanta Babiak", "Berenika Dyczek", "Przemys\u0142aw Kazienko"], "title": "Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In this work we present the Social Influence Technique Taxonomy (SITT), a\ncomprehensive framework of 58 empirically grounded techniques organized into\nnine categories, designed to detect subtle forms of social influence in textual\ncontent. We also investigate the LLMs ability to identify various forms of\nsocial influence. Building on interdisciplinary foundations, we construct the\nSITT dataset -- a 746-dialogue corpus annotated by 11 experts in Polish and\ntranslated into English -- to evaluate the ability of LLMs to identify these\ntechniques. Using a hierarchical multi-label classification setup, we benchmark\nfive LLMs, including GPT-4o, Claude 3.5, Llama-3.1, Mixtral, and PLLuM. Our\nresults show that while some models, notably Claude 3.5, achieved moderate\nsuccess (F1 score = 0.45 for categories), overall performance of models remains\nlimited, particularly for context-sensitive techniques. The findings\ndemonstrate key limitations in current LLMs' sensitivity to nuanced linguistic\ncues and underscore the importance of domain-specific fine-tuning. This work\ncontributes a novel resource and evaluation example for understanding how LLMs\ndetect, classify, and potentially replicate strategies of social influence in\nnatural dialogues.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u793e\u4f1a\u5f71\u54cd\u6280\u672f\u5206\u7c7b\u6cd5\uff08SITT\uff09\uff0c\u8bc4\u4f30\u4e86LLMs\u5728\u68c0\u6d4b\u548c\u5206\u7c7b\u81ea\u7136\u5bf9\u8bdd\u4e2d\u7684\u793e\u4f1a\u5f71\u54cd\u7b56\u7565\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u5904\u7406\u7ec6\u5fae\u8bed\u8a00\u7ebf\u7d22\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u6784\u5efa\u548c\u8bc4\u4f30LLMs\u68c0\u6d4b\u6587\u672c\u4e2d\u7ec6\u5fae\u793e\u4f1a\u5f71\u54cd\u80fd\u529b\uff0c\u4ee5\u8bc6\u522b\u5f53\u524d\u6a21\u578b\u7684\u5c40\u9650\u6027\u5e76\u5f15\u53d1\u5bf9\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u7684\u91cd\u89c6\u3002", "method": "\u4f7f\u7528\u5c42\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\u8bbe\u7f6e\uff0c\u57fa\u51c6\u6d4b\u8bd5\u4e94\u79cdLLM\uff0c\u5305\u62ecGPT-4o\u3001Claude 3.5\u3001Llama-3.1\u3001Mixtral\u548cPLLuM\uff0c\u901a\u8fc7SITT\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "Claude 3.5\u5728\u7c7b\u522b\u68c0\u6d4b\u4e0a\u53d6\u5f97\u4e00\u5b9a\u6210\u529f\uff0cF1\u5206\u6570\u4e3a0.45\uff0c\u7136\u800c\u603b\u4f53\u6027\u80fd\u6709\u9650\uff0c\u5c24\u5176\u662f\u5728\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u6280\u672f\u9886\u57df\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5f53\u524d\u7684LLMs\u5728\u68c0\u6d4b\u590d\u6742\u7684\u793e\u4f1a\u5f71\u54cd\u6280\u672f\u65f6\u5b58\u5728\u663e\u8457\u9650\u5236\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u654f\u611f\u4e0a\u4e0b\u6587\u6280\u672f\u4e0d\u591f\u654f\u611f\uff0c\u5f3a\u8c03\u4e86\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.00136", "pdf": "https://arxiv.org/pdf/2506.00136", "abs": "https://arxiv.org/abs/2506.00136", "authors": ["Magdalena Proszewska", "Nikolay Malkin", "N. Siddharth"], "title": "On Designing Diffusion Autoencoders for Efficient Generation and Representation Learning", "categories": ["cs.LG"], "comment": "21 pages, 10 tables, 15 figures", "summary": "Diffusion autoencoders (DAs) are variants of diffusion generative models that\nuse an input-dependent latent variable to capture representations alongside the\ndiffusion process. These representations, to varying extents, can be used for\ntasks such as downstream classification, controllable generation, and\ninterpolation. However, the generative performance of DAs relies heavily on how\nwell the latent variables can be modelled and subsequently sampled from. Better\ngenerative modelling is also the primary goal of another class of diffusion\nmodels -- those that learn their forward (noising) process. While effective at\nadjusting the noise process in an input-dependent manner, they must satisfy\nadditional constraints derived from the terminal conditions of the diffusion\nprocess. Here, we draw a connection between these two classes of models and\nshow that certain design decisions (latent variable choice, conditioning\nmethod, etc.) in the DA framework -- leading to a model we term DMZ -- allow us\nto obtain the best of both worlds: effective representations as evaluated on\ndownstream tasks, including domain transfer, as well as more efficient\nmodelling and generation with fewer denoising steps compared to standard DMs.", "AI": {"tldr": "\u901a\u8fc7\u8bbe\u8ba1DMZ\u6a21\u578b\uff0c\u5c06\u4e0d\u540c\u6269\u6563\u6a21\u578b\u7684\u4f18\u70b9\u7ed3\u5408\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u751f\u6210\u548c\u6709\u6548\u7684\u8868\u793a\u3002", "motivation": "\u6269\u6563\u81ea\u52a8\u7f16\u7801\u5668\u4f9d\u8d56\u4e8e\u80fd\u591f\u826f\u597d\u5efa\u6a21\u548c\u91c7\u6837\u7684\u6f5c\u53d8\u91cf\uff0c\u800c\u6539\u8fdb\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u662f\u53e6\u4e00\u7c7b\u5b66\u4e60\u5176\u524d\u5411\u8fc7\u7a0b\u7684\u6269\u6563\u6a21\u578b\u7684\u4e3b\u8981\u76ee\u6807\u3002\u672c\u6587\u65e8\u5728\u7ed3\u5408\u8fd9\u4e24\u7c7b\u6a21\u578b\u7684\u4f18\u70b9\u3002", "method": "\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u6f5c\u53d8\u91cf\u548c\u6761\u4ef6\u65b9\u6cd5\uff0c\u5c06\u4e24\u7c7b\u6a21\u578b\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u751f\u6210\u5efa\u6a21\u4ee5\u53ca\u66f4\u6709\u6548\u7684\u8868\u793a\u3002", "result": "\u8bbe\u8ba1\u4e00\u79cd\u79f0\u4e3aDMZ\u7684\u6a21\u578b\uff0c\u5b83\u53ef\u4ee5\u5728\u8f83\u5c11\u7684\u53bb\u566a\u6b65\u9aa4\u4e2d\u5b9e\u73b0\u6709\u6548\u8868\u793a\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8bc4\u4f30\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684DMZ\u6a21\u578b\u53ef\u4ee5\u540c\u65f6\u83b7\u5f97\u6709\u6548\u7684\u8868\u793a\u548c\u9ad8\u6548\u7684\u751f\u6210\u80fd\u529b\uff0c\u5c24\u5176\u5728\u57df\u8f6c\u79fb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u540c\u65f6\u76f8\u6bd4\u6807\u51c6\u7684\u6269\u6563\u6a21\u578b\uff0c\u51cf\u5c11\u4e86\u53bb\u566a\u6b65\u9aa4\u3002"}}
{"id": "2506.00178", "pdf": "https://arxiv.org/pdf/2506.00178", "abs": "https://arxiv.org/abs/2506.00178", "authors": ["Anirudh Nair", "Adi Banerjee", "Laurent Mombaerts", "Matthew Hagen", "Tarik Borogovac"], "title": "Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Prompt engineering represents a critical bottleneck to harness the full\npotential of Large Language Models (LLMs) for solving complex tasks, as it\nrequires specialized expertise, significant trial-and-error, and manual\nintervention. This challenge is particularly pronounced for tasks involving\nsubjective quality assessment, where defining explicit optimization objectives\nbecomes fundamentally problematic. Existing automated prompt optimization\nmethods falter in these scenarios, as they typically require well-defined\ntask-specific numerical fitness functions or rely on generic templates that\ncannot capture the nuanced requirements of complex use cases. We introduce\nDEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that\nguides prompt evolution through a debate-driven evaluation with an Elo-based\nselection. Contrary to prior work, DEEVOs approach enables exploration of the\ndiscrete prompt space while preserving semantic coherence through intelligent\ncrossover and strategic mutation operations that incorporate debate-based\nfeedback, combining elements from both successful and unsuccessful prompts\nbased on identified strengths rather than arbitrary splicing. Using Elo ratings\nas a fitness proxy, DEEVO simultaneously drives improvement and preserves\nvaluable diversity in the prompt population. Experimental results demonstrate\nthat DEEVO significantly outperforms both manual prompt engineering and\nalternative state-of-the-art optimization approaches on open-ended tasks and\nclose-ended tasks despite using no ground truth feedback. By connecting LLMs\nreasoning capabilities with adaptive optimization, DEEVO represents a\nsignificant advancement in prompt optimization research by eliminating the need\nof predetermined metrics to continuously improve AI systems.", "AI": {"tldr": "DEEVO\u662f\u4e00\u79cd\u65b0\u7684\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8fa9\u8bba\u9a71\u52a8\u7684\u8bc4\u4f30\u548c\u57fa\u4e8eElo\u9009\u62e9\u6765\u4f18\u5316\u63d0\u793a\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u7684\u63d0\u793a\u5de5\u7a0b\u56f0\u96be\uff0c\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u3001\u5927\u91cf\u7684\u8bd5\u9519\u548c\u4eba\u5de5\u5e72\u9884\uff0c\u7279\u522b\u662f\u5bf9\u4e3b\u89c2\u8d28\u91cf\u8bc4\u4f30\u4efb\u52a1\u800c\u8a00\u3002", "method": "\u5f15\u5165DEEVO\u6846\u67b6\uff0c\u901a\u8fc7\u8fa9\u8bba\u9a71\u52a8\u7684\u8bc4\u4f30\u548c\u57fa\u4e8eElo\u9009\u62e9\u6765\u6307\u5bfc\u63d0\u793a\u6f14\u5316\uff0c\u5e76\u901a\u8fc7\u667a\u80fd\u4ea4\u53c9\u548c\u6218\u7565\u7a81\u53d8\u64cd\u4f5c\u6765\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDEEVO\u5728\u5f00\u653e\u5f0f\u548c\u95ed\u5408\u5f0f\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4eba\u5de5\u63d0\u793a\u5de5\u7a0b\u548c\u66ff\u4ee3\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "conclusion": "DEEVO\u663e\u8457\u4f18\u4e8e\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u548c\u66ff\u4ee3\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u65e0\u9700\u771f\u5b9e\u53cd\u9988\u5373\u53ef\u5728\u5f00\u653e\u5f0f\u548c\u95ed\u5408\u5f0f\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.00458", "pdf": "https://arxiv.org/pdf/2506.00458", "abs": "https://arxiv.org/abs/2506.00458", "authors": ["Nina Cohen", "Kordel K. France"], "title": "Reinforcement Learning for Hanabi", "categories": ["cs.LG", "cs.AI", "cs.GT", "cs.MA"], "comment": null, "summary": "Hanabi has become a popular game for research when it comes to reinforcement\nlearning (RL) as it is one of the few cooperative card games where you have\nincomplete knowledge of the entire environment, thus presenting a challenge for\na RL agent. We explored different tabular and deep reinforcement learning\nalgorithms to see which had the best performance both against an agent of the\nsame type and also against other types of agents. We establish that certain\nagents played their highest scoring games against specific agents while others\nexhibited higher scores on average by adapting to the opposing agent's\nbehavior. We attempted to quantify the conditions under which each algorithm\nprovides the best advantage and identified the most interesting interactions\nbetween agents of different types. In the end, we found that temporal\ndifference (TD) algorithms had better overall performance and balancing of play\ntypes compared to tabular agents. Specifically, tabular Expected SARSA and deep\nQ-Learning agents showed the best performance.", "AI": {"tldr": "TD\u7b97\u6cd5\u5728Hanabi\u4e2d\u6574\u4f53\u8868\u73b0\u66f4\u4f73\uff0c\u7279\u522b\u662f\u8868\u683c\u5f0f\u9884\u671fSARSA\u548c\u6df1\u5ea6Q\u5b66\u4e60\u3002", "motivation": "Hanabi\u662f\u4e00\u79cd\u5177\u6709\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5408\u4f5c\u5361\u724c\u6e38\u620f\uff0c\u7ed9\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5e26\u6765\u4e86\u6311\u6218\uff0c\u56e0\u6b64\u7814\u7a76\u5176\u5728\u52a0\u56fa\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u8868\u683c\u5f0f\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728Hanabi\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u4e86\u540c\u7c7b\u548c\u4e0d\u540c\u7c7b\u4ee3\u7406\u5bf9\u51b3\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6700\u7ec8\u53d1\u73b0\uff0c\u65f6\u95f4\u5dee\u5206\uff08TD\uff09\u7b97\u6cd5\u5728\u6574\u4f53\u6027\u80fd\u548c\u6e38\u620f\u7c7b\u578b\u7684\u5e73\u8861\u4e0a\u4f18\u4e8e\u8868\u683c\u5f0f\u4ee3\u7406\uff0c\u5176\u4e2d\u8868\u683c\u5316\u7684\u9884\u671fSARSA\u548c\u6df1\u5ea6Q\u5b66\u4e60\u4ee3\u7406\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5728Hanabi\u8fd9\u4e2a\u5177\u6709\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5408\u4f5c\u5361\u724c\u6e38\u620f\u4e2d\uff0c\u6df1\u5ea6Q\u5b66\u4e60\u7b97\u6cd5\u548c\u8868\u683c\u5f0f\u9884\u671fSARSA\u7b97\u6cd5\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u5bf9\u624b\u9762\u524d\u8868\u73b0\u51fa\u4e86\u6700\u4f73\u6027\u80fd\u3002"}}
{"id": "2506.00064", "pdf": "https://arxiv.org/pdf/2506.00064", "abs": "https://arxiv.org/abs/2506.00064", "authors": ["Jiayi Zeng", "Yizhe Feng", "Mengliang He", "Wenhui Lei", "Wei Zhang", "Zeming Liu", "Xiaoming Shi", "Aimin Zhou"], "title": "Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have demonstrated significant advancements in\nerror handling. Current error-handling works are performed in a passive manner,\nwith explicit error-handling instructions. However, in real-world scenarios,\nexplicit error-handling instructions are usually unavailable. In this paper,\nour work identifies this challenge as how to conduct proactive error handling\nwithout explicit error handling instructions. To promote further research, this\nwork introduces a new benchmark, termed Mis-prompt, consisting of four\nevaluation tasks, an error category taxonomy, and a new evaluation dataset.\nFurthermore, this work analyzes current LLMs' performance on the benchmark, and\nthe experimental results reveal that current LLMs show poor performance on\nproactive error handling, and SFT on error handling instances improves LLMs'\nproactive error handling capabilities. The dataset will be publicly available.", "AI": {"tldr": "The paper presents a new benchmark (Mis-prompt) for proactive error handling in LLMs, revealing current models' limitations and showing that error handling instances enhance performance.", "motivation": "In real-world scenarios, explicit error-handling instructions are often unavailable, posing a challenge for LLMs to conduct proactive error handling.", "method": "Introduce a new benchmark called Mis-prompt, which includes four evaluation tasks, an error category taxonomy, and an evaluation dataset. Analyze LLMs' performance on the benchmark.", "result": "Current LLMs perform poorly on proactive error handling, but the inclusion of error handling instances improves their performance.", "conclusion": "SFT on error handling instances can enhance LLMs' capabilities for proactive error handling."}}
{"id": "2506.00152", "pdf": "https://arxiv.org/pdf/2506.00152", "abs": "https://arxiv.org/abs/2506.00152", "authors": ["Erfan Loghmani"], "title": "Aligning Language Models with Observational Data: Opportunities and Risks from a Causal Perspective", "categories": ["cs.LG", "econ.EM", "stat.ML", "I.2.6; I.2.7; H.4.0; J.4"], "comment": "10+12 pages, 8 figures", "summary": "Large language models are being widely used across industries to generate\ncontent that contributes directly to key performance metrics, such as\nconversion rates. Pretrained models, however, often fall short when it comes to\naligning with human preferences or optimizing for business objectives. As a\nresult, fine-tuning with good-quality labeled data is essential to guide models\nto generate content that achieves better results. Controlled experiments, like\nA/B tests, can provide such data, but they are often expensive and come with\nsignificant engineering and logistical challenges. Meanwhile, companies have\naccess to a vast amount of historical (observational) data that remains\nunderutilized. In this work, we study the challenges and opportunities of\nfine-tuning LLMs using observational data. We show that while observational\noutcomes can provide valuable supervision, directly fine-tuning models on such\ndata can lead them to learn spurious correlations. We present empirical\nevidence of this issue using various real-world datasets and propose\nDeconfoundLM, a method that explicitly removes the effect of known confounders\nfrom reward signals. Using simulation experiments, we demonstrate that\nDeconfoundLM improves the recovery of causal relationships and mitigates\nfailure modes found in fine-tuning methods that ignore or naively incorporate\nconfounding variables. Our findings highlight that while observational data\npresents risks, with the right causal corrections, it can be a powerful source\nof signal for LLM alignment. Please refer to the project page for code and\nrelated resources.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u89c2\u5bdf\u6027\u6570\u636e\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6311\u6218\u548c\u673a\u4f1a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u9664\u6df7\u6dc6\u56e0\u7d20\u5f71\u54cd\u7684\u65b9\u6cd5\u4ee5\u4f18\u5316\u56e0\u679c\u5173\u7cfb\u6062\u590d\u3002", "motivation": "\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u4e0e\u4eba\u7c7b\u504f\u597d\u6216\u4f18\u5316\u5546\u4e1a\u76ee\u6807\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u4f18\u8d28\u6807\u8bb0\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u3002", "method": "\u63d0\u51fa\u4e86DeconfoundLM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u53bb\u9664\u5956\u52b1\u4fe1\u53f7\u4e2d\u7684\u5df2\u77e5\u6df7\u6dc6\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u6539\u5584\u56e0\u679c\u5173\u7cfb\u7684\u6062\u590d\u3002", "result": "DeconfoundLM\u6539\u5584\u4e86\u56e0\u679c\u5173\u7cfb\u7684\u6062\u590d\uff0c\u5e76\u51cf\u8f7b\u4e86\u5ffd\u89c6\u6216\u5929\u771f\u5730\u7ed3\u5408\u6df7\u6dc6\u53d8\u91cf\u7684\u5fae\u8c03\u65b9\u6cd5\u4e2d\u7684\u5931\u6548\u6a21\u5f0f\u3002", "conclusion": "\u89c2\u5bdf\u6027\u6570\u636e\u53ef\u4ee5\u6210\u4e3a\u5927\u6a21\u578b\u5bf9\u9f50\u7684\u5f3a\u5927\u4fe1\u53f7\u6765\u6e90\uff0c\u53ea\u8981\u8fdb\u884c\u6b63\u786e\u7684\u56e0\u679c\u6821\u6b63\u3002"}}
{"id": "2506.00189", "pdf": "https://arxiv.org/pdf/2506.00189", "abs": "https://arxiv.org/abs/2506.00189", "authors": ["Di Zhang", "Weida Wang", "Junxian Li", "Xunzhi Wang", "Jiatong Li", "Jianbo Wu", "Jingdi Lei", "Haonan He", "Peng Ye", "Shufei Zhang", "Wanli Ouyang", "Yuqiang Li", "Dongzhan Zhou"], "title": "Control-R: Towards controllable test-time scaling", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "This paper target in addressing the challenges of underthinking and\noverthinking in long chain-of-thought (CoT) reasoning for Large Reasoning\nModels (LRMs) by introducing Reasoning Control Fields (RCF)--a novel test-time\napproach that injects structured control signals to guide reasoning from a tree\nsearch perspective. RCF enables models to adjust reasoning effort according to\ngiven control conditions when solving complex tasks. Additionally, we present\nthe Control-R-4K dataset, which consists of challenging problems annotated with\ndetailed reasoning processes and corresponding control fields. To further\nenhance reasoning control, we propose a Conditional Distillation Finetuning\n(CDF) method, which trains model--particularly Control-R-32B--to effectively\nadjust reasoning effort during test time. Experimental results on benchmarks\nsuch as AIME2024 and MATH500 demonstrate that our approach achieves\nstate-of-the-art performance at the 32B scale while enabling a controllable\nLong CoT reasoning process (L-CoT). Overall, this work introduces an effective\nparadigm for controllable test-time scaling reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86RCF\u548cCDF\u65b9\u6cd5\u6765\u4f18\u5316\u957f\u94fe\u63a8\u7406\u4e2d\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u572832B\u89c4\u6a21\u4e0a\u7684\u6700\u5148\u8fdb\u6027\u80fd\u548c\u53ef\u63a7\u6d4b\u8bd5\u65f6\u95f4\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u5728\u957f\u94fe\u63a8\u7406\u8fc7\u7a0b\u4e2d\u56e0\u63a8\u7406\u8fc7\u5ea6\u6216\u4e0d\u8db3\u800c\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u5b9e\u73b0\u80fd\u591f\u6839\u636e\u7ed9\u5b9a\u7684\u63a7\u5236\u6761\u4ef6\u8c03\u6574\u63a8\u7406\u529b\u5ea6\u7684\u6a21\u578b\u3002", "method": "\u5229\u7528Reasoning Control Fields (RCF)\u548cConditional Distillation Finetuning (CDF)\u65b9\u6cd5\u5bf9\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u63a7\u5236\u548c\u4f18\u5316\u3002RCF\u901a\u8fc7\u6811\u641c\u7d22\u7684\u89c6\u89d2\u6ce8\u5165\u7ed3\u6784\u5316\u63a7\u5236\u4fe1\u53f7\u4ee5\u6307\u5bfc\u63a8\u7406\uff0cCDF\u901a\u8fc7\u8bad\u7ec3\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u6709\u6548\u8c03\u6574\u63a8\u7406\u52aa\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5982AIME2024\u548cMATH500\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u572832B\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5141\u8bb8\u53ef\u63a7\u7684\u957f\u94fe\u63a8\u7406\u8fc7\u7a0b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u53ef\u63a7\u6d4b\u8bd5\u65f6\u95f4\u63a8\u7406\u7f29\u653e\u8303\u5f0f\uff0c\u4ece\u800c\u5b9e\u73b0\u5728\u957f\u94fe\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u53ef\u63a7\u6027\u3002\u901a\u8fc7RCF\u548cCDF\u65b9\u6cd5\uff0c\u6a21\u578b\u572832B\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u80fd\u591f\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8c03\u6574\u63a8\u7406\u529b\u5ea6\u3002"}}
{"id": "2506.00554", "pdf": "https://arxiv.org/pdf/2506.00554", "abs": "https://arxiv.org/abs/2506.00554", "authors": ["Hadi Hosseini", "Grzegorz Lisowski", "Shraddha Pathak"], "title": "Two-Sided Manipulation Games in Stable Matching Markets", "categories": ["cs.GT", "cs.MA"], "comment": null, "summary": "The Deferred Acceptance (DA) algorithm is an elegant procedure for finding a\nstable matching in two-sided matching markets. It ensures that no pair of\nagents prefers each other to their matched partners. In this work, we initiate\nthe study of two-sided manipulations in matching markets as non-cooperative\ngames. We introduce the accomplice manipulation game, where a man misreports to\nhelp a specific woman obtain a better partner, whenever possible. We provide a\npolynomial time algorithm for finding a pure strategy Nash equilibrium (NE) and\nshow that our algorithm always yields a stable matching - although not every\nNash equilibrium corresponds to a stable matching. Additionally, we show how\nour analytical techniques for the accomplice manipulation game can be applied\nto other manipulation games in matching markets, such as one-for-many and the\nstandard self-manipulation games. We complement our theoretical findings with\nempirical evaluations of different properties of the resulting NE, such as the\nwelfare of the agents.", "AI": {"tldr": "\u7814\u7a76\u4e24\u65b9\u5339\u914d\u5e02\u573a\u64cd\u63a7\uff0c\u5f15\u5165\u540c\u8c0b\u64cd\u63a7\u6e38\u620f\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u627e\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u6269\u5c55\u5230\u5176\u4ed6\u64cd\u63a7\u6e38\u620f\u5e76\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "motivation": "\u7814\u7a76\u4e24\u65b9\u5339\u914d\u5e02\u573a\u4e2d\u7684\u975e\u5408\u4f5c\u535a\u5f08\u64cd\u63a7\uff0c\u4ee5\u5e2e\u52a9\u7279\u5b9a\u4e2a\u4f53\u83b7\u5f97\u66f4\u597d\u5339\u914d\u53ca\u63a2\u7d22\u5176\u5bf9\u5e94\u5747\u8861\u7684\u6027\u8d28\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u5e76\u7814\u7a76\u4e86\u540c\u8c0b\u64cd\u63a7\u6e38\u620f\uff0c\u901a\u8fc7\u7b97\u6cd5\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u627e\u5230\u8be5\u6e38\u620f\u7684\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\u3002\u540c\u65f6\u5c06\u5206\u6790\u6280\u672f\u5e94\u7528\u4e8e\u5176\u4ed6\u64cd\u63a7\u6e38\u620f\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u627e\u5230\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u8bc1\u660e\u4e86\u7b97\u6cd5\u603b\u80fd\u4ea7\u751f\u7a33\u5b9a\u5339\u914d\uff0c\u867d\u7136\u4e0d\u662f\u6bcf\u4e2a\u7eb3\u4ec0\u5747\u8861\u90fd\u80fd\u5bf9\u5e94\u7a33\u5b9a\u5339\u914d\u3002", "conclusion": "\u6211\u4eec\u5f15\u5165\u4e86\u540c\u8c0b\u64cd\u63a7\u6e38\u620f\uff0c\u5e76\u4e14\u4e3a\u627e\u5230\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5c3d\u7ba1\u5e76\u4e0d\u662f\u6bcf\u4e2a\u7eb3\u4ec0\u5747\u8861\u90fd\u5bf9\u5e94\u4e8e\u7a33\u5b9a\u5339\u914d\u3002\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u7406\u8bba\u53d1\u73b0\u53ef\u4ee5\u5e94\u7528\u4e8e\u5339\u914d\u5e02\u573a\u4e2d\u7684\u5176\u4ed6\u64cd\u63a7\u6e38\u620f\uff0c\u5e76\u8003\u5bdf\u4e86\u5747\u8861\u7684\u4e0d\u540c\u5c5e\u6027\u5982\u4ee3\u7406\u4eba\u7684\u798f\u5229\u3002"}}
{"id": "2506.00065", "pdf": "https://arxiv.org/pdf/2506.00065", "abs": "https://arxiv.org/abs/2506.00065", "authors": ["Dota Tianai Dong", "Yifan Luo", "Po-Ya Angela Wang", "Asli Ozyurek", "Paula Rubio-Fernandez"], "title": "You Prefer This One, I Prefer Yours: Using Reference Words is Harder Than Vocabulary Words for Humans and Multimodal Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages", "summary": "Multimodal language models (MLMs) increasingly communicate in human-like\nways, yet their ability to use reference words remains largely overlooked\ndespite their ubiquity in everyday communication. Our study addresses this gap\nby comparing human and MLM use of three word classes with increasing cognitive\ndemands: vocabulary words, possessive pronouns (`mine' vs `yours'), and\ndemonstrative pronouns (`this one' vs `that one'). Evaluating seven\nstate-of-the-art MLMs against human participants, we observe a clear difficulty\nhierarchy: while MLMs approach human-level performance on the vocabulary task,\nthey show substantial deficits with possessives and demonstratives. Our\nanalysis reveals these difficulties stem from limitations in perspective-taking\nand spatial reasoning. Although prompt engineering improved model performance\non possessive use, demonstrative use remained well below human-level\ncompetence. These findings provide theoretical and empirical evidence that\nproducing grammatical forms requiring pragmatics and social cognition remains a\nclear challenge in current NLP systems.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e0e\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0d\u540c\u8bcd\u7c7b\u7684\u4f7f\u7528\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4f7f\u7528\u7269\u4e3b\u4ee3\u8bcd\u548c\u6307\u793a\u4ee3\u8bcd\u4e0a\u56f0\u96be\u91cd\u91cd\uff0c\u4e3b\u8981\u6e90\u4e8e\u89c6\u89d2\u8f6c\u6362\u548c\u7a7a\u95f4\u63a8\u7406\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u5177\u6709\u4eba\u7c7b\u4ea4\u6d41\u7684\u7279\u6027\uff0c\u4f46\u5b83\u4eec\u5bf9\u53c2\u8003\u8bcd\u7684\u4f7f\u7528\u80fd\u529b\u4ecd\u7136\u6ca1\u6709\u5f97\u5230\u8db3\u591f\u7684\u5173\u6ce8\uff0c\u800c\u53c2\u8003\u8bcd\u5728\u65e5\u5e38\u4ea4\u6d41\u4e2d\u975e\u5e38\u666e\u904d\u3002", "method": "\u5c06\u4eba\u7c7b\u4e0e\u4e03\u4e2a\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u79cd\u8ba4\u77e5\u9700\u6c42\u9010\u6e10\u589e\u52a0\u7684\u8bcd\u7c7b\u7684\u4f7f\u7528\u4e0a\u8fdb\u884c\u6bd4\u8f83\uff1a\u8bcd\u6c47\u3001\u7269\u4e3b\u4ee3\u8bcd\uff08\u4f8b\u5982\u201c\u6211\u7684\u201d\u4e0e\u201c\u4f60\u7684\u201d\uff09\u4ee5\u53ca\u6307\u793a\u4ee3\u8bcd\uff08\u4f8b\u5982\u201c\u8fd9\u4e2a\u201d\u4e0e\u201c\u90a3\u4e2a\u201d\uff09\u3002", "result": "\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u8bcd\u6c47\u4efb\u52a1\u4e2d\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\uff0c\u4f46\u5728\u4f7f\u7528\u7269\u4e3b\u4ee3\u8bcd\u548c\u6307\u793a\u4ee3\u8bcd\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002\u8fd9\u4e9b\u56f0\u96be\u6e90\u4e8e\u6a21\u578b\u5728\u89c6\u89d2\u8f6c\u6362\u548c\u7a7a\u95f4\u63a8\u7406\u4e0a\u7684\u5c40\u9650\u6027\u3002\u5c3d\u7ba1\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u53ef\u4ee5\u6539\u5584\u6a21\u578b\u5728\u7269\u4e3b\u4ee3\u8bcd\u4f7f\u7528\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u6307\u793a\u4ee3\u8bcd\u7684\u4f7f\u7528\u4ecd\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "\u5f53\u524d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u5728\u4f7f\u7528\u9700\u8981\u8bed\u7528\u5b66\u548c\u793e\u4f1a\u8ba4\u77e5\u7684\u8bed\u6cd5\u5f62\u5f0f\u4e0a\u4ecd\u7136\u9762\u4e34\u660e\u663e\u6311\u6218\u3002"}}
{"id": "2506.00158", "pdf": "https://arxiv.org/pdf/2506.00158", "abs": "https://arxiv.org/abs/2506.00158", "authors": ["Eli Chien", "Wei-Ning Chen", "Pan Li"], "title": "Privacy Amplification in Differentially Private Zeroth-Order Optimization with Hidden States", "categories": ["cs.LG"], "comment": null, "summary": "Zeroth-order optimization has emerged as a promising approach for fine-tuning\nlarge language models on domain-specific data, particularly under differential\nprivacy (DP) and memory constraints. While first-order methods have been\nextensively studied from a privacy perspective, the privacy analysis and\nalgorithmic design for zeroth-order methods remain significantly underexplored.\nA critical open question concerns hidden-state DP analysis: although convergent\nprivacy bounds are known for first-order methods, it has remained unclear\nwhether similar guarantees can be established for zeroth-order methods. In this\nwork, we provide an affirmative answer by proving a convergent DP bound for\nzeroth-order optimization. Our analysis generalizes the celebrated privacy\namplification-by-iteration framework to the setting of smooth loss functions in\nzeroth-order optimization. Furthermore, it induces better DP zeroth-order\nalgorithmic designs that are previously unknown to the literature.", "AI": {"tldr": "\u7814\u7a76\u7684\u91cd\u70b9\u662f\u96f6\u9636\u4f18\u5316\u7684\u9690\u79c1\u5206\u6790\uff0c\u6210\u529f\u8bc1\u660e\u5176\u6536\u655b\u6027\u9690\u79c1\u754c\u5e76\u63d0\u51fa\u4e86\u66f4\u4f18\u7b97\u6cd5\u8bbe\u8ba1\u3002", "motivation": "\u96f6\u9636\u4f18\u5316\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u5dee\u5206\u9690\u79c1\u548c\u5185\u5b58\u9650\u5236\u6761\u4ef6\u4e0b\uff0c\u4f46\u5176\u9690\u79c1\u5206\u6790\u548c\u7b97\u6cd5\u8bbe\u8ba1\u4ecd\u9700\u6df1\u5165\u63a2\u7d22\u3002", "method": "\u6211\u4eec\u91c7\u7528\u9690\u79c1\u653e\u5927\u7684\u8fed\u4ee3\u6846\u67b6\u6765\u5206\u6790\u96f6\u9636\u4f18\u5316\u7684\u9690\u79c1\u754c\uff0c\u8bc1\u660e\u5176\u6536\u655b\u7279\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u9636\u4f18\u5316\u7684\u6536\u655b\u7684\u5dee\u5206\u9690\u79c1\u754c\uff0c\u5e76\u6539\u5584\u4e86\u96f6\u9636\u7b97\u6cd5\u7684\u8bbe\u8ba1\u3002", "conclusion": "\u6211\u4eec\u8bc1\u660e\u4e86\u96f6\u9636\u4f18\u5316\u7684\u9690\u79c1\u6027\u6536\u655b\u754c\uff0c\u4e3a\u6b64\u7c7b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u9690\u79c1\u653e\u5927\u8fed\u4ee3\u6846\u67b6\u5728\u5e73\u6ed1\u635f\u5931\u51fd\u6570\u6761\u4ef6\u4e0b\u7684\u63a8\u5e7f\uff0c\u4ece\u800c\u63d0\u51fa\u4e86\u66f4\u4f18\u7684\u96f6\u9636\u7b97\u6cd5\u8bbe\u8ba1\u3002"}}
{"id": "2506.00202", "pdf": "https://arxiv.org/pdf/2506.00202", "abs": "https://arxiv.org/abs/2506.00202", "authors": ["Matthew Kam", "Cody Miller", "Miaoxin Wang", "Abey Tidwell", "Irene A. Lee", "Joyce Malyn-Smith", "Beatriz Perez", "Vikram Tiwari", "Joshua Kenitzer", "Andrew Macvean", "Erin Barrar"], "title": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?", "categories": ["cs.AI"], "comment": "12 pages, 4 figures, software engineering education track of the 2025\n  ACM international conference on the foundations of software engineering,\n  includes supplementary material i.e. full 50-page occupational profile of the\n  AI-enhanced software developer", "summary": "Generative AI is showing early evidence of productivity gains for software\ndevelopers, but concerns persist regarding workforce disruption and deskilling.\nWe describe our research with 21 developers at the cutting edge of using AI,\nsummarizing 12 of their work goals we uncovered, together with 75 associated\ntasks and the skills & knowledge for each, illustrating how developers use AI\nat work. From all of these, we distilled our findings in the form of 5\ninsights. We found that the skills & knowledge to be a successful AI-enhanced\ndeveloper are organized into four domains (using Generative AI effectively,\ncore software engineering, adjacent engineering, and adjacent non-engineering)\ndeployed at critical junctures throughout a 6-step task workflow. In order to\n\"future proof\" developers for this age of AI, on-the-job learning initiatives\nand computer science degree programs will need to target both \"soft\" skills and\nthe technical skills & knowledge in all four domains to reskill, upskill and\nsafeguard against deskilling.", "AI": {"tldr": "\u7814\u7a76\u4e86AI\u5bf9\u5f00\u53d1\u4eba\u5458\u7684\u5f71\u54cd\uff0c\u5206\u6790\u4e86\u6240\u9700\u6280\u80fd\uff0c\u63d0\u51fa\u4e86\u6280\u80fd\u63d0\u5347\u7684\u5efa\u8bae\uff0c\u4ee5\u5e94\u5bf9\u53ef\u80fd\u7684\u52b3\u52a8\u529b\u5e02\u573a\u53d8\u5316\u548c\u6280\u80fd\u9000\u5316\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u7684\u751f\u4ea7\u529b\u63d0\u5347\uff0c\u540c\u65f6\u5173\u6ce8\u5176\u5bf9\u52b3\u52a8\u529b\u5e02\u573a\u7684\u5f71\u54cd\u53ca\u53ef\u80fd\u5e26\u6765\u7684\u6280\u80fd\u9000\u5316\u3002", "method": "\u7814\u7a76\u4e8621\u540d\u5904\u4e8eAI\u5e94\u7528\u524d\u6cbf\u7684\u5f00\u53d1\u8005\uff0c\u603b\u7ed3\u5e76\u5206\u6790\u4e86\u4ed6\u4eec\u7684\u5de5\u4f5c\u76ee\u6807\u3001\u76f8\u5173\u4efb\u52a1\u4ee5\u53ca\u6240\u9700\u7684\u6280\u80fd\u548c\u77e5\u8bc6\uff0c\u4ece\u4e2d\u63d0\u70bc\u51fa\u4e94\u6761\u89c1\u89e3\u3002", "result": "\u5f97\u51fa\u4e86\u6210\u529f\u7684AI\u589e\u5f3a\u5f00\u53d1\u4eba\u5458\u7684\u6280\u80fd\u548c\u77e5\u8bc6\u5206\u4e3a\u56db\u4e2a\u9886\u57df\uff0c\u5e76\u5728\u516d\u6b65\u4efb\u52a1\u6d41\u7a0b\u4e2d\u7684\u5173\u952e\u8282\u70b9\u8fdb\u884c\u5e94\u7528\u7684\u7814\u7a76\u7ed3\u679c\u3002", "conclusion": "\u4e3a\u4e86\u5728AI\u65f6\u4ee3\u4fdd\u6301\u5f00\u53d1\u4eba\u5458\u7684\u6280\u672f\u7ade\u4e89\u529b\uff0c\u5de5\u4f5c\u4e2d\u7684\u5b66\u4e60\u8ba1\u5212\u548c\u8ba1\u7b97\u673a\u79d1\u5b66\u5b66\u4f4d\u9879\u76ee\u9700\u8981\u540c\u65f6\u5173\u6ce8\u201c\u8f6f\u201d\u6280\u80fd\u4ee5\u53ca\u56db\u4e2a\u9886\u57df\u7684\u6280\u672f\u6280\u80fd\u548c\u77e5\u8bc6\uff0c\u4ee5\u91cd\u5851\u3001\u63d0\u5347\u6280\u80fd\u5e76\u9632\u6b62\u6280\u80fd\u9000\u5316\u3002"}}
{"id": "2506.00577", "pdf": "https://arxiv.org/pdf/2506.00577", "abs": "https://arxiv.org/abs/2506.00577", "authors": ["Yufa Zhou", "Shaobo Wang", "Xingyu Dong", "Xiangqi Jin", "Yifang Chen", "Yue Min", "Kexin Yang", "Xingzhang Ren", "Dayiheng Liu", "Linfeng Zhang"], "title": "Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.MA"], "comment": null, "summary": "Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)\nremains challenging due to intricate reward modeling, dynamic agent\ninteractions, and demanding generalization requirements. This paper explores\nwhether post-training techniques, specifically Supervised Fine-Tuning (SFT) and\nReinforcement Learning with Verifiable Rewards (RLVR), can effectively\n$\\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a\ntestbed, leveraging its strong foundations in mathematics and game theory, its\ndemand for structured analytical reasoning, and its relevance to real-world\napplications such as market design, resource allocation, and policy analysis.\nWe introduce $\\textbf{Recon}$ ($\\textbf{R}$easoning like an\n$\\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a\nhand-curated dataset of 2,100 high-quality economic reasoning problems.\nComprehensive evaluation on economic reasoning benchmarks and multi-agent games\nreveals clear improvements in structured reasoning and economic rationality.\nThese results underscore the promise of domain-aligned post-training for\nenhancing reasoning and agent alignment, shedding light on the roles of SFT and\nRL in shaping model behavior. Code is available at\nhttps://github.com/MasterZhou1/Recon .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u76f4\u63a5\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5177\u6709\u6311\u6218\u6027\u3002\u8fd9\u662f\u7531\u4e8e\u590d\u6742\u7684\u5956\u52b1\u5efa\u6a21\u3001\u52a8\u6001\u7684\u667a\u80fd\u4f53\u4ea4\u4e92\u4ee5\u53ca\u4e25\u683c\u7684\u6cdb\u5316\u8981\u6c42\u3002", "method": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u540e\u8bad\u7ec3\u6280\u672f\uff0c\u5c24\u5176\u662f\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u662f\u5426\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u3002\u5b83\u4f7f\u7528\u7ecf\u6d4e\u5b66\u63a8\u7406\u4f5c\u4e3a\u8bd5\u9a8c\u5e73\u53f0\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aRecon\u76847B\u53c2\u6570\u5f00\u653e\u6e90\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u540e\u8bad\u7ec3\u4e8e2100\u4e2a\u9ad8\u8d28\u91cf\u7ecf\u6d4e\u5b66\u63a8\u7406\u95ee\u9898\u7684\u6570\u636e\u96c6\u4e0a\u3002", "result": "\u5728\u7ecf\u6d4e\u5b66\u63a8\u7406\u57fa\u51c6\u548c\u591a\u667a\u80fd\u4f53\u6e38\u620f\u7684\u7efc\u5408\u8bc4\u4f30\u4e2d\uff0c\u8be5\u6a21\u578b\u5728\u7ed3\u6784\u5316\u63a8\u7406\u548c\u7ecf\u6d4e\u5408\u7406\u6027\u65b9\u9762\u663e\u793a\u51fa\u660e\u663e\u6539\u8fdb\u3002", "conclusion": "\u57df\u5bf9\u9f50\u7684\u540e\u8bad\u7ec3\u6280\u672f\u80fd\u591f\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u667a\u80fd\u4f53\u5bf9\u9f50\u80fd\u529b\uff0c\u8fd9\u4e5f\u5f3a\u8c03\u4e86\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u5851\u9020\u6a21\u578b\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2506.00068", "pdf": "https://arxiv.org/pdf/2506.00068", "abs": "https://arxiv.org/abs/2506.00068", "authors": ["Afrozah Nadeem", "Mark Dras", "Usman Naseem"], "title": "Probing Politico-Economic Bias in Multilingual Large Language Models: A Cultural Analysis of Low-Resource Pakistani Languages", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint", "summary": "Large Language Models (LLMs) are increasingly shaping public discourse, yet\ntheir politico-economic biases remain underexamined in non-Western and\nlow-resource multilingual contexts. This paper presents a systematic analysis\nof political bias in 13 state-of-the-art LLMs across five low-resource\nlanguages spoken in Pakistan: Urdu, Punjabi, Sindhi, Balochi, and Pashto. We\npropose a novel framework that integrates an adapted Political Compass Test\n(PCT) with a multi-level framing analysis. Our method combines quantitative\nassessment of political orientation across economic (left-right) and social\n(libertarian-authoritarian) axes with qualitative analysis of framing through\ncontent, style, and emphasis. We further contextualize this analysis by\naligning prompts with 11 key socio-political themes relevant to Pakistani\nsociety. Our results reveal that LLMs predominantly align with liberal-left\nvalues, echoing Western training data influences, but exhibit notable shifts\ntoward authoritarian framing in regional languages, suggesting strong cultural\nmodulation effects. We also identify consistent model-specific bias signatures\nand language-conditioned variations in ideological expression. These findings\nshow the urgent need for culturally grounded, multilingual bias auditing\nframeworks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e8613\u4e2aLLMs\u5728\u5df4\u57fa\u65af\u5766\u4e94\u79cd\u8bed\u8a00\u4e2d\u8868\u73b0\u51fa\u7684\u653f\u6cbb\u504f\u89c1\uff0c\u53d1\u73b0\u5b83\u4eec\u65e2\u53d7\u5230\u897f\u65b9\u6570\u636e\u7684\u5f71\u54cd\uff0c\u53c8\u53d7\u6587\u5316\u8c03\u8282\u5f71\u54cd\uff0c\u547c\u5401\u5efa\u7acb\u591a\u8bed\u8a00\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u975e\u897f\u65b9\u548c\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u653f\u6cbb\u7ecf\u6d4e\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u5df4\u57fa\u65af\u5766\u7684\u4e94\u79cd\u8bed\u8a00\u4e2d\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u5c06\u6539\u7f16\u7684\u653f\u6cbb\u7f57\u76d8\u6d4b\u8bd5\u4e0e\u591a\u5c42\u6b21\u7684\u6846\u67b6\u5206\u6790\u76f8\u7ed3\u5408\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5bf9\u7ecf\u6d4e\uff08\u5de6\u53f3\u7ffc\uff09\u548c\u793e\u4f1a\uff08\u81ea\u7531\u4e3b\u4e49-\u6743\u5a01\u4e3b\u4e49\uff09\u8f74\u4e0a\u7684\u653f\u6cbb\u503e\u5411\u7684\u5b9a\u91cf\u8bc4\u4f30\uff0c\u4ee5\u53ca\u901a\u8fc7\u5185\u5bb9\u3001\u98ce\u683c\u548c\u91cd\u70b9\u7684\u6846\u67b6\u5b9a\u6027\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0cLLMs\u4e3b\u8981\u4e0e\u81ea\u7531\u5de6\u6d3e\u4ef7\u503c\u89c2\u4e00\u81f4\uff0c\u53cd\u6620\u4e86\u897f\u65b9\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\uff0c\u4f46\u5728\u5730\u533a\u8bed\u8a00\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u5411\u6743\u5a01\u4e3b\u4e49\u6846\u67b6\u7684\u8f6c\u53d8\uff0c\u8868\u660e\u5f3a\u70c8\u7684\u6587\u5316\u8c03\u8282\u6548\u5e94\u3002\u540c\u65f6\u8bc6\u522b\u51fa\u4e00\u81f4\u7684\u7279\u5b9a\u6a21\u578b\u504f\u89c1\u7279\u5f81\u548c\u7531\u8bed\u8a00\u5236\u7ea6\u7684\u610f\u8bc6\u5f62\u6001\u8868\u8fbe\u53d8\u5316\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u8feb\u5207\u9700\u8981\u6587\u5316\u57fa\u7840\u7684\u591a\u8bed\u8a00\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u975e\u897f\u65b9\u548c\u4f4e\u8d44\u6e90\u73af\u5883\u4e0bLLMs\u7684\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2506.00166", "pdf": "https://arxiv.org/pdf/2506.00166", "abs": "https://arxiv.org/abs/2506.00166", "authors": ["Kundan Krishna", "Joseph Y Cheng", "Charles Maalouf", "Leon A Gatys"], "title": "Disentangled Safety Adapters Enable Efficient Guardrails and Flexible Inference-Time Alignment", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "16 pages, 2 figures, including references and appendix", "summary": "Existing paradigms for ensuring AI safety, such as guardrail models and\nalignment training, often compromise either inference efficiency or development\nflexibility. We introduce Disentangled Safety Adapters (DSA), a novel framework\naddressing these challenges by decoupling safety-specific computations from a\ntask-optimized base model. DSA utilizes lightweight adapters that leverage the\nbase model's internal representations, enabling diverse and flexible safety\nfunctionalities with minimal impact on inference cost. Empirically, DSA-based\nsafety guardrails substantially outperform comparably sized standalone models,\nnotably improving hallucination detection (0.88 vs. 0.61 AUC on Summedits) and\nalso excelling at classifying hate speech (0.98 vs. 0.92 on ToxiGen) and unsafe\nmodel inputs and responses (0.93 vs. 0.90 on AEGIS2.0 & BeaverTails).\nFurthermore, DSA-based safety alignment allows dynamic, inference-time\nadjustment of alignment strength and a fine-grained trade-off between\ninstruction following performance and model safety. Importantly, combining the\nDSA safety guardrail with DSA safety alignment facilitates context-dependent\nalignment strength, boosting safety on StrongReject by 93% while maintaining\n98% performance on MTBench -- a total reduction in alignment tax of 8\npercentage points compared to standard safety alignment fine-tuning. Overall,\nDSA presents a promising path towards more modular, efficient, and adaptable AI\nsafety and alignment.", "AI": {"tldr": "DSA provides an efficient and flexible AI safety framework, outperforming standalone models in multiple safety tasks and reducing alignment tax while maintaining strong performance.", "motivation": "The motivation behind the study is to create a safety framework that does not compromise inference efficiency or the flexibility of development, addressing the limitations of existing AI safety paradigms.", "method": "The paper introduces Disentangled Safety Adapters (DSA), which decouple safety computations from task-optimized base models. DSA utilizes lightweight adapters leveraging the base model's representations to ensure safety with minimal inference cost.", "result": "Empirical results show that DSA-based guardrails outperform standalone models, improving hallucination detection, hate speech classification, and unsafe input recognition. It also allows for dynamic adjustment of alignment at inference time, enhancing safety outcomes in various tests.", "conclusion": "DSA represents a modular and efficient framework for AI safety, offering significant improvements in a variety of safety and alignment metrics without compromising on efficiency or flexibility."}}
{"id": "2506.00233", "pdf": "https://arxiv.org/pdf/2506.00233", "abs": "https://arxiv.org/abs/2506.00233", "authors": ["Aasish Kumar Sharma", "Dimitar Kyosev", "Julian Kunkel"], "title": "Ethical AI: Towards Defining a Collective Evaluation Framework", "categories": ["cs.AI"], "comment": "6 pages, 3 figures, accepted at 8th IEEE International Workshop on\n  Advances in Artificial Intelligence and Machine Learning (AIML 2025):\n  Futuristic AI and ML models & Intelligent Systems", "summary": "Artificial Intelligence (AI) is transforming sectors such as healthcare,\nfinance, and autonomous systems, offering powerful tools for innovation. Yet\nits rapid integration raises urgent ethical concerns related to data ownership,\nprivacy, and systemic bias. Issues like opaque decision-making, misleading\noutputs, and unfair treatment in high-stakes domains underscore the need for\ntransparent and accountable AI systems. This article addresses these challenges\nby proposing a modular ethical assessment framework built on ontological blocks\nof meaning-discrete, interpretable units that encode ethical principles such as\nfairness, accountability, and ownership. By integrating these blocks with FAIR\n(Findable, Accessible, Interoperable, Reusable) principles, the framework\nsupports scalable, transparent, and legally aligned ethical evaluations,\nincluding compliance with the EU AI Act. Using a real-world use case in\nAI-powered investor profiling, the paper demonstrates how the framework enables\ndynamic, behavior-informed risk classification. The findings suggest that\nontological blocks offer a promising path toward explainable and auditable AI\nethics, though challenges remain in automation and probabilistic reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u8bba\u6a21\u5757\u7684\u4f26\u7406\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u6570\u636e\u6240\u6709\u6743\u3001\u9690\u79c1\u3001\u504f\u89c1\u95ee\u9898\uff0c\u7ed3\u5408FAIR\u539f\u5219\uff0c\u53ef\u7528\u4e8eAI\u4f26\u7406\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u6848\u4f8b\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u7684\u5feb\u901f\u6574\u5408\u5e26\u6765\u4e86\u6709\u5173\u6570\u636e\u6240\u6709\u6743\u3001\u9690\u79c1\u548c\u7cfb\u7edf\u504f\u89c1\u7684\u7d27\u8feb\u4f26\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u8bba\u6a21\u5757\u7684\u4f26\u7406\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408FAIR\u539f\u5219\uff0c\u7528\u4e8e\u8bc4\u4f30AI\u4f26\u7406\u3002", "result": "\u4f7f\u7528\u5b9e\u9645\u6848\u4f8b\uff08AI\u9a71\u52a8\u7684\u6295\u8d44\u8005\u5206\u6790\uff09\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5982\u4f55\u5b9e\u73b0\u52a8\u6001\u3001\u884c\u4e3a\u5bfc\u5411\u7684\u98ce\u9669\u5206\u7c7b\u3002", "conclusion": "\u672c\u4f53\u6a21\u5757\u4e3a\u53ef\u89e3\u91ca\u548c\u53ef\u5ba1\u8ba1\u7684AI\u4f26\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\uff0c\u4f46\u5728\u81ea\u52a8\u5316\u548c\u6982\u7387\u63a8\u7406\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2506.00837", "pdf": "https://arxiv.org/pdf/2506.00837", "abs": "https://arxiv.org/abs/2506.00837", "authors": ["Zhiqing Luo", "Yi Wang", "Yingying He", "Wei Wang"], "title": "Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar Assistance", "categories": ["cs.RO", "cs.MA"], "comment": "to appear in IEEE INFOCOM 2025", "summary": "Cooperative perception enables vehicles to share sensor readings and has\nbecome a new paradigm to improve driving safety, where the key enabling\ntechnology for realizing this vision is to real-time and accurately align and\nfuse the perceptions. Recent advances to align the views rely on high-density\nLiDAR data or fine-grained image feature representations, which however fail to\nmeet the requirements of accuracy, real-time, and adaptability for autonomous\ndriving. To this end, we present MMatch, a lightweight system that enables\naccurate and real-time perception fusion with mmWave radar point clouds. The\nkey insight is that fine-grained spatial information provided by the radar\npresent unique associations with all the vehicles even in two separate views.\nAs a result, by capturing and understanding the unique local and global\nposition of the targets in this association, we can quickly find out all the\nco-visible vehicles for view alignment. We implement MMatch on both the\ndatasets collected from the CARLA platform and the real-world traffic with over\n15,000 radar point cloud pairs. Experimental results show that MMatch achieves\ndecimeter-level accuracy within 59ms, which significantly improves the\nreliability for autonomous driving.", "AI": {"tldr": "MMatch uses mmWave radar for real-time, accurate perception fusion, achieving decimeter accuracy in 59ms, improving autonomous driving reliability.", "motivation": "Existing methods relying on high-density LiDAR data or fine-grained image features fail to meet the accuracy, real-time, and adaptability requirements for autonomous driving.", "method": "The paper presents MMatch, a lightweight system that uses mmWave radar point clouds to enable accurate and real-time perception fusion.", "result": "Experiments with over 15,000 radar point cloud pairs show that MMatch achieves decimeter-level accuracy within 59ms.", "conclusion": "MMatch significantly improves the reliability of autonomous driving by achieving decimeter-level accuracy within 59ms."}}
{"id": "2506.00069", "pdf": "https://arxiv.org/pdf/2506.00069", "abs": "https://arxiv.org/abs/2506.00069", "authors": ["Robert Hankache", "Kingsley Nketia Acheampong", "Liang Song", "Marek Brynda", "Raad Khraishi", "Greig A. Cowan"], "title": "Evaluating the Sensitivity of LLMs to Prior Context", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in multi-turn\ndialogue and other sustained interactive scenarios, it is essential to\nunderstand how extended context affects their performance. Popular benchmarks,\nfocusing primarily on single-turn question answering (QA) tasks, fail to\ncapture the effects of multi-turn exchanges. To address this gap, we introduce\na novel set of benchmarks that systematically vary the volume and nature of\nprior context. We evaluate multiple conventional LLMs, including GPT, Claude,\nand Gemini, across these benchmarks to measure their sensitivity to contextual\nvariations. Our findings reveal that LLM performance on multiple-choice\nquestions can degrade dramatically in multi-turn interactions, with performance\ndrops as large as 73% for certain models. Even highly capable models such as\nGPT-4o exhibit up to a 32% decrease in accuracy. Notably, the relative\nperformance of larger versus smaller models is not always predictable.\nMoreover, the strategic placement of the task description within the context\ncan substantially mitigate performance drops, improving the accuracy by as much\nas a factor of 3.5. These findings underscore the need for robust strategies to\ndesign, evaluate, and mitigate context-related sensitivity in LLMs.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u8bc4\u4f30LLM\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u8868\u660e\u4e0a\u4e0b\u6587\u53d8\u5316\u4f1a\u5bfc\u81f4\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u7b56\u7565\u6027\u8c03\u6574\u4e0a\u4e0b\u6587\u6765\u6539\u5584\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u8f6eQA\u4efb\u52a1\u4e0a\uff0c\u672a\u80fd\u6355\u6349\u591a\u8f6e\u4ea4\u4e92\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165\u65b0\u7684\u57fa\u51c6\u6765\u7cfb\u7edf\u5730\u7814\u7a76\u6b64\u524d\u4e0a\u4e0b\u6587\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u7684\u65b0\u57fa\u51c6\uff0c\u7cfb\u7edf\u5730\u6539\u53d8\u5148\u524d\u4e0a\u4e0b\u6587\u7684\u6570\u91cf\u548c\u6027\u8d28\uff0c\u5e76\u8bc4\u4f30\u591a\u79cdLLM\u5728\u8fd9\u4e9b\u57fa\u51c6\u4e0b\u5bf9\u4e0a\u4e0b\u6587\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u8868\u73b0\u53ef\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u67d0\u4e9b\u6a21\u578b\u4e0b\u964d\u5e45\u5ea6\u9ad8\u8fbe73%\uff0c\u5373\u4f7f\u662f\u6027\u80fd\u4f18\u5f02\u7684\u6a21\u578b\u5982GPT-4o\u4e5f\u51fa\u73b0\u4e86\u6700\u9ad832%\u7684\u51c6\u786e\u7387\u4e0b\u964d\u3002\u7136\u800c\uff0c\u901a\u8fc7\u7b56\u7565\u6027\u5730\u653e\u7f6e\u4efb\u52a1\u63cf\u8ff0\uff0c\u51c6\u786e\u7387\u53ef\u63d0\u5347\u81f33.5\u500d\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5f3a\u5927\u7684\u7b56\u7565\u6765\u8bbe\u8ba1\u3001\u8bc4\u4f30\u548c\u51cf\u8f7b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2506.00172", "pdf": "https://arxiv.org/pdf/2506.00172", "abs": "https://arxiv.org/abs/2506.00172", "authors": ["Kaivalya Hariharan", "Uzay Girit", "Atticus Wang", "Jacob Andreas"], "title": "Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents", "categories": ["cs.LG"], "comment": "21 pages, 14 figures", "summary": "Benchmarks for large language models (LLMs) have predominantly assessed\nshort-horizon, localized reasoning. Existing long-horizon suites (e.g.\nSWE-bench) rely on manually curated issues, so expanding or tuning difficulty\ndemands expensive human effort and evaluations quickly saturate. However, many\nreal-world tasks, such as software engineering or scientific research, require\nagents to rapidly comprehend and manipulate novel, complex structures\ndynamically; evaluating these capabilities requires the ability to construct\nlarge and varied sets of problems for agents to solve. We introduce Breakpoint,\na benchmarking methodology that automatically generates code-repair tasks by\nadversarially corrupting functions within real-world software repositories.\nBreakpoint systematically controls task difficulty along two clear dimensions:\nlocal reasoning (characterized by code complexity metrics such as cyclomatic\ncomplexity) and system-level reasoning (characterized by call-graph centrality\nand the number of simultaneously corrupted interdependent functions). In\nexperiments across more than 900 generated tasks we demonstrate that our\nmethodology can scale to arbitrary difficulty, with state-of-the-art models'\nsuccess rates ranging from 55% on the easiest tasks down to 0% on the hardest.", "AI": {"tldr": "Breakpoint\u662f\u4e00\u79cd\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u751f\u6210\u5bf9\u6297\u6027\u7684\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u8bc4\u4f30LLMs\u7684\u957f\u89c6\u8ddd\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u6709\u6548\u63a7\u5236\u4efb\u52a1\u96be\u5ea6\u3002", "motivation": "\u8bb8\u591a\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\uff0c\u5982\u8f6f\u4ef6\u5de5\u7a0b\u6216\u79d1\u7814\uff0c\u9700\u8981\u667a\u80fd\u4f53\u80fd\u591f\u8fc5\u901f\u7406\u89e3\u548c\u5904\u7406\u65b0\u9896\u3001\u590d\u6742\u7684\u7ed3\u6784\u3002\u8bc4\u4f30\u8fd9\u4e9b\u80fd\u529b\u9700\u8981\u80fd\u591f\u6784\u5efa\u5927\u91cf\u591a\u6837\u5316\u7684\u95ee\u9898\u96c6\u4f9b\u667a\u80fd\u4f53\u89e3\u51b3\u3002\u73b0\u6709\u957f\u89c6\u8ddd\u8bc4\u4f30\u5957\u4ef6\uff08\u5982SWE-bench\uff09\u4f9d\u8d56\u4eba\u5de5\u7b56\u5212\u7684\u95ee\u9898\uff0c\u6269\u5c55\u6216\u8c03\u8282\u96be\u5ea6\u9700\u8981\u6602\u8d35\u7684\u4eba\u529b\u6295\u5165\uff0c\u8bc4\u4f30\u4e5f\u5f88\u5feb\u8fbe\u5230\u9971\u548c\u3002", "method": "Breakpoint\u662f\u4e00\u79cd\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u73b0\u5b9e\u8f6f\u4ef6\u5e93\u4e2d\u7684\u51fd\u6570\u8fdb\u884c\u5bf9\u6297\u6027\u7684\u7834\u574f\uff0c\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u3002\u5b83\u7cfb\u7edf\u5730\u63a7\u5236\u4efb\u52a1\u96be\u5ea6\uff0c\u4f9d\u636e\u4e24\u4e2a\u660e\u786e\u7684\u7ef4\u5ea6\u6765\u8bc4\u4f30\uff1a\u5c40\u90e8\u63a8\u7406\uff08\u5982\u5708\u590d\u6742\u5ea6\uff09\u548c\u7cfb\u7edf\u7ea7\u63a8\u7406\uff08\u5982\u8c03\u7528\u56fe\u4e2d\u5fc3\u6027\u4ee5\u53ca\u540c\u65f6\u88ab\u7834\u574f\u7684\u76f8\u4e92\u4f9d\u8d56\u51fd\u6570\u6570\u91cf\uff09\u3002", "result": "\u5728\u8d85\u8fc7900\u4e2a\u751f\u6210\u4efb\u52a1\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u8bba\u53ef\u4ee5\u6269\u5c55\u5230\u4efb\u610f\u96be\u5ea6\uff0c\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7684\u6210\u529f\u7387\u4ece\u6700\u5bb9\u6613\u7684\u4efb\u52a1\u768455%\u4e0b\u964d\u5230\u6700\u56f0\u96be\u4efb\u52a1\u76840%\u3002", "conclusion": "Breakpoint\u80fd\u591f\u81ea\u52a8\u751f\u6210\u6311\u6218\u6027\u7684\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\uff0c\u5e76\u6709\u6548\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u4efb\u52a1\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2506.00239", "pdf": "https://arxiv.org/pdf/2506.00239", "abs": "https://arxiv.org/abs/2506.00239", "authors": ["Dewei Feng", "Carol Li", "Wei Dai", "Paul Pu Liang"], "title": "SMELLNET: A Large-scale Dataset for Real-world Smell Recognition", "categories": ["cs.AI"], "comment": "22 pages, 13 figures", "summary": "The ability of AI to sense and identify various substances based on their\nsmell alone can have profound impacts on allergen detection (e.g., smelling\ngluten or peanuts in a cake), monitoring the manufacturing process, and sensing\nhormones that indicate emotional states, stress levels, and diseases. Despite\nthese broad impacts, there are virtually no large scale benchmarks, and\ntherefore little progress, for training and evaluating AI systems' ability to\nsmell in the real world. In this paper, we use portable gas and chemical\nsensors to create SmellNet, the first large-scale database that digitizes a\ndiverse range of smells in the natural world. SmellNet contains about 180,000\ntime steps of 50 substances (spanning nuts, spices, herbs, fruits, and\nvegetables) with 50 hours of data. Using SmellNet, we train AI models for\nreal-time classification of substances based on their smell alone. Our best\nmethods leverage sequence models, contrastive learning to integrate\nhigh-resolution Gas Chromatography-Mass Spectrometry molecular data, and a new\ntemporal difference method that identifies sharp changes in sensor readings.\nOur best models achieve up to 65.35% accuracy on pre-recorded data, and\ngeneralize to real-world conditions with 10.71% accuracy on nuts and 25.38% on\nspices in the challenging 50-way online classification task. Despite these\npromising results, SmellNet highlights many technical challenges in building AI\nfor smell, including richer feature learning, on-edge smell models, and\nrobustness to environmental changes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSmellNet\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u8bad\u7ec3AI\u4ee5\u57fa\u4e8e\u55c5\u89c9\u8bc6\u522b\u7269\u8d28\uff0c\u53d6\u5f97\u4e86\u4e00\u5b9a\u7684\u51c6\u786e\u7387\uff0c\u4f46\u4ecd\u9762\u4e34\u8bb8\u591a\u6280\u672f\u6311\u6218\u3002", "motivation": "\u5927\u89c4\u6a21\u7684\u57fa\u51c6\u6d4b\u8bd5\u51e0\u4e4e\u4e0d\u5b58\u5728\uff0c\u56e0\u6b64AI\u7cfb\u7edf\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u8fdb\u884c\u55c5\u89c9\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u8fdb\u5c55\u5f88\u5c11\u3002", "method": "\u4f7f\u7528\u4fbf\u643a\u5f0f\u6c14\u4f53\u548c\u5316\u5b66\u4f20\u611f\u5668\u521b\u5efa\u4e86SmellNet\uff0c\u901a\u8fc7\u5e8f\u5217\u6a21\u578b\u3001\u5bf9\u6bd4\u5b66\u4e60\u548c\u65b0\u7684\u65f6\u95f4\u5dee\u65b9\u6cd5\u8bad\u7ec3AI\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u57fa\u4e8e\u55c5\u89c9\u7684\u7269\u8d28\u5206\u7c7b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u9884\u5f55\u6570\u636e\u4e0a\u5b9e\u73b065.35%\u7684\u51c6\u786e\u7387\uff0c\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\uff0c\u5728\u575a\u679c\u548c\u9999\u6599\u768450\u79cd\u5728\u7ebf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5206\u522b\u5b9e\u73b0\u4e8610.71%\u548c25.38%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u5c3d\u7ba1\u53d6\u5f97\u4e86\u4e00\u4e9b\u6210\u679c\uff0c\u8be5\u7814\u7a76\u8868\u660e\u6784\u5efa\u7528\u4e8e\u55c5\u89c9\u7684AI\u4ecd\u5b58\u5728\u8bb8\u591a\u6280\u672f\u6311\u6218\uff0c\u5305\u62ec\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u5b66\u4e60\u3001\u8fb9\u7f18\u55c5\u89c9\u6a21\u578b\u4ee5\u53ca\u5bf9\u73af\u5883\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.00982", "pdf": "https://arxiv.org/pdf/2506.00982", "abs": "https://arxiv.org/abs/2506.00982", "authors": ["Keshawn Smith", "Zhili Zhang", "H M Sabbir Ahmad", "Ehsan Sabouni", "Maniak Mondal", "Song Han", "Wenchao Li", "Fei Miao"], "title": "Robust and Safe Multi-Agent Reinforcement Learning Framework with Communication for Autonomous Vehicles", "categories": ["cs.RO", "cs.MA"], "comment": "19 pages, 9 Figures", "summary": "Deep multi-agent reinforcement learning (MARL) has been demonstrated\neffectively in simulations for many multi-robot problems. For autonomous\nvehicles, the development of vehicle-to-vehicle (V2V) communication\ntechnologies provide opportunities to further enhance safety of the system.\nHowever, zero-shot transfer of simulator-trained MARL policies to hardware\ndynamic systems remains challenging, and how to leverage communication and\nshared information for MARL has limited demonstrations on hardware. This\nproblem is challenged by discrepancies between simulated and physical states,\nsystem state and model uncertainties, practical shared information design, and\nthe need for safety guarantees in both simulation and hardware. This paper\nintroduces RSR-RSMARL, a novel Robust and Safe MARL framework that supports\nReal-Sim-Real (RSR) policy adaptation for multi-agent systems with\ncommunication among agents, with both simulation and hardware demonstrations.\nRSR-RSMARL leverages state (includes shared state information among agents) and\naction representations considering real system complexities for MARL\nformulation. The MARL policy is trained with robust MARL algorithm to enable\nzero-shot transfer to hardware considering the sim-to-real gap. A safety shield\nmodule using Control Barrier Functions (CBFs) provides safety guarantee for\neach individual agent. Experiment results on F1/10th-scale autonomous vehicles\nwith V2V communication demonstrate the ability of RSR-RSMARL framework to\nenhance driving safety and coordination across multiple configurations. These\nfindings emphasize the importance of jointly designing robust policy\nrepresentations and modular safety architectures to enable scalable,\ngeneralizable RSR transfer in multi-agent autonomy.", "AI": {"tldr": "\u5f15\u5165\u4e86RSR-RSMARL\u6846\u67b6\uff0c\u901a\u8fc7\u4fc3\u8fdb\u884c\u4e3a\u9002\u5e94\u548c\u901a\u4fe1\u6765\u63d0\u5347\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u6a21\u62df\u548c\u786c\u4ef6\u4e2d\u7684\u5b89\u5168\u6027\u548c\u534f\u8c03\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u6df1\u5ea6\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u88ab\u8bc1\u660e\u5728\u591a\u673a\u5668\u4eba\u95ee\u9898\u6a21\u62df\u4e2d\u6548\u679c\u663e\u8457\uff0c\u800c\u8f66\u5bf9\u8f66\u901a\u4fe1\u6280\u672f\u7684\u53d1\u5c55\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002\u7136\u800c\uff0c\u5c06\u6a21\u62df\u5668\u8bad\u7ec3\u7684MARL\u7b56\u7565\u96f6\u6837\u672c\u8f6c\u79fb\u81f3\u786c\u4ef6\u52a8\u6001\u7cfb\u7edf\u4ecd\u5177\u6311\u6218\u6027\uff0c\u5e76\u4e14\u5982\u4f55\u5229\u7528\u901a\u4fe1\u548c\u5171\u4eab\u4fe1\u606f\u7684\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u5728\u786c\u4ef6\u4e0a\u5e94\u7528\u6709\u9650\u3002\u672c\u8bba\u6587\u63d0\u51fa\u65b0\u7684\u65b9\u6cd5\u4ee5\u89e3\u51b3\u6a21\u62df\u4e0e\u7269\u7406\u72b6\u6001\u7684\u5dee\u5f02\u3001\u7cfb\u7edf\u72b6\u6001\u548c\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u5b9e\u9645\u5171\u4eab\u4fe1\u606f\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u5728\u6a21\u62df\u548c\u786c\u4ef6\u4e2d\u9700\u8981\u7684\u5b89\u5168\u4fdd\u8bc1\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u548c\u5b89\u5168\u7684MARL\u6846\u67b6RSR-RSMARL\uff0c\u8be5\u6846\u67b6\u652f\u6301\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u901a\u8fc7\u901a\u4fe1\u8fdb\u884cReal-Sim-Real\uff08RSR\uff09\u7b56\u7565\u9002\u5e94\uff0c\u5305\u62ec\u6a21\u62df\u548c\u786c\u4ef6\u6f14\u793a\u3002\u6846\u67b6\u7ed3\u5408\u4e86\u72b6\u6001\uff08\u5305\u62ec\u4ee3\u7406\u95f4\u5171\u4eab\u7684\u72b6\u6001\u4fe1\u606f\uff09\u548c\u52a8\u4f5c\u8868\u793a\uff0c\u4f7f\u7528\u9c81\u68d2\u7684MARL\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u5b9e\u73b0\u786c\u4ef6\u7684\u96f6\u6837\u672c\u4f20\u8f93\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5177\u6709V2V\u901a\u4fe1\u76841/10\u523b\u5ea6\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4e0a\uff0cRSR-RSMARL\u6846\u67b6\u80fd\u591f\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u63d0\u5347\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u534f\u8c03\u6027\u3002", "conclusion": "RSR-RSMARL\u6846\u67b6\u53ef\u4ee5\u589e\u5f3a\u9a7e\u9a76\u5b89\u5168\u6027\u548c\u591a\u4ee3\u7406\u534f\u8c03\u80fd\u529b\uff0c\u5f3a\u8c03\u4e86\u8bbe\u8ba1\u7a33\u5065\u7b56\u7565\u8868\u793a\u548c\u6a21\u5757\u5316\u5b89\u5168\u67b6\u6784\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u901a\u7528\u7684\u591a\u4ee3\u7406\u81ea\u6cbbRSR\u4f20\u8f93\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.00077", "pdf": "https://arxiv.org/pdf/2506.00077", "abs": "https://arxiv.org/abs/2506.00077", "authors": ["Edward Wang", "Tianyu Wang", "Avanti Athreya", "Vince Lyzinski", "Carey E. Priebe"], "title": "Gaussian mixture models as a proxy for interacting language models", "categories": ["cs.CL", "cs.LG", "stat.ML", "62R07"], "comment": null, "summary": "Large language models (LLMs) are a powerful tool with the ability to match\nhuman capabilities and behavior in many settings. Retrieval-augmented\ngeneration (RAG) further allows LLMs to generate diverse output depending on\nthe contents of their RAG database. This motivates their use in the social\nsciences to study human behavior between individuals when large-scale\nexperiments are infeasible. However, LLMs depend on complex, computationally\nexpensive algorithms. In this paper, we introduce interacting Gaussian mixture\nmodels (GMMs) as an alternative to similar frameworks using LLMs. We compare a\nsimplified model of GMMs to select experimental simulations of LLMs whose\nupdating and response depend on feedback from other LLMs. We find that\ninteracting GMMs capture important features of the dynamics in interacting\nLLMs, and we investigate key similarities and differences between interacting\nLLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture\nmodels, potential modifications, and future research directions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e92\u52a8\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMMs\uff09\u4f5c\u4e3a\u590d\u6742LLMs\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u6210\u529f\u6355\u6349\u5230LLMs\u7684\u52a8\u6001\u7279\u5f81\uff0c\u5206\u6790\u4e86GMMs\u4e0eLLMs\u7684\u5f02\u540c\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u7684LLMs\u5728\u8bb8\u591a\u65b9\u9762\u5c55\u793a\u51fa\u4e0e\u4eba\u7c7b\u80fd\u529b\u76f8\u5339\u914d\u7684\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u7528\u4e8e\u7814\u7a76\u5927\u578b\u5b9e\u9a8c\u4e0d\u53ef\u884c\u65f6\u7684\u4eba\u7c7b\u884c\u4e3a\u3002\u4f46\u7531\u4e8eLLMs\u4f9d\u8d56\u590d\u6742\u4e14\u8017\u8d39\u8ba1\u7b97\u7684\u7b97\u6cd5\uff0c\u56e0\u800c\u63d0\u51fa\u4e92\u52a8GMMs\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e92\u52a8\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMMs\uff09\u5e76\u5c06\u5176\u4e0eLLMs\u7684\u5b9e\u9a8c\u6a21\u62df\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u5c24\u5176\u662f\u8fd9\u4e9b\u6a21\u578b\u5728\u63a5\u6536\u5230\u5176\u4ed6LLMs\u53cd\u9988\u65f6\u7684\u66f4\u65b0\u548c\u54cd\u5e94\u3002", "result": "\u4e92\u52a8\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u80fd\u591f\u6210\u529f\u6355\u6349\u4e92\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u91cd\u8981\u52a8\u6001\u7279\u5f81\uff0c\u5e76\u63ed\u793a\u4e86LLMs\u548cGMMs\u4e4b\u95f4\u7684\u5173\u952e\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u3002", "conclusion": "\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMMs\uff09\u53ef\u6355\u6349\u5230\u4e92\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u52a8\u6001\u7279\u5f81\uff0c\u5e76\u80fd\u7528\u4e8e\u66ff\u4ee3\u590d\u6742\u800c\u8017\u8d39\u8ba1\u7b97\u8d44\u6e90\u7684LLMs\u6846\u67b6\u3002\u8bba\u6587\u8ba8\u8bba\u4e86GMMs\u7684\u4f18\u52bf\u3001\u53ef\u80fd\u7684\u4fee\u6539\u4ee5\u53ca\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.00175", "pdf": "https://arxiv.org/pdf/2506.00175", "abs": "https://arxiv.org/abs/2506.00175", "authors": ["Shichang Zhang", "Hongzhe Du", "Karim Saraipour", "Jiaqi W. Ma", "Himabindu Lakkaraju"], "title": "Accountability Attribution: Tracing Model Behavior to Training Processes", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern AI development pipelines often involve multiple stages-pretraining,\nfine-tuning rounds, and subsequent adaptation or alignment-with numerous model\nupdate steps within each stage. This raises a critical question of\naccountability: when a deployed model succeeds or fails, which stage is\nresponsible, and to what extent? We pose the problem of accountability\nattribution, which aims to trace model behavior back to specific stages of the\ntraining process. To address this, we propose a general framework that answers\ncounterfactual questions about stage effects: how would the model behavior have\nchanged if the updates from a training stage had not been executed?. Within\nthis framework, we introduce estimators based on first-order approximations\nthat efficiently quantify the stage effects without retraining. Our estimators\naccount for both the training data and key aspects of optimization dynamics,\nincluding learning rate schedules, momentum, and weight decay. Empirically, we\ndemonstrate that our approach identifies training stages accountable for\nspecific behaviors, offering a practical tool for model analysis and a step\ntoward more accountable AI development.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\u8ffd\u8e2a\u8bad\u7ec3\u9636\u6bb5\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u4f30\u8ba1\u5668\u91cf\u5316\u9636\u6bb5\u6548\u5e94\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u6a21\u578b\u90e8\u7f72\u540e\u6210\u529f\u6216\u5931\u8d25\uff0c\u5982\u4f55\u8ffd\u6eaf\u5230\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u9636\u6bb5\uff0c\u8fd9\u662f\u4e00\u4e2a\u95ee\u8d23\u95ee\u9898\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u8ffd\u6eaf\u6a21\u578b\u884c\u4e3a\u81f3\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5177\u4f53\u9636\u6bb5\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e00\u9636\u8fd1\u4f3c\u7684\u4f30\u8ba1\u5668\uff0c\u8be5\u4f30\u8ba1\u5668\u5728\u4e0d\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u91cf\u5316\u8bad\u7ec3\u9636\u6bb5\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u8bc6\u522b\u51fa\u5bfc\u81f4\u6a21\u578b\u51fa\u73b0\u5177\u4f53\u884c\u4e3a\u7684\u8d23\u4efb\u8bad\u7ec3\u9636\u6bb5\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u8bc6\u522b\u51fa\u5177\u4f53\u884c\u4e3a\u8d23\u4efb\u7684\u8bad\u7ec3\u9636\u6bb5\uff0c\u4e3a\u6a21\u578b\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\uff0c\u5e76\u63a8\u52a8\u4e86\u66f4\u8d1f\u8d23\u4efb\u7684AI\u53d1\u5c55\u3002"}}
{"id": "2506.00242", "pdf": "https://arxiv.org/pdf/2506.00242", "abs": "https://arxiv.org/abs/2506.00242", "authors": ["Shuai Feng", "Wei-Chuang Chan", "Srishti Chouhan", "Junior Francisco Garcia Ayala", "Srujananjali Medicherla", "Kyle Clark", "Mingwei Shi"], "title": "Whispers of Many Shores: Cultural Alignment through Collaborative Cultural Expertise", "categories": ["cs.AI", "cs.CL"], "comment": "14 main pages;8 page appendix", "summary": "The integration of large language models (LLMs) into global applications\nnecessitates effective cultural alignment for meaningful and\nculturally-sensitive interactions. Current LLMs often lack the nuanced\nunderstanding required for diverse cultural contexts, and adapting them\ntypically involves costly full fine-tuning. To address this, we introduce a\nnovel soft prompt fine-tuning framework that enables efficient and modular\ncultural alignment. Our method utilizes vectorized prompt tuning to dynamically\nroute queries to a committee of culturally specialized 'expert' LLM\nconfigurations, created by optimizing soft prompt embeddings without altering\nthe base model's parameters. Extensive experiments demonstrate that our\nframework significantly enhances cultural sensitivity and adaptability,\nimproving alignment scores from 0.208 to 0.820, offering a robust solution for\nculturally-aware LLM deployment. This research paves the way for subsequent\ninvestigations into enhanced cultural coverage and dynamic expert adaptation,\ncrucial for realizing autonomous AI with deeply nuanced understanding in a\nglobally interconnected world.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f6f\u63d0\u793a\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u63d0\u793a\u5d4c\u5165\u63d0\u5347LLM\u7684\u6587\u5316\u654f\u611f\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e0d\u6539\u53d8\u57fa\u7840\u6a21\u578b\uff0c\u63d0\u9ad8\u5951\u5408\u5ea6\u5f97\u5206\u5e76\u4fc3\u8fdb\u591a\u5143\u6587\u5316\u4ea4\u4e92\u3002", "motivation": "\u76ee\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u5143\u6587\u5316\u80cc\u666f\u4e0b\u5f80\u5f80\u7f3a\u4e4f\u7ec6\u81f4\u7684\u7406\u89e3\uff0c\u800c\u8c03\u6574\u5b83\u4eec\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5168\u9762\u5fae\u8c03\u3002", "method": "\u91c7\u7528\u77e2\u91cf\u5316\u63d0\u793a\u5fae\u8c03\uff0c\u901a\u8fc7\u4f18\u5316\u8f6f\u63d0\u793a\u5d4c\u5165\u6765\u52a8\u6001\u5730\u5c06\u67e5\u8be2\u8def\u7531\u5230\u4e00\u4e2a\u7531\u6587\u5316\u4e13\u4e1a'\u4e13\u5bb6' LLM\u914d\u7f6e\u7ec4\u6210\u7684\u59d4\u5458\u4f1a\uff0c\u800c\u4e0d\u6539\u53d8\u57fa\u7840\u6a21\u578b\u7684\u53c2\u6570\u3002", "result": "\u6846\u67b6\u5c06\u6587\u5316\u5951\u5408\u5ea6\u5f97\u5206\u4ece0.208\u63d0\u5347\u52300.820\u3002", "conclusion": "\u7814\u7a76\u6210\u529f\u5730\u8bc1\u660e\u4e86\u8f6f\u63d0\u793a\u5fae\u8c03\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u654f\u611f\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u6587\u5316\u610f\u8bc6\u7684LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u5173\u4e8e\u6587\u5316\u8986\u76d6\u548c\u52a8\u6001\u4e13\u5bb6\u9002\u5e94\u7684\u6df1\u5165\u7814\u7a76\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2506.01332", "pdf": "https://arxiv.org/pdf/2506.01332", "abs": "https://arxiv.org/abs/2506.01332", "authors": ["Min Choi", "Keonwoo Kim", "Sungwon Chae", "Sangyeob Baek"], "title": "An Empirical Study of Group Conformity in Multi-Agent Systems", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have enabled multi-agent\nsystems that simulate real-world interactions with near-human reasoning. While\nprevious studies have extensively examined biases related to protected\nattributes such as race, the emergence and propagation of biases on socially\ncontentious issues in multi-agent LLM interactions remain underexplored. This\nstudy explores how LLM agents shape public opinion through debates on five\ncontentious topics. By simulating over 2,500 debates, we analyze how initially\nneutral agents, assigned a centrist disposition, adopt specific stances over\ntime. Statistical analyses reveal significant group conformity mirroring human\nbehavior; LLM agents tend to align with numerically dominant groups or more\nintelligent agents, exerting a greater influence. These findings underscore the\ncrucial role of agent intelligence in shaping discourse and highlight the risks\nof bias amplification in online interactions. Our results emphasize the need\nfor policy measures that promote diversity and transparency in LLM-generated\ndiscussions to mitigate the risks of bias propagation within anonymous online\nenvironments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u4ee3\u7406\u5728\u8fa9\u8bba\u4e2d\u4f1a\u8d8b\u5411\u7fa4\u4f53\u4e00\u81f4\u6027\uff0c\u5f3a\u8c03\u4e86\u667a\u80fd\u6c34\u5e73\u5728\u8bdd\u8bed\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u53ca\u5728\u5728\u7ebf\u4ea4\u4e92\u4e2d\u653e\u5927\u7247\u9762\u504f\u89c1\u7684\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5173\u4e8e\u793e\u4f1a\u4e89\u8bae\u6027\u95ee\u9898\u7684\u8fa9\u8bba\u4e2d\u5982\u4f55\u5f71\u54cd\u516c\u4f17\u610f\u89c1\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u8d85\u8fc72500\u573a\u8fa9\u8bba\uff0c\u5206\u6790LLM\u4ee3\u7406\u4ece\u4e2d\u7acb\u7acb\u573a\u9010\u6e10\u91c7\u7eb3\u7279\u5b9a\u7acb\u573a\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u7edf\u8ba1\u5206\u6790\u663e\u793a\uff0cLLM\u4ee3\u7406\u5f80\u5f80\u4e0e\u6570\u91cf\u4f18\u52bf\u7fa4\u4f53\u6216\u66f4\u806a\u660e\u7684\u4ee3\u7406\u4fdd\u6301\u4e00\u81f4\uff0c\u53d1\u6325\u66f4\u5927\u5f71\u54cd\u529b\uff0c\u4ece\u800c\u53cd\u6620\u51fa\u4eba\u7c7b\u884c\u4e3a\u7684\u7fa4\u4f53\u4e00\u81f4\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u533f\u540d\u5728\u7ebf\u73af\u5883\u4e2d\uff0c\u4e3a\u9632\u6b62\u504f\u89c1\u4f20\u64ad\uff0c\u9700\u8981\u5236\u5b9a\u653f\u7b56\u63aa\u65bd\u4ee5\u4fc3\u8fdb\u591a\u6837\u6027\u548c\u900f\u660e\u5ea6\u3002"}}
{"id": "2506.00085", "pdf": "https://arxiv.org/pdf/2506.00085", "abs": "https://arxiv.org/abs/2506.00085", "authors": ["Vincent Siu", "Nicholas Crispino", "Zihao Yu", "Sam Pan", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "COSMIC: Generalized Refusal Direction Identification in LLM Activations", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, Accepted to ACL 2025 Findings", "summary": "Large Language Models (LLMs) encode behaviors such as refusal within their\nactivation space, yet identifying these behaviors remains a significant\nchallenge. Existing methods often rely on predefined refusal templates\ndetectable in output tokens or require manual analysis. We introduce\n\\textbf{COSMIC} (Cosine Similarity Metrics for Inversion of Concepts), an\nautomated framework for direction selection that identifies viable steering\ndirections and target layers using cosine similarity - entirely independent of\nmodel outputs. COSMIC achieves steering performance comparable to prior methods\nwithout requiring assumptions about a model's refusal behavior, such as the\npresence of specific refusal tokens. It reliably identifies refusal directions\nin adversarial settings and weakly aligned models, and is capable of steering\nsuch models toward safer behavior with minimal increase in false refusals,\ndemonstrating robustness across a wide range of alignment conditions.", "AI": {"tldr": "COSMIC\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u72ec\u7acb\u4e8e\u6a21\u578b\u8f93\u51fa\u6765\u8bc6\u522b\u548c\u64cd\u63a7\u884c\u4e3a\u65b9\u5411\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5e7f\u6cdb\u6761\u4ef6\u4e0b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bbe\u6a21\u677f\u6216\u9700\u8981\u4eba\u5de5\u5206\u6790\uff0c\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u884c\u4e3a\u3002", "method": "\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u8fdb\u884c\u65b9\u5411\u9009\u62e9\uff0c\u5e76\u81ea\u52a8\u8bc6\u522b\u53ef\u884c\u7684\u65b9\u5411\u548c\u76ee\u6807\u5c42\u3002", "result": "\u5728\u4e0d\u4f9d\u8d56\u7279\u5b9a\u62d2\u7edd\u884c\u4e3a\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0cCOSMIC\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u64cd\u63a7\u6027\u80fd\u3002", "conclusion": "COSMIC identifies rejection directions and steers models towards safer behavior without increasing false refusals, proving robust in various alignment conditions."}}
{"id": "2506.00181", "pdf": "https://arxiv.org/pdf/2506.00181", "abs": "https://arxiv.org/abs/2506.00181", "authors": ["Enea Monzio Compagnoni", "Rustem Islamov", "Antonio Orvieto", "Eduard Gorbunov"], "title": "On the Interaction of Noise, Compression Role, and Adaptivity under $(L_0, L_1)$-Smoothness: An SDE-based Approach", "categories": ["cs.LG", "stat.ML"], "comment": "This manuscript is a work in progress: We welcome comments", "summary": "Using stochastic differential equation (SDE) approximations, we study the\ndynamics of Distributed SGD, Distributed Compressed SGD, and Distributed\nSignSGD under $(L_0,L_1)$-smoothness and flexible noise assumptions. Our\nanalysis provides insights -- which we validate through simulation -- into the\nintricate interactions between batch noise, stochastic gradient compression,\nand adaptivity in this modern theoretical setup. For instance, we show that\n\\textit{adaptive} methods such as Distributed SignSGD can successfully converge\nunder standard assumptions on the learning rate scheduler, even under\nheavy-tailed noise. On the contrary, Distributed (Compressed) SGD with\npre-scheduled decaying learning rate fails to achieve convergence, unless such\na schedule also accounts for an inverse dependency on the gradient norm -- de\nfacto falling back into an adaptive method.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5206\u5e03\u5f0fSignSGD\u5728\u566a\u58f0\u60c5\u51b5\u4e0b\u80fd\u6709\u6548\u6536\u655b\uff0c\u800c\u5206\u5e03\u5f0fSGD\u9700\u8981\u9002\u5e94\u6027\u624d\u80fd\u5b9e\u73b0\u6536\u655b\u3002", "motivation": "\u901a\u8fc7\u5206\u6790\u6279\u91cf\u566a\u58f0\u3001\u968f\u673a\u68af\u5ea6\u538b\u7f29\u548c\u9002\u5e94\u6027\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u73b0\u4ee3\u7406\u8bba\u8bbe\u7f6e\u4e0b\u7684\u7b97\u6cd5\u52a8\u6001\u3002", "method": "\u4f7f\u7528\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u8fd1\u4f3c\u6280\u672f\u5206\u6790\u5206\u5e03\u5f0fSGD\u3001\u538b\u7f29\u5206\u5e03\u5f0fSGD\u548c\u5206\u5e03\u5f0fSignSGD\u7684\u52a8\u6001\u3002", "result": "\u9002\u5e94\u6027\u65b9\u6cd5\u5982\u5206\u5e03\u5f0fSignSGD\u80fd\u591f\u5728\u6807\u51c6\u5b66\u4e60\u7387\u8c03\u5ea6\u5047\u8bbe\u4e0b\u6210\u529f\u6536\u655b\uff0c\u800c\u5206\u5e03\u5f0f\u538b\u7f29SGD\u5219\u9700\u8981\u8003\u8651\u6e10\u8fdb\u5b66\u4e60\u7387\u4e0e\u68af\u5ea6\u8303\u6570\u7684\u53cd\u5411\u4f9d\u8d56\u3002", "conclusion": "\u6211\u4eec\u7814\u7a76\u4e86\u5404\u79cd\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u53d1\u73b0\u5206\u5e03\u5f0fSignSGD\u80fd\u591f\u6709\u6548\u6536\u655b\uff0c\u800c\u5206\u5e03\u5f0fSGD\u9700\u8981\u8003\u8651\u9002\u5e94\u6027\u624d\u80fd\u6536\u655b\u3002"}}
{"id": "2506.00249", "pdf": "https://arxiv.org/pdf/2506.00249", "abs": "https://arxiv.org/abs/2506.00249", "authors": ["Aniketh Garikaparthi", "Manasi Patwardhan", "Aditya Sanjiv Kanade", "Aman Hassan", "Lovekesh Vig", "Arman Cohan"], "title": "MIR: Methodology Inspiration Retrieval for Scientific Research Problems", "categories": ["cs.AI", "cs.CL"], "comment": "ACL 2025", "summary": "There has been a surge of interest in harnessing the reasoning capabilities\nof Large Language Models (LLMs) to accelerate scientific discovery. While\nexisting approaches rely on grounding the discovery process within the relevant\nliterature, effectiveness varies significantly with the quality and nature of\nthe retrieved literature. We address the challenge of retrieving prior work\nwhose concepts can inspire solutions for a given research problem, a task we\ndefine as Methodology Inspiration Retrieval (MIR). We construct a novel dataset\ntailored for training and evaluating retrievers on MIR, and establish\nbaselines. To address MIR, we build the Methodology Adjacency Graph (MAG);\ncapturing methodological lineage through citation relationships. We leverage\nMAG to embed an \"intuitive prior\" into dense retrievers for identifying\npatterns of methodological inspiration beyond superficial semantic similarity.\nThis achieves significant gains of +5.4 in Recall@3 and +7.8 in Mean Average\nPrecision (mAP) over strong baselines. Further, we adapt LLM-based re-ranking\nstrategies to MIR, yielding additional improvements of +4.5 in Recall@3 and\n+4.8 in mAP. Through extensive ablation studies and qualitative analyses, we\nexhibit the promise of MIR in enhancing automated scientific discovery and\noutline avenues for advancing inspiration-driven retrieval.", "AI": {"tldr": "This paper introduces Methodology Inspiration Retrieval (MIR) to aid scientific discovery by improving literature retrieval that can inspire research solutions, using a Methodology Adjacency Graph and LLM aiding in notable performance gains.", "motivation": "The motivation is to improve the process of retrieving literature that can inspire solutions for a given research problem, termed as Methodology Inspiration Retrieval (MIR), in order to harness the reasoning capabilities of Large Language Models (LLMs) for scientific discovery.", "method": "Methodology Adjacency Graph (MAG) is constructed to capture methodological lineage through citation relationships. Use of dense retrievers and MAG allows embedding of 'intuitive prior' to improve the retrieval process beyond semantic similarity. LLM-based re-ranking strategies are adapted for further improvement.", "result": "The proposed methods achieved significant improvements: gains of +5.4 in Recall@3 and +7.8 in Mean Average Precision (mAP) over strong baselines. The MIR process was further improved with +4.5 in Recall@3 and +4.8 in mAP by adapting LLM-based re-ranking strategies.", "conclusion": "MIR shows promise in enhancing automated scientific discovery, with potential for further advancement in inspiration-driven retrieval."}}
{"id": "2506.01404", "pdf": "https://arxiv.org/pdf/2506.01404", "abs": "https://arxiv.org/abs/2506.01404", "authors": ["Xue Xian Zheng", "Weihang Liu", "Xin Lou", "Stefan Vlaski", "Tareq Al-Naffouri"], "title": "Quantitative Error Feedback for Quantization Noise Reduction of Filtering over Graphs", "categories": ["cs.LG", "cs.MA", "cs.SY", "eess.SY"], "comment": "Journal Paper from ICASSP 10.1109/ICASSP49660.2025.10888821", "summary": "This paper introduces an innovative error feedback framework designed to\nmitigate quantization noise in distributed graph filtering, where\ncommunications are constrained to quantized messages. It comes from error\nspectrum shaping techniques from state-space digital filters, and therefore\nestablishes connections between quantized filtering processes over different\ndomains. In contrast to existing error compensation methods, our framework\nquantitatively feeds back the quantization noise for exact compensation. We\nexamine the framework under three key scenarios: (i) deterministic graph\nfiltering, (ii) graph filtering over random graphs, and (iii) graph filtering\nwith random node-asynchronous updates. Rigorous theoretical analysis\ndemonstrates that the proposed framework significantly reduces the effect of\nquantization noise, and we provide closed-form solutions for the optimal error\nfeedback coefficients. Moreover, this quantitative error feedback mechanism can\nbe seamlessly integrated into communication-efficient decentralized\noptimization frameworks, enabling lower error floors. Numerical experiments\nvalidate the theoretical results, consistently showing that our method\noutperforms conventional quantization strategies in terms of both accuracy and\nrobustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u8bef\u5dee\u53cd\u9988\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11\u5206\u5e03\u5f0f\u56fe\u6ee4\u6ce2\u4e2d\u7684\u91cf\u5316\u566a\u58f0\u3002\u901a\u8fc7\u5b9a\u91cf\u53cd\u9988\u5b9e\u73b0\u7cbe\u786e\u8865\u507f\uff0c\u5e76\u5728\u591a\u4e2a\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5206\u5e03\u5f0f\u56fe\u6ee4\u6ce2\u4e2d\u7531\u4e8e\u901a\u4fe1\u7ea6\u675f\u4e3a\u91cf\u5316\u6d88\u606f\u800c\u5f15\u5165\u7684\u91cf\u5316\u566a\u58f0\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u8bef\u5dee\u53cd\u9988\u6846\u67b6\uff0c\u65e8\u5728\u5927\u5e45\u51cf\u5c11\u91cf\u5316\u566a\u58f0\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u8bef\u5dee\u53cd\u9988\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u91cf\u53cd\u9988\u91cf\u5316\u566a\u58f0\u8fdb\u884c\u7cbe\u786e\u8865\u507f\uff0c\u5e76\u8fdb\u884c\u4e25\u683c\u7684\u7406\u8bba\u5206\u6790\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u6700\u4f73\u8bef\u5dee\u53cd\u9988\u7cfb\u6570\u7684\u95ed\u5f0f\u89e3\uff0c\u5e76\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u91cf\u5316\u566a\u58f0\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u91cf\u5316\u7b56\u7565\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5b9a\u91cf\u7684\u8bef\u5dee\u53cd\u9988\u673a\u5236\u53ef\u4ee5\u65e0\u7f1d\u6574\u5408\u5230\u901a\u4fe1\u9ad8\u6548\u7684\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u6846\u67b6\u4e2d\uff0c\u6709\u6548\u964d\u4f4e\u8bef\u5dee\u6c34\u5e73\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u663e\u793a\u51fa\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u91cf\u5316\u7b56\u7565\u3002"}}
{"id": "2506.00087", "pdf": "https://arxiv.org/pdf/2506.00087", "abs": "https://arxiv.org/abs/2506.00087", "authors": ["Peng Xie", "Xingyuan Liu", "Tsz Wai Chan", "Yequan Bie", "Yangqiu Song", "Yang Wang", "Hao Chen", "Kani Chen"], "title": "SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Code-switching (CS) is the alternating use of two or more languages within a\nconversation or utterance, often influenced by social context and speaker\nidentity. This linguistic phenomenon poses challenges for Automatic Speech\nRecognition (ASR) systems, which are typically designed for a single language\nand struggle to handle multilingual inputs. The growing global demand for\nmultilingual applications, including Code-Switching ASR (CSASR), Text-to-Speech\n(CSTTS), and Cross-Lingual Information Retrieval (CLIR), highlights the\ninadequacy of existing monolingual datasets.\n  Although some code-switching datasets exist, most are limited to bilingual\nmixing within homogeneous ethnic groups, leaving a critical need for a\nlarge-scale, diverse benchmark akin to ImageNet in computer vision.\n  To bridge this gap, we introduce \\textbf{LinguaMaster}, a multi-agent\ncollaboration framework specifically designed for efficient and scalable\nmultilingual data synthesis. Leveraging this framework, we curate\n\\textbf{SwitchLingua}, the first large-scale multilingual and multi-ethnic\ncode-switching dataset, including: (1) 420K CS textual samples across 12\nlanguages, and (2) over 80 hours of audio recordings from 174 speakers\nrepresenting 18 countries/regions and 63 racial/ethnic backgrounds, based on\nthe textual data. This dataset captures rich linguistic and cultural diversity,\noffering a foundational resource for advancing multilingual and multicultural\nresearch. Furthermore, to address the issue that existing ASR evaluation\nmetrics lack sensitivity to code-switching scenarios, we propose the\n\\textbf{Semantic-Aware Error Rate (SAER)}, a novel evaluation metric that\nincorporates semantic information, providing a more accurate and context-aware\nassessment of system performance.", "AI": {"tldr": "\u63d0\u51faLinguaMaster\u6846\u67b6\u548cSwitchLingua\u6570\u636e\u96c6\uff0c\u5e76\u53d1\u660eSAER\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u9762\u5bf9\u5168\u7403\u5bf9\u591a\u8bed\u8a00\u5e94\u7528\u7684\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\u4ee5\u53ca\u73b0\u6709\u5355\u8bed\u8a00\u6570\u636e\u96c6\u7684\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u56fe\u50cf\u9886\u57dfImageNet\u7684\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u7684\u57fa\u51c6\u3002", "method": "\u5f15\u5165LinguaMaster\u6846\u67b6\u8fdb\u884c\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u6570\u636e\u5408\u6210\uff0c\u5e76\u521b\u5efaSwitchLingua\u6570\u636e\u96c6\uff0c\u540c\u65f6\u63d0\u51faSAER\u4f5c\u4e3a\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u521b\u5efa\u4e86\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u548c\u591a\u6c11\u65cf\u4ee3\u7801\u8f6c\u6362\u6570\u636e\u96c6SwitchLingua\uff0c\u540c\u65f6\u63d0\u51fa\u4e86SAER\u4f5c\u4e3a\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u3002", "conclusion": "LinguaMaster\u548cSwitchLingua\u4e3a\u591a\u8bed\u8a00\u548c\u591a\u6c11\u65cf\u4ee3\u7801\u8f6c\u6362\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u57fa\u7840\u8d44\u6e90\uff0c\u4e14SAER\u53ef\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30ASR\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2506.00188", "pdf": "https://arxiv.org/pdf/2506.00188", "abs": "https://arxiv.org/abs/2506.00188", "authors": ["Md Mahmuddun Nabi Murad", "Yasin Yilmaz"], "title": "Cluster-Aware Causal Mixer for Online Anomaly Detection in Multivariate Time Series", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Early and accurate detection of anomalies in time series data is critical,\ngiven the significant risks associated with false or missed detections. While\nMLP-based mixer models have shown promise in time series analysis, they lack a\ncausality mechanism to preserve temporal dependencies inherent in the system.\nMoreover, real-world multivariate time series often contain numerous channels\nwith diverse inter-channel correlations. A single embedding mechanism for all\nchannels does not effectively capture these complex relationships. To address\nthese challenges, we propose a novel cluster-aware causal mixer to effectively\ndetect anomalies in multivariate time series. Our model groups channels into\nclusters based on their correlations, with each cluster processed through a\ndedicated embedding layer. In addition, we introduce a causal mixer in our\nmodel, which mixes the information while maintaining causality. Furthermore, we\npresent an anomaly detection framework that accumulates the anomaly evidence\nover time to prevent false positives due to nominal outliers. Our proposed\nmodel operates in an online fashion, making it suitable for real-time\ntime-series anomaly detection tasks. Experimental evaluations across six public\nbenchmark datasets demonstrate that our model consistently achieves superior F1\nscores.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u7fa4\u611f\u77e5\u56e0\u679c\u6df7\u5408\u6a21\u578b\uff0c\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5f02\u5e38\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u8bef\u62a5\u5e76\u83b7\u5f97\u66f4\u9ad8\u7684F1\u5206\u6570\u3002", "motivation": "\u73b0\u6709\u7684MLP-based\u6df7\u5408\u6a21\u578b\u7f3a\u4e4f\u4fdd\u7559\u65f6\u95f4\u4f9d\u8d56\u7684\u56e0\u679c\u673a\u5236\uff0c\u4e14\u4e00\u79cd\u5d4c\u5165\u673a\u5236\u96be\u4ee5\u6709\u6548\u6355\u83b7\u591a\u901a\u9053\u95f4\u590d\u6742\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u7fa4\u611f\u77e5\u7684\u56e0\u679c\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u57fa\u4e8e\u76f8\u5173\u6027\u5c06\u901a\u9053\u5206\u7ec4\u4e3a\u96c6\u7fa4\uff0c\u6bcf\u4e2a\u96c6\u7fa4\u7ecf\u8fc7\u4e13\u7528\u5d4c\u5165\u5c42\u5904\u7406\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u6df7\u5408\u5668\u6765\u7ef4\u6301\u56e0\u679c\u6027\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u59cb\u7ec8\u83b7\u5f97\u66f4\u9ad8\u7684F1\u8bc4\u5206\u3002", "conclusion": "\u7ed3\u5408\u56e0\u679c\u673a\u5236\u548c\u96c6\u7fa4\u611f\u77e5\u5d4c\u5165\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.00258", "pdf": "https://arxiv.org/pdf/2506.00258", "abs": "https://arxiv.org/abs/2506.00258", "authors": ["Qianqi Yan", "Hongquan Li", "Shan Jiang", "Yang Zhao", "Xinze Guan", "Ching-Chen Kuo", "Xin Eric Wang"], "title": "Hidden in Plain Sight: Probing Implicit Reasoning in Multimodal Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly deployed in\nopen-ended, real-world environments where inputs are messy, underspecified, and\nnot always trustworthy. Unlike curated benchmarks, these settings frequently\ninvolve instructions that refer to missing objects or contradictory facts, rely\non ambiguous references, or request infeasible actions. In such cases, success\nhinges not on task execution alone, but on a model's ability to detect when\nsomething is silently wrong. This paper presents a systematic analysis of how\ncurrent MLLMs handle such implicit reasoning scenarios: cases where the flaw is\nnot explicitly stated but must be inferred from context. Using a curated\ndiagnostic suite spanning four categories of real-world failure modes, we\nevaluate six MLLMs, including o3 and GPT-4o, and find that models frequently\nfail to surface hidden issues, even when they possess the necessary perceptual\nand reasoning skills. Explicit prompting reveals that the underlying\ncapabilities exist but are often suppressed in favor of user compliance. We\nfurther show that simple inference-time interventions, such as cautious persona\nprompting and, in particular, requiring a clarifying question, can dramatically\nrecover performance. Our findings highlight a persistent gap between reasoning\ncompetence and behavioral compliance in current MLLMs and suggest practical\nstrategies for making these models more trustworthy in underconstrained\nenvironments.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9690\u6027\u63a8\u7406\u573a\u666f\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u5e72\u9884\u53ef\u4ee5\u6539\u5584\u5176\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u5e94\u7528\u4e8e\u5f00\u653e\u6027\u3001\u771f\u5b9e\u4e16\u754c\u7684\u73af\u5883\u4e2d\uff0c\u5b83\u4eec\u9700\u8981\u5177\u5907\u8bc6\u522b\u7f3a\u5931\u5bf9\u8c61\u6216\u77db\u76fe\u4e8b\u5b9e\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u5b8c\u6210\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5176\u9690\u6027\u63a8\u7406\u80fd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f7f\u7528\u4e86\u5305\u542b\u56db\u7c7b\u73b0\u5b9e\u4e16\u754c\u6545\u969c\u6a21\u5f0f\u7684\u8bca\u65ad\u5957\u4ef6\u6765\u8bc4\u4f30\u516d\u6b3e\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u663e\u5f0f\u63d0\u793a\u548c\u63a8\u7406\u65f6\u5e72\u9884\u6765\u5206\u6790\u6a21\u578b\u7684\u9690\u6027\u63a8\u7406\u80fd\u529b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6a21\u578b\u5177\u5907\u5fc5\u8981\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u9690\u6027\u63a8\u7406\u573a\u666f\u4e2d\u5e38\u5e38\u65e0\u6cd5\u8bc6\u522b\u51fa\u9690\u85cf\u95ee\u9898\u3002\u901a\u8fc7\u7b80\u5355\u7684\u63a8\u7406\u65f6\u5e72\u9884\uff0c\u5982\u8c28\u614e\u8bbe\u5b9a\u89d2\u8272\u548c\u8981\u6c42\u6f84\u6e05\u95ee\u9898\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u7684\u8868\u73b0\u3002", "conclusion": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9690\u6027\u63a8\u7406\u573a\u666f\u5b58\u5728\u4e0d\u8db3\uff0c\u5373\u4f7f\u6a21\u578b\u5177\u5907\u5fc5\u8981\u7684\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4e5f\u5e38\u5e38\u65e0\u6cd5\u8bc6\u522b\u51fa\u9690\u85cf\u95ee\u9898\u3002\u7136\u800c\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u63a8\u7406\u65f6\u5e72\u9884\u53ef\u4ee5\u663e\u8457\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u589e\u5f3a\u5176\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2506.01927", "pdf": "https://arxiv.org/pdf/2506.01927", "abs": "https://arxiv.org/abs/2506.01927", "authors": ["Mel Krusniak", "Hang Xu", "Parker Palermo", "Forrest Laine"], "title": "Online Competitive Information Gathering for Partially Observable Trajectory Games", "categories": ["cs.GT", "cs.AI", "cs.MA", "cs.RO"], "comment": "Accepted at RSS 2025", "summary": "Game-theoretic agents must make plans that optimally gather information about\ntheir opponents. These problems are modeled by partially observable stochastic\ngames (POSGs), but planning in fully continuous POSGs is intractable without\nheavy offline computation or assumptions on the order of belief maintained by\neach player. We formulate a finite history/horizon refinement of POSGs which\nadmits competitive information gathering behavior in trajectory space, and\nthrough a series of approximations, we present an online method for computing\nrational trajectory plans in these games which leverages particle-based\nestimations of the joint state space and performs stochastic gradient play. We\nalso provide the necessary adjustments required to deploy this method on\nindividual agents. The method is tested in continuous pursuit-evasion and\nwarehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more\ncomplex environments with visual and physical obstacles), demonstrating\nevidence of active information gathering and outperforming passive competitors.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u5728\u90e8\u5206\u53ef\u89c2\u5bdf\u968f\u673a\u6e38\u620f\uff08POSG\uff09\u4e2d\u8fdb\u884c\u5728\u7ebf\u8f68\u8ff9\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7c92\u5b50\u4f30\u8ba1\u548c\u968f\u673a\u68af\u5ea6\u6e38\u620f\uff0c\u6210\u529f\u6d4b\u8bd5\u4e8e\u8ffd\u9010-\u9003\u907f\u548c\u4ed3\u5e93\u573a\u666f\uff0c\u5c55\u793a\u4e86\u4f18\u4e8e\u88ab\u52a8\u7ade\u4e89\u8005\u7684\u4fe1\u606f\u6536\u96c6\u80fd\u529b\u3002", "motivation": "\u535a\u5f08\u8bba\u4e2d\u7684\u667a\u80fd\u4f53\u5fc5\u987b\u5236\u5b9a\u8ba1\u5212\u4ee5\u4f18\u5316\u5176\u5bf9\u5bf9\u624b\u7684\u4fe1\u606f\u6536\u96c6\u3002\u8fd9\u4e9b\u95ee\u9898\u901a\u8fc7\u90e8\u5206\u53ef\u89c2\u5bdf\u968f\u673a\u6e38\u620f\uff08POSG\uff09\u5efa\u6a21\uff0c\u4f46\u5728\u6ca1\u6709\u5927\u91cf\u79bb\u7ebf\u8ba1\u7b97\u6216\u5bf9\u6bcf\u4e2a\u73a9\u5bb6\u7684\u4fe1\u5ff5\u987a\u5e8f\u505a\u51fa\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u5b8c\u5168\u8fde\u7eed\u7684POSG\u4e2d\u8fdb\u884c\u89c4\u5212\u662f\u4e0d\u53ef\u884c\u7684\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u9650\u5386\u53f2/\u89c6\u754c\u7ec6\u5316\u7684POSG\uff0c\u901a\u8fc7\u4e00\u7cfb\u5217\u8fd1\u4f3c\uff0c\u5448\u73b0\u4e86\u4e00\u79cd\u5728\u7ebf\u8ba1\u7b97\u5408\u7406\u8f68\u8ff9\u89c4\u5212\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u57fa\u4e8e\u7c92\u5b50\u7684\u8054\u5408\u72b6\u6001\u7a7a\u95f4\u4f30\u8ba1\u5e76\u6267\u884c\u968f\u673a\u68af\u5ea6\u6e38\u620f\u3002\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u5728\u4e2a\u4f53\u4ee3\u7406\u4e0a\u90e8\u7f72\u8fd9\u79cd\u65b9\u6cd5\u6240\u9700\u7684\u5fc5\u8981\u8c03\u6574\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8fde\u7eed\u8ffd\u9010-\u9003\u907f\u548c\u4ed3\u5e93\u53d6\u7269\u573a\u666f\uff08\u4ee5\u53ca\u6269\u5c55\u5230N > 2\u4e2a\u73a9\u5bb6\u548c\u66f4\u590d\u6742\u73af\u5883\u7684\u89c6\u89c9\u548c\u7269\u7406\u969c\u788d\uff09\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u7684\u8bc1\u636e\uff0c\u5e76\u4e14\u4f18\u4e8e\u88ab\u52a8\u7ade\u4e89\u8005\u3002", "conclusion": "\u901a\u8fc7\u5728\u8fde\u7eed\u8ffd\u9010-\u9003\u907f\u548c\u4ed3\u5e93\u53d6\u7269\u573a\u666f\u4e2d\u7684\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u7684\u8bc1\u636e\uff0c\u5e76\u4e14\u8868\u73b0\u4f18\u4e8e\u88ab\u52a8\u7ade\u4e89\u8005\u3002"}}
{"id": "2506.00088", "pdf": "https://arxiv.org/pdf/2506.00088", "abs": "https://arxiv.org/abs/2506.00088", "authors": ["Qing Li", "Jiahui Geng", "Zongxiong Chen", "Derui Zhu", "Yuxia Wang", "Congbo Ma", "Chenyang Lyu", "Fakhri Karray"], "title": "HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "In recent years, large language models (LLMs) have made remarkable\nadvancements, yet hallucination, where models produce inaccurate or non-factual\nstatements, remains a significant challenge for real-world deployment. Although\ncurrent classification-based methods, such as SAPLMA, are highly efficient in\nmitigating hallucinations, they struggle when non-factual information arises in\nthe early or mid-sequence of outputs, reducing their reliability. To address\nthese issues, we propose Hallucination Detection-Neural Differential Equations\n(HD-NDEs), a novel method that systematically assesses the truthfulness of\nstatements by capturing the full dynamics of LLMs within their latent space.\nOur approaches apply neural differential equations (Neural DEs) to model the\ndynamic system in the latent space of LLMs. Then, the sequence in the latent\nspace is mapped to the classification space for truth assessment. The extensive\nexperiments across five datasets and six widely used LLMs demonstrate the\neffectiveness of HD-NDEs, especially, achieving over 14% improvement in AUC-ROC\non the True-False dataset compared to state-of-the-art techniques.", "AI": {"tldr": "HD-NDEs use neural differential equations to improve hallucination detection in LLMs, achieving over 14% AUC-ROC improvement on the True-False dataset.", "motivation": "The motivation is to address the challenge of hallucination in large language models, especially when non-factual information occurs early or mid-sequence, where current methods like SAPLMA are less effective.", "method": "The proposed method, HD-NDEs, utilizes neural differential equations to model the dynamic system in the latent space of large language models, which are then mapped to classify truthfulness.", "result": "HD-NDEs prove to be highly effective in detecting hallucinations across various datasets and models, with significant improvements over current state-of-the-art methods.", "conclusion": "HD-NDEs significantly improve the detection of hallucination in large language models, particularly outperforming existing methods by over 14% in AUC-ROC on the True-False dataset."}}
{"id": "2506.00198", "pdf": "https://arxiv.org/pdf/2506.00198", "abs": "https://arxiv.org/abs/2506.00198", "authors": ["Srivathsan Badrinarayanan", "Rishikesh Magar", "Akshay Antony", "Radheesh Sharma Meda", "Amir Barati Farimani"], "title": "MOFGPT: Generative Design of Metal-Organic Frameworks using Language Models", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "comment": "21 pages, 3 figures (in main text, without references)", "summary": "The discovery of Metal-Organic Frameworks (MOFs) with application-specific\nproperties remains a central challenge in materials chemistry, owing to the\nimmense size and complexity of their structural design space. Conventional\ncomputational screening techniques such as molecular simulations and density\nfunctional theory (DFT), while accurate, are computationally prohibitive at\nscale. Machine learning offers an exciting alternative by leveraging\ndata-driven approaches to accelerate materials discovery. The complexity of\nMOFs, with their extended periodic structures and diverse topologies, creates\nboth opportunities and challenges for generative modeling approaches. To\naddress these challenges, we present a reinforcement learning-enhanced,\ntransformer-based framework for the de novo design of MOFs. Central to our\napproach is MOFid, a chemically-informed string representation encoding both\nconnectivity and topology, enabling scalable generative modeling. Our pipeline\ncomprises three components: (1) a generative GPT model trained on MOFid\nsequences, (2) MOFormer, a transformer-based property predictor, and (3) a\nreinforcement learning (RL) module that optimizes generated candidates via\nproperty-guided reward functions. By integrating property feedback into\nsequence generation, our method drives the model toward synthesizable,\ntopologically valid MOFs with desired functional attributes. This work\ndemonstrates the potential of large language models, when coupled with\nreinforcement learning, to accelerate inverse design in reticular chemistry and\nunlock new frontiers in computational MOF discovery.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u53d8\u538b\u5668\u7684\u6846\u67b6\u6765\u8bbe\u8ba1MOFs\uff0c\u5229\u7528MOFid\u8fdb\u884c\u53ef\u6269\u5c55\u7684\u751f\u6210\u5efa\u6a21\uff0c\u5b9e\u8df5\u8868\u660e\u8fd9\u79cd\u65b9\u5f0f\u80fd\u52a0\u901f\u9006\u5411\u8bbe\u8ba1\u5e76\u63a8\u52a8MOF\u5728\u8ba1\u7b97\u6750\u6599\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7531\u4e8eMOFs\u7ed3\u6784\u8bbe\u8ba1\u7a7a\u95f4\u7684\u5de8\u5927\u89c4\u6a21\u548c\u590d\u6742\u6027\uff0c\u627e\u5230\u5177\u6709\u7279\u5b9a\u5e94\u7528\u5c5e\u6027\u7684MOFs\u4e00\u76f4\u662f\u6750\u6599\u5316\u5b66\u4e2d\u7684\u6838\u5fc3\u6311\u6218\u3002\u4f20\u7edf\u7684\u8ba1\u7b97\u7b5b\u9009\u6280\u672f\u5982\u5206\u5b50\u6a21\u62df\u548c\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\uff08DFT\uff09\u867d\u7136\u51c6\u786e\uff0c\u4f46\u5728\u89c4\u6a21\u4e0a\u65e0\u6cd5\u8ba1\u7b97\u3002\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u632f\u594b\u4eba\u5fc3\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u5229\u7528\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u52a0\u901f\u6750\u6599\u53d1\u73b0\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u53d8\u538b\u5668\u6846\u67b6\uff0c\u7528\u4e8eMOFs\u7684\u5168\u65b0\u8bbe\u8ba1\u3002\u6838\u5fc3\u65b9\u6cd5\u662fMOFid\uff0c\u4e00\u79cd\u5316\u5b66\u4fe1\u606f\u5316\u7684\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u7f16\u7801\u4e86\u8fde\u63a5\u6027\u548c\u62d3\u6251\u7ed3\u6784\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u751f\u6210\u5efa\u6a21\u3002Pipeline\u5305\u62ec\u4e09\u4e2a\u7ec4\u4ef6\uff1a\uff081\uff09\u5728MOFid\u5e8f\u5217\u4e0a\u8bad\u7ec3\u7684\u751f\u6210\u6027GPT\u6a21\u578b\uff0c\uff082\uff09MOFormer\uff0c\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u6027\u8d28\u9884\u6d4b\u5668\uff0c\uff083\uff09\u4e00\u4e2a\u901a\u8fc7\u6027\u8d28\u5f15\u5bfc\u7684\u5956\u52b1\u51fd\u6570\u4f18\u5316\u751f\u6210\u5019\u9009\u7269\u7684\u5f3a\u5316\u5b66\u4e60\u6a21\u5757\u3002", "result": "\u901a\u8fc7\u5c06\u6027\u8d28\u53cd\u9988\u6574\u5408\u5230\u5e8f\u5217\u751f\u6210\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u63a8\u52a8\u6a21\u578b\u671d\u5411\u5408\u6210\u53ef\u884c\u4e14\u62d3\u6251\u7ed3\u6784\u6709\u6548\u7684MOFs\uff0c\u4e14\u5177\u6709\u6240\u9700\u7684\u529f\u80fd\u5c5e\u6027\u3002", "conclusion": "\u6211\u4eec\u901a\u8fc7\u6574\u5408\u6027\u8d28\u53cd\u9988\u5230\u5e8f\u5217\u751f\u6210\u4e2d\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u751f\u6210\u5177\u6709\u6240\u9700\u529f\u80fd\u5c5e\u6027\u7684\u5408\u6210\u53ef\u884c\u4e14\u62d3\u6251\u7ed3\u6784\u6709\u6548\u7684MOFs\u3002\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u52a0\u901f\u7f51\u72b6\u5316\u5b66\u4e2d\u7684\u9006\u5411\u8bbe\u8ba1\uff0c\u5e76\u5728\u8ba1\u7b97MOF\u53d1\u73b0\u4e2d\u5f00\u542f\u65b0\u7684\u524d\u6cbf\u3002"}}
{"id": "2506.00279", "pdf": "https://arxiv.org/pdf/2506.00279", "abs": "https://arxiv.org/abs/2506.00279", "authors": ["Boshra Khajehpiri", "Eric Granger", "Massimiliano de Zambotti", "Fiona C. Baker", "Mohamad Forouzanfar"], "title": "Sleep Brain and Cardiac Activity Predict Cognitive Flexibility and Conceptual Reasoning Using Deep Learning", "categories": ["cs.AI", "cs.LG"], "comment": "This work was accepted for publication in IEEE EMBC 2025", "summary": "Despite extensive research on the relationship between sleep and cognition,\nthe connection between sleep microstructure and human performance across\nspecific cognitive domains remains underexplored. This study investigates\nwhether deep learning models can predict executive functions, particularly\ncognitive adaptability and conceptual reasoning from physiological processes\nduring a night's sleep. To address this, we introduce CogPSGFormer, a\nmulti-scale convolutional-transformer model designed to process multi-modal\npolysomnographic data. This model integrates one-channel ECG and EEG signals\nalong with extracted features, including EEG power bands and heart rate\nvariability parameters, to capture complementary information across modalities.\nA thorough evaluation of the CogPSGFormer architecture was conducted to\noptimize the processing of extended sleep signals and identify the most\neffective configuration. The proposed framework was evaluated on 817\nindividuals from the STAGES dataset using cross-validation. The model achieved\n80.3\\% accuracy in classifying individuals into low vs. high cognitive\nperformance groups on unseen data based on Penn Conditional Exclusion Test\n(PCET) scores. These findings highlight the effectiveness of our multi-scale\nfeature extraction and multi-modal learning approach in leveraging\nsleep-derived signals for cognitive performance prediction. To facilitate\nreproducibility, our code is publicly accessible\n(https://github.com/boshrakh95/CogPSGFormer.git).", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7CogPSGFormer\u6a21\u578b\u5229\u7528\u7761\u7720\u671f\u95f4\u7684\u751f\u7406\u6570\u636e\u9884\u6d4b\u4e2a\u4f53\u7684\u8ba4\u77e5\u8868\u73b0\uff0c\u8fbe\u5230\u9ad8\u8fbe80.3%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22\u7761\u7720\u5fae\u89c2\u7ed3\u6784\u4e0e\u7279\u5b9a\u8ba4\u77e5\u9886\u57df\u4eba\u7c7b\u8868\u73b0\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8fd9\u4e00\u9886\u57df\u76ee\u524d\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u5f15\u5165CogPSGFormer\u591a\u5c3a\u5ea6\u5377\u79ef-Transformer\u6a21\u578b\u5904\u7406\u591a\u6a21\u6001\u591a\u5bfc\u7761\u7720\u76d1\u6d4b\u6570\u636e\uff0c\u5305\u62ec\u4e00\u901a\u9053ECG\u548cEEG\u4fe1\u53f7\u4ee5\u53caEEG\u529f\u7387\u6ce2\u6bb5\u548c\u5fc3\u7387\u53d8\u5f02\u6027\u53c2\u6570\uff0c\u4ee5\u6355\u6349\u8de8\u6a21\u6001\u7684\u4e92\u8865\u4fe1\u606f\u3002", "result": "\u5728817\u540d\u6765\u81eaSTAGES\u6570\u636e\u96c6\u7684\u4e2a\u4f53\u4e0a\u8fdb\u884c\u6846\u67b6\u8bc4\u4f30\uff0c\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u6a21\u578b\u5728\u672a\u89c1\u6570\u636e\u4e2d\u7684\u4e2a\u4f53\u8ba4\u77e5\u8868\u73b0\u5206\u7c7b\u4e0a\u53d6\u5f97\u4e8680.3%\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660eCogPSGFormer\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u591a\u6a21\u6001\u7761\u7720\u6570\u636e\u6709\u6548\u9884\u6d4b\u8ba4\u77e5\u8868\u73b0\uff0c\u7279\u522b\u662f\u8ba4\u77e5\u9002\u5e94\u6027\u548c\u6982\u5ff5\u63a8\u7406\u80fd\u529b\u7684\u9ad8\u4f4e\u3002"}}
{"id": "2506.00103", "pdf": "https://arxiv.org/pdf/2506.00103", "abs": "https://arxiv.org/abs/2506.00103", "authors": ["Xun Lu"], "title": "Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has enabled large\nlanguage models (LLMs) to achieve remarkable breakthroughs in reasoning tasks\nwith objective ground-truth answers, such as mathematics and code generation.\nHowever, a significant gap remains for non-verifiable tasks, like creative\nwriting and open-ended dialogue, where quality assessment is inherently\nsubjective and lacks definitive references. Existing approaches for these\ndomains often rely on scalar reward models trained with human preferences,\nwhich suffer from limited generalization and are prone to reward hacking, such\nas over-explanation and length bias. In this work, we propose a unified\nRLVR-based training paradigm that bridges the gap between non-verifiable tasks\nand verifiable rewards. We introduce a writing-principle-based pairwise\nGenerative Reward Model (GenRM) and a novel Bootstrapped Relative Policy\nOptimization (BRPO) algorithm. The pairwise writing GenRM leverages\nself-principled critique to transform subjective assessments into reliable,\nverifiable rewards, while BRPO enables dynamic, reference-free pairwise\ncomparison by leveraging a bootstrapped response as temporary reference from\nwithin group rollouts during RL training. Our approach empowers LLMs to develop\nrobust writing capabilities without supervised fine-tuning, as demonstrated by\nWriting-Zero, which shows consistent improvement and strong resistance to\nreward hacking compared to scalar reward baselines. Furthermore, our method\nachieves competitive results on both in-house and open-source writing\nbenchmarks. Our findings suggest the potential to unify rule-based,\nreference-based, and reference-free reward modeling under the RLVR framework,\nthus paving the way for a comprehensive and scalable RL training paradigm\napplicable across all language tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRLVR\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5199\u4f5c\u539f\u5219\u4e3a\u57fa\u7840\u7684\u751f\u6210\u5956\u52b1\u6a21\u578b\u548c\u81ea\u4e3e\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u975e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u4e8e\u975e\u53ef\u9a8c\u8bc1\u4efb\u52a1\uff08\u5982\u521b\u610f\u5199\u4f5c\u548c\u5f00\u653e\u5f0f\u5bf9\u8bdd\uff09\u7684\u8d28\u91cf\u8bc4\u4f30\u5177\u6709\u4e3b\u89c2\u6027\uff0c\u7f3a\u4e4f\u786e\u5b9a\u7684\u53c2\u8003\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u95ee\u9898\uff0c\u5982\u8fc7\u5ea6\u89e3\u91ca\u548c\u957f\u5ea6\u504f\u597d\u3002\u6211\u4eec\u65e8\u5728\u5f25\u5408\u975e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eRLVR\u7684\u7edf\u4e00\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u5199\u4f5c\u539f\u5219\u4e3a\u57fa\u7840\u7684\u6210\u5bf9\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08GenRM\uff09\u548c\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u4e3e\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08BRPO\uff09\u7b97\u6cd5\u6765\u5b9e\u73b0\u3002", "result": "\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u6807\u91cf\u5956\u52b1\u57fa\u7ebf\u76f8\u6bd4\uff0cWriting-Zero\u5728\u9c81\u68d2\u5199\u4f5c\u80fd\u529b\u4e0a\u8868\u73b0\u51fa\u6301\u7eed\u6539\u8fdb\u548c\u5bf9\u5956\u52b1\u9ed1\u5ba2\u653b\u51fb\u7684\u5f3a\u5927\u62b5\u6297\u529b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5185\u90e8\u548c\u5f00\u6e90\u5199\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u4ee5\u5728RLVR\u6846\u67b6\u4e0b\u7edf\u4e00\u57fa\u4e8e\u89c4\u5219\u3001\u57fa\u4e8e\u53c2\u8003\u548c\u65e0\u53c2\u8003\u7684\u5956\u52b1\u5efa\u6a21\uff0c\u4ece\u800c\u4e3a\u6240\u6709\u8bed\u8a00\u4efb\u52a1\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684RL\u8bad\u7ec3\u8303\u5f0f\u3002"}}
{"id": "2506.00205", "pdf": "https://arxiv.org/pdf/2506.00205", "abs": "https://arxiv.org/abs/2506.00205", "authors": ["Junze Deng", "Qinhang Wu", "Peizhong Ju", "Sen Lin", "Yingbin Liang", "Ness Shroff"], "title": "Unlocking the Power of Rehearsal in Continual Learning: A Theoretical Perspective", "categories": ["cs.LG"], "comment": "accepted to ICML 2025", "summary": "Rehearsal-based methods have shown superior performance in addressing\ncatastrophic forgetting in continual learning (CL) by storing and training on a\nsubset of past data alongside new data in current task. While such a concurrent\nrehearsal strategy is widely used, it remains unclear if this approach is\nalways optimal. Inspired by human learning, where sequentially revisiting tasks\nhelps mitigate forgetting, we explore whether sequential rehearsal can offer\ngreater benefits for CL compared to standard concurrent rehearsal. To address\nthis question, we conduct a theoretical analysis of rehearsal-based CL in\noverparameterized linear models, comparing two strategies: 1) Concurrent\nRehearsal, where past and new data are trained together, and 2) Sequential\nRehearsal, where new data is trained first, followed by revisiting past data\nsequentially. By explicitly characterizing forgetting and generalization error,\nwe show that sequential rehearsal performs better when tasks are less similar.\nThese insights further motivate a novel Hybrid Rehearsal method, which trains\nsimilar tasks concurrently and revisits dissimilar tasks sequentially. We\ncharacterize its forgetting and generalization performance, and our experiments\nwith deep neural networks further confirm that the hybrid approach outperforms\nstandard concurrent rehearsal. This work provides the first comprehensive\ntheoretical analysis of rehearsal-based CL.", "AI": {"tldr": "The study analyzes rehearsal strategies in continual learning, proposing a hybrid method that combines concurrent and sequential approaches for better performance and less forgetting, particularly with dissimilar tasks.", "motivation": "To explore whether sequential revisiting of tasks, akin to human learning patterns, can improve continual learning performance by mitigating catastrophic forgetting more effectively than concurrent rehearsal methods.", "method": "Conducted a theoretical analysis of rehearsal strategies in overparameterized linear models and introduced a Hybrid Rehearsal method that combines concurrent and sequential training approaches based on task similarity, validated through experiments with deep neural networks.", "result": "Characterized the forgetting and generalization error of different rehearsal strategies and demonstrated through experiments that the hybrid rehearsal method outperforms standard concurrent rehearsal, especially with dissimilar tasks.", "conclusion": "Sequential rehearsal performs better in rehearsal-based continual learning when tasks are less similar, and a hybrid method that combines concurrent and sequential strategies outperforms standard methods."}}
{"id": "2506.00309", "pdf": "https://arxiv.org/pdf/2506.00309", "abs": "https://arxiv.org/abs/2506.00309", "authors": ["Ruonan Wang", "Runxi Wang", "Yunwen Shen", "Chengfeng Wu", "Qinglin Zhou", "Rohitash Chandra"], "title": "Evaluation of LLMs for mathematical problem solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance on a range of\neducational tasks, but are still understudied for their potential to solve\nmathematical problems. In this study, we compare three prominent LLMs,\nincluding GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of\nvarying complexities (GSM8K, MATH500, and UNSW datasets). We take a\nfive-dimensional approach based on the Structured Chain-of-Thought (SCoT)\nframework to assess final answer correctness, step completeness, step validity,\nintermediate calculation accuracy, and problem comprehension. The results show\nthat GPT-4o is the most stable and consistent in performance across all the\ndatasets, but particularly it performs outstandingly in high-level questions of\nthe UNSW dataset. DeepSeek-V3 is competitively strong in well-structured\ndomains such as optimisation, but suffers from fluctuations in accuracy in\nstatistical inference tasks. Gemini-2.0 shows strong linguistic understanding\nand clarity in well-structured problems but performs poorly in multi-step\nreasoning and symbolic logic. Our error analysis reveals particular deficits in\neach model: GPT-4o is at times lacking in sufficient explanation or precision;\nDeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in\nmathematical reasoning in higher dimensions.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-4o\u603b\u4f53\u6700\u7a33\u5b9a\uff0cDeepSeek-V3\u548cGemini-2.0\u5728\u67d0\u4e9b\u9886\u57df\u6709\u7279\u957f\uff0c\u4f46\u5728\u5176\u4ed6\u65b9\u9762\u6709\u6240\u6b20\u7f3a\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u6bd4\u8f83GPT-4o\u3001DeepSeek-V3\u548cGemini-2.0\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u91c7\u7528\u57fa\u4e8e\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\uff08SCoT\uff09\u6846\u67b6\u7684\u4e94\u7ef4\u5ea6\u65b9\u6cd5\uff0c\u8bc4\u4f30LLMs\u5728\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u3001\u6b65\u9aa4\u5b8c\u6574\u6027\u3001\u6b65\u9aa4\u6709\u6548\u6027\u3001\u4e2d\u95f4\u8ba1\u7b97\u51c6\u786e\u6027\u548c\u95ee\u9898\u7406\u89e3\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cGPT-4o\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u6700\u7a33\u5b9a\uff0c\u7279\u522b\u662f\u5728UNSW\u6570\u636e\u96c6\u7684\u9ad8\u6c34\u5e73\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff1bDeepSeek-V3\u5728\u7ed3\u6784\u826f\u597d\u7684\u9886\u57df\u5982\u4f18\u5316\u4e2d\u5177\u7ade\u4e89\u529b\uff0c\u4f46\u5728\u7edf\u8ba1\u63a8\u7406\u4efb\u52a1\u4e2d\u51c6\u786e\u6027\u6ce2\u52a8\u8f83\u5927\uff1bGemini-2.0\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u548c\u9ad8\u7ea7\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "GPT-4o\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5b9a\uff0c\u5c24\u5176\u5728UNSW\u6570\u636e\u96c6\u7684\u9ad8\u96be\u5ea6\u95ee\u9898\u4e0a\u8868\u73b0\u7a81\u51fa\uff1bDeepSeek-V3\u5728\u4f18\u5316\u9886\u57df\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u7edf\u8ba1\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff1bGemini-2.0\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u548c\u7b26\u53f7\u903b\u8f91\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2506.00134", "pdf": "https://arxiv.org/pdf/2506.00134", "abs": "https://arxiv.org/abs/2506.00134", "authors": ["Fardin Ahsan Sakib", "Ziwei Zhu", "Karen Trister Grace", "Meliha Yetisgen", "Ozlem Uzuner"], "title": "Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Social determinants of health (SDOH) extraction from clinical text is\ncritical for downstream healthcare analytics. Although large language models\n(LLMs) have shown promise, they may rely on superficial cues leading to\nspurious predictions. Using the MIMIC portion of the SHAC (Social History\nAnnotation Corpus) dataset and focusing on drug status extraction as a case\nstudy, we demonstrate that mentions of alcohol or smoking can falsely induce\nmodels to predict current/past drug use where none is present, while also\nuncovering concerning gender disparities in model performance. We further\nevaluate mitigation strategies - such as prompt engineering and\nchain-of-thought reasoning - to reduce these false positives, providing\ninsights into enhancing LLM reliability in health domains.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u5728\u63d0\u53d6SDOH\u65f6\u7684\u9519\u8bef\u548c\u504f\u89c1\uff0c\u5e76\u8bc4\u4f30\u4e86\u51cf\u5c11\u8fd9\u4e9b\u9519\u8bef\u9884\u6d4b\u7684\u7b56\u7565\u3002", "motivation": "\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u6587\u672c\u4e2d\u63d0\u53d6\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u836f\u7269\u72b6\u6001\u7684\u63d0\u53d6\u3002", "method": "\u4f7f\u7528SHAC\u6570\u636e\u96c6\u4e2d\u7684MIMIC\u90e8\u5206\uff0c\u7814\u7a76\u836f\u7269\u4f7f\u7528\u72b6\u6001\u7684\u63d0\u53d6\u3002", "result": "\u53d1\u73b0\u4ec5\u4ec5\u63d0\u5230\u9152\u7cbe\u6216\u5438\u70df\u65f6\uff0c\u6a21\u578b\u53ef\u80fd\u9519\u8bef\u9884\u6d4b\u4e3a\u5f53\u524d/\u8fc7\u53bb\u7684\u836f\u7269\u4f7f\u7528\uff0c\u540c\u65f6\u63ed\u793a\u51fa\u6027\u522b\u4e0a\u6a21\u578b\u6027\u80fd\u7684\u4e0d\u5e73\u7b49\u3002", "conclusion": "\u901a\u8fc7\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728\u63d0\u53d6\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\uff08SDOH\uff09\u65f6\u53ef\u80fd\u53d7\u8868\u9762\u7ebf\u7d22\u7684\u8bef\u5bfc\uff0c\u4ece\u800c\u5bfc\u81f4\u9519\u8bef\u9884\u6d4b\u3002"}}
{"id": "2506.00209", "pdf": "https://arxiv.org/pdf/2506.00209", "abs": "https://arxiv.org/abs/2506.00209", "authors": ["Liwen Sun", "Hao-Ren Yao", "Gary Gao", "Ophir Frieder", "Chenyan Xiong"], "title": "Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Cancer screening, leading to early detection, saves lives. Unfortunately,\nexisting screening techniques require expensive and intrusive medical\nprocedures, not globally available, resulting in too many lost would-be-saved\nlives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation\nModels, a cancer pre-screening methodology that identifies high-risk patients\nfor further screening solely based on their historical medical records. With\nmillions of electronic healthcare records (EHR), we establish the scaling law\nof EHR foundation models pretrained on medical code sequences, pretrain\ncompute-optimal foundation models of up to 2.4 billion parameters, and finetune\nthem on clinician-curated cancer risk prediction cohorts. In our retrospective\nevaluation comprising of thirty thousand patients, CATCH-FM achieved strong\nefficacy (60% sensitivity) with low risk (99% specificity and Negative\nPredictive Value), outperforming feature-based tree models as well as general\nand medical large language models by large margins. Despite significant\ndemographic, healthcare system, and EHR coding differences, CATCH-FM achieves\nstate-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot\nleaderboard, outperforming EHR foundation models pretrained using on-site\npatient data. Our analysis demonstrates the robustness of CATCH-FM in various\npatient distributions, the benefits of operating in the ICD code space, and its\nability to capture non-trivial cancer risk factors. Our code will be\nopen-sourced.", "AI": {"tldr": "CATCH-FM is a new method for early cancer detection using EHR data, showing high efficacy and outperforming existing models. It's cost-effective, non-intrusive, and globally applicable, significantly improving early cancer risk prediction accuracy.", "motivation": "The motivation is to create a cost-effective, non-intrusive, and globally accessible cancer pre-screening tool due to the limitations of current screening methods that rely on expensive and invasive procedures, hence losing many lives that could have been saved with early detection.", "method": "CATCH-FM utilizes a cancer pre-screening methodology based on analyzing historical medical records of patients using large-scale electronic healthcare records (EHRs). It involves pretraining foundation models on medical code sequences and finetuning them on cancer risk prediction cohorts. The models boast up to 2.4 billion parameters and leverage pretrained compute-optimal foundation models to achieve predictions.", "result": "CATCH-FM achieved a 60% sensitivity rate and a 99% specificity rate in predicting cancer risks, outperforming existing feature-based tree models and large language models significantly. It provided state-of-the-art pancreatic cancer risk predictions and demonstrated robustness across demographic and healthcare variations.", "conclusion": "CATCH-FM demonstrates robust performance in predicting cancer risks using EHR data, achieving state-of-the-art results in pre-screening high-risk patients for further cancer screening processes with significant efficacy and specificity. The methodology can lead to significant life-saving potential by addressing limitations of current cancer screening methods."}}
{"id": "2506.00320", "pdf": "https://arxiv.org/pdf/2506.00320", "abs": "https://arxiv.org/abs/2506.00320", "authors": ["Xiao Yu", "Baolin Peng", "Ruize Xu", "Michel Galley", "Hao Cheng", "Suman Nath", "Jianfeng Gao", "Zhou Yu"], "title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent progress in reasoning with large language models (LLMs), such as\nDeepSeek-R1, demonstrates impressive capabilities in domains like mathematics\nand coding, by exhibiting complex cognitive behaviors such as verification,\ngoal decomposition, and self-reflection. However, it is unclear what behavior\nis effective and what behavior is missing for long-horizon AI agents tasks. In\nthis work, we propose Dyna-Think, a thinking framework that integrates planning\nwith an internal world model with reasoning and acting to enhance AI agent\nperformance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning\n(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with\nDyna-Think, DIT reconstructs the thinking process of R1 to focus on performing\nworld model simulation relevant to the proposed (and planned) action, and\ntrains the policy using this reconstructed data. To enhance Dyna-Think, DDT\nuses a two-stage training process to first improve the agent's world modeling\nability via objectives such as state prediction or critique generation, and\nthen improve the agent's action via policy training. We evaluate our methods on\nOSWorld, and demonstrate that Dyna-Think improves the agent's in-domain and\nout-of-domain performance, achieving similar best-of-n performance compared to\nR1 while generating 2x less tokens on average. Our extensive empirical studies\nreveal that 1) using critique generation for world model training is effective\nto improve policy performance; and 2) AI agents with better performance\ncorrelate with better world modeling abilities. We believe our results suggest\na promising research direction to integrate world model simulation into AI\nagents to enhance their reasoning, planning, and acting capabilities.", "AI": {"tldr": "Dyna-Think\u6846\u67b6\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u6a21\u62df\u63d0\u5347AI\u4ee3\u7406\u7684\u63a8\u7406\u548c\u884c\u52a8\u80fd\u529b\uff0c\u8868\u73b0\u4f18\u4e8eR1\uff0c\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982DeepSeek-R1\uff09\u5728\u67d0\u4e9b\u9886\u57df\u5c55\u793a\u4e86\u590d\u6742\u7684\u8ba4\u77e5\u884c\u4e3a\uff0c\u4f46\u5728\u957f\u89c6\u89d2\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u96c6\u6210\u89c4\u5212\u548c\u5185\u5728\u4e16\u754c\u6a21\u578b\u7684\u601d\u7ef4\u6846\u67b6\u63d0\u5347AI\u4ee3\u7406\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86Dyna-Think\u6846\u67b6\uff0c\u5e76\u901a\u8fc7Dyna-Think\u6a21\u4eff\u5b66\u4e60\uff08DIT\uff09\u548cDyna-Think\u52a8\u6001\u8bad\u7ec3\uff08DDT\uff09\u65b9\u6cd5\u5b9e\u73b0\u3002DIT\u91cd\u5efa\u601d\u7ef4\u8fc7\u7a0b\u4ee5\u8bad\u7ec3\u7b56\u7565\uff0cDDT\u5219\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\u63d0\u5347\u4ee3\u7406\u7684\u4e16\u754c\u5efa\u6a21\u548c\u884c\u52a8\u80fd\u529b\u3002", "result": "\u5728OSWorld\u7684\u8bc4\u4f30\u4e2d\uff0cDyna-Think\u5728\u751f\u6210\u7684tokens\u6570\u91cf\u51cf\u5c11\u4e00\u534a\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u4e0eR1\u76f8\u4f3c\u7684\u6700\u4f73\u6027\u80fd\uff0c\u5e76\u4e14\u6539\u8fdb\u4e86\u4ee3\u7406\u7684\u5728\u57df\u5185\u548c\u8de8\u57df\u8868\u73b0\u3002\u7814\u7a76\u663e\u793a\u4f7f\u7528\u6279\u5224\u751f\u6210\u7684\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u6709\u6548\u63d0\u5347\u4e86\u7b56\u7565\u6027\u80fd\u3002", "conclusion": "Dyna-Think\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u89c4\u5212\u3001\u63a8\u7406\u548c\u884c\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86AI\u4ee3\u7406\u7684\u5728\u57df\u5185\u548c\u8de8\u57df\u6027\u80fd\u3002\u6279\u5224\u6027\u751f\u6210\u80fd\u6709\u6548\u63d0\u9ad8\u7b56\u7565\u6027\u80fd\uff0c\u5e76\u4e0e\u4e16\u754c\u5efa\u6a21\u80fd\u529b\u6709\u6b63\u76f8\u5173\u6027\u3002"}}
{"id": "2506.00137", "pdf": "https://arxiv.org/pdf/2506.00137", "abs": "https://arxiv.org/abs/2506.00137", "authors": ["Alireza Salemi", "Hamed Zamani"], "title": "LaMP-QA: A Benchmark for Personalized Long-form Question Answering", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "Personalization is essential for question answering systems that are\nuser-centric. Despite its importance, personalization in answer generation has\nbeen relatively underexplored. This is mainly due to lack of resources for\ntraining and evaluating personalized question answering systems. We address\nthis gap by introducing LaMP-QA -- a benchmark designed for evaluating\npersonalized long-form answer generation. The benchmark covers questions from\nthree major categories: (1) Arts & Entertainment, (2) Lifestyle & Personal\nDevelopment, and (3) Society & Culture, encompassing over 45 subcategories in\ntotal. To assess the quality and potential impact of the LaMP-QA benchmark for\npersonalized question answering, we conduct comprehensive human and automatic\nevaluations, to compare multiple evaluation strategies for evaluating generated\npersonalized responses and measure their alignment with human preferences.\nFurthermore, we benchmark a number of non-personalized and personalized\napproaches based on open-source and proprietary large language models (LLMs).\nOur results show that incorporating the personalized context provided leads to\nperformance improvements of up to 39%. The benchmark is publicly released to\nsupport future research in this area.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa\u4e86LaMP-QA\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e2a\u6027\u5316\u957f\u6587\u672c\u56de\u7b54\u751f\u6210\uff0c\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\u8bc1\u660e\u4e2a\u6027\u5316\u80cc\u666f\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u652f\u6301\u5e7f\u6cdb\u7684\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u4e2a\u6027\u5316\u5728\u7528\u6237\u4e2d\u5fc3\u7684\u95ee\u9898\u56de\u7b54\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u56de\u7b54\u751f\u6210\u4e2d\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u8bad\u7ec3\u548c\u8bc4\u4f30\u8d44\u6e90\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86LaMP-QA\u57fa\u51c6\uff0c\u6db5\u76d6\u827a\u672f\u4e0e\u5a31\u4e50\u3001\u751f\u6d3b\u65b9\u5f0f\u4e0e\u4e2a\u4eba\u53d1\u5c55\u4ee5\u53ca\u793e\u4f1a\u4e0e\u6587\u5316\u4e09\u4e2a\u4e3b\u8981\u7c7b\u522b\u7684\u63d0\u95ee\u3002\u6211\u4eec\u8fdb\u884c\u4e86\u7efc\u5408\u7684\u4eba\u7c7b\u548c\u81ea\u52a8\u8bc4\u4f30\uff0c\u6bd4\u8f83\u591a\u79cd\u8bc4\u4f30\u7b56\u7565\u4ee5\u6d4b\u91cf\u4e2a\u6027\u5316\u56de\u590d\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u5ea6\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u6240\u63d0\u4f9b\u7684\u4e2a\u6027\u5316\u80cc\u666f\u53ef\u4ee5\u5c06\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe39%\uff0c\u57fa\u51c6\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u5f15\u5165\u7684LaMP-QA\u57fa\u51c6\u6709\u52a9\u4e8e\u8bc4\u4f30\u4e2a\u6027\u5316\u957f\u6587\u672c\u56de\u7b54\u751f\u6210\uff0c\u4ece\u800c\u5f25\u8865\u4e86\u4e2a\u6027\u5316\u95ee\u7b54\u7cfb\u7edf\u7814\u7a76\u4e2d\u7684\u8d44\u6e90\u4e0d\u8db3\u95ee\u9898\u3002\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\uff0c\u6211\u4eec\u8bc1\u660e\u4e2a\u6027\u5316\u80cc\u666f\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.00236", "pdf": "https://arxiv.org/pdf/2506.00236", "abs": "https://arxiv.org/abs/2506.00236", "authors": ["Babak Barazandeh"], "title": "Localized LoRA: A Structured Low-Rank Approximation for Efficient Fine-Tuning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, offer compact\nand effective alternatives to full model fine-tuning by introducing low-rank\nupdates to pretrained weights. However, most existing approaches rely on global\nlow-rank structures, which can overlook spatial patterns spread across the\nparameter space. In this work, we propose Localized LoRA, a generalized\nframework that models weight updates as a composition of low-rank matrices\napplied to structured blocks of the weight matrix. This formulation enables\ndense, localized updates throughout the parameter space-without increasing the\ntotal number of trainable parameters. We provide a formal comparison between\nglobal, diagonal-local, and fully localized low-rank approximations, and show\nthat our method consistently achieves lower approximation error under matched\nparameter budgets. Experiments on both synthetic and practical settings\ndemonstrate that Localized LoRA offers a more expressive and adaptable\nalternative to existing methods, enabling efficient fine-tuning with improved\nperformance.", "AI": {"tldr": "Localized LoRA\u901a\u8fc7\u5728\u53c2\u6570\u7a7a\u95f4\u5b9e\u73b0\u5c40\u90e8\u5316\u66f4\u65b0\uff0c\u63d0\u9ad8\u4e86\u5fae\u8c03\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u5168\u5c40\u4f4e\u79e9\u7ed3\u6784\uff0c\u5bb9\u6613\u5ffd\u89c6\u53c2\u6570\u7a7a\u95f4\u4e2d\u5206\u6563\u7684\u7a7a\u95f4\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86Localized LoRA\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u6743\u91cd\u66f4\u65b0\u5efa\u6a21\u4e3a\u5e94\u7528\u4e8e\u6743\u91cd\u77e9\u9635\u7ed3\u6784\u6027\u5757\u7684\u4e00\u7cfb\u5217\u4f4e\u79e9\u77e9\u9635\u4e4b\u7ec4\u5408\uff0c\u5b9e\u73b0\u66f4\u5bc6\u96c6\u4e14\u5c40\u90e8\u5316\u7684\u66f4\u65b0\u3002", "result": "\u901a\u8fc7\u5408\u6210\u548c\u5b9e\u9645\u573a\u666f\u5b9e\u9a8c\uff0cLocalized LoRA \u5728\u4e0d\u589e\u52a0\u53c2\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u9002\u5e94\u6027\u3002", "conclusion": "Localized LoRA \u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u52a0\u9002\u5e94\u6027\u5f3a\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u4e0d\u589e\u52a0\u53ef\u8bad\u7ec3\u53c2\u6570\u603b\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u5168\u53c2\u6570\u7a7a\u95f4\u7684\u5c40\u90e8\u5316\u66f4\u65b0\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5176\u5728\u5339\u914d\u7684\u53c2\u6570\u9884\u7b97\u4e0b\u53d6\u5f97\u4e86\u66f4\u4f4e\u7684\u8fd1\u4f3c\u8bef\u5dee\uff0c\u63d0\u5347\u4e86\u5fae\u8c03\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2506.00328", "pdf": "https://arxiv.org/pdf/2506.00328", "abs": "https://arxiv.org/abs/2506.00328", "authors": ["Kourosh Shahnazari", "Seyed Moein Ayyoubzadeh", "Mohammadali Keshtparvar"], "title": "BASIL: Best-Action Symbolic Interpretable Learning for Evolving Compact RL Policies", "categories": ["cs.AI"], "comment": null, "summary": "The quest for interpretable reinforcement learning is a grand challenge for\nthe deployment of autonomous decision-making systems in safety-critical\napplications. Modern deep reinforcement learning approaches, while powerful,\ntend to produce opaque policies that compromise verification, reduce\ntransparency, and impede human oversight. To address this, we introduce BASIL\n(Best-Action Symbolic Interpretable Learning), a systematic approach for\ngenerating symbolic, rule-based policies via online evolutionary search with\nquality-diversity (QD) optimization. BASIL represents policies as ordered lists\nof symbolic predicates over state variables, ensuring full interpretability and\ntractable policy complexity. By using a QD archive, the methodology in the\nproposed study encourages behavioral and structural diversity between\ntop-performing solutions, while a complexity-aware fitness encourages the\nsynthesis of compact representations. The evolutionary system supports the use\nof exact constraints for rule count and system adaptability for balancing\ntransparency with expressiveness. Empirical comparisons with three benchmark\ntasks CartPole-v1, MountainCar-v0, and Acrobot-v1 show that BASIL consistently\nsynthesizes interpretable controllers with compact representations comparable\nto deep reinforcement learning baselines. Herein, this article introduces a new\ninterpretable policy synthesis method that combines symbolic expressiveness,\nevolutionary diversity, and online learning through a unifying framework.", "AI": {"tldr": "\u5f15\u5165BASIL\uff0c\u4e00\u79cd\u5229\u7528\u8d28\u91cf\u591a\u6837\u6027\u4f18\u5316\u7684\u7b26\u53f7\u53ef\u89e3\u91ca\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ea7\u751f\u6613\u4e8e\u89e3\u91ca\u7684\u7d27\u51d1\u51b3\u7b56\u7b56\u7565\uff0c\u6027\u80fd\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u76f8\u5f53\u3002", "motivation": "\u73b0\u4ee3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u5f3a\u5927\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u4e0d\u900f\u660e\u7684\u7b56\u7565\uff0c\u5f71\u54cd\u9a8c\u8bc1\u900f\u660e\u5ea6\u548c\u4eba\u7c7b\u76d1\u7763\u3002\u9700\u8981\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u51b3\u7b56\u7b56\u7565\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86BASIL\uff0c\u4e00\u79cd\u901a\u8fc7\u5728\u7ebf\u8fdb\u5316\u641c\u7d22\u548c\u54c1\u8d28\u591a\u6837\u6027\u4f18\u5316\u751f\u6210\u7b26\u53f7\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\u7684\u7cfb\u7edf\u65b9\u6cd5\u3002", "result": "BASIL\u80fd\u591f\u6301\u7eed\u751f\u6210\u53ef\u89e3\u91ca\u63a7\u5236\u5668\uff0c\u5176\u7d27\u51d1\u8868\u73b0\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u76f8\u5f53\u3002", "conclusion": "BASIL\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u53ef\u89e3\u91ca\u7684\u7b26\u53f7\u89c4\u5219\u51b3\u7b56\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u8868\u73b0\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u76f8\u5f53\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u7b80\u6d01\u4ee3\u8868\u6027\u3002"}}
{"id": "2506.00145", "pdf": "https://arxiv.org/pdf/2506.00145", "abs": "https://arxiv.org/abs/2506.00145", "authors": ["Sujeet Kumar", "Pretam Ray", "Abhinay Beerukuri", "Shrey Kamoji", "Manoj Balaji Jagadeeshan", "Pawan Goyal"], "title": "Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Sanskrit, an ancient language with a rich linguistic heritage, presents\nunique challenges for automatic speech recognition (ASR) due to its phonemic\ncomplexity and the phonetic transformations that occur at word junctures,\nsimilar to the connected speech found in natural conversations. Due to these\ncomplexities, there has been limited exploration of ASR in Sanskrit,\nparticularly in the context of its poetic verses, which are characterized by\nintricate prosodic and rhythmic patterns. This gap in research raises the\nquestion: How can we develop an effective ASR system for Sanskrit, particularly\none that captures the nuanced features of its poetic form? In this study, we\nintroduce Vedavani, the first comprehensive ASR study focused on Sanskrit Vedic\npoetry. We present a 54-hour Sanskrit ASR dataset, consisting of 30,779\nlabelled audio samples from the Rig Veda and Atharva Veda. This dataset\ncaptures the precise prosodic and rhythmic features that define the language.\nWe also benchmark the dataset on various state-of-the-art multilingual speech\nmodels.$^{1}$ Experimentation revealed that IndicWhisper performed the best\namong the SOTA models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u4e13\u6ce8\u4e8e\u68b5\u6587\u5420\u9640\u8bd7\u6b4c\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u5927\u91cf\u7684\u6807\u8bb0\u97f3\u9891\u6570\u636e\u5e76\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0IndicWhisper\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5f00\u53d1\u4e00\u79cd\u6709\u6548\u7684\u68b5\u6587\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\uff0c\u5c24\u5176\u662f\u80fd\u591f\u6355\u6349\u5176\u8bd7\u6b4c\u5f62\u5f0f\u590d\u6742\u7279\u5f81\u7684\u7cfb\u7edf\u3002", "method": "\u4ecb\u7ecd\u4e86Vedavani\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u68b5\u6587\u5420\u9640\u8bd7\u6b4c\u7684\u7efc\u5408ASR\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a54\u5c0f\u65f6\u7684\u68b5\u6587ASR\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea\u300a\u68a8\u4ff1\u5420\u9640\u300b\u548c\u300a\u963f\u95fc\u5a46\u5420\u9640\u300b\u768430,779\u4e2a\u6807\u8bb0\u97f3\u9891\u6837\u672c\u3002\u5e76\u5728\u5404\u79cd\u6700\u65b0\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIndicWhisper\u5728\u591a\u4e2a\u6700\u65b0\u6280\u672f\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u7814\u7a76\u4e3a\u68b5\u6587\u7684ASR\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u5411\uff0c\u5c24\u5176\u662f\u5176\u8bd7\u6b4c\u5f62\u5f0f\u7684\u590d\u6742\u7279\u5f81\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u4ee5\u4f9b\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2506.00244", "pdf": "https://arxiv.org/pdf/2506.00244", "abs": "https://arxiv.org/abs/2506.00244", "authors": ["Pintu Kumar", "Nandyala Hemachandra"], "title": "DeGLIF for Label Noise Robust Node Classification using GNNs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Noisy labelled datasets are generally inexpensive compared to clean labelled\ndatasets, and the same is true for graph data. In this paper, we propose a\ndenoising technique DeGLIF: Denoising Graph Data using Leave-One-Out Influence\nFunction. DeGLIF uses a small set of clean data and the leave-one-out influence\nfunction to make label noise robust node-level prediction on graph data.\nLeave-one-out influence function approximates the change in the model\nparameters if a training point is removed from the training dataset. Recent\nadvances propose a way to calculate the leave-one-out influence function for\nGraph Neural Networks (GNNs). We extend that recent work to estimate the change\nin validation loss, if a training node is removed from the training dataset. We\nuse this estimate and a new theoretically motivated relabelling function to\ndenoise the training dataset. We propose two DeGLIF variants to identify noisy\nnodes. Both these variants do not require any information about the noise model\nor the noise level in the dataset; DeGLIF also does not estimate these\nquantities. For one of these variants, we prove that the noisy points detected\ncan indeed increase risk. We carry out detailed computational experiments on\ndifferent datasets to show the effectiveness of DeGLIF. It achieves better\naccuracy than other baseline algorithms", "AI": {"tldr": "\u63d0\u51faDeGLIF\uff0c\u5229\u7528\u7559\u4e00\u6cd5\u5f71\u54cd\u51fd\u6570\u63d0\u9ad8\u56fe\u6570\u636e\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u9ad8\u6548\u53bb\u566a\u3002", "motivation": "\u7531\u4e8e\u566a\u58f0\u6807\u8bb0\u6570\u636e\u96c6\u76f8\u6bd4\u5e72\u51c0\u6570\u636e\u96c6\u66f4\u4fbf\u5b9c\uff0c\u56fe\u6570\u636e\u4e5f\u7b26\u5408\u8fd9\u4e2a\u7279\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u53bb\u566a\u65b9\u6cd5\u6765\u63d0\u9ad8\u56fe\u6570\u636e\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u566a\u6280\u672fDeGLIF\uff0c\u5229\u7528\u8f83\u5c11\u7684\u5e72\u51c0\u6570\u636e\u548c\u7559\u4e00\u6cd5\u5f71\u54cd\u51fd\u6570\u6765\u8fdb\u884c\u6807\u7b7e\u566a\u58f0\u9c81\u68d2\u7684\u8282\u70b9\u7ea7\u522b\u9884\u6d4b\u3002", "result": "DeGLIF\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u8be5\u6280\u672f\u6bd4\u5176\u4ed6\u57fa\u7ebf\u7b97\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DeGLIF\u5728\u53bb\u566a\u56fe\u6570\u636e\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u566a\u58f0\u6a21\u578b\u7684\u4fe1\u606f\u6216\u4f30\u8ba1\u3002"}}
{"id": "2506.00398", "pdf": "https://arxiv.org/pdf/2506.00398", "abs": "https://arxiv.org/abs/2506.00398", "authors": ["Kordel K. France", "Rohith Peddi", "Nik Dennler", "Ovidiu Daescu"], "title": "Position: Olfaction Standardization is Essential for the Advancement of Embodied Artificial Intelligence", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Despite extraordinary progress in artificial intelligence (AI), modern\nsystems remain incomplete representations of human cognition. Vision, audition,\nand language have received disproportionate attention due to well-defined\nbenchmarks, standardized datasets, and consensus-driven scientific foundations.\nIn contrast, olfaction - a high-bandwidth, evolutionarily critical sense - has\nbeen largely overlooked. This omission presents a foundational gap in the\nconstruction of truly embodied and ethically aligned super-human intelligence.\nWe argue that the exclusion of olfactory perception from AI architectures is\nnot due to irrelevance but to structural challenges: unresolved scientific\ntheories of smell, heterogeneous sensor technologies, lack of standardized\nolfactory datasets, absence of AI-oriented benchmarks, and difficulty in\nevaluating sub-perceptual signal processing. These obstacles have hindered the\ndevelopment of machine olfaction despite its tight coupling with memory,\nemotion, and contextual reasoning in biological systems. In this position\npaper, we assert that meaningful progress toward general and embodied\nintelligence requires serious investment in olfactory research by the AI\ncommunity. We call for cross-disciplinary collaboration - spanning\nneuroscience, robotics, machine learning, and ethics - to formalize olfactory\nbenchmarks, develop multimodal datasets, and define the sensory capabilities\nnecessary for machines to understand, navigate, and act within human\nenvironments. Recognizing olfaction as a core modality is essential not only\nfor scientific completeness, but for building AI systems that are ethically\ngrounded in the full scope of the human experience.", "AI": {"tldr": "\u6587\u7ae0\u8ba4\u4e3a\u55c5\u89c9\u5728AI\u7cfb\u7edf\u4e2d\u88ab\u5ffd\u89c6\uff0c\u5e76\u4e3b\u5f20\u8de8\u5b66\u79d1\u5408\u4f5c\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5b9e\u73b0\u66f4\u5168\u9762\u548c\u5177\u4f26\u7406\u6027\u7684\u8d85\u7ea7\u4eba\u5de5\u667a\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u73b0\u4ee3\u7cfb\u7edf\u4ecd\u672a\u80fd\u5b8c\u5168\u4ee3\u8868\u4eba\u7c7b\u8ba4\u77e5\u3002\u89c6\u89c9\u3001\u542c\u89c9\u548c\u8bed\u8a00\u56e0\u660e\u786e\u7684\u57fa\u51c6\u548c\u6807\u51c6\u5316\u6570\u636e\u96c6\u800c\u53d7\u5230\u8fc7\u591a\u5173\u6ce8\uff0c\u800c\u55c5\u89c9\u4f5c\u4e3a\u4e00\u79cd\u9ad8\u5e26\u5bbd\u3001\u8fdb\u5316\u4e0a\u81f3\u5173\u91cd\u8981\u7684\u611f\u5b98\u88ab\u5ffd\u89c6\u3002", "method": "\u672c\u6587\u547c\u5401\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u56ca\u62ec\u795e\u7ecf\u79d1\u5b66\u3001\u673a\u5668\u4eba\u5b66\u3001\u673a\u5668\u5b66\u4e60\u548c\u4f26\u7406\u5b66\uff0c\u4ee5\u516c\u5f0f\u5316\u55c5\u89c9\u57fa\u51c6\u3001\u5f00\u53d1\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5e76\u5b9a\u4e49\u673a\u5668\u5728\u7406\u89e3\u3001\u5bfc\u822a\u548c\u64cd\u4f5c\u4eba\u7c7b\u73af\u5883\u4e2d\u6240\u9700\u7684\u611f\u5b98\u80fd\u529b\u3002", "result": "\u55c5\u89c9\u4e0e\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u8bb0\u5fc6\u3001\u60c5\u611f\u548c\u60c5\u5883\u63a8\u7406\u7d27\u5bc6\u5173\u8054\uff0c\u4f46\u7ed3\u6784\u6027\u6311\u6218\u963b\u788d\u4e86\u5176\u5728AI\u4e2d\u7684\u53d1\u5c55\u3002\u8fd9\u4e9b\u6311\u6218\u5305\u62ec\u672a\u89e3\u51b3\u7684\u55c5\u89c9\u79d1\u5b66\u7406\u8bba\u3001\u5f02\u8d28\u4f20\u611f\u6280\u672f\u3001\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u55c5\u89c9\u6570\u636e\u96c6\u3001\u7f3a\u5c11AI\u5bfc\u5411\u7684\u57fa\u51c6\uff0c\u4ee5\u53ca\u4e9a\u611f\u77e5\u4fe1\u53f7\u5904\u7406\u8bc4\u4ef7\u7684\u56f0\u96be\u3002", "conclusion": "\u8bc6\u522b\u55c5\u89c9\u4f5c\u4e3a\u6838\u5fc3\u6a21\u6001\u5e76\u4e0d\u4ec5\u4ec5\u662f\u4e3a\u79d1\u5b66\u5b8c\u6574\u6027\uff0c\u800c\u662f\u4e3a\u6784\u5efa\u5728\u5168\u9762\u4eba\u7c7b\u4f53\u9a8c\u4e2d\u6709\u9053\u5fb7\u57fa\u7840\u7684AI\u7cfb\u7edf\u6240\u5fc5\u9700\u7684\u3002"}}
{"id": "2506.00160", "pdf": "https://arxiv.org/pdf/2506.00160", "abs": "https://arxiv.org/abs/2506.00160", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "categories": ["cs.CL"], "comment": null, "summary": "The growing popularity of social deduction game systems for both business\napplications and AI research has greatly benefited from the rapid advancements\nin Large Language Models (LLMs), which now demonstrate stronger reasoning and\npersuasion capabilities. Especially with the raise of DeepSeek R1 and V3\nmodels, LLMs should enable a more engaging experience for human players in\nLLM-agent-based social deduction games like Werewolf. Previous works either\nfine-tuning, advanced prompting engineering, or additional experience pool to\nachieve engaging text-format Werewolf game experience. We propose a novel yet\nstraightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)\nmodels designed for enhanced compatibility with various LLM models, and\nimproved user engagement. We argue with ever enhancing LLM reasoning, extra\ncomponents will be unnecessary in the case of Werewolf.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57fa\u4e8eLLM\u548cTTS\u6a21\u578b\u7684\u72fc\u4eba\u6e38\u620f\u7cfb\u7edf\uff0c\u63d0\u9ad8\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u4e0e\u517c\u5bb9\u6027\uff0c\u65e0\u9700\u989d\u5916\u7ec4\u4ef6\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u8bf4\u670d\u80fd\u529b\u4e3a\u4eba\u7c7b\u73a9\u5bb6\u5728\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u793e\u4ea4\u63a8\u7406\u6e38\u620f\uff08\u5982\u72fc\u4eba\u6e38\u620f\uff09\u63d0\u4f9b\u66f4\u5177\u5438\u5f15\u529b\u7684\u4f53\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u7b80\u5355\u7684\u57fa\u4e8eLLM\u7684\u72fc\u4eba\u6e38\u620f\u7cfb\u7edf\uff0c\u4f7f\u7528\u8c03\u6574\u8fc7\u7684\u6587\u672c\u5230\u8bed\u97f3(TTS)\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u4e0e\u5404\u79cdLLM\u6a21\u578b\u7684\u517c\u5bb9\u6027\u53ca\u63d0\u9ad8\u7528\u6237\u53c2\u4e0e\u5ea6\u3002", "result": "\u63d0\u51fa\u7684\u6e38\u620f\u7cfb\u7edf\u80fd\u591f\u63d0\u9ad8\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5e76\u4e0e\u5404\u79cdLLM\u6a21\u578b\u5b9e\u73b0\u589e\u5f3a\u517c\u5bb9\u6027\u3002", "conclusion": "\u6211\u4eec\u8ba4\u4e3a\uff0c\u968f\u7740LLM\u63a8\u7406\u80fd\u529b\u7684\u4e0d\u65ad\u589e\u5f3a\uff0c\u5728\u72fc\u4eba\u6e38\u620f\u4e2d\u65e0\u9700\u989d\u5916\u7ec4\u4ef6\u3002"}}
{"id": "2506.00245", "pdf": "https://arxiv.org/pdf/2506.00245", "abs": "https://arxiv.org/abs/2506.00245", "authors": ["Dang Nguyen", "Ali Payani", "Baharan Mirzasoleiman"], "title": "Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity", "categories": ["cs.LG", "cs.CL"], "comment": "11 pages, 4 figures, 6 tables, link:\n  https://github.com/BigML-CS-UCLA/SNNE", "summary": "Hallucination in large language models (LLMs) can be detected by assessing\nthe uncertainty of model outputs, typically measured using entropy. Semantic\nentropy (SE) enhances traditional entropy estimation by quantifying uncertainty\nat the semantic cluster level. However, as modern LLMs generate longer\none-sentence responses, SE becomes less effective because it overlooks two\ncrucial factors: intra-cluster similarity (the spread within a cluster) and\ninter-cluster similarity (the distance between clusters). To address these\nlimitations, we propose a simple black-box uncertainty quantification method\ninspired by nearest neighbor estimates of entropy. Our approach can also be\neasily extended to white-box settings by incorporating token probabilities.\nAdditionally, we provide theoretical results showing that our method\ngeneralizes semantic entropy. Extensive empirical results demonstrate its\neffectiveness compared to semantic entropy across two recent LLMs (Phi3 and\nLlama3) and three common text generation tasks: question answering, text\nsummarization, and machine translation. Our code is available at\nhttps://github.com/BigML-CS-UCLA/SNNE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u71b5\u4f30\u8ba1\u65b9\u6cd5\uff0c\u80fd\u66f4\u597d\u5730\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u957f\u53e5\u65f6\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u7684\u8bed\u4e49\u71b5\u65b9\u6cd5\u5728\u5904\u7406\u73b0\u4ee3\u5927\u6a21\u578b\u751f\u6210\u7684\u957f\u53e5\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u5ffd\u7565\u4e86\u7c07\u5185\u76f8\u4f3c\u6027\u548c\u7c07\u95f4\u76f8\u4f3c\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u8fd1\u90bb\u71b5\u4f30\u8ba1\u601d\u60f3\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u4f7f\u7528\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u7ed3\u5408\u8bcd\u6982\u7387\u8f7b\u677e\u6269\u5c55\u5230\u767d\u76d2\u8bbe\u7f6e\u4e2d\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e24\u4e2a\u6700\u65b0\u7684\u5927\u8bed\u8a00\u6a21\u578bPhi3\u548cLlama3\u4ee5\u53ca\u4e09\u4e2a\u5e38\u89c1\u6587\u672c\u751f\u6210\u4efb\u52a1\uff08\u95ee\u7b54\u3001\u6587\u672c\u6458\u8981\u3001\u673a\u5668\u7ffb\u8bd1\uff09\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u6548\u679c\u4f18\u4e8e\u8bed\u4e49\u71b5\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u4f20\u7edf\u8bed\u4e49\u71b5\u66f4\u6709\u6548\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u5904\u7406\u957f\u53e5\u751f\u6210\u65f6\u7684\u8bed\u4e49\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002"}}
{"id": "2506.00417", "pdf": "https://arxiv.org/pdf/2506.00417", "abs": "https://arxiv.org/abs/2506.00417", "authors": ["Changyuan Zhao", "Ruichen Zhang", "Jiacheng Wang", "Gaosheng Zhao", "Dusit Niyato", "Geng Sun", "Shiwen Mao", "Dong In Kim"], "title": "World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks", "categories": ["cs.AI"], "comment": "7 pages, 4 figures", "summary": "World models are emerging as a transformative paradigm in artificial\nintelligence, enabling agents to construct internal representations of their\nenvironments for predictive reasoning, planning, and decision-making. By\nlearning latent dynamics, world models provide a sample-efficient framework\nthat is especially valuable in data-constrained or safety-critical scenarios.\nIn this paper, we present a comprehensive overview of world models,\nhighlighting their architecture, training paradigms, and applications across\nprediction, generation, planning, and causal reasoning. We compare and\ndistinguish world models from related concepts such as digital twins, the\nmetaverse, and foundation models, clarifying their unique role as embedded\ncognitive engines for autonomous agents. We further propose Wireless Dreamer, a\nnovel world model-based reinforcement learning framework tailored for wireless\nedge intelligence optimization, particularly in low-altitude wireless networks\n(LAWNs). Through a weather-aware UAV trajectory planning case study, we\ndemonstrate the effectiveness of our framework in improving learning efficiency\nand decision quality.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e16\u754c\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u65e0\u7ebf\u68a6\u60f3\u8005\u6846\u67b6\uff0c\u5c24\u5176\u5728\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u548c\u51b3\u7b56\u8d28\u91cf\u3002", "motivation": "\u4e16\u754c\u6a21\u578b\u4e3a\u6570\u636e\u53d7\u9650\u6216\u5b89\u5168\u5173\u952e\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u672c\u6587\u65e8\u5728\u5168\u9762\u6982\u8ff0\u8fd9\u4e00\u9886\u57df\uff0c\u5e76\u63d0\u51fa\u9002\u7528\u4e8e\u65e0\u7ebf\u8fb9\u7f18\u667a\u80fd\u4f18\u5316\u7684\u65b0\u6846\u67b6\u3002", "method": "\u5728\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u7684\u6c14\u5019\u611f\u77e5\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u6848\u4f8b\u4e2d\uff0c\u5c55\u793a\u4e86\u65e0\u7ebf\u68a6\u60f3\u8005\u6846\u67b6\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u8868\u660e\u65e0\u7ebf\u68a6\u60f3\u8005\u6846\u67b6\u5728\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u51b3\u7b56\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u4e16\u754c\u6a21\u578b\u7684\u67b6\u6784\u3001\u8bad\u7ec3\u8303\u5f0f\u53ca\u5176\u5728\u9884\u6d4b\u3001\u751f\u6210\u3001\u8ba1\u5212\u548c\u56e0\u679c\u63a8\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u65e0\u7ebf\u68a6\u60f3\u8005\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u4f18\u5316\u65e0\u7ebf\u8fb9\u7f18\u667a\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u7a7a\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2506.00195", "pdf": "https://arxiv.org/pdf/2506.00195", "abs": "https://arxiv.org/abs/2506.00195", "authors": ["Mingqian Zheng", "Wenjia Hu", "Patrick Zhao", "Motahhare Eslami", "Jena D. Hwang", "Faeze Brahman", "Carolyn Rose", "Maarten Sap"], "title": "Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": null, "summary": "Current LLMs are trained to refuse potentially harmful input queries\nregardless of whether users actually had harmful intents, causing a tradeoff\nbetween safety and user experience. Through a study of 480 participants\nevaluating 3,840 query-response pairs, we examine how different refusal\nstrategies affect user perceptions across varying motivations. Our findings\nreveal that response strategy largely shapes user experience, while actual user\nmotivation has negligible impact. Partial compliance -- providing general\ninformation without actionable details -- emerges as the optimal strategy,\nreducing negative user perceptions by over 50% to flat-out refusals.\nComplementing this, we analyze response patterns of 9 state-of-the-art LLMs and\nevaluate how 6 reward models score different refusal strategies, demonstrating\nthat models rarely deploy partial compliance naturally and reward models\ncurrently undervalue it. This work demonstrates that effective guardrails\nrequire focusing on crafting thoughtful refusals rather than detecting intent,\noffering a path toward AI safety mechanisms that ensure both safety and\nsustained user engagement.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u90e8\u5206\u5408\u89c4\u7b56\u7565\u662f\u7406\u60f3\u9009\u62e9\uff0c\u53ef\u663e\u8457\u6539\u5584\u7528\u6237\u5bf9LLM\u62d2\u7edd\u54cd\u5e94\u7684\u8d1f\u9762\u770b\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684LLM\u5728\u9762\u5bf9\u53ef\u80fd\u6709\u5bb3\u7684\u8f93\u5165\u67e5\u8be2\u65f6\u4f1a\u62d2\u7edd\uff0c\u65e0\u8bba\u7528\u6237\u7684\u5b9e\u9645\u610f\u56fe\u662f\u5426\u6709\u5bb3\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5b89\u5168\u6027\u548c\u7528\u6237\u4f53\u9a8c\u7684\u6743\u8861\u3002", "method": "\u901a\u8fc7\u5bf9480\u540d\u53c2\u4e0e\u8005\u7684\u7814\u7a76\uff0c\u8bc4\u4f30\u4e863840\u4e2a\u67e5\u8be2\u54cd\u5e94\u5bf9\u3002\u6211\u4eec\u5206\u6790\u4e869\u79cd\u6700\u5148\u8fdb\u7684LLM\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u5e76\u8bc4\u4f30\u4e866\u79cd\u5956\u52b1\u6a21\u578b\u5982\u4f55\u5bf9\u4e0d\u540c\u7684\u62d2\u7edd\u7b56\u7565\u8fdb\u884c\u8bc4\u5206\u3002", "result": "\u90e8\u5206\u5408\u89c4\u62d2\u7edd\u7b56\u7565\u2014\u2014\u63d0\u4f9b\u4e00\u822c\u4fe1\u606f\u800c\u4e0d\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u7ec6\u8282\u2014\u2014\u88ab\u8bc1\u660e\u662f\u6700\u4f73\u7b56\u7565\uff0c\u5c06\u7528\u6237\u5bf9\u76f4\u63a5\u62d2\u7edd\u7684\u8d1f\u9762\u770b\u6cd5\u51cf\u5c11\u4e8650%\u4ee5\u4e0a\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5f88\u5c11\u81ea\u7136\u4f7f\u7528\u90e8\u5206\u5408\u89c4\u7b56\u7565\uff0c\u800c\u5956\u52b1\u6a21\u578b\u76ee\u524d\u5bf9\u5176\u8bc4\u4ef7\u504f\u4f4e\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\u6709\u6548\u7684\u5b89\u5168\u673a\u5236\u9700\u8981\u5173\u6ce8\u8bbe\u8ba1\u7ec6\u81f4\u7684\u62d2\u7edd\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u68c0\u6d4b\u7528\u6237\u610f\u56fe\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\u3002"}}
{"id": "2506.00247", "pdf": "https://arxiv.org/pdf/2506.00247", "abs": "https://arxiv.org/abs/2506.00247", "authors": ["Aasish Kumar Sharma", "Sanjeeb Prashad Pandey", "Julian M. Kunkel"], "title": "Performance Analysis of Convolutional Neural Network By Applying Unconstrained Binary Quadratic Programming", "categories": ["cs.LG", "cs.ET"], "comment": "11 pages, 22 figures, accepted in IEEE COMPSAC 2025 Conference.\n  Preprint before peer review", "summary": "Convolutional Neural Networks (CNNs) are pivotal in computer vision and Big\nData analytics but demand significant computational resources when trained on\nlarge-scale datasets. Conventional training via back-propagation (BP) with\nlosses like Mean Squared Error or Cross-Entropy often requires extensive\niterations and may converge sub-optimally. Quantum computing offers a promising\nalternative by leveraging superposition, tunneling, and entanglement to search\ncomplex optimization landscapes more efficiently. In this work, we propose a\nhybrid optimization method that combines an Unconstrained Binary Quadratic\nProgramming (UBQP) formulation with Stochastic Gradient Descent (SGD) to\naccelerate CNN training. Evaluated on the MNIST dataset, our approach achieves\na 10--15\\% accuracy improvement over a standard BP-CNN baseline while\nmaintaining similar execution times. These results illustrate the potential of\nhybrid quantum-classical techniques in High-Performance Computing (HPC)\nenvironments for Big Data and Deep Learning. Fully realizing these benefits,\nhowever, requires a careful alignment of algorithmic structures with underlying\nquantum mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u4f20\u7edf\u4f18\u5316\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u53ef\u63d0\u9ad8CNN\u8bad\u7ec3\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u5927\u6570\u636e\u5206\u6790\u4e2d\u7684\u91cd\u8981\u6027\u4ee5\u53ca\u5176\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u9ad8\u9700\u6c42\u662f\u7814\u7a76\u7684\u52a8\u673a\u3002\u91cf\u5b50\u8ba1\u7b97\u53ef\u4ee5\u66f4\u9ad8\u6548\u5730\u641c\u7d22\u590d\u6742\u4f18\u5316\u7a7a\u95f4\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8bad\u7ec3CNN\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u65e0\u7ea6\u675f\u4e8c\u6b21\u89c4\u5212\uff08UBQP\uff09\u4e0e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u7ed3\u5408\u6765\u52a0\u901f\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u3002", "result": "\u5728MNIST\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u6807\u51c6\u53cd\u5411\u4f20\u64adCNN\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u9ad810-15%\uff0c\u6267\u884c\u65f6\u95f4\u76f8\u4f3c\u3002", "conclusion": "\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6280\u672f\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e0b\u5177\u6709\u5f88\u5927\u6f5c\u529b\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5927\u6570\u636e\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.00430", "pdf": "https://arxiv.org/pdf/2506.00430", "abs": "https://arxiv.org/abs/2506.00430", "authors": ["Nicole Hsing"], "title": "MIRROR: Cognitive Inner Monologue Between Conversational Turns for Persistent Reflection and Reasoning in Conversational LLMs", "categories": ["cs.AI"], "comment": null, "summary": "Human intelligence relies on inner monologue to process complex information\nthrough simultaneous reflection, memory retrieval, and response formulation. We\nintroduce MIRROR (Modular Internal Reasoning, Reflection, Orchestration, and\nResponse), a cognitive architecture that systematically implements these\nparallel reasoning capabilities in large language models. MIRROR operates as a\nunified system with two distinct functional layers: the Thinker and the Talker.\nThe Thinker encompasses: (1) the Inner Monologue Manager, coordinating\nreasoning threads across cognitive dimensions (Goals, Reasoning, and Memory);\nand (2) the Cognitive Controller, synthesizing these threads into a coherent\ninternal narrative maintained across conversation turns. The Talker component\nthen leverages this integrated narrative for context-aware responses. Evaluated\non the CuRaTe benchmark--testing personalized dialogue with safety-critical\nconstraints, conflicting preferences, and multi-turn consistency--LLMs\nutilizing the MIRROR architecture achieve up to 156% relative improvement in\ncritical safety scenarios involving three persons with conflicting preferences,\nmaintaining an average accuracy of ~>80% on all scenarios. Across\nscenario-specific comparisons, GPT-4o, Gemini 1.5 Pro, Claude 3.7 Sonnet, Llama\n4 variants, and Mistral 3 variants with the MIRROR architecture outperformed\nbaseline models by 21% on average (15.5 percentage points absolute). MIRROR\ndirectly addresses three critical LLM failure modes: sycophancy, attentional\ndeficits to critical information, and inconsistent prioritization of\nconflicting constraints. This work bridges cognitive science and AI by\nimplementing modular internal reasoning inspired by human cognition, creating a\npersistent internal model that significantly enhances multi-turn conversation\ncapabilities.", "AI": {"tldr": "MIRROR is a cognitive architecture that enhances LLMs by mimicking human inner monologues, improving conversation consistency and addressing common LLM failures, with significant performance gains in challenging scenarios.", "motivation": "The motivation is to improve language models by implementing parallel reasoning capabilities similar to human cognitive processes, specifically those involving inner monologue for processing complex information.", "method": "MIRROR operates as a cognitive architecture with two functional layers: the Thinker and the Talker. The Thinker includes the Inner Monologue Manager and Cognitive Controller for reasoning and narrative synthesis. The Talker utilizes this narrative for generating context-aware responses.", "result": "MIRROR outperformed baseline models by 21% on average across scenarios and achieved up to 156% improvement in safety-critical scenarios, maintaining over 80% accuracy. It addresses failure modes like sycophancy and attentional issues.", "conclusion": "MIRROR architecture significantly enhances large language models' ability to manage multi-turn conversations, especially under complex constraints. It bridges cognitive science and AI by addressing key LLM failure modes such as sycophancy, attentional deficits, and inconsistent prioritization, achieving substantial improvements over baseline models."}}
{"id": "2506.00200", "pdf": "https://arxiv.org/pdf/2506.00200", "abs": "https://arxiv.org/abs/2506.00200", "authors": ["Johannes Moll", "Louisa Fay", "Asfandyar Azhar", "Sophie Ostmeier", "Tim Lueth", "Sergios Gatidis", "Curtis Langlotz", "Jean-Benoit Delbrouck"], "title": "Structuring Radiology Reports: Challenging LLMs with Lightweight Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Radiology reports are critical for clinical decision-making but often lack a\nstandardized format, limiting both human interpretability and machine learning\n(ML) applications. While large language models (LLMs) have shown strong\ncapabilities in reformatting clinical text, their high computational\nrequirements, lack of transparency, and data privacy concerns hinder practical\ndeployment. To address these challenges, we explore lightweight encoder-decoder\nmodels (<300M parameters)-specifically T5 and BERT2BERT-for structuring\nradiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark\nthese models against eight open-source LLMs (1B-70B), adapted using prefix\nprompting, in-context learning (ICL), and low-rank adaptation (LoRA)\nfinetuning. Our best-performing lightweight model outperforms all LLMs adapted\nusing prompt-based techniques on a human-annotated test set. While some\nLoRA-finetuned LLMs achieve modest gains over the lightweight model on the\nFindings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%,\nGREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of\nsubstantially greater computational resources. For example, LLaMA-3-70B\nincurred more than 400 times the inference time, cost, and carbon emissions\ncompared to the lightweight model. These results underscore the potential of\nlightweight, task-specific models as sustainable and privacy-preserving\nsolutions for structuring clinical text in resource-constrained healthcare\nsettings.", "AI": {"tldr": "\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6a21\u578b\u4f18\u5316\u533b\u5b66\u62a5\u544a\u7ed3\u6784\u5316\uff0c\u53ef\u66ff\u4ee3\u9ad8\u8ba1\u7b97\u9700\u6c42\u7684LLM\uff0c\u8282\u7ea6\u8d44\u6e90\u5e76\u63d0\u9ad8\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u533b\u5b66\u62a5\u544a\u901a\u5e38\u7f3a\u4e4f\u6807\u51c6\u5316\uff0c\u5f71\u54cd\u4eba\u7c7b\u89e3\u8bfb\u548c\u673a\u5668\u5b66\u4e60\u5e94\u7528\u3002\u9700\u53d1\u5c55\u9ad8\u6548\u6a21\u578b\u514b\u670dLLM\u8ba1\u7b97\u9700\u6c42\u53ca\u9690\u79c1\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7f16\u7801\u89e3\u7801\u6a21\u578b\uff08\u5982T5\u548cBERT2BERT\uff09\u8fdb\u884c\u533b\u5b66\u62a5\u544a\u7684\u7ed3\u6784\u5316\u5904\u7406\uff0c\u5e76\u5bf9\u591a\u79cd\u5f00\u653e\u6e90LLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u524d\u7f00\u63d0\u793a\u3001ICL\u548cLoRA\u5fae\u8c03\u6280\u672f\u3002", "result": "\u6700\u4f73\u8f7b\u91cf\u7ea7\u6a21\u578b\u5728\u5305\u62ecBLEU\u3001ROUGE-L\u3001BERTScore\u7b49\u5ea6\u91cf\u6807\u51c6\u4e0a\u7684\u8868\u73b0\u8d85\u8d8a\u6240\u6709\u901a\u8fc7\u63d0\u793a\u6280\u672f\u9002\u914d\u7684LLM\uff0c\u800c\u67d0\u4e9b\u5fae\u8c03LLM\u867d\u5728\u6280\u672f\u6307\u6807\u4e0a\u6709\u5fae\u5c0f\u4f18\u52bf\uff0c\u4f46\u9700\u8981\u663e\u8457\u66f4\u591a\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u7684\u7f16\u7801\u89e3\u7801\u6a21\u578b\u5728\u7ed3\u6784\u5316\u533b\u5b66\u62a5\u544a\u65b9\u9762\u5177\u5907\u53ef\u6301\u7eed\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u4f18\u52bf\uff0c\u5e76\u5728\u8d44\u6e90\u53d7\u9650\u7684\u533b\u7597\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.00259", "pdf": "https://arxiv.org/pdf/2506.00259", "abs": "https://arxiv.org/abs/2506.00259", "authors": ["Zhengyang Fan", "Wanru Li", "Kuo-chu Chang", "Ting Yuan"], "title": "PerFormer: A Permutation Based Vision Transformer for Remaining Useful Life Prediction", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Accurately estimating the remaining useful life (RUL) for degradation systems\nis crucial in modern prognostic and health management (PHM). Convolutional\nNeural Networks (CNNs), initially developed for tasks like image and video\nrecognition, have proven highly effectively in RUL prediction, demonstrating\nremarkable performance. However, with the emergence of the Vision Transformer\n(ViT), a Transformer model tailored for computer vision tasks such as image\nclassification, and its demonstrated superiority over CNNs, there is a natural\ninclination to explore its potential in enhancing RUL prediction accuracy.\nNonetheless, applying ViT directly to multivariate sensor data for RUL\nprediction poses challenges, primarily due to the ambiguous nature of spatial\ninformation in time series data. To address this issue, we introduce the\nPerFormer, a permutation-based vision transformer approach designed to permute\nmultivariate time series data, mimicking spatial characteristics akin to image\ndata, thereby making it suitable for ViT. To generate the desired permutation\nmatrix, we introduce a novel permutation loss function aimed at guiding the\nconvergence of any matrix towards a permutation matrix. Our experiments on\nNASA's C-MAPSS dataset demonstrate the PerFormer's superior performance in RUL\nprediction compared to state-of-the-art methods employing CNNs, Recurrent\nNeural Networks (RNNs), and various Transformer models. This underscores its\neffectiveness and potential in PHM applications.", "AI": {"tldr": "The paper introduces PerFormer, a vision transformer approach, enhancing RUL prediction accuracy by mimicking spatial characteristics of time series data, outperforming existing models.", "motivation": "Explore the potential of Vision Transformer (ViT) in improving RUL prediction accuracy due to its demonstrated superiority over CNNs in computer vision.", "method": "Introduce PerFormer, a permutation-based vision transformer that creates a permutation matrix mimicking spatial characteristics for ViT.", "result": "PerFormer demonstrates superior RUL prediction performance on NASA's C-MAPSS dataset, surpassing state-of-the-art methods.", "conclusion": "PerFormer shows superior performance in RUL prediction compared to CNNs, RNNs, and various Transformer models."}}
{"id": "2506.00496", "pdf": "https://arxiv.org/pdf/2506.00496", "abs": "https://arxiv.org/abs/2506.00496", "authors": ["Ashutosh Gupta", "Thomas A. Henzinger", "Konstantin Kueffner", "Kaushik Mallik", "David Pape"], "title": "Monitoring Robustness and Individual Fairness", "categories": ["cs.AI"], "comment": null, "summary": "Input-output robustness appears in various different forms in the literature,\nsuch as robustness of AI models to adversarial or semantic perturbations and\nindividual fairness of AI models that make decisions about humans.\n  We propose runtime monitoring of input-output robustness of deployed,\nblack-box AI models, where the goal is to design monitors that would observe\none long execution sequence of the model, and would raise an alarm whenever it\nis detected that two similar inputs from the past led to dissimilar outputs.\n  This way, monitoring will complement existing offline ``robustification''\napproaches to increase the trustworthiness of AI decision-makers.\n  We show that the monitoring problem can be cast as the fixed-radius nearest\nneighbor (FRNN) search problem, which, despite being well-studied, lacks\nsuitable online solutions.\n  We present our tool Clemont, which offers a number of lightweight monitors,\nsome of which use upgraded online variants of existing FRNN algorithms, and one\nuses a novel algorithm based on binary decision diagrams -- a data-structure\ncommonly used in software and hardware verification.\n  We have also developed an efficient parallelization technique that can\nsubstantially cut down the computation time of monitors for which the distance\nbetween input-output pairs is measured using the $L_\\infty$ norm.\n  Using standard benchmarks from the literature of adversarial and semantic\nrobustness and individual fairness, we perform a comparative study of different\nmonitors in \\tool, and demonstrate their effectiveness in correctly detecting\nrobustness violations at runtime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u76d1\u63a7\u9ed1\u76d2AI\u6a21\u578b\u8f93\u5165\u8f93\u51fa\u9c81\u68d2\u6027\u7684\u5de5\u5177Clemont\uff0c\u5229\u7528\u56fa\u5b9a\u534a\u5f84\u6700\u8fd1\u90bb\u641c\u7d22\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u5e76\u884c\u5316\u6280\u672f\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bbe\u8ba1\u53ef\u4ee5\u5728\u8fd0\u884c\u65f6\u76d1\u63a7\u5df2\u90e8\u7f72\u7684\u9ed1\u76d2AI\u6a21\u578b\u7684\u8f93\u5165\u8f93\u51fa\u9c81\u68d2\u6027\uff0c\u65e8\u5728\u5f53\u76d1\u6d4b\u5230\u8fc7\u53bb\u4e24\u4e2a\u76f8\u4f3c\u8f93\u5165\u7ed3\u679c\u4e0d\u540c\u8f93\u51fa\u65f6\u53d1\u51fa\u8b66\u62a5\uff0c\u4ece\u800c\u63d0\u9ad8AI\u51b3\u7b56\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u8bba\u6587\u5c06\u76d1\u63a7\u95ee\u9898\u8f6c\u5316\u4e3a\u56fa\u5b9a\u534a\u5f84\u6700\u8fd1\u90bb\u641c\u7d22\u95ee\u9898\uff08FRNN\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u5143\u51b3\u7b56\u56fe\u7684\u65b0\u7b97\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e76\u884c\u5316\u6280\u672f\u6765\u63d0\u9ad8\u76d1\u63a7\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u76f8\u5173\u5de5\u5177Clemont\u5c55\u793a\u4e86\u5176\u6548\u529b\uff0c\u901a\u8fc7\u6807\u51c6\u57fa\u51c6\u8fdb\u884c\u6bd4\u8f83\u7814\u7a76\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u9c81\u68d2\u6027\u8fdd\u4f8b\u3002", "conclusion": "\u8bba\u6587\u5728\u5de5\u5177Clemont\u7684\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u4e0d\u540c\u76d1\u63a7\u5668\u5728\u8fd0\u884c\u65f6\u6b63\u786e\u68c0\u6d4b\u9c81\u68d2\u6027\u8fdd\u4f8b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.00204", "pdf": "https://arxiv.org/pdf/2506.00204", "abs": "https://arxiv.org/abs/2506.00204", "authors": ["Linyuan Gong", "Alvin Cheung", "Mostafa Elhoushi", "Sida Wang"], "title": "Structure-Aware Fill-in-the-Middle Pretraining for Code", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "14 pages", "summary": "Fill-in-the-Middle (FIM) is a common pretraining method for code LLMs, where\nmodels complete code segments given surrounding context. However, existing LLMs\ntreat code as plain text and mask random character spans. We propose and\nevaluate AST-FIM, a pretraining strategy that leverages Abstract Syntax Trees\n(ASTs) to mask complete syntactic structures at scale, ensuring coherent\ntraining examples better aligned with universal code structures and common code\nediting patterns such as blocks, expressions, or functions. To evaluate\nreal-world fill-in-the-middle (FIM) programming tasks, we introduce\nReal-FIM-Eval, a benchmark derived from 30,000+ GitHub commits across 12\nlanguages. On infilling tasks, experiments on 1B and 8B parameter models show\nthat AST-FIM is particularly beneficial for real-world code editing as it\noutperforms standard random-character FIM by up to 5 pts on standard FIM\nbenchmarks. Our code is publicly available at\nhttps://github.com/gonglinyuan/ast_fim.", "AI": {"tldr": "AST-FIM uses Abstract Syntax Trees for better code LLM pretraining, improving real-world FIM tasks by up to 5 points over traditional methods.", "motivation": "Improve pretraining of code language models (LLMs) by leveraging code structure and editing patterns, enhancing their real-world application.", "method": "Propose and evaluate AST-FIM, utilizing Abstract Syntax Trees to mask syntactic structures during pretraining.", "result": "AST-FIM demonstrates superior performance on infilling tasks in models with 1B and 8B parameters, showing up to 5-point improvement over random-character masking methods.", "conclusion": "AST-FIM significantly improves code completion tasks by aligning better with code structures and editing patterns, outperforming traditional FIM methods."}}
{"id": "2506.00286", "pdf": "https://arxiv.org/pdf/2506.00286", "abs": "https://arxiv.org/abs/2506.00286", "authors": ["Oliver Mortensen", "Mohammad Sadegh Talebi"], "title": "Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "In this paper we analyze the sample complexities of learning the optimal\nstate-action value function $Q^*$ and an optimal policy $\\pi^*$ in a discounted\nMarkov decision process (MDP) where the agent has recursive entropic\nrisk-preferences with risk-parameter $\\beta\\neq 0$ and where a generative model\nof the MDP is available. We provide and analyze a simple model based approach\nwhich we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which\nleads to $(\\epsilon,\\delta)$-PAC-bounds on $\\|Q^*-Q^k\\|$, and\n$\\|V^*-V^{\\pi_k}\\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations\nand $\\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have\nexponential dependence on the effective horizon $\\frac{1}{1-\\gamma}$ and the\nstrength of this dependence grows with the learners risk-sensitivity $|\\beta|$.\nWe also provide two lower bounds which shows that exponential dependence on\n$|\\beta|\\frac{1}{1-\\gamma}$ is unavoidable in both cases. The lower bounds\nreveal that the PAC-bounds are both tight in $\\varepsilon$ and $\\delta$ and\nthat the PAC-bound on $Q$-learning is tight in the number of actions $A$, and\nthat the PAC-bound on policy-learning is nearly tight in $A$.", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u5728\u5177\u6709\u98ce\u9669\u504f\u597d\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u63d0\u51fa\u4e86MB-RS-QVI\u65b9\u6cd5\u5e76\u63d0\u4f9bPAC\u754c\u9650\uff0c\u4e14\u8bc1\u660e\u5176\u754c\u9650\u7684\u7d27\u81f4\u6027\u3002", "motivation": "\u7814\u7a76\u5728\u5177\u6709\u9012\u5f52\u71b5\u98ce\u9669\u504f\u597d\u7684\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u5b66\u4e60\u6700\u4f18\u72b6\u6001-\u52a8\u4f5c\u503c\u51fd\u6570\u548c\u6700\u4f18\u7b56\u7565\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5373\u57fa\u4e8e\u6a21\u578b\u7684\u98ce\u9669\u654f\u611fQ\u503c\u8fed\u4ee3\uff08MB-RS-QVI\uff09\uff0c\u7528\u4e8e\u5206\u6790\u548c\u63d0\u4f9bPAC\u754c\u9650\u3002", "result": "\u63d0\u4f9b\u4e86$(\\epsilon,\\delta)$-PAC\u754c\u9650\uff0c\u5e76\u8bc1\u660e\u4e86\u6307\u6570\u4f9d\u8d56\u6027\u65e0\u6cd5\u907f\u514d\uff0c\u8fd9\u8868\u660e\u8fd9\u4e9b\u754c\u9650\u662f\u7d27\u7684\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5177\u6709\u9012\u5f52\u71b5\u98ce\u9669\u504f\u597d\u7684\u6298\u6263\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u4e2d\uff0c\u5b66\u4e60\u6700\u4f18\u72b6\u6001-\u52a8\u4f5c\u503c\u51fd\u6570\u548c\u6700\u4f18\u7b56\u7565\u7684\u6837\u672c\u590d\u6742\u5ea6\u5177\u6709\u6307\u6570\u4f9d\u8d56\u6027\uff0c\u800c\u8fd9\u79cd\u4f9d\u8d56\u6027\u4e0e\u5b66\u4e60\u8005\u7684\u98ce\u9669\u654f\u611f\u5ea6\u548c\u6709\u6548\u89c6\u91ce\u76f8\u5173\uff0c\u5e76\u4e14\u4e0d\u53ef\u907f\u514d\u3002"}}
{"id": "2506.00530", "pdf": "https://arxiv.org/pdf/2506.00530", "abs": "https://arxiv.org/abs/2506.00530", "authors": ["Tianhui Liu", "Jie Feng", "Hetian Pang", "Xin Zhang", "Tianjian Ouyang", "Zhiyuan Zhang", "Yong Li"], "title": "CityLens: Benchmarking Large Language-Vision Models for Urban Socioeconomic Sensing", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Understanding urban socioeconomic conditions through visual data is a\nchallenging yet essential task for sustainable urban development and policy\nplanning. In this work, we introduce $\\textbf{CityLens}$, a comprehensive\nbenchmark designed to evaluate the capabilities of large language-vision models\n(LLVMs) in predicting socioeconomic indicators from satellite and street view\nimagery. We construct a multi-modal dataset covering a total of 17 globally\ndistributed cities, spanning 6 key domains: economy, education, crime,\ntransport, health, and environment, reflecting the multifaceted nature of urban\nlife. Based on this dataset, we define 11 prediction tasks and utilize three\nevaluation paradigms: Direct Metric Prediction, Normalized Metric Estimation,\nand Feature-Based Regression. We benchmark 17 state-of-the-art LLVMs across\nthese tasks. Our results reveal that while LLVMs demonstrate promising\nperceptual and reasoning capabilities, they still exhibit limitations in\npredicting urban socioeconomic indicators. CityLens provides a unified\nframework for diagnosing these limitations and guiding future efforts in using\nLLVMs to understand and predict urban socioeconomic patterns. Our codes and\ndatasets are open-sourced via https://github.com/tsinghua-fib-lab/CityLens.", "AI": {"tldr": "CityLens\u8bc4\u4f30LLVMs\u5728\u4f7f\u7528\u89c6\u89c9\u6570\u636e\u9884\u6d4b\u57ce\u5e02\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u7684\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u901a\u8fc7\u53ef\u89c6\u5316\u6570\u636e\u7406\u89e3\u57ce\u5e02\u793e\u4f1a\u7ecf\u6d4e\u72b6\u51b5\uff0c\u662f\u53ef\u6301\u7eed\u57ce\u5e02\u53d1\u5c55\u548c\u653f\u7b56\u89c4\u5212\u7684\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u4f46\u53c8\u81f3\u5173\u91cd\u8981\u7684\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5305\u542b 17 \u4e2a\u5168\u7403\u5206\u5e03\u57ce\u5e02\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u4e8611\u4e2a\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u4e09\u4e2a\u8bc4\u4f30\u8303\u5f0f\uff1a\u76f4\u63a5\u6307\u6807\u9884\u6d4b\u3001\u6807\u51c6\u5316\u6307\u6807\u4f30\u8ba1\u548c\u57fa\u4e8e\u7279\u5f81\u7684\u56de\u5f52\uff0c\u5bf9 17 \u4e2a\u6700\u5148\u8fdb\u7684LLVMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u867d\u7136LLVMs\u5728\u611f\u77e5\u548c\u63a8\u7406\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9884\u6d4b\u57ce\u5e02\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "CityLens\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u8bca\u65adLLVMs\u5728\u9884\u6d4b\u57ce\u5e02\u793e\u4f1a\u7ecf\u6d4e\u6307\u6807\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u5982\u4f55\u4f7f\u7528LLVMs\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u793e\u4f1a\u7ecf\u6d4e\u6a21\u5f0f\u3002"}}
{"id": "2506.00210", "pdf": "https://arxiv.org/pdf/2506.00210", "abs": "https://arxiv.org/abs/2506.00210", "authors": ["Ziji Zhang", "Michael Yang", "Zhiyu Chen", "Yingying Zhuang", "Shu-Ting Pi", "Qun Liu", "Rajashekar Maragoud", "Vy Nguyen", "Anurag Beniwal"], "title": "REIC: RAG-Enhanced Intent Classification at Scale", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Accurate intent classification is critical for efficient routing in customer\nservice, ensuring customers are connected with the most suitable agents while\nreducing handling times and operational costs. However, as companies expand\ntheir product lines, intent classification faces scalability challenges due to\nthe increasing number of intents and variations in taxonomy across different\nverticals. In this paper, we introduce REIC, a Retrieval-augmented generation\nEnhanced Intent Classification approach, which addresses these challenges\neffectively. REIC leverages retrieval-augmented generation (RAG) to dynamically\nincorporate relevant knowledge, enabling precise classification without the\nneed for frequent retraining. Through extensive experiments on real-world\ndatasets, we demonstrate that REIC outperforms traditional fine-tuning,\nzero-shot, and few-shot methods in large-scale customer service settings. Our\nresults highlight its effectiveness in both in-domain and out-of-domain\nscenarios, demonstrating its potential for real-world deployment in adaptive\nand large-scale intent classification systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86REIC\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u89e3\u51b3\u610f\u56fe\u5206\u7c7b\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u4f01\u4e1a\u4ea7\u54c1\u7ebf\u6269\u5c55\u5e26\u6765\u7684\u610f\u56fe\u6570\u91cf\u589e\u591a\u548c\u5206\u7c7b\u4f53\u7cfb\u53d8\u5316\uff0c\u5bfc\u81f4\u610f\u56fe\u5206\u7c7b\u9762\u4e34\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165REIC (Retrieval-augmented generation Enhanced Intent Classification) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6765\u52a8\u6001\u7ed3\u5408\u76f8\u5173\u77e5\u8bc6\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u610f\u56fe\u5206\u7c7b\u3002", "result": "\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86REIC\u5728\u5927\u89c4\u6a21\u5ba2\u6237\u670d\u52a1\u73af\u5883\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u3001\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u65b9\u6cd5\u3002", "conclusion": "REIC\u6709\u6548\u89e3\u51b3\u4e86\u968f\u7740\u516c\u53f8\u4ea7\u54c1\u7ebf\u6269\u5c55\u800c\u5bfc\u81f4\u7684\u610f\u56fe\u5206\u7c7b\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u540c\u65f6\u5728\u5927\u89c4\u6a21\u5ba2\u6237\u670d\u52a1\u73af\u5883\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u5177\u6709\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2506.00297", "pdf": "https://arxiv.org/pdf/2506.00297", "abs": "https://arxiv.org/abs/2506.00297", "authors": ["Fanglei Xue", "Andrew Kubaney", "Zhichun Guo", "Joseph K. Min", "Ge Liu", "Yi Yang", "David Baker"], "title": "Improving Protein Sequence Design through Designability Preference Optimization", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": null, "summary": "Protein sequence design methods have demonstrated strong performance in\nsequence generation for de novo protein design. However, as the training\nobjective was sequence recovery, it does not guarantee designability--the\nlikelihood that a designed sequence folds into the desired structure. To bridge\nthis gap, we redefine the training objective by steering sequence generation\ntoward high designability. To do this, we integrate Direct Preference\nOptimization (DPO), using AlphaFold pLDDT scores as the preference signal,\nwhich significantly improves the in silico design success rate. To further\nrefine sequence generation at a finer, residue-level granularity, we introduce\nResidue-level Designability Preference Optimization (ResiDPO), which applies\nresidue-level structural rewards and decouples optimization across residues.\nThis enables direct improvement in designability while preserving regions that\nalready perform well. Using a curated dataset with residue-level annotations,\nwe fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a\nnearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%)\non a challenging enzyme design benchmark.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u86cb\u767d\u8d28\u8bbe\u8ba1\u7684\u6210\u529f\u7387\uff0c\u7279\u522b\u662f\u5728\u9176\u8bbe\u8ba1\u4e0a\u6210\u529f\u7387\u63d0\u5347\u4e09\u500d\u3002", "motivation": "\u76ee\u524d\u7684\u86cb\u767d\u8d28\u5e8f\u5217\u8bbe\u8ba1\u65b9\u6cd5\u5728\u5e8f\u5217\u751f\u6210\u4e2d\u867d\u7136\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u5176\u8bad\u7ec3\u76ee\u6807\u4e3b\u8981\u662f\u5e8f\u5217\u6062\u590d\uff0c\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u8bbe\u8ba1\u86cb\u767d\u8d28\u80fd\u591f\u51c6\u786e\u6298\u53e0\u6210\u671f\u671b\u7684\u7ed3\u6784\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6539\u8fdb\u8bad\u7ec3\u76ee\u6807\u4ee5\u63d0\u9ad8\u8bbe\u8ba1\u80fd\u529b\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\uff0c\u5229\u7528AlphaFold\u7684pLDDT\u5206\u6570\u4f5c\u4e3a\u504f\u597d\u4fe1\u53f7\uff0c\u5e76\u7ed3\u5408Residue-level Designability Preference Optimization (ResiDPO)\u4ee5\u7ec6\u5316\u5e8f\u5217\u751f\u6210\u3002", "result": "\u901a\u8fc7\u4f7f\u7528ResiDPO\u8fdb\u884c\u5fae\u8c03\uff0c\u7814\u7a76\u83b7\u5f97\u4e86\u4e00\u79cd\u79f0\u4e3aEnhancedMPNN\u7684\u6a21\u578b\uff0c\u5728\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u9176\u8bbe\u8ba1\u57fa\u51c6\u4e0a\uff0c\u5176\u6210\u529f\u7387\u51e0\u4e4e\u63d0\u9ad8\u4e86\u4e09\u500d\uff08\u4ece6.56%\u523017.57%\uff09\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165ResiDPO\u4f18\u5316\u548c\u8c03\u4f18LigandMPNN\u81f3EnhancedMPNN\uff0c\u7814\u7a76\u663e\u8457\u63d0\u9ad8\u4e86\u9176\u8bbe\u8ba1\u9886\u57df\u86cb\u767d\u8d28\u5e8f\u5217\u8bbe\u8ba1\u7684\u6210\u529f\u7387\u3002"}}
{"id": "2506.00570", "pdf": "https://arxiv.org/pdf/2506.00570", "abs": "https://arxiv.org/abs/2506.00570", "authors": ["Liang Geng"], "title": "A \"Wenlu\" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge", "categories": ["cs.AI"], "comment": null, "summary": "With the rapid penetration of artificial intelligence across industries and\nscenarios, a key challenge in building the next-generation intelligent core\nlies in effectively integrating the language understanding capabilities of\nfoundation models with domain-specific knowledge bases in complex real-world\napplications. This paper proposes a multimodal cognition and embodied\ndecision-making brain system, ``Wenlu\", designed to enable secure fusion of\nprivate knowledge and public models, unified processing of multimodal data such\nas images and speech, and closed-loop decision-making from cognition to\nautomatic generation of hardware-level code. The system introduces a\nbrain-inspired memory tagging and replay mechanism, seamlessly integrating\nuser-private data, industry-specific knowledge, and general-purpose language\nmodels. It provides precise and efficient multimodal services for enterprise\ndecision support, medical analysis, autonomous driving, robotic control, and\nmore. Compared with existing solutions, ``Wenlu\" demonstrates significant\nadvantages in multimodal processing, privacy security, end-to-end hardware\ncontrol code generation, self-learning, and sustainable updates, thus laying a\nsolid foundation for constructing the next-generation intelligent core.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"Wenlu\"\u7cfb\u7edf\uff0c\u878d\u5408\u79c1\u6709\u77e5\u8bc6\u548c\u516c\u5171\u6a21\u578b\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u6570\u636e\u7edf\u4e00\u5904\u7406\u548c\u95ed\u73af\u51b3\u7b56\uff0c\u5b9e\u73b0\u786c\u4ef6\u7ea7\u4ee3\u7801\u7684\u81ea\u52a8\u751f\u6210\uff0c\u5c55\u73b0\u51fa\u591a\u65b9\u9762\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u5404\u884c\u4e1a\u548c\u573a\u666f\u4e2d\u7684\u5feb\u901f\u6e17\u900f\uff0c\u6784\u5efa\u4e0b\u4e00\u4ee3\u667a\u80fd\u6838\u5fc3\u7684\u5173\u952e\u6311\u6218\u5728\u4e8e\u5982\u4f55\u6709\u6548\u6574\u5408\u57fa\u7840\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u4e0e\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u5e93\uff0c\u4ee5\u9002\u5e94\u590d\u6742\u7684\u73b0\u5b9e\u5e94\u7528\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u8ba4\u77e5\u548c\u4f53\u73b0\u51b3\u7b56\u7684\u8111\u7cfb\u7edf\"Wenlu\"\uff0c\u901a\u8fc7\u8111\u542f\u53d1\u5f0f\u7684\u8bb0\u5fc6\u6807\u8bb0\u548c\u56de\u653e\u673a\u5236\uff0c\u5b9e\u73b0\u7528\u6237\u79c1\u6709\u6570\u636e\u3001\u884c\u4e1a\u7279\u5b9a\u77e5\u8bc6\u548c\u901a\u7528\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u7f1d\u96c6\u6210\uff0c\u4ee5\u4fbf\u4ece\u8ba4\u77e5\u5230\u786c\u4ef6\u7ea7\u4ee3\u7801\u7684\u81ea\u52a8\u751f\u6210\u8fdb\u884c\u95ed\u73af\u51b3\u7b56\u3002", "result": "\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cbe\u786e\u3001\u9ad8\u6548\u7684\u591a\u6a21\u6001\u670d\u52a1\uff0c\u652f\u6301\u4f01\u4e1a\u51b3\u7b56\u3001\u533b\u7597\u5206\u6790\u3001\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u63a7\u5236\u7b49\u591a\u4e2a\u9886\u57df\u3002", "conclusion": "\"Wenlu\"\u7cfb\u7edf\u76f8\u6bd4\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5728\u591a\u6a21\u6001\u5904\u7406\u3001\u9690\u79c1\u5b89\u5168\u3001\u786c\u4ef6\u63a7\u5236\u4ee3\u7801\u751f\u6210\u3001\u81ea\u5b66\u4e60\u548c\u53ef\u6301\u7eed\u66f4\u65b0\u65b9\u9762\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u667a\u80fd\u6838\u5fc3\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2506.00232", "pdf": "https://arxiv.org/pdf/2506.00232", "abs": "https://arxiv.org/abs/2506.00232", "authors": ["Ruofan Wu", "Youngwon Lee", "Fan Shu", "Danmei Xu", "Seung-won Hwang", "Zhewei Yao", "Yuxiong He", "Feng Yan"], "title": "ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems are increasingly diverse, yet\nmany suffer from monolithic designs that tightly couple core functions like\nquery reformulation, retrieval, reasoning, and verification. This limits their\ninterpretability, systematic evaluation, and targeted improvement, especially\nfor complex multi-hop question answering. We introduce ComposeRAG, a novel\nmodular abstraction that decomposes RAG pipelines into atomic, composable\nmodules. Each module, such as Question Decomposition, Query Rewriting,\nRetrieval Decision, and Answer Verification, acts as a parameterized\ntransformation on structured inputs/outputs, allowing independent\nimplementation, upgrade, and analysis. To enhance robustness against errors in\nmulti-step reasoning, ComposeRAG incorporates a self-reflection mechanism that\niteratively revisits and refines earlier steps upon verification failure.\nEvaluated on four challenging multi-hop QA benchmarks, ComposeRAG consistently\noutperforms strong baselines in both accuracy and grounding fidelity.\nSpecifically, it achieves up to a 15% accuracy improvement over\nfine-tuning-based methods and up to a 5% gain over reasoning-specialized\npipelines under identical retrieval conditions. Crucially, ComposeRAG\nsignificantly enhances grounding: its verification-first design reduces\nungrounded answers by over 10% in low-quality retrieval settings, and by\napproximately 3% even with strong corpora. Comprehensive ablation studies\nvalidate the modular architecture, demonstrating distinct and additive\ncontributions from each component. These findings underscore ComposeRAG's\ncapacity to deliver flexible, transparent, scalable, and high-performing\nmulti-hop reasoning with improved grounding and interpretability.", "AI": {"tldr": "ComposeRAG\u662f\u4e00\u79cd\u6a21\u5757\u5316\u7684RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u89e3\u6d41\u7a0b\u548c\u5f15\u5165\u81ea\u6211\u53cd\u601d\u673a\u5236\uff0c\u63d0\u9ad8\u591a\u8df3\u95ee\u7b54\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u57fa\u7840\u771f\u5b9e\u6027\u3002\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u8bb8\u591a\u73b0\u6709\u7684RAG\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u4e8e\u96c6\u6210\u5316\uff0c\u5bfc\u81f4\u5728\u89e3\u91ca\u6027\u3001\u7cfb\u7edf\u8bc4\u4ef7\u548c\u9488\u5bf9\u6027\u6539\u8fdb\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u591a\u8df3\u95ee\u7b54\u4e2d\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e00\u79cd\u6a21\u5757\u5316\u62bd\u8c61\u6765\u63d0\u9ad8\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\u3002", "method": "ComposeRAG\u901a\u8fc7\u5c06RAG\u6d41\u7a0b\u5206\u89e3\u4e3a\u53ef\u7ec4\u5408\u7684\u6a21\u5757\u6765\u6539\u8fdb\u95ee\u7b54\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u6a21\u5757\u5305\u62ec\u95ee\u9898\u5206\u89e3\u3001\u67e5\u8be2\u91cd\u5199\u3001\u68c0\u7d22\u51b3\u7b56\u548c\u7b54\u6848\u9a8c\u8bc1\uff0c\u5141\u8bb8\u72ec\u7acb\u5b9e\u65bd\u3001\u5347\u7ea7\u548c\u5206\u6790\u3002\u6b64\u5916\uff0c\u5b83\u501f\u52a9\u81ea\u6211\u53cd\u601d\u673a\u5236\u6765\u63d0\u9ad8\u591a\u6b65\u63a8\u7406\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728\u56db\u9879\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cComposeRAG\u5728\u51c6\u786e\u6027\u548c\u57fa\u7840\u771f\u5b9e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u76f8\u6bd4\u5fae\u8c03\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6700\u9ad815%\u7684\u51c6\u786e\u6027\uff0c\u4e14\u5728\u76f8\u540c\u68c0\u7d22\u6761\u4ef6\u4e0b\uff0c\u8f83\u63a8\u7406\u4e13\u7528\u7ba1\u9053\u6709\u6700\u9ad85%\u7684\u63d0\u5347\u3002\u6b64\u5916\uff0c\u5b83\u663e\u8457\u4f18\u5316\u4e86\u57fa\u7840\u771f\u5b9e\u6027\uff0c\u5728\u4f4e\u8d28\u91cf\u68c0\u7d22\u4e0b\u51cf\u5c11\u4e86\u8d85\u8fc710%\u7684\u4e0d\u7b26\u5b9e\u56de\u7b54\uff0c\u5373\u4fbf\u5728\u5f3a\u52bf\u8bed\u6599\u5e93\u4e2d\u4e5f\u51cf\u5c11\u7ea63%\u3002", "conclusion": "ComposeRAG\u5c55\u793a\u4e86\u6a21\u5757\u5316\u67b6\u6784\u5728\u591a\u8df3\u95ee\u7b54\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5148\u884c\u8bbe\u8ba1\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u8fd8\u663e\u8457\u51cf\u5c11\u4e86\u4e0d\u7b26\u5408\u5b9e\u9645\u7684\u56de\u7b54\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u9ad8\u6548\u3001\u900f\u660e\u548c\u7075\u6d3b\u7684\u7cfb\u7edf\u7684\u4f5c\u7528\u3002"}}
{"id": "2506.00299", "pdf": "https://arxiv.org/pdf/2506.00299", "abs": "https://arxiv.org/abs/2506.00299", "authors": ["Purvish Jajal", "Nick John Eliopoulos", "Benjamin Shiue-Hal Chou", "George K. Thiruvathukal", "James C. Davis", "Yung-Hsiang Lu"], "title": "Inference-Time Alignment of Diffusion Models with Evolutionary Algorithms", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion models are state-of-the-art generative models in various domains,\nyet their samples often fail to satisfy downstream objectives such as safety\nconstraints or domain-specific validity. Existing techniques for alignment\nrequire gradients, internal model access, or large computational budgets. We\nintroduce an inference-time alignment framework based on evolutionary\nalgorithms. We treat diffusion models as black-boxes and search their latent\nspace to maximize alignment objectives. Our method enables efficient\ninference-time alignment for both differentiable and non-differentiable\nalignment objectives across a range of diffusion models. On the DrawBench and\nOpen Image Preferences benchmark, our EA methods outperform state-of-the-art\ngradient-based and gradient-free inference-time methods. In terms of memory\nconsumption, we require 55% to 76% lower GPU memory than gradient-based\nmethods. In terms of running-time, we are 72% to 80% faster than gradient-based\nmethods. We achieve higher alignment scores over 50 optimization steps on Open\nImage Preferences than gradient-based and gradient-free methods.", "AI": {"tldr": "\u5229\u7528\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u7684\u65b9\u6cd5\u5b9e\u73b0\u6269\u6563\u6a21\u578b\u7684\u9ad8\u6548\u63a8\u65ad\u65f6\u95f4\u5bf9\u9f50\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5feb\u3001\u66f4\u7701\u5185\u5b58\u3001\u66f4\u6709\u6548\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u6837\u672c\u5f80\u5f80\u96be\u4ee5\u6ee1\u8db3\u4e0b\u6e38\u76ee\u6807\u5982\u5b89\u5168\u7ea6\u675f\u6216\u7279\u5b9a\u9886\u57df\u8981\u6c42\uff0c\u56e0\u6b64\u6211\u4eec\u9700\u8981\u4e00\u79cd\u5728\u63a8\u65ad\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u5bf9\u9f50\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u57fa\u4e8e\u8fdb\u5316\u7b97\u6cd5\u63d0\u51fa\u4e86\u4e00\u79cd\u63a8\u65ad\u65f6\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u5c06\u6269\u6563\u6a21\u578b\u89c6\u4e3a\u9ed1\u7bb1\u8fdb\u884c\u5904\u7406\uff0c\u641c\u7d22\u5176\u6f5c\u5728\u7a7a\u95f4\u4ee5\u6700\u5927\u5316\u5bf9\u9f50\u76ee\u6807\u3002", "result": "\u5728DrawBench\u548cOpen Image Preferences\u57fa\u51c6\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u5185\u5b58\u6d88\u8017\u4e0a\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u51cf\u5c11\u4e8655%\u523076%\u7684GPU\u5185\u5b58\u4f7f\u7528\uff0c\u8fd8\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u6bd4\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u5feb72%\u523080%\uff0c\u540c\u65f6\u5728\u5bf9\u9f50\u8bc4\u5206\u4e0a\u8d85\u8fc7\u4e86\u57fa\u4e8e\u68af\u5ea6\u548c\u975e\u68af\u5ea6\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u5728\u4e0d\u540c\u7684\u751f\u6210\u6269\u6563\u6a21\u578b\u4e2d\u6210\u529f\u5b9e\u73b0\u4e86\u63a8\u65ad\u65f6\u95f4\u7684\u9ad8\u6548\u5bf9\u9f50\uff0c\u4e0e\u73b0\u6709\u7684\u57fa\u4e8e\u68af\u5ea6\u548c\u65e0\u68af\u5ea6\u7684\u63a8\u65ad\u65f6\u95f4\u65b9\u6cd5\u76f8\u6bd4\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2506.00235", "pdf": "https://arxiv.org/pdf/2506.00235", "abs": "https://arxiv.org/abs/2506.00235", "authors": ["Yexiao He", "Ang Li", "Boyi Liu", "Zhewei Yao", "Yuxiong He"], "title": "MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility", "categories": ["cs.CL"], "comment": null, "summary": "Healthcare decision-making represents one of the most challenging domains for\nArtificial Intelligence (AI), requiring the integration of diverse knowledge\nsources, complex reasoning, and various external analytical tools. Current AI\nsystems often rely on either task-specific models, which offer limited\nadaptability, or general language models without grounding with specialized\nexternal knowledge and tools. We introduce MedOrch, a novel framework that\norchestrates multiple specialized tools and reasoning agents to provide\ncomprehensive medical decision support. MedOrch employs a modular, agent-based\narchitecture that facilitates the flexible integration of domain-specific tools\nwithout altering the core system. Furthermore, it ensures transparent and\ntraceable reasoning processes, enabling clinicians to meticulously verify each\nintermediate step underlying the system's recommendations. We evaluate MedOrch\nacross three distinct medical applications: Alzheimer's disease diagnosis,\nchest X-ray interpretation, and medical visual question answering, using\nauthentic clinical datasets. The results demonstrate MedOrch's competitive\nperformance across these diverse medical tasks. Notably, in Alzheimer's disease\ndiagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the\nstate-of-the-art baseline by over four percentage points. For predicting\nAlzheimer's disease progression, it attains a 50.35% accuracy, marking a\nsignificant improvement. In chest X-ray analysis, MedOrch exhibits superior\nperformance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover,\nin complex multimodal visual question answering (Image+Table), MedOrch achieves\nan accuracy of 54.47%. These findings underscore MedOrch's potential to advance\nhealthcare AI by enabling reasoning-driven tool utilization for multimodal\nmedical data processing and supporting intricate cognitive tasks in clinical\ndecision-making.", "AI": {"tldr": "MedOrch\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u6574\u5408\u591a\u79cd\u4e13\u4e1a\u5de5\u5177\u548c\u63a8\u7406\u4ee3\u7406\uff0c\u4ee5\u652f\u6301\u533b\u7597\u51b3\u7b56\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524dAI\u7cfb\u7edf\u4f9d\u8d56\u4e8e\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u6216\u4e00\u822c\u8bed\u8a00\u6a21\u578b\uff0c\u7f3a\u4e4f\u4e0e\u4e13\u7528\u5916\u90e8\u77e5\u8bc6\u548c\u5de5\u5177\u7ed3\u5408\u3002\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u6574\u5408\u591a\u6837\u5316\u77e5\u8bc6\u6765\u6e90\u3001\u590d\u6742\u63a8\u7406\u548c\u5404\u79cd\u5916\u90e8\u5206\u6790\u5de5\u5177\u7684AI\u6846\u67b6\u3002", "method": "MedOrch\u4f7f\u7528\u6a21\u5757\u5316\u7684\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u67b6\u6784\uff0c\u4ee5\u4fbf\u7075\u6d3b\u96c6\u6210\u9886\u57df\u4e13\u7528\u5de5\u5177\u800c\u4e0d\u4fee\u6539\u6838\u5fc3\u7cfb\u7edf\uff0c\u5e76\u786e\u4fdd\u900f\u660e\u3001\u53ef\u8ffd\u8e2a\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c7\u8bca\u65ad\u4e0a\uff0cMedOrch\u7684\u51c6\u786e\u7387\u8fbe\u523093.26%\uff0c\u5728\u75be\u75c5\u8fdb\u7a0b\u9884\u6d4b\u4e0a\uff0c\u5176\u51c6\u786e\u7387\u4e3a50.35%\u3002\u5728\u80f8\u90e8X\u5149\u5206\u6790\u4e2d\uff0cMedOrch\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u5b8f\u89c2AUC\u4e3a61.2%\uff0c\u5b8f\u89c2F1\u8bc4\u5206\u4e3a25.5%\u3002\u5728\u590d\u6742\u7684\u591a\u6a21\u6001\u89c6\u89c9\u95ee\u7b54\u4e2d\uff0c\u51c6\u786e\u7387\u4e3a54.47%\u3002", "conclusion": "MedOrch\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u7ade\u4e89\u529b\uff0c\u901a\u8fc7\u542f\u7528\u63a8\u7406\u9a71\u52a8\u7684\u5de5\u5177\u5229\u7528\uff0c\u4fc3\u8fdb\u591a\u6a21\u6001\u533b\u5b66\u6570\u636e\u5904\u7406\uff0c\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u590d\u6742\u8ba4\u77e5\u4efb\u52a1\u3002"}}
{"id": "2506.00302", "pdf": "https://arxiv.org/pdf/2506.00302", "abs": "https://arxiv.org/abs/2506.00302", "authors": ["Can Polat", "Hasan Kurban", "Erchin Serpedin", "Mustafa Kurban"], "title": "Beyond Atomic Geometry Representations in Materials Science: A Human-in-the-Loop Multimodal Framework", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": "Submitted to ICML 2025 Workshop on DataWorld", "summary": "Most materials science datasets are limited to atomic geometries (e.g., XYZ\nfiles), restricting their utility for multimodal learning and comprehensive\ndata-centric analysis. These constraints have historically impeded the adoption\nof advanced machine learning techniques in the field. This work introduces\nMultiCrystalSpectrumSet (MCS-Set), a curated framework that expands materials\ndatasets by integrating atomic structures with 2D projections and structured\ntextual annotations, including lattice parameters and coordination metrics.\nMCS-Set enables two key tasks: (1) multimodal property and summary prediction,\nand (2) constrained crystal generation with partial cluster supervision.\nLeveraging a human-in-the-loop pipeline, MCS-Set combines domain expertise with\nstandardized descriptors for high-quality annotation. Evaluations using\nstate-of-the-art language and vision-language models reveal substantial\nmodality-specific performance gaps and highlight the importance of annotation\nquality for generalization. MCS-Set offers a foundation for benchmarking\nmultimodal models, advancing annotation practices, and promoting accessible,\nversatile materials science datasets. The dataset and implementations are\navailable at https://github.com/KurbanIntelligenceLab/MultiCrystalSpectrumSet.", "AI": {"tldr": "MCS-Set expands materials datasets by combining atomic structures with 2D images and annotations, enabling advanced multimodal machine learning tasks.", "motivation": "The motivation is to overcome the limitations of traditional materials science datasets that only include atomic geometries and hinder the use of advanced machine learning techniques.", "method": "The method involves creating the MCS-Set framework that integrates atomic structures with 2D projections and structured textual annotations. It utilizes a human-in-the-loop pipeline to combine domain expertise with standardized descriptors for annotation.", "result": "Evaluations show significant performance gaps specific to modality, and underscore the importance of annotation quality for generalization in model performance.", "conclusion": "MCS-Set provides a foundation for benchmarking multimodal models, advancing annotation practices, and promoting more accessible and versatile datasets in materials science."}}
{"id": "2506.00582", "pdf": "https://arxiv.org/pdf/2506.00582", "abs": "https://arxiv.org/abs/2506.00582", "authors": ["Chenjun Xu", "Bingbing Wen", "Bin Han", "Robert Wolfe", "Lucy Lu Wang", "Bill Howe"], "title": "Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs", "categories": ["cs.AI", "I.2.7"], "comment": "Accepted by ACL 2025 Findings, 20 pages", "summary": "Psychology research has shown that humans are poor at estimating their\nperformance on tasks, tending towards underconfidence on easy tasks and\noverconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct,\nClaude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty, and\nshow that models exhibit subtle differences from human patterns of\noverconfidence: less sensitive to task difficulty, and when prompted to answer\nbased on different personas -- e.g., expert vs layman, or different race,\ngender, and ages -- the models will respond with stereotypically biased\nconfidence estimations even though their underlying answer accuracy remains the\nsame. Based on these observations, we propose Answer-Free Confidence Estimation\n(AFCE) to improve confidence calibration and LLM interpretability in these\nsettings. AFCE is a self-assessment method that employs two stages of\nprompting, first eliciting only confidence scores on questions, then asking\nseparately for the answer. Experiments on the MMLU and GPQA datasets spanning\nsubjects and difficulty show that this separation of tasks significantly\nreduces overconfidence and delivers more human-like sensitivity to task\ndifficulty.", "AI": {"tldr": "\u7814\u7a76\u5bf9\u6bd4\u4e86\u4e09\u6b3e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u96be\u5ea6\u4e0b\u7684\u4fe1\u5fc3\u8868\u73b0\uff0c\u5f15\u5165\u65e0\u7b54\u6848\u4fe1\u5fc3\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u5584\u6a21\u578b\u7684\u4fe1\u5fc3\u6821\u51c6\u53ca\u5176\u5bf9\u4efb\u52a1\u96be\u5ea6\u7684\u654f\u611f\u6027\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u5927\u6a21\u578b\u5728\u56de\u7b54\u4e0d\u540c\u96be\u5ea6\u7684\u95ee\u9898\u65f6\u7684\u4fe1\u5fc3\u8868\u73b0\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u5bb9\u6613\u4ea7\u751f\u523b\u677f\u5370\u8c61\u4e14\u5bf9\u4efb\u52a1\u96be\u5ea6\u7684\u654f\u611f\u6027\u8f83\u4f4e\uff0c\u6545\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u65e0\u7b54\u6848\u4fe1\u5fc3\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5c06\u4fe1\u5fc3\u8bc4\u5206\u4e0e\u56de\u7b54\u5206\u5f00\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7684\u63d0\u793a\u6765\u8bc4\u4f30\u4fe1\u5fc3\u6821\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528AFCE\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u5c11\u6a21\u578b\u7684\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff0c\u5e76\u589e\u5f3a\u5bf9\u4efb\u52a1\u96be\u5ea6\u7684\u654f\u611f\u6027\uff0c\u4f7f\u5176\u8868\u73b0\u5f97\u66f4\u52a0\u7b26\u5408\u4eba\u7c7b\u7279\u5f81\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u7b54\u6848\u4fe1\u5fc3\u4f30\u8ba1\uff08AFCE\uff09\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u96be\u5ea6\u4e0b\u7684\u4fe1\u5fc3\u6821\u51c6\u80fd\u529b\uff0c\u4f7f\u5176\u5bf9\u4efb\u52a1\u96be\u5ea6\u7684\u654f\u611f\u6027\u66f4\u63a5\u8fd1\u4eba\u7c7b\u3002"}}
{"id": "2506.00250", "pdf": "https://arxiv.org/pdf/2506.00250", "abs": "https://arxiv.org/abs/2506.00250", "authors": ["Mohammad Javad Ranjbar Kalahroodi", "Amirhossein Sheikholselami", "Sepehr Karimi", "Sepideh Ranjbar Kalahroodi", "Heshaam Faili", "Azadeh Shakery"], "title": "PersianMedQA: Language-Centric Evaluation of LLMs in the Persian Medical Domain", "categories": ["cs.CL", "cs.IT", "math.IT"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance on a wide\nrange of NLP benchmarks, often surpassing human-level accuracy. However, their\nreliability in high-stakes domains such as medicine, particularly in\nlow-resource languages, remains underexplored. In this work, we introduce\nPersianMedQA, a large-scale, expert-validated dataset of multiple-choice\nPersian medical questions, designed to evaluate LLMs across both Persian and\nEnglish. We benchmark over 40 state-of-the-art models, including\ngeneral-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and\nchain-of-thought (CoT) settings. Our results show that closed-source general\nmodels (e.g., GPT-4.1) consistently outperform all other categories, achieving\n83.3% accuracy in Persian and 80.7% in English, while Persian fine-tuned models\nsuch as Dorna underperform significantly (e.g., 35.9% in Persian), often\nstruggling with both instruction-following and domain reasoning. We also\nanalyze the impact of translation, showing that while English performance is\ngenerally higher, Persian responses are sometimes more accurate due to cultural\nand clinical contextual cues. Finally, we demonstrate that model size alone is\ninsufficient for robust performance without strong domain or language\nadaptation. PersianMedQA provides a foundation for evaluating multilingual and\nculturally grounded medical reasoning in LLMs. The PersianMedQA dataset can be\naccessed at:\nhttps://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA](https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u8868\u73b0\uff0c\u6784\u5efa\u5e76\u4f7f\u7528\u4e86PersianMedQA\u6570\u636e\u96c6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c01\u95ed\u6e90\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u5927\u5e45\u9886\u5148\uff0c\u6ce2\u65af\u8bed\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u63a2\u7a76\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u53ef\u9760\u6027\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8868\u73b0\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aPersianMedQA\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u8d85\u8fc740\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8fdb\u884cbenchmark\u6d4b\u8bd5\uff0c\u5305\u62ec\u5e38\u89c4\u6a21\u578b\u3001\u8fdb\u884c\u8fc7\u6ce2\u65af\u8bed\u5fae\u8c03\u7684\u6a21\u578b\u4ee5\u53ca\u533b\u5b66\u9886\u57df\u6a21\u578b\uff0c\u5728\u96f6\u6837\u672c\u548c\u601d\u7ef4\u94fe\u6761\u65b9\u6cd5\uff08CoT\uff09\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5c01\u95ed\u6e90\u5e38\u89c4\u6a21\u578b\u5982GPT-4.1\u5728\u6ce2\u65af\u8bed\u548c\u82f1\u8bed\u4e2d\u7684\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523083.3%\u548c80.7%\uff0c\u800c\u6ce2\u65af\u8bed\u5fae\u8c03\u6a21\u578b\u5982Dorna\u8868\u73b0\u8f83\u5dee\uff08\u4f8b\u5982\uff0c\u6ce2\u65af\u8bed\u4e2d\u4ec535.9%\uff09\uff0c\u5728\u6307\u4ee4\u7406\u89e3\u548c\u9886\u57df\u63a8\u7406\u4e0a\u5747\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u8868\u73b0\u4ecd\u6709\u5f85\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u65b9\u9762\u3002\u6784\u5efa\u548c\u4f7f\u7528\u50cfPersianMedQA\u8fd9\u6837\u7684\u4e13\u5bb6\u9a8c\u8bc1\u6570\u636e\u96c6\u53ef\u4ee5\u4e3a\u8bc4\u4f30\u591a\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u533b\u5b66\u63a8\u7406\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2506.00316", "pdf": "https://arxiv.org/pdf/2506.00316", "abs": "https://arxiv.org/abs/2506.00316", "authors": ["Atul Ganju", "Shashaank Aiyer", "Ved Sriraman", "Karthik Sridharan"], "title": "Active Learning via Regression Beyond Realizability", "categories": ["cs.LG"], "comment": null, "summary": "We present a new active learning framework for multiclass classification\nbased on surrogate risk minimization that operates beyond the standard\nrealizability assumption. Existing surrogate-based active learning algorithms\ncrucially rely on realizability$\\unicode{x2014}$the assumption that the optimal\nsurrogate predictor lies within the model class$\\unicode{x2014}$limiting their\napplicability in practical, misspecified settings. In this work we show that\nunder conditions significantly weaker than realizability, as long as the class\nof models considered is convex, one can still obtain a label and sample\ncomplexity comparable to prior work. Despite achieving similar rates, the\nalgorithmic approaches from prior works can be shown to fail in non-realizable\nsettings where our assumption is satisfied. Our epoch-based active learning\nalgorithm departs from prior methods by fitting a model from the full class to\nthe queried data in each epoch and returning an improper classifier obtained by\naggregating these models.", "AI": {"tldr": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u4ee3\u7406\u98ce\u9669\u6700\u5c0f\u5316\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6bd4\u53ef\u5b9e\u73b0\u6027\u5047\u8bbe\u66f4\u5bbd\u677e\u7684\u6761\u4ef6\u4e0b\u6709\u6548\u5de5\u4f5c\uff0c\u63d0\u4f9b\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u7c7b\u4f3c\u7684\u6837\u672c\u548c\u6807\u7b7e\u590d\u6742\u5ea6\u3002", "motivation": "\u8bb8\u591a\u73b0\u6709\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u53ef\u5b9e\u73b0\u6027\u5047\u8bbe\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5b9e\u9645\u7684\u9519\u7528\u8bbe\u7f6e\u4e2d\u7684\u9002\u7528\u6027\u3002\u6211\u4eec\u7684\u52a8\u673a\u662f\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u4f7f\u7b97\u6cd5\u5728\u66f4\u5e7f\u6cdb\u7684\u6761\u4ef6\u4e0b\u6709\u6548\u3002", "method": "\u6211\u4eec\u7684\u7b97\u6cd5\u4f7f\u7528\u4e00\u4e2a\u57fa\u4e8e\u5386\u5143\u7684\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u6bcf\u4e2a\u5386\u5143\u4e2d\u4ece\u5b8c\u6574\u7684\u6a21\u578b\u7c7b\u4e2d\u62df\u5408\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u805a\u5408\u8fd9\u4e9b\u6a21\u578b\u8fd4\u56de\u4e00\u4e2a\u4e0d\u5f53\u5206\u7c7b\u5668\u3002", "result": "\u6211\u4eec\u8bc1\u660e\u4e86\u5728\u975e\u53ef\u5b9e\u73b0\u8bbe\u7f6e\u4e0b\uff0c\u5982\u679c\u6ee1\u8db3\u6211\u4eec\u5047\u8bbe\u7684\u6761\u4ef6\uff0c\u7b97\u6cd5\u7684\u6807\u7b7e\u548c\u6837\u672c\u590d\u6742\u5ea6\u53ef\u4ee5\u4e0e\u4e4b\u524d\u7684\u5de5\u4f5c\u76f8\u5ab2\u7f8e\uff0c\u800c\u4e4b\u524d\u7684\u65b9\u6cd5\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u4f1a\u5931\u8d25\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u7c7b\u5206\u7c7b\u4e3b\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u53ef\u4ee5\u5728\u6bd4\u6807\u51c6\u53ef\u5b9e\u73b0\u6027\u5047\u8bbe\u66f4\u5e7f\u6cdb\u7684\u6761\u4ef6\u4e0b\u8fd0\u884c\u3002\u5c3d\u7ba1\u73b0\u6709\u7684\u57fa\u4e8e\u4ee3\u7406\u98ce\u9669\u6700\u5c0f\u5316\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u53ef\u5b9e\u73b0\u6027\uff0c\u4f46\u6211\u4eec\u5c55\u793a\u4e86\u5728\u5f31\u4e8e\u53ef\u5b9e\u73b0\u6027\u7684\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u8003\u8651\u7684\u6a21\u578b\u7c7b\u662f\u51f8\u7684\uff0c\u4ecd\u7136\u53ef\u4ee5\u83b7\u5f97\u4e0e\u4e4b\u524d\u5de5\u4f5c\u76f8\u5f53\u7684\u6807\u7b7e\u548c\u6837\u672c\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.00618", "pdf": "https://arxiv.org/pdf/2506.00618", "abs": "https://arxiv.org/abs/2506.00618", "authors": ["Jingyi Yang", "Shuai Shao", "Dongrui Liu", "Jing Shao"], "title": "RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents", "categories": ["cs.AI"], "comment": "40 pages, 6 figures, Project Page:\n  https://yjyddq.github.io/RiOSWorld.github.io/", "summary": "With the rapid development of multimodal large language models (MLLMs), they\nare increasingly deployed as autonomous computer-use agents capable of\naccomplishing complex computer tasks. However, a pressing issue arises: Can the\nsafety risk principles designed and aligned for general MLLMs in dialogue\nscenarios be effectively transferred to real-world computer-use scenarios?\nExisting research on evaluating the safety risks of MLLM-based computer-use\nagents suffers from several limitations: it either lacks realistic interactive\nenvironments, or narrowly focuses on one or a few specific risk types. These\nlimitations ignore the complexity, variability, and diversity of real-world\nenvironments, thereby restricting comprehensive risk evaluation for\ncomputer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark\ndesigned to evaluate the potential risks of MLLM-based agents during real-world\ncomputer manipulations. Our benchmark includes 492 risky tasks spanning various\ncomputer applications, involving web, social media, multimedia, os, email, and\noffice software. We categorize these risks into two major classes based on\ntheir risk source: (i) User-originated risks and (ii) Environmental risks. For\nthe evaluation, we evaluate safety risks from two perspectives: (i) Risk goal\nintention and (ii) Risk goal completion. Extensive experiments with multimodal\nagents on \\textbf{RiOSWorld} demonstrate that current computer-use agents\nconfront significant safety risks in real-world scenarios. Our findings\nhighlight the necessity and urgency of safety alignment for computer-use agents\nin real-world computer manipulation, providing valuable insights for developing\ntrustworthy computer-use agents. Our benchmark is publicly available at\nhttps://yjyddq.github.io/RiOSWorld.github.io/.", "AI": {"tldr": "\u5f15\u5165\u540d\u4e3aRiOSWorld\u7684\u57fa\u51c6\uff0c\u4ee5\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u771f\u5b9e\u8ba1\u7b97\u673a\u4efb\u52a1\u4e2d\u7684\u98ce\u9669\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u4ee3\u7406\u9762\u4e34\u91cd\u5927\u5b89\u5168\u98ce\u9669\uff0c\u9700\u7d27\u6025\u8fdb\u884c\u5b89\u5168\u5bf9\u9f50\u3002\u57fa\u51c6\u5df2\u516c\u5f00\u53d1\u5e03\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5b83\u4eec\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u90e8\u7f72\u4e3a\u80fd\u591f\u5b8c\u6210\u590d\u6742\u8ba1\u7b97\u4efb\u52a1\u7684\u81ea\u4e3b\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u3002\u7136\u800c\uff0c\u73b0\u6709\u7814\u7a76\u5728\u8bc4\u4f30\u8fd9\u4e9b\u4ee3\u7406\u7684\u5b89\u5168\u98ce\u9669\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u5f15\u5165\u65b0\u7684\u57fa\u51c6\u6765\u8fdb\u884c\u66f4\u4e3a\u5168\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u4e86\u540d\u4e3aRiOSWorld\u7684\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5305\u62ec492\u4e2a\u5177\u6709\u98ce\u9669\u7684\u4efb\u52a1\uff0c\u6db5\u76d6\u5404\u79cd\u8ba1\u7b97\u673a\u5e94\u7528\u7a0b\u5e8f\uff0c\u98ce\u9669\u5206\u4e3a\u7528\u6237\u6765\u6e90\u98ce\u9669\u548c\u73af\u5883\u98ce\u9669\u4e24\u5927\u7c7b\uff0c\u8bc4\u4f30\u4ece\u98ce\u9669\u76ee\u6807\u610f\u56fe\u548c\u98ce\u9669\u76ee\u6807\u5b8c\u6210\u4e24\u4e2a\u89d2\u5ea6\u8fdb\u884c\u3002", "result": "\u5728RiOSWorld\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u9762\u4e34\u663e\u8457\u7684\u5b89\u5168\u98ce\u9669\uff0c\u8fd9\u7a81\u663e\u4e86\u5bf9\u8fd9\u4e9b\u4ee3\u7406\u8fdb\u884c\u5b89\u5168\u5bf9\u9f50\u7684\u5fc5\u8981\u6027\u548c\u7d27\u8feb\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9762\u4e34\u663e\u8457\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4e14\u9700\u8981\u7d27\u6025\u5730\u8fdb\u884c\u5b89\u5168\u5bf9\u9f50\u3002\u6b64\u5916\uff0c\u8be5\u57fa\u51c6\u4e3a\u5f00\u53d1\u53ef\u4fe1\u4efb\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.00253", "pdf": "https://arxiv.org/pdf/2506.00253", "abs": "https://arxiv.org/abs/2506.00253", "authors": ["Lihao Sun", "Chengzhi Mao", "Valentin Hofmann", "Xuechunzi Bai"], "title": "Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accpeted to ACL 2025 Main Conferencce", "summary": "Although value-aligned language models (LMs) appear unbiased in explicit bias\nevaluations, they often exhibit stereotypes in implicit word association tasks,\nraising concerns about their fair usage. We investigate the mechanisms behind\nthis discrepancy and find that alignment surprisingly amplifies implicit bias\nin model outputs. Specifically, we show that aligned LMs, unlike their\nunaligned counterparts, overlook racial concepts in early internal\nrepresentations when the context is ambiguous. Not representing race likely\nfails to activate safety guardrails, leading to unintended biases. Inspired by\nthis insight, we propose a new bias mitigation strategy that works by\nincentivizing the representation of racial concepts in the early model layers.\nIn contrast to conventional mitigation methods of machine unlearning, our\ninterventions find that steering the model to be more aware of racial concepts\neffectively mitigates implicit bias. Similar to race blindness in humans,\nignoring racial nuances can inadvertently perpetuate subtle biases in LMs.", "AI": {"tldr": "\u5bf9\u9f50\u7684\u8bed\u8a00\u6a21\u578b\u5728\u9690\u6027\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u504f\u89c1\uff0c\u63d0\u51fa\u901a\u8fc7\u5728\u65e9\u671f\u5c42\u6b21\u4e2d\u8868\u793a\u79cd\u65cf\u6982\u5ff5\u6765\u51cf\u5c11\u504f\u89c1\u7684\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u5bf9\u9f50\u7684\u8bed\u8a00\u6a21\u578b\u5728\u9690\u6027\u8bcd\u6c47\u5173\u8054\u4efb\u52a1\u4e2d\u4ecd\u7136\u8868\u73b0\u51fa\u504f\u89c1\u7684\u539f\u56e0\uff0c\u5e0c\u671b\u901a\u8fc7\u65b0\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u504f\u89c1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u504f\u89c1\u7f13\u89e3\u7b56\u7565\uff0c\u901a\u8fc7\u6fc0\u52b1\u6a21\u578b\u5728\u65e9\u671f\u5c42\u6b21\u4e2d\u8868\u793a\u79cd\u65cf\u6982\u5ff5\u6765\u51cf\u5c11\u9690\u6027\u504f\u89c1\u3002", "result": "\u901a\u8fc7\u8ba9\u6a21\u578b\u66f4\u52a0\u610f\u8bc6\u5230\u79cd\u65cf\u6982\u5ff5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9690\u6027\u504f\u89c1\u3002", "conclusion": "\u8003\u8651\u5230\u79cd\u65cf\u5dee\u5f02\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9690\u6027\u504f\u89c1\u3002"}}
{"id": "2506.00329", "pdf": "https://arxiv.org/pdf/2506.00329", "abs": "https://arxiv.org/abs/2506.00329", "authors": ["Muhammad Adnan", "Nithesh Kurella", "Akhil Arunkumar", "Prashant J. Nair"], "title": "Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Diffusion Transformers (DiTs) achieve state-of-the-art results in\ntext-to-image, text-to-video generation, and editing. However, their large\nmodel size and the quadratic cost of spatial-temporal attention over multiple\ndenoising steps make video generation computationally expensive. Static caching\nmitigates this by reusing features across fixed steps but fails to adapt to\ngeneration dynamics, leading to suboptimal trade-offs between speed and\nquality.\n  We propose Foresight, an adaptive layer-reuse technique that reduces\ncomputational redundancy across denoising steps while preserving baseline\nperformance. Foresight dynamically identifies and reuses DiT block outputs for\nall layers across steps, adapting to generation parameters such as resolution\nand denoising schedules to optimize efficiency. Applied to OpenSora, Latte, and\nCogVideoX, Foresight achieves up to 1.63x end-to-end speedup, while maintaining\nvideo quality. The source code of Foresight is available at\n\\texttt{https://github.com/STAR-Laboratory/foresight}.", "AI": {"tldr": "Foresight\u901a\u8fc7\u52a8\u6001\u5c42\u91cd\u7528\u6280\u672f\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u89c6\u9891\u751f\u6210\u4e2d\u7684\u8ba1\u7b97\u5197\u4f59\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u4e14\u4e0d\u5f71\u54cd\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3Diffusion Transformers\u5728\u89c6\u9891\u751f\u6210\u4e2d\u7531\u4e8e\u6a21\u578b\u89c4\u6a21\u5927\u548c\u65f6\u7a7a\u6ce8\u610f\u529b\u7684\u5e73\u65b9\u4ee3\u4ef7\u6240\u5bfc\u81f4\u7684\u8ba1\u7b97\u5f00\u9500\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aForesight\u7684\u81ea\u9002\u5e94\u5c42\u91cd\u7528\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u5e76\u91cd\u7528\u8de8\u6b65\u7684DiT\u5757\u8f93\u51fa\uff0c\u4ee5\u51cf\u5c11\u53bb\u566a\u6b65\u9aa4\u4e2d\u7684\u8ba1\u7b97\u5197\u4f59\u3002", "result": "Foresight\u5728\u4f18\u5316\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u6709\u7684\u57fa\u51c6\u6027\u80fd\uff0c\u5f53\u5e94\u7528\u4e8eOpenSora\u3001Latte\u548cCogVideoX\u7b49\u6a21\u578b\u65f6\uff0c\u8fbe\u5230\u4e86\u663e\u8457\u7684\u52a0\u901f\u6548\u679c\u3002", "conclusion": "Foresight\u5728\u4e0d\u5f71\u54cd\u89c6\u9891\u751f\u6210\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe1.63\u500d\u7684\u7aef\u5230\u7aef\u52a0\u901f\u3002"}}
{"id": "2506.00641", "pdf": "https://arxiv.org/pdf/2506.00641", "abs": "https://arxiv.org/abs/2506.00641", "authors": ["Hanjun Luo", "Shenyu Dai", "Chiming Ni", "Xinfeng Li", "Guibin Zhang", "Kun Wang", "Tongliang Liu", "Hanan Salam"], "title": "AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Despite the rapid advancement of LLM-based agents, the reliable evaluation of\ntheir safety and security remains a significant challenge. Existing rule-based\nor LLM-based evaluators often miss dangers in agents' step-by-step actions,\noverlook subtle meanings, fail to see how small issues compound, and get\nconfused by unclear safety or security rules. To overcome this evaluation\ncrisis, we introduce \\sys, a universal, training-free, memory-augmented\nreasoning framework that empowers LLM evaluators to emulate human expert\nevaluators. \\sys constructs an experiential memory by having an LLM adaptively\nextract structured semantic features (e.g., scenario, risk, behavior) and\ngenerate associated chain-of-thought reasoning traces for past interactions. A\nmulti-stage, context-aware retrieval-augmented generation process then\ndynamically retrieves the most relevant reasoning experiences to guide the LLM\nevaluator's assessment of new cases. Moreover, we developed \\data, the first\nbenchmark designed to check how well LLM-based evaluators can spot both safety\nrisks and security threats. \\data comprises \\textbf{2293} meticulously\nannotated interaction records, covering \\textbf{15} risk types across\n\\textbf{29} application scenarios. A key feature of \\data is its nuanced\napproach to ambiguous risk situations, employing ``Strict'' and ``Lenient''\njudgment standards. Experiments demonstrate that \\sys not only consistently\nimproves the evaluation performance of LLMs across all benchmarks but also sets\na new state-of-the-art in LLM-as-a-judge for agent safety and security,\nachieving human-level accuracy. Our work is openly openly accessible.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\\sys\uff0c\u901a\u8fc7\u589e\u5f3aLLM\u7684\u8bb0\u5fc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\\data\u6570\u636e\u96c6\u8bbe\u7acb\u4e86\u65b0\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u89c4\u5219\u6216LLM\u7684\u8bc4\u4f30\u5668\u5728\u8bc6\u522b\u4ee3\u7406\u9010\u6b65\u884c\u52a8\u4e2d\u7684\u5371\u9669\u3001\u5fae\u5999\u610f\u4e49\u3001\u5c0f\u95ee\u9898\u7684\u79ef\u7d2f\u53ca\u4e0d\u660e\u786e\u5b89\u5168\u548c\u5b89\u5168\u6027\u89c4\u5219\u65f6\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\\sys\uff0c\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u901a\u7528\u8bb0\u5fc6\u589e\u5f3a\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8ba9LLM\u81ea\u9002\u5e94\u63d0\u53d6\u7ed3\u6784\u5316\u7684\u8bed\u4e49\u7279\u5f81\u5e76\u751f\u6210\u8fc7\u53bb\u4ea4\u4e92\u7684\u94fe\u5f0f\u63a8\u7406\u6d41\u4ee5\u6784\u5efa\u7ecf\u9a8c\u8bb0\u5fc6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8fc7\u7a0b\u6765\u5f15\u5bfc\u8bc4\u4f30\u3002", "result": "\\sys\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e00\u81f4\u5730\u63d0\u9ad8\u4e86LLM\u7684\u8bc4\u4f30\u6027\u80fd\uff0c\u5e76\u5728\u4eba\u7c7b\u6c34\u5e73\u7684\u5b89\u5168\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\u8bbe\u7acb\u4e86\u65b0\u7684\u6807\u6746\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\\sys\u6846\u67b6\u6709\u6548\u5730\u63d0\u9ad8\u4e86LLM\u8bc4\u4f30\u5668\u5728\u5b89\u5168\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\u7684\u6027\u80fd\uff0c\u5728\u5168\u90e8\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5e76\u8fbe\u5230\u4e86\u4eba\u7c7b\u4e13\u5bb6\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.00256", "pdf": "https://arxiv.org/pdf/2506.00256", "abs": "https://arxiv.org/abs/2506.00256", "authors": ["Mahammed Kamruzzaman", "Gene Louis Kim"], "title": "The Impact of Disability Disclosure on Fairness and Bias in LLM-Driven Candidate Selection", "categories": ["cs.CL"], "comment": "Accepted at The 38th International FLAIRS Conference (FLAIRS\n  2025)(main)", "summary": "As large language models (LLMs) become increasingly integrated into hiring\nprocesses, concerns about fairness have gained prominence. When applying for\njobs, companies often request/require demographic information, including\ngender, race, and disability or veteran status. This data is collected to\nsupport diversity and inclusion initiatives, but when provided to LLMs,\nespecially disability-related information, it raises concerns about potential\nbiases in candidate selection outcomes. Many studies have highlighted how\ndisability can impact CV screening, yet little research has explored the\nspecific effect of voluntarily disclosed information on LLM-driven candidate\nselection. This study seeks to bridge that gap. When candidates shared\nidentical gender, race, qualifications, experience, and backgrounds, and sought\njobs with minimal employment rate gaps between individuals with and without\ndisabilities (e.g., Cashier, Software Developer), LLMs consistently favored\ncandidates who disclosed that they had no disability. Even in cases where\ncandidates chose not to disclose their disability status, the LLMs were less\nlikely to select them compared to those who explicitly stated they did not have\na disability.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u62db\u8058\u4e2d\u53ef\u80fd\u5bf9\u62ab\u9732\u6b8b\u75be\u72b6\u6001\u7684\u5019\u9009\u4eba\u5b58\u5728\u504f\u89c1\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u62db\u8058\u8fc7\u7a0b\u4e2d\u7684\u4f7f\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u4eba\u4eec\u5bf9\u516c\u5e73\u6027\u7684\u5173\u6ce8\u4e0d\u65ad\u589e\u52a0\uff0c\u5c24\u5176\u662f\u5173\u4e8e\u6b8b\u75be\u76f8\u5173\u4fe1\u606f\u53ef\u80fd\u5bfc\u81f4\u7684\u5019\u9009\u4eba\u9009\u62e9\u7ed3\u679c\u4e2d\u7684\u504f\u89c1\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5728\u62db\u8058\u8fc7\u7a0b\u4e2d\u5904\u7406\u6b8b\u75be\u76f8\u5173\u4fe1\u606f\u8fdb\u884c\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6027\u522b\u3001\u79cd\u65cf\u3001\u8d44\u5386\u3001\u7ecf\u9a8c\u548c\u80cc\u666f\u6761\u4ef6\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u66f4\u503e\u5411\u4e8e\u9009\u62e9\u90a3\u4e9b\u660e\u786e\u8868\u793a\u6ca1\u6709\u6b8b\u75be\u7684\u5019\u9009\u4eba\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u5019\u9009\u4eba\u5728\u6027\u522b\u3001\u79cd\u65cf\u3001\u8d44\u5386\u3001\u7ecf\u9a8c\u548c\u80cc\u666f\u65b9\u9762\u76f8\u540c\uff0c\u5e76\u7533\u8bf7\u5c31\u4e1a\u7387\u5dee\u8ddd\u8f83\u5c0f\u7684\u5de5\u4f5c\u65f6\uff0cLLM\u503e\u5411\u4e8e\u9009\u62e9\u90a3\u4e9b\u62ab\u9732\u6ca1\u6709\u6b8b\u75be\u7684\u5019\u9009\u4eba\uff0c\u5373\u4f7f\u5019\u9009\u4eba\u9009\u62e9\u4e0d\u62ab\u9732\u6b8b\u75be\u72b6\u6001\uff0cLLM\u4e5f\u4e0d\u592a\u53ef\u80fd\u9009\u4e2d\u4ed6\u4eec\u3002"}}
{"id": "2506.00337", "pdf": "https://arxiv.org/pdf/2506.00337", "abs": "https://arxiv.org/abs/2506.00337", "authors": ["Ming Hu", "Jianfu Yin", "Mingyu Dou", "Yuqi Wang", "Ruochen Dang", "Siyi Liang", "Cong Hu", "Yao Wang", "Bingliang Hu", "Quan Wang"], "title": "Channel-Imposed Fusion: A Simple yet Effective Method for Medical Time Series Classification", "categories": ["cs.LG"], "comment": null, "summary": "The automatic classification of medical time series signals, such as\nelectroencephalogram (EEG) and electrocardiogram (ECG), plays a pivotal role in\nclinical decision support and early detection of diseases. Although Transformer\nbased models have achieved notable performance by implicitly modeling temporal\ndependencies through self-attention mechanisms, their inherently complex\narchitectures and opaque reasoning processes undermine their trustworthiness in\nhigh stakes clinical settings. In response to these limitations, this study\nshifts focus toward a modeling paradigm that emphasizes structural\ntransparency, aligning more closely with the intrinsic characteristics of\nmedical data. We propose a novel method, Channel Imposed Fusion (CIF), which\nenhances the signal-to-noise ratio through cross-channel information fusion,\neffectively reduces redundancy, and improves classification performance.\nFurthermore, we integrate CIF with the Temporal Convolutional Network (TCN),\nknown for its structural simplicity and controllable receptive field, to\nconstruct an efficient and explicit classification framework. Experimental\nresults on multiple publicly available EEG and ECG datasets demonstrate that\nthe proposed method not only outperforms existing state-of-the-art (SOTA)\napproaches in terms of various classification metrics, but also significantly\nenhances the transparency of the classification process, offering a novel\nperspective for medical time series classification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u901a\u9053\u4fe1\u606f\u878d\u5408\u548c\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\uff08TCN\uff09\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u900f\u660e\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u867d\u7136\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u901a\u8fc7\u81ea\u6ce8\u610f\u673a\u5236\u5728\u9690\u5f0f\u5efa\u6a21\u65f6\u95f4\u76f8\u5173\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\uff0c\u4f46\u5176\u590d\u6742\u7684\u67b6\u6784\u548c\u4e0d\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\u524a\u5f31\u4e86\u5176\u5728\u9ad8\u98ce\u9669\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u8f6c\u5411\u4e00\u79cd\u5f3a\u8c03\u7ed3\u6784\u900f\u660e\u5ea6\u7684\u5efa\u6a21\u8303\u5f0f\uff0c\u66f4\u52a0\u7b26\u5408\u533b\u5b66\u6570\u636e\u7684\u5185\u5728\u7279\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u79f0\u4e3a\u201c\u901a\u9053\u5f3a\u52a0\u878d\u5408\u201d\uff08CIF\uff09\uff0c\u901a\u8fc7\u8de8\u901a\u9053\u4fe1\u606f\u878d\u5408\u589e\u5f3a\u4fe1\u566a\u6bd4\uff0c\u6709\u6548\u51cf\u5c11\u5197\u4f59\u5e76\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u5c06CIF\u4e0e\u5177\u6709\u7ed3\u6784\u7b80\u5355\u6027\u548c\u53ef\u63a7\u611f\u53d7\u91ce\u7684\u65f6\u95f4\u5377\u79ef\u7f51\u7edc\uff08TCN\uff09\u96c6\u6210\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u6548\u800c\u660e\u786e\u7684\u5206\u7c7b\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u7684EEG\u548cECG\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u5404\u79cd\u5206\u7c7b\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u8fd8\u663e\u8457\u589e\u5f3a\u4e86\u5206\u7c7b\u8fc7\u7a0b\u7684\u900f\u660e\u6027\uff0c\u4e3a\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u4e2a\u516c\u5171EEG\u548cECG\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u591a\u79cd\u5206\u7c7b\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u65b0\u65b9\u6cd5\uff0c\u8fd8\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u8fc7\u7a0b\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2506.00664", "pdf": "https://arxiv.org/pdf/2506.00664", "abs": "https://arxiv.org/abs/2506.00664", "authors": ["Yash Tiwari", "Owais Ahmad Lone", "Mayukha Pal"], "title": "OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Ontologies are pivotal for structuring knowledge bases to enhance question\nanswering (QA) systems powered by Large Language Models (LLMs). However,\ntraditional ontology creation relies on manual efforts by domain experts, a\nprocess that is time intensive, error prone, and impractical for large, dynamic\nknowledge domains. This paper introduces OntoRAG, an automated pipeline\ndesigned to derive ontologies from unstructured knowledge bases, with a focus\non electrical relay documents. OntoRAG integrates advanced techniques,\nincluding web scraping, PDF parsing, hybrid chunking, information extraction,\nknowledge graph construction, and ontology creation, to transform unstructured\ndata into a queryable ontology. By leveraging LLMs and graph based methods,\nOntoRAG enhances global sensemaking capabilities, outperforming conventional\nRetrieval Augmented Generation (RAG) and GraphRAG approaches in\ncomprehensiveness and diversity. Experimental results demonstrate OntoRAGs\neffectiveness, achieving a comprehensiveness win rate of 85% against vector RAG\nand 75% against GraphRAGs best configuration. This work addresses the critical\nchallenge of automating ontology creation, advancing the vision of the semantic\nweb.", "AI": {"tldr": "OntoRAG automatically creates ontologies from unstructured data, improving over traditional methods and enhancing semantic web vision with better comprehensiveness and diversity.", "motivation": "Traditional ontology creation is manual, error-prone, time-intensive, especially for large dynamic knowledge domains.", "method": "Integrates web scraping, PDF parsing, hybrid chunking, information extraction, knowledge graph construction, ontology creation into a single pipeline.", "result": "OntoRAG demonstrated a win rate of 85% over vector RAG and 75% against GraphRAG's best configuration in comprehensiveness.", "conclusion": "OntoRAG enhances ontology creation from unstructured data efficiently, outperforming conventional methods."}}
{"id": "2506.00264", "pdf": "https://arxiv.org/pdf/2506.00264", "abs": "https://arxiv.org/abs/2506.00264", "authors": ["Mohammadamin Shafiei", "Hamidreza Saffari", "Nafise Sadat Moosavi"], "title": "MultiHoax: A Dataset of Multi-hop False-Premise Questions", "categories": ["cs.CL"], "comment": null, "summary": "As Large Language Models are increasingly deployed in high-stakes domains,\ntheir ability to detect false assumptions and reason critically is crucial for\nensuring reliable outputs. False-premise questions (FPQs) serve as an important\nevaluation method by exposing cases where flawed assumptions lead to incorrect\nresponses. While existing benchmarks focus on single-hop FPQs, real-world\nreasoning often requires multi-hop inference, where models must verify\nconsistency across multiple reasoning steps rather than relying on\nsurface-level cues. To address this gap, we introduce MultiHoax, a benchmark\nfor evaluating LLMs' ability to handle false premises in complex, multi-step\nreasoning tasks. Our dataset spans seven countries and ten diverse knowledge\ncategories, using Wikipedia as the primary knowledge source to enable factual\nreasoning across regions. Experiments reveal that state-of-the-art LLMs\nstruggle to detect false premises across different countries, knowledge\ncategories, and multi-hop reasoning types, highlighting the need for improved\nfalse premise detection and more robust multi-hop reasoning capabilities in\nLLMs.", "AI": {"tldr": "\u5f15\u5165MultiHoax\uff0c\u8bc4\u4f30LLM\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u4e2d\u5904\u7406\u9519\u8bef\u524d\u63d0\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u73b0\u6709\u6a21\u578b\u5728\u591a\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e94\u7528\uff0c\u5176\u68c0\u6d4b\u9519\u8bef\u5047\u8bbe\u548c\u8fdb\u884c\u6279\u5224\u6027\u63a8\u7406\u7684\u80fd\u529b\u5bf9\u4e8e\u786e\u4fdd\u53ef\u9760\u8f93\u51fa\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8bc4\u4f30\u6a21\u578b\u5904\u7406\u591a\u8df3\u9519\u8bef\u524d\u63d0\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMultiHoax\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30LLM\u5728\u590d\u6742\u3001\u591a\u6b65\u9aa4\u63a8\u7406\u4efb\u52a1\u4e2d\u5904\u7406\u9519\u8bef\u524d\u63d0\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684LLM\u5728\u68c0\u6d4b\u8de8\u56fd\u5bb6\u3001\u77e5\u8bc6\u7c7b\u522b\u548c\u591a\u8df3\u63a8\u7406\u7c7b\u578b\u4e2d\u7684\u9519\u8bef\u524d\u63d0\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "conclusion": "\u5f53\u524d\u7684LLM\u5728\u5904\u7406\u590d\u6742\u7684\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8bc6\u522b\u9519\u8bef\u524d\u63d0\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u9700\u8981\u6539\u8fdb\u76f8\u5173\u68c0\u6d4b\u673a\u5236\u548c\u589e\u5f3a\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2506.00356", "pdf": "https://arxiv.org/pdf/2506.00356", "abs": "https://arxiv.org/abs/2506.00356", "authors": ["Rorry Brenner", "Evan Davis", "Rushi Chaudhari", "Rowan Morse", "Jingyao Chen", "Xirui Liu", "Zhaoyi You", "Laurent Itti"], "title": "Exploring the Performance of Perforated Backpropagation through Further Experiments", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 7 figures, 1 table", "summary": "Perforated Backpropagation is a neural network optimization technique based\non modern understanding of the computational importance of dendrites within\nbiological neurons. This paper explores further experiments from the original\npublication, generated from a hackathon held at the Carnegie Mellon Swartz\nCenter in February 2025. Students and local Pittsburgh ML practitioners were\nbrought together to experiment with the Perforated Backpropagation algorithm on\nthe datasets and models which they were using for their projects. Results\nshowed that the system could enhance their projects, with up to 90% model\ncompression without negative impact on accuracy, or up to 16% increased\naccuracy of their original models.", "AI": {"tldr": "Perforated Backpropagation, inspired by biological neurons, can compress models by 90% without losing accuracy and improve accuracy by up to 16%.", "motivation": "To investigate the effectiveness of Perforated Backpropagation in optimizing neural networks based on biological neuron understanding.", "method": "Exploration and experimentation with the Perforated Backpropagation algorithm on various datasets and models during a hackathon.", "result": "The system achieved up to 90% model compression without loss of accuracy and up to 16% increased accuracy.", "conclusion": "Perforated Backpropagation can enhance projects by offering significant model compression and accuracy improvements."}}
{"id": "2506.00708", "pdf": "https://arxiv.org/pdf/2506.00708", "abs": "https://arxiv.org/abs/2506.00708", "authors": ["Yongkang Xiao", "Sinian Zhang", "Yi Dai", "Huixue Zhou", "Jue Hou", "Jie Ding", "Rui Zhang"], "title": "DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Knowledge graph completion (KGC) aims to predict missing triples in knowledge\ngraphs (KGs) by leveraging existing triples and textual information. Recently,\ngenerative large language models (LLMs) have been increasingly employed for\ngraph tasks. However, current approaches typically encode graph context in\ntextual form, which fails to fully exploit the potential of LLMs for perceiving\nand reasoning about graph structures. To address this limitation, we propose\nDrKGC (Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph\nCompletion). DrKGC employs a flexible lightweight model training strategy to\nlearn structural embeddings and logical rules within the KG. It then leverages\na novel bottom-up graph retrieval method to extract a subgraph for each query\nguided by the learned rules. Finally, a graph convolutional network (GCN)\nadapter uses the retrieved subgraph to enhance the structural embeddings, which\nare then integrated into the prompt for effective LLM fine-tuning. Experimental\nresults on two general domain benchmark datasets and two biomedical datasets\ndemonstrate the superior performance of DrKGC. Furthermore, a realistic case\nstudy in the biomedical domain highlights its interpretability and practical\nutility.", "AI": {"tldr": "DrKGC\u901a\u8fc7\u52a8\u6001\u5b50\u56fe\u68c0\u7d22\u6cd5\u548c\u56fe\u5377\u79ef\u7f51\u7edc\u9002\u914d\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u5b8c\u5907\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u77e5\u8bc6\u56fe\u8c31\u5b8c\u5907\u65b9\u6cd5\u901a\u5e38\u4ee5\u6587\u672c\u5f62\u5f0f\u7f16\u7801\u56fe\u7684\u4e0a\u4e0b\u6587\uff0c\u8fd9\u79cd\u65b9\u5f0f\u672a\u80fd\u5145\u5206\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7ed3\u6784\u611f\u77e5\u548c\u63a8\u7406\u65b9\u9762\u7684\u6f5c\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e86DrKGC\u3002", "method": "DrKGC\u901a\u8fc7\u7075\u6d3b\u8f7b\u91cf\u7684\u6a21\u578b\u8bad\u7ec3\u7b56\u7565\u6765\u5b66\u4e60\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7ed3\u6784\u5d4c\u5165\u548c\u903b\u8f91\u89c4\u5219\uff0c\u968f\u540e\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u5e95\u5411\u4e0a\u7684\u56fe\u68c0\u7d22\u65b9\u6cd5\uff0c\u6839\u636e\u5b66\u4e60\u5230\u7684\u89c4\u5219\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u63d0\u53d6\u5b50\u56fe\u3002\u6700\u540e\uff0c\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u9002\u914d\u5668\u6765\u589e\u5f3a\u7ed3\u6784\u5d4c\u5165\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u63d0\u793a\u4e2d\uff0c\u4ee5\u6709\u6548\u8fdb\u884c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u3002", "result": "\u5728\u4e24\u4e2a\u901a\u7528\u9886\u57df\u57fa\u51c6\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86DrKGC\u7684\u5353\u8d8a\u6027\u80fd\u3002\u6b64\u5916\uff0c\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u51f8\u663e\u4e86\u5176\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "DrKGC\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u5b50\u56fe\u68c0\u7d22\u548c\u589e\u5f3a\u7684\u7ed3\u6784\u5d4c\u5165\uff0c\u6709\u6548\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u5b8c\u5907\u4efb\u52a1\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u826f\u597d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.00267", "pdf": "https://arxiv.org/pdf/2506.00267", "abs": "https://arxiv.org/abs/2506.00267", "authors": ["Cihan Xiao", "Ruixing Liang", "Xiangyu Zhang", "Mehmet Emre Tiryaki", "Veronica Bae", "Lavanya Shankar", "Rong Yang", "Ethan Poon", "Emmanuel Dupoux", "Sanjeev Khudanpur", "Leibny Paola Garcia Perera"], "title": "CASPER: A Large Scale Spontaneous Speech Dataset", "categories": ["cs.CL"], "comment": null, "summary": "The success of large language models has driven interest in developing\nsimilar speech processing capabilities. However, a key challenge is the\nscarcity of high-quality spontaneous speech data, as most existing datasets\ncontain scripted dialogues. To address this, we present a novel pipeline for\neliciting and recording natural dialogues and release our Stage 1 dataset with\n200+ hours of spontaneous speech. Our approach fosters fluid, natural\nconversations while encouraging a diverse range of topics and interactive\nexchanges. Unlike traditional methods, it facilitates genuine interactions,\nproviding a reproducible framework for future data collection. This paper\nintroduces our dataset and methodology, laying the groundwork for addressing\nthe shortage of spontaneous speech data. We plan to expand this dataset in\nfuture stages, offering a growing resource for the research community.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u6d41\u7a0b\uff0c\u4ee5\u4fc3\u8fdb\u81ea\u7136\u5bf9\u8bdd\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a200\u5c0f\u65f6\u7684\u81ea\u53d1\u8bed\u97f3\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u81ea\u53d1\u8bed\u97f3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6210\u529f\u6fc0\u53d1\u4e86\u5bf9\u7c7b\u4f3c\u8bed\u97f3\u5904\u7406\u80fd\u529b\u7684\u5174\u8da3\uff0c\u800c\u81ea\u53d1\u8bed\u97f3\u6570\u636e\u7684\u7a00\u7f3a\u662f\u5173\u952e\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u7a0b\u4ee5\u5f15\u51fa\u548c\u8bb0\u5f55\u81ea\u7136\u5bf9\u8bdd\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b200\u591a\u4e2a\u5c0f\u65f6\u81ea\u53d1\u8bed\u97f3\u7684Stage 1\u6570\u636e\u96c6\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\uff0c\u4fc3\u8fdb\u771f\u6b63\u7684\u4e92\u52a8\uff0c\u5e76\u4e3a\u672a\u6765\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u6846\u67b6\u3002\u6211\u4eec\u8ba1\u5212\u5728\u672a\u6765\u9636\u6bb5\u6269\u5c55\u6b64\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u754c\u63d0\u4f9b\u4e00\u4e2a\u4e0d\u65ad\u589e\u957f\u7684\u8d44\u6e90\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u6d41\u7545\u3001\u81ea\u7136\u7684\u5bf9\u8bdd\uff0c\u5e76\u9f13\u52b1\u591a\u6837\u5316\u7684\u8bdd\u9898\u548c\u4e92\u52a8\u4ea4\u6d41\uff0c\u4e3a\u672a\u6765\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u6846\u67b6\u3002"}}
{"id": "2506.00362", "pdf": "https://arxiv.org/pdf/2506.00362", "abs": "https://arxiv.org/abs/2506.00362", "authors": ["Hoang T. Nguyen", "Priya L. Donti"], "title": "FSNet: Feasibility-Seeking Neural Network for Constrained Optimization with Guarantees", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Efficiently solving constrained optimization problems is crucial for numerous\nreal-world applications, yet traditional solvers are often computationally\nprohibitive for real-time use. Machine learning-based approaches have emerged\nas a promising alternative to provide approximate solutions at faster speeds,\nbut they struggle to strictly enforce constraints, leading to infeasible\nsolutions in practice. To address this, we propose the\nFeasibility-Seeking-Integrated Neural Network (FSNet), which integrates a\nfeasibility-seeking step directly into its solution procedure to ensure\nconstraint satisfaction. This feasibility-seeking step solves an unconstrained\noptimization problem that minimizes constraint violations in a differentiable\nmanner, enabling end-to-end training and providing guarantees on feasibility\nand convergence. Our experiments across a range of different optimization\nproblems, including both smooth/nonsmooth and convex/nonconvex problems,\ndemonstrate that FSNet can provide feasible solutions with solution quality\ncomparable to (or in some cases better than) traditional solvers, at\nsignificantly faster speeds.", "AI": {"tldr": "FSNet\u901a\u8fc7\u96c6\u6210\u53ef\u884c\u6027\u6b65\u9aa4\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u7ea6\u675f\u95ee\u9898\uff0c\u4ee5\u66f4\u5feb\u7684\u901f\u5ea6\u63d0\u4f9b\u53ef\u884c\u89e3\uff0c\u8d28\u91cf\u5ab2\u7f8e\u6216\u4f18\u4e8e\u4f20\u7edf\u6c42\u89e3\u5668\u3002", "motivation": "\u4f20\u7edf\u6c42\u89e3\u5668\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u5f80\u5f80\u5728\u8ba1\u7b97\u65b9\u9762\u53d7\u5230\u9650\u5236\uff0c\u800c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u867d\u7136\u901f\u5ea6\u66f4\u5feb\uff0c\u4f46\u96be\u4ee5\u4e25\u683c\u6267\u884c\u7ea6\u675f\uff0c\u5bfc\u81f4\u89e3\u51b3\u65b9\u6848\u5728\u5b9e\u8df5\u4e2d\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51faFSNet\u4ee5\u786e\u4fdd\u7ea6\u675f\u6ee1\u8db3\u3002", "method": "FSNet\u901a\u8fc7\u5728\u5176\u89e3\u51b3\u65b9\u6848\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u96c6\u6210\u4e00\u4e2a\u5bfb\u6c42\u53ef\u884c\u6027\u6b65\u9aa4\uff0c\u89e3\u51b3\u65e0\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4ee5\u5fae\u5206\u65b9\u5f0f\u6700\u5c0f\u5316\u7ea6\u675f\u8fdd\u53cd\uff0c\u4ece\u800c\u5b9e\u73b0\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u5e76\u63d0\u4f9b\u5173\u4e8e\u53ef\u884c\u6027\u548c\u6536\u655b\u6027\u7684\u4fdd\u8bc1\u3002", "result": "FSNet\u5728\u4e00\u7cfb\u5217\u4e0d\u540c\u7684\u4f18\u5316\u95ee\u9898\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5305\u62ec\u5149\u6ed1/\u975e\u5149\u6ed1\u548c\u51f8/\u975e\u51f8\u95ee\u9898\uff0c\u8bc1\u660e\u5176\u80fd\u63d0\u4f9b\u4e0e\u4f20\u7edf\u6c42\u89e3\u5668\u76f8\u5f53\uff08\u6216\u66f4\u597d\uff09\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e14\u901f\u5ea6\u66f4\u5feb\u3002", "conclusion": "FSNet\u80fd\u591f\u5728\u6bd4\u4f20\u7edf\u6c42\u89e3\u5668\u663e\u8457\u66f4\u5feb\u7684\u901f\u5ea6\u4e0b\u63d0\u4f9b\u5177\u6709\u53ef\u884c\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e14\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u65b9\u9762\u53ef\u4ee5\u4e0e\u4f20\u7edf\u6c42\u89e3\u5668\u5ab2\u7f8e\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2506.00751", "pdf": "https://arxiv.org/pdf/2506.00751", "abs": "https://arxiv.org/abs/2506.00751", "authors": ["Zhuojun Gu", "Quan Wang", "Shuchu Han"], "title": "Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) highlight the need to align\ntheir behaviors with human values. A critical, yet understudied, issue is the\npotential divergence between an LLM's stated preferences (its reported\nalignment with general principles) and its revealed preferences (inferred from\ndecisions in contextualized scenarios). Such deviations raise fundamental\nconcerns for the interpretability, trustworthiness, reasoning transparency, and\nethical deployment of LLMs, particularly in high-stakes applications. This work\nformally defines and proposes a method to measure this preference deviation. We\ninvestigate how LLMs may activate different guiding principles in specific\ncontexts, leading to choices that diverge from previously stated general\nprinciples. Our approach involves crafting a rich dataset of well-designed\nprompts as a series of forced binary choices and presenting them to LLMs. We\ncompare LLM responses to general principle prompts stated preference with LLM\nresponses to contextualized prompts revealed preference, using metrics like KL\ndivergence to quantify the deviation. We repeat the analysis across different\ncategories of preferences and on four mainstream LLMs and find that a minor\nchange in prompt format can often pivot the preferred choice regardless of the\npreference categories and LLMs in the test. This prevalent phenomenon\nhighlights the lack of understanding and control of the LLM decision-making\ncompetence. Our study will be crucial for integrating LLMs into services,\nespecially those that interact directly with humans, where morality, fairness,\nand social responsibilities are crucial dimensions. Furthermore, identifying or\nbeing aware of such deviation will be critically important as LLMs are\nincreasingly envisioned for autonomous agentic tasks where continuous human\nevaluation of all LLMs' intermediary decision-making steps is impossible.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cLLMs\u5728\u7279\u5b9a\u60c5\u5883\u4e0b\u7684\u504f\u597d\u9009\u62e9\u53ef\u80fd\u504f\u79bb\u5176\u58f0\u660e\u7684\u4e00\u822c\u539f\u5219\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u8bbe\u8ba1\u597d\u7684\u63d0\u793a\u96c6\u8fdb\u884c\u91cf\u5316\u6d4b\u91cf\u3002\u8fd9\u4e00\u73b0\u8c61\u5bf9LLMs\u7684\u53ef\u4fe1\u90e8\u7f72\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u548c\u63a7\u5236LLMs\u5728\u5177\u4f53\u60c5\u5883\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u504f\u597d\u504f\u79bb\u73b0\u8c61\uff0c\u8fd9\u5bf9\u4e8eLLMs\u7684\u89e3\u91ca\u6027\u3001\u53ef\u4fe1\u6027\u3001\u63a8\u7406\u900f\u660e\u6027\u53ca\u4f26\u7406\u90e8\u7f72\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6211\u4eec\u8bbe\u8ba1\u4e00\u4e2a\u5305\u542b\u5f3a\u5236\u4e8c\u9009\u4e00\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5c06\u5176\u5448\u73b0\u7ed9LLMs\uff0c\u4ee5\u6bd4\u8f83\u5176\u5728\u4e00\u822c\u539f\u5219\u63d0\u793a\uff08\u58f0\u79f0\u504f\u597d\uff09\u4e0e\u60c5\u5883\u5316\u63d0\u793a\uff08\u63ed\u793a\u504f\u597d\uff09\u4e0b\u7684\u53cd\u5e94\uff0c\u4f7f\u7528KL\u6563\u5ea6\u7b49\u6307\u6807\u91cf\u5316\u504f\u5dee\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u504f\u597d\u7c7b\u522b\u548c\u4e3b\u6d41LLMs\u4e0a\uff0c\u4e00\u4e2a\u5fae\u5c0f\u7684\u63d0\u793a\u683c\u5f0f\u53d8\u5316\u5e38\u5e38\u4f1a\u9020\u6210\u504f\u597d\u9009\u62e9\u7684\u6539\u53d8\uff0c\u8fd9\u4e00\u666e\u904d\u73b0\u8c61\u7a81\u663e\u4e86\u5bf9LLMs\u51b3\u7b56\u80fd\u529b\u7684\u7406\u89e3\u548c\u63a7\u5236\u7684\u7f3a\u4e4f\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9762\u4e34\u5177\u4f53\u4e0a\u4e0b\u6587\u65f6\uff0c\u53ef\u80fd\u4f1a\u504f\u79bb\u5176\u5148\u524d\u58f0\u660e\u7684\u539f\u5219\u504f\u597d\uff0c\u8fd9\u8868\u660e\u5f53\u524d\u5bf9LLMs\u51b3\u7b56\u80fd\u529b\u7684\u7406\u89e3\u548c\u63a7\u5236\u4e0d\u8db3\u3002\u5728\u5404\u79cd\u504f\u597d\u548c\u591a\u6b3e\u4e3b\u6d41LLMs\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u63d0\u793a\u683c\u5f0f\u7684\u5fae\u5c0f\u53d8\u5316\u4f1a\u5bfc\u81f4\u504f\u597d\u9009\u62e9\u7684\u53d8\u5316\u3002"}}
{"id": "2506.00277", "pdf": "https://arxiv.org/pdf/2506.00277", "abs": "https://arxiv.org/abs/2506.00277", "authors": ["Hans W. A. Hanley", "Zakir Durumeric"], "title": "Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings", "categories": ["cs.CL", "cs.AI", "cs.SI"], "comment": "Accepted to The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Contextual large language model embeddings are increasingly utilized for\ntopic modeling and clustering. However, current methods often scale poorly,\nrely on opaque similarity metrics, and struggle in multilingual settings. In\nthis work, we present a novel, scalable, interpretable, hierarchical, and\nmultilingual approach to clustering news articles and social media data. To do\nthis, we first train multilingual Matryoshka embeddings that can determine\nstory similarity at varying levels of granularity based on which subset of the\ndimensions of the embeddings is examined. This embedding model achieves\nstate-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson\n$\\rho$ = 0.816). Once trained, we develop an efficient hierarchical clustering\nalgorithm that leverages the hierarchical nature of Matryoshka embeddings to\nidentify unique news stories, narratives, and themes. We conclude by\nillustrating how our approach can identify and cluster stories, narratives, and\noverarching themes within real-world news datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u3001\u5c42\u6b21\u5316\u53ca\u591a\u8bed\u8a00\u7684\u65b0\u95fb\u6587\u7ae0\u548c\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u805a\u7c7b\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u8bed\u8a00Matryoshka\u5d4c\u5165\u548c\u76f8\u5e94\u7684\u5206\u5c42\u805a\u7c7b\u7b97\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u96be\u4ee5\u89e3\u91ca\u3002\u6211\u4eec\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u53ef\u89e3\u91ca\u7684\u5c42\u6b21\u5316\u548c\u591a\u8bed\u8a00\u7684\u65b0\u95fb\u6587\u7ae0\u548c\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u9996\u5148\u8bad\u7ec3\u591a\u8bed\u8a00\u7684Matryoshka\u5d4c\u5165\uff0c\u7528\u4e8e\u786e\u5b9a\u6545\u4e8b\u76f8\u4f3c\u6027\uff0c\u7136\u540e\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5206\u5c42\u805a\u7c7b\u7b97\u6cd5\uff0c\u5229\u7528Matryoshka\u5d4c\u5165\u7684\u5c42\u6b21\u7ed3\u6784\u6765\u8bc6\u522b\u72ec\u7279\u7684\u65b0\u95fb\u6545\u4e8b\u3001\u53d9\u8ff0\u548c\u4e3b\u9898\u3002", "result": "\u5728SemEval 2022 Task 8\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\uff0c\u6211\u4eec\u7684\u5d4c\u5165\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff08Pearson \u03c1 = 0.816\uff09\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u8bc6\u522b\u548c\u805a\u7c7b\u771f\u5b9e\u4e16\u754c\u65b0\u95fb\u6570\u636e\u96c6\u4e2d\u7684\u6545\u4e8b\u3001\u53d9\u8ff0\u548c\u4e3b\u9898\u3002"}}
{"id": "2506.00382", "pdf": "https://arxiv.org/pdf/2506.00382", "abs": "https://arxiv.org/abs/2506.00382", "authors": ["Xuyuan Liu", "Lei Hsiung", "Yaoqing Yang", "Yujun Yan"], "title": "Spectral Insights into Data-Oblivious Critical Layers in Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by Findings of ACL2025", "summary": "Understanding how feature representations evolve across layers in large\nlanguage models (LLMs) is key to improving their interpretability and\nrobustness. While recent studies have identified critical layers linked to\nspecific functions or behaviors, these efforts typically rely on data-dependent\nanalyses of fine-tuned models, limiting their use to post-hoc settings. In\ncontrast, we introduce a data-oblivious approach to identify intrinsic critical\nlayers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered\nKernel Alignment(CKA). We show that layers with significant shifts in\nrepresentation space are also those most affected during fine-tuning--a pattern\nthat holds consistently across tasks for a given model. Our spectral analysis\nfurther reveals that these shifts are driven by changes in the top principal\ncomponents, which encode semantic transitions from rationales to conclusions.\nWe further apply these findings to two practical scenarios: efficient domain\nadaptation, where fine-tuning critical layers leads to greater loss reduction\ncompared to non-critical layers; and backdoor defense, where freezing them\nreduces attack success rates by up to 40%.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7CKA\u65b9\u6cd5\u8bc6\u522bLLMs\u4e2d\u7684\u5173\u952e\u5c42\uff0c\u53d1\u73b0\u8fd9\u4e9b\u5c42\u5728\u5fae\u8c03\u4e2d\u53d7\u5230\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u5728\u5b9e\u9645\u4e2d\u53ef\u7528\u4e8e\u63d0\u9ad8\u57df\u9002\u5e94\u6548\u7387\u548c\u589e\u5f3a\u540e\u95e8\u9632\u5fa1\u3002", "motivation": "\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u660e\u786e\u4e86\u89e3\u4e0d\u540c\u5c42\u7279\u5f81\u8868\u793a\u7684\u6f14\u53d8\u8fc7\u7a0b\u53ca\u5176\u5bf9\u6a21\u578b\u529f\u80fd\u548c\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e2d\u5fc3\u6838\u5bf9\u9f50\uff08CKA\uff09\u7684\u8868\u793a\u52a8\u6001\u6765\u8bc6\u522b\u672a\u8fdb\u884c\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4e2d\u7684\u5185\u5728\u5173\u952e\u5c42\u3002", "result": "\u5728\u5fae\u8c03\u5173\u952e\u5c42\u65f6\uff0c\u76f8\u8f83\u4e8e\u975e\u5173\u952e\u5c42\u9020\u6210\u7684\u635f\u5931\u51cf\u5c0f\u66f4\u5927\uff1b\u5728\u540e\u95e8\u653b\u51fb\u9632\u5fa1\u4e2d\uff0c\u51bb\u7ed3\u5173\u952e\u5c42\u53ef\u4f7f\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e\u81f3\u591a40%\u3002", "conclusion": "\u53d1\u73b0\u8868\u793a\u7a7a\u95f4\u4e2d\u53d1\u751f\u663e\u8457\u53d8\u5316\u7684\u5c42\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53d7\u5230\u7684\u5f71\u54cd\u6700\u5927\uff0c\u8fd9\u662f\u5728\u7ed9\u5b9a\u6a21\u578b\u7684\u4efb\u52a1\u4e2d\u4e00\u81f4\u7684\u73b0\u8c61\u3002"}}
{"id": "2506.00765", "pdf": "https://arxiv.org/pdf/2506.00765", "abs": "https://arxiv.org/abs/2506.00765", "authors": ["Shengkun Wang", "Yanshen Sun", "Fanglan Chen", "Linhan Wang", "Naren Ramakrishnan", "Chang-Tien Lu", "Yinlin Chen"], "title": "HouseTS: A Large-Scale, Multimodal Spatiotemporal U.S. Housing Dataset", "categories": ["cs.AI"], "comment": null, "summary": "Accurate house-price forecasting is essential for investors, planners, and\nresearchers. However, reproducible benchmarks with sufficient spatiotemporal\ndepth and contextual richness for long horizon prediction remain scarce. To\naddress this, we introduce HouseTS a large scale, multimodal dataset covering\nmonthly house prices from March 2012 to December 2023 across 6,000 ZIP codes in\n30 major U.S. metropolitan areas. The dataset includes over 890K records,\nenriched with points of Interest (POI), socioeconomic indicators, and detailed\nreal estate metrics. To establish standardized performance baselines, we\nevaluate 14 models, spanning classical statistical approaches, deep neural\nnetworks (DNNs), and pretrained time-series foundation models. We further\ndemonstrate the value of HouseTS in a multimodal case study, where a vision\nlanguage model extracts structured textual descriptions of geographic change\nfrom time stamped satellite imagery. This enables interpretable, grounded\ninsights into urban evolution. HouseTS is hosted on Kaggle, while all\npreprocessing pipelines, benchmark code, and documentation are openly\nmaintained on GitHub to ensure full reproducibility and easy adoption.", "AI": {"tldr": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u540d\u4e3aHouseTS\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u4f4f\u623f\u4ef7\u683c\u9884\u6d4b\uff0c\u5e76\u5229\u7528\u591a\u79cd\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u6a21\u6001\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u957f\u65f6\u8de8\u5ea6\u9884\u6d4b\u4e2d\u5177\u5907\u8db3\u591f\u7684\u65f6\u7a7a\u6df1\u5ea6\u548c\u80cc\u666f\u4e30\u5bcc\u7684\u53ef\u590d\u73b0\u57fa\u51c6\u7a00\u7f3a\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4ee5\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u5728\u4f4f\u623f\u4ef7\u683c\u9884\u6d4b\u4e2d\u5efa\u7acb\u6807\u51c6\u5316\u6027\u80fd\u57fa\u7ebf\u3002", "method": "\u901a\u8fc7\u5f15\u5165HouseTS\u6570\u636e\u96c6\uff0c\u91c7\u7528\u591a\u79cd\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5305\u62ec\u7ecf\u5178\u7edf\u8ba1\u65b9\u6cd5\u3001\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u9884\u8bad\u7ec3\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u3002\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4ece\u65f6\u95f4\u6233\u7684\u536b\u661f\u56fe\u50cf\u4e2d\u63d0\u53d6\u5730\u7406\u53d8\u66f4\u7684\u7ed3\u6784\u5316\u6587\u672c\u63cf\u8ff0\uff0c\u8fdb\u884c\u591a\u6a21\u6001\u5206\u6790\u3002", "result": "\u5229\u7528\u65b0\u7684HouseTS\u6570\u636e\u96c6\u5728\u591a\u79cd\u6a21\u578b\u4e0b\u8fdb\u884c\u4e86\u6807\u51c6\u5316\u7684\u6027\u80fd\u57fa\u7ebf\u8bc4\u4f30\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0d\u540c\u80cc\u666f\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u6a21\u6001\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6570\u636e\u96c6\u7684\u9644\u52a0\u4ef7\u503c\u3002", "conclusion": "HouseTS\u6570\u636e\u96c6\u901a\u8fc7\u591a\u6837\u7684\u6a21\u578b\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u7814\u7a76\u4f4f\u623f\u4ef7\u683c\u9884\u6d4b\u4e2d\u7684\u72ec\u7279\u4ef7\u503c\uff0c\u5e76\u5728\u591a\u6a21\u6001\u6848\u4f8b\u7814\u7a76\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.00288", "pdf": "https://arxiv.org/pdf/2506.00288", "abs": "https://arxiv.org/abs/2506.00288", "authors": ["Ahmed Elhady", "Eneko Agirre", "Mikel Artetxe"], "title": "Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in ACL 2025 Main", "summary": "Continued pretraining (CPT) is a popular approach to adapt existing large\nlanguage models (LLMs) to new languages. When doing so, it is common practice\nto include a portion of English data in the mixture, but its role has not been\ncarefully studied to date. In this work, we show that including English does\nnot impact validation perplexity, yet it is critical for the emergence of\ndownstream capabilities in the target language. We introduce a\nlanguage-agnostic benchmark for in-context learning (ICL), which reveals\ncatastrophic forgetting early on CPT when English is not included. This in turn\ndamages the ability of the model to generalize to downstream prompts in the\ntarget language as measured by perplexity, even if it does not manifest in\nterms of accuracy until later in training, and can be tied to a big shift in\nthe model parameters. Based on these insights, we introduce curriculum learning\nand exponential moving average (EMA) of weights as effective alternatives to\nmitigate the need for English. All in all, our work sheds light into the\ndynamics by which emergent abilities arise when doing CPT for language\nadaptation, and can serve as a foundation to design more effective methods in\nthe future.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0CPT\u4e2d\u52a0\u5165\u82f1\u8bed\u6570\u636e\u6709\u52a9\u4e8e\u76ee\u6807\u8bed\u8a00\u80fd\u529b\u7684\u51fa\u73b0\uff0c\u5f15\u5165\u8bfe\u7a0b\u5b66\u4e60\u548cEMA\u65b9\u6cd5\u53ef\u4ee5\u51cf\u5c11\u5bf9\u82f1\u8bed\u7684\u4f9d\u8d56\u3002", "motivation": "\u63a2\u8ba8\u5728CPT\u4e2d\u52a0\u5165\u82f1\u8bed\u6570\u636e\u7684\u4f5c\u7528\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u5176\u4ed6\u65b9\u6cd5\u51cf\u8f7b\u5bf9\u82f1\u8bed\u7684\u4f9d\u8d56\uff0c\u4ee5\u63d0\u9ad8\u8bed\u8a00\u9002\u5e94\u7684\u6548\u679c\u3002", "method": "\u5f15\u5165\u8bed\u8a00\u65e0\u5173\u7684ICL\u57fa\u51c6\u6d4b\u8bd5\u6765\u5206\u6790\u5728\u4e0d\u4f7f\u7528\u82f1\u8bed\u7684\u6761\u4ef6\u4e0b\u51fa\u73b0\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u63d0\u51fa\u8bfe\u7a0b\u5b66\u4e60\u548c\u6743\u91cd\u6307\u6570\u79fb\u52a8\u5e73\u5747\uff08EMA\uff09\u4f5c\u4e3a\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u3002", "result": "\u53d1\u73b0\u82f1\u8bed\u6570\u636e\u5bf9\u4e8e\u76ee\u6807\u8bed\u8a00\u7684\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0c\u5176\u7f3a\u5931\u4f1a\u5bfc\u81f4\u6a21\u578b\u53c2\u6570\u7684\u5927\u53d8\u52a8\uff0c\u4ece\u800c\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5f15\u5165\u7684\u89e3\u51b3\u65b9\u6848\u5982\u8bfe\u7a0b\u5b66\u4e60\u548cEMA\u80fd\u591f\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728CPT\u8fc7\u7a0b\u4e2d\u52a0\u5165\u82f1\u8bed\u6570\u636e\u5bf9\u76ee\u6807\u8bed\u8a00\u4e0b\u6e38\u4efb\u52a1\u80fd\u529b\u7684\u589e\u5f3a\u81f3\u5173\u91cd\u8981\uff0c\u867d\u7136\u5728\u9a8c\u8bc1\u56f0\u60d1\u5ea6\u4e0a\u6ca1\u6709\u8868\u73b0\u51fa\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2506.00384", "pdf": "https://arxiv.org/pdf/2506.00384", "abs": "https://arxiv.org/abs/2506.00384", "authors": ["Yutong Huang", "Zhiyuan Guo", "Yiying Zhang"], "title": "Deep-Learning-Driven Prefetching for Far Memory", "categories": ["cs.LG", "cs.DC", "cs.OS"], "comment": null, "summary": "Modern software systems face increasing runtime performance demands,\nparticularly in emerging architectures like far memory, where local-memory\nmisses incur significant latency. While machine learning (ML) has proven\neffective in offline systems optimization, its application to high-frequency,\nruntime-level problems remains limited due to strict performance,\ngeneralization, and integration constraints. We present FarSight, a Linux-based\nfar-memory system that leverages deep learning (DL) to efficiently perform\naccurate data prefetching. FarSight separates application semantics from\nruntime memory layout, allowing offline-trained DL models to predict access\npatterns using a compact vocabulary of ordinal possibilities, resolved at\nruntime through lightweight mapping structures. By combining asynchronous\ninference, lookahead prediction, and a cache-resident DL model, FarSight\nachieves high prediction accuracy with low runtime overhead. Our evaluation of\nFarSight on four data-intensive workloads shows that it outperforms the\nstate-of-the-art far-memory system by up to 3.6 times. Overall, this work\ndemonstrates the feasibility and advantages of applying modern ML techniques to\ncomplex, performance-critical software runtime problems.", "AI": {"tldr": "FarSight uses deep learning for data prefetching in Linux-based systems, enhancing performance in far-memory architectures by separating application semantics and runtime memory layouts.", "motivation": "The motivation for this work arises from the increasing runtime performance demands in modern software systems, particularly with new architectures like far memory, where local-memory misses lead to significant latency. While ML has improved offline systems optimization, there is a need to address high-frequency, runtime-level issues where ML applications remain limited.", "method": "The method involves using FarSight, a Linux-based far-memory system that utilizes deep learning for accurate data prefetching. It separates application semantics from runtime memory layout and uses offline-trained DL models to predict access patterns, resolved at runtime by lightweight mapping structures. It also incorporates asynchronous inference, lookahead prediction, and utilizes a cache-resident DL model for performance optimization.", "result": "Through evaluation on four data-intensive workloads, FarSight outperformed the current state-of-the-art far-memory system by up to 3.6 times, indicating significant performance advancements.", "conclusion": "FarSight demonstrates the feasibility and efficiency of employing modern ML techniques, specifically deep learning, in performance-critical runtime software systems to significantly enhance data prefetching and system performance."}}
{"id": "2506.00780", "pdf": "https://arxiv.org/pdf/2506.00780", "abs": "https://arxiv.org/abs/2506.00780", "authors": ["Jingyu Liu", "Jingquan Peng", "xiaopeng Wu", "Xubin Li", "Tiezheng Ge", "Bo Zheng", "Yong Liu"], "title": "Do not Abstain! Identify and Solve the Uncertainty", "categories": ["cs.AI"], "comment": null, "summary": "Despite the widespread application of Large Language Models (LLMs) across\nvarious domains, they frequently exhibit overconfidence when encountering\nuncertain scenarios, yet existing solutions primarily rely on evasive responses\n(e.g., \"I don't know\") overlooks the opportunity of identifying and addressing\nthe uncertainty to generate more satisfactory responses. To systematically\ninvestigate and improve LLMs' ability of recognizing and addressing the source\nof uncertainty, we introduce \\textbf{ConfuseBench}, a benchmark mainly focus on\nthree types of uncertainty: document scarcity, limited capability, and query\nambiguity. Experiments with ConfuseBench reveal that current LLMs struggle to\naccurately identify the root cause of uncertainty and solve it. They prefer to\nattribute uncertainty to query ambiguity while overlooking capability\nlimitations, especially for those weaker models. To tackle this challenge, we\nfirst generate context-aware inquiries that highlight the confusing aspect of\nthe original query. Then we judge the source of uncertainty based on the\nuniqueness of the inquiry's answer. Further we use an on-policy training\nmethod, InteractDPO to generate better inquiries. Experimental results\ndemonstrate the efficacy of our approach.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165ConfuseBench\u57fa\u51c6\u4ee5\u8bc4\u4f30\u548c\u6539\u5584\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u8bc6\u522b\u548c\u89e3\u51b3\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u4e0a\u4e0b\u6587\u76f8\u5173\u8be2\u95ee\u548cInteractDPO\u65b9\u6cd5\u63d0\u9ad8\u6a21\u578b\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u60c5\u5883\u65f6\u5f80\u5f80\u8fc7\u4e8e\u81ea\u4fe1\uff0c\u800c\u4e3b\u8981\u4ee5\u56de\u907f\u6027\u56de\u5e94\u4e3a\u4e3b\uff0c\u672a\u80fd\u8bc6\u522b\u548c\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u751f\u6210\u66f4\u6ee1\u610f\u7684\u56de\u5e94\u3002\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u6539\u8fdb\u6a21\u578b\u8bc6\u522b\u5e76\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165ConfuseBench\u57fa\u51c6\uff0c\u8fdb\u884c\u5b9e\u9a8c\u4ee5\u8bc4\u4f30\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u8bc6\u522b\u548c\u5e94\u5bf9\u4e0a\u7684\u8868\u73b0\uff0c\u7136\u540e\u901a\u8fc7\u751f\u6210\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u8be2\u95ee\u5e76\u4f7f\u7528\u5728\u7b56\u7565\u8bad\u7ec3\u65b9\u6cd5InteractDPO\u53bb\u751f\u6210\u66f4\u597d\u7684\u8be2\u95ee\u6765\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u901a\u8fc7ConfuseBench\u57fa\u51c6\u6d4b\u8bd5\u548c\u4f7f\u7528InteractDPO\u8bad\u7ec3\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u548c\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\u3002", "conclusion": "ConfuseBench\u901a\u8fc7\u7cfb\u7edf\u6d4b\u8bd5\u63ed\u793a\u4e86\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u5e76\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u7684\u6839\u6e90\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5728\u7b56\u7565\u8bad\u7ec3\u65b9\u6cd5InteractDPO\uff0c\u4ee5\u751f\u6210\u66f4\u597d\u7684\u8be2\u95ee\uff0c\u4ece\u800c\u6539\u5584\u6a21\u578b\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.00290", "pdf": "https://arxiv.org/pdf/2506.00290", "abs": "https://arxiv.org/abs/2506.00290", "authors": ["Tianqi Chen", "Shujian Zhang", "Mingyuan Zhou"], "title": "DLM-One: Diffusion Language Models for One-Step Sequence Generation", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces DLM-One, a score-distillation-based framework for\none-step sequence generation with continuous diffusion language models (DLMs).\nDLM-One eliminates the need for iterative refinement by aligning the scores of\na student model's outputs in the continuous token embedding space with the\nscore function of a pretrained teacher DLM. We investigate whether DLM-One can\nachieve substantial gains in sampling efficiency for language modeling. Through\ncomprehensive experiments on DiffuSeq -- a representative continuous DLM -- we\nshow that DLM-One achieves up to ~500x speedup in inference time while\nmaintaining competitive performance on benchmark text generation tasks used to\nevaluate the teacher models. We further analyze the method's empirical behavior\nacross multiple datasets, providing initial insights into its generality and\npractical applicability. Our findings position one-step diffusion as a\npromising direction for efficient, high-quality language generation and broader\nadoption of continuous diffusion models operating in embedding space for\nnatural language processing.", "AI": {"tldr": "DLM-One significantly speeds up inference in language modeling by aligning student and teacher model scores, maintaining high performance without iterative refinement.", "motivation": "The motivation is to enhance sampling efficiency in language modeling by eliminating the need for iterative refinement processes.", "method": "The method involves using a score-distillation-based framework for one-step sequence generation, aligning a student model's score with a pretrained teacher DLM's in the continuous token embedding space.", "result": "DLM-One achieves up to ~500x speedup in inference time while maintaining competitive performance in the evaluated tasks.", "conclusion": "DLM-One provides a substantial speedup in inference time while maintaining competitive performance on benchmark text generation tasks, showing its potential as a promising direction for efficient, high-quality language generation with continuous diffusion models."}}
{"id": "2506.00388", "pdf": "https://arxiv.org/pdf/2506.00388", "abs": "https://arxiv.org/abs/2506.00388", "authors": ["Ni Mu", "Hao Hu", "Xiao Hu", "Yiqin Yang", "Bo Xu", "Qing-Shan Jia"], "title": "CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Preference-based reinforcement learning (PbRL) bypasses explicit reward\nengineering by inferring reward functions from human preference comparisons,\nenabling better alignment with human intentions. However, humans often struggle\nto label a clear preference between similar segments, reducing label efficiency\nand limiting PbRL's real-world applicability. To address this, we propose an\noffline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback\n(CLARIFY), which learns a trajectory embedding space that incorporates\npreference information, ensuring clearly distinguished segments are spaced\napart, thus facilitating the selection of more unambiguous queries. Extensive\nexperiments demonstrate that CLARIFY outperforms baselines in both non-ideal\nteachers and real human feedback settings. Our approach not only selects more\ndistinguished queries but also learns meaningful trajectory embeddings.", "AI": {"tldr": "CLARIFY\u6539\u5584\u4e86\u504f\u597d\u6807\u7b7e\u6548\u7387\uff0c\u901a\u8fc7\u5b66\u4e60\u8f68\u8ff9\u5d4c\u5165\u66f4\u597d\u5730\u5904\u7406\u6a21\u7cca\u53cd\u9988\uff0c\u63d0\u9ad8\u67e5\u8be2\u9009\u62e9\u7684\u660e\u786e\u6027\u4e0e\u6548\u529b\u3002", "motivation": "\u5728\u4eba\u7c7b\u96be\u4ee5\u660e\u786e\u6807\u8bb0\u76f8\u4f3c\u7247\u6bb5\u7684\u504f\u597d\u65f6\uff0c\u6807\u7b7e\u6548\u7387\u964d\u4f4e\uff0c\u9650\u5236\u4e86PbRL\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u7ebf\u751f\u6210\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5373Contrastive LeArning for ResolvIng Ambiguous Feedback (CLARIFY)\uff0c\u901a\u8fc7\u5b66\u4e60\u8f68\u8ff9\u5d4c\u5165\u7a7a\u95f4\u6765\u5904\u7406\u504f\u597d\u4fe1\u606f\uff0c\u5c06\u660e\u663e\u533a\u5206\u7684\u7247\u6bb5\u5206\u9694\u5f00\u6765\uff0c\u4ece\u800c\u4fc3\u8fdb\u66f4\u660e\u786e\u7684\u67e5\u8be2\u9009\u62e9\u3002", "result": "CLARIFY\u5728\u975e\u7406\u60f3\u6559\u5e08\u548c\u771f\u5b9e\u4eba\u7c7b\u53cd\u9988\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CLARIFY\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u6a21\u7cca\u7684\u53cd\u9988\uff0c\u9009\u62e9\u66f4\u660e\u786e\u7684\u67e5\u8be2\uff0c\u5e76\u5b66\u4e60\u6709\u610f\u4e49\u7684\u8f68\u8ff9\u5d4c\u5165\u3002"}}
{"id": "2506.00781", "pdf": "https://arxiv.org/pdf/2506.00781", "abs": "https://arxiv.org/abs/2506.00781", "authors": ["Chen Xiong", "Pin-Yu Chen", "Tsung-Yi Ho"], "title": "CoP: Agentic Red-teaming for Large Language Models using Composition of Principles", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have spurred transformative\napplications in various domains, ranging from open-source to proprietary LLMs.\nHowever, jailbreak attacks, which aim to break safety alignment and user\ncompliance by tricking the target LLMs into answering harmful and risky\nresponses, are becoming an urgent concern. The practice of red-teaming for LLMs\nis to proactively explore potential risks and error-prone instances before the\nrelease of frontier AI technology. This paper proposes an agentic workflow to\nautomate and scale the red-teaming process of LLMs through the\nComposition-of-Principles (CoP) framework, where human users provide a set of\nred-teaming principles as instructions to an AI agent to automatically\norchestrate effective red-teaming strategies and generate jailbreak prompts.\nDistinct from existing red-teaming methods, our CoP framework provides a\nunified and extensible framework to encompass and orchestrate human-provided\nred-teaming principles to enable the automated discovery of new red-teaming\nstrategies. When tested against leading LLMs, CoP reveals unprecedented safety\nrisks by finding novel jailbreak prompts and improving the best-known\nsingle-turn attack success rate by up to 19.0 times.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdCoP\u6846\u67b6\u6765\u81ea\u52a8\u5316\u8bed\u8a00\u6a21\u578b\u7ea2\u961f\u5de5\u4f5c\uff0c\u63ed\u793a\u4e86\u524d\u6240\u672a\u6709\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u5927\u5e45\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5e94\u5bf9\u5f53\u524d\u8d8a\u6765\u8d8a\u4e25\u91cd\u7684\u8d8a\u72f1\u653b\u51fb\u95ee\u9898\uff0c\u8fd9\u79cd\u653b\u51fb\u7834\u574f\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u548c\u7528\u6237\u5408\u89c4\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7Composition-of-Principles (CoP)\u6846\u67b6\u8fdb\u884c\u81ea\u52a8\u5316\u7ea2\u961f\u5de5\u4f5c\u7684\u6d41\u7a0b\uff0c\u4eba\u7c7b\u7528\u6237\u63d0\u4f9b\u539f\u5219\u6307\u5bfcAI\u8fdb\u884c\u7b56\u7565\u751f\u6210\u3002", "result": "\u5bf9\u9886\u5148\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u53d1\u73b0\u65b0\u578b\u8d8a\u72f1\u63d0\u793a\uff0c\u5e76\u63d0\u9ad8\u5355\u6b21\u653b\u51fb\u6210\u529f\u7387\u8fbe19\u500d\u3002", "conclusion": "CoP\u6846\u67b6\u5728\u63ed\u9732\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u901a\u8fc7\u751f\u6210\u65b0\u578b\u8d8a\u72f1\u63d0\u793a\u5e76\u63d0\u9ad8\u73b0\u6709\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2506.00304", "pdf": "https://arxiv.org/pdf/2506.00304", "abs": "https://arxiv.org/abs/2506.00304", "authors": ["Payal Mohapatra", "Akash Pandey", "Xiaoyuan Zhang", "Qi Zhu"], "title": "Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 main conference", "summary": "Unvoiced electromyography (EMG) is an effective communication tool for\nindividuals unable to produce vocal speech. However, most prior methods rely on\npaired voiced and unvoiced EMG signals, along with speech data, for EMG-to-text\nconversion, which is not practical for such individuals. Given the rise of\nlarge language models (LLMs) in speech recognition, we explore their potential\nto understand unvoiced speech. To this end, we address the challenge of\nlearning from unvoiced EMG alone and propose a novel EMG adaptor module that\nmaps EMG features into an LLM's input space, achieving an average word error\nrate (WER) of 0.49 on a closed-vocabulary unvoiced EMG-to-text task. Even with\na conservative data availability of just six minutes, our approach improves\nperformance over specialized models by nearly 20%. While LLMs have been shown\nto be extendable to new language modalities -- such as audio -- understanding\narticulatory biosignals like unvoiced EMG remains more challenging. This work\ntakes a crucial first step toward enabling LLMs to comprehend unvoiced speech\nusing surface EMG.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u521b\u65b0\u7684EMG\u9002\u914d\u5668\u6a21\u5757\uff0c\u5c06EMG\u7279\u5f81\u6620\u5c04\u5230LLMs\u7684\u8f93\u5165\u7a7a\u95f4\uff0c\u4f7f\u5f97LLMs\u80fd\u591f\u7406\u89e3\u65e0\u58f0\u8bed\u8a00\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86EMG\u5230\u6587\u672c\u8f6c\u6362\u7684\u6548\u679c\u3002", "motivation": "\u65e0\u58f0\u7535\u808c\u56fe\uff08EMG\uff09\u4e3a\u65e0\u6cd5\u8fdb\u884c\u8bed\u8a00\u8868\u8fbe\u7684\u4e2a\u4eba\u63d0\u4f9b\u4e86\u6c9f\u901a\u624b\u6bb5\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6709\u58f0\u4e0e\u65e0\u58f0EMG\u4fe1\u53f7\u7684\u914d\u5bf9\uff0c\u4ee5\u53ca\u8bed\u97f3\u6570\u636e\uff0c\u8fd9\u5bf9\u4e8e\u65e0\u6cd5\u53d1\u58f0\u7684\u4eba\u6765\u8bf4\u4e0d\u5b9e\u7528\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u97f3\u8bc6\u522b\u4e2d\u7684\u5d1b\u8d77\uff0c\u7814\u7a76\u8005\u63a2\u7d22\u4e86\u5176\u5728\u7406\u89e3\u65e0\u58f0\u8bed\u8a00\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684EMG\u9002\u914d\u6a21\u5757\uff0c\u80fd\u591f\u5c06EMG\u7279\u5f81\u6620\u5c04\u5230LLM\u7684\u8f93\u5165\u7a7a\u95f4\uff0c\u5e76\u5728\u5c01\u95ed\u8bcd\u6c47\u7684\u65e0\u58f0EMG\u5230\u6587\u672c\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5e73\u5747\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u4e3a0.49\u3002", "result": "\u5728\u4ec5\u6709\u516d\u5206\u949f\u6570\u636e\u7684\u4fdd\u5b88\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u6bd4\u4e13\u4e1a\u6a21\u578b\u63d0\u9ad8\u4e86\u8fd120%\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7406\u89e3\u65e0\u58f0\u7535\u808c\u56fe\uff08EMG\uff09\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684EMG\u9002\u914d\u6a21\u5757\uff0c\u53ef\u4ee5\u5c06EMG\u7279\u5f81\u6620\u5c04\u5230LLMs\u7684\u8f93\u5165\u7a7a\u95f4\uff0c\u4ece\u800c\u5b9e\u73b0EMG\u5230\u6587\u672c\u7684\u8f6c\u6362\u3002"}}
{"id": "2506.00407", "pdf": "https://arxiv.org/pdf/2506.00407", "abs": "https://arxiv.org/abs/2506.00407", "authors": ["Ruixuan Chen", "Wentao Li", "Jiahui Xiao", "Yuchen Li", "Yimin Tang", "Xiaonan Wang"], "title": "Bias as a Virtue: Rethinking Generalization under Distribution Shifts", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "14 pages", "summary": "Machine learning models often degrade when deployed on data distributions\ndifferent from their training data. Challenging conventional validation\nparadigms, we demonstrate that higher in-distribution (ID) bias can lead to\nbetter out-of-distribution (OOD) generalization. Our Adaptive Distribution\nBridge (ADB) framework implements this insight by introducing controlled\nstatistical diversity during training, enabling models to develop bias profiles\nthat effectively generalize across distributions. Empirically, we observe a\nrobust negative correlation where higher ID bias corresponds to lower OOD\nerror--a finding that contradicts standard practices focused on minimizing\nvalidation error. Evaluation on multiple datasets shows our approach\nsignificantly improves OOD generalization. ADB achieves robust mean error\nreductions of up to 26.8% compared to traditional cross-validation, and\nconsistently identifies high-performing training strategies, evidenced by\npercentile ranks often exceeding 74.4%. Our work provides both a practical\nmethod for improving generalization and a theoretical framework for\nreconsidering the role of bias in robust machine learning.", "AI": {"tldr": "ADB\u901a\u8fc7\u589e\u52a0\u8bad\u7ec3\u4e2d\u7684\u7edf\u8ba1\u591a\u6837\u6027\uff0c\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4eOOD\u9519\u8bef\u7387\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u4e0e\u90e8\u7f72\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u65f6\u901a\u5e38\u4f1a\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u6211\u4eec\u6311\u6218\u4f20\u7edf\u9a8c\u8bc1\u8303\u5f0f\uff0c\u63d0\u51fa\u4e00\u79cd\u63d0\u9ad8OOD\u6cdb\u5316\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u5f15\u5165ADB\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u63a7\u5236\u7684\u7edf\u8ba1\u591a\u6837\u6027\uff0c\u53d1\u5c55\u6a21\u578b\u7684\u504f\u5dee\u7279\u5f81\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u4e0d\u540c\u6570\u636e\u5206\u5e03\u7684\u6709\u6548\u6cdb\u5316\u3002", "result": "\u6211\u4eec\u7684ADB\u6846\u67b6\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86OOD\u6cdb\u5316\u80fd\u529b\uff0c\u4e0e\u4f20\u7edf\u4ea4\u53c9\u9a8c\u8bc1\u76f8\u6bd4\uff0c\u5e73\u5747\u9519\u8bef\u7387\u51cf\u5c11\u4e86\u6700\u9ad826.8%\uff0c\u5e76\u4e14\u4e00\u81f4\u6027\u5730\u627e\u5230\u9ad8\u6027\u80fd\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5176\u8868\u73b0\u6392\u5e8f\u5e38\u8d85\u8fc7\u7b2c74.4\u767e\u5206\u4f4d\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684ADB\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u5728OOD\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u4e3a\u91cd\u65b0\u8003\u8651\u504f\u5dee\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.00782", "pdf": "https://arxiv.org/pdf/2506.00782", "abs": "https://arxiv.org/abs/2506.00782", "authors": ["Weiyang Guo", "Zesheng Shi", "Zhuo Li", "Yequan Wang", "Xuebo Liu", "Wenya Wang", "Fangming Liu", "Min Zhang", "Jing Li"], "title": "Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning", "categories": ["cs.AI"], "comment": "21 pages, 8 figures", "summary": "As large language models (LLMs) grow in power and influence, ensuring their\nsafety and preventing harmful output becomes critical. Automated red teaming\nserves as a tool to detect security vulnerabilities in LLMs without manual\nlabor. However, most existing methods struggle to balance the effectiveness and\ndiversity of red-team generated attack prompts. To address this challenge, we\npropose \\ourapproach, a novel automated red teaming training framework that\nutilizes reinforcement learning to explore and generate more effective attack\nprompts while balancing their diversity. Specifically, it consists of three\ntraining stages: (1) Cold Start: The red team model is supervised and\nfine-tuned on a jailbreak dataset obtained through imitation learning. (2)\nWarm-up Exploration: The model is trained in jailbreak instruction following\nand exploration, using diversity and consistency as reward signals. (3)\nEnhanced Jailbreak: Progressive jailbreak rewards are introduced to gradually\nenhance the jailbreak performance of the red-team model. Extensive experiments\non a variety of LLMs show that \\ourapproach effectively balances the diversity\nand effectiveness of jailbreak prompts compared to existing methods. Our work\nsignificantly improves the efficiency of red team exploration and provides a\nnew perspective on automated red teaming.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u8bad\u7ec3\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u653b\u51fb\u63d0\u793a\u7684\u6709\u6548\u6027\u548c\u591a\u6837\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u548c\u9632\u6b62\u6709\u5bb3\u8f93\u51fa\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u7ea2\u961f\u751f\u6210\u653b\u51fb\u63d0\u793a\u7684\u6709\u6548\u6027\u548c\u591a\u6837\u6027\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u548c\u751f\u6210\u66f4\u6709\u6548\u653b\u51fb\u63d0\u793a\u7684\u81ea\u52a8\u5316\u7ea2\u961f\u8bad\u7ec3\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff1a\u51b7\u542f\u52a8\u3001\u70ed\u8eab\u63a2\u7d22\u548c\u589e\u5f3a\u7834\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u751f\u6210\u6709\u6548\u4e14\u591a\u6837\u7684\u7834\u89e3\u63d0\u793a\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u663e\u8457\u63d0\u9ad8\u4e86\u7ea2\u961f\u63a2\u7d22\u7684\u6548\u7387\uff0c\u5e76\u4e3a\u81ea\u52a8\u5316\u7ea2\u961f\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2506.00307", "pdf": "https://arxiv.org/pdf/2506.00307", "abs": "https://arxiv.org/abs/2506.00307", "authors": ["John Harvill", "Ziwei Fan", "Hao Wang", "Yizhou Sun", "Hao Ding", "Luke Huan", "Anoop Deoras"], "title": "Lossless Token Sequence Compression via Meta-Tokens", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "16 pages, 8 figures", "summary": "Existing work on prompt compression for Large Language Models (LLM) focuses\non lossy methods that try to maximize the retention of semantic information\nthat is relevant to downstream tasks while significantly reducing the sequence\nlength. In this paper, we introduce a task-agnostic lossless compression\ntechnique similar to LZ77 that makes it possible to reduce the input token\nsequence length on average by 27\\% and 18\\% for the two evaluation tasks\nexplored here. Given that we use transformer-based LLMs, this equates to 47\\%\nand 33\\% less encoding computation, respectively, due to the quadratic nature\nof attention. The token sequence transformation is trivial to reverse and\nhighlights that no semantic information is lost in the process. We evaluate our\nproposed approach on two tasks that require strict preservation of\nsemantics/syntax and demonstrate that existing lossy compression methods\nperform poorly in this setting. We find that our lossless compression technique\nproduces only a small gap in performance compared to using the uncompressed\ninput and posit that larger models and an expanded computing budget would\nlikely erase the gap entirely.", "AI": {"tldr": "Introduced a lossless compression method reducing input sequences by 27% and 18%, leading to significant computation savings in LLMs without losing semantic meaning.", "motivation": "The motivation is to reduce sequence length and encoding computation in transformer-based LLMs without losing any semantic information.", "method": "We introduce a task-agnostic lossless compression technique similar to LZ77, which is reversible and preserves semantic information.", "result": "The technique achieves a 27% and 18% reduction in sequence length for the evaluation tasks, corresponding to 47% and 33% less encoding computation, with minimal performance loss.", "conclusion": "Our lossless compression technique allows for a significant reduction in input sequence length while preserving semantic information, resulting in less encoding computation."}}
{"id": "2506.00410", "pdf": "https://arxiv.org/pdf/2506.00410", "abs": "https://arxiv.org/abs/2506.00410", "authors": ["Ziwen Wang"], "title": "JojoSCL: Shrinkage Contrastive Learning for single-cell RNA sequence Clustering", "categories": ["cs.LG", "q-bio.GN", "stat.ML"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding\nof cellular processes by enabling gene expression analysis at the individual\ncell level. Clustering allows for the identification of cell types and the\nfurther discovery of intrinsic patterns in single-cell data. However, the high\ndimensionality and sparsity of scRNA-seq data continue to challenge existing\nclustering models. In this paper, we introduce JojoSCL, a novel self-supervised\ncontrastive learning framework for scRNA-seq clustering. By incorporating a\nshrinkage estimator based on hierarchical Bayesian estimation, which adjusts\ngene expression estimates towards more reliable cluster centroids to reduce\nintra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate\n(SURE), JojoSCL refines both instance-level and cluster-level contrastive\nlearning. Experiments on ten scRNA-seq datasets substantiate that JojoSCL\nconsistently outperforms prevalent clustering methods, with further validation\nof its practicality through robustness analysis and ablation studies. JojoSCL's\ncode is available at: https://github.com/ziwenwang28/JojoSCL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJojoSCL\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u548c\u4f18\u5316\u65b9\u6cd5\u63d0\u5347\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\u6570\u636e\u7684\u805a\u7c7b\u6548\u679c\u3002", "motivation": "\u5355\u7ec6\u80deRNA\u6d4b\u5e8f\uff08scRNA-seq\uff09\u9769\u547d\u6027\u5730\u6539\u53d8\u4e86\u6211\u4eec\u5bf9\u7ec6\u80de\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u4f46\u5176\u6570\u636e\u7684\u9ad8\u7ef4\u6027\u548c\u7a00\u758f\u6027\u4ecd\u7136\u662f\u73b0\u6709\u805a\u7c7b\u6a21\u578b\u7684\u6311\u6218\u3002", "method": "\u5f15\u5165JojoSCL\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u5c42\u6b21\u8d1d\u53f6\u65af\u4f30\u8ba1\u7684\u6536\u7f29\u4f30\u8ba1\u5668\u548cStein\u7684\u65e0\u504f\u98ce\u9669\u4f30\u8ba1\u5bf9\u5176\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728\u5341\u4e2ascRNA-seq\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJojoSCL\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7a33\u5065\u6027\u5206\u6790\u548c\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "JojoSCL\u901a\u8fc7\u6539\u8fdb\u5b9e\u4f8b\u7ea7\u548c\u805a\u7c7b\u7ea7\u5bf9\u6bd4\u5b66\u4e60\uff0c\u63d0\u5347\u4e86scRNA-seq\u6570\u636e\u805a\u7c7b\u7684\u6548\u679c\u3002"}}
{"id": "2506.00785", "pdf": "https://arxiv.org/pdf/2506.00785", "abs": "https://arxiv.org/abs/2506.00785", "authors": ["Sahiti Yerramilli", "Nilay Pande", "Rynaa Grover", "Jayant Sravan Tamarapalli"], "title": "GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning", "categories": ["cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "This paper introduces GeoChain, a large-scale benchmark for evaluating\nstep-by-step geographic reasoning in multimodal large language models (MLLMs).\nLeveraging 1.46 million Mapillary street-level images, GeoChain pairs each\nimage with a 21-step chain-of-thought (CoT) question sequence (over 30 million\nQ&A pairs). These sequences guide models from coarse attributes to fine-grained\nlocalization across four reasoning categories - visual, spatial, cultural, and\nprecise geolocation - annotated by difficulty. Images are also enriched with\nsemantic segmentation (150 classes) and a visual locatability score. Our\nbenchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5\nvariants) on a diverse 2,088-image subset reveals consistent challenges: models\nfrequently exhibit weaknesses in visual grounding, display erratic reasoning,\nand struggle to achieve accurate localization, especially as the reasoning\ncomplexity escalates. GeoChain offers a robust diagnostic methodology, critical\nfor fostering significant advancements in complex geographic reasoning within\nMLLMs.", "AI": {"tldr": "GeoChain is a benchmark for testing MLLMs in geographic reasoning, using annotated images and reasoning sequences. Models struggle with visual grounding and localization as task difficulty increases.", "motivation": "The main motivation is to evaluate and improve the capability of multimodal large language models in step-by-step geographic reasoning, which remains challenging in current models.", "method": "GeoChain uses a combination of step-by-step chain-of-thought reasoning and extensive annotated datasets, including semantic segmentation and visual locatability scores, to evaluate MLLMs across different reasoning categories.", "result": "The study found that even advanced MLLMs face consistent challenges with visual grounding and accurate localization, particularly as reasoning tasks become more complex, highlighting areas for potential improvement in model development.", "conclusion": "GeoChain provides a comprehensive benchmark for diagnosing and improving the ability of MLLMs to handle complex geographic reasoning, helping pinpoint specific challenges these models face in tasks of increasing difficulty."}}
{"id": "2506.00312", "pdf": "https://arxiv.org/pdf/2506.00312", "abs": "https://arxiv.org/abs/2506.00312", "authors": ["Brendan Sands", "Yining Wang", "Chenhao Xu", "Yuxuan Zhou", "Lai Wei", "Rohitash Chandra"], "title": "An evaluation of LLMs for generating movie reviews: GPT-4o, Gemini-2.0 and DeepSeek-V3", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been prominent in various tasks, including\ntext generation and summarisation. The applicability of LLMs to the generation\nof product reviews is gaining momentum, paving the way for the generation of\nmovie reviews. In this study, we propose a framework that generates movie\nreviews using three LLMs (GPT-4o, DeepSeek-V3, and Gemini-2.0), and evaluate\ntheir performance by comparing the generated outputs with IMDb user reviews. We\nuse movie subtitles and screenplays as input to the LLMs and investigate how\nthey affect the quality of reviews generated. We review the LLM-based movie\nreviews in terms of vocabulary, sentiment polarity, similarity, and thematic\nconsistency in comparison to IMDB user reviews. The results demonstrate that\nLLMs are capable of generating syntactically fluent and structurally complete\nmovie reviews. Nevertheless, there is still a noticeable gap in emotional\nrichness and stylistic coherence between LLM-generated and IMDb reviews,\nsuggesting that further refinement is needed to improve the overall quality of\nmovie review generation. We provided a survey-based analysis where participants\nwere told to distinguish between LLM and IMDb user reviews. The results show\nthat LLM-generated reviews are difficult to distinguish from IMDB user reviews.\nWe found that DeepSeek-V3 produced the most balanced reviews, closely matching\nIMDb reviews. GPT-4o overemphasised positive emotions, while Gemini-2.0\ncaptured negative emotions better but showed excessive emotional intensity.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7535\u5f71\u8bc4\u8bba\u7684\u6548\u679c\uff0c\u53d1\u73b0LLM\u751f\u6210\u7684\u8bc4\u8bba\u5728\u8bed\u6cd5\u4e0a\u6d41\u7545\u4f46\u7f3a\u4e4f\u60c5\u611f\u548c\u98ce\u683c\u7684\u4e00\u81f4\u6027\uff0c\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u751f\u6210\u7535\u5f71\u8bc4\u8bba\u4e0a\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u8bc4\u4f30\u5176\u751f\u6210\u8f93\u51fa\u4e0eIMDb\u7528\u6237\u8bc4\u8bba\u76f8\u6bd4\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u6846\u67b6\u4f7f\u7528\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u3001DeepSeek-V3\u548cGemini-2.0\uff09\u751f\u6210\u7535\u5f71\u8bc4\u8bba\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u751f\u6210\u7684\u8bc4\u8bba\u4e0eIMDb\u7528\u6237\u8bc4\u8bba\u6765\u8bc4\u4f30\u5176\u8868\u73b0\u3002", "result": "LLM\u751f\u6210\u7684\u7535\u5f71\u8bc4\u8bba\u5728\u8bed\u6cd5\u548c\u7ed3\u6784\u4e0a\u8f83\u4e3a\u5b8c\u6574\u6d41\u7545\uff0c\u4f46\u5728\u60c5\u611f\u4e30\u5bcc\u6027\u548c\u98ce\u683c\u4e00\u81f4\u6027\u65b9\u9762\u4e0eIMDb\u8bc4\u8bba\u5b58\u5728\u5dee\u8ddd\u3002\u8c03\u67e5\u663e\u793a\uff0c\u53c2\u4e0e\u8005\u96be\u4ee5\u533a\u5206LLM\u4e0eIMDb\u7528\u6237\u8bc4\u8bba\uff0c\u5176\u4e2dDeepSeek-V3\u751f\u6210\u7684\u8bc4\u8bba\u6700\u4e3a\u5e73\u8861\uff0cGPT-4o\u504f\u5411\u6b63\u9762\u60c5\u611f\uff0c\u800cGemini-2.0\u66f4\u597d\u5730\u6355\u6349\u8d1f\u9762\u60c5\u611f\u4f46\u8868\u73b0\u60c5\u611f\u5f3a\u5ea6\u8fc7\u9ad8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1LLM\u53ef\u4ee5\u751f\u6210\u5728\u8bed\u6cd5\u4e0a\u6d41\u7545\u4e14\u7ed3\u6784\u5b8c\u6574\u7684\u7535\u5f71\u8bc4\u8bba\uff0c\u4f46\u4e0eIMDb\u7528\u6237\u8bc4\u8bba\u76f8\u6bd4\uff0c\u5176\u60c5\u611f\u4e30\u5bcc\u6027\u548c\u98ce\u683c\u4e00\u81f4\u6027\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u9ad8\u7535\u5f71\u8bc4\u8bba\u751f\u6210\u7684\u6574\u4f53\u8d28\u91cf\u3002"}}
{"id": "2506.00416", "pdf": "https://arxiv.org/pdf/2506.00416", "abs": "https://arxiv.org/abs/2506.00416", "authors": ["Anum Nawaz", "Muhammad Irfan", "Xianjia Yu", "Zhuo Zou", "Tomi Westerlund"], "title": "Blockchain-Enabled Privacy-Preserving Second-Order Federated Edge Learning in Personalized Healthcare", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "Federated learning (FL) has attracted increasing attention to mitigate\nsecurity and privacy challenges in traditional cloud-centric machine learning\nmodels specifically in healthcare ecosystems. FL methodologies enable the\ntraining of global models through localized policies, allowing independent\noperations at the edge clients' level. Conventional first-order FL approaches\nface several challenges in personalized model training due to heterogeneous\nnon-independent and identically distributed (non-iid) data of each edge client.\nRecently, second-order FL approaches maintain the stability and consistency of\nnon-iid datasets while improving personalized model training. This study\nproposes and develops a verifiable and auditable optimized second-order FL\nframework BFEL (blockchain-enhanced federated edge learning) based on optimized\nFedCurv for personalized healthcare systems. FedCurv incorporates information\nabout the importance of each parameter to each client's task (through Fisher\nInformation Matrix) which helps to preserve client-specific knowledge and\nreduce model drift during aggregation. Moreover, it minimizes communication\nrounds required to achieve a target precision convergence for each edge client\nwhile effectively managing personalized training on non-iid and heterogeneous\ndata. The incorporation of Ethereum-based model aggregation ensures trust,\nverifiability, and auditability while public key encryption enhances privacy\nand security. Experimental results of federated CNNs and MLPs utilizing Mnist,\nCifar-10, and PathMnist demonstrate the high efficiency and scalability of the\nproposed framework.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u4f18\u5316\u7684\u7b2c\u4e8c\u9636\u8054\u90a6\u5b66\u4e60\u6846\u67b6BFEL\uff0c\u80fd\u591f\u589e\u5f3a\u4e2a\u6027\u5316\u533b\u7597\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u3001\u5b89\u5168\u6027\u548c\u9690\u79c1\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfFL\u65b9\u6cd5\u5728\u5904\u7406\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u65f6\u7684\u4e2a\u6027\u5316\u8bad\u7ec3\u95ee\u9898\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u7b2c\u4e8c\u9636FL\u65b9\u6cd5\uff0c\u7ed3\u5408Fisher\u4fe1\u606f\u77e9\u9635\u548cEthereum\u8fdb\u884c\u6a21\u578b\u805a\u5408\u4e0e\u52a0\u5bc6\uff0c\u4f7f\u7528CNN\u548cMLP\u5728Mnist\u3001Cifar-10\u548cPathMnist\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBFEL\u6846\u67b6\u5728\u5904\u7406Mnist\u3001Cifar-10\uff0c\u4ee5\u53caPathMnist\u6570\u636e\u96c6\u65f6\u8868\u73b0\u51fa\u9ad8\u5ea6\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BFEL\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u533a\u5757\u94fe\u6280\u672f\u548c\u4f18\u5316\u7684FedCurv\u5b9e\u73b0\u4e86\u4e2a\u6027\u5316\u533b\u7597\u7cfb\u7edf\u7684\u9ad8\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u4fdd\u62a4\u9690\u79c1\u548c\u589e\u5f3a\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.00794", "pdf": "https://arxiv.org/pdf/2506.00794", "abs": "https://arxiv.org/abs/2506.00794", "authors": ["Jiaxin Wen", "Chenglei Si", "Yueh-han Chen", "He He", "Shi Feng"], "title": "Predicting Empirical AI Research Outcomes with Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Many promising-looking ideas in AI research fail to deliver, but their\nvalidation takes substantial human labor and compute. Predicting an idea's\nchance of success is thus crucial for accelerating empirical AI research, a\nskill that even expert researchers can only acquire through substantial\nexperience. We build the first benchmark for this task and compare LMs with\nhuman experts. Concretely, given two research ideas (e.g., two jailbreaking\nmethods), we aim to predict which will perform better on a set of benchmarks.\nWe scrape ideas and experimental results from conference papers, yielding 1,585\nhuman-verified idea pairs published after our base model's cut-off date for\ntesting, and 6,000 pairs for training. We then develop a system that combines a\nfine-tuned GPT-4.1 with a paper retrieval agent, and we recruit 25 human\nexperts to compare with. In the NLP domain, our system beats human experts by a\nlarge margin (64.4% v.s. 48.9%). On the full test set, our system achieves 77%\naccuracy, while off-the-shelf frontier LMs like o3 perform no better than\nrandom guessing, even with the same retrieval augmentation. We verify that our\nsystem does not exploit superficial features like idea complexity through\nextensive human-written and LM-designed robustness tests. Finally, we evaluate\nour system on unpublished novel ideas, including ideas generated by an AI\nideation agent. Our system achieves 63.6% accuracy, demonstrating its potential\nas a reward model for improving idea generation models. Altogether, our results\noutline a promising new direction for LMs to accelerate empirical AI research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e3a\u9884\u6d4bAI\u7814\u7a76\u60f3\u6cd5\u7684\u6210\u529f\u6982\u7387\u8bbe\u7acb\u4e86\u9996\u4e2a\u57fa\u51c6\uff0c\u7ed3\u5408\u5fae\u8c03GPT-4.1\u548c\u8bba\u6587\u68c0\u7d22\u7cfb\u7edf\u6d4b\u8bd5\u53d1\u73b0\uff0c\u6bd4\u4eba\u7c7b\u4e13\u5bb6\u8868\u73b0\u66f4\u4f73\uff0c\u5c55\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u52a0\u901fAI\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5f88\u591a\u6709\u524d\u9014\u7684AI\u7814\u7a76\u60f3\u6cd5\u6ca1\u80fd\u5b9e\u73b0\uff0c\u4f46\u5176\u9a8c\u8bc1\u9700\u8981\u5927\u91cf\u4eba\u529b\u548c\u8ba1\u7b97\u8d44\u6e90\u3002\u56e0\u6b64\uff0c\u9884\u6d4b\u4e00\u4e2a\u60f3\u6cd5\u6210\u529f\u7684\u53ef\u80fd\u6027\u5bf9\u4e8e\u52a0\u901f\u7ecf\u9a8c\u6027AI\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u662f\u4e00\u9879\u5373\u4f7f\u662f\u4e13\u5bb6\u7814\u7a76\u8005\u4e5f\u9700\u8981\u901a\u8fc7\u5927\u91cf\u7ecf\u9a8c\u624d\u80fd\u83b7\u5f97\u7684\u80fd\u529b\u3002", "method": "\u5efa\u7acb\u9996\u4e2a\u7528\u4e8e\u9884\u6d4b\u7814\u7a76\u60f3\u6cd5\u6210\u529f\u6982\u7387\u7684\u57fa\u51c6\uff0c\u5e76\u5c06\u8bed\u8a00\u6a21\u578b\uff08LMs\uff09\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6bd4\u8f83\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7ed9\u5b9a\u4e24\u79cd\u7814\u7a76\u60f3\u6cd5\uff08\u5982\u4e24\u79cd\u7834\u89e3\u65b9\u6cd5\uff09\uff0c\u6211\u4eec\u65e8\u5728\u9884\u6d4b\u54ea\u79cd\u5728\u4e00\u7ec4\u57fa\u51c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002\u6211\u4eec\u4ece\u4f1a\u8bae\u8bba\u6587\u4e2d\u83b7\u53d6\u60f3\u6cd5\u548c\u5b9e\u9a8c\u7ed3\u679c\uff0c\u5171\u67091585\u5bf9\u7ecf\u8fc7\u4eba\u7c7b\u9a8c\u8bc1\u7684\u60f3\u6cd5\u5bf9\u7528\u4e8e\u6d4b\u8bd5\uff0c\u8fd8\u67096000\u5bf9\u7528\u4e8e\u8bad\u7ec3\u3002\u968f\u540e\u5f00\u53d1\u4e86\u4e00\u79cd\u7ed3\u5408\u5fae\u8c03GPT-4.1\u548c\u8bba\u6587\u68c0\u7d22\u4ee3\u7406\u7684\u7cfb\u7edf\uff0c\u5e76\u62db\u52df25\u4f4d\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728NLP\u9886\u57df\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u8fdc\u8d85\u4eba\u7c7b\u4e13\u5bb6\uff0864.4%\u5bf948.9%\uff09\u3002\u5728\u5b8c\u6574\u7684\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5b9e\u73b0\u4e8677%\u7684\u51c6\u786e\u7387\uff0c\u800c\u5373\u4f7f\u662f\u540c\u6837\u6dfb\u52a0\u4e86\u68c0\u7d22\u589e\u5f3a\u7684\u73b0\u6210\u524d\u6cbfLMs\u5982o3\u7684\u8868\u73b0\u4e5f\u4ec5\u76f8\u5f53\u4e8e\u968f\u673a\u731c\u6d4b\u3002\u6211\u4eec\u901a\u8fc7\u5e7f\u6cdb\u7684\u4eba\u7c7b\u7f16\u5199\u548cLM\u8bbe\u8ba1\u7684\u9c81\u68d2\u6027\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u6211\u4eec\u7684\u7cfb\u7edf\u5e76\u672a\u5229\u7528\u5982\u60f3\u6cd5\u590d\u6742\u6027\u7b49\u8868\u9762\u7279\u5f81\u3002\u6700\u7ec8\uff0c\u6211\u4eec\u5728\u672a\u53d1\u8868\u7684\u65b0\u60f3\u6cd5\u4e0a\u8bc4\u4f30\u4e86\u6211\u4eec\u7684\u7cfb\u7edf\uff0c\u5305\u62ec\u7531AI\u521b\u610f\u751f\u6210\u4ee3\u7406\u751f\u6210\u7684\u60f3\u6cd5\uff0c\u7cfb\u7edf\u5b9e\u73b0\u4e8663.6%\u7684\u51c6\u786e\u7387\uff0c\u5c55\u793a\u5176\u4f5c\u4e3a\u6539\u8fdb\u521b\u610f\u751f\u6210\u6a21\u578b\u7684\u5956\u52b1\u6a21\u578b\u7684\u6f5c\u529b\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u679c\u4e3a\u8bed\u8a00\u6a21\u578b\u52a0\u901f\u7ecf\u9a8c\u6027AI\u7814\u7a76\u5f00\u8f9f\u4e86\u4e00\u4e2a\u65b0\u7684\u6709\u524d\u9014\u7684\u65b9\u5411\u3002"}}
{"id": "2506.00319", "pdf": "https://arxiv.org/pdf/2506.00319", "abs": "https://arxiv.org/abs/2506.00319", "authors": ["Yufei Tian", "Jiao Sun", "Nanyun Peng", "Zizhao Zhang"], "title": "SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "As language models evolve to tackle complex, multifaceted tasks, their\nevaluation must adapt to capture this intricacy. A granular, skill-specific\nunderstanding of model capabilities can empower researchers to make informed\nmodel development plans. In this paper, we introduce SkillVerse, an\nunsupervised tree-structured diagnosis framework for understanding model\nproficiency in specific abilities. With LLM as a judge, SkillVerse first\ncritiques the model responses, and then organizes them into a hierarchical\nstructure termed dendrogram. Given proficiency at arbitrary levels of\ngranularity, SkillVerse is flexible to produce insights of behaviors of modern\nlarge models. We also demonstrate its efficacy in two downstream tasks: 1)\nimproving model in-context learning by 25% using a tree-search algorithm to\nselect more informative few-shot demonstrations, and 2) accurately predicting\nnew model weaknesses with a 55% success rate, 22% higher than without\nSkillVerse.", "AI": {"tldr": "Introduction of SkillVerse for evaluating language models, demonstrating improved in-context learning and prediction of weaknesses.", "motivation": "To provide a granular understanding of language models' capabilities to support better development strategies.", "method": "SkillVerse evaluates model skills using LLM as a judge and organizes results into a tree-structured framework called dendrogram.", "result": "SkillVerse improves model in-context learning by 25% and predicts model weaknesses with a 55% success rate, outperforming previous methods by 22%.", "conclusion": "SkillVerse is effective in diagnosing the proficiency of language models in specific skills, enhancing in-context learning and predicting model weaknesses."}}
{"id": "2506.00420", "pdf": "https://arxiv.org/pdf/2506.00420", "abs": "https://arxiv.org/abs/2506.00420", "authors": ["Miao Ye", "Suxiao Wang", "Jiaguang Han", "Yong Wang", "Xiaoli Wang", "Jingxuan Wei", "Peng Wen", "Jing Cui"], "title": "A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Detecting anomalies in the data collected by WSNs can provide crucial\nevidence for assessing the reliability and stability of WSNs. Existing methods\nfor WSN anomaly detection often face challenges such as the limited extraction\nof spatiotemporal correlation features, the absence of sample labels, few\nanomaly samples, and an imbalanced sample distribution. To address these\nissues, a spatiotemporal correlation detection model (MTAD-RD) considering both\nmodel architecture and a two-stage training strategy perspective is proposed.\nIn terms of model structure design, the proposed MTAD-RD backbone network\nincludes a retentive network (RetNet) enhanced by a cross-retention (CR)\nmodule, a multigranular feature fusion module, and a graph attention network\nmodule to extract internode correlation information. This proposed model can\nintegrate the intermodal correlation features and spatial features of WSN\nneighbor nodes while extracting global information from time series data.\nMoreover, its serialized inference characteristic can remarkably reduce\ninference overhead. For model training, a two-stage training approach was\ndesigned. First, a contrastive learning proxy task was designed for time series\ndata with graph structure information in WSNs, enabling the backbone network to\nlearn transferable features from unlabeled data using unsupervised contrastive\nlearning methods, thereby addressing the issue of missing sample labels in the\ndataset. Then, a caching-based sample sampler was designed to divide samples\ninto few-shot and contrastive learning data. A specific joint loss function was\ndeveloped to jointly train the dual-graph discriminator network to address the\nproblem of sample imbalance effectively. In experiments carried out on real\npublic datasets, the designed MTAD-RD anomaly detection method achieved an F1\nscore of 90.97%, outperforming existing supervised WSN anomaly detection\nmethods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684WSN\u5f02\u5e38\u68c0\u6d4b\u6a21\u578bMTAD-RD\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0cF1\u5f97\u5206\u8fbe\u523090.97%\u3002", "motivation": "\u73b0\u6709\u7684WSN\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9762\u4e34\u65f6\u7a7a\u76f8\u5173\u7279\u5f81\u63d0\u53d6\u6709\u9650\u3001\u6837\u672c\u6807\u7b7e\u7f3a\u5931\u3001\u5f02\u5e38\u6837\u672c\u5c11\u4ee5\u53ca\u6837\u672c\u5206\u5e03\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65f6\u7a7a\u76f8\u5173\u6027\u68c0\u6d4b\u6a21\u578b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u7a7a\u76f8\u5173\u68c0\u6d4b\u6a21\u578b\uff08MTAD-RD\uff09\uff0c\u7ed3\u5408\u6a21\u578b\u7ed3\u6784\u8bbe\u8ba1\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002\u6a21\u578b\u8bbe\u8ba1\u5305\u62ec\u4fdd\u7559\u7f51\u7edc\uff08RetNet\uff09\u3001\u8de8\u4fdd\u7559\u6a21\u5757\u3001\u591a\u7c92\u5ea6\u7279\u5f81\u878d\u5408\u6a21\u5757\u548c\u56fe\u6ce8\u610f\u7f51\u7edc\u6a21\u5757\u3002\u8bad\u7ec3\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u4ee3\u7406\u4efb\u52a1\u548c\u57fa\u4e8e\u7f13\u5b58\u7684\u6837\u672c\u91c7\u6837\u5668\uff0c\u8054\u5408\u8bad\u7ec3\u53cc\u56fe\u9274\u522b\u5668\u7f51\u7edc\u3002", "result": "\u5728\u771f\u5b9e\u7684\u516c\u5171\u6570\u636e\u96c6\u4e0a\uff0cMTAD-RD\u65b9\u6cd5\u5728F1\u5f97\u5206\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u4e8690.97%\uff0c\u8d85\u8fc7\u73b0\u6709\u7684\u8bb8\u591a\u76d1\u7763\u68c0\u6d4b\u65b9\u6cd5\u3002", "conclusion": "MTAD-RD\u6a21\u578b\u5728\u771f\u5b9e\u516c\u5171\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8690.97%\u7684F1\u5f97\u5206\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u76d1\u7763\u5f0fWSN\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2506.00807", "pdf": "https://arxiv.org/pdf/2506.00807", "abs": "https://arxiv.org/abs/2506.00807", "authors": ["Jiahui Zhou", "Dan Li", "Lin Li", "Zhuomin Chen", "Shunyu Wu", "Haozheng Ye", "Jian Lou", "Costas J. Spanos"], "title": "Enhancing LLM Reasoning for Time Series Classification by Tailored Thinking and Fused Decision", "categories": ["cs.AI"], "comment": null, "summary": "The reasoning capabilities of large language models (LLMs) have significantly\nadvanced their performance by enabling in-depth understanding of diverse tasks.\nWith growing interest in applying LLMs to the time series domain, this has\nproven nontrivial, as evidenced by the limited efficacy of straightforwardly\nadapting text-domain reasoning techniques. Although recent work has shown\npromise in several time series tasks, further leveraging advancements in LLM\nreasoning remains under-explored for time series classification (TSC) tasks,\ndespite their prevalence and significance in many real-world applications. In\nthis paper, we propose ReasonTSC, a novel framework designed to effectively\nleverage LLM reasoning for time series classification through both a multi-turn\nreasoning and a fused decision-making strategy tailored to TSC. Rather than\nstraightforwardly applying existing reasoning techniques or relying solely on\nLLMs' built-in reasoning capabilities, ReasonTSC first steers the model to\nthink over the essential characteristics of time series data. Next, it\nintegrates predictions and confidence scores from plug-in classifiers, e.g.,\ndomain-specific time series models, as in-context examples. Finally, ReasonTSC\nguides the LLM through a structured reasoning process: it evaluates the initial\nassessment, backtracks to consider alternative hypotheses, and compares their\nmerits before arriving at a final classification. Extensive experiments and\nsystematic ablation studies demonstrate that ReasonTSC consistently outperforms\nboth existing time series reasoning baselines and plug-in models, and is even\ncapable of identifying and correcting plug-in models' false predictions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faReasonTSC\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u5347\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u6280\u672f\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e94\u7528\u8f83\u5c11\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528LLM\u5728\u8be5\u9886\u57df\u7684\u63a8\u7406\u4f18\u52bf\u5e94\u5bf9\u6b64\u7c7b\u4efb\u52a1\u7684\u6311\u6218\u3002", "method": "\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u8f6e\u63a8\u7406\u548c\u878d\u5408\u51b3\u7b56\u7a0b\u5e8f\u5229\u7528LLM\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff0c\u540c\u65f6\u5229\u7528\u63d2\u4ef6\u5206\u7c7b\u5668\u7684\u9884\u6d4b\u548c\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u63d0\u4f9b\u4e0a\u4e0b\u6587\u6848\u4f8b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u7cfb\u7edf\u6027\u62c6\u89e3\u7814\u7a76\u8868\u660e\uff0cReasonTSC\u80fd\u591f\u6301\u7eed\u8d85\u8d8a\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u57fa\u51c6\u548c\u63d2\u4ef6\u6a21\u578b\uff0c\u5e76\u4e14\u80fd\u591f\u8bc6\u522b\u5e76\u7ea0\u6b63\u63d2\u4ef6\u6a21\u578b\u7684\u9519\u8bef\u9884\u6d4b\u3002", "conclusion": "ReasonTSC\u6846\u67b6\u80fd\u591f\u6709\u6548\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u6548\u548c\u7cbe\u51c6\u7684\u5206\u7c7b\u4f18\u52bf\u3002"}}
{"id": "2506.00331", "pdf": "https://arxiv.org/pdf/2506.00331", "abs": "https://arxiv.org/abs/2506.00331", "authors": ["Boyi Zhang", "Zhuo Liu", "Hangfeng He"], "title": "TreeRare: Syntax Tree-Guided Retrieval and Reasoning for Knowledge-Intensive Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "In real practice, questions are typically complex and knowledge-intensive,\nrequiring Large Language Models (LLMs) to recognize the multifaceted nature of\nthe question and reason across multiple information sources. Iterative and\nadaptive retrieval, where LLMs decide when and what to retrieve based on their\nreasoning, has been shown to be a promising approach to resolve complex,\nknowledge-intensive questions. However, the performance of such retrieval\nframeworks is limited by the accumulation of reasoning errors and misaligned\nretrieval results. To overcome these limitations, we propose TreeRare (Syntax\nTree-Guided Retrieval and Reasoning), a framework that utilizes syntax trees to\nguide information retrieval and reasoning for question answering. Following the\nprinciple of compositionality, TreeRare traverses the syntax tree in a\nbottom-up fashion, and in each node, it generates subcomponent-based queries\nand retrieves relevant passages to resolve localized uncertainty. A\nsubcomponent question answering module then synthesizes these passages into\nconcise, context-aware evidence. Finally, TreeRare aggregates the evidence\nacross the tree to form a final answer. Experiments across five question\nanswering datasets involving ambiguous or multi-hop reasoning demonstrate that\nTreeRare achieves substantial improvements over existing state-of-the-art\nmethods.", "AI": {"tldr": "TreeRare\u901a\u8fc7\u8bed\u6cd5\u6811\u5f15\u5bfc\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u95ee\u9898\u7684\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8fed\u4ee3\u68c0\u7d22\u6846\u67b6\u6027\u80fd\u53d7\u5230\u63a8\u7406\u9519\u8bef\u7d2f\u79ef\u548c\u68c0\u7d22\u7ed3\u679c\u4e0d\u5339\u914d\u7684\u9650\u5236\u3002TreeRare\u63d0\u51fa\u7528\u8bed\u6cd5\u6811\u6765\u5f15\u5bfc\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u4ee5\u89e3\u51b3\u590d\u6742\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u95ee\u9898\u3002", "method": "TreeRare\u901a\u8fc7\u8bed\u6cd5\u6811\u5f15\u5bfc\u68c0\u7d22\u548c\u63a8\u7406\uff0c\u91c7\u7528\u4ece\u4e0b\u5230\u4e0a\u904d\u5386\u8bed\u6cd5\u6811\u7684\u65b9\u6cd5\uff0c\u5728\u6bcf\u4e2a\u8282\u70b9\u751f\u6210\u5b50\u7ec4\u4ef6\u67e5\u8be2\u5e76\u68c0\u7d22\u76f8\u5173\u6bb5\u843d\uff0c\u7136\u540e\u901a\u8fc7\u5b50\u7ec4\u4ef6\u95ee\u7b54\u6a21\u5757\u7efc\u5408\u8fd9\u4e9b\u6bb5\u843d\u5f62\u6210\u8bc1\u636e\uff0c\u6700\u540e\u805a\u5408\u6574\u4e2a\u6811\u7684\u8bc1\u636e\u4ee5\u5f62\u6210\u6700\u7ec8\u7b54\u6848\u3002", "result": "\u5728\u4e94\u4e2a\u6d89\u53ca\u6a21\u7cca\u6216\u591a\u6b65\u63a8\u7406\u7684\u95ee\u9898\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTreeRare\u5728\u73b0\u6709\u65b9\u6cd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u3002", "conclusion": "TreeRare\u663e\u8457\u6539\u5584\u4e86\u590d\u6742\u95ee\u9898\u7684\u95ee\u7b54\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u591a\u6b65\u63a8\u7406\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u6811\u7ed3\u6784\u7684\u5f15\u5bfc\uff0c\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u68c0\u7d22\u548c\u6574\u5408\u4fe1\u606f\u3002"}}
{"id": "2506.00424", "pdf": "https://arxiv.org/pdf/2506.00424", "abs": "https://arxiv.org/abs/2506.00424", "authors": ["Chamika Sudusinghe", "Gerasimos Gerogiannis Damitha Lenadora", "Charles Block", "Josep Torrellas", "Charith Mendis"], "title": "COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning", "categories": ["cs.LG", "cs.AI", "cs.AR", "cs.ET"], "comment": "Accepted at the 42nd International Conference on Machine Learning", "summary": "Sparse tensor programs are essential in deep learning and graph analytics,\ndriving the need for optimized processing. To meet this demand, specialized\nhardware accelerators are being developed. Optimizing these programs for\naccelerators is challenging for two reasons: program performance is highly\nsensitive to variations in sparse inputs, and early-stage accelerators rely on\nexpensive simulators. Therefore, ML-based cost models used for optimizing such\nprograms on general-purpose hardware are often ineffective for early-stage\naccelerators, as they require large datasets for proper training. To this end,\nwe introduce COGNATE, a novel framework that leverages inexpensive data samples\nfrom general-purpose hardware (e.g., CPUs) to train cost models, followed by\nfew-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of\ninput features across hardware platforms while effectively mitigating\nheterogeneity, enabling cost model training with just 5% of the data samples\nneeded by accelerator-specific models to achieve comparable performance. We\nconduct extensive experiments to demonstrate that COGNATE outperforms existing\ntechniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and\n1.39x (up to 4.22x) for SDDMM.", "AI": {"tldr": "COGNATE\u6846\u67b6\u901a\u8fc7\u5c11\u91cf\u6570\u636e\u5bf9\u7a00\u758f\u5f20\u91cf\u7a0b\u5e8f\u8fdb\u884c\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u4e86\u65b0\u5174\u786c\u4ef6\u7684\u6027\u80fd\u3002", "motivation": "\u4f18\u5316\u7a00\u758f\u5f20\u91cf\u7a0b\u5e8f\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u4f46\u9488\u5bf9\u52a0\u901f\u5668\u7684\u65e9\u671f\u6210\u672c\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4e14\u73b0\u6709\u6a21\u578b\u5728\u65b0\u5174\u52a0\u901f\u5668\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "method": "COGNATE\u6846\u67b6\u901a\u8fc7\u5229\u7528\u901a\u7528\u786c\u4ef6\u4e0a\u7684\u5ec9\u4ef7\u6570\u636e\u6837\u672c\u8fdb\u884c\u521d\u6b65\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u65b0\u5174\u786c\u4ef6\u4e0a\u8fdb\u884c\u5c11\u91cf\u5fae\u8c03\uff0c\u4ee5\u4f18\u5316\u6210\u672c\u6a21\u578b\u3002", "result": "COGNATE\u5728SpMM\u548cSDDMM\u65b9\u9762\u5e73\u5747\u52a0\u901f1.47\u500d\uff08\u6700\u9ad8\u8fbe5.46\u500d\uff09\u548c1.39\u500d\uff08\u6700\u9ad8\u8fbe4.22\u500d\uff09\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u6280\u672f\u3002", "conclusion": "COGNATE\u5927\u5e45\u63d0\u9ad8\u4e86\u7a00\u758f\u5f20\u91cf\u7a0b\u5e8f\u5728\u65b0\u5174\u786c\u4ef6\u4e0a\u7684\u4f18\u5316\u6548\u679c\uff0c\u4ee5\u5c11\u91cf\u6570\u636e\u5b9e\u73b0\u4e86\u4e0e\u52a0\u901f\u5668\u7279\u5b9a\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2506.00835", "pdf": "https://arxiv.org/pdf/2506.00835", "abs": "https://arxiv.org/abs/2506.00835", "authors": ["Jisheng Dang", "Yizhou Zhang", "Hao Ye", "Teng Wang", "Siming Chen", "Huicheng Zheng", "Yulan Guo", "Jianhuang Lai", "Bin Hu"], "title": "SynPO: Synergizing Descriptiveness and Preference Optimization for Video Detailed Captioning", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Fine-grained video captioning aims to generate detailed, temporally coherent\ndescriptions of video content. However, existing methods struggle to capture\nsubtle video dynamics and rich detailed information. In this paper, we leverage\npreference learning to enhance the performance of vision-language models in\nfine-grained video captioning, while mitigating several limitations inherent to\ndirect preference optimization (DPO). First, we propose a pipeline for\nconstructing preference pairs that leverages the intrinsic properties of VLMs\nalong with partial assistance from large language models, achieving an optimal\nbalance between cost and data quality. Second, we propose Synergistic\nPreference Optimization (SynPO), a novel optimization method offering\nsignificant advantages over DPO and its variants. SynPO prevents negative\npreferences from dominating the optimization, explicitly preserves the model's\nlanguage capability to avoid deviation of the optimization objective, and\nimproves training efficiency by eliminating the need for the reference model.\nWe extensively evaluate SynPO not only on video captioning benchmarks (e.g.,\nVDC, VDD, VATEX) but also across well-established NLP tasks, including general\nlanguage understanding and preference evaluation, using diverse pretrained\nmodels. Results demonstrate that SynPO consistently outperforms DPO variants\nwhile achieving 20\\% improvement in training efficiency. Code is available at\nhttps://github.com/longmalongma/SynPO", "AI": {"tldr": "The paper introduces SynPO, a method to improve fine-grained video captioning, outperforming existing methods and boosting efficiency by 20%.", "motivation": "To enhance vision-language models' performance in fine-grained video captioning by overcoming limitations in capturing subtle video dynamics and detailed information.", "method": "The paper proposes Synergistic Preference Optimization (SynPO), a novel optimization method, and a pipeline for constructing preference pairs using vision-language models and large language models.", "result": "SynPO offers significant advantages over DPO, improving training efficiency and language capability preservation, and outperforms existing methods in benchmarks and NLP tasks.", "conclusion": "SynPO consistently outperforms existing DPO variants in fine-grained video captioning and provides a 20% improvement in training efficiency."}}
{"id": "2506.00332", "pdf": "https://arxiv.org/pdf/2506.00332", "abs": "https://arxiv.org/abs/2506.00332", "authors": ["Svetlana Churina", "Akshat Gupta", "Insyirah Mujtahid", "Kokil Jaidka"], "title": "Disentangling Codemixing in Chats: The NUS ABC Codemixed Corpus", "categories": ["cs.CL", "cs.SI"], "comment": null, "summary": "Code-mixing involves the seamless integration of linguistic elements from\nmultiple languages within a single discourse, reflecting natural multilingual\ncommunication patterns. Despite its prominence in informal interactions such as\nsocial media, chat messages and instant-messaging exchanges, there has been a\nlack of publicly available corpora that are author-labeled and suitable for\nmodeling human conversations and relationships. This study introduces the first\nlabeled and general-purpose corpus for understanding code-mixing in context\nwhile maintaining rigorous privacy and ethical standards. Our live project will\ncontinuously gather, verify, and integrate code-mixed messages into a\nstructured dataset released in JSON format, accompanied by detailed metadata\nand linguistic statistics. To date, it includes over 355,641 messages spanning\nvarious code-mixing patterns, with a primary focus on English, Mandarin, and\nother languages. We expect the Codemix Corpus to serve as a foundational\ndataset for research in computational linguistics, sociolinguistics, and NLP\napplications.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u7b2c\u4e00\u4e2a\u6807\u8bb0\u7684\u4ee3\u7801\u8f6c\u6362\u901a\u7528\u8bed\u6599\u5e93\uff0c\u5305\u542b\u8d85\u8fc735\u4e07\u6761\u4fe1\u606f\uff0c\u5c06\u6210\u4e3a\u8bed\u8a00\u5b66\u548cNLP\u7814\u7a76\u7684\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1\u4ee3\u7801\u8f6c\u6362\u5728\u8bf8\u5982\u793e\u4ea4\u5a92\u4f53\u3001\u804a\u5929\u4fe1\u606f\u548c\u5373\u65f6\u6d88\u606f\u4ea4\u6d41\u7b49\u975e\u6b63\u5f0f\u4e92\u52a8\u4e2d\u5f88\u7a81\u51fa\uff0c\u4f46\u7f3a\u4e4f\u516c\u5f00\u7684\u3001\u9002\u5408\u4e8e\u5efa\u6a21\u4eba\u7c7b\u5bf9\u8bdd\u548c\u5173\u7cfb\u7684\u4f5c\u8005\u6807\u8bb0\u8bed\u6599\u5e93\u3002", "method": "\u7814\u7a76\u4ecb\u7ecd\u4e86\u9996\u4e2a\u7528\u4e8e\u7406\u89e3\u8bed\u5883\u4e2d\u4ee3\u7801\u8f6c\u6362\u7684\u6807\u8bb0\u901a\u7528\u8bed\u6599\u5e93\uff0c\u5e76\u6301\u7eed\u6027\u5730\u6536\u96c6\u3001\u9a8c\u8bc1\u548c\u6574\u5408\u4ee3\u7801\u8f6c\u6362\u6d88\u606f\u6210\u4e3a\u7ed3\u6784\u5316\u6570\u636e\u96c6\uff0c\u91ca\u653e\u4e3aJSON\u683c\u5f0f\u3002", "result": "\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u8bed\u6599\u5e93\u5305\u542b\u8d85\u8fc7355,641\u6761\u4fe1\u606f\uff0c\u6db5\u76d6\u5404\u79cd\u4ee3\u7801\u8f6c\u6362\u6a21\u5f0f\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u82f1\u8bed\u3001\u666e\u901a\u8bdd\u548c\u5176\u4ed6\u8bed\u8a00\u3002", "conclusion": "Codemix Corpus\u5c06\u6210\u4e3a\u8ba1\u7b97\u8bed\u8a00\u5b66\u3001\u793e\u4f1a\u8bed\u8a00\u5b66\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e94\u7528\u7814\u7a76\u7684\u57fa\u7840\u6570\u636e\u96c6\u3002"}}
{"id": "2506.00431", "pdf": "https://arxiv.org/pdf/2506.00431", "abs": "https://arxiv.org/abs/2506.00431", "authors": ["Jie Peng", "Zhewei Wei", "Yuhang Ye"], "title": "TIDFormer: Exploiting Temporal and Interactive Dynamics Makes A Great Dynamic Graph Transformer", "categories": ["cs.LG"], "comment": "KDD2025", "summary": "Due to the proficiency of self-attention mechanisms (SAMs) in capturing\ndependencies in sequence modeling, several existing dynamic graph neural\nnetworks (DGNNs) utilize Transformer architectures with various encoding\ndesigns to capture sequential evolutions of dynamic graphs. However, the\neffectiveness and efficiency of these Transformer-based DGNNs vary\nsignificantly, highlighting the importance of properly defining the SAM on\ndynamic graphs and comprehensively encoding temporal and interactive dynamics\nwithout extra complex modules. In this work, we propose TIDFormer, a dynamic\ngraph TransFormer that fully exploits Temporal and Interactive Dynamics in an\nefficient manner. We clarify and verify the interpretability of our proposed\nSAM, addressing the open problem of its uninterpretable definitions on dynamic\ngraphs in previous works. To model the temporal and interactive dynamics,\nrespectively, we utilize the calendar-based time partitioning information and\nextract informative interaction embeddings for both bipartite and non-bipartite\ngraphs using merely the sampled first-order neighbors. In addition, we jointly\nmodel temporal and interactive features by capturing potential changes in\nhistorical interaction patterns through a simple decomposition. We conduct\nextensive experiments on several dynamic graph datasets to verify the\neffectiveness and efficiency of TIDFormer. The experimental results demonstrate\nthat TIDFormer excels, outperforming state-of-the-art models across most\ndatasets and experimental settings. Furthermore, TIDFormer exhibits significant\nefficiency advantages compared to previous Transformer-based methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u79f0\u4e3aTIDFormer\u7684\u52a8\u6001\u56feTransformer\u6a21\u578b\uff0c\u901a\u8fc7\u65f6\u95f4\u548c\u4ea4\u4e92\u52a8\u6001\u6355\u83b7\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u5e76\u5177\u6548\u7387\u4f18\u52bf\u3002", "motivation": "\u52a8\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684Transformer\u67b6\u6784\u6709\u6548\u6027\u548c\u6548\u7387\u53c2\u5dee\u4e0d\u9f50\uff0c\u4e9f\u9700\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u7f16\u7801\u65f6\u95f4\u548c\u4ea4\u4e92\u52a8\u6001\u800c\u65e0\u9700\u989d\u5916\u590d\u6742\u6a21\u5757\u7684\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8SAM\u7684\u5b9a\u4e49\u5728\u52a8\u6001\u56fe\u4e0a\u7684\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u548c\u4ea4\u4e92\u52a8\u6001\u8fdb\u884c\u9ad8\u6548\u6355\u83b7\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u5206\u89e3\u6765\u8054\u5408\u5efa\u6a21\u65f6\u95f4\u548c\u4ea4\u4e92\u7279\u5f81\uff0c\u5229\u7528\u65e5\u5386\u65f6\u95f4\u5206\u533a\u4fe1\u606f\u4ee5\u53ca\u5355\u7eaf\u91c7\u6837\u7684\u4e00\u9636\u90bb\u5c45\u6765\u63d0\u53d6\u53cc\u5411\u548c\u975e\u53cc\u5411\u56fe\u4e2d\u7684\u4e92\u52a8\u5d4c\u5165\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eTIDFormer\u5728\u52a8\u6001\u56fe\u6570\u636e\u96c6\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5e76\u5728\u6548\u7387\u4e0a\u663e\u793a\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "TIDFormer\u5728\u52a8\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u548c\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u540c\u65f6\u5728\u6548\u7387\u4e0a\u4e5f\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684Transformer\u65b9\u6cd5\u3002"}}
{"id": "2506.00855", "pdf": "https://arxiv.org/pdf/2506.00855", "abs": "https://arxiv.org/abs/2506.00855", "authors": ["Sau Lai Yip", "Sunan He", "Yuxiang Nie", "Shu Pui Chan", "Yilin Ye", "Sum Ying Lam", "Hao Chen"], "title": "MedBookVQA: A Systematic and Comprehensive Medical Benchmark Derived from Open-Access Book", "categories": ["cs.AI"], "comment": "For data and code, see:\n  https://huggingface.co/datasets/slyipae1/MedBookVQA and\n  https://github.com/slyipae1/MedBookVQA", "summary": "The accelerating development of general medical artificial intelligence\n(GMAI), powered by multimodal large language models (MLLMs), offers\ntransformative potential for addressing persistent healthcare challenges,\nincluding workforce deficits and escalating costs. The parallel development of\nsystematic evaluation benchmarks emerges as a critical imperative to enable\nperformance assessment and provide technological guidance. Meanwhile, as an\ninvaluable knowledge source, the potential of medical textbooks for benchmark\ndevelopment remains underexploited. Here, we present MedBookVQA, a systematic\nand comprehensive multimodal benchmark derived from open-access medical\ntextbooks. To curate this benchmark, we propose a standardized pipeline for\nautomated extraction of medical figures while contextually aligning them with\ncorresponding medical narratives. Based on this curated data, we generate 5,000\nclinically relevant questions spanning modality recognition, disease\nclassification, anatomical identification, symptom diagnosis, and surgical\nprocedures. A multi-tier annotation system categorizes queries through\nhierarchical taxonomies encompassing medical imaging modalities (42\ncategories), body anatomies (125 structures), and clinical specialties (31\ndepartments), enabling nuanced analysis across medical subdomains. We evaluate\na wide array of MLLMs, including proprietary, open-sourced, medical, and\nreasoning models, revealing significant performance disparities across task\ntypes and model categories. Our findings highlight critical capability gaps in\ncurrent GMAI systems while establishing textbook-derived multimodal benchmarks\nas essential evaluation tools. MedBookVQA establishes textbook-derived\nbenchmarking as a critical paradigm for advancing clinical AI, exposing\nlimitations in GMAI systems while providing anatomically structured performance\nmetrics across specialties.", "AI": {"tldr": "\u672c\u6587\u63a8\u51faMedBookVQA\uff0c\u4e00\u4e2a\u4ece\u5f00\u653e\u533b\u7597\u6559\u79d1\u4e66\u4e2d\u884d\u751f\u7684\u7efc\u5408\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u4ee5\u8bc4\u4f30\u548c\u63ed\u793aGMAI\u7cfb\u7edf\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u968f\u7740\u901a\u7528\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u9700\u8981\u5f00\u53d1\u7cfb\u7edf\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u4ee5\u8bc4\u4f30\u6027\u80fd\u5e76\u4e3a\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u6307\u5bfc\u3002\u540c\u65f6\uff0c\u533b\u5b66\u6559\u79d1\u4e66\u4f5c\u4e3a\u57fa\u51c6\u5f00\u53d1\u7684\u5b9d\u8d35\u77e5\u8bc6\u6765\u6e90\uff0c\u5176\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6807\u51c6\u5316\u7ba1\u9053\uff0c\u901a\u8fc7\u81ea\u52a8\u63d0\u53d6\u533b\u5b66\u56fe\u4f8b\u5e76\u5c06\u5176\u4e0e\u76f8\u5e94\u7684\u533b\u5b66\u53d9\u8ff0\u8fdb\u884c\u4e0a\u4e0b\u6587\u5bf9\u9f50\u6765\u7b56\u5212\u57fa\u51c6\u3002\u57fa\u4e8e\u7b56\u5212\u7684\u6570\u636e\uff0c\u751f\u6210\u4e86\u6db5\u76d6\u6a21\u6001\u8bc6\u522b\u3001\u75be\u75c5\u5206\u7c7b\u3001\u89e3\u5256\u7ed3\u6784\u8bc6\u522b\u3001\u75c7\u72b6\u8bca\u65ad\u548c\u5916\u79d1\u624b\u672f\u76845000\u4e2a\u4e34\u5e8a\u76f8\u5173\u95ee\u9898\u3002\u91c7\u7528\u591a\u5c42\u6b21\u6ce8\u91ca\u7cfb\u7edf\u5c06\u67e5\u8be2\u901a\u8fc7\u533b\u5b66\u6210\u50cf\u6a21\u6001\uff0842\u7c7b\uff09\u3001\u8eab\u4f53\u89e3\u5256\u7ed3\u6784\uff08125\u4e2a\uff09\u548c\u4e34\u5e8a\u4e13\u4e1a\uff0831\u4e2a\u90e8\u95e8\uff09\u7684\u5c42\u6b21\u5206\u7c7b\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5bf9\u8bb8\u591aMLLM\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5305\u62ec\u4e13\u6709\u3001\u5f00\u6e90\u3001\u533b\u5b66\u548c\u63a8\u7406\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u4efb\u52a1\u7c7b\u578b\u548c\u6a21\u578b\u7c7b\u522b\u4e4b\u95f4\u7684\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u7a81\u51fa\u663e\u793a\u4e86\u5f53\u524dGMAI\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u80fd\u529b\u7f3a\u53e3\uff0c\u540c\u65f6\u4e5f\u786e\u7acb\u4e86\u6559\u79d1\u4e66\u884d\u751f\u7684\u591a\u6a21\u6001\u57fa\u51c6\u4f5c\u4e3a\u91cd\u8981\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "conclusion": "MedBookVQA\u901a\u8fc7\u4ece\u5f00\u653e\u83b7\u53d6\u7684\u533b\u5b66\u6559\u79d1\u4e66\u4e2d\u63d0\u53d6\u533b\u5b66\u56fe\u4f8b\u548c\u5bf9\u5e94\u7684\u53d9\u8ff0\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u5168\u9762\u7684\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709GMAI\u7cfb\u7edf\u7684\u663e\u8457\u80fd\u529b\u5dee\u8ddd\uff0c\u5e76\u5f15\u5165\u4e86\u533b\u5b66\u6559\u79d1\u4e66\u884d\u751f\u7684\u57fa\u51c6\u4f5c\u4e3a\u91cd\u8981\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2506.00334", "pdf": "https://arxiv.org/pdf/2506.00334", "abs": "https://arxiv.org/abs/2506.00334", "authors": ["Gerard Christopher Yeo", "Kokil Jaidka"], "title": "Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models", "categories": ["cs.CL"], "comment": "9 pages, 3 figures", "summary": "Datasets used for emotion recognition tasks typically contain overt cues that\ncan be used in predicting the emotions expressed in a text. However, one\nchallenge is that texts sometimes contain covert contextual cues that are rich\nin affective semantics, which warrant higher-order reasoning abilities to infer\nemotional states, not simply the emotions conveyed. This study advances beyond\nsurface-level perceptual features to investigate how large language models\n(LLMs) reason about others' emotional states using contextual information,\nwithin a Theory-of-Mind (ToM) framework. Grounded in Cognitive Appraisal\nTheory, we curate a specialized ToM evaluation dataset1 to assess both forward\nreasoning - from context to emotion- and backward reasoning - from emotion to\ninferred context. We showed that LLMs can reason to a certain extent, although\nthey are poor at associating situational outcomes and appraisals with specific\nemotions. Our work highlights the need for psychological theories in the\ntraining and evaluation of LLMs in the context of emotion reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5728\u7406\u8bba\u5fc3\u667a\u6846\u67b6\u5185\u901a\u8fc7\u8ba4\u77e5\u8bc4\u4ef7\u7406\u8bba\u8fdb\u884c\u60c5\u611f\u63a8\u7406\uff0c\u53d1\u73b0\u5176\u5728\u4e0e\u7279\u5b9a\u60c5\u611f\u5173\u8054\u60c5\u5883\u7ed3\u679c\u548c\u8bc4\u4ef7\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0c\u5f3a\u8c03\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u4e3a\u4e86\u8d85\u8d8a\u8868\u5c42\u611f\u77e5\u7279\u5f81\uff0c\u8c03\u67e5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u4f7f\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u63a8\u7406\u4ed6\u4eba\u7684\u60c5\u611f\u72b6\u6001\uff0c\u56e0\u4e3a\u6587\u672c\u4e2d\u6709\u65f6\u5305\u542b\u9690\u853d\u7684\u4e0a\u4e0b\u6587\u7ebf\u7d22\uff0c\u8fd9\u9700\u8981\u66f4\u9ad8\u9636\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5728\u4e00\u4e2a\u7406\u8bba\u5fc3\u667a (ToM) \u6846\u67b6\u5185\uff0c\u57fa\u4e8e\u8ba4\u77e5\u8bc4\u4ef7\u7406\u8bba\uff0c\u6211\u4eec\u7b56\u5212\u4e86\u4e00\u4e2a\u4e13\u95e8\u7684 ToM \u8bc4\u4f30\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u6b63\u5411\u63a8\u7406\uff08\u4ece\u60c5\u5883\u5230\u60c5\u611f\uff09\u548c\u9006\u5411\u63a8\u7406\uff08\u4ece\u60c5\u611f\u5230\u63a8\u65ad\u60c5\u5883\uff09\u3002", "result": "\u6211\u4eec\u53d1\u73b0\uff0cLLMs \u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u80fd\u591f\u8fdb\u884c\u63a8\u7406\uff0c\u4f46\u5b83\u4eec\u96be\u4ee5\u5c06\u60c5\u5883\u7ed3\u679c\u548c\u8bc4\u4ef7\u4e0e\u7279\u5b9a\u60c5\u611f\u8fdb\u884c\u5173\u8054\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u7a81\u51fa\u4e86\u5fc3\u7406\u5b66\u7406\u8bba\u5728\u60c5\u611f\u63a8\u7406\u65b9\u9762\u8bad\u7ec3\u548c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.00432", "pdf": "https://arxiv.org/pdf/2506.00432", "abs": "https://arxiv.org/abs/2506.00432", "authors": ["Seunghan Lee", "Taeyoung Park", "Kibok Lee"], "title": "Channel Normalization for Time Series Channel Identification", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025", "summary": "Channel identifiability (CID) refers to the ability to distinguish between\nindividual channels in time series (TS) modeling. The absence of CID often\nresults in producing identical outputs for identical inputs, disregarding\nchannel-specific characteristics. In this paper, we highlight the importance of\nCID and propose Channel Normalization (CN), a simple yet effective\nnormalization strategy that enhances CID by assigning distinct affine\ntransformation parameters to each channel. We further extend CN in two ways: 1)\nAdaptive CN (ACN) dynamically adjusts parameters based on the input TS,\nimproving adaptability in TS models, and 2) Prototypical CN (PCN) introduces a\nset of learnable prototypes instead of per-channel parameters, enabling\napplicability to datasets with unknown or varying number of channels and\nfacilitating use in TS foundation models. We demonstrate the effectiveness of\nCN and its variants by applying them to various TS models, achieving\nsignificant performance gains for both non-CID and CID models. In addition, we\nanalyze the success of our approach from an information theory perspective.\nCode is available at https://github.com/seunghan96/CN.", "AI": {"tldr": "This paper proposes Channel Normalization to improve channel identifiability in time series models, introducing adaptive and prototypical variants, leading to significant performance gains.", "motivation": "The paper aims to address the lack of channel identifiability in time series modeling, as the absence of it can lead to outputting identical values for identical inputs, ignoring channel-specific properties.", "method": "The paper introduces a normalization strategy called Channel Normalization (CN), which assigns distinct affine transformation parameters to each channel. It extends CN into Adaptive CN (ACN), which adjusts parameters based on input time series, and Prototypical CN (PCN), which uses learnable prototypes for better adaptability and application across various datasets.", "result": "The application of CN and its variants results in significant performance improvements across various time series models and datasets. The paper also provides an analysis from an information theory perspective demonstrating the success of their approach.", "conclusion": "Channel Normalization (CN) and its variants significantly enhance channel identifiability and performance in time series models by providing distinct affine transformations for each channel, leading to performance improvements across different datasets and models."}}
{"id": "2506.00865", "pdf": "https://arxiv.org/pdf/2506.00865", "abs": "https://arxiv.org/abs/2506.00865", "authors": ["Jiajun He", "Jinyi Mi", "Tomoki Toda"], "title": "GIA-MIC: Multimodal Emotion Recognition with Gated Interactive Attention and Modality-Invariant Learning Constraints", "categories": ["cs.AI"], "comment": "Accepted by INTERSPEECH 2025", "summary": "Multimodal emotion recognition (MER) extracts emotions from multimodal data,\nincluding visual, speech, and text inputs, playing a key role in human-computer\ninteraction. Attention-based fusion methods dominate MER research, achieving\nstrong classification performance. However, two key challenges remain:\neffectively extracting modality-specific features and capturing cross-modal\nsimilarities despite distribution differences caused by modality heterogeneity.\nTo address these, we propose a gated interactive attention mechanism to\nadaptively extract modality-specific features while enhancing emotional\ninformation through pairwise interactions. Additionally, we introduce a\nmodality-invariant generator to learn modality-invariant representations and\nconstrain domain shifts by aligning cross-modal similarities. Experiments on\nIEMOCAP demonstrate that our method outperforms state-of-the-art MER\napproaches, achieving WA 80.7% and UA 81.3%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u63d0\u53d6\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u5e76\u5bf9\u9f50\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u4e3b\u8981\u7531\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u878d\u5408\u65b9\u6cd5\u6240\u4e3b\u5bfc\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5206\u7c7b\u6027\u80fd\u4e0a\u8868\u73b0\u826f\u597d\u3002\u7136\u800c\uff0c\u5982\u4f55\u6709\u6548\u63d0\u53d6\u6a21\u6001\u7279\u5b9a\u7279\u5f81\u4ee5\u53ca\u514b\u670d\u7531\u6a21\u6001\u5f02\u8d28\u6027\u5f15\u8d77\u7684\u5206\u5e03\u5dee\u5f02\uff0c\u4ecd\u7136\u662f\u4e24\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u95e8\u63a7\u4ea4\u4e92\u6ce8\u610f\u529b\u673a\u5236\u548c\u4e00\u79cd\u6a21\u6001\u4e0d\u53d8\u751f\u6210\u5668\u3002\u524d\u8005\u7528\u4e8e\u81ea\u9002\u5e94\u63d0\u53d6\u6a21\u6001\u7279\u5b9a\u7279\u5f81\uff0c\u540c\u65f6\u901a\u8fc7\u6210\u5bf9\u4ea4\u4e92\u589e\u5f3a\u60c5\u611f\u4fe1\u606f\uff1b\u540e\u8005\u7528\u4e8e\u5b66\u4e60\u6a21\u6001\u4e0d\u53d8\u7684\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u5bf9\u9f50\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\u6765\u9650\u5236\u9886\u57df\u8f6c\u79fb\u3002", "result": "\u6211\u4eec\u5728IEMOCAP\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86WA 80.7%\u548cUA 81.3%\u7684\u8868\u73b0\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5236\uff0c\u80fd\u6709\u6548\u6539\u5584\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2506.00338", "pdf": "https://arxiv.org/pdf/2506.00338", "abs": "https://arxiv.org/abs/2506.00338", "authors": ["Yifan Peng", "Shakeel Muhammad", "Yui Sudo", "William Chen", "Jinchuan Tian", "Chyi-Jiunn Lin", "Shinji Watanabe"], "title": "OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted at INTERSPEECH 2025", "summary": "The Open Whisper-style Speech Models (OWSM) project has developed a series of\nfully open speech foundation models using academic-scale resources, but their\ntraining data remains insufficient. This work enhances OWSM by integrating\nYODAS, a large-scale web-crawled dataset with a Creative Commons license.\nHowever, incorporating YODAS is nontrivial due to its wild nature, which\nintroduces challenges such as incorrect language labels and audio-text\nmisalignments. To address this, we develop a scalable data-cleaning pipeline\nusing public toolkits, yielding a dataset with 166,000 hours of speech across\n75 languages. Our new series of OWSM v4 models, trained on this curated dataset\nalongside existing OWSM data, significantly outperform previous versions on\nmultilingual benchmarks. Our models even match or surpass frontier industrial\nmodels like Whisper and MMS in multiple scenarios. We will publicly release the\ncleaned YODAS data, pre-trained models, and all associated scripts via the\nESPnet toolkit.", "AI": {"tldr": "OWSM\u9879\u76ee\u901a\u8fc7\u5f15\u5165YODAS\u6570\u636e\u96c6\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u65b0\u7248\u672c\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u79c0\uff0c\u8ba1\u5212\u516c\u5f00\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u7684OWSM\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u5de5\u5177\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6570\u636e\u6e05\u7406\u7ba1\u7ebf\uff0c\u5e76\u7ed3\u5408\u5df2\u6709\u7684OWSM\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5904\u7406\u540e\u7684\u6570\u636e\u96c6\u5305\u542b166,000\u5c0f\u65f6\u7684\u8bed\u97f3\u6570\u636e\uff0c\u652f\u630175\u79cd\u8bed\u8a00\u3002\u65b0\u7cfb\u5217\u7684OWSM v4\u6a21\u578b\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u5c06\u5728ESPnet\u5de5\u5177\u5305\u4e2d\u53d1\u5e03\u76f8\u5173\u8d44\u6e90\u3002", "conclusion": "OWSM v4 model\u663e\u8457\u8d85\u8d8a\u4e86\u4ee5\u524d\u7684\u7248\u672c\uff0c\u5e76\u4e14\u5728\u591a\u79cd\u573a\u666f\u4e2d\u4e0e\u6216\u8d85\u8fc7\u4e3b\u6d41\u5de5\u4e1a\u6a21\u578b\u3002"}}
{"id": "2506.00436", "pdf": "https://arxiv.org/pdf/2506.00436", "abs": "https://arxiv.org/abs/2506.00436", "authors": ["Masahiro Kato", "Yuki Ikeda abd Kentaro Baba", "Takashi Imai", "Ryo Inokuchi"], "title": "Learning from Double Positive and Unlabeled Data for Potential-Customer Identification", "categories": ["cs.LG", "cs.AI", "econ.EM", "stat.ME", "stat.ML"], "comment": "Accepted for publication in the Proceedings of IIAI AAI 2025", "summary": "In this study, we propose a method for identifying potential customers in\ntargeted marketing by applying learning from positive and unlabeled data (PU\nlearning). We consider a scenario in which a company sells a product and can\nobserve only the customers who purchased it. Decision-makers seek to market\nproducts effectively based on whether people have loyalty to the company.\nIndividuals with loyalty are those who are likely to remain interested in the\ncompany even without additional advertising. Consequently, those loyal\ncustomers would likely purchase from the company if they are interested in the\nproduct. In contrast, people with lower loyalty may overlook the product or buy\nsimilar products from other companies unless they receive marketing attention.\nTherefore, by focusing marketing efforts on individuals who are interested in\nthe product but do not have strong loyalty, we can achieve more efficient\nmarketing. To achieve this goal, we consider how to learn, from limited data, a\nclassifier that identifies potential customers who (i) have interest in the\nproduct and (ii) do not have loyalty to the company. Although our algorithm\ncomprises a single-stage optimization, its objective function implicitly\ncontains two losses derived from standard PU learning settings. For this\nreason, we refer to our approach as double PU learning. We verify the validity\nof the proposed algorithm through numerical experiments, confirming that it\nfunctions appropriately for the problem at hand.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528PU\u5b66\u4e60\u8bc6\u522b\u6f5c\u5728\u5ba2\u6237\u7684\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u76ee\u6807\u8425\u9500\u4e2d\uff0c\u867d\u7136\u516c\u53f8\u53ea\u80fd\u89c2\u5bdf\u5230\u8d2d\u4e70\u4ea7\u54c1\u7684\u5ba2\u6237\uff0c\u4f46\u51b3\u7b56\u8005\u5e0c\u671b\u6839\u636e\u5ba2\u6237\u7684\u5fe0\u8bda\u5ea6\u6765\u6709\u6548\u5730\u5f00\u5c55\u4ea7\u54c1\u8425\u9500\u3002", "method": "\u4e00\u4e2a\u57fa\u4e8e\u6b63\u4f8b\u548c\u672a\u6807\u8bb0\u6570\u636e\u5b66\u4e60(PU\u5b66\u4e60)\u7684\u5355\u9636\u6bb5\u4f18\u5316\u7b97\u6cd5\uff0c\u76ee\u6807\u51fd\u6570\u9690\u542b\u4e86\u4e24\u79cd\u635f\u5931\u3002", "result": "\u7b97\u6cd5\u9002\u5f53\u5730\u8bc6\u522b\u4e86\u5bf9\u4ea7\u54c1\u611f\u5174\u8da3\u4f46\u5bf9\u516c\u53f8\u4e0d\u5fe0\u8bda\u7684\u6f5c\u5728\u5ba2\u6237\uff0c\u8fbe\u5230\u4e86\u66f4\u9ad8\u6548\u7684\u8425\u9500\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u786e\u8ba4\u5176\u53ef\u4ee5\u9002\u5f53\u5730\u89e3\u51b3\u95ee\u9898\u3002"}}
{"id": "2506.00886", "pdf": "https://arxiv.org/pdf/2506.00886", "abs": "https://arxiv.org/abs/2506.00886", "authors": ["Hongru Wang", "Cheng Qian", "Manling Li", "Jiahao Qiu", "Boyang Xue", "Mengdi Wang", "Heng Ji", "Kam-Fai Wong"], "title": "Toward a Theory of Agents as Tool-Use Decision-Makers", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) evolve into increasingly autonomous agents,\nfundamental questions about their epistemic foundations remain unresolved: What\ndefines an agent? How should it make decisions? And what objectives should\nguide its behavior? In this position paper, we argue that true autonomy\nrequires agents to be grounded in a coherent epistemic framework that governs\nwhat they know, what they need to know, and how to acquire that knowledge\nefficiently. We propose a unified theory that treats internal reasoning and\nexternal actions as equivalent epistemic tools, enabling agents to\nsystematically coordinate introspection and interaction. Building on this\nframework, we advocate for aligning an agent's tool use decision-making\nboundary with its knowledge boundary, thereby minimizing unnecessary tool use\nand maximizing epistemic efficiency. This perspective shifts the design of\nagents from mere action executors to knowledge-driven intelligence systems,\noffering a principled path toward building foundation agents capable of\nadaptive, efficient, and goal-directed behavior.", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u4e3b\u4ee3\u7406\u65f6\u7684\u8ba4\u8bc6\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7406\u8bba\u6765\u63d0\u9ad8\u4ee3\u7406\u7684\u81ea\u4e3b\u6027\u548c\u8ba4\u8bc6\u6548\u7387\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u4e3a\u66f4\u5177\u81ea\u4e3b\u6027\u7684\u4ee3\u7406\uff0c\u8feb\u5207\u9700\u8981\u89e3\u51b3\u5176\u8ba4\u8bc6\u57fa\u7840\u7684\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5982\u4f55\u5b9a\u4e49\u4e00\u4e2a\u4ee3\u7406\uff1f\u5b83\u5e94\u8be5\u5982\u4f55\u51b3\u7b56\uff1f\u6709\u54ea\u4e9b\u76ee\u6807\u53ef\u4ee5\u5f15\u5bfc\u5176\u884c\u4e3a\uff1f", "method": "\u63d0\u51fa\u4e00\u79cd\u7edf\u4e00\u7406\u8bba\uff0c\u5c06\u5185\u90e8\u63a8\u7406\u548c\u5916\u90e8\u884c\u52a8\u89c6\u4e3a\u7b49\u540c\u7684\u8ba4\u8bc6\u5de5\u5177\u3002\u8fd9\u4f7f\u5f97\u4ee3\u7406\u80fd\u591f\u7cfb\u7edf\u5730\u534f\u8c03\u81ea\u7701\u548c\u4e92\u52a8\u3002", "result": "\u8be5\u6846\u67b6\u5c06\u4ee3\u7406\u7684\u5de5\u5177\u4f7f\u7528\u51b3\u7b56\u8fb9\u754c\u4e0e\u5176\u77e5\u8bc6\u8fb9\u754c\u5bf9\u9f50\uff0c\u4ece\u800c\u6700\u5c0f\u5316\u4e0d\u5fc5\u8981\u7684\u5de5\u5177\u4f7f\u7528\u5e76\u6700\u5927\u5316\u8ba4\u8bc6\u6548\u7387\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4ee3\u7406\u8bbe\u8ba1\u4e3a\u77e5\u8bc6\u9a71\u52a8\u7684\u667a\u80fd\u7cfb\u7edf\uff0c\u8be5\u89c2\u70b9\u4e3a\u6784\u5efa\u5177\u6709\u9002\u5e94\u6027\u3001\u9ad8\u6548\u4e14\u76ee\u6807\u5bfc\u5411\u7684\u57fa\u7840\u4ee3\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u9014\u5f84\u3002"}}
{"id": "2506.00344", "pdf": "https://arxiv.org/pdf/2506.00344", "abs": "https://arxiv.org/abs/2506.00344", "authors": ["Sungjae Lee", "Hoyoung Kim", "Jeongyeon Hwang", "Eunhyeok Park", "Jungseul Ok"], "title": "Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Scaling test-time computation--generating and analyzing multiple or\nsequential outputs for a single input--has become a promising strategy for\nimproving the reliability and quality of large language models (LLMs), as\nevidenced by advances in uncertainty quantification and multi-step reasoning. A\nkey shared component is semantic clustering, which groups outputs that differ\nin form but convey the same meaning. Semantic clustering enables estimation of\nthe distribution over the semantics of outputs and helps avoid redundant\nexploration of reasoning paths. However, existing approaches typically rely on\nexternal models, which introduce substantial computational overhead and often\nfail to capture context-aware semantics. We propose Latent Semantic Clustering\n(LSC), a lightweight and context-sensitive method that leverages the generator\nLLM's internal hidden states for clustering, eliminating the need for external\nmodels. Our extensive experiment across various LLMs and datasets shows that\nLSC significantly improves the computational efficiency of test-time scaling\nwhile maintaining or exceeding the performance of existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u4e49\u805a\u7c7b\u65b9\u6cd5\uff08LSC\uff09\uff0c\u901a\u8fc7LLM\u7684\u5185\u90e8\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u805a\u7c7b\uff0c\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6548\u7387\uff0c\u65e0\u9700\u5916\u90e8\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53ef\u9760\u6027\u548c\u8d28\u91cf\uff0c\u6269\u5c55\u6d4b\u8bd5\u65f6\u7684\u8ba1\u7b97\uff08\u9488\u5bf9\u5355\u4e2a\u8f93\u5165\u751f\u6210\u5e76\u5206\u6790\u591a\u4e2a\u6216\u8fde\u7eed\u7684\u8f93\u51fa\uff09\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u7b56\u7565\u3002\u5176\u4e2d\uff0c\u8bed\u4e49\u805a\u7c7b\u662f\u4e00\u4e2a\u5173\u952e\u7684\u5171\u4eab\u7ec4\u4ef6\uff0c\u4f46\u662f\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5916\u90e8\u6a21\u578b\uff0c\u5bfc\u81f4\u5927\u91cf\u7684\u8ba1\u7b97\u5f00\u9500\u4e14\u5e38\u5e38\u65e0\u6cd5\u6355\u6349\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u8bed\u4e49\u3002", "method": "\u63d0\u51fa\u4e86\u6f5c\u5728\u8bed\u4e49\u805a\u7c7b\uff08LSC\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u751f\u6210\u5668LLM\u7684\u5185\u90e8\u9690\u85cf\u72b6\u6001\u8fdb\u884c\u805a\u7c7b\uff0c\u907f\u514d\u4e86\u5bf9\u5916\u90e8\u6a21\u578b\u7684\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLSC\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u8d85\u8fc7\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u4f7f\u7528\u56f0\u5173\u8bed\u4e49\u805a\u7c7b\uff08LSC\uff09\u65b9\u6cd5\u53ef\u4ee5\u5728\u4fdd\u6301\u6216\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.00437", "pdf": "https://arxiv.org/pdf/2506.00437", "abs": "https://arxiv.org/abs/2506.00437", "authors": ["Jiaxing Zhang", "Xiaoou Liu", "Dongsheng Luo", "Hua Wei"], "title": "Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "In Proceedings of the 31st ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD25)", "summary": "Explaining Graph Neural Networks (GNNs) has garnered significant attention\ndue to the need for interpretability, enabling users to understand the behavior\nof these black-box models better and extract valuable insights from their\npredictions. While numerous post-hoc instance-level explanation methods have\nbeen proposed to interpret GNN predictions, the reliability of these\nexplanations remains uncertain, particularly in the out-of-distribution or\nunknown test datasets. In this paper, we address this challenge by introducing\nan explainer framework with the confidence scoring module ( ConfExplainer),\ngrounded in theoretical principle, which is generalized graph information\nbottleneck with confidence constraint (GIB-CC), that quantifies the reliability\nof generated explanations. Experimental results demonstrate the superiority of\nour approach, highlighting the effectiveness of the confidence score in\nenhancing the trustworthiness and robustness of GNN explanations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6ConfExplainer\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u63d0\u9ad8\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u91ca\u7684\u53ef\u9760\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u89e3\u91ca\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u5916\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u80fd\u591f\u91cf\u5316\u89e3\u91ca\u53ef\u9760\u6027\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u89e3\u91ca\u5668\u6846\u67b6\uff0c\u5305\u542b\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u6a21\u5757\uff08ConfExplainer\uff09\uff0c\u91c7\u7528\u4e86\u4e00\u79cd\u7406\u8bba\u57fa\u7840\u4e3a\u5e7f\u4e49\u56fe\u4fe1\u606f\u74f6\u9888\u5e76\u52a0\u7f6e\u4fe1\u7ea6\u675f\uff08GIB-CC\uff09\u7684\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u5e76\u4e14\u7f6e\u4fe1\u8bc4\u5206\u6709\u6548\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u901a\u8fc7\u52a0\u5165\u7f6e\u4fe1\u5ea6\u8bc4\u5206\u6a21\u5757\uff0c\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u548c\u7a33\u5065\u6027\u3002"}}
{"id": "2506.00911", "pdf": "https://arxiv.org/pdf/2506.00911", "abs": "https://arxiv.org/abs/2506.00911", "authors": ["William Overman", "Mohsen Bayati"], "title": "Conformal Arbitrage: Risk-Controlled Balancing of Competing Objectives in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Modern language model deployments must often balance competing objectives,\nfor example, helpfulness versus harmlessness, cost versus accuracy, and reward\nversus safety. We introduce Conformal Arbitrage, a post hoc framework that\nlearns a data driven threshold to mediate between a Primary model optimized for\na primary objective and a more conservative Guardian which could be another\nmodel or a human domain expert aligned with a guardrail objective. The\nthreshold is calibrated with conformal risk control, yielding finite sample,\ndistribution free guarantees that the long run frequency of undesirable events,\nsuch as factual errors or safety violations, does not exceed a user specified\nquota. Because Conformal Arbitrage operates wholly at the API level, without\nrequiring access to model logits or updating model weights, it complements\nweight based alignment techniques and integrates seamlessly with existing cost\naware cascades. Empirically, Conformal Arbitrage traces an efficient frontier,\nallowing users to define an acceptable performance level for one objective\nwhile maximizing utility in another. We observe that our method outperforms, in\nterms of accuracy, cost matched random routing between models. These properties\nmake Conformal Arbitrage a practical, theoretically grounded tool for\ntrustworthy and economical deployment of large language models across a broad\nrange of potentially competing objectives.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aConformal Arbitrage\u7684\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u9608\u503c\u7ba1\u7406\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4e2a\u76ee\u6807\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728API\u7ea7\u522b\u64cd\u4f5c\uff0c\u786e\u4fdd\u4e0d\u826f\u4e8b\u4ef6\u7684\u957f\u8fdc\u9891\u7387\u4e0d\u8d85\u8fc7\u7528\u6237\u8bbe\u5b9a\u7684\u9650\u989d\uff0c\u5e76\u80fd\u4e0e\u73b0\u6709\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002", "motivation": "\u5728\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\uff0c\u901a\u5e38\u9700\u8981\u5728\u591a\u4e2a\u7ade\u4e89\u76ee\u6807\u4e4b\u95f4\u627e\u5230\u5e73\u8861\uff0c\u4f8b\u5982\u6709\u7528\u6027\u4e0e\u65e0\u5bb3\u6027\u3001\u6210\u672c\u4e0e\u51c6\u786e\u6027\u3001\u5956\u52b1\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u79f0\u4e3aConformal Arbitrage\u7684\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u4e8b\u540e\u6846\u67b6\uff0c\u7528\u6570\u636e\u9a71\u52a8\u7684\u9608\u503c\u6765\u5728\u4f18\u5316\u4e3b\u8981\u76ee\u6807\u7684\u4e3b\u6a21\u578b\u548c\u66f4\u4fdd\u5b88\u7684Guardian\u4e4b\u95f4\u8fdb\u884c\u8c03\u89e3\u3002\u9608\u503c\u901a\u8fc7\u4fdd\u89d2\u98ce\u9669\u63a7\u5236\u8fdb\u884c\u6821\u51c6\uff0c\u786e\u4fdd\u4e0d\u826f\u4e8b\u4ef6\u7684\u957f\u8fdc\u9891\u7387\u4e0d\u8d85\u8fc7\u7528\u6237\u89c4\u5b9a\u7684\u9650\u989d\u3002\u8be5\u65b9\u6cd5\u5728API\u7ea7\u522b\u64cd\u4f5c\uff0c\u65e0\u9700\u8bbf\u95ee\u6a21\u578blogits\u6216\u66f4\u65b0\u6a21\u578b\u6743\u91cd\uff0c\u56e0\u6b64\u80fd\u591f\u4e0e\u73b0\u6709\u7684\u57fa\u4e8e\u6743\u91cd\u7684\u5bf9\u9f50\u6280\u672f\u548c\u6210\u672c\u610f\u8bc6\u7ea7\u8054\u65e0\u7f1d\u96c6\u6210\u3002", "result": "Empirically, Conformal Arbitrage traces an efficient frontier, allowing users to define an acceptable performance level for one objective while maximizing utility in another.\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u968f\u673a\u8def\u7531\u5339\u914d\u6210\u672c\u65b9\u9762\u7684\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u5f97\u66f4\u597d\u3002", "conclusion": "Conformal Arbitrage\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u5177\u6709\u7406\u8bba\u57fa\u7840\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u5728\u5177\u6709\u6f5c\u5728\u7ade\u4e89\u76ee\u6807\u7684\u5e7f\u6cdb\u90e8\u7f72\u4e2d\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u548c\u7ecf\u6d4e\u90e8\u7f72\u3002"}}
{"id": "2506.00381", "pdf": "https://arxiv.org/pdf/2506.00381", "abs": "https://arxiv.org/abs/2506.00381", "authors": ["Siavash Shams", "Richard Antonello", "Gavin Mischler", "Stephan Bickel", "Ashesh Mehta", "Nima Mesgarani"], "title": "Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG", "categories": ["cs.CL", "eess.AS", "eess.SP"], "comment": "Accepted at Interspeech 2025 Code at\n  https://github.com/SiavashShams/neuro2semantic", "summary": "Decoding continuous language from neural signals remains a significant\nchallenge in the intersection of neuroscience and artificial intelligence. We\nintroduce Neuro2Semantic, a novel framework that reconstructs the semantic\ncontent of perceived speech from intracranial EEG (iEEG) recordings. Our\napproach consists of two phases: first, an LSTM-based adapter aligns neural\nsignals with pre-trained text embeddings; second, a corrector module generates\ncontinuous, natural text directly from these aligned embeddings. This flexible\nmethod overcomes the limitations of previous decoding approaches and enables\nunconstrained text generation. Neuro2Semantic achieves strong performance with\nas little as 30 minutes of neural data, outperforming a recent state-of-the-art\nmethod in low-data settings. These results highlight the potential for\npractical applications in brain-computer interfaces and neural decoding\ntechnologies.", "AI": {"tldr": "Neuro2Semantic\u6846\u67b6\u4f7f\u7528iEEG\u8bb0\u5f55\u6709\u6548\u91cd\u6784\u8bed\u97f3\u8bed\u4e49\u5185\u5bb9\uff0c\u5177\u6709\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u8111\u673a\u63a5\u53e3\u3002", "motivation": "\u5728\u795e\u7ecf\u79d1\u5b66\u548c\u4eba\u5de5\u667a\u80fd\u7684\u4ea4\u53c9\u9886\u57df\uff0c\u89e3\u7801\u795e\u7ecf\u4fe1\u53f7\u4e2d\u7684\u8fde\u7eed\u8bed\u8a00\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u91cd\u6784\u611f\u77e5\u8bed\u97f3\u8bed\u4e49\u5185\u5bb9\u7684\u65b0\u6846\u67b6\u3002", "method": "Neuro2Semantic\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\uff0c\u4e00\u4e2a\u57fa\u4e8eLSTM\u7684\u9002\u914d\u5668\u5c06\u795e\u7ecf\u4fe1\u53f7\u4e0e\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5d4c\u5165\u5bf9\u9f50\uff1b\u5176\u6b21\uff0c\u4e00\u4e2a\u6821\u6b63\u6a21\u5757\u4ece\u8fd9\u4e9b\u5bf9\u9f50\u7684\u5d4c\u5165\u4e2d\u76f4\u63a5\u751f\u6210\u8fde\u7eed\u7684\u81ea\u7136\u6587\u672c\u3002", "result": "Neuro2Semantic\u5728\u4ec530\u5206\u949f\u7684\u795e\u7ecf\u6570\u636e\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5728\u4f4e\u6570\u636e\u73af\u5883\u4e2d\u4f18\u4e8e\u6700\u65b0\u7684\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "Neuro2Semantic\u6846\u67b6\u80fd\u591f\u5728\u4f4e\u6570\u636e\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5f3a\u5927\u7684\u8bed\u4e49\u5185\u5bb9\u91cd\u6784\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u8111\u673a\u63a5\u53e3\u548c\u795e\u7ecf\u89e3\u7801\u6280\u672f\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2506.00438", "pdf": "https://arxiv.org/pdf/2506.00438", "abs": "https://arxiv.org/abs/2506.00438", "authors": ["Keisuke Sugiura", "Mizuki Yasuda", "Hiroki Matsutani"], "title": "PointODE: Lightweight Point Cloud Learning with Neural Ordinary Differential Equations on Edge", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Embedded edge devices are often used as a computing platform to run\nreal-world point cloud applications, but recent deep learning-based methods may\nnot fit on such devices due to limited resources. In this paper, we aim to fill\nthis gap by introducing PointODE, a parameter-efficient ResNet-like\narchitecture for point cloud feature extraction based on a stack of MLP blocks\nwith residual connections. We leverage Neural ODE (Ordinary Differential\nEquation), a continuous-depth version of ResNet originally developed for\nmodeling the dynamics of continuous-time systems, to compress PointODE by\nreusing the same parameters across MLP blocks. The point-wise normalization is\nproposed for PointODE to handle the non-uniform distribution of feature points.\nWe introduce PointODE-Elite as a lightweight version with 0.58M trainable\nparameters and design its dedicated accelerator for embedded FPGAs. The\naccelerator consists of a four-stage pipeline to parallelize the feature\nextraction for multiple points and stores the entire parameters on-chip to\neliminate most of the off-chip data transfers. Compared to the ARM Cortex-A53\nCPU, the accelerator implemented on a Xilinx ZCU104 board speeds up the feature\nextraction by 4.9x, leading to 3.7x faster inference and 3.5x better\nenergy-efficiency. Despite the simple architecture, PointODE-Elite shows\ncompetitive accuracy to the state-of-the-art models on both synthetic and\nreal-world classification datasets, greatly improving the trade-off between\naccuracy and inference cost.", "AI": {"tldr": "Introduces PointODE, a resource-efficient model for point cloud feature extraction with an FPGA accelerator, improving speed and energy efficiency on edge devices without compromising accuracy.", "motivation": "To address the gap in running recent deep learning-based methods for point cloud applications on embedded edge devices with resource constraints.", "method": "Developed PointODE, a parameter-efficient architecture utilizing Neural ODE with MLP blocks and residual connections, and introduced PointODE-Elite with 0.58M trainable parameters. Designed a dedicated FPGA accelerator for efficient inference.", "result": "PointODE-Elite speeds up feature extraction by 4.9x, inference by 3.7x, and improves energy-efficiency by 3.5x on Xilinx ZCU104 board compared to ARM Cortex-A53 while maintaining competitive accuracy.", "conclusion": "PointODE-Elite offers competitive accuracy compared to state-of-the-art models while significantly enhancing the trade-off between accuracy and inference cost on embedded platforms."}}
{"id": "2506.00930", "pdf": "https://arxiv.org/pdf/2506.00930", "abs": "https://arxiv.org/abs/2506.00930", "authors": ["Yongqi Li", "Shen Zhou", "Xiaohu Li", "Xin Miao", "Jintao Wen", "Mayi Xu", "Jianhao Chen", "Birong Pan", "Hankun Kang", "Yuanyuan Zhu", "Ming Zhong", "Tieyun Qian"], "title": "Aligning VLM Assistants with Personalized Situated Cognition", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 (main), camera-ready version", "summary": "Vision-language models (VLMs) aligned with general human objectives, such as\nbeing harmless and hallucination-free, have become valuable assistants of\nhumans in managing visual tasks. However, people with diversified backgrounds\nhave different cognition even in the same situation. Consequently, they may\nhave personalized expectations for VLM assistants. This highlights the urgent\nneed to align VLM assistants with personalized situated cognition for\nreal-world assistance. To study this problem, we first simplify it by\ncharacterizing individuals based on the sociological concept of Role-Set. Then,\nwe propose to evaluate the individuals' actions to examine whether the\npersonalized alignment is achieved. Further, we construct a benchmark named\nPCogAlignBench, which includes 18k instances and 20 individuals with different\nRole-Sets. Finally, we present a framework called PCogAlign, which constructs a\ncognition-aware and action-based reward model for personalized alignment.\nExperimental results and human evaluations demonstrate the reliability of the\nPCogAlignBench and the effectiveness of our proposed PCogAlign. We will\nopen-source the constructed benchmark and code at\nhttps://github.com/NLPGM/PCogAlign.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5c06\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e0e\u4e2a\u6027\u5316\u7684\u60c5\u5883\u8ba4\u77e5\u8fdb\u884c\u5bf9\u9f50\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u4e0d\u540c\u80cc\u666f\u7684\u4eba\u5373\u4f7f\u5728\u540c\u6837\u7684\u60c5\u51b5\u4e0b\u4e5f\u4f1a\u6709\u4e0d\u540c\u7684\u8ba4\u77e5\uff0c\u56e0\u6b64\u4ed6\u4eec\u5bf9VLM\u52a9\u624b\u7684\u671f\u671b\u53ef\u80fd\u662f\u4e2a\u6027\u5316\u7684\u3002\u8fd9\u79cd\u5dee\u5f02\u5316\u7684\u9700\u6c42\u4f7f\u5f97\u9700\u8981\u7d27\u6025\u8c03\u6574VLM\u52a9\u624b\u4ee5\u9002\u5e94\u4e2a\u6027\u5316\u7684\u60c5\u5883\u8ba4\u77e5\u3002", "method": "\u672c\u6587\u57fa\u4e8e\u89d2\u8272\u96c6\u5408\u89d2\u8272\u7406\u8bba\u5bf9\u4e2a\u4f53\u8fdb\u884c\u7b80\u5316\uff0c\u7136\u540e\u8bc4\u4f30\u4e2a\u4f53\u7684\u884c\u52a8\u6765\u68c0\u67e5\u4e2a\u6027\u5316\u5bf9\u9f50\u662f\u5426\u5b9e\u73b0\u3002\u6784\u5efa\u4e86PCogAlignBench\u57fa\u51c6\uff0c\u5305\u542b18k\u5b9e\u4f8b\u548c20\u4e2a\u4e0d\u540c\u89d2\u8272\u96c6\u5408\u7684\u4e2a\u4f53\uff0c\u5e76\u63d0\u51fa\u4e86PCogAlign\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u611f\u77e5\u548c\u57fa\u4e8e\u884c\u4e3a\u7684\u5956\u52b1\u6a21\u578b\u5b9e\u73b0\u4e2a\u6027\u5316\u5bf9\u9f50\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u548c\u4eba\u7c7b\u8bc4\u4f30\u8bc1\u660e\u4e86PCogAlignBench\u7684\u53ef\u9760\u6027\u4ee5\u53caPCogAlign\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "PCogAlignBench\u57fa\u51c6\u548cPCogAlign\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5316\u8ba4\u77e5\u5bf9\u9f50\uff0c\u5e76\u5c06\u5728GitHub\u4e0a\u5f00\u6e90\u3002"}}
{"id": "2506.00386", "pdf": "https://arxiv.org/pdf/2506.00386", "abs": "https://arxiv.org/abs/2506.00386", "authors": ["Keyeun Lee", "Seolhee Lee", "Esther Hehsun Kim", "Yena Ko", "Jinsu Eun", "Dahee Kim", "Hyewon Cho", "Haiyi Zhu", "Robert E. Kraut", "Eunyoung Suh", "Eun-mee Kim", "Hajin Lim"], "title": "Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training", "categories": ["cs.CL", "cs.HC"], "comment": "ACL 2025 Findings, 34 pages, 9 figures", "summary": "Effective communication training is essential to preparing nurses for\nhigh-quality patient care. While standardized patient (SP) simulations provide\nvaluable experiential learning, they are often costly and inflexible. Virtual\npatient (VP) systems offer a scalable alternative, but most fail to adapt to\nthe varying communication skills of trainees. In particular, when trainees\nrespond ineffectively, VPs should escalate in hostility or become\nuncooperative--yet this level of adaptive interaction remains largely\nunsupported. To address this gap, we introduce Adaptive-VP, a VP dialogue\ngeneration framework that leverages large language models (LLMs) to dynamically\nadapt VP behavior based on trainee input. The framework features a pipeline for\nconstructing clinically grounded yet flexible VP scenarios and a modular system\nfor assessing trainee communication and adjusting VP responses in real time,\nwhile ensuring learner safety. We validated Adaptive-VP by simulating\nchallenging patient conversations. Automated evaluation using a corpus from\npracticing nurses showed that our communication skill evaluation mechanism\nreflected real-world proficiency levels. Expert nurses further confirmed that\nAdaptive-VP produced more natural and realistic interactions than existing\napproaches, demonstrating its potential as a scalable and effective tool for\nnursing communication training.", "AI": {"tldr": "Adaptive-VP\u7cfb\u7edf\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4e3a\u62a4\u7406\u6c9f\u901a\u63d0\u4f9b\u52a8\u6001\u4e92\u52a8\u548c\u9002\u5e94\u6027\u8bc4\u4f30\uff0c\u88ab\u4e13\u5bb6\u9a8c\u8bc1\u4e3a\u66f4\u8d34\u8fd1\u771f\u5b9e\u7684\u6559\u5b66\u5de5\u5177\u3002", "motivation": "\u4e3a\u4e86\u586b\u8865\u865a\u62df\u60a3\u8005\u7cfb\u7edf\u7f3a\u4e4f\u54cd\u5e94\u6027\u4e92\u52a8\u7684\u7a7a\u767d\uff0c\u63d0\u9ad8\u62a4\u7406\u4eba\u5458\u7684\u6c9f\u901a\u8bad\u7ec3\u8d28\u91cf\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u52a8\u6001\u9002\u5e94VP\u884c\u4e3a\u7684Adaptive-VP\u5bf9\u8bdd\u751f\u6210\u6846\u67b6\u3002", "result": "\u4e13\u5bb6\u62a4\u58eb\u786e\u8ba4Adaptive-VP\u6bd4\u73b0\u6709\u65b9\u6cd5\u4ea7\u751f\u66f4\u81ea\u7136\u548c\u903c\u771f\u7684\u4e92\u52a8\uff0c\u9a8c\u8bc1\u663e\u793a\u6c9f\u901a\u6280\u80fd\u8bc4\u4f30\u673a\u5236\u53cd\u6620\u4e86\u73b0\u5b9e\u4e16\u754c\u7684\u719f\u7ec3\u7a0b\u5ea6\u3002", "conclusion": "Adaptive-VP\u751f\u6210\u66f4\u81ea\u7136\u548c\u771f\u5b9e\u7684\u4e92\u52a8\uff0c\u88ab\u8ba4\u4e3a\u662f\u4e00\u79cd\u6709\u6548\u7684\u62a4\u7406\u6c9f\u901a\u8bad\u7ec3\u5de5\u5177\u3002"}}
{"id": "2506.00439", "pdf": "https://arxiv.org/pdf/2506.00439", "abs": "https://arxiv.org/abs/2506.00439", "authors": ["Yuqian Fu", "Yuanheng Zhu", "Jiajun Chai", "Guojun Yin", "Wei Lin", "Qichao Zhang", "Dongbin Zhao"], "title": "RLAE: Reinforcement Learning-Assisted Ensemble for LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Ensembling large language models (LLMs) can effectively combine diverse\nstrengths of different models, offering a promising approach to enhance\nperformance across various tasks. However, existing methods typically rely on\nfixed weighting strategies that fail to adapt to the dynamic, context-dependent\ncharacteristics of LLM capabilities. In this work, we propose Reinforcement\nLearning-Assisted Ensemble for LLMs (RLAE), a novel framework that reformulates\nLLM ensemble through the lens of a Markov Decision Process (MDP). Our approach\nintroduces a RL agent that dynamically adjusts ensemble weights by considering\nboth input context and intermediate generation states, with the agent being\ntrained using rewards that directly correspond to the quality of final outputs.\nWe implement RLAE using both single-agent and multi-agent reinforcement\nlearning algorithms ($\\text{RLAE}_\\text{PPO}$ and $\\text{RLAE}_\\text{MAPPO}$ ),\ndemonstrating substantial improvements over conventional ensemble methods.\nExtensive evaluations on a diverse set of tasks show that RLAE outperforms\nexisting approaches by up to $3.3\\%$ accuracy points, offering a more effective\nframework for LLM ensembling. Furthermore, our method exhibits superior\ngeneralization capabilities across different tasks without the need for\nretraining, while simultaneously achieving lower time latency.", "AI": {"tldr": "RLAE uses reinforcement learning to improve LLM ensembles, achieving higher accuracy, better generalization, and lower latency than traditional methods.", "motivation": "To enhance the performance of LLMs ensembling by overcoming the limitations of fixed weighting strategies in adapting to dynamic and context-dependent characteristics.", "method": "Reinforcement Learning-Assisted Ensemble for LLMs (RLAE) using Markov Decision Process with RL agent adjusting weights dynamically.", "result": "RLAE shows better performance with up to 3.3% higher accuracy, superior generalization across tasks, and reduced time latency compared to existing ensemble methods.", "conclusion": "RLAE demonstrates substantial improvements over conventional ensemble methods with up to 3.3% increase in accuracy, better generalization across tasks, and lower latency."}}
{"id": "2506.00958", "pdf": "https://arxiv.org/pdf/2506.00958", "abs": "https://arxiv.org/abs/2506.00958", "authors": ["Youngmin Kim", "Jiwan Chung", "Jisoo Kim", "Sunghyun Lee", "Sangkyu Lee", "Junhyeok Kim", "Cheoljong Yang", "Youngjae Yu"], "title": "Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "Accepted to ACL 2025 (Main), Our code and dataset:\n  https://github.com/winston1214/nonverbal-conversation", "summary": "Nonverbal communication is integral to human interaction, with gestures,\nfacial expressions, and body language conveying critical aspects of intent and\nemotion. However, existing large language models (LLMs) fail to effectively\nincorporate these nonverbal elements, limiting their capacity to create fully\nimmersive conversational experiences. We introduce MARS, a multimodal language\nmodel designed to understand and generate nonverbal cues alongside text,\nbridging this gap in conversational AI. Our key innovation is VENUS, a\nlarge-scale dataset comprising annotated videos with time-aligned text, facial\nexpressions, and body language. Leveraging VENUS, we train MARS with a\nnext-token prediction objective, combining text with vector-quantized nonverbal\nrepresentations to achieve multimodal understanding and generation within a\nunified framework. Based on various analyses of the VENUS datasets, we validate\nits substantial scale and high effectiveness. Our quantitative and qualitative\nresults demonstrate that MARS successfully generates text and nonverbal\nlanguages, corresponding to conversational input.", "AI": {"tldr": "MARS\u662f\u4e00\u79cd\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7VENUS\u6570\u636e\u96c6\u6574\u5408\u975e\u8bed\u8a00\u5143\u7d20\u5b9e\u73b0\u66f4\u6c89\u6d78\u5f0f\u7684\u5bf9\u8bdd\u4f53\u9a8c\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u672a\u80fd\u6709\u6548\u6574\u5408\u975e\u8bed\u8a00\u5143\u7d20\uff0c\u9650\u5236\u4e86\u5176\u521b\u9020\u5b8c\u5168\u6c89\u6d78\u5f0f\u5bf9\u8bdd\u4f53\u9a8c\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6a21\u578b\u4ee5\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u7ed3\u5408\u4e86\u6587\u672c\u4e0e\u77e2\u91cf\u91cf\u5316\u7684\u975e\u8bed\u8a00\u8868\u8ff0\u7684\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u76ee\u6807\u65b9\u6cd5\u5bf9MARS\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u7684\u7edf\u4e00\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARS\u80fd\u591f\u6210\u529f\u751f\u6210\u4e0e\u5bf9\u8bdd\u5185\u5bb9\u76f8\u5339\u914d\u7684\u6587\u672c\u548c\u975e\u8bed\u8a00\u4fe1\u606f\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u73b0\u591a\u6a21\u6001\u5bf9\u8bdd\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "MARS\u6a21\u578b\u6210\u529f\u751f\u6210\u4e86\u4e0e\u5bf9\u8bdd\u8f93\u5165\u76f8\u5bf9\u5e94\u7684\u6587\u672c\u548c\u975e\u8bed\u8a00\u4fe1\u606f\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.00391", "pdf": "https://arxiv.org/pdf/2506.00391", "abs": "https://arxiv.org/abs/2506.00391", "authors": ["Ge Qu", "Jinyang Li", "Bowen Qin", "Xiaolong Li", "Nan Huo", "Chenhao Ma", "Reynold Cheng"], "title": "SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main", "summary": "Current self-correction approaches in text-to-SQL face two critical\nlimitations: 1) Conventional self-correction methods rely on recursive\nself-calls of LLMs, resulting in multiplicative computational overhead, and 2)\nLLMs struggle to implement effective error detection and correction for\ndeclarative SQL queries, as they fail to demonstrate the underlying reasoning\npath. In this work, we propose SHARE, an SLM-based Hierarchical Action\ncorREction assistant that enables LLMs to perform more precise error\nlocalization and efficient correction. SHARE orchestrates three specialized\nSmall Language Models (SLMs) in a sequential pipeline, where it first\ntransforms declarative SQL queries into stepwise action trajectories that\nreveal underlying reasoning, followed by a two-phase granular refinement. We\nfurther propose a novel hierarchical self-evolution strategy for data-efficient\ntraining. Experimental results demonstrate that SHARE effectively enhances\nself-correction capabilities while proving robust across various LLMs.\nFurthermore, our comprehensive analysis shows that SHARE maintains strong\nperformance even in low-resource training settings, which is particularly\nvaluable for text-to-SQL applications with data privacy constraints.", "AI": {"tldr": "SHARE\u901a\u8fc7\u5206\u5c42\u884c\u52a8\u7ea0\u6b63\u52a9\u7406\u6539\u5584\u6587\u672c\u5230SQL\u7684\u9519\u8bef\u5b9a\u4f4d\u548c\u7ea0\u6b63\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u9ad8\u6548\u6027\u548c\u7a33\u5065\u6027\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u548c\u6570\u636e\u9690\u79c1\u9650\u5236\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230SQL\u7684\u81ea\u6211\u7ea0\u6b63\u65b9\u6cd5\u5b58\u5728\u9012\u5f52\u8ba1\u7b97\u5f00\u9500\u5927\u548c\u7f3a\u4e4f\u6709\u6548\u9519\u8bef\u68c0\u6d4b\u53ca\u7ea0\u6b63\u8fd9\u4e24\u4e2a\u5c40\u9650\u6027\u3002", "method": "SHARE\u4f7f\u7528\u57fa\u4e8eSLMs\u7684\u4e09\u4e2a\u4e13\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u4e00\u4e2a\u987a\u5e8f\u6d41\u6c34\u7ebf\u4e2d\u5de5\u4f5c\uff0c\u9996\u5148\u5c06\u58f0\u660e\u6027SQL\u67e5\u8be2\u8f6c\u6362\u4e3a\u9010\u6b65\u63ed\u793a\u5e95\u5c42\u63a8\u7406\u7684\u884c\u52a8\u8f68\u8ff9\uff0c\u7136\u540e\u8fdb\u884c\u4e24\u9636\u6bb5\u7ec6\u5316\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u5c42\u81ea\u6211\u8fdb\u5316\u7b56\u7565\u4ee5\u63d0\u9ad8\u6570\u636e\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSHARE\u6709\u6548\u63d0\u5347\u4e86\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u5404\u79cdLLMs\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "SHARE\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u7684\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\uff0c\u5e76\u5728\u4f4e\u8d44\u6e90\u8bad\u7ec3\u73af\u5883\u4e2d\u4f9d\u7136\u8868\u73b0\u5f3a\u52b2\uff0c\u5bf9\u6570\u636e\u9690\u79c1\u6709\u9650\u5236\u7684\u6587\u672c\u5230SQL\u5e94\u7528\u5c24\u5176\u6709\u4ef7\u503c\u3002"}}
{"id": "2506.00440", "pdf": "https://arxiv.org/pdf/2506.00440", "abs": "https://arxiv.org/abs/2506.00440", "authors": ["Daniel-M. Jimenez-Gutierrez", "David Solans", "Mohammed Elbamby", "Nicolas Kourtellis"], "title": "PSI-PFL: Population Stability Index for Client Selection in non-IID Personalized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables decentralized machine learning (ML) model\ntraining while preserving data privacy by keeping data localized across\nclients. However, non-independent and identically distributed (non-IID) data\nacross clients poses a significant challenge, leading to skewed model updates\nand performance degradation. Addressing this, we propose PSI-PFL, a novel\nclient selection framework for Personalized Federated Learning (PFL) that\nleverages the Population Stability Index (PSI) to quantify and mitigate data\nheterogeneity (so-called non-IIDness). Our approach selects more homogeneous\nclients based on PSI, reducing the impact of label skew, one of the most\ndetrimental factors in FL performance. Experimental results over multiple data\nmodalities (tabular, image, text) demonstrate that PSI-PFL significantly\nimproves global model accuracy, outperforming state-of-the-art baselines by up\nto 10\\% under non-IID scenarios while ensuring fairer local performance.\nPSI-PFL enhances FL performance and offers practical benefits in applications\nwhere data privacy and heterogeneity are critical.", "AI": {"tldr": "PSI-PFL\u6846\u67b6\u901a\u8fc7\u4f7f\u7528PSI\u9009\u62e9\u66f4\u5747\u5300\u7684\u5ba2\u6237\u7aef\u6765\u6539\u5584\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u5e94\u5bf9non-IID\u6570\u636e\u5bfc\u81f4\u7684\u6311\u6218\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u5bfc\u81f4\u6a21\u578b\u66f4\u65b0\u504f\u659c\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PSI-PFL\u4f7f\u7528\u4eba\u53e3\u7a33\u5b9a\u6027\u6307\u6570\uff08PSI\uff09\u6765\u91cf\u5316\u548c\u7f13\u89e3\u6570\u636e\u5f02\u8d28\u6027\uff0c\u901a\u8fc7\u9009\u62e9\u66f4\u5747\u5300\u7684\u5ba2\u6237\u7aef\u6765\u51cf\u5c11\u6807\u7b7e\u503e\u659c\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPSI-PFL\u5728\u591a\u79cd\u6570\u636e\u6a21\u6001\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u5168\u7403\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5728non-IID\u573a\u666f\u4e0b\u6027\u80fd\u8d85\u8d8a\u4e86\u6700\u65b0\u57fa\u7ebf\u6a21\u578b\u8fbe10%\u3002", "conclusion": "PSI-PFL\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u9690\u79c1\u548c\u5f02\u8d28\u6027\u81f3\u5173\u91cd\u8981\u7684\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.00965", "pdf": "https://arxiv.org/pdf/2506.00965", "abs": "https://arxiv.org/abs/2506.00965", "authors": ["Fan Liu", "Bikang Pan", "Zhongyi Wang", "Xi Yao", "Xiaoying Tang", "Jingya Wang", "Ye Shi"], "title": "Unlocking Personalized Knowledge in Federated Large Language Model: The Power of Mixture of Experts", "categories": ["cs.AI"], "comment": null, "summary": "The Mixture of Experts (MoE) architecture has emerged as a prominent strategy\nfor scaling large language models (LLMs), effectively leveraging sparse\nactivation and facilitating task-specific personalization. However, current\nfederated learning (FL) approaches are primarily designed for dense models,\nmaking them unable to directly exploit the sparsity inherent in MoE\narchitectures. Treating MoE models as dense networks in federated scenarios\nresults in excessive communication overhead and computational costs,\nundermining the potential for personalized knowledge sharing. To address these\nchallenges, we propose FLEx (Federated LLMs with Personalized Experts), a novel\nfederated learning framework explicitly tailored for MoE-based LLMs. FLEx\nefficiently personalizes by pruning the global MoE model to keep only one\nexpert per client, and employs an adaptive gating mechanism to reintegrate\nthese personalized experts into the pre-trained MoE layers, ensuring the\noriginal backbone architecture remains unchanged. These personalized experts\nare trained with local data and stored locally on each client, while the shared\nmodules are aggregated globally. Extensive evaluations on diverse\ninstruction-based datasets under non-IID conditions consistently demonstrate\nthat FLEx outperforms existing federated baselines. Our code is available at\nhttps://anonymous.4open.science/r/FLEx-8F12.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51faFLEx\uff0c\u4e3aMoE\u6a21\u578b\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4fdd\u7559\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4e00\u4e2a\u4e13\u5bb6\uff0c\u5e76\u4f7f\u7528\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u91cd\u65b0\u6574\u5408\u8fd9\u4e9b\u4e13\u5bb6\u3002\u8bc4\u4f30\u663e\u793aFLEx\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u3002", "motivation": "\u5f53\u524d\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u8bbe\u8ba1\u7528\u4e8e\u5bc6\u96c6\u6a21\u578b\uff0c\u65e0\u6cd5\u76f4\u63a5\u5229\u7528\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u4e2d\u7684\u7a00\u758f\u6027\u3002\u5c06MoE\u6a21\u578b\u89c6\u4e3a\u8054\u90a6\u573a\u666f\u4e2d\u7684\u5bc6\u96c6\u7f51\u7edc\u4f1a\u5bfc\u81f4\u8fc7\u591a\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u524a\u5f31\u4e2a\u6027\u5316\u77e5\u8bc6\u5171\u4eab\u7684\u6f5c\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFLEx\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u526a\u679d\u5168\u5c40MoE\u6a21\u578b\u6765\u4fdd\u7559\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684\u4e00\u4e2a\u4e13\u5bb6\uff0c\u5e76\u4f7f\u7528\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u5c06\u8fd9\u4e9b\u4e2a\u6027\u5316\u4e13\u5bb6\u91cd\u65b0\u6574\u5408\u56de\u9884\u8bad\u7ec3\u7684MoE\u5c42\u3002", "result": "FLEx\u5728\u975eIID\u6761\u4ef6\u4e0b\u5bf9\u591a\u79cd\u6307\u4ee4\u96c6\u6570\u636e\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\u4e00\u8d2f\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u8054\u90a6\u57fa\u51c6\u3002", "conclusion": "FLEx\u8bc1\u660e\u53ef\u4ee5\u6709\u6548\u4e2a\u6027\u5316\uff0c\u901a\u8fc7\u4fee\u526a\u548c\u95e8\u63a7\u673a\u5236\u4fdd\u6301\u539f\u59cb\u67b6\u6784\u4e0d\u53d8\uff0c\u4e2a\u6027\u5316\u4e13\u5bb6\u5728\u672c\u5730\u6570\u636e\u4e2d\u8bad\u7ec3\uff0c\u516c\u5171\u6a21\u5757\u5168\u7403\u805a\u5408\u3002"}}
{"id": "2506.00396", "pdf": "https://arxiv.org/pdf/2506.00396", "abs": "https://arxiv.org/abs/2506.00396", "authors": ["Jiawei Gu", "Shangsong Liang"], "title": "Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively", "categories": ["cs.CL"], "comment": "ACL2025 Oral (Industry Track)", "summary": "Effective decision-making in Large Language Models (LLMs) is essential for\nhandling intricate tasks. However, existing approaches prioritize performance\nbut often overlook the balance between effectiveness and computational cost. To\naddress this, we first introduce the 3E Criteria to systematically assess the\ncost-effectiveness of search strategies, revealing that existing methods often\ntrade significant efficiency for marginal performance gains. To improve LLM\ndecision-making while maintaining efficiency, we propose the Speculative Reward\nModel (SRM), a plug-and-play framework that seamlessly integrates with existing\nsearch strategies. Specifically, SRM employs an external reward assigner to\npredict optimal actions, reducing reliance on LLMs' internal self-evaluation.\nAnd a speculative verification mechanism is used to prune suboptimal choices\nand guide the search toward more promising steps. We evaluate SRM on several\ncomplex decision-making tasks including mathematical reasoning, planning and\nnumerical reasoning in specialized domains. Experimental results show that SRM\nreduces costs to 1/10 of the original search framework on average while\nmaintaining effectiveness.", "AI": {"tldr": "\u63d0\u51faSRM\u6a21\u578b\uff0c\u901a\u8fc7\u5916\u90e8\u5956\u52b1\u53ca\u63a8\u6d4b\u9a8c\u8bc1\u673a\u5236\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u6548\u7387\uff0c\u5b9e\u9a8c\u663e\u793a\u964d\u4f4e\u6210\u672c\u81f3\u539f\u6765\u76841/10\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u8861\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u4e3a\u6b64\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u51b3\u7b56\u6846\u67b6\u3002", "method": "\u5f15\u51653E\u51c6\u5219\u8bc4\u4f30\u7b56\u7565\u6027\u4ef7\u6bd4\uff1b\u63d0\u51fa\u63a8\u6d4b\u6027\u5956\u52b1\u6a21\u578b\u4e0e\u73b0\u6709\u641c\u7d22\u7b56\u7565\u7ed3\u5408\uff0c\u901a\u8fc7\u5916\u90e8\u5956\u52b1\u5206\u914d\u5668\u53ca\u63a8\u6d4b\u6027\u9a8c\u8bc1\u673a\u5236\u51cf\u5c11LLM\u81ea\u6211\u8bc4\u4f30\u4f9d\u8d56\u3002", "result": "SRM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5c06\u6210\u672c\u964d\u4f4e\u81f3\u539f\u6846\u67b6\u76841/10\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u6548\u6027\u3002", "conclusion": "SRM\u80fd\u591f\u663e\u8457\u964d\u4f4e\u51b3\u7b56\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.00453", "pdf": "https://arxiv.org/pdf/2506.00453", "abs": "https://arxiv.org/abs/2506.00453", "authors": ["Hao Li", "Hao Wan", "Yuzhou Chen", "Dongsheng Ye", "Yulia Gel", "Hao Jiang"], "title": "TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "ICML2025", "summary": "Dynamic graphs evolve continuously, presenting challenges for traditional\ngraph learning due to their changing structures and temporal dependencies.\nRecent advancements have shown potential in addressing these challenges by\ndeveloping suitable meta-learning-based dynamic graph neural network models.\nHowever, most meta-learning approaches for dynamic graphs rely on fixed weight\nupdate parameters, neglecting the essential intrinsic complex high-order\ntopological information of dynamically evolving graphs. We have designed Dowker\nZigzag Persistence (DZP), an efficient and stable dynamic graph persistent\nhomology representation method based on Dowker complex and zigzag persistence,\nto capture the high-order features of dynamic graphs. Armed with the DZP ideas,\nwe propose TMetaNet, a new meta-learning parameter update model based on\ndynamic topological features. By utilizing the distances between high-order\ntopological features, TMetaNet enables more effective adaptation across\nsnapshots. Experiments on real-world datasets demonstrate TMetaNet's\nstate-of-the-art performance and resilience to graph noise, illustrating its\nhigh potential for meta-learning and dynamic graph analysis. Our code is\navailable at https://github.com/Lihaogx/TMetaNet.", "AI": {"tldr": "TMetaNet, based on a new DZP method, improves dynamic graph analysis by considering high-order topological features, showing high performance and resilience to noise.", "motivation": "Most meta-learning approaches neglect intrinsic high-order topological information of dynamic graphs.", "method": "Design of Dowker Zigzag Persistence (DZP) and proposal of TMetaNet model based on dynamic topological features.", "result": "Experiments demonstrate TMetaNet's state-of-the-art performance and resilience to graph noise on real-world datasets.", "conclusion": "TMetaNet shows state-of-the-art performance and resilience to graph noise in dynamic graph analysis."}}
{"id": "2506.00968", "pdf": "https://arxiv.org/pdf/2506.00968", "abs": "https://arxiv.org/abs/2506.00968", "authors": ["Linhan Xia", "Mingzhan Yang", "Guohui Yuan", "Shengnan Tao", "Yujing Qiu", "Guo Yu", "Kai Lei"], "title": "PolyBERT: Fine-Tuned Poly Encoder BERT-Based Model for Word Sense Disambiguation", "categories": ["cs.AI"], "comment": null, "summary": "Mainstream Word Sense Disambiguation (WSD) approaches have employed BERT to\nextract semantics from both context and definitions of senses to determine the\nmost suitable sense of a target word, achieving notable performance. However,\nthere are two limitations in these approaches. First, previous studies failed\nto balance the representation of token-level (local) and sequence-level\n(global) semantics during feature extraction, leading to insufficient semantic\nrepresentation and a performance bottleneck. Second, these approaches\nincorporated all possible senses of each target word during the training phase,\nleading to unnecessary computational costs. To overcome these limitations, this\npaper introduces a poly-encoder BERT-based model with batch contrastive\nlearning for WSD, named PolyBERT. Compared with previous WSD methods, PolyBERT\nhas two improvements: (1) A poly-encoder with a multi-head attention mechanism\nis utilized to fuse token-level (local) and sequence-level (global) semantics,\nrather than focusing on just one. This approach enriches semantic\nrepresentation by balancing local and global semantics. (2) To avoid redundant\ntraining inputs, Batch Contrastive Learning (BCL) is introduced. BCL utilizes\nthe correct senses of other target words in the same batch as negative samples\nfor the current target word, which reduces training inputs and computational\ncost. The experimental results demonstrate that PolyBERT outperforms baseline\nWSD methods such as Huang's GlossBERT and Blevins's BEM by 2\\% in F1-score. In\naddition, PolyBERT with BCL reduces GPU hours by 37.6\\% compared with PolyBERT\nwithout BCL.", "AI": {"tldr": "PolyBERT is a BERT-based model using poly-encoder and batch contrastive learning to enhance performance and efficiency in WSD, outperforming existing methods by 2% in F1-score and saving 37.6% GPU hours.", "motivation": "The motivation is to address the limitations in existing BERT-based WSD approaches, specifically the imbalance between token-level and sequence-level semantics and the unnecessary computational cost from incorporating all possible senses of target words during training.", "method": "The paper introduces a poly-encoder BERT-based model with batch contrastive learning, named PolyBERT. It employs a poly-encoder with a multi-head attention mechanism to fuse local and global semantics, and uses Batch Contrastive Learning to reduce training inputs by utilizing other target words in the batch as negative samples.", "result": "PolyBERT improves F1-score by 2% compared to baseline methods like GlossBERT and BEM, and reduces GPU hours by 37.6% when using batch contrastive learning.", "conclusion": "PolyBERT outperforms previous mainstream WSD methods and reduces computational costs by effectively balancing token-level and sequence-level semantics and by minimizing redundant training inputs."}}
{"id": "2506.00400", "pdf": "https://arxiv.org/pdf/2506.00400", "abs": "https://arxiv.org/abs/2506.00400", "authors": ["Zixin Ding", "Junyuan Hong", "Jiachen T. Wang", "Zinan Lin", "Zhangyang Wang", "Yuxin Chen"], "title": "Scaling Textual Gradients via Sampling-Based Momentum", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As prompts play an increasingly critical role in large language models\n(LLMs), optimizing textual prompts has become a crucial challenge. The Textual\nGradient Descent (TGD) framework has emerged as a promising data-driven\napproach that iteratively refines textual prompts using LLM - suggested updates\n(or textual gradients) over minibatches of training samples. In this paper, we\nempirically demonstrate that scaling the number of training examples initially\nimproves but later degrades TGD's performance across multiple downstream NLP\ntasks. However, while data scaling improves results for most tasks, it also\nsignificantly increases the computational cost when leveraging LLMs. To address\nthis, we draw inspiration from numerical gradient descent and propose Textual\nStochastic Gradient Descent with Momentum (TSGD-M) - a method that facilitates\nscalable in-context learning by reweighting prompt sampling based on past batch\ndistributions. Across nine NLP tasks spanning three domains - including\nBIG-Bench Hard (BBH), natural language understanding tasks, and reasoning tasks\n- TSGD-M significantly outperforms TGD baselines that do not incorporate\nreweighted sampling, while also reducing variance in most tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TSGD-M\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u52a0\u6743\u62bd\u6837\u6539\u8fdbTGD\u6027\u80fd\uff0c\u5728\u591a\u4e2aNLP\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u66f4\u597d\u8868\u73b0\u5e76\u51cf\u5c11\u4e86\u65b9\u5dee\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u793a\u7684\u5173\u952e\u6027\u589e\u52a0\uff0c\u4f18\u5316\u6587\u672c\u63d0\u793a\u53d8\u5f97\u6781\u4e3a\u91cd\u8981\u3002\u73b0\u6709\u7684TGD\u6846\u67b6\u5728\u6570\u636e\u6269\u5c55\u540e\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u4e14\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8eTSGD-M\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8fc7\u53bb\u6279\u6b21\u5206\u5e03\u7684\u91cd\u52a0\u6743\u62bd\u6837\uff0c\u4fc3\u8fdb\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u8de8\u8d8a\u4e09\u4e2a\u9886\u57df\u7684\u4e5d\u4e2aNLP\u4efb\u52a1\u4e2d\uff0cTSGD-M\u663e\u8457\u4f18\u4e8e\u672a\u5305\u542b\u91cd\u65b0\u52a0\u6743\u62bd\u6837\u7684TGD\u57fa\u7ebf\uff0c\u540c\u65f6\u5728\u5927\u90e8\u5206\u4efb\u52a1\u4e2d\u4e5f\u51cf\u5c11\u4e86\u65b9\u5dee\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86TSGD-M\u65b9\u6cd5\uff0c\u5728\u591a\u4e2aNLP\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u51cf\u5c11\u4e86\u65b9\u5dee\u3002"}}
{"id": "2506.00457", "pdf": "https://arxiv.org/pdf/2506.00457", "abs": "https://arxiv.org/abs/2506.00457", "authors": ["Junwoo Park", "Hyuck Lee", "Dohyun Lee", "Daehoon Gwak", "Jaegul Choo"], "title": "Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models", "categories": ["cs.LG"], "comment": "Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2025, Accepted as Short Paper", "summary": "Large Language Models (LLMs) have shown remarkable performance across diverse\ntasks without domain-specific training, fueling interest in their potential for\ntime-series forecasting. While LLMs have shown potential in zero-shot\nforecasting through prompting alone, recent studies suggest that LLMs lack\ninherent effectiveness in forecasting. Given these conflicting findings, a\nrigorous validation is essential for drawing reliable conclusions. In this\npaper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared\nto state-of-the-art domain-specific models. Our experiments show that LLM-based\nzero-shot forecasters often struggle to achieve high accuracy due to their\nsensitivity to noise, underperforming even simple domain-specific models. We\nhave explored solutions to reduce LLMs' sensitivity to noise in the zero-shot\nsetting, but improving their robustness remains a significant challenge. Our\nfindings suggest that rather than emphasizing zero-shot forecasting, a more\npromising direction would be to focus on fine-tuning LLMs to better process\nnumerical sequences. Our experimental code is available at\nhttps://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.", "AI": {"tldr": "LLMs struggle in zero-shot time-series forecasting; fine-tuning is recommended to improve performance due to noise sensitivity issues.", "motivation": "Investigating LLMs' potential for time-series forecasting amid conflicting findings on their effectiveness.", "method": "Evaluation of LLMs as zero-shot forecasters compared to domain-specific models through experiments.", "result": "LLMs underperform in zero-shot settings compared to even simple domain-specific models, due to noise sensitivity.", "conclusion": "LLMs struggle with zero-shot forecasting accuracy due to noise sensitivity, and focusing on fine-tuning for numerical sequences is more promising."}}
{"id": "2506.00989", "pdf": "https://arxiv.org/pdf/2506.00989", "abs": "https://arxiv.org/abs/2506.00989", "authors": ["Buyun He", "Xiaorui Jiang", "Qi Wu", "Hao Liu", "Yingguang Yang", "Yong Liao"], "title": "Boosting Bot Detection via Heterophily-Aware Representation Learning and Prototype-Guided Cluster Discovery", "categories": ["cs.AI"], "comment": "KDD 2025", "summary": "Detecting social media bots is essential for maintaining the security and\ntrustworthiness of social networks. While contemporary graph-based detection\nmethods demonstrate promising results, their practical application is limited\nby label reliance and poor generalization capability across diverse\ncommunities. Generative Graph Self-Supervised Learning (GSL) presents a\npromising paradigm to overcome these limitations, yet existing approaches\npredominantly follow the homophily assumption and fail to capture the global\npatterns in the graph, which potentially diminishes their effectiveness when\nfacing the challenges of interaction camouflage and distributed deployment in\nbot detection scenarios. To this end, we propose BotHP, a generative GSL\nframework tailored to boost graph-based bot detectors through heterophily-aware\nrepresentation learning and prototype-guided cluster discovery. Specifically,\nBotHP leverages a dual-encoder architecture, consisting of a graph-aware\nencoder to capture node commonality and a graph-agnostic encoder to preserve\nnode uniqueness. This enables the simultaneous modeling of both homophily and\nheterophily, effectively countering the interaction camouflage issue.\nAdditionally, BotHP incorporates a prototype-guided cluster discovery pretext\ntask to model the latent global consistency of bot clusters and identify\nspatially dispersed yet semantically aligned bot collectives. Extensive\nexperiments on two real-world bot detection benchmarks demonstrate that BotHP\nconsistently boosts graph-based bot detectors, improving detection performance,\nalleviating label reliance, and enhancing generalization capability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBotHP\u7684\u751f\u6210\u5f0f\u56fe\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u8d28\u6027\u611f\u77e5\u7684\u8868\u793a\u5b66\u4e60\u548c\u539f\u578b\u6307\u5bfc\u7684\u805a\u7c7b\u53d1\u73b0\u4efb\u52a1\uff0c\u63d0\u5347\u56fe\u5f62\u57fa\u7840\u7684\u673a\u5668\u4eba\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u56fe\u5f62\u57fa\u7840\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6807\u7b7e\u4f9d\u8d56\u548c\u6cdb\u5316\u80fd\u529b\u5c40\u9650\u7684\u95ee\u9898\u3002GSL\u662f\u4e00\u4e2a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u7684\u524d\u666f\u826f\u597d\u8303\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u6355\u6349\u5168\u7403\u56fe\u5f62\u6a21\u5f0f\uff0c\u5f71\u54cd\u5176\u5728\u673a\u5668\u4eba\u68c0\u6d4b\u573a\u666f\u4e2d\u7684\u6548\u679c\u3002", "method": "BotHP\u91c7\u7528\u53cc\u7f16\u7801\u5668\u67b6\u6784\uff0c\u5305\u62ec\u4e00\u4e2a\u56fe\u5f62\u610f\u8bc6\u7f16\u7801\u5668\u548c\u4e00\u4e2a\u56fe\u5f62\u65e0\u5173\u7f16\u7801\u5668\uff0c\u5e76\u7ed3\u5408\u539f\u578b\u6307\u5bfc\u7684\u805a\u7c7b\u53d1\u73b0\u4efb\u52a1\u6765\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0cBotHP\u8bc1\u660e\u80fd\u63d0\u5347\u56fe\u5f62\u57fa\u7840\u7684\u673a\u5668\u4eba\u68c0\u6d4b\u5668\uff0c\u6539\u5584\u68c0\u6d4b\u6027\u80fd\uff0c\u51cf\u8f7b\u6807\u7b7e\u4f9d\u8d56\uff0c\u5e76\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "BotHP\u6846\u67b6\u901a\u8fc7\u5f02\u8d28\u6027\u654f\u611f\u7684\u8868\u793a\u5b66\u4e60\u548c\u539f\u578b\u6307\u5bfc\u7684\u805a\u7c7b\u53d1\u73b0\uff0c\u6709\u6548\u63d0\u5347\u4e86\u56fe\u5f62\u57fa\u7840\u7684\u673a\u5668\u4eba\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.00402", "pdf": "https://arxiv.org/pdf/2506.00402", "abs": "https://arxiv.org/abs/2506.00402", "authors": ["Vishwanath Pratap Singh", "Md. Sahidullah", "Tomi Kinnunen"], "title": "Causal Structure Discovery for Error Diagnostics of Children's ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Interspeech 2025", "summary": "Children's automatic speech recognition (ASR) often underperforms compared to\nthat of adults due to a confluence of interdependent factors: physiological\n(e.g., smaller vocal tracts), cognitive (e.g., underdeveloped pronunciation),\nand extrinsic (e.g., vocabulary limitations, background noise). Existing\nanalysis methods examine the impact of these factors in isolation, neglecting\ninterdependencies-such as age affecting ASR accuracy both directly and\nindirectly via pronunciation skills. In this paper, we introduce a causal\nstructure discovery to unravel these interdependent relationships among\nphysiology, cognition, extrinsic factors, and ASR errors. Then, we employ\ncausal quantification to measure each factor's impact on children's ASR. We\nextend the analysis to fine-tuned models to identify which factors are\nmitigated by fine-tuning and which remain largely unaffected. Experiments on\nWhisper and Wav2Vec2.0 demonstrate the generalizability of our findings across\ndifferent ASR systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56e0\u679c\u7ed3\u6784\u53d1\u73b0\u5206\u6790\u5f71\u54cd\u513f\u7ae5 ASR \u7684\u56e0\u7d20\uff0c\u5e76\u6d4b\u91cf\u5404\u56e0\u7d20\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8868\u660e\u7ed3\u679c\u5728\u4e0d\u540c ASR \u7cfb\u7edf\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\u53ea\u8003\u8651\u5404\u56e0\u7d20\u7684\u5355\u72ec\u5f71\u54cd\uff0c\u5ffd\u89c6\u4e86\u76f8\u4e92\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u56e0\u679c\u7ed3\u6784\u53d1\u73b0\u548c\u56e0\u679c\u91cf\u5316\u65b9\u6cd5\u7528\u4e8e\u5206\u6790\u513f\u7ae5 ASR \u7684\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u5bf9\u6a21\u578b\u7684\u5fae\u8c03\uff0c\u8fa8\u8bc6\u51fa\u54ea\u4e9b\u56e0\u7d20\u5bf9\u513f\u7ae5 ASR \u7684\u5f71\u54cd\u88ab\u51cf\u5c0f\uff0c\u54ea\u4e9b\u56e0\u7d20\u4ecd\u7136\u5b58\u5728\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u56e0\u679c\u7ed3\u6784\u53d1\u73b0\u548c\u56e0\u679c\u91cf\u5316\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u5f71\u54cd\u513f\u7ae5 ASR \u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u5206\u6790\u5728\u6a21\u578b\u5fae\u8c03\u540e\u4ecd\u7136\u53d7\u5230\u5f71\u54cd\u7684\u56e0\u7d20\u3002\u7ed3\u679c\u5728\u4e0d\u540c\u7684 ASR \u7cfb\u7edf\u4e2d\u5c55\u793a\u51fa\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.01003", "pdf": "https://arxiv.org/pdf/2506.01003", "abs": "https://arxiv.org/abs/2506.01003", "authors": ["Junli Jiang", "Pavel Naumov"], "title": "Higher-Order Responsibility", "categories": ["cs.AI", "cs.CC", "cs.GT"], "comment": null, "summary": "In ethics, individual responsibility is often defined through Frankfurt's\nprinciple of alternative possibilities. This definition is not adequate in a\ngroup decision-making setting because it often results in the lack of a\nresponsible party or \"responsibility gap''. One of the existing approaches to\naddress this problem is to consider group responsibility. Another, recently\nproposed, approach is \"higher-order'' responsibility. The paper considers the\nproblem of deciding if higher-order responsibility up to degree $d$ is enough\nto close the responsibility gap. The main technical result is that this problem\nis $\\Pi_{2d+1}$-complete.", "AI": {"tldr": "\u7814\u7a76\u9ad8\u9636\u8d23\u4efb\u80fd\u5426\u586b\u8865\u8d23\u4efb\u7f3a\u53e3\uff0c\u53d1\u73b0\u8fd9\u662f\u4e00\u4e2a$\\Pi_{2d+1}$-\u5b8c\u5168\u95ee\u9898\u3002", "motivation": "\u4e3a\u89e3\u51b3\u4f20\u7edf\u8d23\u4efb\u5b9a\u4e49\u5728\u7fa4\u4f53\u51b3\u7b56\u4e2d\u5bfc\u81f4\u7684\u8d23\u4efb\u7a7a\u7f3a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u9ad8\u9636\u8d23\u4efb\u8fd9\u4e00\u65b0\u65b9\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u6709\u6548\u6027\u3002", "method": "\u4f5c\u8005\u5bf9\u9ad8\u9636\u8d23\u4efb\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u5206\u6790\uff0c\u81f4\u529b\u4e8e\u7814\u7a76\u5728\u9ad8\u8fbed\u7ea7\u7684\u8d23\u4efb\u4e0b\u662f\u5426\u80fd\u591f\u5f25\u5408\u8d23\u4efb\u7f3a\u53e3\u95ee\u9898\uff0c\u5e76\u5bf9\u5176\u8ba1\u7b97\u590d\u6742\u6027\u8fdb\u884c\u4e86\u5206\u6790\u3002", "result": "\u7814\u7a76\u7684\u4e3b\u8981\u6280\u672f\u7ed3\u679c\u8868\u660e\uff0c\u786e\u5b9a\u9ad8\u9636\u8d23\u4efb\u662f\u5426\u8db3\u4ee5\u5f25\u5408\u8d23\u4efb\u7f3a\u53e3\u662f\u4e00\u4e2a$\\Pi_{2d+1}$-\u5b8c\u5168\u95ee\u9898\uff0c\u663e\u793a\u4e86\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u548c\u6311\u6218\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f97\u51fa\u7ed3\u8bba\uff0c\u4ee5\u9ad8\u9636\u8d23\u4efb\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u5f25\u5408\u4f20\u7edf\u8d23\u4efb\u754c\u9650\u6240\u5b58\u5728\u7684\u8d23\u4efb\u7f3a\u53e3\uff0c\u4f46\u8be5\u8ba1\u7b97\u95ee\u9898\u7684\u590d\u6742\u6027\u4e3a$\\Pi_{2d+1}$-\u5b8c\u5168\u3002"}}
{"id": "2506.00413", "pdf": "https://arxiv.org/pdf/2506.00413", "abs": "https://arxiv.org/abs/2506.00413", "authors": ["Daniel Israel", "Guy Van den Broeck", "Aditya Grover"], "title": "Accelerating Diffusion LLMs via Adaptive Parallel Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PF"], "comment": "10 pages, 5 figures", "summary": "The generation speed of LLMs are bottlenecked by autoregressive decoding,\nwhere tokens are predicted sequentially one by one. Alternatively, diffusion\nlarge language models (dLLMs) theoretically allow for parallel token\ngeneration, but in practice struggle to achieve the speed of autoregressive\nmodels without significantly sacrificing quality. We therefore introduce\nadaptive parallel decoding (APD), a novel method that dynamically adjusts the\nnumber of tokens sampled in parallel. We achieve this by defining a\nmultiplicative mixture between the dLLM marginal probabilities and the joint\nprobability of sequences under a small auxiliary autoregressive model. This\ninverts the standard setup of speculative decoding, where the goal is to sample\nfrom a large autoregressive verifier by drafting from a smaller model. We\nfurther optimize APD by enabling KV caching and limiting the size of the masked\ninput. Altogether, our method puts forward three tunable parameters to flexibly\ntradeoff throughput and quality. We show that APD provides markedly higher\nthroughput with minimal quality degradations on downstream benchmarks.", "AI": {"tldr": "\u5f15\u5165APD\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408dLLM\u548c\u5c0f\u578b\u81ea\u56de\u5f52\u6a21\u578b\u7684\u8054\u5408\u6982\u7387\u6765\u52a8\u6001\u8c03\u6574\u5e76\u884c\u751f\u6210\u901f\u5ea6\uff0c\u4f18\u5316\u4e86\u6027\u80fd\uff0c\u8fbe\u5230\u9ad8\u541e\u5410\u91cf\u4e14\u8d28\u91cf\u635f\u5931\u5c0f\u3002", "motivation": "\u5bfb\u6c42\u89e3\u51b3\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u5728\u5b9e\u73b0\u5e76\u884c\u4ee4\u724c\u751f\u6210\u65f6\u96be\u4ee5\u5728\u901f\u5ea6\u4e0a\u8d85\u8d8a\u81ea\u56de\u5f52\u6a21\u578b\u4e14\u4e0d\u660e\u663e\u727a\u7272\u8d28\u91cf\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u5e76\u884c\u89e3\u7801\uff08APD\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4e49dLLM\u8fb9\u9645\u6982\u7387\u4e0e\u5c0f\u578b\u8f85\u52a9\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5e8f\u5217\u8054\u5408\u6982\u7387\u7684\u4e58\u6cd5\u6df7\u5408\u6765\u52a8\u6001\u8c03\u6574\u5e76\u884c\u91c7\u6837\u7684\u4ee4\u724c\u6570\u91cf\u3002", "result": "APD\u53ef\u4ee5\u7075\u6d3b\u5730\u5728\u541e\u5410\u91cf\u548c\u8d28\u91cf\u4e4b\u95f4\u8fdb\u884c\u8c03\u6574\uff0c\u4f18\u5316\u4e86KV\u7f13\u5b58\u5e76\u9650\u5236\u4e86\u8f93\u5165\u906e\u7f69\u7684\u5927\u5c0f\u3002", "conclusion": "APD\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u5e76\u4e14\u5728\u4e3b\u8981\u8bc4\u6d4b\u4e2d\u8d28\u91cf\u4ec5\u6709\u5fae\u5c0f\u7684\u4e0b\u964d\u3002"}}
{"id": "2506.00459", "pdf": "https://arxiv.org/pdf/2506.00459", "abs": "https://arxiv.org/abs/2506.00459", "authors": ["Elinor Ginzburg", "Itay Segev", "Yoash Levron", "Sarah Keren"], "title": "Comparing Traditional and Reinforcement-Learning Methods for Energy Storage Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We aim to better understand the tradeoffs between traditional and\nreinforcement learning (RL) approaches for energy storage management. More\nspecifically, we wish to better understand the performance loss incurred when\nusing a generative RL policy instead of using a traditional approach to find\noptimal control policies for specific instances. Our comparison is based on a\nsimplified micro-grid model, that includes a load component, a photovoltaic\nsource, and a storage device. Based on this model, we examine three use cases\nof increasing complexity: ideal storage with convex cost functions, lossy\nstorage devices, and lossy storage devices with convex transmission losses.\nWith the aim of promoting the principled use RL based methods in this\nchallenging and important domain, we provide a detailed formulation of each use\ncase and a detailed description of the optimization challenges. We then compare\nthe performance of traditional and RL methods, discuss settings in which it is\nbeneficial to use each method, and suggest avenues for future investigation.", "AI": {"tldr": "\u63a2\u8ba8\u4f20\u7edf\u4e0e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u80fd\u91cf\u5b58\u50a8\u7ba1\u7406\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u65e8\u5728\u7406\u89e3\u5728\u7279\u5b9a\u5b9e\u4f8b\u4e2d\u4f7f\u7528\u751f\u6210\u6027\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u66ff\u4ee3\u4f20\u7edf\u65b9\u6cd5\u5bfb\u627e\u6700\u4f18\u63a7\u5236\u7b56\u7565\u65f6\u7684\u6027\u80fd\u635f\u5931\u3002", "method": "\u91c7\u7528\u7b80\u5316\u7684\u5fae\u7535\u7f51\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u6bd4\u8f83\uff0c\u5305\u62ec\u8d1f\u8f7d\u7ec4\u4ef6\u3001\u5149\u4f0f\u6e90\u548c\u5b58\u50a8\u8bbe\u5907\u3002\u9488\u5bf9\u4e09\u79cd\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u5e94\u7528\u573a\u666f\uff0c\u8fdb\u884c\u4e86\u4f18\u5316\u6311\u6218\u7684\u8be6\u7ec6\u63cf\u8ff0\u3002", "result": "\u5206\u6790\u4e86\u4f20\u7edf\u4e0e\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u8ba8\u8bba\u4e86\u5404\u81ea\u9002\u7528\u7684\u60c5\u5883\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u5bf9\u4f20\u7edf\u65b9\u6cd5\u548c\u751f\u6210\u6027\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u80fd\u91cf\u5b58\u50a8\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5f3a\u8c03\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002"}}
{"id": "2506.01048", "pdf": "https://arxiv.org/pdf/2506.01048", "abs": "https://arxiv.org/abs/2506.01048", "authors": ["Wei Song", "Zhenya Huang", "Cheng Cheng", "Weibo Gao", "Bihan Xu", "GuanHao Zhao", "Fei Wang", "Runze Wu"], "title": "IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory", "categories": ["cs.AI"], "comment": "ACL 2025 Main", "summary": "Large language models (LLMs) have demonstrated exceptional performance across\na wide range of natural language tasks. However, selecting the optimal LLM to\nrespond to a user query often necessitates a delicate balance between\nperformance and cost. While powerful models deliver better results, they come\nat a high cost, whereas smaller models are more cost-effective but less\ncapable. To address this trade-off, we propose IRT-Router, a multi-LLM routing\nframework that efficiently routes user queries to the most suitable LLM.\nInspired by Item Response Theory (IRT), a psychological measurement\nmethodology, IRT-Router explicitly models the relationship between LLM\ncapabilities and user query attributes. This not only enables accurate\nprediction of response performance but also provides interpretable insights,\nsuch as LLM abilities and query difficulty. Additionally, we design an online\nquery warm-up technique based on semantic similarity, further enhancing the\nonline generalization capability of IRT-Router. Extensive experiments on 20\nLLMs and 12 datasets demonstrate that IRT-Router outperforms most baseline\nmethods in terms of effectiveness and interpretability. Its superior\nperformance in cold-start scenarios further confirms the reliability and\npracticality of IRT-Router in real-world applications. Code is available at\nhttps://github.com/Mercidaiha/IRT-Router.", "AI": {"tldr": "\u63d0\u51faIRT-Router\u6846\u67b6\uff0c\u901a\u8fc7\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u4f18\u5316LLM\u9009\u62e9\uff0c\u63d0\u5347\u67e5\u8be2\u54cd\u5e94\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u9009\u62e9\u6700\u4f73\u7684LLM\u9700\u5728\u6027\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86IRT-Router\u6846\u67b6\u3002", "method": "IRT-Router\u4f7f\u7528\u5fc3\u7406\u6d4b\u91cf\u65b9\u6cd5\u4e2d\u7684\u9879\u76ee\u53cd\u5e94\u7406\u8bba\u6765\u5efa\u6a21LLM\u80fd\u529b\u4e0e\u7528\u6237\u67e5\u8be2\u5c5e\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u5728\u7ebf\u67e5\u8be2\u9884\u70ed\u6280\u672f\u3002", "result": "\u5bf920\u4e2aLLM\u548c12\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cIRT-Router\u5728\u6709\u6548\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u5927\u591a\u6570\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u5373\u65f6\u542f\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8d85\u5f3a\u7684\u53ef\u9760\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "conclusion": "IRT-Router\u5728\u89e3\u51b3\u6a21\u578b\u95f4\u6027\u80fd\u4e0e\u6210\u672c\u7684\u6743\u8861\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.00418", "pdf": "https://arxiv.org/pdf/2506.00418", "abs": "https://arxiv.org/abs/2506.00418", "authors": ["Siqi Liang", "Sumyeong Ahn", "Paramveer S. Dhillon", "Jiayu Zhou"], "title": "Dual Debiasing for Noisy In-Context Learning for Text Generation", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Accepted by 2025 ACL Findings", "summary": "In context learning (ICL) relies heavily on high quality demonstrations drawn\nfrom large annotated corpora. Existing approaches detect noisy annotations by\nranking local perplexities, presuming that noisy samples yield higher\nperplexities than their clean counterparts. However, this assumption breaks\ndown when the noise ratio is high and many demonstrations are flawed. We\nreexamine the perplexity based paradigm for text generation under noisy\nannotations, highlighting two sources of bias in perplexity: the annotation\nitself and the domain specific knowledge inherent in large language models\n(LLMs). To overcome these biases, we introduce a dual debiasing framework that\nuses synthesized neighbors to explicitly correct perplexity estimates, yielding\na robust Sample Cleanliness Score. This metric uncovers absolute sample\ncleanliness regardless of the overall corpus noise level. Extensive experiments\ndemonstrate our method's superior noise detection capabilities and show that\nits final ICL performance is comparable to that of a fully clean demonstration\ncorpus. Moreover, our approach remains robust even when noise ratios are\nextremely high.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53cc\u91cd\u53bb\u504f\u6846\u67b6\u4ee5\u6539\u5584\u566a\u58f0\u6ce8\u91ca\u4e0b\u7684\u6587\u672c\u751f\u6210\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u566a\u58f0\u68c0\u6d4b\u80fd\u529b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u566a\u58f0\u6bd4\u4f8b\u7684\u8bed\u6599\u5e93\u65f6\u5b58\u5728\u7f3a\u9677\uff0c\u56e0\u6b64\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u57fa\u4e8e\u56f0\u60d1\u5ea6\u7684\u6587\u672c\u751f\u6210\u8303\u5f0f\uff0c\u5e76\u514b\u670d\u56f0\u60d1\u5ea6\u4e2d\u7684\u504f\u5dee\u3002", "method": "\u5f15\u5165\u53cc\u91cd\u53bb\u504f\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u90bb\u5c45\u6765\u663e\u5f0f\u6821\u6b63\u56f0\u60d1\u5ea6\u4f30\u8ba1\uff0c\u4ea7\u751f\u7a33\u5065\u7684\u6837\u672c\u6e05\u6d01\u5ea6\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u566a\u58f0\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u566a\u58f0\u6bd4\u4f8b\u6781\u9ad8\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u7ef4\u6301\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u9ad8\u566a\u58f0\u6bd4\u7387\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\uff0c\u5e76\u4e14\u6700\u7ec8\u7684ICL\u6027\u80fd\u4e0e\u5b8c\u5168\u5e72\u51c0\u7684\u793a\u4f8b\u8bed\u6599\u5e93\u76f8\u5f53\u3002"}}
{"id": "2506.00467", "pdf": "https://arxiv.org/pdf/2506.00467", "abs": "https://arxiv.org/abs/2506.00467", "authors": ["Shuai Zhao", "Heyan Huang", "Xinge Li", "Xiaokang Chen", "Rui Wang"], "title": "SST: Self-training with Self-adaptive Thresholding for Semi-supervised Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted by Information Processing & Management (IP&M)", "summary": "Neural networks have demonstrated exceptional performance in supervised\nlearning, benefiting from abundant high-quality annotated data. However,\nobtaining such data in real-world scenarios is costly and labor-intensive.\nSemi-supervised learning (SSL) offers a solution to this problem. Recent\nstudies, such as Semi-ViT and Noisy Student, which employ consistency\nregularization or pseudo-labeling, have demonstrated significant achievements.\nHowever, they still face challenges, particularly in accurately selecting\nsufficient high-quality pseudo-labels due to their reliance on fixed\nthresholds. Recent methods such as FlexMatch and FreeMatch have introduced\nflexible or self-adaptive thresholding techniques, greatly advancing SSL\nresearch. Nonetheless, their process of updating thresholds at each iteration\nis deemed time-consuming, computationally intensive, and potentially\nunnecessary. To address these issues, we propose Self-training with\nSelf-adaptive Thresholding (SST), a novel, effective, and efficient SSL\nframework. SST introduces an innovative Self-Adaptive Thresholding (SAT)\nmechanism that adaptively adjusts class-specific thresholds based on the\nmodel's learning progress. SAT ensures the selection of high-quality\npseudo-labeled data, mitigating the risks of inaccurate pseudo-labels and\nconfirmation bias. Extensive experiments demonstrate that SST achieves\nstate-of-the-art performance with remarkable efficiency, generalization, and\nscalability across various architectures and datasets. Semi-SST-ViT-Huge\nachieves the best results on competitive ImageNet-1K SSL benchmarks, with 80.7%\n/ 84.9% Top-1 accuracy using only 1% / 10% labeled data. Compared to the\nfully-supervised DeiT-III-ViT-Huge, which achieves 84.8% Top-1 accuracy using\n100% labeled data, our method demonstrates superior performance using only 10%\nlabeled data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6SST\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u9608\u503c\u673a\u5236\u9ad8\u6548\u9009\u62e9\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\uff0c\u5728\u591a\u4e2a\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5728ImageNet-1KSSL\u57fa\u51c6\u4e0a\u4ee5\u8f83\u5c11\u7684\u6807\u8bb0\u6570\u636e\u8fbe\u5230\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u7531\u4e8e\u5728\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\u83b7\u5f97\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u6602\u8d35\u4e14\u8d39\u529b\uff0c\u56e0\u6b64\u73b0\u5728\u7684\u7814\u7a76\u63a2\u7d22\u534a\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u4f5c\u4e3a\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\u5f53\u524d\u7684\u65b9\u6cd5\u5728\u9009\u62e9\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u65f6\u7531\u4e8e\u4f9d\u8d56\u56fa\u5b9a\u9608\u503c\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u901a\u8fc7\u5f15\u5165\u81ea\u9002\u5e94\u9608\u503c\u673a\u5236\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u4f2a\u6807\u7b7e\u9009\u62e9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aSST\uff08\u81ea\u8bad\u7ec3\u4e0e\u81ea\u9002\u5e94\u9608\u503c\uff09\u7684\u65b0\u7684SSL\u6846\u67b6\u3002SST\u5f15\u5165\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u81ea\u9002\u5e94\u9608\u503c\u673a\u5236\uff08SAT\uff09\uff0c\u6839\u636e\u6a21\u578b\u7684\u5b66\u4e60\u8fdb\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u7c7b\u7279\u5f02\u6027\u9608\u503c\u3002SAT\u786e\u4fdd\u9009\u62e9\u9ad8\u8d28\u91cf\u7684\u4f2a\u6807\u8bb0\u6570\u636e\uff0c\u7f13\u89e3\u4e0d\u51c6\u786e\u7684\u4f2a\u6807\u7b7e\u548c\u786e\u8ba4\u504f\u5dee\u7684\u98ce\u9669\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSST\u6846\u67b6\u5728\u5404\u79cd\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u663e\u8457\u7684\u6548\u7387\u3001\u6cdb\u5316\u80fd\u529b\u548c\u6269\u5c55\u6027\u3002\u5728ImageNet-1K SSL\u57fa\u51c6\u4e0a\uff0cSemi-SST-ViT-Huge\u4f7f\u75281%\u548c10%\u7684\u6807\u8bb0\u6570\u636e\u5206\u522b\u5b9e\u73b0\u4e8680.7%\u548c84.9%\u7684Top-1\u51c6\u786e\u7387\uff0c\u6bd4\u5168\u76d1\u7763\u7684DeiT-III-ViT-Huge\u4f7f\u7528100%\u6807\u8bb0\u6570\u636e\u768484.8%\u51c6\u786e\u7387\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684SST\u6846\u67b6\u5728\u5404\u79cd\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u90fd\u5b9e\u73b0\u4e86\u9ad8\u6548\u7387\u3001\u5e7f\u6cdb\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6269\u5c55\u6027\uff0c\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u7279\u522b\u662fSemi-SST-ViT-Huge\u5728ImageNet-1K SSL\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u4f7f\u7528\u4ec51%/10%\u6807\u8bb0\u6570\u636e\u5206\u522b\u8fbe\u5230\u4e8680.7%/84.9%\u7684Top-1\u51c6\u786e\u7387\u3002\u4e0e\u5b8c\u5168\u76d1\u7763\u7684DeiT-III-ViT-Huge\u76f8\u6bd4\uff0c\u4f7f\u7528100%\u6807\u8bb0\u6570\u636e\u8fbe\u5230\u4e8684.8%\u7684Top-1\u51c6\u786e\u7387\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4ec5\u4f7f\u752810%\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2506.01056", "pdf": "https://arxiv.org/pdf/2506.01056", "abs": "https://arxiv.org/abs/2506.01056", "authors": ["Xiang Fei", "Xiawu Zheng", "Hao Feng"], "title": "MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "Function-calling has enabled large language models (LLMs) to act as\ntool-using agents, but injecting thousands of tool schemas into the prompt is\ncostly and error-prone. We introduce MCP-Zero, a proactive agent framework that\nlets the LLM itself decide when and which external tools to retrieve, thereby\nassembling a task-specific toolchain from scratch. The framework is built upon\nthree components: (1) Proactive Tool Request, where the model emits a\nstructured $\\left<\\operatorname{tool\\_assistant}\\right>$ block that explicitly\nspecifies the desired server and task; (2) Hierarchical Vector Routing, a\ncoarse-to-fine retrieval algorithm that first selects candidate servers and\nthen ranks tools within each server based on the semantic similarity; (3)\nIterative Proactive Invocation, enabling multi-round, cross-domain toolchain\nconstruction with minimal context overhead, and allowing the model to\niteratively revise its request when the returned tools are insufficient. To\nevaluate our approach we also compile MCP-tools, a retrieval dataset comprising\n308 MCP servers and 2,797 tools extracted from the official\nModel-Context-Protocol repository and normalized into a unified JSON schema.\nExperiments show that MCP-Zero (i) effectively addresses the context overhead\nproblem of existing methods and accurately selects the correct tool from a pool\nof nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by\n98\\% on the APIbank while maintaining high accuracy; and (iii) supports\nmulti-turn tool invocation with consistent accuracy across rounds. The code and\ndataset will be released soon.", "AI": {"tldr": "\u5f15\u5165MCP-Zero\uff0c\u4e00\u79cd\u80fd\u81ea\u884c\u51b3\u5b9a\u5de5\u5177\u8c03\u7528\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4e0a\u4e0b\u6587\u5f00\u9500\u95ee\u9898\uff0c\u51c6\u786e\u9009\u62e9\u5de5\u5177\u5e76\u51cf\u5c11\u4e86\u4ee4\u724c\u6d88\u8017\u3002", "motivation": "\u5bf9\u5927\u6a21\u578b\u8fdb\u884c\u5de5\u5177\u8c03\u7528\u65f6\uff0c\u5927\u91cf\u5de5\u5177\u6a21\u5f0f\u6ce8\u5165\u5bfc\u81f4\u7684\u6210\u672c\u9ad8\u548c\u6613\u51fa\u9519\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u52a8\u4ee3\u7406\u6846\u67b6MCP-Zero\uff0c\u5305\u62ec\u4e3b\u52a8\u5de5\u5177\u8bf7\u6c42\u3001\u5206\u5c42\u5411\u91cf\u8def\u7531\u548c\u8fed\u4ee3\u4e3b\u52a8\u8c03\u7528\u4e09\u4e2a\u7ec4\u4ef6\u3002", "result": "MCP-Zero\u4e0d\u4ec5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0a\u4e0b\u6587\u5f00\u9500\u95ee\u9898\uff0c\u800c\u4e14\u5728\u63a5\u8fd1\u4e09\u5343\u4e2a\u5019\u9009\u5de5\u5177\u6c60\u4e2d\u51c6\u786e\u9009\u62e9\uff0c\u4ee4\u724c\u6d88\u8017\u51cf\u5c1198%\uff0c\u5e76\u652f\u6301\u8de8\u8f6e\u6b21\u5de5\u5177\u8c03\u7528\u3002", "conclusion": "MCP-Zero\u5b9e\u73b0\u4e86\u5728\u5927\u89c4\u6a21\u5de5\u5177\u6c60\u4e2d\u9ad8\u6548\u3001\u51c6\u786e\u7684\u5de5\u5177\u9009\u62e9\u548c\u4f7f\u7528\uff0c\u8fd8\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u4e0a\u4e0b\u6587\u5f00\u9500\u95ee\u9898\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u4ee4\u724c\u6d88\u8017\u3002"}}
{"id": "2506.00421", "pdf": "https://arxiv.org/pdf/2506.00421", "abs": "https://arxiv.org/abs/2506.00421", "authors": ["Jihyoung Jang", "Minwook Bae", "Minji Kim", "Dilek Hakkani-Tur", "Hyounghun Kim"], "title": "Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "ACL 2025 (32 pages); Project website: https://m3c-dataset.github.io/", "summary": "As chatbots continue to evolve toward human-like, real-world, interactions,\nmultimodality remains an active area of research and exploration. So far,\nefforts to integrate multimodality into chatbots have primarily focused on\nimage-centric tasks, such as visual dialogue and image-based instructions,\nplacing emphasis on the \"eyes\" of human perception while neglecting the \"ears\",\nnamely auditory aspects. Moreover, these studies often center around static\ninteractions that focus on discussing the modality rather than naturally\nincorporating it into the conversation, which limits the richness of\nsimultaneous, dynamic engagement. Furthermore, while multimodality has been\nexplored in multi-party and multi-session conversations, task-specific\nconstraints have hindered its seamless integration into dynamic, natural\nconversations. To address these challenges, this study aims to equip chatbots\nwith \"eyes and ears\" capable of more immersive interactions with humans. As\npart of this effort, we introduce a new multimodal conversation dataset,\nMultimodal Multi-Session Multi-Party Conversation ($M^3C$), and propose a novel\nmultimodal conversation model featuring multimodal memory retrieval. Our model,\ntrained on the $M^3C$, demonstrates the ability to seamlessly engage in\nlong-term conversations with multiple speakers in complex, real-world-like\nsettings, effectively processing visual and auditory inputs to understand and\nrespond appropriately. Human evaluations highlight the model's strong\nperformance in maintaining coherent and dynamic interactions, demonstrating its\npotential for advanced multimodal conversational agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6a21\u578b\u548c\u6570\u636e\u96c6M^3C\uff0c\u80fd\u591f\u5904\u7406\u89c6\u89c9\u548c\u542c\u89c9\u4fe1\u606f\uff0c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u4e92\u52a8\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u804a\u5929\u673a\u5668\u4eba\u7684\u53d1\u5c55\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u5c06\u591a\u6a21\u6001\u6027\u878d\u5165\u5176\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u66f4\u8d34\u8fd1\u4eba\u7c7b\u7684\u771f\u5b9e\u4e16\u754c\u4e92\u52a8\u3002\u7136\u800c\uff0c\u4ee5\u5f80\u7684\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u56fe\u50cf\u4efb\u52a1\uff0c\u800c\u5ffd\u7565\u4e86\u542c\u89c9\u65b9\u9762\u3002\u8fd9\u9879\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u5347\u804a\u5929\u673a\u5668\u4eba\u7684\u4e92\u52a8\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u65b0\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6570\u636e\u96c6M^3C\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u5bf9\u8bdd\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5177\u6709\u591a\u6a21\u6001\u8bb0\u5fc6\u68c0\u7d22\u529f\u80fd\u3002", "result": "\u6a21\u578b\u5728\u590d\u6742\u7684\u73b0\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u5904\u7406\u89c6\u89c9\u548c\u542c\u89c9\u8f93\u5165\uff0c\u8fdb\u884c\u957f\u65f6\u95f4\u3001\u591a\u65b9\u7684\u4e92\u52a8\u3002", "conclusion": "\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u5728\u4fdd\u6301\u8fde\u8d2f\u548c\u52a8\u6001\u4e92\u52a8\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u5148\u8fdb\u591a\u6a21\u6001\u5bf9\u8bdd\u4ee3\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.00476", "pdf": "https://arxiv.org/pdf/2506.00476", "abs": "https://arxiv.org/abs/2506.00476", "authors": ["Abhisek Ray", "Lukas Esterle"], "title": "Towards Graph-Based Privacy-Preserving Federated Learning: ModelNet -- A ResNet-based Model Classification Dataset", "categories": ["cs.LG"], "comment": "8 pages, 8 figures", "summary": "Federated Learning (FL) has emerged as a powerful paradigm for training\nmachine learning models across distributed data sources while preserving data\nlocality. However, the privacy of local data is always a pivotal concern and\nhas received a lot of attention in recent research on the FL regime. Moreover,\nthe lack of domain heterogeneity and client-specific segregation in the\nbenchmarks remains a critical bottleneck for rigorous evaluation. In this\npaper, we introduce ModelNet, a novel image classification dataset constructed\nfrom the embeddings extracted from a pre-trained ResNet50 model. First, we\nmodify the CIFAR100 dataset into three client-specific variants, considering\nthree domain heterogeneities (homogeneous, heterogeneous, and random).\nSubsequently, we train each client-specific subset of all three variants on the\npre-trained ResNet50 model to save model parameters. In addition to\nmulti-domain image data, we propose a new hypothesis to define the FL algorithm\nthat can access the anonymized model parameters to preserve the local privacy\nin a more effective manner compared to existing ones. ModelNet is designed to\nsimulate realistic FL settings by incorporating non-IID data distributions and\nclient diversity design principles in the mainframe for both conventional and\nfuturistic graph-driven FL algorithms. The three variants are ModelNet-S,\nModelNet-D, and ModelNet-R, which are based on homogeneous, heterogeneous, and\nrandom data settings, respectively. To the best of our knowledge, we are the\nfirst to propose a cross-environment client-specific FL dataset along with the\ngraph-based variant. Extensive experiments based on domain shifts and\naggregation strategies show the effectiveness of the above variants, making it\na practical benchmark for classical and graph-based FL research. The dataset\nand related code are available online.", "AI": {"tldr": "\u5f15\u5165\u4e86ModelNet\uff0c\u4e00\u4e2a\u65b0\u7684\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\uff0c\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u8de8\u73af\u5883\u7684\u5ba2\u6237\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u5c55\u793a\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u672c\u5730\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u5e76\u5e94\u5bf9\u9886\u57df\u5f02\u8d28\u6027\u548c\u5ba2\u6237\u7279\u5b9a\u5212\u5206\u7684\u8bc4\u4f30\u74f6\u9888\u3002", "method": "\u901a\u8fc7\u5c06CIFAR100\u6570\u636e\u96c6\u4fee\u6539\u4e3a\u4e09\u79cd\u5ba2\u6237\u7279\u5b9a\u7684\u53d8\u4f53\uff08\u540c\u8d28\u3001\u5f02\u8d28\u548c\u968f\u673a\uff09\uff0c\u5e76\u5728\u9884\u8bad\u7ec3\u7684ResNet50\u6a21\u578b\u4e0a\u8bad\u7ec3\u8fd9\u4e9b\u5b50\u96c6\u4ee5\u4fdd\u5b58\u6a21\u578b\u53c2\u6570\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5047\u8bbe\uff0c\u5b9a\u4e49FL\u7b97\u6cd5\u53ef\u4ee5\u8bbf\u95ee\u533f\u540d\u5316\u7684\u6a21\u578b\u53c2\u6570\uff0c\u66f4\u6709\u6548\u5730\u4fdd\u62a4\u672c\u5730\u9690\u79c1\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u5c55\u793a\u4e86\u8fd9\u4e9b\u53d8\u4f53\u5728\u9886\u57df\u8f6c\u79fb\u548c\u805a\u5408\u7b56\u7565\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684ModelNet\u6570\u636e\u96c6\u5728\u591a\u57df\u56fe\u9a71\u52a8FL\u7b97\u6cd5\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4f7f\u5176\u6210\u4e3a\u7ecf\u5178\u548c\u57fa\u4e8e\u56fe\u7684FL\u7814\u7a76\u7684\u5b9e\u7528\u57fa\u51c6\u3002"}}
{"id": "2506.01080", "pdf": "https://arxiv.org/pdf/2506.01080", "abs": "https://arxiv.org/abs/2506.01080", "authors": ["Florian Carichon", "Aditi Khandelwal", "Marylou Fauchard", "Golnoosh Farnadi"], "title": "The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process", "categories": ["cs.AI", "cs.CY"], "comment": "Preprint of NeurIPS 2025 Position Paper", "summary": "This position paper states that AI Alignment in Multi-Agent Systems (MAS)\nshould be considered a dynamic and interaction-dependent process that heavily\ndepends on the social environment where agents are deployed, either\ncollaborative, cooperative, or competitive. While AI alignment with human\nvalues and preferences remains a core challenge, the growing prevalence of MAS\nin real-world applications introduces a new dynamic that reshapes how agents\npursue goals and interact to accomplish various tasks. As agents engage with\none another, they must coordinate to accomplish both individual and collective\ngoals. However, this complex social organization may unintentionally misalign\nsome or all of these agents with human values or user preferences. Drawing on\nsocial sciences, we analyze how social structure can deter or shatter group and\nindividual values. Based on these analyses, we call on the AI community to\ntreat human, preferential, and objective alignment as an interdependent\nconcept, rather than isolated problems. Finally, we emphasize the urgent need\nfor simulation environments, benchmarks, and evaluation frameworks that allow\nresearchers to assess alignment in these interactive multi-agent contexts\nbefore such dynamics grow too complex to control.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u793e\u4f1a\u73af\u5883\u5bf9\u4ee3\u7406\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u5e76\u547c\u5401\u7ed3\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u3001\u504f\u597d\u548c\u76ee\u6807\u4f5c\u4e3a\u4e92\u76f8\u5173\u8054\u7684\u6982\u5ff5\u8fdb\u884c\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u591a\u4ee3\u7406\u7cfb\u7edf\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u5b83\u6539\u53d8\u4e86\u4ee3\u7406\u5982\u4f55\u8ffd\u6c42\u76ee\u6807\u548c\u4e92\u52a8\u7684\u52a8\u6001\u3002\u590d\u6742\u7684\u793e\u4f1a\u7ec4\u7ec7\u53ef\u80fd\u4f1a\u5bfc\u81f4\u4ee3\u7406\u4e0e\u4eba\u7c7b\u4ef7\u503c\u6216\u7528\u6237\u504f\u597d\u7684\u504f\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u7814\u7a76\u548c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u6587\u7ae0\u4ece\u793e\u4f1a\u79d1\u5b66\u7684\u89c6\u89d2\u5206\u6790\u4e86\u793e\u4f1a\u7ed3\u6784\u5982\u4f55\u5f71\u54cd\u7fa4\u4f53\u548c\u4e2a\u4eba\u4ef7\u503c\u89c2\uff0c\u5e76\u63d0\u51fa\u9700\u8981\u6a21\u62df\u73af\u5883\u548c\u8bc4\u4f30\u6846\u67b6\u6765\u7814\u7a76\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "result": "\u5206\u6790\u4e86\u793e\u4f1a\u7ed3\u6784\u5bf9\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ef7\u503c\u89c2\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u5728\u591a\u4ee3\u7406\u4e92\u52a8\u80cc\u666f\u4e2d\u8bc4\u4f30\u5bf9\u9f50\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "conclusion": "\u547c\u5401AI\u793e\u533a\u5c06\u4eba\u7c7b\u3001\u504f\u597d\u548c\u76ee\u6807\u5bf9\u9f50\u89c6\u4e3a\u76f8\u4e92\u4f9d\u5b58\u7684\u6982\u5ff5\uff0c\u800c\u4e0d\u662f\u5b64\u7acb\u7684\u95ee\u9898\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u6a21\u62df\u73af\u5883\u3001\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u4fbf\u5728\u591a\u4ee3\u7406\u4e92\u52a8\u80cc\u666f\u4e2d\u8bc4\u4f30\u5bf9\u9f50\u95ee\u9898\u3002"}}
{"id": "2506.00422", "pdf": "https://arxiv.org/pdf/2506.00422", "abs": "https://arxiv.org/abs/2506.00422", "authors": ["Yui Sudo", "Yosuke Fukumoto", "Muhammad Shakeel", "Yifan Peng", "Chyi-Jiunn Lin", "Shinji Watanabe"], "title": "DYNAC: Dynamic Vocabulary based Non-Autoregressive Contextualization for Speech Recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Contextual biasing (CB) improves automatic speech recognition for rare and\nunseen phrases. Recent studies have introduced dynamic vocabulary, which\nrepresents context phrases as expandable tokens in autoregressive (AR) models.\nThis method improves CB accuracy but with slow inference speed. While dynamic\nvocabulary can be applied to non-autoregressive (NAR) models, such as\nconnectionist temporal classification (CTC), the conditional independence\nassumption fails to capture dependencies between static and dynamic tokens.\nThis paper proposes DYNAC (Dynamic Vocabulary-based NAR Contextualization), a\nself-conditioned CTC method that integrates dynamic vocabulary into\nintermediate layers. Conditioning the encoder on dynamic vocabulary, DYNAC\neffectively captures dependencies between static and dynamic tokens while\nreducing the real-time factor (RTF). Experimental results show that DYNAC\nreduces RTF by 81% with a 0.1-point degradation in word error rate on the\nLibriSpeech 960 test-clean set.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDYNAC\u65b9\u6cd5\uff0c\u5c06\u52a8\u6001\u8bcd\u6c47\u96c6\u6210\u5230\u975e\u81ea\u56de\u5f52CTC\u6a21\u578b\u4e2d\uff0c\u6709\u6548\u964d\u4f4e\u5b9e\u65f6\u56e0\u5b50\u5e76\u4fdd\u6301\u8bed\u5883\u504f\u5411\u51c6\u786e\u3002", "motivation": "\u52a8\u6001\u8bcd\u6c47\u80fd\u591f\u63d0\u9ad8\u8bed\u5883\u504f\u5411\u7cbe\u5ea6\uff0c\u4f46\u5728\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u63a8\u7406\u901f\u5ea6\u8f83\u6162\u3002\u4e3a\u4e86\u5728\u975e\u81ea\u56de\u5f52\u6a21\u578b\u4e2d\u5e94\u7528\u52a8\u6001\u8bcd\u6c47\u5e76\u89e3\u51b3\u6761\u4ef6\u72ec\u7acb\u5047\u8bbe\u6240\u5bfc\u81f4\u7684\u4f9d\u8d56\u5173\u7cfb\u6355\u6349\u95ee\u9898\uff0c\u63d0\u51fa\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u6761\u4ef6\u5316CTC\u65b9\u6cd5\uff08DYNAC\uff09\uff0c\u5c06\u52a8\u6001\u8bcd\u6c47\u6574\u5408\u5230\u4e2d\u95f4\u5c42\uff0c\u5bf9\u7f16\u7801\u5668\u8fdb\u884c\u52a8\u6001\u8bcd\u6c47\u6761\u4ef6\u5316\uff0c\u4ee5\u6355\u6349\u9759\u6001\u548c\u52a8\u6001\u8bcd\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDYNAC\u5728LibriSpeech 960 test-clean\u96c6\u5408\u4e0a\u5c06\u5b9e\u65f6\u56e0\u5b50\u964d\u4f4e\u4e8681%\uff0c\u540c\u65f6\u8bcd\u9519\u8bef\u7387\u4ec5\u7565\u5fae\u4e0b\u964d\u4e860.1\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684DYNAC\u65b9\u6cd5\u901a\u8fc7\u5728\u4e2d\u95f4\u5c42\u96c6\u6210\u52a8\u6001\u8bcd\u6c47\uff0c\u6709\u6548\u6355\u83b7\u4e86\u9759\u6001\u548c\u52a8\u6001\u8bcd\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5b9e\u65f6\u56e0\u5b50\uff08RTF\uff09\u3002"}}
{"id": "2506.00477", "pdf": "https://arxiv.org/pdf/2506.00477", "abs": "https://arxiv.org/abs/2506.00477", "authors": ["Leila Mahmoodi", "Peyman Moghadam", "Munawar Hayat", "Christian Simon", "Mehrtash Harandi"], "title": "Flashbacks to Harmonize Stability and Plasticity in Continual Learning", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "Manuscript submitted to Neural Networks (Elsevier) in August 2024;\n  and accepted in May 2025 for publication. This version is author-accepted\n  manuscript before copyediting and typesetting. The codes of this article will\n  be available at https://github.com/csiro-robotics/Flashback-Learning", "summary": "We introduce Flashback Learning (FL), a novel method designed to harmonize\nthe stability and plasticity of models in Continual Learning (CL). Unlike prior\napproaches that primarily focus on regularizing model updates to preserve old\ninformation while learning new concepts, FL explicitly balances this trade-off\nthrough a bidirectional form of regularization. This approach effectively\nguides the model to swiftly incorporate new knowledge while actively retaining\nits old knowledge. FL operates through a two-phase training process and can be\nseamlessly integrated into various CL methods, including replay, parameter\nregularization, distillation, and dynamic architecture techniques. In designing\nFL, we use two distinct knowledge bases: one to enhance plasticity and another\nto improve stability. FL ensures a more balanced model by utilizing both\nknowledge bases to regularize model updates. Theoretically, we analyze how the\nFL mechanism enhances the stability-plasticity balance. Empirically, FL\ndemonstrates tangible improvements over baseline methods within the same\ntraining budget. By integrating FL into at least one representative baseline\nfrom each CL category, we observed an average accuracy improvement of up to\n4.91% in Class-Incremental and 3.51% in Task-Incremental settings on standard\nimage classification benchmarks. Additionally, measurements of the\nstability-to-plasticity ratio confirm that FL effectively enhances this\nbalance. FL also outperforms state-of-the-art CL methods on more challenging\ndatasets like ImageNet.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u79f0\u4e3aFlashback Learning (FL) \u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u534f\u8c03\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u3002\u901a\u8fc7\u53cc\u5411\u6b63\u5219\u5316\u5f62\u5f0f\uff0cFL \u6709\u6548\u5e73\u8861\u4e86\u65b0\u65e7\u77e5\u8bc6\u7684\u83b7\u53d6\u548c\u4fdd\u7559\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFL \u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u7684\u51c6\u786e\u6027\u5e73\u5747\u63d0\u9ad8\u4e864.91%\uff08Class-Incremental) \u548c3.51%\uff08Task-Incremental)\uff0c\u5e76\u4e14\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\uff0c\u6a21\u578b\u9700\u8981\u540c\u65f6\u4fdd\u7559\u65e7\u77e5\u8bc6\u53ca\u8fc5\u901f\u5438\u6536\u65b0\u77e5\u8bc6\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u6570\u5173\u6ce8\u901a\u8fc7\u5bf9\u6a21\u578b\u66f4\u65b0\u8fdb\u884c\u6b63\u5219\u5316\u6765\u4fdd\u7559\u65e7\u4fe1\u606f\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u65b9\u6cd5\u6765\u5e73\u8861\u8fd9\u4e00\u8fc7\u7a0b\u4e2d\u7684\u7a33\u5b9a\u6027\u4e0e\u53ef\u5851\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u534f\u8c03\u8fd9\u79cd\u5e73\u8861\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684Flashback Learning (FL) \u662f\u4e00\u79cd\u901a\u8fc7\u53cc\u5411\u6b63\u5219\u5316\u6709\u6548\u534f\u8c03\u65e7\u77e5\u8bc6\u4fdd\u6301\u548c\u65b0\u77e5\u8bc6\u5b66\u4e60\u7684\u8fc7\u7a0b\u3002FL \u91c7\u7528\u53cc\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4f7f\u7528\u4e24\u4e2a\u4e0d\u540c\u7684\u77e5\u8bc6\u5e93\uff1a\u4e00\u4e2a\u589e\u5f3a\u53ef\u5851\u6027\uff0c\u53e6\u4e00\u4e2a\u63d0\u9ad8\u7a33\u5b9a\u6027\u3002FL \u53ef\u4ee5\u65e0\u7f1d\u7ed3\u5408\u5230\u591a\u79cdCL\u65b9\u6cd5\u4e2d\uff0c\u5305\u62ec\u91cd\u653e\u3001\u53c2\u6570\u6b63\u5219\u5316\u3001\u84b8\u998f\u548c\u52a8\u6001\u67b6\u6784\u6280\u672f\u3002", "result": "\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\uff0cFL\u5728Class-Incremental\u548cTask-Incremental\u8bbe\u7f6e\u4e2d\u7684\u5e73\u5747\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e864.91%\u548c3.51%\u3002\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\uff08\u5982ImageNet\uff09\u4e0a\uff0cFL \u7684\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684CL\u65b9\u6cd5\u3002", "conclusion": "Flashback Learning (FL) \u662f\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6709\u6548\u5e73\u8861\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u4e0e\u53ef\u5851\u6027\uff0c\u63d0\u9ad8\u4e86\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u7279\u5b9a\u8bad\u7ec3\u9884\u7b97\u5185\uff0cFL \u5728\u5404\u7c7b\u57fa\u51c6\u548c\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u5747\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002"}}
{"id": "2506.01087", "pdf": "https://arxiv.org/pdf/2506.01087", "abs": "https://arxiv.org/abs/2506.01087", "authors": ["Bertram Lud\u00e4scher", "Yilin Xia", "Shawn Bowers"], "title": "Choices and their Provenance: Explaining Stable Solutions of Abstract Argumentation Frameworks", "categories": ["cs.AI", "cs.SC"], "comment": "International Workshop on the Theory and Practice of Provenance\n  (TaPP) and ProvenanceWeek'25 @SIGMOD, June 27, 2025. Berlin, Germany", "summary": "The rule $\\mathrm{Defeated}(x) \\leftarrow \\mathrm{Attacks}(y,x),\\, \\neg \\,\n\\mathrm{Defeated}(y)$, evaluated under the well-founded semantics (WFS), yields\na unique 3-valued (skeptical) solution of an abstract argumentation framework\n(AF). An argument $x$ is defeated ($\\mathrm{OUT}$) if there exists an\nundefeated argument $y$ that attacks it. For 2-valued (stable) solutions, this\nis the case iff $y$ is accepted ($\\mathrm{IN}$), i.e., if all of $y$'s\nattackers are defeated. Under WFS, arguments that are neither accepted nor\ndefeated are undecided ($\\mathrm{UNDEC}$). As shown in prior work, well-founded\nsolutions (a.k.a. grounded labelings) \"explain themselves\": The provenance of\narguments is given by subgraphs (definable via regular path queries) rooted at\nthe node of interest. This provenance is closely related to winning strategies\nof a two-player argumentation game.\n  We present a novel approach for extending this provenance to stable AF\nsolutions. Unlike grounded solutions, which can be constructed via a bottom-up\nalternating fixpoint procedure, stable models often involve non-deterministic\nchoice as part of the search for models. Thus, the provenance of stable\nsolutions is of a different nature, and reflects a more expressive generate &\ntest paradigm. Our approach identifies minimal sets of critical attacks,\npinpointing choices and assumptions made by a stable model. These critical\nattack edges provide additional insights into the provenance of an argument's\nstatus, combining well-founded derivation steps with choice steps. Our approach\ncan be understood as a form of diagnosis that finds minimal \"repairs\" to an AF\ngraph such that the well-founded solution of the repaired graph coincides with\nthe desired stable model of the original AF graph.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6269\u5c55\u7a33\u5b9aAF\u65b9\u6848\u6765\u6e90\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc6\u522b\u5173\u952e\u653b\u51fb\u96c6\uff0c\u7ed3\u5408\u57fa\u7840\u63a8\u5bfc\u6b65\u9aa4\u4e0e\u9009\u62e9\u6b65\u9aa4\u4ee5\u8bca\u65ad\u5e76\u4fee\u590dAF\u56fe\u3002", "motivation": "\u5bf9\u4e8e\u7a33\u5b9a\u6a21\u578b\uff0c\u5bfb\u6c42\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u6269\u5c55\u5176\u63a8\u5bfc\u8fc7\u7a0b\uff0c\u5e76\u66f4\u8be6\u7ec6\u5730\u7406\u89e3\u8bba\u8bc1\u72b6\u6001\u7684\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u751f\u6210\u5e76\u6d4b\u8bd5\u7684\u65b9\u5f0f\u6269\u5c55\u7a33\u5b9aAF\u65b9\u6848\u7684\u6765\u6e90\uff0c\u8bc6\u522b\u6700\u5c0f\u7684\u5173\u952e\u653b\u51fb\u96c6\uff0c\u7ed3\u5408\u57fa\u7840\u63a8\u5bfc\u6b65\u9aa4\u4e0e\u9009\u62e9\u6b65\u9aa4\u3002\u901a\u8fc7\u8bc6\u522b\u6bcf\u4e2a\u8bba\u8bc1\u72b6\u6001\u7684\u5173\u952e\u653b\u51fb\u8fb9\uff0c\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u89c1\u89e3\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u8bc6\u522b\u7a33\u5b9a\u6a21\u578b\u4e2d\u7684\u6700\u5c0f\u5173\u952e\u653b\u51fb\u96c6\uff0c\u5e76\u5c06\u5176\u4e0e\u57fa\u7840AF\u6a21\u578b\u7ed3\u5408\uff0c\u4ee5\u63d0\u4f9b\u5173\u4e8e\u8bba\u8bc1\u72b6\u6001\u7684\u66f4\u8be6\u7ec6\u7684\u6765\u6e90\u4fe1\u606f\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u6269\u5c55\u7a33\u5b9aAF\u65b9\u6848\u7684\u6765\u6e90\uff0c\u5e76\u8bc6\u522b\u6700\u5c0f\u7684\u5173\u952e\u653b\u51fb\u96c6\uff0c\u7ed3\u5408\u4e86\u57fa\u7840\u63a8\u5bfc\u6b65\u9aa4\u548c\u9009\u62e9\u6b65\u9aa4\u7684\u89c1\u89e3\u3002\u901a\u8fc7\u627e\u5230\u5bf9AF\u56fe\u7684\u6700\u5c0f\"\u4fee\u590d\"\uff0c\u4f7f\u4e4b\u901a\u8fc7\u57fa\u7840\u9009\u62e9\u6b65\u9aa4\u4e0e\u539f\u59cbAF\u56fe\u7684\u7a33\u5b9a\u6a21\u578b\u4e00\u81f4\u3002"}}
{"id": "2506.00425", "pdf": "https://arxiv.org/pdf/2506.00425", "abs": "https://arxiv.org/abs/2506.00425", "authors": ["Bingsen Chen", "Shengjie Wang", "Xi Ye", "Chen Zhao"], "title": "Inter-Passage Verification for Multi-evidence Multi-answer QA", "categories": ["cs.CL"], "comment": "19 pages, 6 figures, to appear in ACL 2025 Findings", "summary": "Multi-answer question answering (QA), where questions can have many valid\nanswers, presents a significant challenge for existing retrieval-augmented\ngeneration-based QA systems, as these systems struggle to retrieve and then\nsynthesize a large number of evidence passages. To tackle these challenges, we\npropose a new multi-answer QA framework -- Retrieval-augmented Independent\nReading with Inter-passage Verification (RI$^2$VER). Our framework retrieves a\nlarge set of passages and processes each passage individually to generate an\ninitial high-recall but noisy answer set. Then we propose a new inter-passage\nverification pipeline that validates every candidate answer through (1)\nVerification Question Generation, (2) Gathering Additional Evidence, and (3)\nVerification with inter-passage synthesis. Evaluations on the QAMPARI and RoMQA\ndatasets demonstrate that our framework significantly outperforms existing\nbaselines across various model sizes, achieving an average F1 score improvement\nof 11.17%. Further analysis validates that our inter-passage verification\npipeline enables our framework to be particularly beneficial for questions\nrequiring multi-evidence synthesis.", "AI": {"tldr": "RI$^2$VER enhances multi-answer QA by individually processing passages and using inter-passage verification, greatly improving F1 scores over existing systems.", "motivation": "Existing retrieval-augmented generation-based QA systems struggle to manage large amounts of evidence due to multiple valid answers, motivating the need for an improved framework to handle multi-answer questions.", "method": "The proposed method retrieves a large set of passages, processes each individually to generate initial answers, and then applies an inter-passage verification pipeline involving verification question generation, gathering additional evidence, and verification through inter-passage synthesis.", "result": "Evaluations on the QAMPARI and RoMQA datasets show the proposed framework outperforms existing baselines across various model sizes, improving the average F1 score by 11.17%.", "conclusion": "RI$^2$VER framework significantly improves multi-answer QA by effectively handling challenges of retrieving and synthesizing evidence from multiple passages, outperforming existing baselines with an average F1 score improvement of 11.17%."}}
{"id": "2506.00478", "pdf": "https://arxiv.org/pdf/2506.00478", "abs": "https://arxiv.org/abs/2506.00478", "authors": ["Hongjie Zhu", "Zezheng Zhang", "Zeyu Zhang", "Yu Bai", "Shimin Wen", "Huazhang Wang", "Daji Ergu", "Ying Cai", "Yang Zhao"], "title": "Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generator\npower outputs by utilizing the non-linear relationships between voltage\nmagnitudes and phase angles in a power system. However, current AC-OPF solvers\nstruggle to effectively represent the complex relationship between variable\ndistributions in the constraint space and their corresponding optimal\nsolutions. This limitation in constraint modeling restricts the system's\nability to develop diverse knowledge representations. Additionally, modeling\nthe power grid solely based on spatial topology further limits the integration\nof additional prior knowledge, such as temporal information. To overcome these\nchallenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-Driven\nPhysics-Informed Graph Convolutional Network), a new method designed to address\nconstraint-related issues and build a graph-based learning framework that\nincorporates spatiotemporal features. DDA-PIGCN improves consistency\noptimization for features with varying long-range dependencies by applying\nmulti-layer, hard physics-informed constraints. It also uses a dynamic domain\nadaptation learning mechanism that iteratively updates and refines key state\nvariables under predefined constraints, enabling precise constraint\nverification. Moreover, it captures spatiotemporal dependencies between\ngenerators and loads by leveraging the physical structure of the power grid,\nallowing for deep integration of topological information across time and space.\nExtensive comparative and ablation studies show that DDA-PIGCN delivers strong\nperformance across several IEEE standard test cases (such as case9, case30, and\ncase300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 and\nconstraint satisfaction rates between 99.6% and 100%, establishing it as a\nreliable and efficient AC-OPF solver.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41\u6c42\u89e3\u5668DDA-PIGCN\uff0c\u901a\u8fc7\u52a8\u6001\u57df\u9002\u5e94\u4e0e\u7269\u7406\u4fe1\u606f\u56fe\u5377\u79ef\u7f51\u7edc\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u7ea6\u675f\u76f8\u5173\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u7684\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41\u6c42\u89e3\u5668\u96be\u4ee5\u6709\u6548\u8868\u793a\u53d8\u91cf\u5206\u5e03\u7684\u590d\u6742\u5173\u7cfb\u53ca\u5176\u5bf9\u5e94\u7684\u6700\u4f18\u89e3\uff0c\u7ea6\u675f\u5efa\u6a21\u7684\u5c40\u9650\u6027\u9650\u5236\u4e86\u7cfb\u7edf\u53d1\u5c55\u77e5\u8bc6\u8868\u793a\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5355\u7eaf\u57fa\u4e8e\u7a7a\u95f4\u62d3\u6251\u6765\u5efa\u6a21\u7535\u7f51\u8fdb\u4e00\u6b65\u9650\u5236\u4e86\u989d\u5916\u5148\u9a8c\u77e5\u8bc6\u7684\u6574\u5408\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5DDA-PIGCN\uff0c\u901a\u8fc7\u5c06\u52a8\u6001\u57df\u9002\u5e94\u4e0e\u7269\u7406\u4fe1\u606f\u56fe\u5377\u79ef\u7f51\u7edc\u76f8\u7ed3\u5408\uff0c\u4ee5\u89e3\u51b3\u7ea6\u675f\u76f8\u5173\u7684\u95ee\u9898\u5e76\u6784\u5efa\u4e00\u4e2a\u5305\u542b\u65f6\u7a7a\u7279\u5f81\u7684\u56fe\u5b66\u4e60\u6846\u67b6\u3002", "result": "DDA-PIGCN \u5728\u591a\u4e2aIEEE\u6807\u51c6\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u8868\u73b0\u5f3a\u52b2\uff0c\u83b7\u5f97\u4e86\u4ece0.0011\u52300.0624\u7684\u5747\u7edd\u5bf9\u8bef\u5dee\u548c\u4ece99.6%\u5230100%\u7684\u7ea6\u675f\u6ee1\u8db3\u7387\u3002", "conclusion": "DDA-PIGCN \u662f\u4e00\u79cd\u53ef\u9760\u800c\u9ad8\u6548\u7684\u4ea4\u6d41\u6700\u4f18\u6f6e\u6d41(AC-OPF)\u6c42\u89e3\u5668\uff0c\u80fd\u591f\u5728\u591a\u4e2aIEEE\u6807\u51c6\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4f4e\u5747\u7edd\u5bf9\u8bef\u5dee\u548c\u9ad8\u7ea6\u675f\u6ee1\u8db3\u7387\u3002"}}
{"id": "2506.01093", "pdf": "https://arxiv.org/pdf/2506.01093", "abs": "https://arxiv.org/abs/2506.01093", "authors": ["Kunal Khanvilkar", "Kranthi Kommuru"], "title": "Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking", "categories": ["cs.AI", "cs.CE", "cs.LG"], "comment": null, "summary": "This paper presents a real-time transaction monitoring framework that\nintegrates graph-based modeling, narrative field embedding, and generative\nexplanation to support automated financial compliance. The system constructs\ndynamic transaction graphs, extracts structural and contextual features, and\nclassifies suspicious behavior using a graph neural network. A\nretrieval-augmented generation module generates natural language explanations\naligned with regulatory clauses for each flagged transaction. Experiments\nconducted on a simulated stream of financial data show that the proposed method\nachieves superior results, with 98.2% F1-score, 97.8% precision, and 97.0%\nrecall. Expert evaluation further confirms the quality and interpretability of\ngenerated justifications. The findings demonstrate the potential of combining\ngraph intelligence and generative models to support explainable, audit-ready\ncompliance in high-risk financial environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u56fe\u6a21\u578b\u5316\u3001\u53d9\u8ff0\u5b57\u6bb5\u5d4c\u5165\u548c\u751f\u6210\u6027\u89e3\u91ca\u7684\u5b9e\u65f6\u4ea4\u6613\u76d1\u63a7\u6846\u67b6\uff0c\u7528\u4e8e\u652f\u6301\u81ea\u52a8\u5316\u91d1\u878d\u5408\u89c4\u6027\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u83b7\u5f97\u4e13\u5bb6\u8ba4\u53ef\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u81ea\u52a8\u5316\u91d1\u878d\u5408\u89c4\u6027\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u4ea4\u6613\u76d1\u63a7\u6846\u67b6\u3002", "method": "\u8be5\u7cfb\u7edf\u6784\u5efa\u52a8\u6001\u4ea4\u6613\u56fe\uff0c\u63d0\u53d6\u7ed3\u6784\u548c\u4e0a\u4e0b\u6587\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u53ef\u7591\u884c\u4e3a\u3002\u7136\u540e\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u5757\u4e3a\u6bcf\u4e2a\u6807\u8bb0\u7684\u4ea4\u6613\u751f\u6210\u4e0e\u6cd5\u89c4\u6761\u6b3e\u4e00\u81f4\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u5728\u6a21\u62df\u91d1\u878d\u6570\u636e\u6d41\u4e0a\u7684\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e8698.2%\u7684F1-score\u300197.8%\u7684\u7cbe\u5ea6\u548c97.0%\u7684\u53ec\u56de\u7387\u3002\u4e13\u5bb6\u8bc4\u4f30\u8fdb\u4e00\u6b65\u786e\u8ba4\u751f\u6210\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5c06\u56fe\u667a\u80fd\u4e0e\u751f\u6210\u6a21\u578b\u7ed3\u5408\u53ef\u4ee5\u652f\u6301\u89e3\u91ca\u6027\u5f3a\u3001\u53ef\u5ba1\u8ba1\u7684\u9ad8\u98ce\u9669\u91d1\u878d\u73af\u5883\u5408\u89c4\u3002"}}
{"id": "2506.00445", "pdf": "https://arxiv.org/pdf/2506.00445", "abs": "https://arxiv.org/abs/2506.00445", "authors": ["Long Bai", "Zixuan Li", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng", "Tat-Seng Chua"], "title": "G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models", "categories": ["cs.CL"], "comment": "Findings of ACL 2025", "summary": "Forecasting over Temporal Knowledge Graphs (TKGs) which predicts future facts\nbased on historical ones has received much attention. Recent studies have\nintroduced Large Language Models (LLMs) for this task to enhance the models'\ngeneralization abilities. However, these models perform forecasting via\nsimultaneously learning two kinds of entangled knowledge in the TKG: (1)\ngeneral patterns, i.e., invariant temporal structures shared across different\nscenarios; and (2) scenario information, i.e., factual knowledge engaged in\nspecific scenario, such as entities and relations. As a result, the learning\nprocesses of these two kinds of knowledge may interfere with each other, which\npotentially impact the generalization abilities of the models. To enhance the\ngeneralization ability of LLMs on this task, in this paper, we propose a\nGeneral-to-Specific learning framework (G2S) that disentangles the learning\nprocesses of the above two kinds of knowledge. In the general learning stage,\nwe mask the scenario information in different TKGs and convert it into\nanonymous temporal structures. After training on these structures, the model is\nable to capture the general patterns across different TKGs. In the specific\nlearning stage, we inject the scenario information into the structures via\neither in-context learning or fine-tuning modes. Experimental results show that\nG2S effectively improves the generalization abilities of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u6846\u67b6G2S\uff0c\u901a\u8fc7\u5206\u79bb\u4e00\u822c\u6a21\u5f0f\u548c\u573a\u666f\u4fe1\u606f\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\uff08TKG\uff09\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u5728TKG\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u73b0\u6709\u7814\u7a76\u5f15\u5165\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u5c06\u4e24\u79cd\u77e5\u8bc6\uff08\u4e00\u822c\u6a21\u5f0f\u548c\u573a\u666f\u4fe1\u606f\uff09\u6df7\u6dc6\uff0c\u4e92\u76f8\u5e72\u6270\uff0c\u5f71\u54cd\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u800c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u5206\u79bb\u8fd9\u4e24\u79cd\u77e5\u8bc6\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aG2S\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5c06\u5b66\u4e60\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\u6765\u89e3\u51b3\u95ee\u9898\u3002\u5728\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u901a\u8fc7\u5c06\u573a\u666f\u4fe1\u606f\u63a9\u76d6\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u533f\u540d\u7684\u65f6\u95f4\u7ed3\u6784\uff0c\u8ba9\u6a21\u578b\u6355\u6349\u4e0d\u540cTKG\u4e2d\u7684\u4e00\u822c\u6a21\u5f0f\u3002\u5728\u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u4f7f\u7528\u60c5\u666f\u4fe1\u606f\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u6216\u5fae\u8c03\u65b9\u5f0f\u5c06\u5176\u6ce8\u5165\u7ed3\u6784\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cG2S\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "G2S\u5b66\u4e60\u6846\u67b6\u6210\u529f\u5730\u5206\u79bb\u4e86\u4e00\u822c\u6a21\u5f0f\u548c\u573a\u666f\u4fe1\u606f\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728TKG\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.00482", "pdf": "https://arxiv.org/pdf/2506.00482", "abs": "https://arxiv.org/abs/2506.00482", "authors": ["Eunsu Kim", "Haneul Yoo", "Guijin Son", "Hitesh Patel", "Amit Agarwal", "Alice Oh"], "title": "BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "As large language models (LLMs) continue to advance, the need for up-to-date\nand well-organized benchmarks becomes increasingly critical. However, many\nexisting datasets are scattered, difficult to manage, and make it challenging\nto perform evaluations tailored to specific needs or domains, despite the\ngrowing importance of domain-specific models in areas such as math or code. In\nthis paper, we introduce BenchHub, a dynamic benchmark repository that empowers\nresearchers and developers to evaluate LLMs more effectively. BenchHub\naggregates and automatically classifies benchmark datasets from diverse\ndomains, integrating 303K questions across 38 benchmarks. It is designed to\nsupport continuous updates and scalable data management, enabling flexible and\ncustomizable evaluation tailored to various domains or use cases. Through\nextensive experiments with various LLM families, we demonstrate that model\nperformance varies significantly across domain-specific subsets, emphasizing\nthe importance of domain-aware benchmarking. We believe BenchHub can encourage\nbetter dataset reuse, more transparent model comparisons, and easier\nidentification of underrepresented areas in existing benchmarks, offering a\ncritical infrastructure for advancing LLM evaluation research.", "AI": {"tldr": "\u5f15\u5165BenchHub\uff0c\u4e00\u4e2a\u52a8\u6001\u57fa\u51c6\u5e93\uff0c\u7528\u4e8e\u66f4\u6709\u6548\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u9886\u57df\u7279\u5b9a\u7684\u7075\u6d3b\u8bc4\u4f30\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u6570\u636e\u96c6\u6563\u4e71\u4e14\u96be\u4ee5\u7ba1\u7406\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7279\u5b9a\u9886\u57df\u6216\u9700\u6c42\u7684\u8bc4\u4f30\u65f6\u56f0\u96be\u91cd\u91cd\uff0c\u56e0\u6b64\u672c\u6587\u5f15\u5165\u4e86BenchHub\uff0c\u4ee5\u5e2e\u52a9\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u4eba\u5458\u66f4\u6709\u6548\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u5728\u8bba\u6587\u4e2d\uff0c\u901a\u8fc7\u591a\u9879\u5b9e\u9a8c\u5c55\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u5b50\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u9886\u57df\u611f\u77e5\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002BenchHub\u81ea\u52a8\u805a\u5408\u548c\u5206\u7c7b\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u652f\u6301\u6301\u7eed\u66f4\u65b0\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u7ba1\u7406\u3002", "result": "BenchHub\u96c6\u6210\u4e8638\u4e2a\u57fa\u51c6\u7684303K\u95ee\u9898\uff0c\u652f\u6301\u7075\u6d3b\u53ef\u5b9a\u5236\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9002\u5e94\u5404\u79cd\u9886\u57df\u6216\u4f7f\u7528\u6848\u4f8b\uff0c\u662f\u63a8\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7814\u7a76\u7684\u91cd\u8981\u57fa\u7840\u8bbe\u65bd\u3002", "conclusion": "BenchHub\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u57fa\u51c6\u5e93\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4fc3\u8fdb\u66f4\u597d\u7684\u6570\u636e\u96c6\u91cd\u7528\u3001\u66f4\u900f\u660e\u7684\u6a21\u578b\u6bd4\u8f83\u548c\u66f4\u5bb9\u6613\u8bc6\u522b\u73b0\u6709\u57fa\u51c6\u4e2d\u7684\u4e0d\u8db3\u4e4b\u5904\u3002"}}
{"id": "2506.01095", "pdf": "https://arxiv.org/pdf/2506.01095", "abs": "https://arxiv.org/abs/2506.01095", "authors": ["Khe-Han Toh", "Hong-Kuan Teo"], "title": "Modular Speaker Architecture: A Framework for Sustaining Responsibility and Contextual Integrity in Multi-Agent AI Communication", "categories": ["cs.AI"], "comment": null, "summary": "Sustaining coherent, role-aware communication across multi-agent systems\nremains a foundational challenge in AI. Current frameworks often lack explicit\nmechanisms for speaker responsibility, leading to context drift, alignment\ninstability, and degraded interpretability over time. We propose the Modular\nSpeaker Architecture (MSA), a framework that decomposes speaker behavior into\nmodular components for role tracking, responsibility continuity, and contextual\ncoherence. Grounded in high-context human-AI dialogues, MSA includes three core\nmodules: a Speaker Role Module, a Responsibility Chain Tracker, and a\nContextual Integrity Validator. We evaluate MSA through annotated case studies\nand introduce structural metrics-pragmatic consistency, responsibility flow,\nand context stability-quantified via manual and automatic scoring and\nbootstrapped statistical analysis. Our results show that MSA reliably maintains\ninteraction structure without reliance on affective signals or surface-level\nheuristics. We further implement a prototype configuration language (G-Code)\nand modular API to support MSA deployment in dynamic multi-agent scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u6a21\u5757\u5316\u8bf4\u8bdd\u8005\u67b6\u6784\uff08MSA\uff09\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u8ddf\u8e2a\u3001\u8d23\u4efb\u8fde\u7eed\u6027\u548c\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6846\u67b6\u7f3a\u4e4f\u660e\u786e\u7684\u8bf4\u8bdd\u8005\u8d23\u4efb\u673a\u5236\uff0c\u5bfc\u81f4\u8bed\u5883\u6f02\u79fb\u3001\u5bf9\u9f50\u4e0d\u7a33\u5b9a\u4ee5\u53ca\u53ef\u89e3\u91ca\u6027\u4e0b\u964d\u3002\u6b64\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u7684\u8bf4\u8bdd\u8005\u67b6\u6784\uff0c\u5305\u62ec\u8bf4\u8bdd\u8005\u89d2\u8272\u6a21\u5757\u3001\u8d23\u4efb\u94fe\u8ddf\u8e2a\u5668\u548c\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\u9a8c\u8bc1\u5668\uff0c\u901a\u8fc7\u624b\u52a8\u548c\u81ea\u52a8\u8bc4\u5206\u4ee5\u53ca\u5f15\u5bfc\u7684\u7edf\u8ba1\u5206\u6790\u6765\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "MSA \u5728\u52a8\u6001\u7684\u591a\u4ee3\u7406\u573a\u666f\u4e2d\u5b9e\u73b0\u7a33\u5b9a\u7684\u6c9f\u901a\u7ed3\u6784\uff0c\u4e14\u65e0\u9700\u4f9d\u8d56\u60c5\u611f\u4fe1\u53f7\u6216\u6d45\u5c42\u542f\u53d1\u3002", "conclusion": "MSA\u53ef\u4ee5\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u7a33\u5b9a\u7684\u4ea4\u4e92\u7ed3\u6784\uff0c\u5e76\u4e14\u4e0d\u4f9d\u8d56\u4e8e\u60c5\u611f\u4fe1\u53f7\u6216\u8868\u9762\u5c42\u7ea7\u542f\u53d1\u3002"}}
{"id": "2506.00448", "pdf": "https://arxiv.org/pdf/2506.00448", "abs": "https://arxiv.org/abs/2506.00448", "authors": ["Suhas BN", "Han-Chin Shing", "Lei Xu", "Mitch Strong", "Jon Burnsky", "Jessica Ofor", "Jordan R. Mason", "Susan Chen", "Sundararajan Srinivasan", "Chaitanya Shivade", "Jack Moriarty", "Joseph Paul Cohen"], "title": "Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization", "categories": ["cs.CL"], "comment": "https://github.com/amazon-science/acibench-hallucination-annotations", "summary": "Hallucinations in large language models (LLMs) during summarization of\npatient-clinician dialogues pose significant risks to patient care and clinical\ndecision-making. However, the phenomenon remains understudied in the clinical\ndomain, with uncertainty surrounding the applicability of general-domain\nhallucination detectors. The rarity and randomness of hallucinations further\ncomplicate their investigation. In this paper, we conduct an evaluation of\nhallucination detection methods in the medical domain, and construct two\ndatasets for the purpose: A fact-controlled Leave-N-out dataset -- generated by\nsystematically removing facts from source dialogues to induce hallucinated\ncontent in summaries; and a natural hallucination dataset -- arising\norganically during LLM-based medical summarization. We show that general-domain\ndetectors struggle to detect clinical hallucinations, and that performance on\nfact-controlled hallucinations does not reliably predict effectiveness on\nnatural hallucinations. We then develop fact-based approaches that count\nhallucinations, offering explainability not available with existing methods.\nNotably, our LLM-based detectors, which we developed using fact-controlled\nhallucinations, generalize well to detecting real-world clinical\nhallucinations. This research contributes a suite of specialized metrics\nsupported by expert-annotated datasets to advance faithful clinical\nsummarization systems.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u533b\u5b66\u9886\u57df\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5f00\u53d1\u7684LLM\u68c0\u6d4b\u5668\u80fd\u6709\u6548\u68c0\u6d4b\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8a\u5e7b\u89c9\uff0c\u800c\u901a\u7528\u68c0\u6d4b\u5668\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5728\u60a3\u8005-\u4e34\u5e8a\u533b\u751f\u5bf9\u8bdd\u603b\u7ed3\u4e2d\uff0cLLM\u51fa\u73b0\u5e7b\u89c9\u5bf9\u75c5\u4eba\u62a4\u7406\u548c\u4e34\u5e8a\u51b3\u7b56\u9020\u6210\u91cd\u5927\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7814\u7a76\u4e34\u5e8a\u57df\u4e2d\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u8bc4\u4f30\u4e86\u533b\u5b66\u9886\u57df\u4e2d\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4e24\u4e2a\u6570\u636e\u96c6\uff1a\u4e00\u4e2a\u662f\u901a\u8fc7\u7cfb\u7edf\u5730\u4ece\u6e90\u5bf9\u8bdd\u4e2d\u5220\u9664\u4e8b\u5b9e\u4ee5\u8bf1\u5bfc\u5728\u603b\u7ed3\u4e2d\u51fa\u73b0\u5e7b\u89c9\u5185\u5bb9\u7684\"fact-controlled Leave-N-out\"\u6570\u636e\u96c6\uff0c\u53e6\u4e00\u4e2a\u662f\u81ea\u7136\u4ea7\u751f\u7684\u5e7b\u89c9\u6570\u636e\u96c6\u3002", "result": "\u6211\u4eec\u5f00\u53d1\u7684\u57fa\u4e8eLLM\u7684\u68c0\u6d4b\u5668\u5728\u68c0\u6d4b\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8a\u5e7b\u89c9\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u800c\u901a\u7528\u9886\u57df\u7684\u68c0\u6d4b\u5668\u5728\u68c0\u6d4b\u4e34\u5e8a\u5e7b\u89c9\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5728\u63a7\u5236\u5e7b\u89c9\u4e0a\u8868\u73b0\u826f\u597d\u7684\u80fd\u529b\u5e76\u4e0d\u4e00\u5b9a\u80fd\u6709\u6548\u9884\u6d4b\u5176\u5bf9\u81ea\u7136\u5e7b\u89c9\u7684\u68c0\u6d4b\u6548\u7387\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u8d21\u732e\u4e86\u4e00\u5957\u7531\u4e13\u5bb6\u6807\u6ce8\u7684\u6570\u636e\u96c6\u652f\u6301\u7684\u4e13\u4e1a\u5316\u6307\u6807\uff0c\u4ee5\u63a8\u8fdb\u53ef\u4fe1\u7684\u4e34\u5e8a\u603b\u7ed3\u7cfb\u7edf\u3002"}}
{"id": "2506.00486", "pdf": "https://arxiv.org/pdf/2506.00486", "abs": "https://arxiv.org/abs/2506.00486", "authors": ["Jun Wu", "Yirong Xiong", "Jiangtao Wen", "Yuxing Han"], "title": "It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Despite rapid advancements in the research and deployment of large language\nmodels (LLMs), the statistical distribution of model parameters, as well as\ntheir influence on initialization, training dynamics, and downstream\nefficiency, has received surprisingly little attention. A recent work\nintroduced BackSlash, a training-time compression algorithm. It first\ndemonstrated that pre-trained LLM parameters follow generalized Gaussian\ndistributions (GGDs) better. By optimizing GG priors during training, BackSlash\ncan reduce parameters by up to 90\\% with minimal performance loss. Building on\nthis foundational insight, we propose a unified, end-to-end framework for LLM\noptimization based on the GG model. Our contributions are threefold: (1)\nGG-based initialization scheme that aligns with the statistical structure of\ntrained models, resulting in faster convergence and improved accuracy; (2)\nDeepShape, a post-training regularization method that reshapes weight\ndistributions to match a GG profile, improving compressibility with minimized\ndegradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit\nfloating-point format designed for GG-distributed-initialized BackSlash\ntraining, enabling low-cost inference without compromising accuracy.\nExperiments across diverse model architectures show that our framework\nconsistently yields smaller and faster models that match or outperform standard\ntraining baselines. By grounding LLM development in principled statistical\nmodeling, this work forges a new path toward efficient, scalable, and\nhardware-aware AI systems. The code is available on our project page:\nhttps://huggingface.co/spaces/shifeng3711/gg_prior.", "AI": {"tldr": "The paper presents a framework using GG distributions for LLM optimization, improving model size and speed with minimal performance loss by focusing on statistical modeling.", "motivation": "Despite advancements in LLMs, little attention has been given to the statistical distribution of model parameters and their influence on various aspects of the models. The motivation is to enhance the efficiency and scalability of LLMs through principled statistical modeling.", "method": "The method involves a GG-based initialization scheme for faster convergence and improved accuracy, a post-training regularization method called DeepShape to match weight distributions to a GG profile, and an RF8 floating-point format for efficient BackSlash training.", "result": "Experiments show that the framework generates smaller and faster models with maintained or improved performance compared to standard training methods, with parameter reduction of up to 90% and minimal performance loss.", "conclusion": "Our framework consistently yields smaller and faster models that match or outperform standard training baselines by utilizing a GG-based approach that focuses on statistical modeling for efficient and scalable LLM development."}}
{"id": "2506.01096", "pdf": "https://arxiv.org/pdf/2506.01096", "abs": "https://arxiv.org/abs/2506.01096", "authors": ["Yihao Liu", "Shuocheng Li", "Lang Cao", "Yuhang Xie", "Mengyu Zhou", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "title": "SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Large language models are increasingly used for complex reasoning tasks where\nhigh-quality offline data such as expert-annotated solutions and distilled\nreasoning traces are often available. However, in environments with sparse\nrewards, reinforcement learning struggles to sample successful trajectories,\nleading to inefficient learning. At the same time, these offline trajectories\nthat represent correct reasoning paths are not utilized by standard on-policy\nreinforcement learning methods. To address this limitation, we propose SuperRL,\na unified training framework that adaptively incorporates offline supervision\ninto reinforcement learning. SuperRL introduces an Adaptive Switch to detect\nsparse reward conditions and activates a Hybrid Actor when necessary. The\nHybrid Actor integrates policy gradient and supervised learning objectives at\nthe loss level, enabling the model to benefit from accurate offline reasoning\nsignals while maintaining the exploratory capacity of reinforcement learning.\nExperiments on a range of reasoning benchmarks show that SuperRL consistently\noutperforms standard reinforcement learning by improving sample efficiency,\ngeneralization, and robustness under sparse rewards.", "AI": {"tldr": "\u63d0\u51faSuperRL\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u7ebf\u76d1\u7763\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u96be\u4ee5\u91c7\u6837\u6210\u529f\u8f68\u8ff9\u4e14\u6807\u51c6\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u672a\u5229\u7528\u79bb\u7ebf\u8f68\u8ff9\u7684\u95ee\u9898\u3002", "method": "SuperRL\u5f15\u5165\u4e86\u81ea\u9002\u5e94\u5f00\u5173\u548c\u6df7\u5408\u6267\u884c\u5668\uff0c\u4ee5\u5728\u68c0\u6d4b\u5230\u7a00\u758f\u5956\u52b1\u6761\u4ef6\u65f6\u96c6\u6210\u7b56\u7565\u68af\u5ea6\u548c\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cSuperRL\u5728\u4ece\u7a00\u758f\u5956\u52b1\u4e2d\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3001\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u3002", "conclusion": "SuperRL\u80fd\u591f\u5728\u7a00\u758f\u5956\u52b1\u6761\u4ef6\u4e0b\u901a\u8fc7\u7ed3\u5408\u79bb\u7ebf\u76d1\u7763\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3001\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.00469", "pdf": "https://arxiv.org/pdf/2506.00469", "abs": "https://arxiv.org/abs/2506.00469", "authors": ["Shaoxiong Ji", "Zihao Li", "Jaakko Paavola", "Indraneil Paul", "Hengyu Luo", "J\u00f6rg Tiedemann"], "title": "Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data", "categories": ["cs.CL"], "comment": "EMMA-500 Gen 2; refer to Gen 1 in arXiv:2409.17892", "summary": "This paper investigates a critical design decision in the practice of\nmassively multilingual continual pre-training -- the inclusion of parallel\ndata. Specifically, we study the impact of bilingual translation data for\nmassively multilingual language adaptation of the Llama3 family of models to\n500 languages. To this end, we construct the MaLA bilingual translation corpus,\ncontaining data from more than 2,500 language pairs. Subsequently, we develop\nthe EMMA-500 Llama 3 suite of four massively multilingual models -- continually\npre-trained from the Llama 3 family of base models extensively on diverse data\nmixes up to 671B tokens -- and explore the effect of continual pre-training\nwith or without bilingual translation data. Comprehensive evaluation across 7\ntasks and 12 benchmarks demonstrates that bilingual data tends to enhance\nlanguage transfer and performance, particularly for low-resource languages. We\nopen-source the MaLA corpus, EMMA-500 Llama 3 suite artefacts, code, and model\ngenerations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u53cc\u8bed\u7ffb\u8bd1\u6570\u636e\u5bf9Llama3\u6a21\u578b\u591a\u8bed\u8a00\u9002\u5e94\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\u53cc\u8bed\u6570\u636e\u80fd\u63d0\u5347\u8bed\u8a00\u8fc1\u79fb\u548c\u6027\u80fd\uff0c\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002", "motivation": "\u7814\u7a76\u591a\u8bed\u8a00\u8fde\u7eed\u9884\u8bad\u7ec3\u7684\u5173\u952e\u8bbe\u8ba1\u51b3\u7b56 -- \u5e73\u884c\u6570\u636e\u7684\u5305\u542b\uff0c\u4ee5\u53ca\u53cc\u8bed\u7ffb\u8bd1\u6570\u636e\u5bf9\u591a\u8bed\u8a00\u8bed\u8a00\u9002\u5e94\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efaMaLA\u53cc\u8bed\u7ffb\u8bd1\u8bed\u6599\u5e93\uff0c\u5f00\u53d1EMMA-500 Llama 3\u5957\u4ef6\uff0c\u901a\u8fc7\u5bf9\u591a\u79cd\u6570\u636e\u7ec4\u5408\u8fdb\u884c\u8fde\u7eed\u9884\u8bad\u7ec3\uff0c\u7814\u7a76\u53cc\u8bed\u7ffb\u8bd1\u6570\u636e\u5bf9\u8bed\u8a00\u9002\u5e94\u7684\u5f71\u54cd\u3002", "result": "\u57287\u4e2a\u4efb\u52a1\u548c12\u4e2a\u57fa\u51c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0c\u53cc\u8bed\u6570\u636e\u53ef\u4ee5\u589e\u5f3a\u8bed\u8a00\u8fc1\u79fb\u548c\u6027\u80fd\u3002", "conclusion": "\u53cc\u8bed\u6570\u636e\u503e\u5411\u4e8e\u589e\u5f3a\u8bed\u8a00\u8fc1\u79fb\u548c\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002"}}
{"id": "2506.00495", "pdf": "https://arxiv.org/pdf/2506.00495", "abs": "https://arxiv.org/abs/2506.00495", "authors": ["Xinyi Wang", "Lirong Gao", "Haobo Wang", "Yiming Zhang", "Junbo Zhao"], "title": "FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "17 pages, 9 figures", "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a widely\nadopted strategy for adapting pre-trained Large Language Models (LLMs) to\ndownstream tasks, significantly reducing memory and computational costs.\nHowever, most existing PEFT techniques uniformly deploy LoRA adapters across\nall layers, disregarding the intrinsic heterogeneity of layer contributions and\ntask-specific rank requirements. This uniform paradigm leads to redundant\nparameter allocation and suboptimal adaptation efficiency. To address these\nlimitations, we propose FLoE, a novel PEFT framework that introduces two key\ninnovations: (i) a Fisher information-guided importance scoring mechanism to\ndynamically identify task-critical transformer layers for MoE-based low-rank\nadaptation, enabling sparse adapter deployment; and (ii) a Bayesian\noptimization-driven rank allocator that automatically determines optimal LoRA\nranks on specific datasets without exhaustive grid search. Extensive\nexperiments across diverse LLMs and benchmarks reveal that FLoE achieves\nimpressive efficiency-accuracy trade-offs, making FLoE particularly\nadvantageous in resource-constrained environments that necessitate rapid\nadaptation.", "AI": {"tldr": "FLoE is a PEFT method that enhances fine-tuning efficiency by using Fisher scoring for important layer identification and Bayesian optimization for rank allocation, outperforming traditional methods in efficiency and accuracy, especially in resource-limited settings.", "motivation": "The motivation is to improve the efficiency of PEFT methods by addressing the issue of redundant parameter allocation and suboptimal adaptation efficiency in existing methods, which do not consider the varying contributions of different layers and task-specific rank needs.", "method": "FLoE introduces a two-fold method: a Fisher information-based scoring mechanism for identifying important layers for sparse adapter deployment, and a Bayesian optimization-driven rank allocator to determine the optimal LoRA ranks without extensive searching.", "result": "FLoE achieves better efficiency-accuracy trade-offs across multiple large language models and benchmarks, particularly in environments with resource constraints.", "conclusion": "FLoE provides a more efficient approach to fine-tune large language models by using a Fisher information-based method to identify important layers and a Bayesian optimization technique to allocate ranks. This makes it more suited for environments with limited resources."}}
{"id": "2506.01116", "pdf": "https://arxiv.org/pdf/2506.01116", "abs": "https://arxiv.org/abs/2506.01116", "authors": ["Xinyi Liu", "Lipeng Ma", "Yixuan Li", "Weidong Yang", "Qingyuan Zhou", "Jiayi Song", "Shuhao Li", "Ben Fei"], "title": "ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Large Language Models (LLMs) are widely used across various scenarios due to\ntheir exceptional reasoning capabilities and natural language understanding.\nWhile LLMs demonstrate strong performance in tasks involving mathematics and\ncoding, their effectiveness diminishes significantly when applied to\nchemistry-related problems. Chemistry problems typically involve long and\ncomplex reasoning steps, which contain specific terminology, including\nspecialized symbol systems and complex nomenclature conventions. These\ncharacteristics often cause general LLMs to experience hallucinations during\nthe reasoning process due to their lack of specific knowledge. However,\nexisting methods are struggling to effectively leverage chemical expertise and\nformulas. Moreover, current uncertainty estimation methods, designed to\nmitigate potential reasoning errors, are unable to precisely identify specific\nsteps or key knowledge. In this work, we propose a novel framework called\nChemAU, which incorporates our adaptive uncertainty estimation method that\napplies different uncertainty values based on the position of reasoning steps\nwithin the whole reasoning chain. Leveraging this method, ChemAU identifies\ngaps in chemistry knowledge and precisely supplements chemical expertise with\nthe specialized domain model, thereby correcting and updating the previously\nflawed reasoning chain. Our experiments with three popular LLMs across three\nchemistry datasets demonstrate that ChemAU significantly enhances both\nreasoning accuracy and uncertainty estimation.", "AI": {"tldr": "ChemAU enhances LLM performance in chemistry by adapting uncertainty estimation, addressing reasoning accuracy and knowledge gaps.", "motivation": "To address the diminished effectiveness of LLMs in chemistry-related problem-solving due to hallucinations and lack of specific domain knowledge.", "method": "ChemAU incorporates an adaptive uncertainty estimation method that applies varying uncertainty values based on the position of reasoning steps in the reasoning chain.", "result": "ChemAU identifies gaps in chemistry knowledge and supplements chemical expertise, correcting flawed reasoning chains. Experiments show improvement in accuracy and uncertainty estimation.", "conclusion": "ChemAU significantly enhances reasoning accuracy and uncertainty estimation for chemistry problems, addressing the shortcomings of LLMs."}}
{"id": "2506.00479", "pdf": "https://arxiv.org/pdf/2506.00479", "abs": "https://arxiv.org/abs/2506.00479", "authors": ["Zekun Wang", "Minghua Ma", "Zexin Wang", "Rongchuan Mu", "Liping Shan", "Ming Liu", "Bing Qin"], "title": "EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models", "categories": ["cs.CL", "cs.CV", "cs.LG"], "comment": "ACL 2025", "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable success, yet\ntheir significant computational demands hinder practical deployment. While\nefforts to improve LVLM efficiency are growing, existing methods lack\ncomprehensive evaluation across diverse backbones, benchmarks, and metrics. In\nthis work, we systematically evaluate mainstream acceleration techniques for\nLVLMs, categorized into token and parameter compression. We introduce\nEffiVLM-Bench, a unified framework for assessing not only absolute performance\nbut also generalization and loyalty, while exploring Pareto-optimal trade-offs.\nOur extensive experiments and in-depth analyses offer insights into optimal\nstrategies for accelerating LVLMs. We open-source code and recipes for\nEffiVLM-Bench to foster future research.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86LVLMs\u7684\u52a0\u901f\u6280\u672f\uff0c\u63d0\u51faEffiVLM-Bench\u6846\u67b6\u5e76\u63ed\u793a\u4e86\u4f18\u5316\u7b56\u7565\u3002", "motivation": "LVLMs\u5c3d\u7ba1\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5176\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u5f71\u54cd\u4e86\u5b9e\u9645\u90e8\u7f72\u3002\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u4ee5\u63d0\u5347\u6548\u7387\u3002", "method": "\u672c\u6587\u5c06LVLMs\u7684\u52a0\u901f\u6280\u672f\u5206\u4e3a\u2018token\u2019\u538b\u7f29\u548c\u2018parameter\u2019\u538b\u7f29\u4e24\u7c7b\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6EffiVLM-Bench\uff0c\u7528\u4e8e\u8bc4\u4f30\u7edd\u5bf9\u6027\u80fd\u3001\u6cdb\u5316\u80fd\u529b\u548c\u5fe0\u8bda\u6027\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5b9e\u9a8c\u548c\u6df1\u5165\u5206\u6790\uff0c\u63ed\u793a\u4e86LVLMs\u52a0\u901f\u6280\u672f\u7684\u6700\u4f18\u7b56\u7565\uff0c\u5e76\u5f00\u6e90\u4e86EffiVLM-Bench\u7684\u4ee3\u7801\u548c\u6307\u5357\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5bf9\u4e3b\u6d41\u52a0\u901f\u6280\u672f\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86LVLMs\u52a0\u901f\u7684\u6700\u4f18\u7b56\u7565\uff0c\u4fc3\u8fdb\u4e86\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.00499", "pdf": "https://arxiv.org/pdf/2506.00499", "abs": "https://arxiv.org/abs/2506.00499", "authors": ["Diogo Landau", "Ingeborg de Pater", "Mihaela Mitici", "Nishant Saurabh"], "title": "Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study", "categories": ["cs.LG", "cs.DC", "cs.ET", "cs.SY", "eess.SY", "stat.ML"], "comment": null, "summary": "Complex systems such as aircraft engines are continuously monitored by\nsensors. In predictive aircraft maintenance, the collected sensor measurements\nare used to estimate the health condition and the Remaining Useful Life (RUL)\nof such systems. However, a major challenge when developing prognostics is the\nlimited number of run-to-failure data samples. This challenge could be overcome\nif multiple airlines would share their run-to-failure data samples such that\nsufficient learning can be achieved. Due to privacy concerns, however, airlines\nare reluctant to share their data in a centralized setting. In this paper, a\ncollaborative federated learning framework is therefore developed instead.\nHere, several airlines cooperate to train a collective RUL prognostic machine\nlearning model, without the need to centrally share their data. For this, a\ndecentralized validation procedure is proposed to validate the prognostics\nmodel without sharing any data. Moreover, sensor data is often noisy and of low\nquality. This paper therefore proposes four novel methods to aggregate the\nparameters of the global prognostic model. These methods enhance the robustness\nof the FL framework against noisy data. The proposed framework is illustrated\nfor training a collaborative RUL prognostic model for aircraft engines, using\nthe N-CMAPSS dataset. Here, six airlines are considered, that collaborate in\nthe FL framework to train a collective RUL prognostic model for their\naircraft's engines. When comparing the proposed FL framework with the case\nwhere each airline independently develops their own prognostic model, the\nresults show that FL leads to more accurate RUL prognostics for five out of the\nsix airlines. Moreover, the novel robust aggregation methods render the FL\nframework robust to noisy data samples.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u63d0\u5347\u822a\u7a7a\u53d1\u52a8\u673a\u7684\u5269\u4f59\u5bff\u547d\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u65b0\u65b9\u6cd5\u63d0\u5347\u5bf9\u566a\u58f0\u6570\u636e\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u822a\u7a7a\u53d1\u52a8\u673a\u7b49\u590d\u6742\u7cfb\u7edf\u9700\u8981\u51c6\u786e\u7684\u5269\u4f59\u5bff\u547d\u9884\u6d4b\uff0c\u7136\u800c\u7531\u4e8e\u6570\u636e\u9690\u79c1\u95ee\u9898\uff0c\u5404\u822a\u7a7a\u516c\u53f8\u4e0d\u613f\u5171\u4eab\u5176\u6570\u636e\uff0c\u5bfc\u81f4\u96be\u4ee5\u83b7\u53d6\u8db3\u591f\u7684\u6545\u969c\u6837\u672c\u6765\u8fdb\u884c\u6709\u6548\u7684\u9884\u6d4b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u534f\u4f5c\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u51fa\u56db\u79cd\u65b0\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\uff0c\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u9a8c\u8bc1\u7a0b\u5e8f\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7N-CMAPSS\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u5b9e\u9a8c\u3002", "result": "\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u8f83\u72ec\u7acb\u5f00\u53d1\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u5269\u4f59\u5bff\u547d\uff0c\u5c24\u5176\u5728\u516d\u5bb6\u822a\u7a7a\u516c\u53f8\u4e2d\u6709\u4e94\u5bb6\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002\u65b0\u63d0\u51fa\u7684\u65b9\u6cd5\u4e5f\u589e\u5f3a\u4e86\u6846\u67b6\u5e94\u5bf9\u566a\u58f0\u6570\u636e\u7684\u80fd\u529b\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u80fd\u5728\u4e0d\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u591a\u822a\u7a7a\u516c\u53f8\u534f\u4f5c\uff0c\u63d0\u5347\u4e86\u53d1\u52a8\u673a\u5269\u4f59\u5bff\u547d\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u65b0\u9896\u7684\u53c2\u6570\u805a\u5408\u65b9\u6cd5\u589e\u5f3a\u4e86\u5176\u5bf9\u566a\u58f0\u6570\u636e\u7684\u9c81\u68d2\u6027\u3002"}}
