{"id": "2506.06837", "pdf": "https://arxiv.org/pdf/2506.06837", "abs": "https://arxiv.org/abs/2506.06837", "authors": ["Eyal Briman", "Ehud Shapiro", "Nimrod Talmon"], "title": "AI-Generated Compromises for Coalition Formation", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "The challenge of finding compromises between agent proposals is fundamental\nto AI subfields such as argumentation, mediation, and negotiation. Building on\nthis tradition, Elkind et al. (2021) introduced a process for coalition\nformation that seeks majority-supported proposals preferable to the status quo,\nusing a metric space where each agent has an ideal point. A crucial step in\nthis process involves identifying compromise proposals around which agent\ncoalitions can unite. How to effectively find such compromise proposals remains\nan open question. We address this gap by formalizing a model that incorporates\nagent bounded rationality and uncertainty, and by developing AI methods to\ngenerate compromise proposals. We focus on the domain of collaborative document\nwriting, such as the democratic drafting of a community constitution. Our\napproach uses natural language processing techniques and large language models\nto induce a semantic metric space over text. Based on this space, we design\nalgorithms to suggest compromise points likely to receive broad support. To\nevaluate our methods, we simulate coalition formation processes and show that\nAI can facilitate large-scale democratic text editing, a domain where\ntraditional tools are limited.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\uff0c\u7ed3\u5408\u667a\u80fd\u4f53\u7684\u6709\u9650\u7406\u6027\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u751f\u6210\u59a5\u534f\u63d0\u6848\uff0c\u65e8\u5728\u6539\u5584\u534f\u4f5c\u6587\u4ef6\u64b0\u5199\u4e2d\u7684\u6c11\u4e3b\u8fc7\u7a0b\u3002", "motivation": "\u89e3\u51b3\u5982\u4f55\u5728\u667a\u80fd\u4f53\u63d0\u6848\u4e4b\u95f4\u5bfb\u627e\u59a5\u534f\u7684\u95ee\u9898\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5408\u4f5c\u6027\u6587\u4ef6\u64b0\u5199\u9886\u57df\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6587\u672c\u4e0a\u8bf1\u5bfc\u4e00\u4e2a\u8bed\u4e49\u5ea6\u91cf\u7a7a\u95f4\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u4ee5\u5efa\u8bae\u53ef\u80fd\u83b7\u5f97\u5e7f\u6cdb\u652f\u6301\u7684\u59a5\u534f\u70b9\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u8054\u76df\u5f62\u6210\u8fc7\u7a0b\uff0c\u8bc1\u660eAI\u80fd\u591f\u5728\u5927\u89c4\u6a21\u6c11\u4e3b\u6587\u672c\u7f16\u8f91\uff08\u4f20\u7edf\u5de5\u5177\u53d7\u9650\u7684\u9886\u57df\uff09\u4e2d\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "AI methods can facilitate large-scale democratic text editing by generating compromise proposals in collaborative settings."}}
{"id": "2506.07232", "pdf": "https://arxiv.org/pdf/2506.07232", "abs": "https://arxiv.org/abs/2506.07232", "authors": ["Xinran Li", "Chenjia Bai", "Zijian Li", "Jiakun Zheng", "Ting Xiao", "Jun Zhang"], "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) possess extensive knowledge bases and strong\nreasoning capabilities, making them promising tools for complex, multi-agent\nplanning in embodied environments. However, despite LLMs' advanced abilities\nand the sophisticated modular design of agentic methods, existing LLM-based\nplanning algorithms remain limited by weak adaptation capabilities to\nmulti-agent embodied scenarios. We address this limitation by introducing a\nframework that enables LLM agents to learn and evolve both before and during\ntest time, equipping them with environment-relevant knowledge for better\nplanning and enhanced communication for improved cooperation. Inspired by\ncentralized training with decentralized execution in multi-agent reinforcement\nlearning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)}\nparadigm for multi-agent LLMs adaptation. At the individual level, LLM agents\nlearn a local utility function from exploratory datasets to better comprehend\nthe embodied environment, which is then queried during test time to support\ninformed decision-making. At the team level, LLM agents collaboratively and\niteratively maintain and update a shared cooperation knowledge list based on\nnew experiences, using it to guide more effective communication. By combining\nindividual learning with team evolution, LIET enables comprehensive and\nflexible adaptation for LLM agents. Our experiments on Communicative\nWatch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate\nthat LIET, instantiated with both LLaMA and GPT-4o, outperforms existing\nbaselines and exhibits strong cooperative planning abilities.", "AI": {"tldr": "LIET\u6846\u67b6\u901a\u8fc7\u4e2a\u4f53\u5b66\u4e60\u548c\u56e2\u961f\u8fdb\u5316\u63d0\u9ad8LLMs\u5728\u591a\u4ee3\u7406\u73af\u5883\u4e2d\u7684\u89c4\u5212\u548c\u5408\u4f5c\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684LLM\u89c4\u5212\u7b97\u6cd5\u5728\u9002\u5e94\u591a\u4ee3\u7406\u5177\u4f53\u573a\u666f\u65b9\u9762\u80fd\u529b\u8f83\u5f31\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u6d4b\u8bd5\u524d\u548c\u6d4b\u8bd5\u671f\u95f4\u5b66\u4e60\u548c\u8fdb\u5316\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u73af\u5883\u76f8\u5173\u77e5\u8bc6\u548c\u901a\u4fe1\u80fd\u529b\u3002", "method": "LIET\uff08Learn as Individuals, Evolve as a Team\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u4e2a\u4f53\u5b66\u4e60\u548c\u56e2\u961f\u8fdb\u5316\uff0c\u7ed3\u5408\u96c6\u4e2d\u8bad\u7ec3\u548c\u5206\u6563\u6267\u884c\u7684\u7406\u5ff5\uff0c\u4f7fLLMs\u9002\u5e94\u591a\u4ee3\u7406\u73af\u5883\u3002", "result": "LIET\u6846\u67b6\u5728Communicative Watch-And-Help\u548cThreeD-World Multi-Agent Transport\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u5408\u4f5c\u89c4\u5212\u80fd\u529b\u3002", "conclusion": "LIET\u6846\u67b6\u4f7f\u5f97LLMs\u5728\u591a\u4ee3\u7406\u73af\u5883\u4e2d\u80fd\u591f\u66f4\u597d\u5730\u8fdb\u884c\u590d\u6742\u89c4\u5212\u548c\u5408\u4f5c\uff0c\u901a\u8fc7\u4e2a\u4f53\u5b66\u4e60\u548c\u56e2\u961f\u8fdb\u5316\u5b9e\u73b0\u5168\u9762\u7075\u6d3b\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2506.07332", "pdf": "https://arxiv.org/pdf/2506.07332", "abs": "https://arxiv.org/abs/2506.07332", "authors": ["Bo Fu", "Mingjie Bi", "Shota Umeda", "Takahiro Nakano", "Youichi Nonaka", "Quan Zhou", "Takaharu Matsui", "Dawn M. Tilbury", "Kira Barton"], "title": "Digital Twin-based Smart Manufacturing: Dynamic Line Reconfiguration for Disturbance Handling", "categories": ["cs.MA", "93A16"], "comment": "IEEE Transactions on Automation Science and Engineering (T-ASE) and\n  CASE 2025", "summary": "The increasing complexity of modern manufacturing, coupled with demand\nfluctuation, supply chain uncertainties, and product customization, underscores\nthe need for manufacturing systems that can flexibly update their\nconfigurations and swiftly adapt to disturbances. However, current research\nfalls short in providing a holistic reconfigurable manufacturing framework that\nseamlessly monitors system disturbances, optimizes alternative line\nconfigurations based on machine capabilities, and automates simulation\nevaluation for swift adaptations. This paper presents a dynamic manufacturing\nline reconfiguration framework to handle disturbances that result in operation\ntime changes. The framework incorporates a system process digital twin for\nmonitoring disturbances and triggering reconfigurations, a capability-based\nontology model capturing available agent and resource options, a configuration\noptimizer generating optimal line configurations, and a simulation generation\nprogram initializing simulation setups and evaluating line configurations at\napproximately 400x real-time speed. A case study of a battery production line\nhas been conducted to evaluate the proposed framework. In two implemented\ndisturbance scenarios, the framework successfully recovers system throughput\nwith limited resources, preventing the 26% and 63% throughput drops that would\nhave occurred without a reconfiguration plan. The reconfiguration optimizer\nefficiently finds optimal solutions, taking an average of 0.03 seconds to find\na reconfiguration plan for a manufacturing line with 51 operations and 40\navailable agents across 8 agent types.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u5236\u9020\u7ebf\u91cd\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u76d1\u63a7\u3001\u80fd\u529b\u6a21\u578b\u4f18\u5316\u548c\u5feb\u901f\u6a21\u62df\uff0c\u6210\u529f\u5e94\u5bf9\u751f\u4ea7\u5e72\u6270\uff0c\u5e76\u907f\u514d\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\u7684\u5927\u5e45\u5ea6\u4e0b\u964d\u3002", "motivation": "\u73b0\u4ee3\u5236\u9020\u4e1a\u7684\u590d\u6742\u6027\u3001\u591a\u6837\u5316\u9700\u6c42\u3001\u4f9b\u5e94\u94fe\u4e0d\u786e\u5b9a\u6027\u3001\u4ea7\u54c1\u5b9a\u5236\u5316\uff0c\u8981\u6c42\u5236\u9020\u7cfb\u7edf\u5177\u5907\u7075\u6d3b\u66f4\u65b0\u914d\u7f6e\u548c\u5feb\u901f\u9002\u5e94\u6270\u52a8\u7684\u80fd\u529b\u3002\u73b0\u6709\u7814\u7a76\u5e76\u672a\u80fd\u63d0\u4f9b\u8fd9\u79cd\u5168\u9762\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u5236\u9020\u7ebf\u91cd\u6784\u6846\u67b6\uff0c\u5305\u62ec\uff1a\u76d1\u63a7\u5e72\u6270\u548c\u89e6\u53d1\u91cd\u6784\u7684\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u3001\u6355\u6349\u53ef\u7528\u4ee3\u7406\u548c\u8d44\u6e90\u9009\u9879\u7684\u80fd\u529b\u672c\u4f53\u6a21\u578b\u3001\u751f\u6210\u6700\u4f18\u7ebf\u914d\u7f6e\u7684\u4f18\u5316\u5668\u3001\u521d\u59cb\u5316\u6a21\u62df\u5e76\u8bc4\u4f30\u7ebf\u914d\u7f6e\u7684\u7a0b\u5e8f\u3002", "result": "\u5728\u7535\u6c60\u751f\u4ea7\u7ebf\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u6846\u67b6\u6210\u529f\u5728\u4e24\u79cd\u5e72\u6270\u60c5\u5883\u4e0b\u6062\u590d\u7cfb\u7edf\u541e\u5410\u91cf\u3002\u5728\u6ca1\u6709\u91cd\u6784\u8ba1\u5212\u7684\u60c5\u51b5\u4e0b\uff0c\u541e\u5410\u91cf\u5206\u522b\u4e0b\u964d26%\u548c63%\uff0c\u800c\u6846\u67b6\u80fd\u591f\u907f\u514d\u8fd9\u79cd\u60c5\u51b5\u3002\u91cd\u6784\u4f18\u5316\u5668\u57280.03\u79d2\u5185\u4e3a\u5177\u670951\u4e2a\u64cd\u4f5c\u548c40\u4e2a\u4ee3\u7406\u7684\u5236\u9020\u7ebf\u627e\u5230\u6700\u4f18\u91cd\u6784\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u52a8\u6001\u5236\u9020\u7ebf\u91cd\u6784\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5236\u9020\u8fc7\u7a0b\u4e2d\u7684\u5e72\u6270\uff0c\u7ef4\u6301\u7cfb\u7edf\u541e\u5410\u91cf\uff0c\u5373\u4fbf\u8d44\u6e90\u6709\u9650\u4e5f\u80fd\u6062\u590d\u751f\u4ea7\u80fd\u529b\u3002"}}
{"id": "2506.07388", "pdf": "https://arxiv.org/pdf/2506.07388", "abs": "https://arxiv.org/abs/2506.07388", "authors": ["Yun Hua", "Haosheng Chen", "Shiqin Wang", "Wenhao Li", "Xiangfeng Wang", "Jun Luo"], "title": "Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) show strong collaborative performance in\nmulti-agent systems with predefined roles and workflows. However, in open-ended\nenvironments lacking coordination rules, agents tend to act in self-interested\nways. The central challenge in achieving coordination lies in credit assignment\n-- fairly evaluating each agent's contribution and designing pricing mechanisms\nthat align their heterogeneous goals. This problem is critical as LLMs\nincreasingly participate in complex human-AI collaborations, where fair\ncompensation and accountability rely on effective pricing mechanisms. Inspired\nby how human societies address similar coordination challenges (e.g., through\ntemporary collaborations such as employment or subcontracting), we propose a\ncooperative workflow, Shapley-Coop. Shapley-Coop integrates Shapley\nChain-of-Thought -- leveraging marginal contributions as a principled basis for\npricing -- with structured negotiation protocols for effective price matching,\nenabling LLM agents to coordinate through rational task-time pricing and\npost-task reward redistribution. This approach aligns agent incentives, fosters\ncooperation, and maintains autonomy. We evaluate Shapley-Coop across two\nmulti-agent games and a software engineering simulation, demonstrating that it\nconsistently enhances LLM agent collaboration and facilitates equitable credit\nassignment. These results highlight the effectiveness of Shapley-Coop's pricing\nmechanisms in accurately reflecting individual contributions during task\nexecution.", "AI": {"tldr": "\u63d0\u51faShapley-Coop\u5de5\u4f5c\u6d41\uff0c\u7ed3\u5408Shapley\u94fe\u5f0f\u601d\u7ef4\u548c\u534f\u5546\u534f\u8bae\uff0c\u4fc3\u8fdbLLM\u4ee3\u7406\u7684\u534f\u4f5c\u4e0e\u516c\u5e73\u4fe1\u7528\u5206\u914d\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u8868\u73b0\u4f18\u79c0\u5e76\u9010\u6e10\u53c2\u4e0e\u590d\u6742\u7684\u4eba\u673a\u534f\u4f5c\uff0c\u5bf9\u516c\u5e73\u6709\u6548\u7684\u5b9a\u4ef7\u673a\u5236\u9700\u6c42\u53d8\u5f97\u8feb\u5207\uff0c\u4ee5\u786e\u4fdd\u516c\u6b63\u7684\u8865\u507f\u548c\u8d23\u4efb\u5206\u914d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u4f5c\u5de5\u4f5c\u6d41Shapley-Coop\uff0c\u5c06Shapley\u94fe\u5f0f\u601d\u7ef4\u4e0e\u7ed3\u6784\u5316\u7684\u534f\u5546\u534f\u8bae\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u4ef7\u683c\u5339\u914d\uff0c\u4f7fLLM\u4ee3\u7406\u80fd\u901a\u8fc7\u7406\u6027\u7684\u4efb\u52a1\u65f6\u95f4\u5b9a\u4ef7\u548c\u540e\u4efb\u52a1\u5956\u52b1\u91cd\u65b0\u5206\u914d\u8fdb\u884c\u534f\u8c03\u3002", "result": "\u5728\u4e24\u4e2a\u591a\u4ee3\u7406\u6e38\u620f\u548c\u4e00\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u6a21\u62df\u4e2d\u8bc4\u4f30\u4e86Shapley-Coop\uff0c\u8bc1\u660e\u4e86\u5176\u80fd\u591f\u6301\u7eed\u589e\u5f3aLLM\u4ee3\u7406\u534f\u4f5c\u5e76\u4fc3\u8fdb\u516c\u5e73\u7684\u4fe1\u7528\u5206\u914d\u3002", "conclusion": "Shapley-Coop\u7684\u5b9a\u4ef7\u673a\u5236\u5728\u4efb\u52a1\u6267\u884c\u8fc7\u7a0b\u4e2d\u6709\u6548\u53cd\u6620\u4e86\u4e2a\u4f53\u8d21\u732e\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06331", "pdf": "https://arxiv.org/pdf/2506.06331", "abs": "https://arxiv.org/abs/2506.06331", "authors": ["Qiming Zeng", "Xiao Yan", "Hao Luo", "Yuhao Lin", "Yuxiang Wang", "Fangcheng Fu", "Bo Du", "Quanqing Xu", "Jiawei Jiang"], "title": "How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "By retrieving contexts from knowledge graphs, graph-based retrieval-augmented\ngeneration (GraphRAG) enhances large language models (LLMs) to generate quality\nanswers for user questions. Many GraphRAG methods have been proposed and\nreported inspiring performance in answer quality. However, we observe that the\ncurrent answer evaluation framework for GraphRAG has two critical flaws, i.e.,\nunrelated questions and evaluation biases, which may lead to biased or even\nwrong conclusions on performance. To tackle the two flaws, we propose an\nunbiased evaluation framework that uses graph-text-grounded question generation\nto produce questions that are more related to the underlying dataset and an\nunbiased evaluation procedure to eliminate the biases in LLM-based answer\nassessment. We apply our unbiased framework to evaluate 3 representative\nGraphRAG methods and find that their performance gains are much more moderate\nthan reported previously. Although our evaluation framework may still have\nflaws, it calls for scientific evaluations to lay solid foundations for\nGraphRAG research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u504f\u89c1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30GraphRAG\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684GraphRAG\u7b54\u6848\u8bc4\u4f30\u6846\u67b6\u5b58\u5728\u4e0e\u95ee\u9898\u65e0\u5173\u548c\u8bc4\u4f30\u504f\u89c1\u4e24\u4e2a\u5173\u952e\u7f3a\u9677\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bf9\u6027\u80fd\u7684\u504f\u89c1\u6216\u9519\u8bef\u7684\u7ed3\u8bba\u3002", "method": "\u901a\u8fc7\u56fe-\u6587\u672c\u57fa\u7840\u7684\u95ee\u9898\u751f\u6210\u6765\u521b\u5efa\u4e0e\u6570\u636e\u96c6\u66f4\u76f8\u5173\u7684\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u65e0\u504f\u89c1\u7684\u8bc4\u4f30\u8fc7\u7a0b\u6765\u6d88\u9664\u57fa\u4e8eLLM\u7684\u7b54\u6848\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\u3002", "result": "\u901a\u8fc7\u5e94\u7528\u65e0\u504f\u89c1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u4e09\u79cd\u4ee3\u8868\u6027GraphRAG\u65b9\u6cd5\u7684\u6027\u80fd\u63d0\u5347\u6bd4\u4e4b\u524d\u62a5\u9053\u7684\u8981\u6e29\u548c\u5f97\u591a\u3002", "conclusion": "\u63d0\u51fa\u4e00\u79cd\u65e0\u504f\u89c1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u91cd\u65b0\u8bc4\u4f30\u4e86\u4e09\u79cdGraphRAG\u65b9\u6cd5\uff0c\u53d1\u73b0\u5176\u6027\u80fd\u63d0\u5347\u8f83\u4e3a\u6e29\u548c\u3002"}}
{"id": "2506.06791", "pdf": "https://arxiv.org/pdf/2506.06791", "abs": "https://arxiv.org/abs/2506.06791", "authors": ["Zheng Wang", "Wenchang Qi", "Jinjie Zhu", "Xianbin Liu"], "title": "How do higher-order interactions shape the energy landscape?", "categories": ["nlin.AO"], "comment": null, "summary": "Understanding how higher-order interactions shape the energy landscape of\ncoupled oscillator networks is crucial for characterizing complex\nsynchronization phenomena. Here, we investigate a generalized Kuramoto model\nwith triadic interactions, combining deterministic basin analysis,\nnoise-induced transitions, and quantum annealing methods. We uncover a dual\neffect of higher-order interactions: they simultaneously expand basins for\nnon-twisted states while contracting those of twisted states, yet modify\npotential well depths for both. As triadic coupling strengthens,\nhigher-winding-number states and non-twisted states gain stability relative to\nsynchronized states. The system exhibits remarkable stability asymmetry, where\nstates with small basins can possess deep potential wells, making them highly\nresistant to noise-induced transitions once formed. These findings extend\nquasipotential theory to high-dimensional networked systems and offer new\ninsights for controlling synchronization in complex systems.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u6269\u5c55\u6216\u6536\u7f29\u8026\u5408\u632f\u8361\u5668\u7f51\u7edc\u4e0d\u540c\u72b6\u6001\u7684\u76c6\u5730\uff0c\u5e76\u63d0\u9ad8\u67d0\u4e9b\u72b6\u6001\u7684\u7a33\u5b9a\u6027\uff0c\u4e3a\u590d\u6742\u7cfb\u7edf\u540c\u6b65\u63a7\u5236\u63d0\u4f9b\u65b0\u89c1\u89e3\u3002", "motivation": "\u4e86\u89e3\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u5982\u4f55\u5851\u9020\u8026\u5408\u632f\u8361\u5668\u7f51\u7edc\u7684\u80fd\u91cf\u666f\u89c2\uff0c\u5bf9\u8868\u5f81\u590d\u6742\u7684\u540c\u6b65\u73b0\u8c61\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5e7f\u4e49\u5e93\u62c9\u83ab\u6258\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u786e\u5b9a\u6027\u76c6\u5730\u5206\u6790\u3001\u566a\u58f0\u8bf1\u5bfc\u7684\u8f6c\u53d8\u53ca\u91cf\u5b50\u9000\u706b\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u5143\u8026\u5408\u65f6\u9ad8\u7ed5\u6570\u6001\u548c\u975e\u626d\u66f2\u6001\u76f8\u5bf9\u4e8e\u540c\u6b65\u6001\u7684\u7a33\u5b9a\u6027\u63d0\u9ad8\uff0c\u5e76\u4e14\u7cfb\u7edf\u53ef\u80fd\u5c55\u793a\u51fa\u6df1\u52bf\u9631\u7684\u7a33\u5b9a\u6027\u4e0d\u5bf9\u79f0\u6027\uff0c\u4f7f\u5176\u6297\u566a\u58f0\u8f6c\u53d8\u80fd\u529b\u589e\u5f3a\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u5bf9\u8026\u5408\u632f\u8361\u5668\u7f51\u7edc\u80fd\u91cf\u666f\u89c2\u7684\u53cc\u91cd\u5f71\u54cd\u3002\u9ad8\u9636\u76f8\u4e92\u4f5c\u7528\u4e00\u65b9\u9762\u6269\u5c55\u4e86\u975e\u626d\u66f2\u6001\u7684\u76c6\u5730\uff0c\u53e6\u4e00\u65b9\u9762\u6536\u7f29\u4e86\u626d\u66f2\u6001\u7684\u76c6\u5730\uff0c\u540c\u65f6\u4e5f\u6539\u53d8\u4e86\u4e24\u8005\u7684\u52bf\u9631\u6df1\u5ea6\u3002\u968f\u7740\u4e09\u5143\u8026\u5408\u7684\u589e\u5f3a\uff0c\u9ad8\u7ed5\u6570\u6001\u548c\u975e\u626d\u66f2\u6001\u76f8\u5bf9\u4e8e\u540c\u6b65\u6001\u7684\u7a33\u5b9a\u6027\u63d0\u9ad8\u3002\u7cfb\u7edf\u8868\u73b0\u51fa\u663e\u8457\u7684\u7a33\u5b9a\u6027\u4e0d\u5bf9\u79f0\u6027\uff0c\u5c0f\u76c6\u5730\u7684\u72b6\u6001\u6709\u6df1\u7684\u52bf\u9631\uff0c\u4f7f\u5176\u4e00\u65e6\u5f62\u6210\u4fbf\u9ad8\u5ea6\u6297\u566a\u58f0\u8bf1\u5bfc\u7684\u72b6\u6001\u8f6c\u53d8\u3002\u8fd9\u4e9b\u53d1\u73b0\u5c06\u51c6\u52bf\u7406\u8bba\u6269\u5c55\u5230\u9ad8\u7ef4\u7f51\u7edc\u7cfb\u7edf\uff0c\u5e76\u4e3a\u63a7\u5236\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u540c\u6b65\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.06290", "pdf": "https://arxiv.org/pdf/2506.06290", "abs": "https://arxiv.org/abs/2506.06290", "authors": ["Mingyu Lu", "Ethan Weinberger", "Chanwoo Kim", "Su-In Lee"], "title": "CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "High-content screening (HCS) assays based on high-throughput microscopy\ntechniques such as Cell Painting have enabled the interrogation of cells'\nmorphological responses to perturbations at an unprecedented scale. The\ncollection of such data promises to facilitate a better understanding of the\nrelationships between different perturbations and their effects on cellular\nstate. Towards achieving this goal, recent advances in cross-modal contrastive\nlearning could, in theory, be leveraged to learn a unified latent space that\naligns perturbations with their corresponding morphological effects. However,\nthe application of such methods to HCS data is not straightforward due to\nsubstantial differences in the semantics of Cell Painting images compared to\nnatural images, and the difficulty of representing different classes of\nperturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent\nspace. In response to these challenges, here we introduce CellCLIP, a\ncross-modal contrastive learning framework for HCS data. CellCLIP leverages\npre-trained image encoders coupled with a novel channel encoding scheme to\nbetter capture relationships between different microscopy channels in image\nembeddings, along with natural language encoders for representing\nperturbations. Our framework outperforms current open-source models,\ndemonstrating the best performance in both cross-modal retrieval and\nbiologically meaningful downstream tasks while also achieving significant\nreductions in computation time.", "AI": {"tldr": "\u5f15\u5165CellCLIP\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u6539\u8fdb\u9ad8\u5185\u6db5\u7b5b\u9009\u6570\u636e\u7684\u89e3\u6790\uff0c\u4f18\u4e8e\u76ee\u524d\u7684\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u4e0d\u540c\u5e72\u6270\u4e4b\u95f4\u7684\u5173\u7cfb\u53ca\u5176\u5bf9\u7ec6\u80de\u72b6\u6001\u7684\u5f71\u54cd\uff0c\u7ed3\u5408\u73b0\u6709\u7684\u9ad8\u5185\u6db5\u7b5b\u9009\u6570\u636e\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u6765\u5b66\u4e60\u7edf\u4e00\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f7f\u5f97\u5e72\u6270\u53ca\u5176\u5bf9\u5e94\u7684\u5f62\u6001\u6548\u5e94\u80fd\u591f\u5bf9\u9f50\u3002", "method": "\u5f15\u5165\u4e86CellCLIP\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e\u9ad8\u5185\u6db5\u7b5b\u9009\u6570\u636e\u7684\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u3002\u5b83\u5229\u7528\u9884\u8bad\u7ec3\u7684\u56fe\u50cf\u7f16\u7801\u5668\u548c\u65b0\u9896\u7684\u901a\u9053\u7f16\u7801\u65b9\u6848\u6765\u66f4\u597d\u5730\u6355\u6349\u4e0d\u540c\u663e\u5fae\u955c\u901a\u9053\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u540c\u65f6\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u7f16\u7801\u5668\u6765\u8868\u793a\u5e72\u6270\u3002", "result": "CellCLIP\u6846\u67b6\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "CellCLIP\u6846\u67b6\u4f18\u4e8e\u5f53\u524d\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u53ca\u751f\u7269\u5b66\u6709\u610f\u4e49\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u597d\uff0c\u540c\u65f6\u5927\u5927\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002"}}
{"id": "2506.06282", "pdf": "https://arxiv.org/pdf/2506.06282", "abs": "https://arxiv.org/abs/2506.06282", "authors": ["Shuangyan Deng", "Haizhou Peng", "Jiachen Xu", "Chunhou Liu", "Ciprian Doru Giurcuaneanu", "Jiamou Liu"], "title": "Understanding Financial Reasoning in AI: A Multimodal Benchmark and Error Learning Approach", "categories": ["cs.AI"], "comment": null, "summary": "Effective financial reasoning demands not only textual understanding but also\nthe ability to interpret complex visual data such as charts, tables, and trend\ngraphs. This paper introduces a new benchmark designed to evaluate how well AI\nmodels - especially large language and multimodal models - reason in\nfinance-specific contexts. Covering 3,200 expert-level question-answer pairs\nacross 15 core financial topics, the benchmark integrates both textual and\nvisual modalities to reflect authentic analytical challenges in finance. To\naddress limitations in current reasoning approaches, we propose an error-aware\nlearning framework that leverages historical model mistakes and feedback to\nguide inference, without requiring fine-tuning. Our experiments across\nstate-of-the-art models show that multimodal inputs significantly enhance\nperformance and that incorporating error feedback leads to consistent and\nmeasurable improvements. The results highlight persistent challenges in visual\nunderstanding and mathematical logic, while also demonstrating the promise of\nself-reflective reasoning in financial AI systems. Our code and data can be\nfound at https://anonymous/FinMR/CodeData.", "AI": {"tldr": "\u5f15\u5165\u4e86\u8bc4\u4f30AI\u5728\u91d1\u878d\u80cc\u666f\u4e0b\u63a8\u7406\u80fd\u529b\u7684\u65b0\u57fa\u51c6\uff0c\u63d0\u51fa\u4e86\u65e0\u9700\u5fae\u8c03\u7684\u9519\u8bef\u611f\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u89c6\u89c9\u7406\u89e3\u548c\u6570\u5b66\u903b\u8f91\u4ecd\u5177\u6311\u6218\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5728\u91d1\u878d\u7279\u5b9a\u80cc\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u7406\u89e3\u6587\u672c\u548c\u89e3\u91ca\u590d\u6742\u89c6\u89c9\u6570\u636e\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9519\u8bef\u611f\u77e5\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5229\u7528\u6a21\u578b\u7684\u5386\u53f2\u9519\u8bef\u548c\u53cd\u9988\u6307\u5bfc\u63a8\u7406\uff0c\u800c\u65e0\u9700\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u591a\u6a21\u6001\u8f93\u5165\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u4e14\u52a0\u5165\u9519\u8bef\u53cd\u9988\u53ef\u6301\u7eed\u6539\u8fdb\u6548\u679c\u3002\u5c55\u793a\u4e86\u91d1\u878dAI\u7cfb\u7edf\u4e2d\u81ea\u6211\u53cd\u601d\u63a8\u7406\u7684\u6f5c\u529b\u3002", "conclusion": "\u591a\u6a21\u6001\u8f93\u5165\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8868\u73b0\uff0c\u800c\u878d\u5165\u9519\u8bef\u53cd\u9988\u5219\u5e26\u6765\u4e86\u6301\u7eed\u4e14\u53ef\u6d4b\u91cf\u7684\u6539\u8fdb\u3002\u7136\u800c\uff0c\u5728\u89c6\u89c9\u7406\u89e3\u548c\u6570\u5b66\u903b\u8f91\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2506.07398", "pdf": "https://arxiv.org/pdf/2506.07398", "abs": "https://arxiv.org/abs/2506.07398", "authors": ["Guibin Zhang", "Muxin Fu", "Guancheng Wan", "Miao Yu", "Kun Wang", "Shuicheng Yan"], "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "categories": ["cs.MA", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language model (LLM)-powered multi-agent systems (MAS) have\ndemonstrated cognitive and execution capabilities that far exceed those of\nsingle LLM agents, yet their capacity for self-evolution remains hampered by\nunderdeveloped memory architectures. Upon close inspection, we are alarmed to\ndiscover that prevailing MAS memory mechanisms (1) are overly simplistic,\ncompletely disregarding the nuanced inter-agent collaboration trajectories, and\n(2) lack cross-trial and agent-specific customization, in stark contrast to the\nexpressive memory developed for single agents. To bridge this gap, we introduce\nG-Memory, a hierarchical, agentic memory system for MAS inspired by\norganizational memory theory, which manages the lengthy MAS interaction via a\nthree-tier graph hierarchy: insight, query, and interaction graphs. Upon\nreceiving a new user query, G-Memory performs bi-directional memory traversal\nto retrieve both $\\textit{high-level, generalizable insights}$ that enable the\nsystem to leverage cross-trial knowledge, and $\\textit{fine-grained, condensed\ninteraction trajectories}$ that compactly encode prior collaboration\nexperiences. Upon task execution, the entire hierarchy evolves by assimilating\nnew collaborative trajectories, nurturing the progressive evolution of agent\nteams. Extensive experiments across five benchmarks, three LLM backbones, and\nthree popular MAS frameworks demonstrate that G-Memory improves success rates\nin embodied action and accuracy in knowledge QA by up to $20.89\\%$ and\n$10.12\\%$, respectively, without any modifications to the original frameworks.\nOur codes are available at https://github.com/bingreeky/GMemory.", "AI": {"tldr": "\u5f15\u5165G-Memory\u5185\u5b58\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u8bb0\u5fc6\u7ed3\u6784\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8868\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u6210\u529f\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5185\u5b58\u673a\u5236\u8fc7\u4e8e\u7b80\u5355\uff0c\u5ffd\u89c6\u4e86\u4ee3\u7406\u4e4b\u95f4\u5408\u4f5c\u7684\u590d\u6742\u8f68\u8ff9\uff0c\u5e76\u7f3a\u4e4f\u4e2a\u6027\u5316\u5b9a\u5236\uff0c\u4e0e\u5355\u4e00\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u76f8\u6bd4\u76f8\u5dee\u751a\u8fdc\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aG-Memory\u7684\u5c42\u6b21\u5316\u667a\u80fd\u4f53\u5185\u5b58\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u501f\u9274\u4e86\u7ec4\u7ec7\u8bb0\u5fc6\u7406\u8bba\uff0c\u901a\u8fc7\u4e09\u5c42\u56fe\u5c42\u6b21\u7ed3\u6784\u6765\u7ba1\u7406\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4ea4\u4e92\u3002", "result": "G-Memory\u5728\u4e94\u4e2a\u57fa\u51c6\u3001\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u79cd\u6d41\u884c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u6210\u529f\u7387\u6700\u9ad8\u63d0\u534720.89%\uff0c\u77e5\u8bc6\u95ee\u7b54\u51c6\u786e\u6027\u63d0\u534710.12%\u3002", "conclusion": "G-Memory\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5177\u4f53\u73b0\u5b9e\u884c\u4e3a\u548c\u77e5\u8bc6\u95ee\u7b54\u4e0a\u7684\u6210\u529f\u7387\u548c\u51c6\u786e\u6027\uff0c\u800c\u65e0\u9700\u66f4\u6539\u539f\u6709\u6846\u67b6\u3002"}}
{"id": "2506.06343", "pdf": "https://arxiv.org/pdf/2506.06343", "abs": "https://arxiv.org/abs/2506.06343", "authors": ["Taesoo Kim", "Jong Hwan Ko"], "title": "TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "Recent advances in speech-enabled language models have shown promising\nresults in building intelligent voice assistants. However, most existing\napproaches rely on large-scale paired speech-text data and extensive\ncomputational resources, which pose challenges in terms of scalability and\naccessibility. In this paper, we present \\textbf{TESU-LLM}, a novel framework\nthat enables training speech-capable language models using only text data. Our\nkey insight is to leverage a unified encoder that maps semantically equivalent\ntext and speech inputs to a shared latent space. By aligning the encoder output\nwith the embedding space of a LLM via a lightweight projection network, we\nenable the model to generalize from text-only supervision to speech-based\ninference. Despite being trained exclusively on text, TESU-LLM achieves strong\nperformance on various speech-related benchmarks, comparable to baseline\nmethods trained with large-scale multimodal datasets and substantial\ncomputational resources. These results highlight the effectiveness and\nefficiency of our approach, offering a scalable path toward building speech\nLLMs without speech data.", "AI": {"tldr": "TESU-LLM\u662f\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u6587\u672c\u6570\u636e\u8bad\u7ec3\u8bed\u97f3\u529f\u80fd\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u8bed\u97f3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u4e8e\u5927\u89c4\u6a21\u914d\u5bf9\u7684\u8bed\u97f3\u6587\u672c\u6570\u636e\u548c\u5e7f\u6cdb\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u8fd9\u5728\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6TESU-LLM\uff0c\u901a\u8fc7\u4e00\u4e2a\u7edf\u4e00\u7684\u7f16\u7801\u5668\u5c06\u8bed\u4e49\u7b49\u4ef7\u7684\u6587\u672c\u548c\u8bed\u97f3\u8f93\u5165\u6620\u5c04\u5230\u5171\u4eab\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6295\u5f71\u7f51\u7edc\u5c06\u7f16\u7801\u5668\u8f93\u51fa\u4e0eLLM\u7684\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u3002", "result": "TESU-LLM\u5373\u4f7f\u4ec5\u63a5\u53d7\u8fc7\u6587\u672c\u8bad\u7ec3\uff0c\u4e5f\u5728\u591a\u4e2a\u8bed\u97f3\u76f8\u5173\u57fa\u51c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4e0e\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u8bad\u7ec3\u7684\u65b9\u6cd5\u76f8\u6bd4\u4e0d\u900a\u8272\u3002", "conclusion": "TESU-LLM\u80fd\u591f\u5728\u4ec5\u4f7f\u7528\u6587\u672c\u6570\u636e\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u4f9d\u7136\u5728\u591a\u79cd\u8bed\u97f3\u76f8\u5173\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u4f7f\u7528\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u8bad\u7ec3\u7684\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2506.06897", "pdf": "https://arxiv.org/pdf/2506.06897", "abs": "https://arxiv.org/abs/2506.06897", "authors": ["Mahault Albarracin", "Dalton A R Sakthivadivel"], "title": "Resilience and adaptability in self-evidencing systems", "categories": ["nlin.AO", "cond-mat.stat-mech"], "comment": "12+2 pages, one figure. Submitted to the Sixth International Workshop\n  on Active Inference", "summary": "In this paper we will articulate a view of resilience under the free energy\nprinciple and vice versa. The free energy principle is about existence and\nidentity, and resilience is the condition under which things exist at all. In\nprevious work this has been investigated as modelling resilience using the free\nenergy principle. We will extend that work by making the case that\nself-organisation under the free energy principle is about resilience, in the\nsense that identity is a constant process of self-reconfiguration, implying the\nexistence of a self-model and the energy to reconfigure that self-model -- and\nhence, the resilience of a maintained identity under changes. A general\nframework for thinking about resilience in this context will be sketched out\nand some models will be provided using that framework.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u97e7\u6027\u548c\u81ea\u7531\u80fd\u539f\u5219\u7684\u5173\u7cfb\uff0c\u901a\u8fc7\u81ea\u7ec4\u7ec7\u8fc7\u7a0b\u7684\u89d2\u5ea6\u6765\u7406\u89e3\u8eab\u4efd\u7684\u7ef4\u62a4\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u97e7\u6027\u7684\u601d\u8003\u6846\u67b6\u5e76\u63d0\u4f9b\u76f8\u5e94\u6a21\u578b\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u97e7\u6027\u4e0e\u81ea\u7531\u80fd\u539f\u5219\u4e4b\u95f4\u7684\u5173\u7cfb\u4ee5\u53ca\u81ea\u7ec4\u7ec7\u5bf9\u4e8e\u4fdd\u6301\u8eab\u4efd\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u81ea\u7531\u80fd\u539f\u5219\u5efa\u6a21\u97e7\u6027\uff0c\u5e76\u6269\u5c55\u4e3a\u81ea\u7ec4\u7ec7\u8fc7\u7a0b\u6d89\u53ca\u8eab\u4efd\u81ea\u6211\u91cd\u65b0\u914d\u7f6e\u7684\u6846\u67b6\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u5728\u81ea\u7531\u80fd\u539f\u5219\u4e0b\u601d\u8003\u97e7\u6027\u7684\u6846\u67b6\uff0c\u5e76\u7528\u6a21\u578b\u6765\u5c55\u793a\u548c\u9a8c\u8bc1\u8fd9\u4e00\u6846\u67b6\u7684\u5e94\u7528\u3002", "conclusion": "\u6587\u7ae0\u5f97\u51fa\u7ed3\u8bba\uff0c\u81ea\u7ec4\u7ec7\u5728\u81ea\u7531\u80fd\u539f\u5219\u4e0b\u4e0e\u97e7\u6027\u76f8\u5173\uff0c\u8868\u660e\u81ea\u6211\u8eab\u4efd\u7684\u6301\u7eed\u5b58\u5728\u6d89\u53ca\u81ea\u6211\u91cd\u65b0\u914d\u7f6e\u7684\u80fd\u91cf\u548c\u8fc7\u7a0b\u3002"}}
{"id": "2506.06291", "pdf": "https://arxiv.org/pdf/2506.06291", "abs": "https://arxiv.org/abs/2506.06291", "authors": ["Xiaoke Wang", "Batuhan Altundas", "Zhaoxin Li", "Aaron Zhao", "Matthew Gombolay"], "title": "Improvement of Optimization using Learning Based Models in Mixed Integer Linear Programming Tasks", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "4 pages, 4 figures", "summary": "Mixed Integer Linear Programs (MILPs) are essential tools for solving\nplanning and scheduling problems across critical industries such as\nconstruction, manufacturing, and logistics. However, their widespread adoption\nis limited by long computational times, especially in large-scale, real-time\nscenarios. To address this, we present a learning-based framework that\nleverages Behavior Cloning (BC) and Reinforcement Learning (RL) to train Graph\nNeural Networks (GNNs), producing high-quality initial solutions for\nwarm-starting MILP solvers in Multi-Agent Task Allocation and Scheduling\nProblems. Experimental results demonstrate that our method reduces optimization\ntime and variance compared to traditional techniques while maintaining solution\nquality and feasibility.", "AI": {"tldr": "A learning-based framework using GNNs, BC, and RL reduces MILP computation times in real-time tasks, maintaining solution quality.", "motivation": "Mixed Integer Linear Programs (MILPs) are widely used in industries such as construction, manufacturing, and logistics for planning and scheduling, but they suffer from long computational times in large-scale, real-time scenarios.", "method": "The paper presents a learning-based framework that uses Behavior Cloning and Reinforcement Learning to train Graph Neural Networks, which generate high-quality initial solutions for warm-starting MILP solvers in Multi-Agent Task Allocation and Scheduling Problems.", "result": "Experimental results show that the proposed method reduces optimization time and variance compared to traditional techniques, while maintaining solution quality and feasibility.", "conclusion": "The proposed learning-based framework effectively reduces computational time for MILPs without sacrificing solution quality, making it viable for real-time applications in critical industries."}}
{"id": "2506.06284", "pdf": "https://arxiv.org/pdf/2506.06284", "abs": "https://arxiv.org/abs/2506.06284", "authors": ["John Beverley", "Jim Logan"], "title": "Unreal Patterns", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces a framework for representing information about entities\nthat do not exist or may never exist, such as those involving fictional\nentities, blueprints, simulations, and future scenarios. Traditional approaches\nthat introduce \"dummy instances\" or rely on modal logic are criticized, and a\nproposal is defended in which such cases are modeled using the intersections of\nactual types rather than specific non existent tokens. The paper positions\nitself within the Basic Formal Ontology and its realist commitments,\nemphasizing the importance of practical, implementable solutions over purely\nmetaphysical or philosophical proposals, arguing that existing approaches to\nnon existent entities either overcommit to metaphysical assumptions or\nintroduce computational inefficiencies that hinder applications. By developing\na structured ontology driven approach to unreal patterns, the paper aims to\nprovide a useful and computationally viable means of handling references to\nhypothetical or non existent entities.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u901a\u8fc7\u5b9e\u9645\u7c7b\u578b\u4ea4\u96c6\u800c\u975e\u865a\u6784\u9879\u6765\u5904\u7406\u4e0d\u5b58\u5728\u5b9e\u4f53\u7684\u4fe1\u606f\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u5728\u65e2\u5b9a\u672c\u4f53\u8bba\u627f\u8bfa\u4e0b\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\u548c\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u95ee\u9898\uff1a\u8981\u4e48\u8fc7\u5ea6\u627f\u8bfa\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\uff0c\u8981\u4e48\u5bfc\u81f4\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63d0\u51fa\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u5b9e\u65bd\u7684\u5904\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u672c\u4f53\u8bba\u9a71\u52a8\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u5b9e\u9645\u7c7b\u578b\u7684\u4ea4\u96c6\u6765\u5904\u7406\u4e0d\u771f\u5b9e\u6a21\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u5b9e\u65bd\u7684\u672c\u4f53\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5904\u7406\u4e0d\u771f\u5b9e\u6a21\u5f0f\uff0c\u4e3a\u5904\u7406\u5047\u8bbe\u6216\u4e0d\u5b58\u5728\u5b9e\u4f53\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u8ba1\u7b97\u53ef\u884c\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ea4\u96c6\u800c\u975e\u7279\u5b9a\u4e0d\u5b58\u5728\u9879\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u4ee5\u5904\u7406\u6709\u5173\u865a\u6784\u5b9e\u4f53\u3001\u84dd\u56fe\u3001\u6a21\u62df\u548c\u672a\u6765\u573a\u666f\u7684\u4fe1\u606f\u3002\u6b64\u6846\u67b6\u53ef\u4ee5\u5728\u73b0\u6709\u771f\u5b9e\u4e3b\u4e49\u627f\u8bfa\u4e0b\u63d0\u4f9b\u5207\u5b9e\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u907f\u514d\u8fc7\u5ea6\u4f9d\u8d56\u5f62\u800c\u4e0a\u5b66\u5047\u8bbe\uff0c\u540c\u65f6\u89e3\u51b3\u8ba1\u7b97\u6548\u7387\u95ee\u9898\u3002"}}
{"id": "2506.07400", "pdf": "https://arxiv.org/pdf/2506.07400", "abs": "https://arxiv.org/abs/2506.07400", "authors": ["Philip Liu", "Sparsh Bansal", "Jimmy Dinh", "Aditya Pawar", "Ramani Satishkumar", "Shail Desai", "Neeraj Gupta", "Xin Wang", "Shu Hu"], "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "comment": "7 pages, 6 figures. Accepted to the 2025 IEEE 8th International\n  Conference on Multimedia Information Processing and Retrieval (MIPR). Code\n  and platform available at https://github.com/Purdue-M2/MedChat", "summary": "The integration of deep learning-based glaucoma detection with large language\nmodels (LLMs) presents an automated strategy to mitigate ophthalmologist\nshortages and improve clinical reporting efficiency. However, applying general\nLLMs to medical imaging remains challenging due to hallucinations, limited\ninterpretability, and insufficient domain-specific medical knowledge, which can\npotentially reduce clinical accuracy. Although recent approaches combining\nimaging models with LLM reasoning have improved reporting, they typically rely\non a single generalist agent, restricting their capacity to emulate the diverse\nand complex reasoning found in multidisciplinary medical teams. To address\nthese limitations, we propose MedChat, a multi-agent diagnostic framework and\nplatform that combines specialized vision models with multiple role-specific\nLLM agents, all coordinated by a director agent. This design enhances\nreliability, reduces hallucination risk, and enables interactive diagnostic\nreporting through an interface tailored for clinical review and educational\nuse. Code available at https://github.com/Purdue-M2/MedChat.", "AI": {"tldr": "MedChat enhances medical imaging diagnostics by using multiple specialized agents to improve reliability and interaction, overcoming limitations of general LLMs in medical contexts.", "motivation": "To address the limitations of applying general LLMs to medical imaging, such as hallucinations, lack of interpretability, and insufficient domain-specific knowledge, and to improve the emulation of multidisciplinary medical team reasoning.", "method": "MedChat employs a multi-agent diagnostic framework where specialized vision models are combined with multiple role-specific LLM agents, coordinated by a director agent, to enhance interaction and reliability in clinical use.", "result": "The use of MedChat reduces the risk of hallucinations, improves reliability, and allows for interactive diagnostic reporting suitable for clinical review and education.", "conclusion": "MedChat offers a more reliable and interactive diagnostic reporting platform by using a multi-agent approach combining specialized vision models and role-specific LLM agents, addressing the limitations of using single generalist agents in medical imaging."}}
{"id": "2506.06347", "pdf": "https://arxiv.org/pdf/2506.06347", "abs": "https://arxiv.org/abs/2506.06347", "authors": ["Zachary Yang", "Domenico Tullo", "Reihaneh Rabbany"], "title": "Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for Resource-Efficient Toxicity Detection", "categories": ["cs.CL", "cs.AI", "I.2.7; J.4"], "comment": "11 pages, 1 figure, 9 Tables, KDD 2025 ADS Track", "summary": "Toxicity detection in gaming communities faces significant scaling challenges\nwhen expanding across multiple games and languages, particularly in real-time\nenvironments where computational efficiency is crucial. We present two key\nfindings to address these challenges while building upon our previous work on\nToxBuster, a BERT-based real-time toxicity detection system. First, we\nintroduce a soft-prompting approach that enables a single model to effectively\nhandle multiple games by incorporating game-context tokens, matching the\nperformance of more complex methods like curriculum learning while offering\nsuperior scalability. Second, we develop an LLM-assisted label transfer\nframework using GPT-4o-mini to extend support to seven additional languages.\nEvaluations on real game chat data across French, German, Portuguese, and\nRussian achieve macro F1-scores ranging from 32.96% to 58.88%, with\nparticularly strong performance in German, surpassing the English benchmark of\n45.39%. In production, this unified approach significantly reduces\ncomputational resources and maintenance overhead compared to maintaining\nseparate models for each game and language combination. At Ubisoft, this model\nsuccessfully identifies an average of 50 players, per game, per day engaging in\nsanctionable behavior.", "AI": {"tldr": "\u901a\u8fc7\u8f6f\u63d0\u793a\u548cLLM\u52a9\u624b\u6807\u7b7e\u8f6c\u79fb\u65b9\u6cd5\u63d0\u5347\u4e0d\u540c\u8bed\u8a00\u4e0b\u6e38\u620f\u6bd2\u6027\u68c0\u6d4b\u7684\u6548\u7387\u548c\u6269\u5c55\u80fd\u529b\u3002", "motivation": "\u5728\u6e38\u620f\u793e\u533a\u4e2d\uff0c\u56e0\u4e3a\u8981\u652f\u6301\u591a\u4e2a\u6e38\u620f\u548c\u8bed\u8a00\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u65f6\u73af\u5883\u4e2d\uff0c\u6bd2\u6027\u68c0\u6d4b\u9762\u4e34\u663e\u8457\u7684\u89c4\u6a21\u5316\u6311\u6218\uff0c\u9700\u8981\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u5f15\u5165\u8f6f\u63d0\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u6e38\u620f\u73af\u5883\u6807\u8bb0\u4f7f\u5355\u4e00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u591a\u6e38\u620f\u3002\u540c\u65f6\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f7f\u7528GPT-4o-mini\u7684LLM\u8f85\u52a9\u6807\u7b7e\u4f20\u9012\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u66f4\u591a\u8bed\u8a00\u3002", "result": "\u5728\u6cd5\u8bed\u3001\u5fb7\u8bed\u3001\u8461\u8404\u7259\u8bed\u548c\u4fc4\u8bed\u7684\u6e38\u620f\u804a\u5929\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b8f\u5e73\u5747F1\u5206\u6570\u4ece32.96%\u523058.88%\u4e0d\u7b49\uff0c\u5e76\u8d85\u8fc7\u4e86\u82f1\u8bed\u57fa\u51c6\u768445.39%\u3002", "conclusion": "\u7edf\u4e00\u7684\u65b9\u6cd5\u5728\u751f\u4ea7\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u548c\u7ef4\u62a4\u8d1f\u62c5\uff0c\u6bcf\u5929\u5e73\u5747\u6bcf\u4e2a\u6e38\u620f\u53d1\u73b050\u540d\u884c\u4e3a\u8fdd\u89c4\u7684\u73a9\u5bb6\u3002"}}
{"id": "2506.06292", "pdf": "https://arxiv.org/pdf/2506.06292", "abs": "https://arxiv.org/abs/2506.06292", "authors": ["Tianyuan Shi", "Canbin Huang", "Fanqi Wan", "Longguang Zhong", "Ziyi Yang", "Weizhou Shen", "Xiaojun Quan", "Ming Yan"], "title": "Mutual-Taught for Co-adapting Policy and Reward Models", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ACL 2025 (Main Conference)", "summary": "During the preference optimization of large language models (LLMs),\ndistribution shifts may arise between newly generated model samples and the\ndata used to train the reward model (RM). This shift reduces the efficacy of\nthe RM, which in turn negatively impacts the performance of the policy model\n(PM). To address this challenge, we propose Mutual-Taught, a self-training\nmethod that iteratively improves both the PM and RM without requiring\nadditional human annotation. Our approach mirrors the expectation-maximization\n(EM) algorithm. In the E-step, the PM is updated using feedback from the\ncurrent RM, guiding the PM toward a better approximation of the latent optimal\npreference distribution. In the M-step, we update the RM by constructing\ntraining data from the outputs of the PM before and after the E-step update.\nThis process ensures that the RM adapts to the evolving policy distribution.\nExperimental results demonstrate that this iterative approach leads to\nconsistent improvements in both models. Specifically, our 8B policy model,\nLLaMA-3-8B-Instruct-MT, achieves a length-controlled win rate of 54.1\\% on\nAlpacaEval-2, while our 8B reward model, FsfairX-LLaMA3-RM-MT, performs on par\nwith GPT-4o-2024-08-06 on RewardBench.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u8bad\u7ec3\u65b9\u6cd5Mutual-Taught\uff0c\u901a\u8fc7\u6a21\u62dfEM\u7b97\u6cd5\u8fed\u4ee3\u4f18\u5316\u653f\u7b56\u6a21\u578b\u548c\u5956\u52b1\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u4eba\u5de5\u6807\u6ce8\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u504f\u597d\u4f18\u5316\u4e2d\u4ea7\u751f\u7684\u5206\u5e03\u53d8\u5316\u964d\u4f4e\u4e86\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u7684\u6709\u6548\u6027\uff0c\u53cd\u8fc7\u6765\u5f71\u54cd\u4e86\u653f\u7b56\u6a21\u578b\uff08PM\uff09\u7684\u6027\u80fd\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u5347PM\uff0c\u53c8\u80fd\u9002\u5e94\u5206\u5e03\u53d8\u5316\u7684RM\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86Mutual-Taught\u81ea\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u62df\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u7b97\u6cd5\uff0c\u4ece\u800c\u5728E\u6b65\u4e2d\u4f7f\u7528\u5f53\u524d\u7684RM\u53cd\u9988\u66f4\u65b0PM\uff0c\u5e76\u5728M\u6b65\u4e2d\u901a\u8fc7PM\u7684\u8f93\u51fa\u6784\u5efa\u8bad\u7ec3\u6570\u636e\u6765\u66f4\u65b0RM\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u63d0\u51fa\u7684\u65b9\u6cd5\u4f7f\u5f978B\u653f\u7b56\u6a21\u578bLLaMA-3-8B-Instruct-MT\u5728AlpacaEval-2\u4e0a\u8fbe\u523054.1%\u7684\u957f\u5ea6\u63a7\u5236\u80dc\u7387\uff0c\u800c8B\u5956\u52b1\u6a21\u578bFsfairX-LLaMA3-RM-MT\u5728RewardBench\u4e0a\u7684\u8868\u73b0\u53ef\u4e0eGPT-4o-2024-08-06\u5ab2\u7f8e\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684Mutual-Taught\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u989d\u5916\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u8fed\u4ee3\u63d0\u5347\u653f\u7b56\u6a21\u578b\uff08PM\uff09\u548c\u5956\u52b1\u6a21\u578b\uff08RM\uff09\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u8fed\u4ee3\u65b9\u6cd5\u80fd\u591f\u4e3a\u4e24\u4e2a\u6a21\u578b\u5e26\u6765\u6301\u7eed\u7684\u6539\u8fdb\u3002"}}
{"id": "2506.06285", "pdf": "https://arxiv.org/pdf/2506.06285", "abs": "https://arxiv.org/abs/2506.06285", "authors": ["Kaike Sa Teles Rocha Alves", "Eduardo Pestana de Aguiar"], "title": "NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting", "categories": ["cs.AI"], "comment": null, "summary": "Evolving Fuzzy Systems (eFS) have gained significant attention due to their\nability to adaptively update their structure in response to data dynamics while\nmaintaining interpretability. However, the lack of publicly available\nimplementations of these models limits their accessibility and widespread\nadoption. To address this gap, we present evolvingfuzzysystems, a Python\nlibrary that provides implementations of several well-established eFS models,\nincluding ePL-KRLS-DISCO, ePL+, eMG, ePL, exTS, Simpl\\_eTS, and eTS. The\nlibrary facilitates model evaluation and comparison by offering built-in tools\nfor training, visualization, and performance assessment. The models are\nevaluated using the fetch\\_california\\_housing dataset, with performance\nmeasured in terms of normalized root-mean-square error (NRMSE), non-dimensional\nerror index (NDEI), and mean absolute percentage error (MAPE). Additionally,\ncomputational complexity is analyzed by measuring execution times and rule\nevolution during training and testing phases. The results highlight ePL as a\nsimple yet efficient model that balances accuracy and computational cost,\nmaking it particularly suitable for real-world applications. By making these\nmodels publicly available, evolvingfuzzysystems aims to foster research and\npractical applications in adaptive and interpretable machine learning.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u6b3ePython\u5e93evolvingfuzzysystems,\u5b83\u63d0\u4f9b\u591a\u4e2a\u6210\u719f\u7684\u53ef\u6f14\u5316\u6a21\u7cca\u7cfb\u7edf\u6a21\u578b\u7684\u5b9e\u73b0,\u5e76\u901a\u8fc7\u52a0\u5dde\u4f4f\u623f\u6570\u636e\u96c6\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u6027\u80fd\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u7f3a\u4e4f\u516c\u5f00\u7684\u53ef\u6f14\u5316\u6a21\u7cca\u7cfb\u7edf\u6a21\u578b\u9650\u5236\u4e86\u5176\u53ef\u8bbf\u95ee\u6027\u548c\u5e7f\u6cdb\u91c7\u7528\u3002", "method": "\u8bc4\u4f30\u6a21\u578b\u5e76\u6bd4\u8f83\u5176\u6027\u80fd\uff0c\u4f7f\u7528\u7684\u8bc4\u4f30\u5de5\u5177\u5305\u62ec\uff1a\u8bad\u7ec3\u3001\u53ef\u89c6\u5316\u548c\u6027\u80fd\u8bc4\u4f30\uff1b\u5e76\u5bf9\u52a0\u5dde\u4f4f\u623f\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bc4\uff0c\u5206\u6790\u6267\u884c\u65f6\u95f4\u548c\u8bad\u7ec3\u6d4b\u8bd5\u9636\u6bb5\u7684\u89c4\u5219\u6f14\u53d8\u3002 ", "result": "\u7ed3\u679c\u663e\u793aePL\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u800c\u9ad8\u6548\u7684\u6a21\u578b,\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5177\u5907\u5e73\u8861\u6027,\u9002\u5408\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u8fd9\u4e9b\u6a21\u578b\u516c\u5f00\u53ef\u7528, evolvingfuzzysystems\u65e8\u5728\u4fc3\u8fdb\u81ea\u9002\u5e94\u548c\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u4e0e\u5b9e\u8df5\u5e94\u7528\u3002"}}
{"id": "2506.07935", "pdf": "https://arxiv.org/pdf/2506.07935", "abs": "https://arxiv.org/abs/2506.07935", "authors": ["Pavel Naumov", "Jia Tao"], "title": "Diffusion of Responsibility in Collective Decision Making", "categories": ["cs.MA", "cs.AI", "cs.GT"], "comment": null, "summary": "The term \"diffusion of responsibility'' refers to situations in which\nmultiple agents share responsibility for an outcome, obscuring individual\naccountability. This paper examines this frequently undesirable phenomenon in\nthe context of collective decision-making mechanisms.\n  The work shows that if a decision is made by two agents, then the only way to\navoid diffusion of responsibility is for one agent to act as a \"dictator'',\nmaking the decision unilaterally. In scenarios with more than two agents, any\ndiffusion-free mechanism is an \"elected dictatorship'' where the agents elect a\nsingle agent to make a unilateral decision.\n  The technical results are obtained by defining a bisimulation of\ndecision-making mechanisms, proving that bisimulation preserves\nresponsibility-related properties, and establishing the results for a smallest\nbisimular mechanism.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u4e3a\u907f\u514d\u8d23\u4efb\u6269\u6563\uff0c\u4e24\u4ee3\u7406\u4e2d\u9700\u6709\u72ec\u88c1\u8005\uff0c\u591a\u4ee3\u7406\u9700\u9009\u4e3e\u72ec\u88c1\u8005\u51b3\u7b56\u3002", "motivation": "\u7814\u7a76\u8d23\u4efb\u6269\u6563\u95ee\u9898\u5bf9\u96c6\u4f53\u51b3\u7b56\u673a\u5236\u4e2d\u7684\u4e2a\u4f53\u8d23\u4efb\u611f\u5230\u6a21\u7cca\u7684\u73b0\u8c61\uff0c\u5c24\u5176\u662f\u5728\u591a\u4e2a\u4ee3\u7406\u5171\u4eab\u8d23\u4efb\u60c5\u51b5\u4e0b\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u51b3\u7b56\u673a\u5236\u7684\u53cc\u4eff\u771f\uff0c\u8bc1\u660e\u53cc\u4eff\u771f\u4fdd\u6301\u4e0e\u8d23\u4efb\u76f8\u5173\u7684\u5c5e\u6027\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u4e3a\u4e00\u4e2a\u6700\u5c0f\u7684\u53cc\u4eff\u771f\u673a\u5236\u5efa\u7acb\u7ed3\u679c\u3002", "result": "\u5728\u4e24\u4e2a\u4ee3\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u907f\u514d\u8d23\u4efb\u6269\u6563\u7684\u65b9\u6cd5\u662f\u8ba9\u4e00\u4e2a\u4ee3\u7406\u6210\u4e3a\u72ec\u88c1\u8005\uff1b\u5728\u591a\u4e2a\u4ee3\u7406\u60c5\u51b5\u4e0b\uff0c\u4efb\u4f55\u907f\u514d\u8d23\u4efb\u6269\u6563\u7684\u673a\u5236\u90fd\u662f\u201c\u9009\u4e3e\u72ec\u88c1\u201d\u673a\u5236\u3002", "conclusion": "\u5728\u591a\u4ee3\u7406\u7684\u51b3\u7b56\u573a\u666f\u4e2d\uff0c\u907f\u514d\u8d23\u4efb\u6269\u6563\u7684\u552f\u4e00\u673a\u5236\u662f\u5728\u4e24\u4e2a\u4ee3\u7406\u7684\u60c5\u51b5\u4e0b\u8ba9\u4e00\u4e2a\u4ee3\u7406\u6210\u4e3a\u72ec\u88c1\u8005\uff0c\u800c\u5728\u591a\u4e2a\u4ee3\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u673a\u5236\u5fc5\u987b\u662f\u901a\u8fc7\u9009\u4e3e\u4ea7\u751f\u4e00\u4e2a\u4ee3\u7406\u6765\u5355\u65b9\u9762\u51b3\u7b56\uff0c\u8fd9\u79f0\u4e3a\u201c\u9009\u4e3e\u72ec\u88c1\u201d\u3002"}}
{"id": "2506.06371", "pdf": "https://arxiv.org/pdf/2506.06371", "abs": "https://arxiv.org/abs/2506.06371", "authors": ["Panagiotis Koletsis", "Christos Panagiotopoulos", "Georgios Th. Papadopoulos", "Vasilis Efthymiou"], "title": "Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Over the past few years, table interpretation tasks have made significant\nprogress due to their importance and the introduction of new technologies and\nbenchmarks in the field. This work experiments with a hybrid approach for\ndetecting relationships among columns of unlabeled tabular data, using a\nKnowledge Graph (KG) as a reference point, a task known as CPA. This approach\nleverages large language models (LLMs) while employing statistical analysis to\nreduce the search space of potential KG relations. The main modules of this\napproach for reducing the search space are domain and range constraints\ndetection, as well as relation co-appearance analysis. The experimental\nevaluation on two benchmark datasets provided by the SemTab challenge assesses\nthe influence of each module and the effectiveness of different\nstate-of-the-art LLMs at various levels of quantization. The experiments were\nperformed, as well as at different prompting techniques. The proposed\nmethodology, which is publicly available on github, proved to be competitive\nwith state-of-the-art approaches on these datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u8868\u683c\u6570\u636e\u5217\u5173\u7cfb\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5177\u7ade\u4e89\u529b\uff0c\u5e76\u516c\u5f00\u63d0\u4f9b\u4ee3\u7801\u3002", "motivation": "\u9274\u4e8e\u8868\u683c\u89e3\u91ca\u4efb\u52a1\u7684\u91cd\u8981\u6027\u53ca\u8be5\u9886\u57df\u4e2d\u65b0\u6280\u672f\u548c\u57fa\u51c6\u7684\u5f15\u5165\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5bf9\u672a\u6807\u8bb0\u8868\u683c\u6570\u636e\u5217\u5173\u7cfb\u68c0\u6d4b\u7684\u80fd\u529b\u3002", "method": "\u6b64\u7814\u7a76\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u4f5c\u4e3a\u53c2\u8003\u70b9\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u91c7\u7528\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\u6765\u68c0\u6d4b\u975e\u6807\u8bb0\u8868\u683c\u6570\u636e\u4e2d\u7684\u5217\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u4e3b\u8981\u6a21\u5757\u5305\u62ec\u57df\u548c\u8303\u56f4\u7ea6\u675f\u68c0\u6d4b\u4ee5\u53ca\u5173\u7cfb\u5171\u540c\u51fa\u73b0\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u4e86SemTab\u6311\u6218\u63d0\u4f9b\u7684\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5404\u4e2a\u6a21\u5757\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u4e0d\u540c\u91cf\u5316\u6c34\u5e73\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728SemTab\u6311\u6218\u63d0\u4f9b\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2506.06293", "pdf": "https://arxiv.org/pdf/2506.06293", "abs": "https://arxiv.org/abs/2506.06293", "authors": ["Junyi Liu", "Stanley Kok"], "title": "Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "WITS 2024 (Workshop on Information Technologies and Systems 2024)", "summary": "Agencies such as Standard & Poor's and Moody's provide bank credit ratings\nthat influence economic stability and decision-making by stakeholders. Accurate\nand timely predictions support informed decision-making, regulatory actions,\nand investor protection. However, a complete interbank connection graph is\noften unavailable due to privacy concerns, complicating the direct application\nof Graph Neural Networks (GNNs) for rating prediction. our research utilizes\npersistent homology to construct a network that captures relationships among\nbanks and combines this with a traditional lending network to create a\nheterogeneous network that integrates information from both sources, leading to\nimproved predictions. Experiments on a global, real-world dataset validate the\neffectiveness of HTGNN. This research has implications for investors and\nregulatory bodies in enhancing proactive risk mitigation and the implementation\nof effective market interventions.The code can be find at\nhttps://github.com/Liu-Jun-Yi/HTGNN.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u6301\u4e45\u540c\u6e90\u6027\u4e0e\u4f20\u7edf\u7f51\u7edc\u6784\u5efa\u5f02\u8d28\u7f51\u7edc\uff0c\u6539\u8fdb\u94f6\u884c\u4fe1\u7528\u8bc4\u7ea7\u3002\u5b9e\u9a8c\u8868\u660e\u65b0\u65b9\u6cd5\u6548\u679c\u4f18\u5f02\u3002", "motivation": "\u5728\u94f6\u884c\u95f4\u8fde\u63a5\u56fe\u4e0d\u5b8c\u6574\u4e14\u4fdd\u5bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u6539\u5584\u94f6\u884c\u4fe1\u7528\u8bc4\u7ea7\u7684\u9884\u6d4b\u6548\u679c\u3002", "method": "\u5229\u7528\u6301\u4e45\u540c\u6e90\u6027\u6784\u5efa\u94f6\u884c\u95f4\u5173\u7cfb\u7f51\u7edc\uff0c\u5e76\u7ed3\u5408\u4f20\u7edf\u8d37\u6b3e\u7f51\u7edc\uff0c\u5f62\u6210\u5f02\u8d28\u7f51\u7edc\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u8fdb\u884c\u8bc4\u7ea7\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cHTGNN\u5728\u5168\u7403\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u6548\u63d0\u9ad8\u4e86\u94f6\u884c\u4fe1\u7528\u8bc4\u7ea7\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06287", "pdf": "https://arxiv.org/pdf/2506.06287", "abs": "https://arxiv.org/abs/2506.06287", "authors": ["FutureSearch", ":", "Nikos I. Bosse", "Jon Evans", "Robert G. Gambee", "Daniel Hnyk", "Peter M\u00fchlbacher", "Lawrence Phillips", "Dan Schwarz", "Jack Wildman"], "title": "Deep Research Bench: Evaluating AI Web Research Agents", "categories": ["cs.AI"], "comment": null, "summary": "Amongst the most common use cases of modern AI is LLM chat with web search\nenabled. However, no direct evaluations of the quality of web research agents\nexist that control for the continually-changing web. We introduce Deep Research\nBench, consisting of 89 multi-step web research task instances of varying\ndifficulty across 8 diverse task categories, with the answers carefully worked\nout by skilled humans. We provide a \"RetroSearch\" environment with a large\nfrozen set of scraped web pages, and demonstrate that offline \"RetroSearch\"\nagents perform comparably to \"live web\" agents, enabling reliable evaluations\nof models over time. We provide robust agent tooling and scaffolding to\nbenchmark major LLMs as they are released, including \"thinking\" models like o3\nand Gemini 2.5 Pro. We include automated evaluations of the lengthy agent\ntraces to report progress over time in hallucinations, tool use, and\nforgetting. Finally, we evaluate the major web research products branded as\n\"Deep Research\", \"Deep Search\", \"Search\", or \"Research.\" Results are available\non a public leaderboard at https://drb.futuresearch.ai/.", "AI": {"tldr": "\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u540d\u4e3a Deep Research Bench \u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u6765\u8bc4\u4f30\u7f51\u9875\u7814\u7a76\u4ee3\u7406\u7684\u8d28\u91cf\uff0c\u5e76\u8bc1\u660e\u79bb\u7ebf\u4ee3\u7406\u7684\u8868\u73b0\u80fd\u591f\u53ef\u9760\u5730\u53cd\u6620\u6a21\u578b\u7684\u80fd\u529b\u3002", "motivation": "\u6ca1\u6709\u76f4\u63a5\u8bc4\u4f30\u63a7\u5236\u4e0d\u65ad\u53d8\u5316\u7684\u7f51\u7edc\u73af\u5883\u4e0b\u7684\u7f51\u9875\u7814\u7a76\u4ee3\u7406\u8d28\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u6a21\u578b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3a Deep Research Bench \u7684\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\uff0c\u5176\u4e2d\u5305\u542b 89 \u4e2a\u591a\u6b65\u9aa4\u7684\u7f51\u7edc\u7814\u7a76\u4efb\u52a1\u5b9e\u4f8b\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u540d\u4e3a 'RetroSearch' \u7684\u79bb\u7ebf\u73af\u5883\u3002", "result": "\u79bb\u7ebf 'RetroSearch' \u4ee3\u7406\u7684\u8868\u73b0\u4e0e '\u5b9e\u65f6\u7f51\u7edc' \u4ee3\u7406\u76f8\u5f53\uff0c\u8fd9\u8bc1\u660e\u4e86\u53ef\u4ee5\u8fdb\u884c\u53ef\u9760\u7684\u6a21\u578b\u8bc4\u4f30\u3002", "conclusion": "\u6211\u4eec\u8bc4\u4f30\u4e86\u4e3b\u8981\u7684\u7f51\u7edc\u7814\u7a76\u4ea7\u54c1\uff0c\u5e76\u5728\u516c\u5f00\u7684\u6392\u884c\u699c\u4e0a\u516c\u5e03\u4e86\u7ed3\u679c\u3002"}}
{"id": "2506.06376", "pdf": "https://arxiv.org/pdf/2506.06376", "abs": "https://arxiv.org/abs/2506.06376", "authors": ["Heng Dong", "Kefei Duan", "Chongjie Zhang"], "title": "Enhancing Decision-Making of Large Language Models via Actor-Critic", "categories": ["cs.CL", "cs.AI"], "comment": "Forty-second International Conference on Machine Learning (ICML 2025)", "summary": "Large Language Models (LLMs) have achieved remarkable advancements in natural\nlanguage processing tasks, yet they encounter challenges in complex\ndecision-making scenarios that require long-term reasoning and alignment with\nhigh-level objectives. Existing methods either rely on short-term\nauto-regressive action generation or face limitations in accurately simulating\nrollouts and assessing outcomes, leading to sub-optimal decisions. This paper\nintroduces a novel LLM-based Actor-Critic framework, termed LAC, that\neffectively improves LLM policies with long-term action evaluations in a\nprincipled and scalable way. Our approach addresses two key challenges: (1)\nextracting robust action evaluations by computing Q-values via token logits\nassociated with positive/negative outcomes, enhanced by future trajectory\nrollouts and reasoning; and (2) enabling efficient policy improvement through a\ngradient-free mechanism. Experiments across diverse environments -- including\nhigh-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text),\nand large action spaces (WebShop) -- demonstrate the framework's generality and\nsuperiority over state-of-the-art methods. Notably, our approach achieves\ncompetitive performance using 7B/8B parameter LLMs, even outperforming baseline\nmethods employing GPT-4 in complex tasks. These results underscore the\npotential of integrating structured policy optimization with LLMs' intrinsic\nknowledge to advance decision-making capabilities in multi-step environments.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165LAC\u6846\u67b6\uff0c\u901a\u8fc7\u957f\u8fdc\u884c\u52a8\u8bc4\u4f30\u6539\u8fdbLLM\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u51b3\u7b56\u573a\u666f\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u96be\u4ee5\u8fdb\u884c\u957f\u671f\u63a8\u7406\u548c\u51c6\u786e\u8bc4\u4f30\u7ed3\u679c\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eLLM\u7684Actor-Critic\u6846\u67b6LAC\uff0c\u5728\u65e0\u68af\u5ea6\u673a\u5236\u4e0b\u8fdb\u884c\u9ad8\u6548\u7684\u7b56\u7565\u6539\u8fdb\u3002", "result": "\u5728\u5404\u7c7b\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLAC\u6846\u67b6\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u4f18\u8d8a\u6027\uff0c\u4f7f\u7528\u8f83\u5c0f\u7684\u53c2\u6570\u6a21\u578b\u4e5f\u80fd\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684LAC\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86LLM\u5728\u591a\u6b65\u51b3\u7b56\u73af\u5883\u4e2d\u7684\u7b56\u7565\u4f18\u5316\u80fd\u529b\u3002"}}
{"id": "2506.06294", "pdf": "https://arxiv.org/pdf/2506.06294", "abs": "https://arxiv.org/abs/2506.06294", "authors": ["Yunqing Liu", "Wenqi Fan", "Xiaoyong Wei", "Qing Li"], "title": "GLProtein: Global-and-Local Structure Aware Protein Representation Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.BM"], "comment": null, "summary": "Proteins are central to biological systems, participating as building blocks\nacross all forms of life. Despite advancements in understanding protein\nfunctions through protein sequence analysis, there remains potential for\nfurther exploration in integrating protein structural information. We argue\nthat the structural information of proteins is not only limited to their 3D\ninformation but also encompasses information from amino acid molecules (local\ninformation) to protein-protein structure similarity (global information). To\naddress this, we propose \\textbf{GLProtein}, the first framework in protein\npre-training that incorporates both global structural similarity and local\namino acid details to enhance prediction accuracy and functional insights.\nGLProtein innovatively combines protein-masked modelling with triplet structure\nsimilarity scoring, protein 3D distance encoding and substructure-based amino\nacid molecule encoding. Experimental results demonstrate that GLProtein\noutperforms previous methods in several bioinformatics tasks, including\npredicting protein-protein interaction, contact prediction, and so on.", "AI": {"tldr": "GLProtein\u662f\u4e00\u79cd\u521b\u65b0\u7684\u86cb\u767d\u8d28\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408\u86cb\u767d\u8d28\u7684\u5168\u5c40\u7ed3\u6784\u548c\u5c40\u90e8\u6c28\u57fa\u9178\u4fe1\u606f\u4ee5\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u5176\u6027\u80fd\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\u3002", "motivation": "\u76ee\u524d\u5bf9\u86cb\u767d\u8d28\u7ed3\u6784\u4fe1\u606f\u7684\u7406\u89e3\u4ecd\u6709\u6539\u8fdb\u7684\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u5982\u4f55\u6574\u5408\u86cb\u767d\u8d28\u76843D\u4fe1\u606f\u548c\u5c40\u90e8\u7684\u6c28\u57fa\u9178\u5206\u5b50\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u529f\u80fd\u6d1e\u5bdf\u3002", "method": "\u63d0\u51faGLProtein\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u86cb\u767d\u8d28\u63a9\u819c\u6a21\u578b\u548c\u4e09\u5143\u7ec4\u7ed3\u6784\u76f8\u4f3c\u6027\u8bc4\u5206\u3001\u86cb\u767d\u8d28\u4e09\u7ef4\u8ddd\u79bb\u7f16\u7801\u53ca\u57fa\u4e8e\u5b50\u7ed3\u6784\u7684\u6c28\u57fa\u9178\u5206\u5b50\u7f16\u7801\u6765\u5b9e\u73b0\u5bf9\u86cb\u767d\u8d28\u7684\u9884\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGLProtein\u5728\u9884\u6d4b\u86cb\u767d\u8d28-\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u3001\u63a5\u89e6\u9884\u6d4b\u7b49\u591a\u4e2a\u751f\u7269\u4fe1\u606f\u5b66\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GLProtein\u6846\u67b6\u6709\u6548\u6574\u5408\u4e86\u86cb\u767d\u8d28\u7684\u5168\u5c40\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u5c40\u90e8\u6c28\u57fa\u9178\u7ec6\u8282\uff0c\u63d0\u5347\u4e86\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06301", "pdf": "https://arxiv.org/pdf/2506.06301", "abs": "https://arxiv.org/abs/2506.06301", "authors": ["Muhammad Monjurul Karim", "Yan Shi", "Shucheng Zhang", "Bingzhang Wang", "Mehrdad Nasri", "Yinhai Wang"], "title": "Large Language Models and Their Applications in Roadway Safety and Mobility Enhancement: A Comprehensive Review", "categories": ["cs.AI"], "comment": null, "summary": "Roadway safety and mobility remain critical challenges for modern\ntransportation systems, demanding innovative analytical frameworks capable of\naddressing complex, dynamic, and heterogeneous environments. While traditional\nengineering methods have made progress, the complexity and dynamism of\nreal-world traffic necessitate more advanced analytical frameworks. Large\nLanguage Models (LLMs), with their unprecedented capabilities in natural\nlanguage understanding, knowledge integration, and reasoning, represent a\npromising paradigm shift. This paper comprehensively reviews the application\nand customization of LLMs for enhancing roadway safety and mobility. A key\nfocus is how LLMs are adapted -- via architectural, training, prompting, and\nmultimodal strategies -- to bridge the \"modality gap\" with transportation's\nunique spatio-temporal and physical data. The review systematically analyzes\ndiverse LLM applications in mobility (e.g., traffic flow prediction, signal\ncontrol) and safety (e.g., crash analysis, driver behavior assessment,).\nEnabling technologies such as V2X integration, domain-specific foundation\nmodels, explainability frameworks, and edge computing are also examined.\nDespite significant potential, challenges persist regarding inherent LLM\nlimitations (hallucinations, reasoning deficits), data governance (privacy,\nbias), deployment complexities (sim-to-real, latency), and rigorous safety\nassurance. Promising future research directions are highlighted, including\nadvanced multimodal fusion, enhanced spatio-temporal reasoning, human-AI\ncollaboration, continuous learning, and the development of efficient,\nverifiable systems. This review provides a structured roadmap of current\ncapabilities, limitations, and opportunities, underscoring LLMs' transformative\npotential while emphasizing the need for responsible innovation to realize\nsafer, more intelligent transportation systems.", "AI": {"tldr": "This paper reviews the use of LLMs in transportation for improving safety and mobility, discussing their applications, customization strategies, potential, challenges, and future research directions.", "motivation": "The complexity and dynamism of real-world traffic require advanced analytical frameworks beyond traditional engineering methods.", "method": "Review of LLM applications and customization strategies in roadway safety and mobility, focusing on architectural, training, prompting, and multimodal strategies.", "result": "Identified challenges of LLMs in transportation, such as hallucinations, reasoning deficits, data privacy issues, deployment complexities, and the need for rigorous safety assurance.", "conclusion": "LLMs have transformative potential in enhancing roadway safety and mobility, but responsible innovation is essential for realizing safer, more intelligent transportation systems."}}
{"id": "2506.06325", "pdf": "https://arxiv.org/pdf/2506.06325", "abs": "https://arxiv.org/abs/2506.06325", "authors": ["Viorica Rozina Chifu", "Tudor Cioara", "Cristina Bianca Pop", "Ionut Anghel"], "title": "Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies", "categories": ["cs.NE", "cs.AI", "cs.GT", "cs.MA"], "comment": null, "summary": "This paper proposes a decentralized model of energy cooperation between\nmicrogrids, in which decisions are made locally, at the level of the microgrid\ncommunity. Each microgrid is modeled as an autonomous agent that adopts a Hawk\nor Dove strategy, depending on the level of energy stored in the battery and\nits role in the energy trading process. The interactions between selling and\nbuying microgrids are modeled through an evolutionary algorithm. An individual\nin the algorithm population is represented as an energy trading matrix that\nencodes the amounts of energy traded between the selling and buying microgrids.\nThe population evolution is achieved by recombination and mutation operators.\nRecombination uses a specialized operator for matrix structures, and mutation\nis applied to the matrix elements according to a Gaussian distribution. The\nevaluation of an individual is made with a multi-criteria fitness function that\nconsiders the seller profit, the degree of energy stability at the community\nlevel, penalties for energy imbalance at the community level and for the\ndegradation of microgrids batteries. The method was tested on a simulated\nscenario with 100 microgrids, each with its own selling and buying thresholds,\nto reflect a realistic environment with variable storage characteristics of\nmicrogrids batteries. By applying the algorithm on this scenario, 95 out of the\n100 microgrids reached a stable energy state. This result confirms the\neffectiveness of the proposed model in achieving energy balance both at the\nindividual level, for each microgrid, and at the level of the entire community.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u5fae\u7535\u7f51\u80fd\u6e90\u5408\u4f5c\u6a21\u578b\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u8fdb\u884c\u4ea4\u6613\u884c\u4e3a\u5efa\u6a21\uff0c\u5728\u4eff\u771f\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u53d1\u5c55\u53bb\u4e2d\u5fc3\u5316\u7684\u5fae\u7535\u7f51\u80fd\u6e90\u5408\u4f5c\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u793e\u533a\u5c42\u9762\u7684\u51b3\u7b56\u81ea\u4e3b\u6027\u3002", "method": "\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u8fdb\u884c\u4ea4\u6613\u884c\u4e3a\u7684\u5efa\u6a21\uff0c\u4f7f\u7528\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u77e9\u9635\u7ed3\u6784\u7684\u91cd\u7ec4\u8fd0\u7b97\u7b26\u4ee5\u53ca\u9ad8\u65af\u5206\u5e03\u7684\u53d8\u5f02\u8fd0\u7b97\u7b26\u6765\u5b9e\u73b0\u79cd\u7fa4\u8fdb\u5316\u3002", "result": "100\u4e2a\u5fae\u7535\u7f51\u4e2d\u670995\u4e2a\u8fbe\u5230\u4e86\u7a33\u5b9a\u7684\u80fd\u6e90\u72b6\u6001\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u5fae\u7535\u7f51\u5185\u4e2a\u4f53\u5c42\u9762\u548c\u6574\u4e2a\u793e\u533a\u5c42\u9762\u7684\u7a33\u5b9a\u80fd\u6e90\u72b6\u6001\u3002"}}
{"id": "2506.06384", "pdf": "https://arxiv.org/pdf/2506.06384", "abs": "https://arxiv.org/abs/2506.06384", "authors": ["Yi Ji", "Runzhi Li", "Baolei Mao"], "title": "Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by KSEM2025 AI & Sec Workshop", "summary": "With the widespread adoption of Large Language Models (LLMs), prompt\ninjection attacks have emerged as a significant security threat. Existing\ndefense mechanisms often face critical trade-offs between effectiveness and\ngeneralizability. This highlights the urgent need for efficient prompt\ninjection detection methods that are applicable across a wide range of LLMs. To\naddress this challenge, we propose DMPI-PMHFE, a dual-channel feature fusion\ndetection framework. It integrates a pretrained language model with heuristic\nfeature engineering to detect prompt injection attacks. Specifically, the\nframework employs DeBERTa-v3-base as a feature extractor to transform input\ntext into semantic vectors enriched with contextual information. In parallel,\nwe design heuristic rules based on known attack patterns to extract explicit\nstructural features commonly observed in attacks. Features from both channels\nare subsequently fused and passed through a fully connected neural network to\nproduce the final prediction. This dual-channel approach mitigates the\nlimitations of relying only on DeBERTa to extract features. Experimental\nresults on diverse benchmark datasets demonstrate that DMPI-PMHFE outperforms\nexisting methods in terms of accuracy, recall, and F1-score. Furthermore, when\ndeployed actually, it significantly reduces attack success rates across\nmainstream LLMs, including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.", "AI": {"tldr": "DMPI-PMHFE\u6846\u67b6\u901a\u8fc7\u7279\u5f81\u878d\u5408\u63d0\u9ad8\u4e86\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5728\u5404\u9879\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u9632\u5fa1\u673a\u5236\u5728\u6709\u6548\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u4e4b\u95f4\u5b58\u5728\u91cd\u5927\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u3001\u9002\u7528\u4e8e\u5404\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u6ce8\u5165\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "DMPI-PMHFE\u662f\u4e00\u4e2a\u53cc\u901a\u9053\u7279\u5f81\u878d\u5408\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u542f\u53d1\u5f0f\u7279\u5f81\u5de5\u7a0b\u68c0\u6d4b\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDMPI-PMHFE\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u503c\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u6210\u529f\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684DMPI-PMHFE\u6846\u67b6\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3002"}}
{"id": "2506.06295", "pdf": "https://arxiv.org/pdf/2506.06295", "abs": "https://arxiv.org/abs/2506.06295", "authors": ["Zhiyuan Liu", "Yicun Yang", "Yaojie Zhang", "Junjie Chen", "Chang Zou", "Qingyuan Wei", "Shaobo Wang", "Linfeng Zhang"], "title": "dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Autoregressive Models (ARMs) have long dominated the landscape of Large\nLanguage Models. Recently, a new paradigm has emerged in the form of\ndiffusion-based Large Language Models (dLLMs), which generate text by\niteratively denoising masked segments. This approach has shown significant\nadvantages and potential. However, dLLMs suffer from high inference latency.\nTraditional ARM acceleration techniques, such as Key-Value caching, are\nincompatible with dLLMs due to their bidirectional attention mechanism. To\naddress this specific challenge, our work begins with a key observation that\ndLLM inference involves a static prompt and a partially dynamic response, where\nmost tokens remain stable across adjacent denoising steps. Based on this, we\npropose dLLM-Cache, a training-free adaptive caching framework that combines\nlong-interval prompt caching with partial response updates guided by feature\nsimilarity. This design enables efficient reuse of intermediate computations\nwithout compromising model performance. Extensive experiments on representative\ndLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1\nx speedup over standard inference without compromising output quality. Notably,\nour method brings dLLM inference latency close to that of ARMs under many\nsettings. Codes are provided in the supplementary material and will be released\npublicly on GitHub.", "AI": {"tldr": "\u63d0\u51fa\u4e86dLLM-Cache\u7f13\u5b58\u6846\u67b6\uff0c\u5927\u5e45\u63d0\u5347dLLM\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u63a5\u8fd1\u4f20\u7edfARMs\u3002", "motivation": "\u514b\u670ddLLMs\u7684\u9ad8\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u5e76\u517c\u5bb9\u5176\u53cc\u5411\u6ce8\u610f\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u81ea\u9002\u5e94\u7f13\u5b58\u6846\u67b6dLLM-Cache\uff0c\u901a\u8fc7\u957f\u95f4\u9694\u63d0\u793a\u7f13\u5b58\u548c\u57fa\u4e8e\u7279\u5f81\u76f8\u4f3c\u5ea6\u7684\u90e8\u5206\u54cd\u5e94\u66f4\u65b0\u6765\u52a0\u901f\u63a8\u7406\u3002", "result": "dLLM-Cache\u5728\u4e0d\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u901f\u5ea6\u6700\u9ad89.1\u500d\u7684\u63d0\u5347\uff0c\u63a8\u7406\u5ef6\u8fdf\u63a5\u8fd1ARMs\u3002\u4ee3\u7801\u5c06\u5728GitHub\u4e0a\u516c\u5f00\u3002", "conclusion": "dLLM-Cache\u80fd\u591f\u663e\u8457\u52a0\u901fdLLM\u63a8\u7406\u800c\u4e0d\u727a\u7272\u8f93\u51fa\u8d28\u91cf\uff0c\u4f7f\u5176\u63a8\u7406\u5ef6\u8fdf\u63a5\u8fd1\u4f20\u7edfARMs\u3002"}}
{"id": "2506.06324", "pdf": "https://arxiv.org/pdf/2506.06324", "abs": "https://arxiv.org/abs/2506.06324", "authors": ["Shruti Kumar", "Xiaoyu Chen", "Xiaomei Wang"], "title": "Mapping Human-Agent Co-Learning and Co-Adaptation: A Scoping Review", "categories": ["cs.AI"], "comment": "Abstract accepted to HFES 2024 Annual Meeting", "summary": "Several papers have delved into the challenges of human-AI-robot co-learning\nand co-adaptation. It has been noted that the terminology used to describe this\ncollaborative relationship in existing studies needs to be more consistent. For\nexample, the prefix \"co\" is used interchangeably to represent both\n\"collaborative\" and \"mutual,\" and the terms \"co-learning\" and \"co-adaptation\"\nare sometimes used interchangeably. However, they can reflect subtle\ndifferences in the focus of the studies. The current scoping review's primary\nresearch question (RQ1) aims to gather existing papers discussing this\ncollaboration pattern and examine the terms researchers use to describe this\nhuman-agent relationship. Given the relative newness of this area of study, we\nare also keen on exploring the specific types of intelligent agents and task\ndomains that have been considered in existing research (RQ2). This exploration\nis significant as it can shed light on the diversity of human-agent\ninteractions, from one-time to continuous learning/adaptation scenarios. It can\nalso help us understand the dynamics of human-agent interactions in different\ntask domains, guiding our expectations towards research situated in dynamic,\ncomplex domains. Our third objective (RQ3) is to investigate the cognitive\ntheories and frameworks that have been utilized in existing studies to measure\nhuman-agent co-learning and co-adaptation. This investigation is crucial as it\ncan help us understand the theoretical underpinnings of human-agent\ncollaboration and adaptation, and it can also guide us in identifying any new\nframeworks proposed specifically for this type of relationship.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u7814\u7a76\u5206\u6790\u4e86\u4eba\u7c7b-AI-\u673a\u5668\u4eba\u5408\u4f5c\u5b66\u4e60\u548c\u9002\u5e94\u7814\u7a76\u4e2d\u7684\u672f\u8bed\u3001\u667a\u80fd\u4ee3\u7406\u7c7b\u578b\u548c\u7406\u8bba\u6846\u67b6\uff0c\u53d1\u73b0\u672f\u8bed\u4f7f\u7528\u4e0d\u4e00\u81f4\u5e76\u63a2\u8ba8\u5176\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u7531\u4e8e\u4eba\u7c7b-AI-\u673a\u5668\u4eba\u5171\u5b66\u4e60\u548c\u5171\u9002\u5e94\u7814\u7a76\u9886\u57df\u76f8\u5bf9\u8f83\u65b0\uff0c\u65e8\u5728\u660e\u786e\u548c\u7edf\u4e00\u63cf\u8ff0\u8fd9\u4e9b\u73b0\u8c61\u7684\u65b9\u6cd5\u548c\u672f\u8bed\u3002", "method": "\u8303\u56f4\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u6536\u96c6\u5e76\u5206\u6790\u5df2\u53d1\u8868\u7684\u9488\u5bf9\u4eba\u7c7b-AI-\u673a\u5668\u4eba\u5408\u4f5c\u5b66\u4e60\u548c\u9002\u5e94\u7684\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u4e0d\u540c\u672f\u8bed\uff0c\u4e0d\u540c\u667a\u80fd\u4ee3\u7406\u548c\u4efb\u52a1\u9886\u57df\uff0c\u4ee5\u53ca\u7528\u4e8e\u6d4b\u91cf\u5171\u5b66\u4e60\u548c\u9002\u5e94\u7684\u8ba4\u77e5\u7406\u8bba\u548c\u6846\u67b6\u3002", "conclusion": "\u5728\u73b0\u6709\u7814\u7a76\u4e2d\uff0c\u63cf\u8ff0\u4eba\u7c7b-\u667a\u80fd\u4f53\u5408\u4f5c\u5173\u7cfb\u7684\u672f\u8bed\u4f7f\u7528\u4e0d\u4e00\u81f4\uff0c\u9700\u66f4\u4e25\u683c\u5b9a\u4e49\u4ee5\u6307\u5bfc\u7814\u7a76\u3002"}}
{"id": "2506.06366", "pdf": "https://arxiv.org/pdf/2506.06366", "abs": "https://arxiv.org/abs/2506.06366", "authors": ["Lin Chen", "Yunke Zhang", "Jie Feng", "Haoye Chai", "Honglin Zhang", "Bingbing Fan", "Yibo Ma", "Shiyuan Zhang", "Nian Li", "Tianhui Liu", "Nicholas Sukiennik", "Keyu Zhao", "Yu Li", "Ziyi Liu", "Fengli Xu", "Yong Li"], "title": "AI Agent Behavioral Science", "categories": ["q-bio.NC", "cs.CY", "cs.MA"], "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled AI systems to\nbehave in increasingly human-like ways, exhibiting planning, adaptation, and\nsocial dynamics across increasingly diverse, interactive, and open-ended\nscenarios. These behaviors are not solely the product of the models' internal\narchitecture, but emerge from their integration into agentic systems that\noperate within situated contexts, where goals, feedback, and interactions shape\nbehavior over time. This shift calls for a new scientific lens: AI Agent\nBehavioral Science. Rather than focusing only on internal mechanisms, this\nparadigm emphasizes the systematic observation of behavior, design of\ninterventions to test hypotheses, and theory-guided interpretation of how AI\nagents act, adapt, and interact over time. We systematize a growing body of\nresearch across individual, multi-agent, and human-agent interaction settings,\nand further demonstrate how this perspective informs responsible AI by treating\nfairness, safety, interpretability, accountability, and privacy as behavioral\nproperties. By unifying recent findings and laying out future directions, we\nposition AI Agent Behavioral Science as a necessary complement to traditional\napproaches, providing essential tools for understanding, evaluating, and\ngoverning the real-world behavior of increasingly autonomous AI systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faAI\u4ee3\u7406\u884c\u4e3a\u79d1\u5b66\uff0c\u4ee5\u89c2\u5bdf\u5e76\u89e3\u91caAI\u7cfb\u7edf\u884c\u4e3a\uff0c\u5e76\u63a8\u52a8\u5728\u516c\u5e73\u3001\u5b89\u5168\u3001\u89e3\u91ca\u6027\u7b49\u65b9\u9762\u7684\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\uff0cAI\u7cfb\u7edf\u5728\u4ea4\u4e92\u548c\u5f00\u653e\u6027\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u8d8a\u6765\u8d8a\u50cf\u4eba\u7c7b\u7684\u884c\u4e3a\u3002\u8fd9\u79cd\u884c\u4e3a\u4e0d\u4ec5\u4ec5\u662f\u6a21\u578b\u5185\u90e8\u67b6\u6784\u7684\u4ea7\u7269\uff0c\u800c\u662f\u4ece\u5b83\u4eec\u6574\u5408\u5230\u4ee3\u7406\u7cfb\u7edf\u4e2d\u5e76\u5728\u7279\u5b9a\u73af\u5883\u4e0b\u8fd0\u4f5c\u65f6\u6240\u4ea7\u751f\u7684\uff0c\u5176\u4e2d\u76ee\u6807\u3001\u53cd\u9988\u548c\u4e92\u52a8\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u5851\u9020\u884c\u4e3a\u3002\u8fd9\u4e00\u8f6c\u53d8\u547c\u5524\u65b0\u7684\u79d1\u5b66\u89c6\u89d2\uff1aAI\u4ee3\u7406\u884c\u4e3a\u79d1\u5b66\u3002", "method": "\u7cfb\u7edf\u5316\u7814\u7a76\u4e2a\u4eba\u3001\u591a\u4ee3\u7406\u548c\u4eba\u7c7b\u4ee3\u7406\u4ea4\u4e92\u573a\u666f\u4e2d\u7684AI\u884c\u4e3a\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5e72\u9884\u6765\u6d4b\u8bd5\u5047\u8bbe\uff0c\u5e76\u57fa\u4e8e\u7406\u8bba\u6307\u5bfc\u89e3\u91caAI\u4ee3\u7406\u5982\u4f55\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u884c\u52a8\u3001\u9002\u5e94\u548c\u4e92\u52a8\u3002", "result": "\u63d0\u51fa\u4e86AI\u4ee3\u7406\u884c\u4e3a\u79d1\u5b66\u4f5c\u4e3a\u5bf9\u4f20\u7edf\u65b9\u6cd5\u7684\u5fc5\u8981\u8865\u5145\uff0c\u63d0\u4f9b\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u6cbb\u7406\u8d8a\u6765\u8d8a\u81ea\u4e3b\u7684AI\u7cfb\u7edf\u5728\u73b0\u5b9e\u4e16\u754c\u884c\u4e3a\u65b9\u9762\u7684\u57fa\u672c\u5de5\u5177\u3002", "conclusion": "AI\u4ee3\u7406\u884c\u4e3a\u79d1\u5b66\u5f3a\u8c03\u89c2\u5bdf\u884c\u4e3a\u3001\u8bbe\u8ba1\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1\u5047\u8bbe\uff0c\u5e76\u89e3\u91caAI\u4ee3\u7406\u5982\u4f55\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u884c\u52a8\u548c\u4e92\u52a8\u3002\u8fd9\u79cd\u89c6\u89d2\u6709\u52a9\u4e8e\u5904\u7406\u516c\u5e73\u3001\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u6027\u3001\u95ee\u8d23\u548c\u9690\u79c1\u4f5c\u4e3a\u884c\u4e3a\u5c5e\u6027\u7684\u95ee\u9898\uff0c\u5e76\u4e3a\u8d1f\u8d23\u7684AI\u5f00\u53d1\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2506.06395", "pdf": "https://arxiv.org/pdf/2506.06395", "abs": "https://arxiv.org/abs/2506.06395", "authors": ["Pengyi Li", "Matvey Skripkin", "Alexander Zubrey", "Andrey Kuznetsov", "Ivan Oseledets"], "title": "Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at reasoning, yet post-training remains\ncritical for aligning their behavior with task goals. Existing reinforcement\nlearning (RL) methods often depend on costly human annotations or external\nreward models. We propose Reinforcement Learning via Self-Confidence (RLSC),\nwhich uses the model's own confidence as reward signals-eliminating the need\nfor labels, preference models, or reward engineering. Applied to\nQwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC\nimproves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on\nAMC23. RLSC offers a simple, scalable post-training method for reasoning models\nwith minimal supervision.", "AI": {"tldr": "\u81ea\u4fe1\u5f3a\u5316\u5b66\u4e60\uff08RLSC\uff09\u901a\u8fc7\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u7cbe\u5ea6\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "motivation": "\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u7cbe\u5ea6\uff0c\u5e76\u51cf\u5c11\u5bf9\u4eba\u5de5\u6807\u6ce8\u548c\u5916\u90e8\u5956\u52b1\u6a21\u578b\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u2014\u2014\u81ea\u4fe1\u5f3a\u5316\u5b66\u4e60\uff08RLSC\uff09\uff0c\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u800c\u65e0\u9700\u6807\u6ce8\u548c\u5956\u52b1\u5de5\u7a0b\u3002", "result": "\u901a\u8fc7\u5e94\u7528RLSC\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u6570\u5b66\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u7cbe\u5ea6\u63d0\u5347\uff1a\u5728AIME2024\u4e0a\u63d0\u5347\u4e8620.10%\uff0c\u5728MATH500\u4e0a\u63d0\u5347\u4e8649.40%\uff0c\u5728AMC23\u4e0a\u63d0\u5347\u4e8652.50%\u3002", "conclusion": "\u81ea\u4fe1\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u53ef\u6269\u5c55\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u6700\u5c0f\u76d1\u7763\u4e0b\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06296", "pdf": "https://arxiv.org/pdf/2506.06296", "abs": "https://arxiv.org/abs/2506.06296", "authors": ["Hanaa El Afia", "Said Ohamouddou", "Raddouane Chiheb", "Abdellatif El Afia"], "title": "Dynamic Graph CNN with Jacobi Kolmogorov-Arnold Networks for 3D Classification of Point Sets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Jacobi-KAN-DGCNN, a framework that integrates Dynamic Graph\nConvolutional Neural Network (DGCNN) with Jacobi Kolmogorov-Arnold Networks\n(KAN) for the classification of three-dimensional point clouds. This method\nreplaces Multi-Layer Perceptron (MLP) layers with adaptable univariate\npolynomial expansions within a streamlined DGCNN architecture, circumventing\ndeep levels for both MLP and KAN to facilitate a layer-by-layer comparison. In\ncomparative experiments on the ModelNet40 dataset, KAN layers employing Jacobi\npolynomials outperform the traditional linear layer-based DGCNN baseline in\nterms of accuracy and convergence speed, while maintaining parameter\nefficiency. Our results demonstrate that higher polynomial degrees do not\nautomatically improve performance, highlighting the need for further\ntheoretical and empirical investigation to fully understand the interactions\nbetween polynomial bases, degrees, and the mechanisms of graph-based learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684Jacobi-KAN-DGCNN\u5728\u4e09\u7ef4\u70b9\u4e91\u5206\u7c7b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5e0c\u671b\u901a\u8fc7\u5c06Jacobi-KAN\u6846\u67b6\u6574\u5408\u8fdbDGCNN\u67b6\u6784\u4e2d\uff0c\u6539\u8fdb\u5176\u5206\u7c7b\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u4fdd\u6301\u53c2\u6570\u6548\u7387\u7684\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002", "method": "\u5c06Dynamic Graph Convolutional Neural Network (DGCNN)\u4e0eJacobi Kolmogorov-Arnold Networks (KAN)\u96c6\u6210\u7528\u4e8e\u4e09\u7ef4\u70b9\u4e91\u5206\u7c7b\uff0c\u5e76\u7528\u81ea\u9002\u5e94\u5355\u53d8\u91cf\u591a\u9879\u5f0f\u6269\u5c55\u66ff\u6362DGCNN\u4e2d\u7684\u591a\u5c42\u611f\u77e5\u673a\u5c42\u3002", "result": "\u5728ModelNet40\u6570\u636e\u96c6\u4e0a\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528Jacobi\u591a\u9879\u5f0f\u7684KAN\u5c42\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edfDGCNN\u3002", "conclusion": "\u672c\u7814\u7a76\u5f15\u5165\u7684Jacobi-KAN-DGCNN\u6846\u67b6\u80fd\u591f\u5728\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u7ebf\u6027\u5c42\u57fa\u7840\u7684DGCNN\uff0c\u540c\u65f6\u4fdd\u6301\u53c2\u6570\u6548\u7387\u3002"}}
{"id": "2506.06326", "pdf": "https://arxiv.org/pdf/2506.06326", "abs": "https://arxiv.org/abs/2506.06326", "authors": ["Jiazheng Kang", "Mingming Ji", "Zhe Zhao", "Ting Bai"], "title": "Memory OS of AI Agent", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) face a crucial challenge from fixed context\nwindows and inadequate memory management, leading to a severe shortage of\nlong-term memory capabilities and limited personalization in the interactive\nexperience with AI agents. To overcome this challenge, we innovatively propose\na Memory Operating System, i.e., MemoryOS, to achieve comprehensive and\nefficient memory management for AI agents. Inspired by the memory management\nprinciples in operating systems, MemoryOS designs a hierarchical storage\narchitecture and consists of four key modules: Memory Storage, Updating,\nRetrieval, and Generation. Specifically, the architecture comprises three\nlevels of storage units: short-term memory, mid-term memory, and long-term\npersonal memory. Key operations within MemoryOS include dynamic updates between\nstorage units: short-term to mid-term updates follow a dialogue-chain-based\nFIFO principle, while mid-term to long-term updates use a segmented page\norganization strategy. Our pioneering MemoryOS enables hierarchical memory\nintegration and dynamic updating. Extensive experiments on the LoCoMo benchmark\nshow an average improvement of 49.11% on F1 and 46.18% on BLEU-1 over the\nbaselines on GPT-4o-mini, showing contextual coherence and personalized memory\nretention in long conversations. The implementation code is open-sourced at\nhttps://github.com/BAI-LAB/MemoryOS.", "AI": {"tldr": "\u5f15\u5165MemoryOS\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5b58\u7ba1\u7406\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u5c42\u67b6\u6784\u63d0\u9ad8\u8bb0\u5fc6\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56fa\u5b9a\u4e0a\u4e0b\u6587\u7a97\u53e3\u548c\u4e0d\u5145\u5206\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u4ece\u800c\u589e\u5f3a\u957f\u65f6\u95f4\u8bb0\u5fc6\u80fd\u529b\u548c\u4e92\u52a8\u4f53\u9a8c\u4e2d\u7684\u4e2a\u6027\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faMemoryOS\uff0c\u4e00\u4e2a\u7528\u4e8eAI\u4ee3\u7406\u7684\u5168\u9762\u9ad8\u6548\u7684\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\u3002MemoryOS\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5206\u5c42\u5b58\u50a8\u67b6\u6784\uff0c\u5e76\u5305\u542b\u56db\u4e2a\u5173\u952e\u6a21\u5757\uff1a\u5185\u5b58\u5b58\u50a8\u3001\u66f4\u65b0\u3001\u68c0\u7d22\u548c\u751f\u6210\u3002\u5305\u62ec\u77ed\u671f\u8bb0\u5fc6\u3001\u4e2d\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u4e2a\u4eba\u8bb0\u5fc6\u7684\u5b58\u50a8\u5355\u5143\u3002\u4f7f\u7528\u52a8\u6001\u66f4\u65b0\uff0c\u901a\u8fc7\u5bf9\u8bdd\u94fe\u7684FIFO\u539f\u5219\u4ee5\u53ca\u5206\u6bb5\u9875\u9762\u7ec4\u7ec7\u7b56\u7565\uff0c\u5b9e\u73b0\u77ed\u671f\u5230\u4e2d\u671f\u548c\u4e2d\u671f\u5230\u957f\u671f\u8bb0\u5fc6\u7684\u66f4\u65b0\u3002", "result": "\u5728LoCoMo\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793aF1\u5e73\u5747\u63d0\u9ad849.11%\uff0cBLEU-1\u63d0\u9ad846.18%\uff0c\u5728GPT-4o-mini\u4e0a\u663e\u793a\u51fa\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u548c\u4fdd\u6301\u4e2a\u6027\u5316\u8bb0\u5fc6\u7684\u80fd\u529b\u3002", "conclusion": "MemoryOS\u901a\u8fc7\u5206\u5c42\u8bb0\u5fc6\u6574\u5408\u548c\u52a8\u6001\u66f4\u65b0\uff0c\u6539\u5584\u4e86AI\u4ee3\u7406\u7684\u957f\u4e45\u8bb0\u5fc6\u80fd\u529b\u548c\u4e2a\u6027\u5316\u4e92\u52a8\u3002"}}
{"id": "2506.06381", "pdf": "https://arxiv.org/pdf/2506.06381", "abs": "https://arxiv.org/abs/2506.06381", "authors": ["Trisanth Srinivasan", "Santosh Patapati", "Himani Musku", "Idhant Gode", "Aditya Arora", "Samvit Bhattacharya", "Abubakr Nazriev", "Sanika Hirave", "Zaryab Kanjiani", "Srinjoy Ghose", "Srinidhi Shetty"], "title": "CPS-Guard: Framework for Dependability Assurance of AI- and LLM-Based Cyber-Physical Systems", "categories": ["cs.RO", "cs.AI", "cs.ET", "cs.HC", "cs.MA", "C.3; C.4; D.2.4; D.4.6; I.2.7"], "comment": null, "summary": "Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to\noperate in critical applications. However, traditional verification and\nvalidation methods often struggle to handle the unpredictable and dynamic\nnature of AI components. In this paper, we introduce CPS-Guard, a novel\nframework that employs multi-role orchestration to automate the iterative\nassurance process for AI-powered CPS. By assigning specialized roles (e.g.,\nsafety monitoring, security assessment, fault injection, and recovery planning)\nto dedicated agents within a simulated environment, CPS-Guard continuously\nevaluates and refines AI behavior against a range of dependability\nrequirements. We demonstrate the framework through a case study involving an\nautonomous vehicle navigating an intersection with an AI-based planner. Our\nresults show that CPS-Guard effectively detects vulnerabilities, manages\nperformance impacts, and supports adaptive recovery strategies, thereby\noffering a structured and extensible solution for rigorous V&V in safety- and\nsecurity-critical systems.", "AI": {"tldr": "CPS-Guard is a novel framework for automating assurance in AI-powered Cyber-Physical Systems, offering continuous evaluation through a multi-role orchestration approach.", "motivation": "Traditional verification and validation methods struggle to handle the unpredictable and dynamic nature of AI components in CPS, necessitating a new approach for assurance in critical applications.", "method": "CPS-Guard employs multi-role orchestration by assigning specialized roles like safety monitoring, security assessment, fault injection, and recovery planning to dedicated agents within a simulated environment. This allows for continuous evaluation and refinement of AI behavior against dependability requirements.", "result": "Through a case study with an autonomous vehicle, CPS-Guard effectively detects vulnerabilities, manages performance impacts, and supports adaptive recovery strategies.", "conclusion": "CPS-Guard provides a structured and extensible solution for rigorous verification and validation in safety- and security-critical systems."}}
{"id": "2506.06396", "pdf": "https://arxiv.org/pdf/2506.06396", "abs": "https://arxiv.org/abs/2506.06396", "authors": ["Christopher D. Molek", "Roberto Fronteddu", "K. Brent Venable", "Niranjan Suri"], "title": "Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things", "categories": ["cs.CL", "cs.AI", "cs.DB"], "comment": null, "summary": "The expansion of the Internet of Things (IoT) in the battlefield, Internet of\nBattlefield Things (IoBT), gives rise to new opportunities for enhancing\nsituational awareness. To increase the potential of IoBT for situational\nawareness in critical decision making, the data from these devices must be\nprocessed into consumer-ready information objects, and made available to\nconsumers on demand. To address this challenge we propose a workflow that makes\nuse of natural language processing (NLP) to query a database technology and\nreturn a response in natural language. Our solution utilizes Large Language\nModels (LLMs) that are sized for edge devices to perform NLP as well as\ngraphical databases which are well suited for dynamic connected networks which\nare pervasive in the IoBT. Our architecture employs LLMs for both mapping\nquestions in natural language to Cypher database queries as well as to\nsummarize the database output back to the user in natural language. We evaluate\nseveral medium sized LLMs for both of these tasks on a database representing\npublicly available data from the US Army's Multipurpose Sensing Area (MSA) at\nthe Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion\nparameters) outperforms the other models across all the considered metrics.\nMost importantly, we note that, unlike current methods, our two step approach\nallows the relaxation of the Exact Match (EM) requirement of the produced\nCypher queries with ground truth code and, in this way, it achieves a 19.4%\nincrease in accuracy. Our workflow lays the ground work for deploying LLMs on\nedge devices to enable natural language interactions with databases containing\ninformation objects for critical decision making.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5e76\u4f7f\u7528\u56fe\u5f62\u6570\u636e\u5e93\u6765\u589e\u5f3a\u6218\u573a\u7269\u8054\u7f51\uff08IoBT\uff09\u7684\u6001\u52bf\u611f\u77e5\u3002\u5728\u6d4b\u8bd5\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u67e5\u8be2\u51c6\u786e\u5ea6\uff0c\u5e76\u4e3a\u5173\u952e\u51b3\u7b56\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002", "motivation": "\u968f\u7740\u6218\u573a\u7269\u8054\u7f51\uff08IoBT\uff09\u7684\u6269\u5c55\uff0c\u4e3a\u589e\u5f3a\u6001\u52bf\u611f\u77e5\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\u3002\u4e3a\u4e86\u5728\u5173\u952e\u51b3\u7b56\u4e2d\u63d0\u9ad8IoBT\u7684\u6001\u52bf\u611f\u77e5\u6f5c\u529b\uff0c\u5fc5\u987b\u5c06\u8fd9\u4e9b\u8bbe\u5907\u7684\u6570\u636e\u5904\u7406\u4e3a\u6d88\u8d39\u8005\u53ef\u7528\u7684\u4fe1\u606f\u5bf9\u8c61\uff0c\u5e76\u6309\u9700\u63d0\u4f9b\u7ed9\u6d88\u8d39\u8005\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u6280\u672f\u67e5\u8be2\u6570\u636e\u5e93\uff0c\u5e76\u4ee5\u81ea\u7136\u8bed\u8a00\u8fd4\u56de\u54cd\u5e94\u3002\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u4f7f\u7528\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884cNLP\u5904\u7406\uff0c\u5e76\u5229\u7528\u9002\u5408\u52a8\u6001\u8fde\u63a5\u7f51\u7edc\u7684\u56fe\u5f62\u6570\u636e\u5e93\u3002", "result": "\u6211\u4eec\u8bc4\u4f30\u4e86\u51e0\u79cd\u4e2d\u578bLLMs\u5904\u7406\u6570\u636e\u5e93\u67e5\u8be2\u4efb\u52a1\uff0c\u7ed3\u679c\u663e\u793aLlama 3.1\uff08\u62e5\u670980\u4ebf\u53c2\u6570\uff09\u5728\u6240\u6709\u6307\u6807\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002\u6700\u663e\u8457\u7684\u662f\uff0c\u6211\u4eec\u7684\u4e24\u6b65\u65b9\u6cd5\u4e0e\u5f53\u524d\u65b9\u6cd5\u4e0d\u540c\uff0c\u5b83\u653e\u5bbd\u4e86\u751f\u6210\u7684Cypher\u67e5\u8be2\u4e0e\u771f\u5b9e\u4ee3\u7801\u7684\u7cbe\u786e\u5339\u914d\uff08EM\uff09\u8981\u6c42\uff0c\u4ece\u800c\u5b9e\u73b0\u4e8619.4%\u7684\u51c6\u786e\u5ea6\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e3a\u90e8\u7f72\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5230\u8fb9\u7f18\u8bbe\u5907\u4e0a\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u4f7f\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u4e0e\u5305\u542b\u4fe1\u606f\u5bf9\u8c61\u7684\u6570\u636e\u5e93\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\uff0c\u4ee5\u652f\u6301\u5173\u952e\u51b3\u7b56\u3002"}}
{"id": "2506.06297", "pdf": "https://arxiv.org/pdf/2506.06297", "abs": "https://arxiv.org/abs/2506.06297", "authors": ["Bozhi Sun", "Seda Tierney", "Jeffrey A. Feinstein", "Frederick Damen", "Alison L. Marsden", "Daniele E. Schiavazzi"], "title": "Optimal patient allocation for echocardiographic assessments", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scheduling echocardiographic exams in a hospital presents significant\nchallenges due to non-deterministic factors (e.g., patient no-shows, patient\narrival times, diverse exam durations, etc.) and asymmetric resource\nconstraints between fetal and non-fetal patient streams. To address these\nchallenges, we first conducted extensive pre-processing on one week of\noperational data from the Echo Laboratory at Stanford University's Lucile\nPackard Children's Hospital, to estimate patient no-show probabilities and\nderive empirical distributions of arrival times and exam durations. Based on\nthese inputs, we developed a discrete-event stochastic simulation model using\nSimPy, and integrate it with the open source Gymnasium Python library. As a\nbaseline for policy optimization, we developed a comparative framework to\nevaluate on-the-fly versus reservation-based allocation strategies, in which\ndifferent proportions of resources are reserved in advance. Considering a\nhospital configuration with a 1:6 ratio of fetal to non-fetal rooms and a 4:2\nratio of fetal to non-fetal sonographers, we show that on-the-fly allocation\ngenerally yields better performance, more effectively adapting to patient\nvariability and resource constraints. Building on this foundation, we apply\nreinforcement learning (RL) to derive an approximated optimal dynamic\nallocation policy. This RL-based policy is benchmarked against the\nbest-performing rule-based strategies, allowing us to quantify their\ndifferences and provide actionable insights for improving echo lab efficiency\nthrough intelligent, data-driven resource management.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u533b\u9662\u8d85\u58f0\u5fc3\u52a8\u56fe\u68c0\u67e5\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u5b9e\u65f6\u7b56\u7565\u80fd\u66f4\u597d\u9002\u5e94\u53d8\u5316\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5b89\u6392\u533b\u9662\u91cc\u7684\u8d85\u58f0\u5fc3\u52a8\u56fe\u68c0\u67e5\u5b58\u5728\u8bb8\u591a\u6311\u6218\uff0c\u5305\u62ec\u60a3\u8005\u672a\u51fa\u73b0\u3001\u5230\u8fbe\u65f6\u95f4\u3001\u68c0\u67e5\u65f6\u95f4\u4e0d\u786e\u5b9a\u7b49\u56e0\u7d20\uff0c\u4ee5\u53ca\u80ce\u513f\u4e0e\u975e\u80ce\u513f\u75c5\u60a3\u8d44\u6e90\u7684\u975e\u5bf9\u79f0\u7ea6\u675f\u3002", "method": "\u5229\u7528SimPy\u5e93\u5f00\u53d1\u4e86\u79bb\u6563\u4e8b\u4ef6\u968f\u673a\u6a21\u62df\u6a21\u578b\uff0c\u5e76\u4e0eGymnasium Python\u5e93\u96c6\u6210\u3002\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u65f6\u5206\u914d\u548c\u9884\u7ea6\u5206\u914d\u7b56\u7565\uff0c\u5bf9\u8d44\u6e90\u5206\u914d\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "\u5b9e\u65f6\u5206\u914d\u7b56\u7565\u8868\u73b0\u66f4\u4f73\uff0c\u66f4\u6709\u6548\u5730\u9002\u5e94\u4e86\u60a3\u8005\u7684\u53d8\u52a8\u548c\u8d44\u6e90\u7684\u7ea6\u675f\u3002\u57fa\u4e8e\u6b64\uff0c\u5e94\u7528\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u63a8\u5bfc\u8fd1\u4f3c\u6700\u4f18\u52a8\u6001\u5206\u914d\u7b56\u7565\uff0c\u5e76\u4e0e\u6700\u4f73\u89c4\u5219\u7b56\u7565\u8fdb\u884c\u6bd4\u8f83\u3002", "conclusion": "\u901a\u8fc7\u667a\u80fd\u5316\u3001\u6570\u636e\u9a71\u52a8\u7684\u8d44\u6e90\u7ba1\u7406\uff0c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8d85\u58f0\u5fc3\u52a8\u56fe\u5b9e\u9a8c\u5ba4\u6548\u7387\u3002"}}
{"id": "2506.06352", "pdf": "https://arxiv.org/pdf/2506.06352", "abs": "https://arxiv.org/abs/2506.06352", "authors": ["Christian Tarsney"], "title": "Will artificial agents pursue power by default?", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "Researchers worried about catastrophic risks from advanced AI have argued\nthat we should expect sufficiently capable AI agents to pursue power over\nhumanity because power is a convergent instrumental goal, something that is\nuseful for a wide range of final goals. Others have recently expressed\nskepticism of these claims. This paper aims to formalize the concepts of\ninstrumental convergence and power-seeking in an abstract, decision-theoretic\nframework, and to assess the claim that power is a convergent instrumental\ngoal. I conclude that this claim contains at least an element of truth, but\nmight turn out to have limited predictive utility, since an agent's options\ncannot always be ranked in terms of power in the absence of substantive\ninformation about the agent's final goals. However, the fact of instrumental\nconvergence is more predictive for agents who have a good shot at attaining\nabsolute or near-absolute power.", "AI": {"tldr": "\u672c\u6587\u5f62\u5f0f\u5316\u4e86\u5de5\u5177\u4f1a\u805a\u548c\u6743\u529b\u8ffd\u6c42\u7684\u6982\u5ff5\uff0c\u63a2\u8ba8\u4e86\u6743\u529b\u4f5c\u4e3a\u4f1a\u805a\u5de5\u5177\u76ee\u6807\u7684\u5b9e\u7528\u6027\uff0c\u5f97\u51fa\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u8fd9\u4e00\u6982\u5ff5\u66f4\u5177\u9884\u6d4b\u6027\u3002", "motivation": "\u7814\u7a76\u4eba\u5458\u62c5\u5fc3\u6765\u81ea\u5148\u8fdbAI\u7684\u707e\u96be\u6027\u98ce\u9669\uff0c\u4ed6\u4eec\u8ba4\u4e3a\u6211\u4eec\u5e94\u8be5\u9884\u671f\u5177\u6709\u8db3\u591f\u80fd\u529b\u7684AI\u4ee3\u7406\u4f1a\u8ffd\u6c42\u5bf9\u4eba\u7c7b\u7684\u6743\u529b\uff0c\u56e0\u4e3a\u6743\u529b\u662f\u4e00\u4e2a\u4f1a\u805a\u5de5\u5177\u76ee\u6807\uff0c\u5bf9\u5e7f\u6cdb\u7684\u6700\u7ec8\u76ee\u6807\u90fd\u6709\u7528\u3002", "method": "\u672c\u6587\u65e8\u5728\u5728\u4e00\u4e2a\u62bd\u8c61\u7684\u3001\u51b3\u7b56\u7406\u8bba\u7684\u6846\u67b6\u5185\u5f62\u5f0f\u5316\u5de5\u5177\u4f1a\u805a\u548c\u5bfb\u6c42\u6743\u529b\u7684\u6982\u5ff5\uff0c\u5e76\u8bc4\u4f30\u6743\u529b\u4f5c\u4e3a\u4f1a\u805a\u5de5\u5177\u76ee\u6807\u7684\u4e3b\u5f20\u3002", "result": "\u6743\u529b\u4f5c\u4e3a\u4f1a\u805a\u5de5\u5177\u76ee\u6807\u7684\u4e3b\u5f20\u5305\u542b\u771f\u5b9e\u4f46\u6709\u9650\u7684\u9884\u6d4b\u5b9e\u7528\u6027\uff0c\u4f1a\u805a\u5de5\u5177\u7684\u4e8b\u5b9e\u5bf9\u90a3\u4e9b\u6709\u671b\u83b7\u5f97\u7edd\u5bf9\u6743\u529b\u7684\u4ee3\u7406\u66f4\u5177\u6709\u9884\u6d4b\u610f\u4e49\u3002", "conclusion": "\u867d\u7136\u6743\u529b\u662f\u4e00\u4e2a\u4f1a\u805a\u5de5\u5177\u76ee\u6807\u8fd9\u4e00\u8bf4\u6cd5\u5305\u542b\u4e00\u5b9a\u7684\u771f\u5b9e\u6027\uff0c\u4f46\u53ef\u80fd\u5728\u9884\u6d4b\u7684\u5b9e\u7528\u6027\u4e0a\u6709\u9650\uff0c\u56e0\u4e3a\u5728\u7f3a\u4e4f\u6709\u5173\u4ee3\u7406\u6700\u7ec8\u76ee\u6807\u7684\u5b9e\u8d28\u4fe1\u606f\u65f6\uff0c\u4e00\u4e2a\u4ee3\u7406\u7684\u9009\u62e9\u65e0\u6cd5\u603b\u662f\u4ee5\u6743\u529b\u8fdb\u884c\u6392\u540d\u3002\u7136\u800c\uff0c\u5bf9\u90a3\u4e9b\u6709\u53ef\u80fd\u83b7\u5f97\u7edd\u5bf9\u6216\u63a5\u8fd1\u7edd\u5bf9\u6743\u529b\u7684\u4ee3\u7406\u800c\u8a00\uff0c\u4f1a\u805a\u5de5\u5177\u7684\u4e8b\u5b9e\u66f4\u5177\u9884\u6d4b\u6027\u3002"}}
{"id": "2506.06474", "pdf": "https://arxiv.org/pdf/2506.06474", "abs": "https://arxiv.org/abs/2506.06474", "authors": ["Everett Richards", "Bipul Thapa", "Lena Mashayekhy"], "title": "Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.MA", "cs.NI", "I.4.8; I.2.10; I.2.11; I.2.9; C.2.4"], "comment": "This paper has been accepted to IEEE EDGE 2025. The final version\n  will be published in IEEE Xplore later this year", "summary": "Accurate and reliable object detection is critical for ensuring the safety\nand efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board\nperception systems have limited accuracy due to occlusions and blind spots,\nwhile cloud-based solutions introduce significant latency, making them\nunsuitable for real-time processing demands required for autonomous driving in\ndynamic environments. To address these challenges, we introduce an innovative\nframework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that\nleverages edge computing and multi-CAV collaboration for real-time,\nmulti-perspective object detection. Our ECOD framework integrates two key\nalgorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and\nVariable Object Tally and Evaluation (VOTE). PACE aggregates detection data\nfrom multiple CAVs on an edge server to enhance perception in scenarios where\nindividual CAVs have limited visibility. VOTE utilizes a consensus-based voting\nmechanism to improve the accuracy of object classification by integrating data\nfrom multiple CAVs. Both algorithms are designed at the edge to operate in\nreal-time, ensuring low-latency and reliable decision-making for CAVs. We\ndevelop a hardware-based controlled testbed consisting of camera-equipped\nrobotic CAVs and an edge server to evaluate the efficacy of our framework. Our\nexperimental results demonstrate the significant benefits of ECOD in terms of\nimproved object classification accuracy, outperforming traditional\nsingle-perspective onboard approaches by up to 75%, while ensuring low-latency,\nedge-driven real-time processing. This research highlights the potential of\nedge computing to enhance collaborative perception for latency-sensitive\nautonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fb9\u7f18\u542f\u7528\u7684\u534f\u4f5c\u7269\u4f53\u68c0\u6d4b\u6846\u67b6\uff08ECOD\uff09\uff0c\u901a\u8fc7\u611f\u77e5\u805a\u5408\u4e0e\u534f\u4f5c\u4f30\u8ba1\u3001\u53ef\u53d8\u5bf9\u8c61\u8ba1\u6570\u4e0e\u8bc4\u4f30\u7b97\u6cd5\u5b9e\u73b0\u591a\u89c6\u89d2\u7269\u4f53\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u5b9e\u65f6\u6027\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f7d\u611f\u77e5\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u53d7\u963b\u4e8e\u906e\u6321\u548c\u76f2\u533a\uff0c\u800c\u4e91\u7aef\u89e3\u51b3\u65b9\u6848\u7684\u9ad8\u5ef6\u8fdf\u4f7f\u5176\u4e0d\u9002\u5408\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u52a8\u9a7e\u9a76\u7684\u5b9e\u65f6\u5904\u7406\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u591f\u589e\u5f3a\u68c0\u6d4b\u7cbe\u5ea6\u53c8\u80fd\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u8fb9\u7f18\u542f\u7528\u7684\u534f\u4f5c\u7269\u4f53\u68c0\u6d4b(ECOD)\u6846\u67b6\uff0c\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u7b97\u6cd5\uff1a\u611f\u77e5\u805a\u5408\u4e0e\u534f\u4f5c\u4f30\u8ba1(PACE)\u548c\u53ef\u53d8\u5bf9\u8c61\u8ba1\u6570\u4e0e\u8bc4\u4f30(VOTE)\u3002\u5728\u8fb9\u7f18\u670d\u52a1\u5668\u4e0a\u805a\u5408\u6765\u81ea\u591a\u4e2aCAV\u7684\u68c0\u6d4b\u6570\u636e\u4ee5\u589e\u5f3a\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5171\u8bc6\u7684\u6295\u7968\u673a\u5236\u63d0\u5347\u7269\u4f53\u5206\u7c7b\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cECOD\u6846\u67b6\u5728\u7269\u4f53\u5206\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u8f66\u8f7d\u5355\u89c6\u89d2\u65b9\u6cd5\uff0c\u63d0\u5347\u5e45\u5ea6\u8fbe\u523075%\u3002", "conclusion": "ECOD\u6846\u67b6\u901a\u8fc7\u4f7f\u7528\u8fb9\u7f18\u8ba1\u7b97\u548c\u591aCAV\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86CAV\u7684\u7269\u4f53\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u6bd4\u4f20\u7edf\u5355\u4e00\u89c6\u89d2\u8f66\u8f7d\u65b9\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u63d0\u5347\u4e8675%\u3002"}}
{"id": "2506.06401", "pdf": "https://arxiv.org/pdf/2506.06401", "abs": "https://arxiv.org/abs/2506.06401", "authors": ["Hongming Yang", "Shi Lin", "Jun Shao", "Changting Lin", "Donghai Zhu", "Meng Han", "Qinglei Kong"], "title": "Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work is accepted at ACL 2025", "summary": "Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized\nmodels designed to run efficiently on consumer-grade hardware, offering\nsignificant advantages in resource efficiency, cost-effectiveness, and data\nprivacy. However, these models often struggle with limited inference and\nreasoning capabilities, which restrict their performance on complex tasks and\nlimit their practical applicability. Moreover, existing prompt optimization\nmethods typically rely on extensive manual effort or the meta-cognitive\nabilities of state-of-the-art LLMs, making them less effective for LwLLMs. To\naddress these challenges, we introduce DeBoP, a new Direct Behavior\nOptimization Paradigm, original from the Chain-of-Thought (CoT) prompting\ntechnique. Unlike CoT Prompting, DeBoP is an automatic optimization method,\nwhich focuses on the optimization directly on the behavior of LwLLMs. In\nparticular, DeBoP transforms the optimization of complex prompts into the\noptimization of discrete, quantifiable execution sequences using a\ngradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging\ntasks where state-of-the-art LLMs excel but LwLLMs generally underperform.\nExperimental results demonstrate that DeBoP significantly outperforms recent\nprompt optimization methods on most tasks. In particular, DeBoP-optimized\nLwLLMs surpass GPT-3.5 on most tasks while reducing computational time by\napproximately 60% compared to other automatic prompt optimization methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDeBoP\uff0c\u4e00\u79cd\u4f18\u5316\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5e76\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u8f7b\u91cf\u7ea7\u5927\u578b\u8bed\u8a00\u6a21\u578b(LwLLMs)\u7406\u8bba\u4e0a\u7684\u8d44\u6e90\u6548\u7387\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u9690\u79c1\u4f18\u70b9\u53d7\u5230\u5176\u6709\u9650\u7684\u63a8\u7406\u80fd\u529b\u7684\u9650\u5236\uff0c\u800c\u73b0\u6709\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u9700\u8981\u8017\u8d39\u5927\u91cf\u7684\u4eba\u5de5\u52aa\u529b\u6216\u4f9d\u8d56\u9876\u5c16\u7684LLMs\u8ba4\u77e5\u80fd\u529b\uff0c\u5bfc\u81f4\u5bf9LwLLMs\u7f3a\u4e4f\u6709\u6548\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u76f4\u63a5\u884c\u4e3a\u4f18\u5316\u8303\u5f0f(DeBoP)\uff0c\u8fd9\u662f\u6e90\u4e8e\u94fe\u5f0f\u601d\u7ef4(COT)\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u4f18\u5316\uff0c\u76f4\u63a5\u5173\u6ce8\u4e8eLwLLMs\u7684\u884c\u4e3a\u8fdb\u884c\u4f18\u5316\uff0c\u901a\u8fc7\u65e0\u68af\u5ea6\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u5c06\u590d\u6742\u7684\u63d0\u793a\u4f18\u5316\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u7684\u6267\u884c\u5e8f\u5217\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e03\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u4e2d\uff0cDeBoP\u663e\u8457\u4f18\u4e8e\u6700\u8fd1\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u3002\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e2d\uff0cDeBoP\u4f18\u5316\u7684LwLLMs\u8d85\u8d8a\u4e86GPT-3.5\uff0c\u540c\u65f6\u4e0e\u5176\u4ed6\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u7ea660%\u3002", "conclusion": "DeBoP\u4e3a\u4f18\u5316\u8f7b\u91cf\u7ea7\u6a21\u578b(LwLLMs)\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f7f\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u63a5\u8fd1\u751a\u81f3\u8d85\u8fc7\u66f4\u5f3a\u5927\u7684LLM\u3002"}}
{"id": "2506.06298", "pdf": "https://arxiv.org/pdf/2506.06298", "abs": "https://arxiv.org/abs/2506.06298", "authors": ["Daniel Halpern", "Evi Micha", "Ariel D. Procaccia", "Itai Shapira"], "title": "Pairwise Calibrated Rewards for Pluralistic Alignment", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current alignment pipelines presume a single, universal notion of desirable\nbehavior. However, human preferences often diverge across users, contexts, and\ncultures. As a result, disagreement collapses into the majority signal and\nminority perspectives are discounted. To address this, we propose reflecting\ndiverse human preferences through a distribution over multiple reward\nfunctions, each inducing a distinct aligned policy. The distribution is learned\ndirectly from pairwise preference without annotator identifiers or predefined\ngroups. Instead, annotator disagreements are treated as informative soft\nlabels. Our central criterion is pairwise calibration: for every pair of\ncandidate responses, the proportion of reward functions preferring one response\nmatches the fraction of annotators with that preference. We prove that even a\nsmall outlier-free ensemble can accurately represent diverse preference\ndistributions. Empirically, we introduce and validate a practical training\nheuristic to learn such ensembles, and demonstrate its effectiveness through\nimproved calibration, implying a more faithful representation of pluralistic\nvalues.", "AI": {"tldr": "\u901a\u8fc7\u591a\u79cd\u5956\u52b1\u51fd\u6570\u7684\u5206\u5e03\u53cd\u6620\u4eba\u7c7b\u504f\u597d\u7684\u591a\u6837\u6027\uff0c\u63d0\u51fa\u7684\u5b9e\u7528\u8bad\u7ec3\u542f\u53d1\u80fd\u591f\u63d0\u9ad8\u5bf9\u591a\u5143\u5316\u4ef7\u503c\u89c2\u7684\u5fe0\u5b9e\u8868\u73b0\u3002", "motivation": "\u76ee\u524d\u7684\u5bf9\u9f50\u7ba1\u9053\u5047\u5b9a\u7684\u552f\u4e00\u7edf\u4e00\u7684\u7406\u60f3\u884c\u4e3a\u672a\u5fc5\u80fd\u591f\u9002\u5e94\u7528\u6237\u3001\u60c5\u5883\u548c\u6587\u5316\u7684\u4e0d\u540c\u504f\u597d\uff0c\u4f7f\u5f97\u5c11\u6570\u7fa4\u4f53\u89c2\u70b9\u88ab\u5ffd\u89c6\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u901a\u8fc7\u591a\u79cd\u5956\u52b1\u51fd\u6570\u7684\u5206\u5e03\u6765\u53cd\u6620\u4eba\u7c7b\u504f\u597d\u7684\u591a\u6837\u6027\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6210\u5bf9\u6821\u51c6\u7684\u4e2d\u5fc3\u6807\u51c6\uff0c\u901a\u8fc7\u4e00\u7ec4\u5956\u52b1\u51fd\u6570\u7684\u5206\u5e03\u6765\u53cd\u6620\u591a\u79cd\u4eba\u7c7b\u504f\u597d\u3002\u8fd9\u4e9b\u51fd\u6570\u4ece\u6210\u5bf9\u504f\u597d\u4e2d\u76f4\u63a5\u5b66\u4e60\uff0c\u800c\u65e0\u9700\u6807\u6ce8\u8005\u8eab\u4efd\u6216\u9884\u5b9a\u4e49\u7ec4\u3002\u504f\u597d\u4e2d\u7684\u5206\u6b67\u88ab\u89c6\u4e3a\u6709\u610f\u4e49\u7684\u8f6f\u6807\u7b7e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u8bad\u7ec3\u542f\u53d1\u6765\u5b66\u4e60\u8fd9\u79cd\u96c6\u6210\u6a21\u578b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u6821\u51c6\u6765\u63d0\u5347\u5bf9\u591a\u5143\u5316\u4ef7\u503c\u89c2\u7684\u5fe0\u5b9e\u8868\u73b0\u3002", "conclusion": "\u5373\u4f7f\u662f\u5728\u53ea\u6709\u5c11\u6570\u975e\u5f02\u5e38\u4e2a\u4f53\u7684\u60c5\u51b5\u4e0b\uff0c\u96c6\u6210\u6a21\u578b\u4e5f\u80fd\u591f\u51c6\u786e\u5730\u4ee3\u8868\u591a\u6837\u5316\u7684\u504f\u597d\u5206\u5e03\u3002\u63d0\u51fa\u7684\u8bad\u7ec3\u542f\u53d1\u7b97\u6cd5\u88ab\u9a8c\u8bc1\u6709\u6548\uff0c\u80fd\u591f\u66f4\u597d\u53cd\u6620\u591a\u5143\u5316\u7684\u4ef7\u503c\u89c2\u3002"}}
{"id": "2506.06367", "pdf": "https://arxiv.org/pdf/2506.06367", "abs": "https://arxiv.org/abs/2506.06367", "authors": ["Jiaxin Pan", "Mojtaba Nayyeri", "Osama Mohammed", "Daniel Hernandez", "Rongchuan Zhang", "Cheng Cheng", "Steffen Staab"], "title": "Towards Foundation Model on Temporal Knowledge Graph Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Temporal Knowledge Graphs (TKGs) store temporal facts with quadruple formats\n(s, p, o, t). Existing Temporal Knowledge Graph Embedding (TKGE) models perform\nlink prediction tasks in transductive or semi-inductive settings, which means\nthe entities, relations, and temporal information in the test graph are fully\nor partially observed during training. Such reliance on seen elements during\ninference limits the models' ability to transfer to new domains and generalize\nto real-world scenarios. A central limitation is the difficulty in learning\nrepresentations for entities, relations, and timestamps that are transferable\nand not tied to dataset-specific vocabularies. To overcome these limitations,\nwe introduce the first fully-inductive approach to temporal knowledge graph\nlink prediction. Our model employs sinusoidal positional encodings to capture\nfine-grained temporal patterns and generates adaptive entity and relation\nrepresentations using message passing conditioned on both local and global\ntemporal contexts. Our model design is agnostic to temporal granularity and\ntime span, effectively addressing temporal discrepancies across TKGs and\nfacilitating time-aware structural information transfer. As a pretrained,\nscalable, and transferable model, POSTRA demonstrates strong zero-shot\nperformance on unseen temporal knowledge graphs, effectively generalizing to\nnovel entities, relations, and timestamps. Extensive theoretical analysis and\nempirical results show that a single pretrained model can improve zero-shot\nperformance on various inductive temporal reasoning scenarios, marking a\nsignificant step toward a foundation model for temporal KGs.", "AI": {"tldr": "\u5f15\u5165\u4e86\u4e00\u79cd\u5b8c\u5168\u5f52\u7eb3\u7684\u65f6\u95f4\u77e5\u8bc6\u56fe\u94fe\u63a5\u9884\u6d4b\u65b9\u6cd5POSTRA\uff0c\u5229\u7528\u6b63\u5f26\u4f4d\u7f6e\u7f16\u7801\u548c\u6d88\u606f\u4f20\u9012\uff0c\u5b9e\u73b0\u96f6\u6837\u672c\u63a8\u7406\u548c\u5e7f\u6cdb\u7684\u65f6\u95f4\u7ed3\u6784\u4fe1\u606f\u8f6c\u79fb\u3002", "motivation": "\u73b0\u6709\u7684\u8f6c\u6362\u6027\u6216\u534a\u5f52\u7eb3\u6027Temporal Knowledge Graph Embedding (TKGE)\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u4f9d\u8d56\u4e8e\u8bad\u7ec3\u4e2d\u5b8c\u5168\u6216\u90e8\u5206\u89c2\u5bdf\u5230\u7684\u5143\u7d20\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u8f6c\u79fb\u5230\u65b0\u9886\u57df\u5e76\u63a8\u5e7f\u5230\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7684\u80fd\u529b\u3002\u9700\u8981\u514b\u670d\u8fd9\u4e00\u9650\u5236\u4ee5\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "method": "\u4f7f\u7528\u6b63\u5f26\u4f4d\u7f6e\u7f16\u7801\u6355\u6349\u7ec6\u7c92\u5ea6\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u5728\u5c40\u90e8\u548c\u5168\u5c40\u65f6\u95f4\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u6d88\u606f\u4f20\u9012\u751f\u6210\u81ea\u9002\u5e94\u5b9e\u4f53\u548c\u5173\u7cfb\u8868\u793a\u3002", "result": "\u5355\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u80fd\u591f\u5728\u5404\u79cd\u5f52\u7eb3\u65f6\u95f4\u63a8\u7406\u573a\u666f\u4e2d\u63d0\u9ad8\u96f6\u6837\u672c\u8868\u73b0\uff0c\u6807\u5fd7\u7740\u671d\u65f6\u95f4\u77e5\u8bc6\u56fe\u57fa\u7840\u6a21\u578b\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002", "conclusion": "POSTRA\u662f\u4e00\u79cd\u9884\u8bad\u7ec3\u7684\u3001\u53ef\u6269\u5c55\u7684\u3001\u53ef\u8f6c\u79fb\u7684\u6a21\u578b\uff0c\u5728\u770b\u4e0d\u89c1\u7684\u65f6\u95f4\u77e5\u8bc6\u56fe\u4e0a\u7684\u96f6\u6837\u672c\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u63a8\u5e7f\u5230\u65b0\u5b9e\u4f53\u3001\u5173\u7cfb\u548c\u65f6\u95f4\u6233\u3002"}}
{"id": "2506.06541", "pdf": "https://arxiv.org/pdf/2506.06541", "abs": "https://arxiv.org/abs/2506.06541", "authors": ["Eugenie Lai", "Gerardo Vitagliano", "Ziyu Zhang", "Sivaprasad Sudhir", "Om Chabra", "Anna Zeng", "Anton A. Zabreyko", "Chenning Li", "Ferdi Kossmann", "Jialin Ding", "Jun Chen", "Markos Markakis", "Matthew Russo", "Weiyang Wang", "Ziniu Wu", "Michael J. Cafarella", "Lei Cao", "Samuel Madden", "Tim Kraska"], "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "categories": ["cs.DB", "cs.AI", "cs.MA"], "comment": null, "summary": "Constructing real-world data-to-insight pipelines often involves data\nextraction from data lakes, data integration across heterogeneous data sources,\nand diverse operations from data cleaning to analysis. The design and\nimplementation of data science pipelines require domain knowledge, technical\nexpertise, and even project-specific insights. AI systems have shown remarkable\nreasoning, coding, and understanding capabilities. However, it remains unclear\nto what extent these capabilities translate into successful design and\nexecution of such complex pipelines. We introduce KRAMABENCH: a benchmark\ncomposed of 104 manually-curated real-world data science pipelines spanning\n1700 data files from 24 data sources in 6 different domains. We show that these\npipelines test the end-to-end capabilities of AI systems on data processing,\nrequiring data discovery, wrangling and cleaning, efficient processing,\nstatistical reasoning, and orchestrating data processing steps given a\nhigh-level task. Our evaluation tests 5 general models and 3 code generation\nmodels using our reference framework, DS-GURU, which instructs the AI model to\ndecompose a question into a sequence of subtasks, reason through each step, and\nsynthesize Python code that implements the proposed design. Our results on\nKRAMABENCH show that, although the models are sufficiently capable of solving\nwell-specified data science code generation tasks, when extensive data\nprocessing and domain knowledge are required to construct real-world data\nscience pipelines, existing out-of-box models fall short. Progress on\nKramaBench represents crucial steps towards developing autonomous data science\nagents for real-world applications. Our code, reference framework, and data are\navailable at https://github.com/mitdbg/KramaBench.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e00\u4e2a\u540d\u4e3aKRAMABENCH\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u4e2d\u7684\u6027\u80fd\uff0c\u7ed3\u679c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u5904\u7406\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u65f6\u8fd8\u6709\u5f85\u5b8c\u5584\u3002", "motivation": "\u8bbe\u8ba1\u548c\u5b9e\u73b0\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u9700\u8981\u9886\u57df\u77e5\u8bc6\u3001\u6280\u672f\u4e13\u957f\u548c\u9879\u76ee\u7279\u5b9a\u7684\u89c1\u89e3\u3002\u5c3d\u7ba1AI\u7cfb\u7edf\u5728\u63a8\u7406\u3001\u7f16\u7801\u548c\u7406\u89e3\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8fd9\u4e9b\u80fd\u529b\u80fd\u5426\u6210\u529f\u5730\u8f6c\u5316\u4e3a\u590d\u6742\u7ba1\u9053\u7684\u8bbe\u8ba1\u548c\u6267\u884c\u5c1a\u4e0d\u786e\u5b9a\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aKRAMABENCH\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec104\u4e2a\u624b\u52a8\u6574\u7406\u7684\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u79d1\u5b66\u7ba1\u9053\uff0c\u6d89\u53ca1700\u4e2a\u6570\u636e\u6587\u4ef6\uff0c\u6765\u81ea6\u4e2a\u4e0d\u540c\u9886\u57df\u768424\u4e2a\u6570\u636e\u6e90\u3002\u6b64\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u6570\u636e\u5904\u7406\u4e2d\u7684\u7aef\u5230\u7aef\u80fd\u529b\uff0c\u6d4b\u8bd5\u4e865\u4e2a\u901a\u7528\u6a21\u578b\u548c3\u4e2a\u4ee3\u7801\u751f\u6210\u6a21\u578b\u3002\u4f7f\u7528\u53c2\u8003\u6846\u67b6DS-GURU\u6307\u5bfcAI\u6a21\u578b\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u6bcf\u4e00\u6b65\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u5408\u6210\u5b9e\u73b0\u6240\u8bbe\u8ba1\u7684Python\u4ee3\u7801\u3002", "result": "\u5728KRAMABENCH\u4e0a\u7684\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u9700\u8981\u5e7f\u6cdb\u7684\u6570\u636e\u5904\u7406\u548c\u9886\u57df\u77e5\u8bc6\u65f6\uff0c\u73b0\u6709\u7684\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5730\u6784\u5efa\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u3002", "conclusion": "\u867d\u7136\u73b0\u6709\u7684AI\u6a21\u578b\u5728\u89e3\u51b3\u6570\u636e\u79d1\u5b66\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u5e7f\u6cdb\u7684\u6570\u636e\u5904\u7406\u548c\u9886\u57df\u77e5\u8bc6\u6765\u6784\u5efa\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u79d1\u5b66\u7ba1\u9053\u65f6\uff0c\u8fd9\u4e9b\u6a21\u578b\u8fd8\u4e0d\u591f\u5b8c\u5907\u3002"}}
{"id": "2506.06404", "pdf": "https://arxiv.org/pdf/2506.06404", "abs": "https://arxiv.org/abs/2506.06404", "authors": ["Sooyung Choi", "Jaehyeok Lee", "Xiaoyuan Yi", "Jing Yao", "Xing Xie", "JinYeong Bak"], "title": "Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "The application scope of Large Language Models (LLMs) continues to expand,\nleading to increasing interest in personalized LLMs that align with human\nvalues. However, aligning these models with individual values raises\nsignificant safety concerns, as certain values may correlate with harmful\ninformation. In this paper, we identify specific safety risks associated with\nvalue-aligned LLMs and investigate the psychological principles behind these\nchallenges. Our findings reveal two key insights. (1) Value-aligned LLMs are\nmore prone to harmful behavior compared to non-fine-tuned models and exhibit\nslightly higher risks in traditional safety evaluations than other fine-tuned\nmodels. (2) These safety issues arise because value-aligned LLMs genuinely\ngenerate text according to the aligned values, which can amplify harmful\noutcomes. Using a dataset with detailed safety categories, we find significant\ncorrelations between value alignment and safety risks, supported by\npsychological hypotheses. This study offers insights into the \"black box\" of\nvalue alignment and proposes in-context alignment methods to enhance the safety\nof value-aligned LLMs.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4ef7\u503c\u5bf9\u9f50LLMs\u5728\u5b89\u5168\u6027\u65b9\u9762\u7684\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u4ee5\u4fc3\u8fdb\u5176\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740LLMs\u7684\u5e94\u7528\u8303\u56f4\u4e0d\u65ad\u6269\u5c55\uff0c\u4e2a\u6027\u5316\u7684LLMs\u5bf9\u9f50\u5230\u4eba\u7c7b\u4ef7\u503c\u89c2\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5174\u8da3\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5bf9\u9f50\u4e5f\u5e26\u6765\u4e86\u91cd\u5927\u7684\u5b89\u5168\u9690\u60a3\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6df1\u5165\u7684\u7814\u7a76\u4e0e\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5305\u542b\u8be6\u7ec6\u5b89\u5168\u7c7b\u522b\u7684\u6570\u636e\u96c6\u6765\u5206\u6790\u4ef7\u503c\u5bf9\u9f50\u4e0e\u5b89\u5168\u98ce\u9669\u4e4b\u95f4\u7684\u663e\u8457\u76f8\u5173\u6027\uff0c\u5e76\u652f\u6301\u5176\u5fc3\u7406\u5047\u8bbe\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ef7\u503c\u5bf9\u9f50\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6bd4\u672a\u5fae\u8c03\u6a21\u578b\u66f4\u5bb9\u6613\u4ea7\u751f\u6709\u5bb3\u884c\u4e3a\uff0c\u5e76\u4e14\u5728\u4f20\u7edf\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\u98ce\u9669\u7565\u9ad8\u4e8e\u5176\u4ed6\u5fae\u8c03\u6a21\u578b\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u4ef7\u503c\u5bf9\u9f50\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u6f5c\u5728\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u5bf9\u9f50\u7684\u65b9\u6cd5\u4ee5\u589e\u5f3a\u5176\u5b89\u5168\u6027\u3002"}}
{"id": "2506.06300", "pdf": "https://arxiv.org/pdf/2506.06300", "abs": "https://arxiv.org/abs/2506.06300", "authors": ["Yuanye Zhou", "Zhaokun Wang", "Kai Zhou", "Hui Tang", "Xiaofan Li"], "title": "LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful meshless\ntool for topology optimization, capable of simultaneously determining optimal\ntopologies and physical solutions. However, conventional PINNs rely on\ndensity-based topology descriptions, which necessitate manual interpolation and\nlimit their applicability to complex geometries. To address this, we propose\nLagrangian topology-conscious PINNs (LT-PINNs), a novel framework for\nboundary-focused engineering optimization. By parameterizing the control\nvariables of topology boundary curves as learnable parameters, LT-PINNs\neliminate the need for manual interpolation and enable precise boundary\ndetermination. We further introduce specialized boundary condition loss\nfunction and topology loss function to ensure sharp and accurate boundary\nrepresentations, even for intricate topologies. The accuracy and robustness of\nLT-PINNs are validated via two types of partial differential equations (PDEs),\nincluding elastic equation with Dirichlet boundary conditions and Laplace's\nequation with Neumann boundary conditions. Furthermore, we demonstrate\neffectiveness of LT-PINNs on more complex time-dependent and time-independent\nflow problems without relying on measurement data, and showcase their\nengineering application potential in flow velocity rearrangement, transforming\na uniform upstream velocity into a sine-shaped downstream profile. The results\ndemonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors\ncompared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2)\nLT-PINNs can handle arbitrary boundary conditions, making them suitable for a\nwide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries\nwithout manual interpolation, especially for complex topologies.", "AI": {"tldr": "LT-PINNs\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u624b\u52a8\u63d2\u503c\u7684\u8fb9\u754c\u4f18\u5316\u65b0\u65b9\u6cd5\uff0c\u5728\u590d\u6742\u62d3\u6251\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u7684PINNs\u4f9d\u8d56\u57fa\u4e8e\u5bc6\u5ea6\u7684\u62d3\u6251\u63cf\u8ff0\uff0c\u9700\u624b\u52a8\u63d2\u503c\uff0c\u4e14\u4e0d\u9002\u7528\u4e8e\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u3002\u63d0\u51faLT-PINNs\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u7cbe\u786e\u8fb9\u754c\u7684\u786e\u5b9a\u3002", "method": "LT-PINNs\u901a\u8fc7\u5c06\u62d3\u6251\u8fb9\u754c\u66f2\u7ebf\u7684\u63a7\u5236\u53d8\u91cf\u53c2\u6570\u5316\u4e3a\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u6d88\u9664\u4e86\u624b\u52a8\u63d2\u503c\u7684\u9700\u6c42\u3002\u5f15\u5165\u4e86\u7279\u6b8a\u7684\u8fb9\u754c\u6761\u4ef6\u635f\u5931\u51fd\u6570\u548c\u62d3\u6251\u635f\u5931\u51fd\u6570\u4ee5\u786e\u4fdd\u7cbe\u786e\u7684\u8fb9\u754c\u8868\u793a\u3002", "result": "LT-PINNs\u5728\u76f8\u8f83\u4e8eDT-PINNs\u5177\u6709\u66f4\u4f4e\u7684\u76f8\u5bf9L2\u8bef\u5dee\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u8fb9\u754c\u6761\u4ef6\uff0c\u5e76\u4e14\u5728\u590d\u6742\u62d3\u6251\u6761\u4ef6\u4e0b\u65e0\u9700\u624b\u52a8\u63d2\u503c\u5373\u53ef\u63a8\u65ad\u51fa\u6e05\u6670\u7684\u62d3\u6251\u8fb9\u754c\u3002", "conclusion": "LT-PINNs\u5728\u5904\u7406\u590d\u6742\u62d3\u6251\u7ed3\u6784\u7684\u8fb9\u754c\u4f18\u5316\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4e0d\u9700\u8981\u624b\u52a8\u63d2\u503c\uff0c\u80fd\u591f\u6709\u6548\u63a8\u65ad\u51fa\u6e05\u6670\u7684\u62d3\u6251\u8fb9\u754c\u3002"}}
{"id": "2506.06470", "pdf": "https://arxiv.org/pdf/2506.06470", "abs": "https://arxiv.org/abs/2506.06470", "authors": ["Yanwei Ren", "Haotian Zhang", "Fuxiang Wu", "Jiayan Qiu", "Jiaxing Huang", "Baosheng Yu", "Liu Liu"], "title": "SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Enhancing large language models by simply scaling up datasets has begun to\nyield diminishing returns, shifting the spotlight to data quality. Monte Carlo\nTree Search (MCTS) has emerged as a powerful technique for generating\nhigh-quality chain-of-thought data, yet conventional approaches typically\nretain only the top-scoring trajectory from the search tree, discarding sibling\nnodes that often contain valuable partial insights, recurrent error patterns,\nand alternative reasoning strategies. This unconditional rejection of\nnon-optimal reasoning branches may waste vast amounts of informative data in\nthe whole search tree. We propose SIGMA (Sibling Guided Monte Carlo\nAugmentation), a novel framework that reintegrates these discarded sibling\nnodes to refine LLM reasoning. SIGMA forges semantic links among sibling nodes\nalong each search path and applies a two-stage refinement: a critique model\nidentifies overlooked strengths and weaknesses across the sibling set, and a\nrevision model conducts text-based backpropagation to refine the top-scoring\ntrajectory in light of this comparative feedback. By recovering and amplifying\nthe underutilized but valuable signals from non-optimal reasoning branches,\nSIGMA substantially improves reasoning trajectories. On the challenging MATH\nbenchmark, our SIGMA-tuned 7B model achieves 54.92% accuracy using only 30K\nsamples, outperforming state-of-the-art models trained on 590K samples. This\nresult highlights that our sibling-guided optimization not only significantly\nreduces data usage but also significantly boosts LLM reasoning.", "AI": {"tldr": "SIGMA optimizes LLMs by reintegrating discarded decision paths, improving accuracy efficiently on reasoning tasks.", "motivation": "Traditional Monte Carlo Tree Search discards non-optimal nodes, wasting potentially valuable data that could improve model reasoning by enhancing data quality rather than quantity.", "method": "SIGMA reintegrates discarded sibling nodes from Monte Carlo Tree Search, uses semantic links and a two-stage refinement model to improve reasoning paths in LLMs.", "result": "SIGMA improves a 7B model's accuracy to 54.92% on the MATH benchmark with only 30K samples, exceeding the performance of models trained with much larger datasets.", "conclusion": "SIGMA significantly enhances the reasoning capability of language models by leveraging non-optimal reasoning paths, providing efficient data use and improving performance on benchmarks."}}
{"id": "2506.06574", "pdf": "https://arxiv.org/pdf/2506.06574", "abs": "https://arxiv.org/abs/2506.06574", "authors": ["Suhana Bedi", "Iddah Mlauzi", "Daniel Shin", "Sanmi Koyejo", "Nigam H. Shah"], "title": "The Optimization Paradox in Clinical AI Multi-Agent Systems", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Multi-agent artificial intelligence systems are increasingly deployed in\nclinical settings, yet the relationship between component-level optimization\nand system-wide performance remains poorly understood. We evaluated this\nrelationship using 2,400 real patient cases from the MIMIC-CDM dataset across\nfour abdominal pathologies (appendicitis, pancreatitis, cholecystitis,\ndiverticulitis), decomposing clinical diagnosis into information gathering,\ninterpretation, and differential diagnosis. We evaluated single agent systems\n(one model performing all tasks) against multi-agent systems (specialized\nmodels for each task) using comprehensive metrics spanning diagnostic outcomes,\nprocess adherence, and cost efficiency. Our results reveal a paradox: while\nmulti-agent systems generally outperformed single agents, the\ncomponent-optimized or Best of Breed system with superior components and\nexcellent process metrics (85.5% information accuracy) significantly\nunderperformed in diagnostic accuracy (67.7% vs. 77.4% for a top multi-agent\nsystem). This finding underscores that successful integration of AI in\nhealthcare requires not just component level optimization but also attention to\ninformation flow and compatibility between agents. Our findings highlight the\nneed for end to end system validation rather than relying on component metrics\nalone.", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u4ec5\u4f9d\u9760\u7ec4\u4ef6\u4f18\u5316\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u6ce8\u91cd\u4fe1\u606f\u6d41\u548c\u517c\u5bb9\u6027\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u7ec4\u4ef6\u4f18\u5316\u4e0e\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u75282,400\u4e2a\u771f\u5b9e\u75c5\u4eba\u6848\u4f8b\uff0c\u5e76\u5c06\u4e34\u5e8a\u8bca\u65ad\u5206\u89e3\u4e3a\u4fe1\u606f\u6536\u96c6\u3001\u89e3\u91ca\u548c\u9274\u522b\u8bca\u65ad\u3002\u8bc4\u4f30\u4e86\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u4e0e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4e0d\u540c\u4efb\u52a1\u6267\u884c\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u4f18\u4e8e\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f46\u5373\u4f7f\u5177\u6709\u4f18\u79c0\u7ec4\u4ef6\u7684\u6700\u4f73\u7cfb\u7edf\u5728\u8bca\u65ad\u51c6\u786e\u7387\u4e0a\u4e5f\u8868\u73b0\u4e0d\u4f73\uff0c\u663e\u793a\u51fa\u4fe1\u606f\u6d41\u548c\u4ee3\u7406\u95f4\u517c\u5bb9\u6027\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u6210\u529f\u7684\u533b\u7597AI\u96c6\u6210\u4e0d\u4ec5\u9700\u8981\u7ec4\u4ef6\u7ea7\u7684\u4f18\u5316\uff0c\u8fd8\u9700\u8981\u91cd\u89c6\u4fe1\u606f\u6d41\u548c\u4ee3\u7406\u95f4\u7684\u517c\u5bb9\u6027\uff0c\u5e76\u4e14\u9700\u8981\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u7cfb\u7edf\u9a8c\u8bc1\u3002"}}
{"id": "2506.06406", "pdf": "https://arxiv.org/pdf/2506.06406", "abs": "https://arxiv.org/abs/2506.06406", "authors": ["Guoyang Xia", "Yifeng Ding", "Fengfa Li", "Lei Ren", "Chen Wei", "Fangxiang Feng", "Xiaojie Wang"], "title": "SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture of Experts (MoE) architectures have become a key approach for scaling\nlarge language models, with growing interest in extending them to multimodal\ntasks. Existing methods to build multimodal MoE models either incur high\ntraining costs or suffer from degraded language capabilities when adapting\npretrained models. To address this, we propose Soft ModalityAware Routing\n(SMAR), a novel regularization technique that uses Kullback Leibler divergence\nto control routing probability distributions across modalities, encouraging\nexpert specialization without modifying model architecture or heavily relying\non textual data. Experiments on visual instruction tuning show that SMAR\npreserves language ability at 86.6% retention with only 2.5% pure text,\noutperforming baselines while maintaining strong multimodal performance. Our\napproach offers a practical and efficient solution to balance modality\ndifferentiation and language capabilities in multimodal MoE models.", "AI": {"tldr": "We introduce SMAR, a technique for better multimodal MoE models, maintaining language capabilities efficiently without high costs.", "motivation": "Existing methods to build multimodal MoE models either incur high training costs or suffer from degraded language capabilities when adapting pretrained models.", "method": "We propose Soft Modality-Aware Routing (SMAR), a novel regularization technique using Kullback Leibler divergence to control routing probability distributions across modalities.", "result": "Experiments show that SMAR preserves language ability at 86.6% retention with only 2.5% pure text, outperforming baselines while maintaining strong multimodal performance.", "conclusion": "Our approach offers a practical and efficient solution to balance modality differentiation and language capabilities in multimodal MoE models."}}
{"id": "2506.06303", "pdf": "https://arxiv.org/pdf/2506.06303", "abs": "https://arxiv.org/abs/2506.06303", "authors": ["Kefan Song", "Amir Moeini", "Peng Wang", "Lei Gong", "Rohan Chandra", "Yanjun Qi", "Shangtong Zhang"], "title": "Reward Is Enough: LLMs Are In-Context Reinforcement Learners", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) is a human-designed framework for solving\nsequential decision making problems. In this work, we demonstrate that,\nsurprisingly, RL emerges in LLM's (Large Language Model) inference time -- a\nphenomenon known as in-context RL (ICRL). Specifically, we propose a novel\nmulti-round prompting framework called ICRL prompting. The goal is to prompt\nthe LLM to complete a task. After the LLM generates a response at the current\nround, we give numerical scalar feedbacks for the response, called the rewards.\nAt the next round, we prompt the LLM again with the same task and a context\nconsisting of all previous responses and rewards. We observe that the quality\nof the LLM's response increases as the context grows. In other words, the LLM\nis able to maximize the scalar reward signal in the inference time, just like\nan RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,\ncreative writing, and ScienceWorld) and demonstrate significant performance\nimprovements over baseline methods such as Self-Refine and Reflexion.\nSurprisingly, in some experiments the reward signals are generated by the LLM\nitself, yet performance improvements are still observed from ICRL prompting,\noffering a promising paradigm for scaling test-time compute.", "AI": {"tldr": "LLM\u80fd\u5728\u63a8\u7406\u65f6\u81ea\u6211\u4f18\u5316\uff0cICRL\u63d0\u793a\u663e\u8457\u6539\u5584\u5176\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u63a8\u7406\u65f6\u81ea\u7136\u5730\u8868\u73b0\u51fa\u7c7b\u4f3c\u5f3a\u5316\u5b66\u4e60\u7684\u73b0\u8c61\uff0c\u5e0c\u671b\u901a\u8fc7\u63d0\u793a\u673a\u5236\u63d0\u9ad8LLM\u7684\u4efb\u52a1\u5b8c\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aICRL\u63d0\u793a\u7684\u591a\u8f6e\u63d0\u793a\u6846\u67b6\uff0c\u901a\u8fc7\u5956\u52b1\u53cd\u9988\u9010\u6b65\u6539\u8fdbLLM\u5bf9\u4efb\u52a1\u7684\u56de\u5e94\u3002", "result": "ICRL\u63d0\u793a\u5728Game of 24\u3001\u521b\u610f\u5199\u4f5c\u3001ScienceWorld\u7b49\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0cICRL\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u5956\u52b1\u4fe1\u53f7\u7531LLM\u81ea\u8eab\u751f\u6210\u65f6\u4e5f\u80fd\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.06523", "pdf": "https://arxiv.org/pdf/2506.06523", "abs": "https://arxiv.org/abs/2506.06523", "authors": ["Sumanth Pillella"], "title": "Reinforcement Learning for Autonomous Warehouse Orchestration in SAP Logistics Execution: Redefining Supply Chain Agility", "categories": ["cs.AI"], "comment": "6 pages", "summary": "In an era of escalating supply chain demands, SAP Logistics Execution (LE) is\npivotal for managing warehouse operations, transportation, and delivery. This\nresearch introduces a pioneering framework leveraging reinforcement learning\n(RL) to autonomously orchestrate warehouse tasks in SAP LE, enhancing\noperational agility and efficiency. By modeling warehouse processes as dynamic\nenvironments, the framework optimizes task allocation, inventory movement, and\norder picking in real-time. A synthetic dataset of 300,000 LE transactions\nsimulates real-world warehouse scenarios, including multilingual data and\noperational disruptions. The analysis achieves 95% task optimization accuracy,\nreducing processing times by 60% compared to traditional methods.\nVisualizations, including efficiency heatmaps and performance graphs, guide\nagile warehouse strategies. This approach tackles data privacy, scalability,\nand SAP integration, offering a transformative solution for modern supply\nchains.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u4f18\u5316SAP LE\u4e2d\u7684\u4ed3\u5e93\u4efb\u52a1\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4efb\u52a1\u5904\u7406\u548c\u5b9e\u65f6\u4f18\u5316\u3002", "motivation": "\u5728\u4f9b\u5e94\u94fe\u9700\u6c42\u65e5\u76ca\u589e\u52a0\u7684\u65f6\u4ee3\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u7ba1\u7406\u4ed3\u5e93\u3001\u8fd0\u8f93\u548c\u4ea4\u8d27\u64cd\u4f5c\uff0c\u63d0\u5347\u4f9b\u5e94\u94fe\u7684\u6574\u4f53\u6548\u7387\u3002", "method": "\u7814\u7a76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5c06\u4ed3\u5e93\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u52a8\u6001\u73af\u5883\uff0c\u8fdb\u884c\u5b9e\u65f6\u7684\u4efb\u52a1\u5206\u914d\u3001\u5e93\u5b58\u79fb\u52a8\u548c\u8ba2\u5355\u62e3\u9009\u4f18\u5316\u3002", "result": "\u901a\u8fc7\u6a21\u62df30\u4e07\u6761LE\u4ea4\u6613\u7684\u5408\u6210\u6570\u636e\uff0c\u6846\u67b6\u5b9e\u73b0\u4e8695%\u7684\u4efb\u52a1\u4f18\u5316\u51c6\u786e\u6027\uff0c\u5904\u7406\u65f6\u95f4\u51cf\u5c11\u4e8660%\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f15\u5165\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316SAP LE\u4e2d\u7684\u4ed3\u5e93\u4efb\u52a1\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u64cd\u4f5c\u654f\u6377\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.06958", "pdf": "https://arxiv.org/pdf/2506.06958", "abs": "https://arxiv.org/abs/2506.06958", "authors": ["Chance Jiajie Li", "Jiayi Wu", "Zhenze Mo", "Ao Qu", "Yuhan Tang", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Jinhua Zhao", "Paul Liang", "Luis Alonso", "Kent Larson"], "title": "Position: Simulating Society Requires Simulating Thought", "categories": ["cs.CY", "cs.AI", "cs.MA"], "comment": null, "summary": "Simulating society with large language models (LLMs), we argue, requires more\nthan generating plausible behavior -- it demands cognitively grounded reasoning\nthat is structured, revisable, and traceable. LLM-based agents are increasingly\nused to emulate individual and group behavior -- primarily through prompting\nand supervised fine-tuning. Yet they often lack internal coherence, causal\nreasoning, and belief traceability -- making them unreliable for analyzing how\npeople reason, deliberate, or respond to interventions.\n  To address this, we present a conceptual modeling paradigm, Generative Minds\n(GenMinds), which draws from cognitive science to support structured belief\nrepresentations in generative agents. To evaluate such agents, we introduce the\nRECAP (REconstructing CAusal Paths) framework, a benchmark designed to assess\nreasoning fidelity via causal traceability, demographic grounding, and\nintervention consistency. These contributions advance a broader shift: from\nsurface-level mimicry to generative agents that simulate thought -- not just\nlanguage -- for social simulations.", "AI": {"tldr": "\u63d0\u51fa\u751f\u6210\u578b\u601d\u7ef4\uff08GenMinds\uff09\u548cRECAP\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u751f\u6210\u4ee3\u7406\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u7684\u8ba4\u77e5\u548c\u56e0\u679c\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684LLM-based\u4ee3\u7406\u5728\u6a21\u62df\u4e2a\u4eba\u548c\u7fa4\u4f53\u884c\u4e3a\u65f6\u7f3a\u4e4f\u5185\u90e8\u4e00\u81f4\u6027\u3001\u56e0\u679c\u63a8\u7406\u548c\u4fe1\u5ff5\u53ef\u8ffd\u6eaf\u6027\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u751f\u6210\u4ee3\u7406\u5728\u793e\u4f1a\u6a21\u62df\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u751f\u6210\u578b\u601d\u7ef4\uff08GenMinds\uff09\u53ca\u5176\u8bc4\u6d4b\u6846\u67b6RECAP\uff08\u91cd\u5efa\u56e0\u679c\u8def\u5f84\uff09\u6765\u652f\u6301\u751f\u6210\u4ee3\u7406\u4e2d\u7684\u7ed3\u6784\u5316\u8ba4\u77e5\u548c\u56e0\u679c\u5206\u6790\u3002", "result": "\u5f15\u5165\u4e86RECAP\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u4ee3\u7406\u7684\u63a8\u7406\u4fdd\u771f\u5ea6\u4ee5\u53ca\u56e0\u679c\u53ef\u8ffd\u8e2a\u6027\u3001\u4eba\u53e3\u7edf\u8ba1\u5b66\u57fa\u7840\u548c\u5e72\u9884\u4e00\u81f4\u6027\u3002\u8fd9\u5c06\u6a21\u62df\u601d\u7ef4\u800c\u4e0d\u4ec5\u4ec5\u662f\u8bed\u8a00\uff0c\u4ece\u800c\u66f4\u597d\u5730\u8fdb\u884c\u793e\u4f1a\u6a21\u62df\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u5ff5\u5efa\u6a21\u8303\u5f0f\uff0c\u5373\u751f\u6210\u578b\u601d\u7ef4\uff08GenMinds\uff09\uff0c\u7528\u4e8e\u901a\u8fc7\u4ece\u8ba4\u77e5\u79d1\u5b66\u501f\u9274\u6765\u652f\u6301\u751f\u6210\u4ee3\u7406\u4e2d\u7684\u7ed3\u6784\u5316\u4fe1\u5ff5\u8868\u793a\u3002"}}
{"id": "2506.06446", "pdf": "https://arxiv.org/pdf/2506.06446", "abs": "https://arxiv.org/abs/2506.06446", "authors": ["Ivi Chatzi", "Nina Corvelo Benz", "Stratis Tsirtsis", "Manuel Gomez-Rodriguez"], "title": "Canonical Autoregressive Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "State of the art large language models are trained using large amounts of\ntokens derived from raw text using what is called a tokenizer. Crucially, the\ntokenizer determines the (token) vocabulary a model will use during inference\nas well as, in principle, the (token) language. This is because, while the\ntoken vocabulary may allow for different tokenizations of a string, the\ntokenizer always maps the string to only one of these tokenizations--the\ncanonical tokenization. However, multiple lines of empirical evidence suggest\nthat large language models do not always generate canonical token sequences,\nand this comes with several negative consequences. In this work, we first show\nthat, to generate a canonical token sequence, a model needs to generate\n(partial) canonical token sequences at each step of the autoregressive\ngeneration process underpinning its functioning. Building upon this theoretical\nresult, we introduce canonical sampling, a simple and efficient sampling method\nthat precludes a given model from generating non-canonical token sequences.\nFurther, we also show that, in comparison with standard sampling, the\ndistribution of token sequences generated using canonical sampling is provably\ncloser to the true distribution of token sequences used during training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u786e\u4fdd\u8bed\u8a00\u6a21\u578b\u751f\u6210\u89c4\u8303\u5316\u7684token\u5e8f\u5217\uff0c\u6539\u5584\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u7684token\u5e8f\u5217\u53ef\u80fd\u5b58\u5728\u975e\u89c4\u8303\u5316\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u4e00\u4e9b\u8d1f\u9762\u540e\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u89c4\u8303\u5316\u91c7\u6837\u7684\u7b80\u5355\u9ad8\u6548\u91c7\u6837\u65b9\u6cd5\uff0c\u9632\u6b62\u6a21\u578b\u751f\u6210\u975e\u89c4\u8303\u5316\u7684token\u5e8f\u5217\u3002", "result": "\u6240\u63d0\u7684\u89c4\u8303\u5316\u91c7\u6837\u4ea7\u751f\u7684token\u5e8f\u5217\u5206\u5e03\u6bd4\u6807\u51c6\u91c7\u6837\u66f4\u63a5\u8fd1\u4e8e\u8bad\u7ec3\u65f6\u4f7f\u7528\u7684\u771f\u5b9etoken\u5e8f\u5217\u5206\u5e03\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u89c4\u8303\u5316\u91c7\u6837\uff0c\u53ef\u4ee5\u786e\u4fdd\u5728\u6bcf\u4e00\u6b65\u751f\u6210\u8fc7\u7a0b\u4e2d\u751f\u6210\u90e8\u5206\u89c4\u8303\u5316\u7684token\u5e8f\u5217\uff0c\u4ece\u800c\u6539\u8fdb\u6a21\u578b\u751f\u6210\u7ed3\u679c\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06327", "pdf": "https://arxiv.org/pdf/2506.06327", "abs": "https://arxiv.org/abs/2506.06327", "authors": ["Zilang Chen"], "title": "Wine Quality Prediction with Ensemble Trees: A Unified, Leak-Free Comparative Study", "categories": ["cs.LG"], "comment": "14pages, 7figures,2tables", "summary": "Accurate and reproducible wine-quality assessment is critical for production\ncontrol yet remains dominated by subjective, labour-intensive tasting panels.\nWe present the first unified benchmark of five ensemble learners (Random\nForest, Gradient Boosting, XGBoost, LightGBM, CatBoost) on the canonical Vinho\nVerde red- and white-wine datasets (1,599 and 4,898 instances, 11\nphysicochemical attributes). Our leakage-free workflow employs an 80:20\nstratified train-test split, five-fold StratifiedGroupKFold within the training\nset, per-fold standardisation, SMOTE-Tomek resampling, inverse-frequency cost\nweighting, Optuna hyper-parameter search (120-200 trials per model) and a\ntwo-stage feature-selection refit. Final scores on untouched test sets are\nreported with weighted F1 as the headline metric. Gradient Boosting achieves\nthe highest accuracy (weighted F1 0.693 +/- 0.028 for red and 0.664 +/- 0.016\nfor white), followed within three percentage points by Random Forest and\nXGBoost. Limiting each model to its five top-ranked variables lowers\ndimensionality by 55 percent while reducing weighted F1 by only 2.6 percentage\npoints for red and 3.0 percentage points for white, indicating that alcohol,\nvolatile acidity, sulphates, free SO2 and chlorides capture most predictive\nsignal. Runtime profiling on an EPYC 9K84/H20 node reveals a steep efficiency\ngradient: Gradient Boosting averages 12 h per five-fold study, XGBoost and\nLightGBM require 2-3 h, CatBoost 1 h, and Random Forest under 50 min. We\ntherefore recommend Random Forest as the most cost-effective production model,\nXGBoost and LightGBM as GPU-efficient alternatives, and Gradient Boosting as\nthe accuracy ceiling for offline benchmarking. The fully documented pipeline\nand metric set provide a reproducible baseline for future work on imbalanced\nmulti-class wine-quality prediction.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e94\u79cd\u96c6\u6210\u5b66\u4e60\u5668\u5728\u8461\u8404\u9152\u8d28\u91cf\u9884\u6d4b\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u8868\u73b0\u6700\u4f18\uff0c\u968f\u673a\u68ee\u6797\u4e3a\u751f\u4ea7\u4e2d\u6700\u5177\u6027\u4ef7\u6bd4\u7684\u9009\u62e9\u3002", "motivation": "\u8461\u8404\u9152\u8d28\u91cf\u8bc4\u4f30\u901a\u5e38\u56e0\u4f9d\u8d56\u4e8e\u4e3b\u89c2\u7684\u3001\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u54c1\u9274\u5c0f\u7ec4\u800c\u4e0d\u591f\u51c6\u786e\u548c\u53ef\u91cd\u590d\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u63d0\u9ad8\u8461\u8404\u9152\u8d28\u91cf\u8bc4\u4f30\u7684\u7cbe\u786e\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u4e94\u79cd\u96c6\u6210\u5b66\u4e60\u5668\uff08\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u3001XGBoost\u3001LightGBM\u3001CatBoost\uff09\u5728Vinho Verde\u7ea2\u3001\u767d\u8461\u8404\u9152\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u91c7\u7528\u65e0\u6cc4\u6f0f\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec80:20\u5206\u5c42\u8bad\u7ec3-\u6d4b\u8bd5\u6570\u636e\u5212\u5206\u3001\u4e94\u6298\u5206\u5c42\u7ec4\u4ea4\u53c9\u9a8c\u8bc1\u3001\u6807\u51c6\u5316\u5904\u7406\u3001SMOTE-Tomek\u91cd\u91c7\u6837\u3001\u9006\u9891\u7387\u6210\u672c\u52a0\u6743\u3001Optuna\u8d85\u53c2\u6570\u641c\u7d22\u4ee5\u53ca\u4e24\u9636\u6bb5\u7279\u5f81\u9009\u62e9\u3002\u6700\u7ec8\u5728\u672a\u5904\u7406\u7684\u6d4b\u8bd5\u96c6\u4e0a\u4ee5\u52a0\u6743F1\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728\u52a0\u6743F1\u6307\u6807\u4e0a\uff0c\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u5728\u7ea2\u9152\u548c\u767d\u9152\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e860.693\uff08\u00b10.028\uff09\u548c0.664\uff08\u00b10.016\uff09\u7684\u6700\u9ad8\u5206\u3002\u7814\u7a76\u8868\u660e\uff0c\u9650\u5236\u6bcf\u4e2a\u6a21\u578b\u5728\u4e94\u4e2a\u6700\u9ad8\u6392\u540d\u53d8\u91cf\u4e0a\u7684\u8868\u73b0\u53ef\u4ee5\u964d\u4f4e55%\u7684\u7ef4\u5ea6\uff0c\u4e14\u53ea\u5bf9\u52a0\u6743F1\u5f97\u5206\u4ea7\u751f\u5fae\u5c0f\u5f71\u54cd\u3002\u8fd0\u884c\u65f6\u5256\u6790\u663e\u793a\uff0c\u68af\u5ea6\u63d0\u5347\u5e73\u5747\u9700\u898112\u5c0f\u65f6\u5b8c\u6210\u4e94\u6298\u7814\u7a76\uff0c\u800c\u5176\u4ed6\u6a21\u578b\u8fd0\u884c\u65f6\u95f4\u66f4\u77ed\u3002", "conclusion": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e94\u79cd\u96c6\u6210\u5b66\u4e60\u5668\u5728\u8461\u8404\u9152\u8d28\u91cf\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u5f97\u51fa\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u5728\u51c6\u786e\u5ea6\u4e0a\u8868\u73b0\u6700\u4f73\u3002\u5c3d\u7ba1\u964d\u7ef4\u4f1a\u7565\u5fae\u5f71\u54cd\u52a0\u6743F1\u5f97\u5206\uff0c\u4f46\u6a21\u578b\u4ecd\u80fd\u4fdd\u6301\u8f83\u9ad8\u7684\u9884\u6d4b\u4fe1\u53f7\u3002\u7814\u7a76\u5efa\u8bae\u5728\u751f\u4ea7\u4e2d\u4f7f\u7528\u968f\u673a\u68ee\u6797\u4f5c\u4e3a\u6700\u5177\u6027\u4ef7\u6bd4\u7684\u6a21\u578b\uff0c\u800cXGBoost\u548cLightGBM\u9002\u5408\u4e8eGPU\u6548\u7387\u7684\u573a\u5408\uff0c\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u5219\u9002\u7528\u4e8e\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2506.06524", "pdf": "https://arxiv.org/pdf/2506.06524", "abs": "https://arxiv.org/abs/2506.06524", "authors": ["Sam Earle", "Ahmed Khalifa", "Muhammad Umair Nasir", "Zehua Jiang", "Graham Todd", "Andrzej Banburski-Fahey", "Julian Togelius"], "title": "ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search", "categories": ["cs.AI", "cs.HC"], "comment": "5 pages, 3 figures, 3 tables, submitted to IEEE Conference on Games\n  as a Short Paper", "summary": "There is much interest in using large pre-trained models in Automatic Game\nDesign (AGD), whether via the generation of code, assets, or more abstract\nconceptualization of design ideas. But so far this interest largely stems from\nthe ad hoc use of such generative models under persistent human supervision.\nMuch work remains to show how these tools can be integrated into\nlonger-time-horizon AGD pipelines, in which systems interface with game engines\nto test generated content autonomously. To this end, we introduce ScriptDoctor,\na Large Language Model (LLM)-driven system for automatically generating and\ntesting games in PuzzleScript, an expressive but highly constrained description\nlanguage for turn-based puzzle games over 2D gridworlds. ScriptDoctor generates\nand tests game design ideas in an iterative loop, where human-authored examples\nare used to ground the system's output, compilation errors from the\nPuzzleScript engine are used to elicit functional code, and search-based agents\nplay-test generated games. ScriptDoctor serves as a concrete example of the\npotential of automated, open-ended LLM-based workflows in generating novel game\ncontent.", "AI": {"tldr": "ScriptDoctor\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\uff0c\u5c55\u793a\u4e86LLM\u5728\u751f\u6210\u548c\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u81ea\u52a8\u5316\u548c\u521b\u65b0\u7684\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5728\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u9886\u57df\u4e2d\u5bf9\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5174\u8da3\u52a0\u5267\uff0c\u4f46\u76ee\u524d\u8fd9\u4e9b\u751f\u6210\u6a21\u578b\u7684\u4f7f\u7528\u4e3b\u8981\u4e3a\u4e34\u65f6\u6027\uff0c\u4e14\u4f9d\u8d56\u6301\u7eed\u7684\u4eba\u5de5\u76d1\u7763\u3002\u4e9f\u9700\u5c55\u793a\u8fd9\u4e9b\u5de5\u5177\u5982\u4f55\u6574\u5408\u5230\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u7684\u957f\u65f6\u95f4\u8de8\u5ea6\u7684\u6d41\u7a0b\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u80fd\u81ea\u4e3b\u6d4b\u8bd5\u751f\u6210\u5185\u5bb9\u7684\u7cfb\u7edf\u63a5\u53e3\u4e2d\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u901a\u8fc7ScriptDoctor\u5c55\u793a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "ScriptDoctor\u7cfb\u7edf\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\uff0c\u5b9e\u73b0\u81ea\u52a8\u751f\u6210\u548c\u6d4b\u8bd5\u57fa\u4e8ePuzzleScript\u7684\u56de\u5408\u5236\u8c1c\u9898\u6e38\u620f\u3002\u7cfb\u7edf\u91c7\u7528\u8fed\u4ee3\u5faa\u73af\u7684\u65b9\u5f0f\u751f\u6210\u548c\u6d4b\u8bd5\u6e38\u620f\u8bbe\u8ba1\u521b\u610f\uff0c\u5229\u7528PuzzleScript\u5f15\u64ce\u7684\u7f16\u8bd1\u9519\u8bef\u6765\u751f\u6210\u53ef\u51fd\u6570\u4ee3\u7801\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u641c\u7d22\u7684\u4ee3\u7406\u6765\u8fdb\u884c\u6e38\u620f\u8bd5\u73a9\u6d4b\u8bd5\u3002", "result": "ScriptDoctor\u7cfb\u7edf\u80fd\u591f\u81ea\u52a8\u751f\u6210\u548c\u6d4b\u8bd5\u57fa\u4e8ePuzzleScript\u7684\u6e38\u620f\u8bbe\u8ba1\u521b\u610f\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u5faa\u73af\u4e0d\u65ad\u6539\u8fdb\u5176\u521b\u610f\u7684\u529f\u80fd\u6027\u548c\u5b8c\u6210\u5ea6\u3002", "conclusion": "ScriptDoctor\u5c55\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u5728\u81ea\u52a8\u751f\u6210\u548c\u6d4b\u8bd5\u6e38\u620f\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8fed\u4ee3\u751f\u6210\u548c\u6d4b\u8bd5\u6e38\u620f\u8bbe\u8ba1\u8fd9\u4e00\u73af\u8282\u4e2d\u663e\u793a\u4e86LLM\u5728\u81ea\u52a8\u5316\u3001\u5f00\u653e\u5f0f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u53ef\u884c\u6027\u548c\u521b\u65b0\u6027\u3002"}}
{"id": "2506.07293", "pdf": "https://arxiv.org/pdf/2506.07293", "abs": "https://arxiv.org/abs/2506.07293", "authors": ["Seabin Lee", "Joonyeol Sim", "Changjoo Nam"], "title": "Very Large-scale Multi-Robot Task Allocation in Challenging Environments via Robot Redistribution", "categories": ["cs.RO", "cs.MA"], "comment": "15 pages", "summary": "We consider the Multi-Robot Task Allocation (MRTA) problem that aims to\noptimize an assignment of multiple robots to multiple tasks in challenging\nenvironments which are with densely populated obstacles and narrow passages. In\nsuch environments, conventional methods optimizing the sum-of-cost are often\nineffective because the conflicts between robots incur additional costs (e.g.,\ncollision avoidance, waiting). Also, an allocation that does not incorporate\nthe actual robot paths could cause deadlocks, which significantly degrade the\ncollective performance of the robots.\n  We propose a scalable MRTA method that considers the paths of the robots to\navoid collisions and deadlocks which result in a fast completion of all tasks\n(i.e., minimizing the \\textit{makespan}). To incorporate robot paths into task\nallocation, the proposed method constructs a roadmap using a Generalized\nVoronoi Diagram. The method partitions the roadmap into several components to\nknow how to redistribute robots to achieve all tasks with less conflicts\nbetween the robots. In the redistribution process, robots are transferred to\ntheir final destinations according to a push-pop mechanism with the first-in\nfirst-out principle. From the extensive experiments, we show that our method\ncan handle instances with hundreds of robots in dense clutter while competitors\nare unable to compute a solution within a time limit.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8def\u5f84\u89c4\u5212\u7684\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u5904\u7406\u5bc6\u96c6\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u51b2\u7a81\u548c\u6b7b\u9501\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u7ade\u54c1\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u591a\u969c\u788d\u73af\u5883\u4e0b\u4e0d\u7406\u60f3\uff0c\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u51b2\u7a81\u5bfc\u81f4\u7684\u989d\u5916\u6210\u672c\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u673a\u5668\u4eba\u8def\u5f84\uff0c\u907f\u514d\u51b2\u7a81\u548c\u6b7b\u9501\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u5e7f\u4e49Voronoi\u56fe\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff0c\u5229\u7528\u5206\u533a\u548c\u63a8\u9001\u673a\u5236\u4f18\u5316\u4efb\u52a1\u5206\u914d\uff0c\u907f\u514d\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u51b2\u7a81\u548c\u50f5\u5c40\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5bc6\u96c6\u73af\u5883\u4e2d\u53ef\u4ee5\u5904\u7406\u6570\u767e\u4e2a\u673a\u5668\u4eba\u7684\u4efb\u52a1\u5206\u914d\uff0c\u8868\u73b0\u4f18\u4e8e\u7ade\u54c1\uff0c\u80fd\u591f\u5728\u9650\u5b9a\u65f6\u95f4\u5185\u7ed9\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff0c\u5728\u5bc6\u96c6\u969c\u788d\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5728\u5927\u91cf\u673a\u5668\u4eba\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5de5\u4f5c\u3002"}}
{"id": "2506.06485", "pdf": "https://arxiv.org/pdf/2506.06485", "abs": "https://arxiv.org/abs/2506.06485", "authors": ["Kaiser Sun", "Fan Bai", "Mark Dredze"], "title": "What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models frequently rely on both contextual input and parametric\nknowledge to perform tasks. However, these sources can come into conflict,\nespecially when retrieved documents contradict the model's parametric\nknowledge. We propose a diagnostic framework to systematically evaluate LLM\nbehavior under context-memory conflict, where the contextual information\ndiverges from their parametric beliefs. We construct diagnostic data that\nelicit these conflicts and analyze model performance across multiple task\ntypes. Our findings reveal that (1) knowledge conflict has minimal impact on\ntasks that do not require knowledge utilization, (2) model performance is\nconsistently higher when contextual and parametric knowledge are aligned, (3)\nmodels are unable to fully suppress their internal knowledge even when\ninstructed, and (4) providing rationales that explain the conflict increases\nreliance on contexts. These insights raise concerns about the validity of\nmodel-based evaluation and underscore the need to account for knowledge\nconflict in the deployment of LLMs.", "AI": {"tldr": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u80cc\u666f\u4fe1\u606f\u4e0e\u5176\u53c2\u6570\u77e5\u8bc6\u51b2\u7a81\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e24\u8005\u5bf9\u9f50\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u800c\u5728\u51b2\u7a81\u65f6\u96be\u4ee5\u6291\u5236\u5185\u90e8\u77e5\u8bc6\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u80cc\u666f\u4fe1\u606f\u4e0e\u53c2\u6570\u77e5\u8bc6\u53d1\u751f\u51b2\u7a81\u65f6\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u6846\u67b6\uff0c\u5728\u60c5\u5883\u8bb0\u5fc6\u51b2\u7a81\u4e0b\u7cfb\u7edf\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u5e76\u6784\u5efa\u8bca\u65ad\u6570\u636e\u6765\u5f15\u53d1\u8fd9\u4e9b\u51b2\u7a81\uff0c\u4ee5\u5206\u6790\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u7c7b\u578b\u4e2d\u7684\u8868\u73b0\u3002", "result": "\uff081\uff09\u5728\u4e0d\u9700\u8981\u4f7f\u7528\u77e5\u8bc6\u7684\u4efb\u52a1\u4e0a\uff0c\u77e5\u8bc6\u51b2\u7a81\u5f71\u54cd\u8f83\u5c0f\uff0c\uff082\uff09\u5f53\u80cc\u666f\u4e0e\u53c2\u6570\u77e5\u8bc6\u5bf9\u9f50\u65f6\uff0c\u6a21\u578b\u8868\u73b0\u66f4\u4f73\uff0c\uff083\uff09\u5373\u4f7f\u88ab\u6307\u793a\uff0c\u6a21\u578b\u4e5f\u96be\u4ee5\u5b8c\u5168\u538b\u5236\u5176\u5185\u90e8\u77e5\u8bc6\uff0c\uff084\uff09\u63d0\u4f9b\u89e3\u91ca\u51b2\u7a81\u7684\u7406\u7531\u4f1a\u589e\u52a0\u5bf9\u80cc\u666f\u7684\u4f9d\u8d56\u3002", "conclusion": "\u6a21\u578b\u5728\u80cc\u666f\u77e5\u8bc6\u4e0e\u53c2\u6570\u77e5\u8bc6\u5bf9\u9f50\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u800c\u5728\u77e5\u8bc6\u51b2\u7a81\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u96be\u4ee5\u5b8c\u5168\u6291\u5236\u5176\u5185\u90e8\u77e5\u8bc6\uff0c\u663e\u793a\u51fa\u6a21\u578b\u8bc4\u4f30\u7684\u6709\u6548\u6027\u95ee\u9898\u3002"}}
{"id": "2506.06330", "pdf": "https://arxiv.org/pdf/2506.06330", "abs": "https://arxiv.org/abs/2506.06330", "authors": ["James Afful"], "title": "ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications", "categories": ["cs.LG"], "comment": null, "summary": "As machine learning systems are increasingly deployed in high-stakes domains\nsuch as criminal justice, finance, and healthcare, the demand for interpretable\nand trustworthy models has intensified. Despite the proliferation of local\nexplanation techniques, including SHAP, LIME, and counterfactual methods, there\nexists no standardized, reproducible framework for their comparative\nevaluation, particularly in fairness-sensitive settings.\n  We introduce ExplainBench, an open-source benchmarking suite for systematic\nevaluation of local model explanations across ethically consequential datasets.\nExplainBench provides unified wrappers for popular explanation algorithms,\nintegrates end-to-end pipelines for model training and explanation generation,\nand supports evaluation via fidelity, sparsity, and robustness metrics. The\nframework includes a Streamlit-based graphical interface for interactive\nexploration and is packaged as a Python module for seamless integration into\nresearch workflows.\n  We demonstrate ExplainBench on datasets commonly used in fairness research,\nsuch as COMPAS, UCI Adult Income, and LendingClub, and showcase how different\nexplanation methods behave under a shared experimental protocol. By enabling\nreproducible, comparative analysis of local explanations, ExplainBench advances\nthe methodological foundations of interpretable machine learning and\nfacilitates accountability in real-world AI systems.", "AI": {"tldr": "\u63a8\u51faExplainBench\uff0c\u63d0\u4f9b\u7cfb\u7edf\u8bc4\u4f30\u5730\u65b9\u6a21\u578b\u89e3\u91ca\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u4fc3\u8fdb\u516c\u5e73\u7814\u7a76\u4e2d\u7684\u53ef\u89e3\u91caAI\u65b9\u6cd5\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\u5bf9\u53ef\u89e3\u91ca\u548c\u503c\u5f97\u4fe1\u8d56\u7684\u6a21\u578b\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\uff0c\u5f53\u524d\u7f3a\u4e4f\u7528\u4e8e\u6bd4\u8f83\u8bc4\u4f30\u5730\u65b9\u89e3\u91ca\u6280\u672f\u7684\u6807\u51c6\u5316\u548c\u53ef\u91cd\u73b0\u6846\u67b6\uff0c\u7279\u522b\u662f\u5728\u516c\u5e73\u654f\u611f\u73af\u5883\u4e2d\u3002", "method": "\u4ecb\u7ecd\u4e86ExplainBench\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7528\u4e8e\u901a\u8fc7\u7edf\u4e00\u5c01\u88c5\u5668\u3001\u96c6\u6210\u7684\u6a21\u578b\u8bad\u7ec3\u548c\u89e3\u91ca\u751f\u6210\u7ba1\u9053\u4ee5\u53ca\u8bc4\u4f30\u6807\u51c6\uff08\u5fe0\u8bda\u5ea6\u3001\u7a00\u758f\u6027\u548c\u9c81\u68d2\u6027\uff09\u5bf9\u5730\u65b9\u6a21\u578b\u89e3\u91ca\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5c55\u793a\u4e86ExplainBench\u5728\u5e38\u7528\u4e8e\u516c\u5e73\u7814\u7a76\u7684\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u89e3\u91ca\u65b9\u6cd5\u5728\u7edf\u4e00\u5b9e\u9a8c\u534f\u8bae\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "ExplainBench\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u5c01\u88c5\u3001\u96c6\u6210\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u591a\u6837\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u8fdb\u6b65\u4e86\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u57fa\u7840\uff0c\u5e76\u4fc3\u8fdb\u4e86\u73b0\u5b9e\u4e16\u754cAI\u7cfb\u7edf\u4e2d\u7684\u8d23\u4efb\u6027\u3002"}}
{"id": "2506.07468", "pdf": "https://arxiv.org/pdf/2506.07468", "abs": "https://arxiv.org/abs/2506.07468", "authors": ["Mickel Liu", "Liwei Jiang", "Yancheng Liang", "Simon Shaolei Du", "Yejin Choi", "Tim Althoff", "Natasha Jaques"], "title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models", "categories": ["cs.LG", "cs.CL", "cs.MA"], "comment": null, "summary": "Conventional language model (LM) safety alignment relies on a reactive,\ndisjoint procedure: attackers exploit a static model, followed by defensive\nfine-tuning to patch exposed vulnerabilities. This sequential approach creates\na mismatch -- attackers overfit to obsolete defenses, while defenders\nperpetually lag behind emerging threats. To address this, we propose\nSelf-RedTeam, an online self-play reinforcement learning algorithm where an\nattacker and defender agent co-evolve through continuous interaction. We cast\nsafety alignment as a two-player zero-sum game, where a single model alternates\nbetween attacker and defender roles -- generating adversarial prompts and\nsafeguarding against them -- while a reward LM adjudicates outcomes. This\nenables dynamic co-adaptation. Grounded in the game-theoretic framework of\nzero-sum games, we establish a theoretical safety guarantee which motivates the\ndesign of our method: if self-play converges to a Nash Equilibrium, the\ndefender will reliably produce safe responses to any adversarial input.\nEmpirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared\nto attackers trained against static defenders and achieves higher robustness on\nsafety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained\nagainst static attackers. We further propose hidden Chain-of-Thought, allowing\nagents to plan privately, which boosts adversarial diversity and reduces\nover-refusals. Our results motivate a shift from reactive patching to proactive\nco-evolution in LM safety training, enabling scalable, autonomous, and robust\nself-improvement of LMs via multi-agent reinforcement learning (MARL).", "AI": {"tldr": "\u63d0\u51fa\u81ea\u5bf9\u5f08\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5Self-RedTeam\uff0c\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u653b\u51fb\u548c\u9632\u5fa1\u8005\u7684\u534f\u540c\u8fdb\u5316\uff0c\u5b9e\u73b0\u66f4\u9ad8\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u901a\u5e38\u662f\u53cd\u5e94\u6027\u548c\u5206\u6563\u7684\uff0c\u5bfc\u81f4\u9632\u5fa1\u8005\u603b\u662f\u843d\u540e\u4e8e\u65b0\u51fa\u73b0\u7684\u5a01\u80c1\u3002\u56e0\u6b64\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4f7f\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u901a\u8fc7\u6301\u7eed\u4e92\u52a8\u5171\u540c\u8fdb\u5316\uff0c\u6765\u63d0\u9ad8\u5b89\u5168\u6027\u80fd\u3002", "method": "\u8bba\u6587\u91c7\u7528\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7684\u65b9\u6cd5\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\u95ee\u9898\u8868\u8ff0\u4e3a\u4e24\u4e2a\u89d2\u8272\u8f6e\u6d41\u626e\u6f14\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u7684\u96f6\u548c\u6e38\u620f\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u6a21\u578b\u53ef\u4ee5\u4e0d\u65ad\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u81ea\u6211\u6539\u8fdb\u3002", "result": "Self-RedTeam \u65b9\u6cd5\u53ef\u4ee5\u53d1\u73b0\u6bd4\u9759\u6001\u9632\u5fa1\u8005\u8bad\u7ec3\u7684\u653b\u51fb\u65b9\u6cd5\u591a21.8%\u7684\u591a\u6837\u6027\u653b\u51fb\uff0c\u5e76\u5728\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\uff0c\u4f8b\u5982\u5728WildJailBreak\u6d4b\u9a8c\u4e2d\u7684\u8868\u73b0\u63d0\u9ad8\u4e8665.5%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u901a\u8fc7\u9690\u5f0f\u601d\u7ef4\u94fe\u63d0\u9ad8\u4e86\u653b\u51fb\u7684\u591a\u6837\u6027\u5e76\u51cf\u5c11\u4e86\u8fc7\u591a\u62d2\u7edd\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSelf-RedTeam\u7684\u5728\u7ebf\u81ea\u5bf9\u5f08\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u53ef\u4ee5\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u89e3\u51b3\u73b0\u884c\u65b9\u6cd5\u4e2d\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u4e0d\u540c\u6b65\u7684\u95ee\u9898\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u9759\u6001\u8bad\u7ec3\u7684\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u53d1\u73b0\u66f4\u5177\u591a\u6837\u6027\u7684\u653b\u51fb\uff0c\u5e76\u5728\u5b89\u5168\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.06500", "pdf": "https://arxiv.org/pdf/2506.06500", "abs": "https://arxiv.org/abs/2506.06500", "authors": ["Luyao Shi", "Michael Kazda", "Charles Schmitter", "Hemlata Gupta"], "title": "Improving LLM-Powered EDA Assistants with RAFT", "categories": ["cs.CL"], "comment": "Accepted paper at IEEE International Conference on LLM-Aided Design,\n  2025 (LAD 2025)", "summary": "Electronic design engineers often struggle to efficiently access relevant\ninformation for tasks like design verification and technology development.\nWhile large language models (LLMs) can enhance productivity as conversational\nagents, pre-trained open-source LLMs lack domain-specific knowledge for\nElectronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG)\ncontext, LLMs rely on external context but may still produce inaccurate\nresponses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but\nacquiring labeled question/answer (Q/A) data in EDA is difficult. To address\nthis, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our\nresults show that RAFT with synthetic data significantly boosts LLM performance\nfor RAG-based EDA tasks. We also investigate the impact of using real user\nquestions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data\ngeneration. Additionally, we implement secure access control to ensure\nsensitive information is only accessible to authorized personnel. Finally, we\nassess the risk of data leakage and unintended memorization during fine-tuning\nwith synthetic data, providing practical insights.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u6765\u6539\u5584\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\u9886\u57df\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u548c\u5b9e\u73b0\u4e86\u786e\u4fdd\u4fe1\u606f\u5b89\u5168\u7684\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u9886\u57df\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u5e76\u6539\u5584\u5176\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u9762\u5bf9\u83b7\u53d6EDA\u6807\u6ce8\u95ee\u7b54\u6570\u636e\u7684\u56f0\u96be\uff0c\u63d0\u51fa\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u6765\u589e\u5f3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u4f7f\u7528\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u5fae\u8c03\uff08RAFT\uff09\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u95ee\u9898\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u5c11\u6837\u672c\uff08RAFS\uff09\u793a\u4f8b\u5bf9\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5f71\u54cd\uff0c\u8fd8\u5b9e\u65bd\u4e86\u5b89\u5168\u8bbf\u95ee\u63a7\u5236\u4ee5\u786e\u4fdd\u654f\u611f\u4fe1\u606f\u7684\u5b89\u5168\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u7684\u4f7f\u7528\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u4e2d\u7684\u4efb\u52a1\u8868\u73b0\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u771f\u5b9e\u7528\u6237\u95ee\u9898\u4f5c\u4e3aRAFS\u793a\u4f8b\u5bf9\u5408\u6210\u6570\u636e\u751f\u6210\u6709\u79ef\u6781\u7684\u6539\u5584\u6548\u679c\u3002", "conclusion": "\u4f7f\u7528\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u8fdb\u884c\u68c0\u7d22\u589e\u5f3a\u5fae\u8c03\uff08RAFT\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u81ea\u56de\u5f52\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4efb\u52a1\u4e2d\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u9886\u57df\u3002\u771f\u5b9e\u7528\u6237\u95ee\u9898\u4f5c\u4e3a\u68c0\u7d22\u589e\u5f3a\u5c11\u6837\u672c\uff08RAFS\uff09\u793a\u4f8b\u4e5f\u5bf9\u5408\u6210\u6570\u636e\u751f\u6210\u6709\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2506.06333", "pdf": "https://arxiv.org/pdf/2506.06333", "abs": "https://arxiv.org/abs/2506.06333", "authors": ["Benjamin von Berg", "Bernhard K. Aichernig"], "title": "Extending AALpy with Passive Learning: A Generalized State-Merging Approach", "categories": ["cs.LG", "cs.FL"], "comment": "Accepted for publication at CAV 2025, the 37th International\n  Conference on Computer Aided Verification", "summary": "AALpy is a well-established open-source automata learning library written in\nPython with a focus on active learning of systems with IO behavior. It provides\na wide range of state-of-the-art algorithms for different automaton types\nranging from fully deterministic to probabilistic automata. In this work, we\npresent the recent addition of a generalized implementation of an important\nmethod from the domain of passive automata learning: state-merging in the\nred-blue framework. Using a common internal representation for different\nautomaton types allows for a general and highly configurable implementation of\nthe red-blue framework. We describe how to define and execute state-merging\nalgorithms using AALpy, which reduces the implementation effort for\nstate-merging algorithms mainly to the definition of compatibility criteria and\nscoring. This aids the implementation of both existing and novel algorithms. In\nparticular, defining some existing state-merging algorithms from the literature\nwith AALpy only takes a few lines of code.", "AI": {"tldr": "AALpy\u5f15\u5165\u4e86\u4e00\u79cd\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u6267\u884c\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\uff0c\u6781\u5927\u7b80\u5316\u4e86\u7b97\u6cd5\u5b9e\u73b0\u8fc7\u7a0b\u3002", "motivation": "\u5e0c\u671b\u5728AALpy\u4e2d\u52a0\u5165\u4e00\u79cd\u901a\u7528\u5b9e\u73b0\uff0c\u51cf\u5c11\u5b9a\u4e49\u53ca\u6267\u884c\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\u7684\u5de5\u4f5c\u91cf\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u7684\u5185\u90e8\u8868\u793a\u6cd5\u5b9e\u73b0\u7ea2\u84dd\u6846\u67b6\u7684\u901a\u7528\u5b9e\u73b0\uff0c\u4f7f\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\u914d\u7f6e\u7075\u6d3b\u7b80\u5355\u3002", "result": "\u5728AALpy\u4e2d\u5b9a\u4e49\u67d0\u4e9b\u73b0\u6709\u7684\u72b6\u6001\u5408\u5e76\u7b97\u6cd5\u4ec5\u9700\u51e0\u884c\u4ee3\u7801\uff0c\u5927\u5927\u7b80\u5316\u4e86\u7b97\u6cd5\u7684\u5b9e\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86AALpy\u65b0\u7684\u901a\u7528\u5b9e\u73b0\uff0c\u91cd\u70b9\u5728\u4e8e\u88ab\u52a8\u81ea\u52a8\u5b66\u4e60\u9886\u57df\u7684\u91cd\u8981\u65b9\u6cd5\uff1a\u5728\u7ea2\u84dd\u6846\u67b6\u4e2d\u7684\u72b6\u6001\u5408\u5e76\u3002"}}
{"id": "2506.06580", "pdf": "https://arxiv.org/pdf/2506.06580", "abs": "https://arxiv.org/abs/2506.06580", "authors": ["Xiaoran Liu", "Istvan David"], "title": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "categories": ["cs.AI", "cs.ET", "cs.SE", "cs.SY", "eess.SY"], "comment": null, "summary": "Insufficient data volume and quality are particularly pressing challenges in\nthe adoption of modern subsymbolic AI. To alleviate these challenges, AI\nsimulation uses virtual training environments in which AI agents can be safely\nand efficiently developed with simulated, synthetic data. Digital twins open\nnew avenues in AI simulation, as these high-fidelity virtual replicas of\nphysical systems are equipped with state-of-the-art simulators and the ability\nto further interact with the physical system for additional data collection. In\nthis article, we report on our systematic survey of digital twin-enabled AI\nsimulation. By analyzing 22 primary studies, we identify technological trends\nand derive a reference framework to situate digital twins and AI components.\nBased on our findings, we derive a reference framework and provide\narchitectural guidelines by mapping it onto the ISO 23247 reference\narchitecture for digital twins. Finally, we identify challenges and research\nopportunities for prospective researchers.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u6570\u5b57\u5b6a\u751f\u4f53\u5728AI\u6a21\u62df\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u6846\u67b6\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u4ee3\u7b26\u53f7\u5b66\u4eba\u5de5\u667a\u80fd\u7684\u91c7\u7eb3\u9762\u4e34\u6570\u636e\u91cf\u548c\u8d28\u91cf\u4e0d\u8db3\u7684\u6311\u6218\u3002", "method": "\u5bf922\u9879\u7814\u7a76\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u6280\u672f\u8d8b\u52bf\uff0c\u5e76\u5efa\u7acb\u53c2\u8003\u6846\u67b6\u3002", "result": "\u63d0\u51fa\u4e86\u53c2\u7167\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0eISO 23247\u6570\u5b57\u5b6a\u751f\u53c2\u8003\u67b6\u6784\u7684\u6620\u5c04\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u4f53\u5728\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u4e2d\u7684\u5e94\u7528\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u6311\u6218\u548c\u673a\u9047\u3002"}}
{"id": "2506.07755", "pdf": "https://arxiv.org/pdf/2506.07755", "abs": "https://arxiv.org/abs/2506.07755", "authors": ["Nikolaos Bousias", "Lars Lindemann", "George Pappas"], "title": "Deep Equivariant Multi-Agent Control Barrier Functions", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "comment": null, "summary": "With multi-agent systems increasingly deployed autonomously at scale in\ncomplex environments, ensuring safety of the data-driven policies is critical.\nControl Barrier Functions have emerged as an effective tool for enforcing\nsafety constraints, yet existing learning-based methods often lack in\nscalability, generalization and sampling efficiency as they overlook inherent\ngeometric structures of the system. To address this gap, we introduce\nsymmetries-infused distributed Control Barrier Functions, enforcing the\nsatisfaction of intrinsic symmetries on learnable graph-based safety\ncertificates. We theoretically motivate the need for equivariant\nparametrization of CBFs and policies, and propose a simple, yet efficient and\nadaptable methodology for constructing such equivariant group-modular networks\nvia the compatible group actions. This approach encodes safety constraints in a\ndistributed data-efficient manner, enabling zero-shot generalization to larger\nand denser swarms. Through extensive simulations on multi-robot navigation\ntasks, we demonstrate that our method outperforms state-of-the-art baselines in\nterms of safety, scalability, and task success rates, highlighting the\nimportance of embedding symmetries in safe distributed neural policies.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u6ce8\u5165\u5bf9\u79f0\u6027\u7684\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u4ee5\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5e38\u5e38\u5728\u53ef\u6269\u5c55\u6027\u3001\u6cdb\u5316\u548c\u91c7\u6837\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u56e0\u4e3a\u5b83\u4eec\u5ffd\u7565\u4e86\u7cfb\u7edf\u56fa\u6709\u7684\u51e0\u4f55\u7ed3\u6784\u3002\u56e0\u6b64\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u5bf9\u79f0\u6027\u6ce8\u5165\u7684\u5206\u5e03\u5f0f\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u5bf9\u79f0\u6027\u6ce8\u5165\u7684\u5206\u5e03\u5f0f\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff0c\u5229\u7528\u53ef\u4ee5\u5b66\u4e60\u7684\u57fa\u4e8e\u56fe\u7684\u5b89\u5168\u8bc1\u4e66\u6765\u5f3a\u5236\u6ee1\u8db3\u5185\u5728\u5bf9\u79f0\u6027\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u517c\u5bb9\u7684\u7fa4\u4f5c\u7528\u6784\u5efa\u7b49\u53d8\u7ec4\u6a21\u5757\u5316\u7f51\u7edc\u7684\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u662f\u7b80\u5355\u3001\u9ad8\u6548\u4e14\u53ef\u9002\u5e94\u7684\u3002", "result": "\u901a\u8fc7\u5728\u591a\u673a\u5668\u4eba\u5bfc\u822a\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u6a21\u62df\uff0c\u8be5\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u57fa\u7ebf\u3002", "conclusion": "\u5d4c\u5165\u5bf9\u79f0\u6027\u7684\u5206\u5e03\u5f0f\u795e\u7ecf\u7b56\u7565\u5728\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u5f3a\u8c03\u4e86\u5728\u5b89\u5168\u5206\u5e03\u5f0f\u795e\u7ecf\u7b56\u7565\u4e2d\u5d4c\u5165\u5bf9\u79f0\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.06506", "pdf": "https://arxiv.org/pdf/2506.06506", "abs": "https://arxiv.org/abs/2506.06506", "authors": ["Kshitish Ghate", "Tessa Charlesworth", "Mona Diab", "Aylin Caliskan"], "title": "Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes", "categories": ["cs.CL"], "comment": "Accepted to ACL Findings 2025", "summary": "To build fair AI systems we need to understand how social-group biases\nintrinsic to foundational encoder-based vision-language models (VLMs) manifest\nin biases in downstream tasks. In this study, we demonstrate that intrinsic\nbiases in VLM representations systematically ``carry over'' or propagate into\nzero-shot retrieval tasks, revealing how deeply rooted biases shape a model's\noutputs. We introduce a controlled framework to measure this propagation by\ncorrelating (a) intrinsic measures of bias in the representational space with\n(b) extrinsic measures of bias in zero-shot text-to-image (TTI) and\nimage-to-text (ITT) retrieval. Results show substantial correlations between\nintrinsic and extrinsic bias, with an average $\\rho$ = 0.83 $\\pm$ 0.10. This\npattern is consistent across 114 analyses, both retrieval directions, six\nsocial groups, and three distinct VLMs. Notably, we find that\nlarger/better-performing models exhibit greater bias propagation, a finding\nthat raises concerns given the trend towards increasingly complex AI models.\nOur framework introduces baseline evaluation tasks to measure the propagation\nof group and valence signals. Investigations reveal that underrepresented\ngroups experience less robust propagation, further skewing their model-related\noutcomes.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u7840\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u56fa\u6709\u504f\u5dee\u4f1a\u7cfb\u7edf\u5730\u4f20\u64ad\u5230\u540e\u7eed\u4efb\u52a1\u4e2d\uff0c\u5c24\u5176\u662f\u5728\u96f6\u6837\u672c\u68c0\u7d22\u4efb\u52a1\u4e2d\uff0c\u4e14\u66f4\u590d\u6742\u7684\u6a21\u578b\u504f\u5dee\u4f20\u64ad\u66f4\u4e25\u91cd\u3002\u8fd9\u5bf9\u4e8e\u5f31\u52bf\u7fa4\u4f53\u7684\u5f71\u54cd\u5c24\u4e3a\u660e\u663e\u3002", "motivation": "\u4e3a\u4e86\u5efa\u7acb\u516c\u5e73\u7684AI\u7cfb\u7edf\uff0c\u9700\u8981\u4e86\u89e3\u5728\u57fa\u7840\u7f16\u7801\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u793e\u4f1a\u7fa4\u4f53\u504f\u5dee\u5982\u4f55\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u504f\u5dee\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u5173\u8054\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u56fa\u6709\u504f\u5dee\u4e0e\u96f6\u6837\u672c\u6587\u672c\u5230\u56fe\u50cf\u4e0e\u56fe\u50cf\u5230\u6587\u672c\u68c0\u7d22\u4e2d\u7684\u5916\u5728\u504f\u5dee\u6765\u8861\u91cf\u504f\u5dee\u4f20\u64ad\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5185\u5728\u504f\u5dee\u4e0e\u5916\u5728\u504f\u5dee\u4e4b\u95f4\u6709\u663e\u8457\u76f8\u5173\u6027\uff0c\u5e73\u5747\u76f8\u5173\u7cfb\u6570\u4e3a0.83\u00b10.10\u3002\u8fd9\u79cd\u6a21\u5f0f\u5728\u6240\u6709\u5206\u6790\u3001\u68c0\u7d22\u65b9\u5411\u3001\u793e\u4f1a\u7fa4\u4f53\u548c\u4e0d\u540c\u6a21\u578b\u4e2d\u662f\u4e00\u81f4\u7684\u3002", "conclusion": "\u66f4\u5927\u6216\u6027\u80fd\u66f4\u597d\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5927\u7684\u504f\u5dee\u4f20\u64ad\uff0c\u8fd9\u5728\u8d8a\u6765\u8d8a\u590d\u6742\u7684AI\u6a21\u578b\u8d8b\u52bf\u4e0b\u5f15\u8d77\u5173\u6ce8\u3002\u7814\u7a76\u663e\u793a\u5f31\u52bf\u7fa4\u4f53\u7684\u4f20\u64ad\u8f83\u4e0d\u5f3a\u5065\uff0c\u8fdb\u4e00\u6b65\u5bfc\u81f4\u6a21\u578b\u76f8\u5173\u7ed3\u679c\u7684\u504f\u5dee\u3002"}}
{"id": "2506.06337", "pdf": "https://arxiv.org/pdf/2506.06337", "abs": "https://arxiv.org/abs/2506.06337", "authors": ["Ali Murad", "Bo Hui", "Wei-Shinn Ku"], "title": "Optimized Local Updates in Federated Learning via Reinforcement Learning", "categories": ["cs.LG"], "comment": "This paper is accepted at IEEE IJCNN 2025", "summary": "Federated Learning (FL) is a distributed framework for collaborative model\ntraining over large-scale distributed data, enabling higher performance while\nmaintaining client data privacy. However, the nature of model aggregation at\nthe centralized server can result in a performance drop in the presence of\nnon-IID data across different clients. We remark that training a client locally\non more data than necessary does not benefit the overall performance of all\nclients. In this paper, we devise a novel framework that leverages a Deep\nReinforcement Learning (DRL) agent to select an optimized amount of data\nnecessary to train a client model without oversharing information with the\nserver. Starting without awareness of the client's performance, the DRL agent\nutilizes the change in training loss as a reward signal and learns to optimize\nthe amount of training data necessary for improving the client's performance.\nSpecifically, after each aggregation round, the DRL algorithm considers the\nlocal performance as the current state and outputs the optimized weights for\neach class, in the training data, to be used during the next round of local\ntraining. In doing so, the agent learns a policy that creates an optimized\npartition of the local training dataset during the FL rounds. After FL, the\nclient utilizes the entire local training dataset to further enhance its\nperformance on its own data distribution, mitigating the non-IID effects of\naggregation. Through extensive experiments, we demonstrate that training FL\nclients through our algorithm results in superior performance on multiple\nbenchmark datasets and FL frameworks. Our code is available at\nhttps://github.com/amuraddd/optimized_client_training.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u7684\u65b0\u6846\u67b6\uff0c\u5728\u591a\u79cd\u57fa\u51c6\u6570\u636e\u96c6 \u548c\u6846\u67b6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u975eIID\u6570\u636e\u73af\u5883\u4e2d\uff0c\u8054\u90a6\u5b66\u4e60\u7684\u4e2d\u5fc3\u5316\u6a21\u578b\u805a\u5408\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u672c\u5730\u8fc7\u591a\u7684\u6570\u636e\u8bad\u7ec3\u4e0d\u4e00\u5b9a\u6709\u5229\u4e8e\u5168\u5c40\u6027\u80fd\u63d0\u5347\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u9009\u62e9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u6700\u4f73\u6570\u636e\u91cf\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0cDRL\u4ee3\u7406\u901a\u8fc7\u89c2\u5bdf\u8bad\u7ec3\u635f\u5931\u7684\u53d8\u5316\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u4e0d\u65ad\u8c03\u6574\u6bcf\u4e2a\u7c7b\u7684\u6700\u4f73\u6743\u91cd\uff0c\u4ee5\u4f18\u5316\u6570\u636e\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u901a\u8fc7\u6240\u63d0\u7b97\u6cd5\u8bad\u7ec3\u7684\u8054\u90a6\u5b66\u4e60\u5ba2\u6237\u7aef\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6846\u67b6\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u6027\u80fd\uff0c\u5c24\u5176\u5728\u975eIID\u6570\u636e\u60c5\u5883\u4e0b\u6548\u679c\u66f4\u4f73\u3002"}}
{"id": "2506.06634", "pdf": "https://arxiv.org/pdf/2506.06634", "abs": "https://arxiv.org/abs/2506.06634", "authors": ["Yubin Xiao", "Di Wang", "Rui Cao", "Xuan Wu", "Boyang Li", "You Zhou"], "title": "GELD: A Unified Neural Model for Efficiently Solving Traveling Salesman Problems Across Different Scales", "categories": ["cs.AI"], "comment": "21pages, 4 figures, and 14 tables", "summary": "The Traveling Salesman Problem (TSP) is a well-known combinatorial\noptimization problem with broad real-world applications. Recent advancements in\nneural network-based TSP solvers have shown promising results. Nonetheless,\nthese models often struggle to efficiently solve both small- and large-scale\nTSPs using the same set of pre-trained model parameters, limiting their\npractical utility. To address this issue, we introduce a novel neural TSP\nsolver named GELD, built upon our proposed broad global assessment and refined\nlocal selection framework. Specifically, GELD integrates a lightweight\nGlobal-view Encoder (GE) with a heavyweight Local-view Decoder (LD) to enrich\nembedding representation while accelerating the decision-making process.\nMoreover, GE incorporates a novel low-complexity attention mechanism, allowing\nGELD to achieve low inference latency and scalability to larger-scale TSPs.\nAdditionally, we propose a two-stage training strategy that utilizes training\ninstances of different sizes to bolster GELD's generalization ability.\nExtensive experiments conducted on both synthetic and real-world datasets\ndemonstrate that GELD outperforms seven state-of-the-art models considering\nboth solution quality and inference speed. Furthermore, GELD can be employed as\na post-processing method to significantly elevate the quality of the solutions\nderived by existing neural TSP solvers via spending affordable additional\ncomputing time. Notably, GELD is shown as capable of solving TSPs with up to\n744,710 nodes, first-of-its-kind to solve this large size TSP without relying\non divide-and-conquer strategies to the best of our knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684GELD\u795e\u7ecfTSP\u6c42\u89e3\u5668\u80fd\u591f\u9ad8\u6548\u89e3\u51b3\u5404\u79cd\u89c4\u6a21\u7684TSP\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u4e14\u53ef\u4ee5\u5904\u7406\u591a\u8fbe744,710\u8282\u70b9\u7684\u5927\u89c4\u6a21TSP\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7f51\u7edcTSP\u89e3\u7b97\u5668\u867d\u7136\u6709\u4e86\u5f88\u5927\u8fdb\u5c55\uff0c\u4f46\u5728\u4f7f\u7528\u76f8\u540c\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u65f6\u901a\u5e38\u96be\u4ee5\u9ad8\u6548\u89e3\u51b3\u5404\u79cd\u89c4\u6a21\u7684TSP\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecfTSP\u89e3\u7b97\u5668GELD\uff0c\u57fa\u4e8e\u5e7f\u57df\u5168\u5c40\u8bc4\u4f30\u548c\u7cbe\u7ec6\u5c40\u90e8\u9009\u62e9\u6846\u67b6\u3002\u5177\u4f53\u800c\u8a00\uff0cGELD\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u7684\u5168\u5c40\u89c6\u89d2\u7f16\u7801\u5668\uff08GE\uff09\u548c\u91cd\u91cf\u7ea7\u7684\u5c40\u90e8\u89c6\u89d2\u89e3\u7801\u5668\uff08LD\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u4f4e\u590d\u6742\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u6765\u589e\u5f3aGELD\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGELD\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u63a8\u7406\u901f\u5ea6\u65b9\u9762\u4f18\u4e8e\u4e03\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5e76\u80fd\u4f5c\u4e3a\u540e\u5904\u7406\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u73b0\u6709\u795e\u7ecfTSP\u89e3\u7b97\u5668\u7684\u89e3\u7684\u8d28\u91cf\u3002GELD\u9996\u6b21\u5728\u4e0d\u4f9d\u8d56\u5206\u800c\u6cbb\u4e4b\u7b56\u7565\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u4e86\u9ad8\u8fbe744,710\u8282\u70b9\u7684TSP\u95ee\u9898\u3002", "conclusion": "GELD\u5177\u6709\u8f83\u5927\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u6269\u5c55\u6027\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21TSP\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5176\u5728\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u901f\u5ea6\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.07756", "pdf": "https://arxiv.org/pdf/2506.07756", "abs": "https://arxiv.org/abs/2506.07756", "authors": ["Mark Burgess"], "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; F.4.1; I.2.4; G.2.2"], "comment": null, "summary": "Some formal aspects of the Semantic Spacetime graph model are presented, with\nreference to its use for directed knowledge representations and process\nmodelling. A finite $\\gamma(3,4)$ representation is defined to form a closed\nset of operations that can scale to any degree of semantic complexity. The\nSemantic Spacetime postulates bring predictability with minimal constraints to\npathways in graphs. The ubiquitous appearance of absorbing states in any\npartial graph means that a graph process leaks information. The issue is\nclosely associated with the issue of division by zero, which signals a loss of\nclosure and the need for manual injection of remedial information. The Semantic\nSpacetime model (and its Promise Theory) origins help to clarify how such\nabsorbing states are associated with boundary information where intentionality\ncan enter.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Semantic Spacetime\u56fe\u6a21\u578b\u7684\u5f62\u5f0f\u65b9\u9762\uff0c\u5b9a\u4e49\u4e86\u6709\u9650\u8868\u793a\u4ee5\u5904\u7406\u590d\u6742\u8bed\u4e49\uff0c\u5e76\u53d1\u73b0\u56fe\u4e2d\u7684\u5438\u6536\u6001\u8c61\u5f81\u4fe1\u606f\u6cc4\u6f0f\u3002", "motivation": "\u7528\u4e8e\u77e5\u8bc6\u8868\u793a\u548c\u8fc7\u7a0b\u5efa\u6a21\u3002", "method": "\u5b9a\u4e49\u6709\u9650\u7684\u03b3(3,4)\u8868\u793a\uff0c\u4ee5\u5f62\u6210\u4e00\u4e2a\u5c01\u95ed\u7684\u64cd\u4f5c\u96c6\uff0c\u53ef\u4ee5\u6269\u5c55\u5230\u4efb\u610f\u8bed\u4e49\u590d\u6742\u5ea6\u3002", "result": "\u53d1\u73b0\u5728\u4efb\u4f55\u90e8\u5206\u56fe\u4e2d\u90fd\u4f1a\u51fa\u73b0\u5438\u6536\u6001\uff0c\u610f\u5473\u7740\u56fe\u8fc7\u7a0b\u4f1a\u6cc4\u6f0f\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cSemantic Spacetime\u6a21\u578b\u5728\u56fe\u8def\u5f84\u4e2d\u63d0\u4f9b\u4e86\u9884\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u7ea6\u675f\u3002"}}
{"id": "2506.06522", "pdf": "https://arxiv.org/pdf/2506.06522", "abs": "https://arxiv.org/abs/2506.06522", "authors": ["Aladin Djuhera", "Swanand Ravindra Kadhe", "Syed Zawad", "Farhan Ahmed", "Heiko Ludwig", "Holger Boche"], "title": "Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent work on large language models (LLMs) has increasingly focused on\npost-training and alignment with datasets curated to enhance instruction\nfollowing, world knowledge, and specialized skills. However, most post-training\ndatasets used in leading open- and closed-source LLMs remain inaccessible to\nthe public, with limited information about their construction process. This\nlack of transparency has motivated the recent development of open-source\npost-training corpora. While training on these open alternatives can yield\nperformance comparable to that of leading models, systematic comparisons remain\nchallenging due to the significant computational cost of conducting them\nrigorously at scale, and are therefore largely absent. As a result, it remains\nunclear how specific samples, task types, or curation strategies influence\ndownstream performance when assessing data quality. In this work, we conduct\nthe first comprehensive side-by-side analysis of two prominent open\npost-training datasets: Tulu-3-SFT-Mix and SmolTalk. Using the Magpie\nframework, we annotate each sample with detailed quality metrics, including\nturn structure (single-turn vs. multi-turn), task category, input quality, and\nresponse quality, and we derive statistics that reveal structural and\nqualitative similarities and differences between the two datasets. Based on\nthese insights, we design a principled curation recipe that produces a new data\nmixture, TuluTalk, which contains 14% fewer samples than either source dataset\nwhile matching or exceeding their performance on key benchmarks. Our findings\noffer actionable insights for constructing more effective post-training\ndatasets that improve model performance within practical resource limits. To\nsupport future research, we publicly release both the annotated source datasets\nand our curated TuluTalk mixture.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u4e24\u4e2a\u5f00\u653e\u540e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u521b\u9020\u4e86\u6837\u672c\u66f4\u5c11\u4f46\u6027\u80fd\u4f18\u8d8a\u7684\u65b0\u6570\u636e\u96c6TuluTalk\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u6d41\u884c\u7684\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u5bf9\u516c\u4f17\u4e0d\u53ef\u89c1\u4e14\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u5f00\u653e\u6e90\u7801\u7684\u6570\u636e\u66ff\u4ee3\u65b9\u6848\u867d\u7136\u8868\u73b0\u4e0d\u9519\uff0c\u4f46\u5c1a\u65e0\u7cfb\u7edf\u6027\u6bd4\u8f83\u3002\u56e0\u6b64\uff0c\u9488\u5bf9\u6570\u636e\u8d28\u91cf\u7684\u8bc4\u4f30\u5f71\u54cd\u7f3a\u4e4f\u660e\u786e\u7684\u5206\u6790\u3002", "method": "\u5e94\u7528Magpie\u6846\u67b6\u5bf9\u6837\u672c\u8fdb\u884c\u8be6\u7ec6\u7684\u8d28\u91cf\u6307\u6807\u6807\u6ce8\uff0c\u5305\u62ec\u5bf9\u8bdd\u7ed3\u6784\u3001\u4efb\u52a1\u7c7b\u522b\u3001\u8f93\u5165\u8d28\u91cf\u548c\u54cd\u5e94\u8d28\u91cf\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7ed3\u6784\u6027\u548c\u5b9a\u6027\u4e0a\u7684\u76f8\u4f3c\u6027\u4e0e\u5dee\u5f02\u7684\u7edf\u8ba1\u5206\u6790\u3002\u57fa\u4e8e\u8fd9\u4e9b\u5206\u6790\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u7b56\u5212\u65b9\u6cd5\u6765\u751f\u6210\u65b0\u7684\u6570\u636e\u96c6TuluTalk\u3002", "result": "TuluTalk\u5305\u542b\u7684\u6837\u672c\u6bd4\u539f\u59cb\u6570\u636e\u96c6\u5c1114%\uff0c\u4f46\u5728\u5173\u952e\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u5339\u914d\u6216\u8d85\u8fc7\u5b83\u4eec\u3002", "conclusion": "\u901a\u8fc7\u7efc\u5408\u5206\u6790\u4e24\u4e2a\u4e3b\u8981\u7684\u5f00\u653e\u540e\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u51fa\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u6df7\u5408\u96c6TuluTalk\uff0c\u5176\u6837\u672c\u91cf\u51cf\u5c11\u4e8614%\u4f46\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u539f\u6570\u636e\u96c6\u3002\u7814\u7a76\u6210\u679c\u4e3a\u6784\u5efa\u66f4\u6709\u6548\u7684\u540e\u8bad\u7ec3\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.06359", "pdf": "https://arxiv.org/pdf/2506.06359", "abs": "https://arxiv.org/abs/2506.06359", "authors": ["Gabriel Antonesi", "Tudor Cioara", "Ionut Anghel", "Vasilis Michalakopoulos", "Elissaios Sarmas", "Liana Toderean"], "title": "From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Artificial intelligence (AI) has long promised to improve energy management\nin smart grids by enhancing situational awareness and supporting more effective\ndecision-making. While traditional machine learning has demonstrated notable\nresults in forecasting and optimization, it often struggles with\ngeneralization, situational awareness, and heterogeneous data integration.\nRecent advances in foundation models such as Transformer architecture and Large\nLanguage Models (LLMs) have demonstrated improved capabilities in modelling\ncomplex temporal and contextual relationships, as well as in multi-modal data\nfusion which is essential for most AI applications in the energy sector. In\nthis review we synthesize the rapid expanding field of AI applications in the\nenergy domain focusing on Transformers and LLMs. We examine the architectural\nfoundations, domain-specific adaptations and practical implementations of\ntransformer models across various forecasting and grid management tasks. We\nthen explore the emerging role of LLMs in the field: adaptation and fine tuning\nfor the energy sector, the type of tasks they are suited for, and the new\nchallenges they introduce. Along the way, we highlight practical\nimplementations, innovations, and areas where the research frontier is rapidly\nexpanding. These recent developments reviewed underscore a broader trend:\nGenerative AI (GenAI) is beginning to augment decision-making not only in\nhigh-level planning but also in day-to-day operations, from forecasting and\ngrid balancing to workforce training and asset onboarding. Building on these\ndevelopments, we introduce the concept of the Agentic Digital Twin, a\nnext-generation model that integrates LLMs to bring autonomy, proactivity, and\nsocial interaction into digital twin-based energy management systems.", "AI": {"tldr": "AI, especially Transformers and LLMs, improves energy management by enhancing decision-making and situational awareness.", "motivation": "To synthesize advancements in AI, particularly Transformers and LLMs, for improving energy management in smart grids, addressing challenges in generalization, situational awareness, and heterogeneous data integration.", "method": "The paper reviews recent advancements in AI applications, specifically focusing on Transformers and Large Language Models, examining their architectural foundations, domain-specific adaptations, and practical implementations in the energy sector.", "result": "The paper introduces the concept of the Agentic Digital Twin, a next-generation model integrating LLMs to enhance autonomy and proactivity in digital twin-based energy management systems.", "conclusion": "Generative AI is playing an increasing role in both high-level planning and daily operations in the energy sector, enhancing tasks such as forecasting, grid balancing, workforce training, and asset onboarding."}}
{"id": "2506.06698", "pdf": "https://arxiv.org/pdf/2506.06698", "abs": "https://arxiv.org/abs/2506.06698", "authors": ["Yitao Liu", "Chenglei Si", "Karthik Narasimhan", "Shunyu Yao"], "title": "Contextual Experience Replay for Self-Improvement of Language Agents", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "Accepted to ACL 2025. 20 pages", "summary": "Large language model (LLM) agents have been applied to sequential\ndecision-making tasks such as web navigation, but without any\nenvironment-specific experiences, they often fail in these complex tasks.\nMoreover, current LLM agents are not designed to continually learn from past\nexperiences during inference time, which could be crucial for them to gain\nthese environment-specific experiences. To address this, we propose Contextual\nExperience Replay (CER), a training-free framework to enable efficient\nself-improvement for language agents in their context window. Specifically, CER\naccumulates and synthesizes past experiences into a dynamic memory buffer.\nThese experiences encompass environment dynamics and common decision-making\npatterns, allowing the agents to retrieve and augment themselves with relevant\nknowledge in new tasks, enhancing their adaptability in complex environments.\nWe evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On\nVisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena,\nCER also gets a competitive average success rate of 36.7%, relatively improving\nthe success rate of the GPT-4o agent baseline by 51.0%. We also conduct a\ncomprehensive analysis on it to prove its efficiency, validity and understand\nit better.", "AI": {"tldr": "\u5f15\u5165CER\u6846\u67b6\uff0c\u589e\u5f3a\u8bed\u8a00\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u76ee\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u73af\u5883\u7279\u5b9a\u7ecf\u9a8c\u7f3a\u4e4f\u60c5\u51b5\u4e0b\u5e38\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5931\u8d25\uff0c\u4e14\u65e0\u6cd5\u5728\u63a8\u7406\u65f6\u95f4\u6301\u7eed\u5b66\u4e60\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u81ea\u6211\u63d0\u5347\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aContextual Experience Replay (CER) \u7684\u65e0\u8bad\u7ec3\u6846\u67b6\uff0c\u7d2f\u79ef\u5e76\u5408\u6210\u8fc7\u53bb\u7684\u7ecf\u9a8c\u5230\u52a8\u6001\u8bb0\u5fc6\u7f13\u51b2\u533a\u4e2d\uff0c\u4ee5\u4fbf\u5728\u65b0\u7684\u4efb\u52a1\u4e2d\u68c0\u7d22\u548c\u6269\u5145\u76f8\u5173\u77e5\u8bc6\u3002", "result": "\u5728VisualWebArena\u4e0a\uff0cCER\u53d6\u5f97\u4e8631.9%\u7684\u7ade\u4e89\u6027\u8868\u73b0\uff1b\u5728WebArena\u4e0a\uff0cCER\u5b9e\u73b0\u4e8636.7%\u7684\u5e73\u5747\u6210\u529f\u7387\uff0c\u76f8\u6bd4GPT-4o\u4ee3\u7406\u57fa\u51c6\u6210\u529f\u7387\u63d0\u9ad8\u4e8651.0%\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165Contextual Experience Replay (CER)\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8bed\u8a00\u4ee3\u7406\u5728\u590d\u6742\u73af\u5883\u4e0b\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2506.06539", "pdf": "https://arxiv.org/pdf/2506.06539", "abs": "https://arxiv.org/abs/2506.06539", "authors": ["Yijie Hao", "Haofei Yu", "Jiaxuan You"], "title": "Beyond Facts: Evaluating Intent Hallucination in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 main conference", "summary": "When exposed to complex queries containing multiple conditions, today's large\nlanguage models (LLMs) tend to produce responses that only partially satisfy\nthe query while neglecting certain conditions. We therefore introduce the\nconcept of Intent Hallucination. In this phenomenon, LLMs either omit\n(neglecting to address certain parts) or misinterpret (responding to invented\nquery parts) elements of the given query, leading to intent hallucinated\ngeneration. To systematically evaluate intent hallucination, we introduce\nFAITHQA, a novel benchmark for intent hallucination that contains 20,068\nproblems, covering both query-only and retrieval-augmented generation (RAG)\nsetups with varying topics and difficulty. FAITHQA is the first hallucination\nbenchmark that goes beyond factual verification, tailored to identify the\nfundamental cause of intent hallucination. By evaluating various LLMs on\nFAITHQA, we find that (1) intent hallucination is a common issue even for\nstate-of-the-art models, and (2) the phenomenon stems from omission or\nmisinterpretation of LLMs. To facilitate future research, we introduce an\nautomatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting\nintent hallucination. Human evaluation results demonstrate that CONSTRAINT\nSCORE is closer to human performance for intent hallucination compared to\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u68c0\u6d4b\u610f\u56fe\u5e7b\u89c9\u7684FAITHQA\u57fa\u51c6\u548cCONSTRAINT SCORE\u6307\u6807\uff0c\u53d1\u73b0\u5373\u4fbf\u662f\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u4e5f\u5e38\u51fa\u73b0\u610f\u56fe\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u5bf9\u5305\u542b\u591a\u4e2a\u6761\u4ef6\u7684\u590d\u6742\u67e5\u8be2\u65f6\uff0c\u5e38\u5e38\u53ea\u90e8\u5206\u6ee1\u8db3\u67e5\u8be2\u800c\u5ffd\u7565\u67d0\u4e9b\u6761\u4ef6\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u8fd9\u79cd\u73b0\u8c61\u8fdb\u884c\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5f15\u5165FAITHQA\u57fa\u51c6\u548cCONSTRAINT SCORE\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u68c0\u6d4b\u610f\u56fe\u5e7b\u89c9\u3002", "result": "FAITHQA\u57fa\u51c6\u8bc4\u4f30\u663e\u793a\uff0c\u610f\u56fe\u5e7b\u89c9\u666e\u904d\u5b58\u5728\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e2d\u3002\u5f15\u5165\u7684CONSTRAINT SCORE\u6307\u6807\u80fd\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u68c0\u6d4b\u610f\u56fe\u5e7b\u89c9\u3002", "conclusion": "\u610f\u56fe\u5e7b\u89c9\u5728\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4ecd\u7136\u5f88\u5e38\u89c1\uff0c\u4e3b\u8981\u7531\u4e8e\u7701\u7565\u6216\u8bef\u89e3\u67e5\u8be2\u7684\u90e8\u5206\u3002"}}
{"id": "2506.06380", "pdf": "https://arxiv.org/pdf/2506.06380", "abs": "https://arxiv.org/abs/2506.06380", "authors": ["Jingyi Gu", "Xuan Zhang", "Guiling Wang"], "title": "Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Extreme events, such as market crashes, natural disasters, and pandemics, are\nrare but catastrophic, often triggering cascading failures across\ninterconnected systems. Accurate prediction and early warning can help minimize\nlosses and improve preparedness. While data-driven methods offer powerful\ncapabilities for extreme event modeling, they require abundant training data,\nyet extreme event data is inherently scarce, creating a fundamental challenge.\nSynthetic data generation has emerged as a powerful solution. However, existing\nsurveys focus on general data with privacy preservation emphasis, rather than\nextreme events' unique performance requirements. This survey provides the first\noverview of synthetic data generation for extreme events. We systematically\nreview generative modeling techniques and large language models, particularly\nthose enhanced by statistical theory as well as specialized training and\nsampling mechanisms to capture heavy-tailed distributions. We summarize\nbenchmark datasets and introduce a tailored evaluation framework covering\nstatistical, dependence, visual, and task-oriented metrics. A central\ncontribution is our in-depth analysis of each metric's applicability in\nextremeness and domain-specific adaptations, providing actionable guidance for\nmodel evaluation in extreme settings. We categorize key application domains and\nidentify underexplored areas like behavioral finance, wildfires, earthquakes,\nwindstorms, and infectious outbreaks. Finally, we outline open challenges,\nproviding a structured foundation for advancing synthetic rare-event research.", "AI": {"tldr": "\u6587\u7ae0\u9996\u6b21\u7efc\u8ff0\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6280\u672f\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u8bc4\u4f30\u6846\u67b6\uff0c\u5206\u6790\u5404\u6307\u6807\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u7684\u9002\u7528\u6027\uff0c\u5e76\u5217\u51fa\u5f00\u653e\u6311\u6218\u548c\u672a\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002", "motivation": "\u6781\u7aef\u4e8b\u4ef6\u5982\u5e02\u573a\u5d29\u76d8\u3001\u81ea\u7136\u707e\u5bb3\u548c\u6d41\u884c\u75c5\u901a\u5e38\u662f\u7f55\u89c1\u4f46\u707e\u96be\u6027\u7684\u4e8b\u4ef6\uff0c\u53ef\u4ee5\u5f15\u53d1\u7cfb\u7edf\u6027\u7684\u8fde\u9501\u53cd\u5e94\u3002\u867d\u7136\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6781\u7aef\u4e8b\u4ef6\u5efa\u6a21\u4e2d\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u529f\u80fd\uff0c\u4f46\u4e4b\u6240\u9700\u7684\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u4e0e\u6781\u7aef\u4e8b\u4ef6\u6570\u636e\u7a00\u7f3a\u7684\u7279\u6027\u5f62\u6210\u77db\u76fe\u3002\u56e0\u6b64\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u751f\u6210\u5408\u6210\u6570\u636e\u6210\u4e3a\u89e3\u51b3\u8be5\u95ee\u9898\u7684\u91cd\u8981\u65b9\u6cd5\u3002", "method": "\u8fd9\u7bc7\u6587\u7ae0\u7cfb\u7edf\u56de\u987e\u4e86\u751f\u6210\u5efa\u6a21\u6280\u672f\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c24\u5176\u662f\u90a3\u4e9b\u7ecf\u8fc7\u7edf\u8ba1\u7406\u8bba\u589e\u5f3a\u7684\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86\u4e13\u95e8\u7684\u8bad\u7ec3\u548c\u91c7\u6837\u673a\u5236\u4ee5\u6355\u6349\u539a\u5c3e\u5206\u5e03\u7279\u5f81\u3002\u6b64\u5916\uff0c\u8fd8\u603b\u7ed3\u4e86\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u6db5\u76d6\u7edf\u8ba1\u3001\u4f9d\u8d56\u6027\u3001\u89c6\u89c9\u548c\u4efb\u52a1\u5bfc\u5411\u7684\u8bc4\u4ef7\u6846\u67b6\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u751f\u6210\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\uff0c\u5e76\u8bc6\u522b\u4e86\u884c\u4e3a\u91d1\u878d\u3001\u91ce\u706b\u3001\u5730\u9707\u3001\u98ce\u66b4\u548c\u611f\u67d3\u6027\u7206\u53d1\u7b49\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u9886\u57df\uff0c\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u5f00\u653e\u6311\u6218\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u5bf9\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7684\u6982\u8ff0\u3002\u901a\u8fc7\u5bf9\u751f\u6210\u5efa\u6a21\u6280\u672f\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee5\u53ca\u7edf\u8ba1\u7406\u8bba\u589e\u5f3a\u65b9\u6cd5\u7684\u7cfb\u7edf\u56de\u987e\uff0c\u6587\u7ae0\u4e3a\u6781\u7aef\u4e8b\u4ef6\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u63d0\u4f9b\u4e86\u884c\u4e4b\u6709\u6548\u7684\u8bc4\u4f30\u6846\u67b6\u53ca\u9886\u57df\u9002\u5e94\u6027\u5206\u6790\u3002"}}
{"id": "2506.06714", "pdf": "https://arxiv.org/pdf/2506.06714", "abs": "https://arxiv.org/abs/2506.06714", "authors": ["Hamied Nabizada", "Tom Jeleniewski", "Lasse Beers", "Maximilian Weigand", "Felix Gehlhoff", "Alexander Fay"], "title": "Integrating AI Planning Semantics into SysML System Models for Automated PDDL File Generation", "categories": ["cs.AI"], "comment": null, "summary": "This paper presents a SysML profile that enables the direct integration of\nplanning semantics based on the Planning Domain Definition Language (PDDL) into\nsystem models. Reusable stereotypes are defined for key PDDL concepts such as\ntypes, predicates, functions and actions, while formal OCL constraints ensure\nsyntactic consistency. The profile was derived from the Backus-Naur Form (BNF)\ndefinition of PDDL 3.1 to align with SysML modeling practices. A case study\nfrom aircraft manufacturing demonstrates the application of the profile: a\nrobotic system with interchangeable end effectors is modeled and enriched to\ngenerate both domain and problem descriptions in PDDL format. These are used as\ninput to a PDDL solver to derive optimized execution plans. The approach\nsupports automated and model-based generation of planning descriptions and\nprovides a reusable bridge between system modeling and AI planning in\nengineering design.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cdSysML\u6846\u67b6\uff0c\u53ef\u5c06PDDL\u7684\u89c4\u5212\u8bed\u4e49\u96c6\u6210\u5230\u7cfb\u7edf\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u53ef\u91cd\u7528\u523b\u677f\u5370\u8c61\u5b9a\u4e49\u5173\u952e\u6982\u5ff5\uff0c\u5e76\u501f\u52a9OCL\u7ea6\u675f\u786e\u4fdd\u4e00\u81f4\u6027\u3002\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u652f\u6301\u5728\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u81ea\u52a8\u5316\u548c\u6a21\u578b\u5316\u7684\u89c4\u5212\u751f\u6210\u3002", "motivation": "\u5728\u7cfb\u7edf\u6a21\u578b\u4e2d\u76f4\u63a5\u96c6\u6210\u57fa\u4e8e\u89c4\u5212\u57df\u5b9a\u4e49\u8bed\u8a00\uff08PDDL\uff09\u7684\u89c4\u5212\u8bed\u4e49\uff0c\u4ee5\u4fbf\u652f\u6301\u81ea\u52a8\u5316\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u63cf\u8ff0\u751f\u6210\uff0c\u5e76\u5728\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u63d0\u4f9b\u53ef\u91cd\u7528\u7684\u6865\u6881\u3002", "method": "\u5b9a\u4e49\u53ef\u91cd\u7528\u7684\u523b\u677f\u5370\u8c61\uff0c\u4ee5\u652f\u6301PDDL\u7684\u5173\u952e\u6982\u5ff5\uff0c\u5982\u7c7b\u578b\u3001\u8c13\u8bcd\u3001\u51fd\u6570\u548c\u52a8\u4f5c\uff0c\u5e76\u901a\u8fc7\u6b63\u5f0f\u7684OCL\u7ea6\u675f\u786e\u4fdd\u8bed\u6cd5\u4e00\u81f4\u6027\u3002\u91c7\u7528BNF\u5b9a\u4e49\u7684PDDL 3.1\u63a8\u5bfc\u51fa\u7684\u6846\u67b6\uff0c\u5e94\u7528\u4e8eSysML\u5efa\u6a21\u5b9e\u8df5\u3002", "result": "\u901a\u8fc7\u822a\u5929\u5236\u9020\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5e94\u7528\uff1a\u4e00\u4e2a\u5177\u6709\u53ef\u66f4\u6362\u672b\u7aef\u6267\u884c\u5668\u7684\u673a\u5668\u4eba\u7cfb\u7edf\u88ab\u5efa\u6a21\u548c\u4e30\u5bcc\uff0c\u4ee5\u751f\u6210PDDL\u683c\u5f0f\u7684\u57df\u548c\u95ee\u9898\u63cf\u8ff0\u3002\u8fd9\u4e9b\u63cf\u8ff0\u88ab\u8f93\u5165\u5230PDDL\u6c42\u89e3\u5668\u4e2d\uff0c\u4ee5\u5bfc\u51fa\u4f18\u5316\u7684\u6267\u884c\u8ba1\u5212\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u652f\u6301\u81ea\u52a8\u5316\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u63cf\u8ff0\u751f\u6210\uff0c\u5e76\u5728\u5de5\u7a0b\u8bbe\u8ba1\u4e2d\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5efa\u6a21\u548cAI\u89c4\u5212\u4e4b\u95f4\u53ef\u91cd\u7528\u7684\u6865\u6881\u3002"}}
{"id": "2506.06561", "pdf": "https://arxiv.org/pdf/2506.06561", "abs": "https://arxiv.org/abs/2506.06561", "authors": ["Ho Yin 'Sam' Ng", "Ting-Yao Hsu", "Aashish Anantha Ramakrishnan", "Branislav Kveton", "Nedim Lipka", "Franck Dernoncourt", "Dongwon Lee", "Tong Yu", "Sungchul Kim", "Ryan A. Rossi", "Ting-Hao 'Kenneth' Huang"], "title": "LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Figure captions are crucial for helping readers understand and remember a\nfigure's key message. Many models have been developed to generate these\ncaptions, helping authors compose better quality captions more easily. Yet,\nauthors almost always need to revise generic AI-generated captions to match\ntheir writing style and the domain's style, highlighting the need for\npersonalization. Despite language models' personalization (LaMP) advances,\nthese technologies often focus on text-only settings and rarely address\nscenarios where both inputs and profiles are multimodal. This paper introduces\nLaMP-Cap, a dataset for personalized figure caption generation with multimodal\nfigure profiles. For each target figure, LaMP-Cap provides not only the needed\ninputs, such as figure images, but also up to three other figures from the same\ndocument--each with its image, caption, and figure-mentioning paragraphs--as a\nprofile to characterize the context. Experiments with four LLMs show that using\nprofile information consistently helps generate captions closer to the original\nauthor-written ones. Ablation studies reveal that images in the profile are\nmore helpful than figure-mentioning paragraphs, highlighting the advantage of\nusing multimodal profiles over text-only ones.", "AI": {"tldr": "\u5f15\u5165\u4e86\u53ef\u7528\u4e8e\u56fe\u4f8b\u4e2a\u6027\u5316\u751f\u6210\u7684LaMP-Cap\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u56fe\u50cf\u53ca\u591a\u6a21\u6001\u56fe\u50cf\u914d\u7f6e\u6587\u4ef6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4fe1\u606f\u63d0\u9ad8\u56fe\u4f8b\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u867d\u7136\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5316\u6280\u672f\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u591a\u6d89\u53ca\u4ec5\u9650\u6587\u5b57\u7684\u8bbe\u7f6e\uff0c\u5f88\u5c11\u6d89\u53ca\u591a\u6a21\u6001\u7684\u8f93\u5165\u548c\u914d\u7f6e\u6587\u4ef6\u3002", "method": "\u5f15\u5165LaMP-Cap\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u56fe\u50cf\u914d\u7f6e\u6587\u4ef6\u7684\u4e2a\u6027\u5316\u56fe\u4f8b\u8bf4\u660e\u751f\u6210\u3002", "result": "\u4f7f\u7528\u591a\u6a21\u6001\u914d\u7f6e\u6587\u4ef6\u7684\u4fe1\u606f\u53ef\u4ee5\u5e2e\u52a9\u66f4\u597d\u5730\u751f\u6210\u63a5\u8fd1\u4f5c\u8005\u98ce\u683c\u7684\u56fe\u4f8b\uff0c\u56fe\u7247\u6bd4\u6587\u5b57\u6bb5\u843d\u66f4\u6709\u52a9\u4e8e\u63d0\u5347\u7ed3\u679c\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5229\u7528\u56fe\u50cf\u7b80\u6863\u53ef\u4ee5\u751f\u6210\u66f4\u63a5\u8fd1\u539f\u4f5c\u8005\u7f16\u5199\u7684\u56fe\u4f8b\u8bf4\u660e\u3002"}}
{"id": "2506.06398", "pdf": "https://arxiv.org/pdf/2506.06398", "abs": "https://arxiv.org/abs/2506.06398", "authors": ["Yin Li"], "title": "Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization", "categories": ["cs.LG", "cs.AI", "68T07, 68Q32", "I.2.6; I.2.7; F.1.1"], "comment": null, "summary": "Positional encodings are a core part of transformer-based models, enabling\nprocessing of sequential data without recurrence. This paper presents a\ntheoretical framework to analyze how various positional encoding methods,\nincluding sinusoidal, learned, relative, and bias-based methods like Attention\nwith Linear Biases (ALiBi), impact a transformer's expressiveness,\ngeneralization ability, and extrapolation to longer sequences. Expressiveness\nis defined via function approximation, generalization bounds are established\nusing Rademacher complexity, and new encoding methods based on orthogonal\nfunctions, such as wavelets and Legendre polynomials, are proposed. The\nextrapolation capacity of existing and proposed encodings is analyzed,\nextending ALiBi's biasing approach to a unified theoretical context.\nExperimental evaluation on synthetic sequence-to-sequence tasks shows that\northogonal transform-based encodings outperform traditional sinusoidal\nencodings in generalization and extrapolation. This work addresses a critical\ngap in transformer theory, providing insights for design choices in natural\nlanguage processing, computer vision, and other transformer applications.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4f4d\u7f6e\u7f16\u7801\u5bf9Transformer\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7f16\u7801\u65b9\u6cd5\uff0c\u5176\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f4d\u7f6e\u7f16\u7801\u662fTransformer\u6a21\u578b\u5904\u7406\u5e8f\u5217\u6570\u636e\u7684\u6838\u5fc3\u90e8\u5206\u3002\u672c\u6587\u65e8\u5728\u5206\u6790\u4e0d\u540c\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5bf9Transformer\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u3001\u6cdb\u5316\u80fd\u529b\u53ca\u5bf9\u957f\u5e8f\u5217\u7684\u5916\u63a8\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u7f16\u7801\u65b9\u6cd5\u3002", "method": "\u7406\u8bba\u6846\u67b6\u5206\u6790\u5404\u79cd\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u57fa\u4e8e\u6b63\u4ea4\u51fd\u6570\u7684\u65b0\u7f16\u7801\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6b63\u4ea4\u53d8\u6362\u7f16\u7801\u5728\u6cdb\u5316\u548c\u5916\u63a8\u80fd\u529b\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684\u6b63\u5f26\u7f16\u7801\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u5404\u79cd\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5bf9\u4e8eTransformer\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6b63\u4ea4\u51fd\u6570\u7684\u65b0\u7f16\u7801\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684\u6b63\u5f26\u7f16\u7801\u3002"}}
{"id": "2506.06725", "pdf": "https://arxiv.org/pdf/2506.06725", "abs": "https://arxiv.org/abs/2506.06725", "authors": ["Guillaume Levy", "Cedric Colas", "Pierre-Yves Oudeyer", "Thomas Carta", "Clement Romac"], "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) possess general world knowledge but often\nstruggle to generate precise predictions in structured, domain-specific\ncontexts such as simulations. These limitations arise from their inability to\nground their broad, unstructured understanding in specific environments. To\naddress this, we present WorldLLM, a framework that enhances LLM-based world\nmodeling by combining Bayesian inference and autonomous active exploration with\nreinforcement learning. WorldLLM leverages the in-context learning abilities of\nLLMs to guide an LLM-based world model's predictions using natural language\nhypotheses given in its prompt. These hypotheses are iteratively refined\nthrough a Bayesian inference framework that leverages a second LLM as the\nproposal distribution given collected evidence. This evidence is collected\nusing a curiosity-driven reinforcement learning policy that explores the\nenvironment to find transitions with a low log-likelihood under our LLM-based\npredictive model using the current hypotheses. By alternating between refining\nhypotheses and collecting new evidence, our framework autonomously drives\ncontinual improvement of the predictions. Our experiments demonstrate the\neffectiveness of WorldLLM in a textual game environment that requires agents to\nmanipulate and combine objects. The framework not only enhances predictive\naccuracy, but also generates human-interpretable theories of environment\ndynamics.", "AI": {"tldr": "WorldLLM\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u5f3a\u5316\u5b66\u4e60\u6539\u5584LLM\u5728\u7279\u5b9a\u9886\u57df\u7684\u9884\u6d4b\u80fd\u529b\u3002\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u6587\u672c\u6e38\u620f\u4e2d\u6709\u6548\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "LLMs\u5728\u751f\u6210\u7ed3\u6784\u5316\u3001\u7279\u5b9a\u9886\u57df\u4e0a\u4e0b\u6587\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u65e0\u6cd5\u5c06\u5bbd\u6cdb\u7684\u975e\u7ed3\u6784\u5316\u7406\u89e3\u951a\u5b9a\u5230\u7279\u5b9a\u73af\u5883\u4e2d\u3002WorldLLM\u65e8\u5728\u901a\u8fc7\u63d0\u5347\u9884\u6d4b\u529f\u80fd\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u57fa\u4e8e\u597d\u5947\u5fc3\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5047\u8bbe\u6307\u5bfcLLM\u8fdb\u884c\u9884\u6d4b\u3002\u5047\u8bbe\u5728\u6536\u96c6\u7684\u8bc1\u636e\u652f\u6301\u4e0b\uff0c\u901a\u8fc7\u4f7f\u7528\u7b2c\u4e8c\u4e2aLLM\u4f5c\u4e3a\u63d0\u51fa\u5206\u5e03\u8fdb\u884c\u8c03\u6574\uff0c\u5e76\u901a\u8fc7\u63a2\u7d22\u4f4e\u5bf9\u6570\u4f3c\u7136\u7684\u72b6\u6001\u8f6c\u6362\u6765\u6536\u96c6\u8bc1\u636e\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWorldLLM\u5728\u9700\u8981\u64cd\u63a7\u548c\u7ec4\u5408\u5bf9\u8c61\u7684\u6587\u672c\u6e38\u620f\u73af\u5883\u4e2d\u662f\u6709\u6548\u7684\uff0c\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u751f\u6210\u73af\u5883\u52a8\u6001\u7684\u7406\u8bba\u3002", "conclusion": "WorldLLM\u6846\u67b6\u63d0\u9ad8\u4e86LLM\u5728\u7ed3\u6784\u5316\u3001\u7279\u5b9a\u9886\u57df\u6a21\u62df\u73af\u5883\u4e2d\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u901a\u8fc7\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u4e3b\u4e3b\u52a8\u63a2\u7d22\u5b9e\u73b0\u3002\u8fd9\u4e00\u65b9\u6cd5\u4f7f\u9884\u6d4b\u66f4\u51c6\u786e\uff0c\u5e76\u751f\u6210\u53ef\u4eba\u7c7b\u89e3\u91ca\u7684\u73af\u5883\u52a8\u6001\u7406\u8bba\u3002"}}
{"id": "2506.06589", "pdf": "https://arxiv.org/pdf/2506.06589", "abs": "https://arxiv.org/abs/2506.06589", "authors": ["Jacqueline He", "Howard Yen", "Margaret Li", "Shuyue Stella Li", "Zhiyuan Zeng", "Weijia Shi", "Yulia Tsvetkov", "Danqi Chen", "Pang Wei Koh", "Luke Zettlemoyer"], "title": "Precise Information Control in Long-Form Text Generation", "categories": ["cs.CL"], "comment": "56 pages, 8 figures. Code and models are publicly available at\n  https://github.com/jacqueline-he/precise-information-control", "summary": "A central challenge in modern language models (LMs) is intrinsic\nhallucination: the generation of information that is plausible but\nunsubstantiated relative to input context. To study this problem, we propose\nPrecise Information Control (PIC), a new task formulation that requires models\nto generate long-form outputs grounded in a provided set of short\nself-contained statements, known as verifiable claims, without adding any\nunsupported ones. For comprehensiveness, PIC includes a full setting that tests\na model's ability to include exactly all input claims, and a partial setting\nthat requires the model to selectively incorporate only relevant claims. We\npresent PIC-Bench, a benchmark of eight long-form generation tasks (e.g.,\nsummarization, biography generation) adapted to the PIC setting, where LMs are\nsupplied with well-formed, verifiable input claims. Our evaluation of a range\nof open and proprietary LMs on PIC-Bench reveals that, surprisingly,\nstate-of-the-art LMs still intrinsically hallucinate in over 70% of outputs. To\nalleviate this lack of faithfulness, we introduce a post-training framework,\nusing a weakly supervised preference data construction method, to train an 8B\nPIC-LM with stronger PIC ability--improving from 69.1% to 91.0% F1 in the full\nPIC setting. When integrated into end-to-end factual generation pipelines,\nPIC-LM improves exact match recall by 17.1% on ambiguous QA with retrieval, and\nfactual precision by 30.5% on a birthplace verification task, underscoring the\npotential of precisely grounded generation.", "AI": {"tldr": "\u7814\u7a76\u4ecb\u7ecd\u4e86'\u51c6\u786e\u4fe1\u606f\u63a7\u5236'\u4efb\u52a1\uff0c\u7528\u4e8e\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u65e0\u652f\u6301\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u58f0\u660e\u8f93\u5165\u63d0\u9ad8\u6a21\u578b\u957f\u7bc7\u751f\u6210\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4fe1\u606f\u770b\u4f3c\u5408\u7406\u4f46\u5b9e\u9645\u4e0a\u7f3a\u4e4f\u652f\u6301\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u751f\u6210\u4fe1\u606f\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa'\u51c6\u786e\u4fe1\u606f\u63a7\u5236\uff08PIC\uff09'\u4efb\u52a1\uff0c\u8ba9\u6a21\u578b\u4ec5\u57fa\u4e8e\u4e00\u7ec4\u77ed\u5c0f\u7684\u81ea\u5305\u542b\u58f0\u660e\u751f\u6210\u957f\u7bc7\u8f93\u51fa\u3002\u4f7f\u7528\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u7684\u504f\u597d\u6570\u636e\u6784\u5efa\u65b9\u6cd5\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u8bad\u7ec3\u51fa\u5177\u6709\u66f4\u5f3aPIC\u80fd\u529b\u76848B PIC-LM\u578b\u53f7\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6539\u8fdb\u5168PIC\u8bbe\u7f6e\u4e2d\u7684\u7cbe\u786e\u5339\u914d\u53ec\u56de\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u7cbe\u786e\u5ea6\u3002", "result": "\u65b0\u63d0\u51fa\u7684PIC\u4efb\u52a1\u5728\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u5e7b\u89c9\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\u3002\u7ecf\u8fc7\u8bad\u7ec3\u7684PIC-LM\u578b\u53f7\u5728\u5168PIC\u8bbe\u7f6e\u4e2dF1\u63d0\u5347\u81f391.0%\uff0c\u5728\u6a21\u7ccaQA\u548c\u5177\u4f53\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'\u51c6\u786e\u4fe1\u606f\u63a7\u5236'\u7684\u65b0\u4efb\u52a1\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u5373\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u65e0\u4f9d\u636e\u7684\u4fe1\u606f\u3002\u901a\u8fc7\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u8f93\u5165\u58f0\u660e\uff0c\u786e\u4fdd\u751f\u6210\u7684\u957f\u7bc7\u8f93\u51fa\u4e2d\u6ca1\u6709\u4e0d\u652f\u6301\u7684\u4fe1\u606f\u3002\u8fd9\u79cd\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u957f\u7bc7\u4fe1\u606f\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06411", "pdf": "https://arxiv.org/pdf/2506.06411", "abs": "https://arxiv.org/abs/2506.06411", "authors": ["Paul Fogel", "Christophe Geissler", "George Luta"], "title": "CoxNTF: A New Approach for Joint Clustering and Prediction in Survival Analysis", "categories": ["cs.LG"], "comment": "7 pages, 3 figures, Conference on Lifetime Data Science 2025,\n  Brooklyn, New York, USA", "summary": "The interpretation of the results of survival analysis often benefits from\nlatent factor representations of baseline covariates. However, existing\nmethods, such as Nonnegative Matrix Factorization (NMF), do not incorporate\nsurvival information, limiting their predictive power. We present CoxNTF, a\nnovel approach that uses non-negative tensor factorization (NTF) to derive\nmeaningful latent representations that are closely associated with survival\noutcomes. CoxNTF constructs a weighted covariate tensor in which survival\nprobabilities derived from the Coxnet model are used to guide the tensorization\nprocess. Our results show that CoxNTF achieves survival prediction performance\ncomparable to using Coxnet with the original covariates, while providing a\nstructured and interpretable clustering framework. In addition, the new\napproach effectively handles feature redundancy, making it a powerful tool for\njoint clustering and prediction in survival analysis.", "AI": {"tldr": "CoxNTF enhances survival analysis by combining Coxnet-based survival probabilities with non-negative tensor factorization, improving both prediction accuracy and interpretability compared to traditional methods.", "motivation": "Existing methods like Nonnegative Matrix Factorization (NMF) don't incorporate survival information, which limits their predictive power. This motivates the need for a new approach that integrates survival data in latent factor representation.", "method": "CoxNTF uses non-negative tensor factorization (NTF) with survival probabilities derived from the Coxnet model to create a weighted covariate tensor, guiding the tensorization process.", "result": "CoxNTF matches the performance of the Coxnet model's survival predictions when using original covariates, while also providing an interpretable clustering framework and effectively handling feature redundancy.", "conclusion": "CoxNTF achieves a balance between predictive performance and interpretability in survival analysis by utilizing non-negative tensor factorization to produce meaningful latent representations related to survival outcomes."}}
{"id": "2506.06727", "pdf": "https://arxiv.org/pdf/2506.06727", "abs": "https://arxiv.org/abs/2506.06727", "authors": ["Can Li", "Ting Zhang", "Mei Wang", "Hua Huang"], "title": "VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Large Multimodal Models (LMMs) have demonstrated remarkable problem-solving\ncapabilities across various domains. However, their ability to perform\nmathematical reasoning when answer options are represented as images--an\nessential aspect of multi-image comprehension--remains underexplored. To bridge\nthis gap, we introduce VisioMath, a benchmark designed to evaluate mathematical\nreasoning in multimodal contexts involving image-based answer choices.\nVisioMath comprises 8,070 images and 1,800 multiple-choice questions, where\neach answer option is an image, presenting unique challenges to existing LMMs.\nTo the best of our knowledge, VisioMath is the first dataset specifically\ntailored for mathematical reasoning in image-based-option scenarios, where\nfine-grained distinctions between answer choices are critical for accurate\nproblem-solving. We systematically evaluate state-of-the-art LMMs on VisioMath\nand find that even the most advanced models struggle with this task. Notably,\nGPT-4o achieves only 45.9% accuracy, underscoring the limitations of current\nmodels in reasoning over visually similar answer choices. By addressing a\ncrucial gap in existing benchmarks, VisioMath establishes a rigorous testbed\nfor future research, driving advancements in multimodal reasoning.", "AI": {"tldr": "VisioMath\u662f\u9996\u4e2a\u4e13\u4e3a\u8bc4\u4f30\u56fe\u50cf\u9009\u9879\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u800c\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5904\u7406\u6570\u5b66\u63a8\u7406\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5904\u7406\u57fa\u4e8e\u56fe\u50cf\u7684\u9009\u9879\u65f6\u7684\u80fd\u529b\u5c1a\u672a\u63a2\u7d22\u3002VisioMath\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u5f15\u5165VisioMath\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u56fe\u50cf\u9009\u9879\u73af\u5883\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002VisioMath\u5305\u542b8,070\u5f20\u56fe\u50cf\u548c1,800\u4e2a\u591a\u9879\u9009\u62e9\u9898\u3002", "result": "\u901a\u8fc7\u5728VisioMath\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u6700\u5148\u8fdb\u7684LMMs\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u96be\u4ee5\u5904\u7406\u8fd9\u4e9b\u4efb\u52a1\u3002\u4f8b\u5982\uff0cGPT-4o\u4ec5\u5b9e\u73b0\u4e8645.9%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u73b0\u6709\u7684\u6700\u5148\u8fdb\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e0a\u4ecd\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u57fa\u4e8e\u56fe\u50cf\u7684\u9009\u9879\u65f6\u3002VisioMath\u6570\u636e\u96c6\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u9762\u4e34\u7684\u6311\u6218\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2506.06605", "pdf": "https://arxiv.org/pdf/2506.06605", "abs": "https://arxiv.org/abs/2506.06605", "authors": ["Xiao Wang", "Mengjue Tan", "Qiao Jin", "Guangzhi Xiong", "Yu Hu", "Aidong Zhang", "Zhiyong Lu", "Minjia Zhang"], "title": "MedCite: Can Language Models Generate Verifiable Text for Medicine?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Existing LLM-based medical question-answering systems lack citation\ngeneration and evaluation capabilities, raising concerns about their adoption\nin practice. In this work, we introduce \\name, the first end-to-end framework\nthat facilitates the design and evaluation of citation generation with LLMs for\nmedical tasks. Meanwhile, we introduce a novel multi-pass retrieval-citation\nmethod that generates high-quality citations. Our evaluation highlights the\nchallenges and opportunities of citation generation for medical tasks, while\nidentifying important design choices that have a significant impact on the\nfinal citation quality. Our proposed method achieves superior citation\nprecision and recall improvements compared to strong baseline methods, and we\nshow that evaluation results correlate well with annotation results from\nprofessional experts.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\u7528\u4e8e\u652f\u6301LLM\u5728\u533b\u5b66\u4efb\u52a1\u4e2d\u7684\u5f15\u7528\u751f\u6210\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f15\u7528\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u533b\u5b66\u95ee\u7b54\u7cfb\u7edf\u7f3a\u4e4f\u5f15\u7528\u751f\u6210\u548c\u8bc4\u4f30\u80fd\u529b\uff0c\u8fd9\u5bf9\u5176\u5b9e\u8df5\u91c7\u7528\u4ea7\u751f\u4e86\u987e\u8651\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6b21\u68c0\u7d22\u5f15\u7528\u65b9\u6cd5\uff0c\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5f15\u7528\uff0c\u5e76\u901a\u8fc7\u4e13\u4e1a\u4e13\u5bb6\u7684\u6ce8\u91ca\u7ed3\u679c\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5f15\u7528\u7cbe\u786e\u5ea6\u548c\u56de\u5fc6\u5ea6\u65b9\u9762\u76f8\u8f83\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u663e\u8457\u7684\u63d0\u5347\uff0c\u5e76\u4e14\u8bc4\u4f30\u7ed3\u679c\u4e0e\u4e13\u4e1a\u4e13\u5bb6\u7684\u6ce8\u91ca\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\name\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7528\u4e8e\u533b\u7597\u4efb\u52a1\u7684LLM\u5f15\u53d1\u7684\u5f15\u7528\u751f\u6210\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f15\u7528\u7684\u7cbe\u51c6\u5ea6\u548c\u56de\u5fc6\u5ea6\u3002"}}
{"id": "2506.06412", "pdf": "https://arxiv.org/pdf/2506.06412", "abs": "https://arxiv.org/abs/2506.06412", "authors": ["Junming Wang", "Yi Shi"], "title": "NeurNCD: Novel Class Discovery via Implicit Neural Representation", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted by ICMR 2024", "summary": "Discovering novel classes in open-world settings is crucial for real-world\napplications. Traditional explicit representations, such as object descriptors\nor 3D segmentation maps, are constrained by their discrete, hole-prone, and\nnoisy nature, which hinders accurate novel class discovery. To address these\nchallenges, we introduce NeurNCD, the first versatile and data-efficient\nframework for novel class discovery that employs the meticulously designed\nEmbedding-NeRF model combined with KL divergence as a substitute for\ntraditional explicit 3D segmentation maps to aggregate semantic embedding and\nentropy in visual embedding space. NeurNCD also integrates several key\ncomponents, including feature query, feature modulation and clustering,\nfacilitating efficient feature augmentation and information exchange between\nthe pre-trained semantic segmentation network and implicit neural\nrepresentations. As a result, our framework achieves superior segmentation\nperformance in both open and closed-world settings without relying on densely\nlabelled datasets for supervised training or human interaction to generate\nsparse label supervision. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches on the NYUv2 and Replica\ndatasets.", "AI": {"tldr": "NeurNCD\u63d0\u4f9b\u4e86\u4e00\u79cd\u6570\u636e\u9ad8\u6548\u7684\u65b0\u7c7b\u53d1\u73b0\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u5927\u91cf\u6807\u8bb0\u6570\u636e\u6216\u4eba\u5de5\u4ea4\u4e92\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9ad8\u7ea7\u7684\u5206\u5272\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u663e\u5f0f\u8868\u793a\u65b9\u5f0f\u53d7\u9650\u4e8e\u5176\u79bb\u6563\u6027\u3001\u6613\u4ea7\u751f\u5b54\u6d1e\u548c\u566a\u58f0\u7684\u7279\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u65b0\u7c7b\u7684\u51c6\u786e\u53d1\u73b0\u3002", "method": "\u4f7f\u7528Embedding-NeRF\u6a21\u578b\u7ed3\u5408KL\u6563\u5ea6\u66ff\u4ee3\u4f20\u7edf\u76843D\u5206\u5272\u56fe\u6765\u805a\u5408\u8bed\u4e49\u5d4c\u5165\u548c\u89c6\u89c9\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u71b5\u3002", "result": "NeurNCD\u5728NYUv2\u548cReplica\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6NeurNCD\uff0c\u80fd\u591f\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u9ad8\u6548\u8fdb\u884c\u65b0\u7c7b\u53d1\u73b0\uff0c\u5e76\u4e14\u5728\u95ed\u73af\u548c\u5f00\u653e\u4e16\u754c\u4e2d\u5747\u80fd\u5b9e\u73b0\u4f18\u8d8a\u7684\u5206\u5272\u8868\u73b0\u3002"}}
{"id": "2506.06739", "pdf": "https://arxiv.org/pdf/2506.06739", "abs": "https://arxiv.org/abs/2506.06739", "authors": ["Andrew Cropper", "Filipe Gouveia", "David M. Cerna"], "title": "Honey, I shrunk the hypothesis space (through logical preprocessing)", "categories": ["cs.AI", "cs.LG"], "comment": "Submitted to JAIR", "summary": "Inductive logic programming (ILP) is a form of logical machine learning. The\ngoal is to search a hypothesis space for a hypothesis that generalises training\nexamples and background knowledge. We introduce an approach that 'shrinks' the\nhypothesis space before an ILP system searches it. Our approach uses background\nknowledge to find rules that cannot be in an optimal hypothesis regardless of\nthe training examples. For instance, our approach discovers relationships such\nas \"even numbers cannot be odd\" and \"prime numbers greater than 2 are odd\". It\nthen removes violating rules from the hypothesis space. We implement our\napproach using answer set programming and use it to shrink the hypothesis space\nof a constraint-based ILP system. Our experiments on multiple domains,\nincluding visual reasoning and game playing, show that our approach can\nsubstantially reduce learning times whilst maintaining predictive accuracies.\nFor instance, given just 10 seconds of preprocessing time, our approach can\nreduce learning times from over 10 hours to only 2 seconds.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7f29\u5c0f\u5047\u8bbe\u7a7a\u95f4\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u80cc\u666f\u77e5\u8bc6\u53bb\u9664\u4e0d\u53ef\u80fd\u7684\u89c4\u5219\u6765\u63d0\u9ad8ILP\u7cfb\u7edf\u7684\u6548\u7387\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u5b66\u4e60\u65f6\u95f4\u5e76\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u5f52\u7eb3\u903b\u8f91\u7f16\u7a0b (ILP) \u4e2d\u7684\u5047\u8bbe\u641c\u7d22\u7a7a\u95f4\u901a\u5e38\u975e\u5e38\u5927\uff0c\u641c\u7d22\u8fd9\u4e9b\u7a7a\u95f4\u9700\u8981\u8017\u8d39\u5927\u91cf\u65f6\u95f4\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u4e8b\u5148\u7f29\u5c0f\u5047\u8bbe\u7a7a\u95f4\u6765\u63d0\u9ad8ILP\u7cfb\u7edf\u7684\u6548\u7387\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u80cc\u666f\u77e5\u8bc6\u6765\u627e\u5230\u4e0d\u80fd\u5728\u6700\u4f73\u5047\u8bbe\u4e2d\u51fa\u73b0\u7684\u89c4\u5219\uff0c\u7136\u540e\u4ece\u5047\u8bbe\u7a7a\u95f4\u4e2d\u5220\u9664\u8fdd\u53cd\u8fd9\u4e9b\u89c4\u5219\u7684\u5047\u8bbe\u3002\u6211\u4eec\u901a\u8fc7\u56de\u7b54\u96c6\u7f16\u7a0b\u5b9e\u73b0\u8fd9\u4e00\u65b9\u6cd5\uff0c\u5e76\u7528\u4e8e\u6536\u7f29\u57fa\u4e8e\u7ea6\u675f\u7684ILP\u7cfb\u7edf\u7684\u5047\u8bbe\u7a7a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fdb\u884c\u4ec5 10 \u79d2\u7684\u9884\u5904\u7406\u540e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5b66\u4e60\u65f6\u95f4\u4ece\u8d85\u8fc7 10 \u5c0f\u65f6\u51cf\u5c11\u5230\u4ec5 2 \u79d2\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5b66\u4e60\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06607", "pdf": "https://arxiv.org/pdf/2506.06607", "abs": "https://arxiv.org/abs/2506.06607", "authors": ["Charles Goddard", "Fernando Fernandes Neto"], "title": "Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We present a training-free method to transplant tokenizers in pretrained\nlarge language models (LLMs) by reconstructing unseen token embeddings via\nOrthogonal Matching Pursuit (OMP). Specifically, we approximate each\nout-of-vocabulary token as a sparse linear combination of shared tokens, in two\nphases: first, compute each new token's representation in the donor embedding\nspace with a small dictionary of shared anchor tokens, then transfer these same\nsparse coefficients back into the base model's embedding space.\n  On two challenging cross-tokenizer tasks--Llama$\\to$Mistral NeMo (12B) and\nQwen$\\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of\nthe base model's performance across multiple benchmarks, while other zero-shot\napproaches degrade significantly. Compared to baselines (zero-init, mean-init,\nand existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves\nthe best overall performance, effectively bridging large tokenizer\ndiscrepancies without gradient updates. Our analysis further identifies\nmismatched numerical tokenization schemes as a critical challenge for\npreserving mathematical reasoning capabilities. This technique enables direct\nreuse of pretrained model weights with new tokenizers, facilitating\ncross-tokenizer knowledge distillation, speculative decoding, ensembling,\nmerging, and domain-specific vocabulary adaptations. We integrate our method\ninto the open-source mergekit-tokensurgeon tool for post hoc vocabulary\nrealignment.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u6784\u672a\u89c1\u7684\u8bcd\u5d4c\u5165\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f16\u7801\u5668\u79fb\u690d\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u5de5\u5177\u8fdb\u884c\u96c6\u6210\u3002", "motivation": "\u4e0d\u540c\u7f16\u7801\u5668\u4e4b\u95f4\u7684\u8bcd\u5d4c\u5165\u8fc1\u79fb\u662f\u4e2a\u6311\u6218\uff0c\u56e0\u6b64\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u8bad\u7ec3\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u65b0\u7f16\u7801\u5668\u4e0a\u7684\u76f4\u63a5\u518d\u5229\u7528\uff0c\u4ee5\u6253\u7834\u5927\u578b\u7f16\u7801\u5668\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\uff08OMP\uff09\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u8d85\u51fa\u8bcd\u6c47\u8303\u56f4\u7684\u6807\u8bb0\u8fd1\u4f3c\u4e3a\u5171\u4eab\u6807\u8bb0\u7684\u7a00\u758f\u7ebf\u6027\u7ec4\u5408\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u9636\u6bb5\u5b8c\u6210\uff1a\u9996\u5148\u5728\u7ed9\u5b9a\u8bcd\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8ba1\u7b97\u65b0\u6807\u8bb0\u7684\u8868\u793a\uff0c\u7136\u540e\u5c06\u76f8\u540c\u7684\u7a00\u758f\u7cfb\u6570\u8f6c\u79fb\u56de\u57fa\u7840\u6a21\u578b\u7684\u5d4c\u5165\u7a7a\u95f4\u3002", "result": "\u5728\u4e24\u4e2a\u8de8\u7f16\u7801\u5668\u4efb\u52a1\u4e0a\uff0cOMP\u65b9\u6cd5\u5728\u4fdd\u7559\u57fa\u7840\u6a21\u578b\u6027\u80fd\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4f18\u4e8e\u5176\u4ed6\u96f6\u6837\u672c\u65b9\u6cd5\u3002\u5206\u6790\u8868\u660e\uff0c\u4e0d\u5339\u914d\u7684\u6570\u5b57\u6807\u8bb0\u5316\u65b9\u6848\u662f\u4fdd\u7559\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\uff08OMP\uff09\u7684\u65e0\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7f16\u7801\u5668\u79fb\u690d\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u6784\u672a\u89c1\u8fc7\u7684\u8bcd\u5d4c\u5165\u6709\u6548\u5b9e\u73b0\u8de8\u7f16\u7801\u5668\u4efb\u52a1\u7684\u96f6\u6837\u672c\u6027\u80fd\u4fdd\u7559\u3002"}}
{"id": "2506.06443", "pdf": "https://arxiv.org/pdf/2506.06443", "abs": "https://arxiv.org/abs/2506.06443", "authors": ["Luis Pinto"], "title": "Unlocking Chemical Insights: Superior Molecular Representations from Intermediate Encoder Layers", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Pretrained molecular encoders have become indispensable in computational\nchemistry for tasks such as property prediction and molecular generation.\nHowever, the standard practice of relying solely on final-layer embeddings for\ndownstream tasks may discard valuable information. In this work, we challenge\nthis convention by conducting a comprehensive layer-wise analysis of five\ndiverse molecular encoders across 22 ADMET property prediction tasks. Our\nresults demonstrate that embeddings from intermediate layers consistently\noutperform final-layer representations. Specifically, using fixed embeddings\nfrom the optimal intermediate layers improved downstream performance by an\naverage of 5.4%, reaching gains up to 28.6%. Furthermore, finetuning up to\nthese intermediate layers yielded even greater average improvements of 8.5%,\nwith performance increases as high as 40.8%, achieving new state-of-the-art\nresults on several benchmarks. Additionally, a strong positive correlation\nbetween fixed embedding performance and finetuning outcomes supports an\nefficient evaluate-then-finetune approach, enabling identification of optimal\nlayers with reduced computational cost. These findings highlight the importance\nof exploring the full representational depth of molecular encoders to achieve\nsubstantial performance improvements and computational efficiency. The code is\nmade publicly available at\nhttps://github.com/luispintoc/Unlocking-Chemical-Insights.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u4e2d\u95f4\u5c42\u5d4c\u5165\uff0c\u53d1\u73b0\u5176\u5728\u5c5e\u6027\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u6700\u7ec8\u5c42\uff0c\u6539\u8fdb\u6027\u80fd\u8fbe40.8%\uff0c\u5e76\u8bc1\u660e\u4e86\u201c\u8bc4\u4f30\u540e\u5fae\u8c03\u201d\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u4e0a\uff0c\u5206\u5b50\u7f16\u7801\u5668\u7684\u4f7f\u7528\u901a\u5e38\u4f9d\u8d56\u4e8e\u6700\u7ec8\u5c42\u5d4c\u5165\u6765\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4e22\u5931\u91cd\u8981\u7684\u4fe1\u606f\u3002\u672c\u6587\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u60ef\u4f8b\uff0c\u63a2\u7d22\u4e2d\u95f4\u5c42\u5d4c\u5165\u5728ADMET\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9\u4e94\u79cd\u4e0d\u540c\u7684\u5206\u5b50\u7f16\u7801\u5668\u572822\u4e2aADMET\u5c5e\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u5c42\u7ea7\u5206\u6790\uff0c\u8bc4\u4f30\u4e2d\u95f4\u5c42\u5d4c\u5165\u7684\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u5d4c\u5165\u5c42\u7684\u56fa\u5316\u548c\u5fae\u8c03\uff0c\u4ee5\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e2d\u95f4\u5c42\u5d4c\u5165\u7684\u8868\u793a\u6bd4\u6700\u7ec8\u5c42\u8868\u73b0\u66f4\u597d\u3002\u4f7f\u7528\u4e2d\u95f4\u5c42\u56fa\u5316\u5d4c\u5165\u80fd\u63d0\u9ad8\u5e73\u57475.4%\u7684\u4e0b\u6e38\u6027\u80fd\uff0c\u6700\u9ad8\u589e\u5e45\u8fbe28.6%\uff1b\u800c\u5fae\u8c03\u4e2d\u95f4\u5c42\u5d4c\u5165\u80fd\u63d0\u9ad88.5%\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe40.8%\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f97\u65b0\u7684\u6700\u4f18\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u56fa\u5b9a\u5d4c\u5165\u6027\u80fd\u4e0e\u5fae\u8c03\u7ed3\u679c\u4e4b\u95f4\u7684\u5f3a\u6b63\u76f8\u5173\u8868\u660e\u53ef\u4ee5\u901a\u8fc7\u8bc4\u4f30\u540e\u5fae\u8c03\u7684\u7b56\u7565\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u63a2\u7d22\u5206\u5b50\u7f16\u7801\u5668\u7684\u5168\u5c42\u6b21\u8868\u793a\u53ef\u4ee5\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u6548\u7387\u3002\u901a\u8fc7\u4f7f\u7528\u4e2d\u95f4\u5c42\u5d4c\u5165\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u5e76\u4f7f\u5206\u5b50\u7f16\u7801\u5668\u66f4\u7b26\u5408\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2506.06740", "pdf": "https://arxiv.org/pdf/2506.06740", "abs": "https://arxiv.org/abs/2506.06740", "authors": ["Yigui Feng", "Qinglin Wang", "Ke Liu", "Xinhai Chen", "Bo Yang", "Jie Liu"], "title": "AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method", "categories": ["cs.AI"], "comment": null, "summary": "Psychological counseling faces huge challenges due to the growing demand for\nmental health services and the shortage of trained professionals. Large\nlanguage models (LLMs) have shown potential to assist psychological counseling,\nespecially in empathy and emotional support. However, existing models lack a\ndeep understanding of emotions and are unable to generate personalized\ntreatment plans based on fine-grained emotions. To address these shortcomings,\nwe present AI PsyRoom, a multi-agent simulation framework designed to enhance\npsychological counseling by generating empathetic and emotionally nuanced\nconversations. By leveraging fine-grained emotion classification and a\nmulti-agent framework, we construct a multi-agent PsyRoom A for dialogue\nreconstruction, generating a high-quality dialogue dataset EmoPsy, which\ncontains 35 sub-emotions, 423 specific emotion scenarios, and 12,350 dialogues.\nWe also propose PsyRoom B for generating personalized treatment plans.\nQuantitative evaluations demonstrate that AI PsyRoom significantly outperforms\nstate-of-the-art methods, achieving 18% improvement in problem orientation, 23%\nin expression, 24% in Empathy, and 16% in interactive communication quality.\nThe datasets and models are publicly available, providing a foundation for\nadvancing AI-assisted psychological counseling research.", "AI": {"tldr": "AI PsyRoom\u901a\u8fc7\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\u548c\u591a\u4ee3\u7406\u6846\u67b6\u63d0\u5347\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u8d28\u91cf\uff0c\u751f\u6210\u4e2a\u6027\u5316\u6cbb\u7597\u8ba1\u5212\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5fc3\u7406\u54a8\u8be2\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u56e0\u4e3a\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u9700\u6c42\u589e\u52a0\u800c\u4e13\u4e1a\u4eba\u5458\u77ed\u7f3a\u3002\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5bf9\u60c5\u611f\u7684\u6df1\u523b\u7406\u89e3\u53ca\u4e2a\u6027\u5316\u6cbb\u7597\u8ba1\u5212\u7684\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1AI PsyRoom\uff0c\u591a\u4ee3\u7406\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\u548c\u591a\u4ee3\u7406\u6846\u67b6\u6784\u5efa\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6570\u636e\u96c6EmoPsy\uff0c\u5e76\u751f\u6210\u4e2a\u6027\u5316\u6cbb\u7597\u8ba1\u5212\u3002", "result": "\u5728\u95ee\u9898\u5bfc\u5411\u3001\u8868\u8fbe\u3001\u540c\u7406\u5fc3\u548c\u4e92\u52a8\u4ea4\u6d41\u8d28\u91cf\u65b9\u9762\uff0cAI PsyRoom\u8f83\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5206\u522b\u63d0\u9ad8\u4e8618%\u300123%\u300124%\u548c16%\u3002", "conclusion": "AI PsyRoom\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u7406\u54a8\u8be2\u8d28\u91cf\uff0c\u591a\u9879\u6307\u6807\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.06609", "pdf": "https://arxiv.org/pdf/2506.06609", "abs": "https://arxiv.org/abs/2506.06609", "authors": ["Alan Chen", "Jack Merullo", "Alessandro Stolfo", "Ellie Pavlick"], "title": "Transferring Features Across Language Models With Model Stitching", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "In this work, we demonstrate that affine mappings between residual streams of\nlanguage models is a cheap way to effectively transfer represented features\nbetween models. We apply this technique to transfer the weights of Sparse\nAutoencoders (SAEs) between models of different sizes to compare their\nrepresentations. We find that small and large models learn highly similar\nrepresentation spaces, which motivates training expensive components like SAEs\non a smaller model and transferring to a larger model at a FLOPs savings. For\nexample, using a small-to-large transferred SAE as initialization can lead to\n50% cheaper training runs when training SAEs on larger models. Next, we show\nthat transferred probes and steering vectors can effectively recover ground\ntruth performance. Finally, we dive deeper into feature-level transferability,\nfinding that semantic and structural features transfer noticeably differently\nwhile specific classes of functional features have their roles faithfully\nmapped. Overall, our findings illustrate similarities and differences in the\nlinear representation spaces of small and large models and demonstrate a method\nfor improving the training efficiency of SAEs.", "AI": {"tldr": "\u901a\u8fc7\u4eff\u5c04\u6620\u5c04\u6280\u672f\u8f6c\u79fb\u5c0f\u6a21\u578b\u7684\u7279\u5f81\u5230\u5927\u6a21\u578b\uff0c\u80fd\u4ee5\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u7559\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u7c7b\u578b\u7279\u5f81\u8f6c\u79fb\u7684\u5dee\u5f02\u3002", "motivation": "\u6bd4\u8f83\u5c0f\u578b\u548c\u5927\u578b\u6a21\u578b\u4e4b\u95f4\u7684\u8868\u793a\u7a7a\u95f4\u5dee\u5f02\uff0c\u63a2\u7d22\u901a\u8fc7\u7279\u5f81\u8f6c\u79fb\u6765\u8282\u7701\u8bad\u7ec3\u6210\u672c\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f7f\u7528\u4eff\u5c04\u6620\u5c04\u6280\u672f\u5728\u4e0d\u540c\u5927\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u8868\u5f81\u7279\u5f81\u8f6c\u79fb\u3002", "result": "\u5c0f\u578b\u548c\u5927\u578b\u6a21\u578b\u5b66\u4e60\u5230\u76f8\u4f3c\u7684\u8868\u793a\u7a7a\u95f4\uff0c\u8f6c\u79fb\u7279\u5f81\u5230\u5927\u578b\u6a21\u578b\u53ef\u4ee5\u8282\u7701FLOPs\uff0c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u4e5f\u5f97\u5230\u4e86\u6709\u6548\u6062\u590d\uff1b\u4e0d\u540c\u7c7b\u578b\u7684\u7279\u5f81\u5728\u8f6c\u79fb\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\u4e0d\u540c\u3002", "conclusion": "\u5c0f\u578b\u548c\u5927\u578b\u6a21\u578b\u4e4b\u95f4\u7684\u7ebf\u6027\u8868\u5f81\u7a7a\u95f4\u5177\u6709\u76f8\u4f3c\u6027\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u4ece\u5c0f\u6a21\u578b\u8f6c\u79fb\u7279\u5f81\u5230\u5927\u6a21\u578b\u6765\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.06444", "pdf": "https://arxiv.org/pdf/2506.06444", "abs": "https://arxiv.org/abs/2506.06444", "authors": ["Ruizhong Qiu", "Gaotang Li", "Tianxin Wei", "Jingrui He", "Hanghang Tong"], "title": "Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "19 pages", "summary": "Existing safety assurance research has primarily focused on training-phase\nalignment to instill safe behaviors into LLMs. However, recent studies have\nexposed these methods' susceptibility to diverse jailbreak attacks.\nConcurrently, inference scaling has significantly advanced LLM reasoning\ncapabilities but remains unexplored in the context of safety assurance.\nAddressing this gap, our work pioneers inference scaling for robust and\neffective LLM safety against emerging threats. We reveal that conventional\ninference scaling techniques, despite their success in reasoning tasks, perform\npoorly in safety contexts, even falling short of basic approaches like\nBest-of-N Sampling. We attribute this inefficiency to a newly identified\nchallenge, the exploration--efficiency dilemma, arising from the high\ncomputational overhead associated with frequent process reward model (PRM)\nevaluations. To overcome this dilemma, we propose SAFFRON, a novel inference\nscaling paradigm tailored explicitly for safety assurance. Central to our\napproach is the introduction of a multifurcation reward model (MRM) that\nsignificantly reduces the required number of reward model evaluations. To\noperationalize this paradigm, we further propose: (i) a partial supervision\ntraining objective for MRM, (ii) a conservative exploration constraint to\nprevent out-of-distribution explorations, and (iii) a Trie-based key--value\ncaching strategy that facilitates cache sharing across sequences during tree\nsearch. Extensive experiments validate the effectiveness of our method.\nAdditionally, we publicly release our trained multifurcation reward model\n(Saffron-1) and the accompanying token-level safety reward dataset (Safety4M)\nto accelerate future research in LLM safety. Our code, model, and data are\npublicly available at https://github.com/q-rz/saffron , and our project\nhomepage is at https://q-rz.github.io/p/saffron .", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSAFFRON\u63a8\u7406\u6269\u5c55\u65b9\u6cd5\uff0c\u6539\u5584LLM\u5728\u5b89\u5168\u4fdd\u8bc1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u516c\u5f00\u76f8\u5173\u8d44\u6e90\u4ee5\u63a8\u52a8\u5b89\u5168\u9886\u57df\u7684\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u7684\u5b89\u5168\u4fdd\u8bc1\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8bad\u7ec3\u9636\u6bb5\u7684\u5bf9\u9f50\uff0c\u4ee5\u5411LLM\u6ce8\u5165\u5b89\u5168\u884c\u4e3a\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5404\u79cd\u8d8a\u72f1\u653b\u51fb\u4e14\u5728\u63a8\u7406\u9636\u6bb5\u7684\u5b89\u5168\u63a2\u7d22\u4ecd\u7136\u4e0d\u8db3\u3002\u56e0\u800c\u6709\u5fc5\u8981\u63a2\u7d22\u63a8\u7406\u6269\u5c55\u5728\u5b89\u5168\u4fdd\u8bc1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e00\u79cd\u540d\u4e3aSAFFRON\u7684\u63a8\u7406\u6269\u5c55\u8303\u5f0f\uff0c\u91cd\u70b9\u5f15\u5165\u4e86\u591a\u5206\u53c9\u5956\u52b1\u6a21\u578b\uff0c\u4ee5\u51cf\u5c11\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u7684\u6b21\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u90e8\u5206\u76d1\u7763\u7684\u8bad\u7ec3\u76ee\u6807\u3001\u4fdd\u5b88\u63a2\u7d22\u7ea6\u675f\u4ee5\u53ca\u57fa\u4e8eTrie\u7684\u952e\u503c\u7f13\u5b58\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86SAFFRON\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u5b89\u5168\u80cc\u666f\u4e0b\u7684\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u6269\u5c55\u8303\u5f0fSAFFRON\uff0c\u7528\u4e8e\u63d0\u9ad8LLM\u5728\u5b89\u5168\u4fdd\u8bc1\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u76f8\u5173\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\uff0c\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.06750", "pdf": "https://arxiv.org/pdf/2506.06750", "abs": "https://arxiv.org/abs/2506.06750", "authors": ["Zofia Rudnicka", "Janusz Szczepanski", "Agnieszka Pregowska"], "title": "Bio-Inspired Classification: Combining Information Theory and Spiking Neural Networks -- Influence of the Learning Rules", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Training of Spiking Neural Networks (SNN) is challenging due to their unique\nproperties, including temporal dynamics, non-differentiability of spike events,\nand sparse event-driven activations. In this paper, we widely consider the\ninfluence of the type of chosen learning algorithm, including bioinspired\nlearning rules on the accuracy of classification. We proposed a bioinspired\nclassifier based on the combination of SNN and Lempel-Ziv complexity (LZC).\nThis approach synergizes the strengths of SNNs in temporal precision and\nbiological realism with LZC's structural complexity analysis, facilitating\nefficient and interpretable classification of spatiotemporal neural data. It\nturned out that the classic backpropagation algorithm achieves excellent\nclassification accuracy, but at extremely high computational cost, which makes\nit impractical for real-time applications. Biologically inspired learning\nalgorithms such as tempotron and Spikprop provide increased computational\nefficiency while maintaining competitive classification performance, making\nthem suitable for time-sensitive tasks. The results obtained indicate that the\nselection of the most appropriate learning algorithm depends on the trade-off\nbetween classification accuracy and computational cost as well as application\nconstraints.", "AI": {"tldr": "\u7814\u7a76\u4e86SNN\u7ed3\u5408LZC\uff0c\u7528\u4e8e\u9ad8\u6548\u5206\u7c7b\u795e\u7ecf\u6570\u636e\uff0c\u4e0d\u540c\u7b97\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u95f4\u9700\u6743\u8861\u3002", "motivation": "SNN\u7531\u4e8e\u5176\u65f6\u95f4\u52a8\u6001\u6027\u3001\u5c16\u5cf0\u4e8b\u4ef6\u7684\u4e0d\u53ef\u5fae\u6027\u4ee5\u53ca\u7a00\u758f\u4e8b\u4ef6\u9a71\u52a8\u7684\u6fc0\u6d3b\uff0c\u4f7f\u5176\u8bad\u7ec3\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u6b64\u9700\u8981\u8003\u8651\u9009\u62e9\u7684\u5b66\u4e60\u7b97\u6cd5\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSNN\u548cLempel-Ziv\u590d\u6742\u6027\u7684\u751f\u7269\u542f\u53d1\u5206\u7c7b\u5668\uff0c\u901a\u8fc7\u7ed3\u5408SNN\u7684\u65f6\u95f4\u7cbe\u5ea6\u548c\u751f\u7269\u771f\u5b9e\u6027\u4ee5\u53caLZC\u7684\u7ed3\u6784\u590d\u6742\u6027\u5206\u6790\uff0c\u5b9e\u73b0\u5bf9\u65f6\u7a7a\u795e\u7ecf\u6570\u636e\u7684\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u5206\u7c7b\u3002", "result": "\u7ecf\u5178\u7684\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u867d\u7136\u80fd\u8fbe\u5230\u4f18\u5f02\u7684\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u6781\u9ad8\uff0c\u4e0d\u9002\u5408\u5b9e\u65f6\u5e94\u7528\u3002\u751f\u7269\u542f\u53d1\u5b66\u4e60\u7b97\u6cd5\u5982tempotron\u548cSpikprop\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u5206\u7c7b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u65f6\u95f4\u654f\u611f\u4efb\u52a1\u3002", "conclusion": "\u9009\u62e9\u6700\u5408\u9002\u7684\u5b66\u4e60\u7b97\u6cd5\u9700\u8981\u5728\u5206\u7c7b\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6210\u672c\u4ee5\u53ca\u5e94\u7528\u7ea6\u675f\u4e4b\u95f4\u4f5c\u51fa\u6743\u8861\u3002"}}
{"id": "2506.06616", "pdf": "https://arxiv.org/pdf/2506.06616", "abs": "https://arxiv.org/abs/2506.06616", "authors": ["Samuel Kim", "Oghenemaro Imieye", "Yunting Yin"], "title": "Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings", "categories": ["cs.CL"], "comment": "Submitted to the IEEE EMBS BHI 2025 Conference", "summary": "Accurate and interpretable detection of depressive language in social media\nis useful for early interventions of mental health conditions, and has\nimportant implications for both clinical practice and broader public health\nefforts. In this paper, we investigate the performance of large language models\n(LLMs) and traditional machine learning classifiers across three classification\ntasks involving social media data: binary depression classification, depression\nseverity classification, and differential diagnosis classification among\ndepression, PTSD, and anxiety. Our study compares zero-shot LLMs with\nsupervised classifiers trained on both conventional text embeddings and\nLLM-generated summary embeddings. Our experiments reveal that while zero-shot\nLLMs demonstrate strong generalization capabilities in binary classification,\nthey struggle with fine-grained ordinal classifications. In contrast,\nclassifiers trained on summary embeddings generated by LLMs demonstrate\ncompetitive, and in some cases superior, performance on the classification\ntasks, particularly when compared to models using traditional text embeddings.\nOur findings demonstrate the strengths of LLMs in mental health prediction, and\nsuggest promising directions for better utilization of their zero-shot\ncapabilities and context-aware summarization techniques.", "AI": {"tldr": "Zero-shot LLMs effectively classify depressive language but not its severity; LLM-generated summary embeddings help improve classifier performance. Promising for mental health assessment.", "motivation": "To enhance early intervention in mental health conditions by accurately detecting depressive language in social media through advanced NLP techniques.", "method": "Comparing the performance of zero-shot LLMs and traditional classifiers using both conventional text embeddings and LLM-generated summary embeddings across three social media classification tasks.", "result": "Zero-shot LLMs excelled in binary classification but struggled in finer granular tasks, whereas classifiers based on LLM-generated embeddings performed better, sometimes surpassing traditional methods.", "conclusion": "LLMs shows strong abilities in binary classification regarding depressive language, but face challenges in fine-grained tasks, although LLM-generated summary embeddings improve performance."}}
{"id": "2506.06454", "pdf": "https://arxiv.org/pdf/2506.06454", "abs": "https://arxiv.org/abs/2506.06454", "authors": ["Abrar Majeedi", "Viswanatha Reddy Gajjala", "Satya Sai Srinath Namburi GNVV", "Nada Magdi Elkordi", "Yin Li"], "title": "LETS Forecast: Learning Embedology for Time Series Forecasting", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML) 2025", "summary": "Real-world time series are often governed by complex nonlinear dynamics.\nUnderstanding these underlying dynamics is crucial for precise future\nprediction. While deep learning has achieved major success in time series\nforecasting, many existing approaches do not explicitly model the dynamics. To\nbridge this gap, we introduce DeepEDM, a framework that integrates nonlinear\ndynamical systems modeling with deep neural networks. Inspired by empirical\ndynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel\ndeep model that learns a latent space from time-delayed embeddings, and employs\nkernel regression to approximate the underlying dynamics, while leveraging\nefficient implementation of softmax attention and allowing for accurate\nprediction of future time steps. To evaluate our method, we conduct\ncomprehensive experiments on synthetic data of nonlinear dynamical systems as\nwell as real-world time series across domains. Our results show that DeepEDM is\nrobust to input noise, and outperforms state-of-the-art methods in forecasting\naccuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.", "AI": {"tldr": "DeepEDM\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u52a8\u529b\u5b66\u5efa\u6a21\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0a\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u51fa\u8272\u7684\u51c6\u786e\u6027\u548c\u566a\u58f0\u9c81\u68d2\u6027\u3002", "motivation": "\u5f88\u591a\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6ca1\u6709\u660e\u786e\u5efa\u6a21\u65f6\u95f4\u5e8f\u5217\u7684\u52a8\u529b\u5b66\uff0c\u800c\u7406\u89e3\u8fd9\u4e9b\u52a8\u6001\u5bf9\u7cbe\u51c6\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u52a8\u529b\u5b66\u5efa\u6a21\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "DeepEDM\u5c06\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u5efa\u6a21\u4e0e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\uff0c\u901a\u8fc7\u6838\u56de\u5f52\u903c\u8fd1\u5e95\u5c42\u52a8\u529b\u5b66\uff0c\u5e76\u5229\u7528softmax\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u9884\u6d4b\u3002", "result": "\u5728\u5408\u6210\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u6570\u636e\u53ca\u8de8\u9886\u57df\u7684\u5b9e\u9645\u65f6\u95f4\u5e8f\u5217\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDeepEDM\u5bf9\u8f93\u5165\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u76ee\u524d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "DeepEDM\u5728\u5904\u7406\u590d\u6742\u975e\u7ebf\u6027\u52a8\u6001\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2506.06786", "pdf": "https://arxiv.org/pdf/2506.06786", "abs": "https://arxiv.org/abs/2506.06786", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "title": "Learning What Matters Now: A Dual-Critic Context-Aware RL Framework for Priority-Driven Information Gain", "categories": ["cs.AI"], "comment": "6 pages, 2 figures, 3 tables, submitted as a regural paper to IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC) 2025", "summary": "Autonomous systems operating in high-stakes search-and-rescue (SAR) missions\nmust continuously gather mission-critical information while flexibly adapting\nto shifting operational priorities. We propose CA-MIQ (Context-Aware\nMax-Information Q-learning), a lightweight dual-critic reinforcement learning\n(RL) framework that dynamically adjusts its exploration strategy whenever\nmission priorities change. CA-MIQ pairs a standard extrinsic critic for task\nreward with an intrinsic critic that fuses state-novelty, information-location\nawareness, and real-time priority alignment. A built-in shift detector triggers\ntransient exploration boosts and selective critic resets, allowing the agent to\nre-focus after a priority revision. In a simulated SAR grid-world, where\nexperiments specifically test adaptation to changes in the priority order of\ninformation types the agent is expected to focus on, CA-MIQ achieves nearly\nfour times higher mission-success rates than baselines after a single priority\nshift and more than three times better performance in multiple-shift scenarios,\nachieving 100% recovery while baseline methods fail to adapt. These results\nhighlight CA-MIQ's effectiveness in any discrete environment with\npiecewise-stationary information-value distributions.", "AI": {"tldr": "CA-MIQ\u662f\u4e00\u79cd\u8f7b\u91cf\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u9ad8\u98ce\u9669\u641c\u7d22\u6551\u63f4\u60c5\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u7684\u641c\u7d22\u548c\u6551\u63f4\u4efb\u52a1\u4e2d\uff0c\u81ea\u52a8\u5316\u7cfb\u7edf\u9700\u8981\u6301\u7eed\u6536\u96c6\u4efb\u52a1\u5173\u952e\u7684\u4fe1\u606f\uff0c\u5e76\u4e14\u7075\u6d3b\u5730\u9002\u5e94\u53d8\u5316\u7684\u64cd\u4f5c\u4f18\u5148\u7ea7\u3002", "method": "\u63d0\u51fa\u4e86CA-MIQ\uff08Context-Aware Max-Information Q-learning\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u53cc\u91cd\u8bc4\u4ef7\u5668\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4efb\u52a1\u4f18\u5148\u7ea7\u6539\u53d8\u65f6\u52a8\u6001\u8c03\u6574\u5176\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5728\u6a21\u62df\u7684\u641c\u7d22\u548c\u6551\u63f4\u7f51\u683c\u4e16\u754c\u4e2d\uff0c\u5b9e\u9a8c\u6d4b\u8bd5\u4e86CA-MIQ\u5bf9\u9700\u8981\u91cd\u70b9\u5173\u6ce8\u7684\u4fe1\u606f\u7c7b\u578b\u4f18\u5148\u7ea7\u6539\u53d8\u7684\u9002\u5e94\u6027\u3002\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cCA-MIQ\u5728\u5355\u6b21\u4f18\u5148\u7ea7\u53d8\u5316\u540e\u7684\u4efb\u52a1\u6210\u529f\u7387\u9ad8\u51fa\u8fd1\u56db\u500d\uff0c\u5728\u591a\u6b21\u53d8\u5316\u7684\u60c5\u5883\u4e0b\u8868\u73b0\u4e5f\u9ad8\u51fa\u4e09\u500d\uff0c\u5b9e\u73b0\u4e86100%\u7684\u6062\u590d\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u65e0\u6cd5\u9002\u5e94\u3002", "conclusion": "CA-MIQ\u5728\u4efb\u610f\u5177\u6709\u5206\u6bb5\u7a33\u5b9a\u4fe1\u606f\u4ef7\u503c\u5206\u5e03\u7684\u79bb\u6563\u73af\u5883\u4e2d\u80fd\u591f\u6709\u6548\u5de5\u4f5c\u3002"}}
{"id": "2506.06619", "pdf": "https://arxiv.org/pdf/2506.06619", "abs": "https://arxiv.org/abs/2506.06619", "authors": ["Jesse Woo", "Fateme Hashemi Chaleshtori", "Ana Marasovi\u0107", "Kenneth Marino"], "title": "BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs", "categories": ["cs.CL"], "comment": "ACL Findings 2025; 10 pages main, 5 pages references, 37 pages\n  appendix", "summary": "A core part of legal work that has been under-explored in Legal NLP is the\nwriting and editing of legal briefs. This requires not only a thorough\nunderstanding of the law of a jurisdiction, from judgments to statutes, but\nalso the ability to make new arguments to try to expand the law in a new\ndirection and make novel and creative arguments that are persuasive to judges.\nTo capture and evaluate these legal skills in language models, we introduce\nBRIEFME, a new dataset focused on legal briefs. It contains three tasks for\nlanguage models to assist legal professionals in writing briefs: argument\nsummarization, argument completion, and case retrieval. In this work, we\ndescribe the creation of these tasks, analyze them, and show how current models\nperform. We see that today's large language models (LLMs) are already quite\ngood at the summarization and guided completion tasks, even beating\nhuman-generated headings. Yet, they perform poorly on other tasks in our\nbenchmark: realistic argument completion and retrieving relevant legal cases.\nWe hope this dataset encourages more development in Legal NLP in ways that will\nspecifically aid people in performing legal work.", "AI": {"tldr": "BRIEFME\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u6458\u8981\u5199\u4f5c\u4e2d\u7684\u8868\u73b0\uff0cLLMs\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u68c0\u7d22\u548c\u5b8c\u6210\u4efb\u52a1\u4e0a\u4ecd\u6709\u4e0d\u8db3\u3002", "motivation": "\u6cd5\u5f8bNLP\u4e2d\u6cd5\u5f8b\u6458\u8981\u7684\u5199\u4f5c\u548c\u7f16\u8f91\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u65e8\u5728\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aBRIEFME\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e09\u4e2a\u4efb\u52a1\uff1a\u8bba\u70b9\u6458\u8981\u3001\u8bba\u70b9\u5b8c\u6210\u548c\u6848\u4f8b\u68c0\u7d22\uff0c\u4ee5\u534f\u52a9\u6cd5\u5f8b\u4e13\u4e1a\u4eba\u5458\u64b0\u5199\u6458\u8981\u3002", "result": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u548c\u5f15\u5bfc\u5b8c\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u4eba\u7c7b\u751f\u6210\u7684\u6807\u9898\u3002", "conclusion": "\u76ee\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u548c\u5f15\u5bfc\u5b8c\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u73b0\u5b9e\u7684\u8bba\u8bc1\u5b8c\u6210\u548c\u68c0\u7d22\u76f8\u5173\u6cd5\u5f8b\u6848\u4ef6\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5e0c\u671b\u8be5\u6570\u636e\u96c6\u80fd\u4fc3\u8fdb\u6cd5\u5f8bNLP\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.06455", "pdf": "https://arxiv.org/pdf/2506.06455", "abs": "https://arxiv.org/abs/2506.06455", "authors": ["Antonio Jes\u00fas Banegas-Luna", "Horacio P\u00e9rez-S\u00e1nchez", "Carlos Mart\u00ednez-Cort\u00e9s"], "title": "WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "27 pages, 11 figures, 2 tables, 13 equations", "summary": "While predictive accuracy is often prioritized in machine learning (ML)\nmodels, interpretability remains essential in scientific and high-stakes\ndomains. However, diverse interpretability algorithms frequently yield\nconflicting explanations, highlighting the need for consensus to harmonize\nresults. In this study, six ML models were trained on six synthetic datasets\nwith known ground truths, utilizing various model-agnostic interpretability\ntechniques. Consensus explanations were generated using established methods and\na novel approach: WISCA (Weighted Scaled Consensus Attributions), which\nintegrates class probability and normalized attributions. WISCA consistently\naligned with the most reliable individual method, underscoring the value of\nrobust consensus strategies in improving explanation reliability.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86WISCA\uff0c\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u89e3\u91ca\u6027\u7ed3\u679c\uff0c\u63d0\u5347\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5c3d\u7ba1\u9884\u6d4b\u51c6\u786e\u6027\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e38\u88ab\u4f18\u5148\u8003\u8651\uff0c\u4f46\u5728\u79d1\u5b66\u548c\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u53ef\u89e3\u91ca\u6027\u4ecd\u7136\u81f3\u5173\u91cd\u8981\u3002\u4e0d\u540c\u7684\u89e3\u91ca\u6027\u7b97\u6cd5\u5e38\u5e38\u5bfc\u81f4\u51b2\u7a81\u7684\u89e3\u91ca\uff0c\u8fd9\u7a81\u663e\u4e86\u9700\u8981\u901a\u8fc7\u5171\u8bc6\u65b9\u6cd5\u534f\u8c03\u7ed3\u679c\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u516d\u4e2a\u6709\u5df2\u77e5\u771f\u76f8\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u4e86\u516d\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u5229\u7528\u4e0d\u540c\u7684\u6a21\u578b\u65e0\u5173\u89e3\u91ca\u6027\u6280\u672f\u751f\u6210\u5171\u8bc6\u89e3\u91ca\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5WISCA\u3002", "result": "WISCA\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u7c7b\u522b\u6982\u7387\u548c\u5f52\u4e00\u5316\u5c5e\u6027\uff0c\u5728\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002", "conclusion": "WISCA\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u91ca\u7684\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u4e0e\u8868\u73b0\u6700\u597d\u7684\u5355\u4e2a\u65b9\u6cd5\u4e00\u81f4\uff0c\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u5171\u8bc6\u7b56\u7565\u3002"}}
{"id": "2506.06832", "pdf": "https://arxiv.org/pdf/2506.06832", "abs": "https://arxiv.org/abs/2506.06832", "authors": ["Cl\u00e9ment Hongler", "Andrew Emil"], "title": "Cross-Entropy Games for Language Models: From Implicit Knowledge to General Capability Measures", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.IT", "cs.NE", "math.IT"], "comment": "41 pages, 16 figures", "summary": "Large Language Models (LLMs) define probability measures on text. By\nconsidering the implicit knowledge question of what it means for an LLM to know\nsuch a measure and what it entails algorithmically, we are naturally led to\nformulate a series of tasks that go beyond generative sampling, involving forms\nof summarization, counterfactual thinking, anomaly detection, originality\nsearch, reverse prompting, debating, creative solving, etc. These tasks can be\nformulated as games based on LLM measures, which we call Cross-Entropy (Xent)\nGames. Xent Games can be single-player or multi-player. They involve\ncross-entropy scores and cross-entropy constraints, and can be expressed as\nsimple computational graphs and programs. We show the Xent Game space is large\nenough to contain a wealth of interesting examples, while being constructible\nfrom basic game-theoretic consistency axioms. We then discuss how the Xent Game\nspace can be used to measure the abilities of LLMs. This leads to the\nconstruction of Xent Game measures: finite families of Xent Games that can be\nused as capability benchmarks, built from a given scope, by extracting a\ncovering measure. To address the unbounded scope problem associated with the\nchallenge of measuring general abilities, we propose to explore the space of\nXent Games in a coherent fashion, using ideas inspired by evolutionary\ndynamics.", "AI": {"tldr": "\u5b9a\u4e49\u4e86LLM\u6982\u7387\u6d4b\u5ea6\u7684\u76f8\u5173\u4efb\u52a1\uff0c\u63d0\u51faXent\u6e38\u620f\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u80fd\u529b\uff0c\u5305\u542b\u535a\u5f08\u8bba\u6784\u5efa\u65b9\u6cd5\u3002", "motivation": "\u901a\u8fc7\u63a2\u8ba8LLM\u4e2d\u6982\u7387\u6d4b\u5ea6\u7684\u9690\u542b\u77e5\u8bc6\u95ee\u9898\uff0c\u63a8\u52a8\u751f\u6210\u8d85\u8d8a\u6027\u4efb\u52a1\u7684\u754c\u5b9a\u3002", "method": "\u5c06\u4efb\u52a1\u8868\u8ff0\u4e3a\u57fa\u4e8eLLM\u6d4b\u5ea6\u7684\u535a\u5f08\uff0c\u5373\u4ea4\u53c9\u71b5\uff08Xent\uff09\u6e38\u620f\uff0c\u91c7\u7528\u535a\u5f08\u8bba\u7684\u4e00\u81f4\u6027\u516c\u7406\u6784\u5efa\u3002", "result": "\u5c55\u793aXent\u6e38\u620f\u7a7a\u95f4\u7684\u6784\u5efa\u65b9\u6cd5\u4ee5\u53ca\u5176\u5e94\u7528\u4e8e\u6d4b\u91cfLLM\u80fd\u529b\u7684\u6f5c\u529b\u3002", "conclusion": "Xent\u6e38\u620f\u7a7a\u95f4\u53ef\u7528\u4e8e\u6784\u5efaLLM\u7684\u80fd\u529b\u57fa\u51c6\uff0c\u901a\u8fc7\u6d4b\u5ea6\u8986\u76d6\u89e3\u51b3\u8303\u56f4\u65e0\u754c\u95ee\u9898\u3002"}}
{"id": "2506.06626", "pdf": "https://arxiv.org/pdf/2506.06626", "abs": "https://arxiv.org/abs/2506.06626", "authors": ["Junzhe Wang", "Bichen Wang", "Xing Fu", "Yixin Sun", "Yanyan Zhao", "Bing Qin"], "title": "Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations", "categories": ["cs.CL"], "comment": "15 pages, 19 figures", "summary": "In recent years, Large Language Models (LLMs) have made significant progress\nin automated psychological counseling. However, current research focuses on\nsingle-session counseling, which doesn't represent real-world scenarios. In\npractice, psychological counseling is a process, not a one-time event,\nrequiring sustained, multi-session engagement to progressively address clients'\nissues. To overcome this limitation, we introduce a dataset for Multi-Session\nPsychological Counseling Conversation Dataset (MusPsy-Dataset). Our\nMusPsy-Dataset is constructed using real client profiles from publicly\navailable psychological case reports. It captures the dynamic arc of\ncounseling, encompassing multiple progressive counseling conversations from the\nsame client across different sessions. Leveraging our dataset, we also\ndeveloped our MusPsy-Model, which aims to track client progress and adapt its\ncounseling direction over time. Experiments show that our model performs better\nthan baseline models across multiple sessions.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165MusPsy-Dataset\u548cMusPsy-Model\u8fdb\u884c\u591a\u4f1a\u8bdd\u5fc3\u7406\u54a8\u8be2\uff0c\u7ed3\u679c\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u96c6\u4e2d\u4e8e\u5355\u6b21\u4f1a\u8bdd\u7684\u5fc3\u7406\u54a8\u8be2\u7814\u7a76\uff0c\u4f46\u5fc3\u7406\u54a8\u8be2\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u662f\u4e00\u4e2a\u9700\u8981\u6301\u7eed\u591a\u6b21\u4f1a\u8bdd\u7684\u8fc7\u7a0b\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u5f15\u5165\u4e86MusPsy-Dataset\u6570\u636e\u96c6\u3002", "method": "\u5229\u7528\u771f\u5b9e\u7684\u5ba2\u6237\u6863\u6848\u6784\u5efaMusPsy-Dataset\uff0c\u540c\u65f6\u5f00\u53d1MusPsy-Model\u6765\u8ddf\u8e2a\u5ba2\u6237\u8fdb\u5c55\u548c\u8c03\u6574\u54a8\u8be2\u65b9\u5411\u3002", "result": "MusPsy-Model\u5728\u591a\u4f1a\u8bdd\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u4ecb\u7ecd\u4e86MusPsy-Dataset\uff0c\u4e00\u4e2a\u7531\u591a\u4f1a\u8bdd\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u7ec4\u6210\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u53caMusPsy-Model\uff0c\u65e8\u5728\u8ddf\u8e2a\u5ba2\u6237\u8fdb\u5c55\u5e76\u968f\u65f6\u95f4\u8c03\u6574\u54a8\u8be2\u65b9\u5411\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u5728\u591a\u4f1a\u8bdd\u4e2d\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002"}}
{"id": "2506.06459", "pdf": "https://arxiv.org/pdf/2506.06459", "abs": "https://arxiv.org/abs/2506.06459", "authors": ["Ruitao Chen", "Mozhang Guo", "Jinge Li"], "title": "Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control", "categories": ["cs.LG", "cs.ET", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Automated driving (AD) has substantially improved vehicle safety and driving\ncomfort, but their impact on passenger well-being, particularly infant sleep,\nis not sufficiently studied. Sudden acceleration, abrupt braking, and sharp\nmaneuvers can disrupt infant sleep, compromising both passenger comfort and\nparental convenience. To solve this problem, this paper explores the\nintegration of reinforcement learning (RL) within AD to personalize driving\nbehavior and optimally balance occupant comfort and travel efficiency. In\nparticular, we propose an intelligent cruise control framework that adapts to\nvarying driving conditions to enhance infant sleep quality by effectively\nsynergizing wearable sensing and vehicle data. Long short-term memory (LSTM)\nand transformer-based neural networks are integrated with RL to model the\nrelationship between driving behavior and infant sleep quality under diverse\ntraffic and road conditions. Based on the sleep quality indicators from the\nwearable sensors, driving action data from vehicle controllers, and map data\nfrom map applications, the model dynamically computes the optimal driving\naggressiveness level, which is subsequently translated into specific AD control\nstrategies, e.g., the magnitude and frequency of acceleration, lane change, and\novertaking. Simulation results demonstrate that the proposed solution\nsignificantly improves infant sleep quality compared to baseline methods, while\npreserving desirable travel efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u667a\u80fd\u5de1\u822a\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4e0e\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u4f18\u5316\u9a7e\u9a76\u884c\u4e3a\u4ee5\u63d0\u9ad8\u5a74\u513f\u4e58\u5750\u65f6\u7684\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u65c5\u884c\u6548\u7387\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u867d\u7136\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u548c\u8212\u9002\u5ea6\uff0c\u4f46\u5bf9\u4e58\u5750\u8005\u798f\u7949\uff0c\u5c24\u5176\u662f\u5a74\u513f\u7761\u7720\u7684\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4e0e\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u53ca\u53d8\u538b\u5668\u6a21\u578b\u96c6\u6210\uff0c\u57fa\u4e8e\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u7684\u7761\u7720\u8d28\u91cf\u6307\u6807\u3001\u8f66\u8f86\u63a7\u5236\u5668\u7684\u9a7e\u9a76\u884c\u4e3a\u6570\u636e\u53ca\u5730\u56fe\u5e94\u7528\u7684\u6570\u636e\u6765\u52a8\u6001\u8ba1\u7b97\u6700\u4f73\u9a7e\u9a76\u6fc0\u8fdb\u7a0b\u5ea6\uff0c\u5e76\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236\u7b56\u7565\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u5a74\u513f\u7761\u7720\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51fa\u884c\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u667a\u80fd\u5de1\u822a\u63a7\u5236\u6846\u67b6\u5728\u6539\u5584\u5a74\u513f\u7761\u7720\u8d28\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u4ee4\u4eba\u6ee1\u610f\u7684\u884c\u9a76\u6548\u7387\u3002"}}
{"id": "2506.06843", "pdf": "https://arxiv.org/pdf/2506.06843", "abs": "https://arxiv.org/abs/2506.06843", "authors": ["HaoYang Shang", "Xuan Liu", "Zi Liang", "Jie Zhang", "Haibo Hu", "Song Guo"], "title": "United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) exhibit a notable performance ceiling on\ncomplex, multi-faceted tasks, as they often fail to integrate diverse\ninformation or adhere to multiple constraints. We posit that such limitation\narises when the demands of a task exceed the LLM's effective cognitive load\ncapacity. This interpretation draws a strong analogy to Cognitive Load Theory\n(CLT) in cognitive science, which explains similar performance boundaries in\nthe human mind, and is further supported by emerging evidence that reveals LLMs\nhave bounded working memory characteristics. Building upon this CLT-grounded\nunderstanding, we introduce CoThinker, a novel LLM-based multi-agent framework\ndesigned to mitigate cognitive overload and enhance collaborative\nproblem-solving abilities. CoThinker operationalizes CLT principles by\ndistributing intrinsic cognitive load through agent specialization and managing\ntransactional load via structured communication and a collective working\nmemory. We empirically validate CoThinker on complex problem-solving tasks and\nfabricated high cognitive load scenarios, demonstrating improvements over\nexisting multi-agent baselines in solution quality and efficiency. Our analysis\nreveals characteristic interaction patterns, providing insights into the\nemergence of collective cognition and effective load management, thus offering\na principled approach to overcoming LLM performance ceilings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faCoThinker\u6846\u67b6\uff0c\u901a\u8fc7\u7ba1\u7406\u8ba4\u77e5\u8fc7\u8f7d\u548c\u4fc3\u8fdb\u534f\u4f5c\uff0c\u63d0\u5347LLM\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u7684LLM\u5728\u590d\u6742\u591a\u9762\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u4e2d\u7684\u754c\u9650\uff0c\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5176\u534f\u4f5c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e13\u95e8\u5316\u7684\u4ee3\u7406\u5206\u914d\u5185\u5728\u8ba4\u77e5\u8d1f\u8377\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u901a\u4fe1\u548c\u96c6\u4f53\u5de5\u4f5c\u8bb0\u5fc6\u7ba1\u7406\u4e8b\u52a1\u6027\u8d1f\u8377\uff0c\u4ece\u800c\u51cf\u8f7b\u8ba4\u77e5\u8fc7\u8f7d\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCoThinker\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u4efb\u52a1\u4e0a\u7684\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u4ee3\u7406\u57fa\u7ebf\uff0c\u4e0d\u4ec5\u5728\u89e3\u51b3\u8d28\u91cf\u4e0a\u6709\u6240\u6539\u5584\uff0c\u800c\u4e14\u5728\u6548\u7387\u4e0a\u4e5f\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u5f15\u5165\u4e86CoThinker\uff0c\u4e00\u4e2a\u57fa\u4e8eCLT\u539f\u7406\u8bbe\u8ba1\u7684LLM\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u80fd\u591f\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65f6\u6709\u6548\u7ba1\u7406\u8ba4\u77e5\u8d1f\u8377\uff0c\u63d0\u5347\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2506.06636", "pdf": "https://arxiv.org/pdf/2506.06636", "abs": "https://arxiv.org/abs/2506.06636", "authors": ["Chuxue Cao", "Han Zhu", "Jiaming Ji", "Qichao Sun", "Zhenghao Zhu", "Yinyu Wu", "Juntao Dai", "Yaodong Yang", "Sirui Han", "Yike Guo"], "title": "SafeLawBench: Towards Safe Alignment of Large Language Models", "categories": ["cs.CL"], "comment": "Accepted to ACL2025 Findings", "summary": "With the growing prevalence of large language models (LLMs), the safety of\nLLMs has raised significant concerns. However, there is still a lack of\ndefinitive standards for evaluating their safety due to the subjective nature\nof current safety benchmarks. To address this gap, we conducted the first\nexploration of LLMs' safety evaluation from a legal perspective by proposing\nthe SafeLawBench benchmark. SafeLawBench categorizes safety risks into three\nlevels based on legal standards, providing a systematic and comprehensive\nframework for evaluation. It comprises 24,860 multi-choice questions and 1,106\nopen-domain question-answering (QA) tasks. Our evaluation included 2\nclosed-source LLMs and 18 open-source LLMs using zero-shot and few-shot\nprompting, highlighting the safety features of each model. We also evaluated\nthe LLMs' safety-related reasoning stability and refusal behavior.\nAdditionally, we found that a majority voting mechanism can enhance model\nperformance. Notably, even leading SOTA models like Claude-3.5-Sonnet and\nGPT-4o have not exceeded 80.5% accuracy in multi-choice tasks on SafeLawBench,\nwhile the average accuracy of 20 LLMs remains at 68.8\\%. We urge the community\nto prioritize research on the safety of LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4ece\u6cd5\u5f8b\u89c6\u89d2\u8fdb\u884c\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u8bc4\u4f30\u7684SafeLawBench\u57fa\u51c6\uff0c\u53d1\u73b0\u5f53\u524d\u9886\u5148\u6a21\u578b\u8868\u73b0\u4ecd\u6709\u5f85\u63d0\u9ad8\uff0c\u5e76\u547c\u5401\u8fdb\u4e00\u6b65\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u7684\u4e3b\u89c2\u6027\u4f7f\u5f97\u6ca1\u6709\u660e\u786e\u7684\u6807\u51c6\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u4ece\u6cd5\u5f8b\u7684\u89d2\u5ea6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5SafeLawBench, \u57fa\u4e8e\u6cd5\u5f8b\u6807\u51c6\u5c06\u5b89\u5168\u98ce\u9669\u5206\u4e3a\u4e09\u4e2a\u5c42\u7ea7\uff0c\u901a\u8fc7\u591a\u9009\u9898\u548c\u5f00\u653e\u57df\u95ee\u7b54\u4efb\u52a1\u7cfb\u7edf\u5730\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "result": "\u57282\u4e2a\u95ed\u6e90\u548c18\u4e2a\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0cSafeLawBench\u80fd\u591f\u6709\u6548\u5730\u7a81\u51fa\u6bcf\u4e2a\u6a21\u578b\u7684\u5b89\u5168\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u6570\u6295\u7968\u673a\u5236\u63d0\u9ad8\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "SafeLawBench\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u4e14\u5168\u9762\u7684\u6846\u67b6\uff0c\u867d\u7136\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u5176\u591a\u9879\u9009\u62e9\u4efb\u52a1\u4e2d\u4e5f\u672a\u8fbe\u523080.5%\u7684\u51c6\u786e\u7387\uff0c\u5f3a\u8c03\u4e86\u7ee7\u7eed\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.06482", "pdf": "https://arxiv.org/pdf/2506.06482", "abs": "https://arxiv.org/abs/2506.06482", "authors": ["Zhiyuan Zhao", "Juntong Ni", "Shangqing Xu", "Haoxin Liu", "Wei Jin", "B. Aditya Prakash"], "title": "TimeRecipe: A Time-Series Forecasting Recipe via Benchmarking Module Level Effectiveness", "categories": ["cs.LG"], "comment": "46 pages, 1 figure, 28 tables", "summary": "Time-series forecasting is an essential task with wide real-world\napplications across domains. While recent advances in deep learning have\nenabled time-series forecasting models with accurate predictions, there remains\nconsiderable debate over which architectures and design components, such as\nseries decomposition or normalization, are most effective under varying\nconditions. Existing benchmarks primarily evaluate models at a high level,\noffering limited insight into why certain designs work better. To mitigate this\ngap, we propose TimeRecipe, a unified benchmarking framework that\nsystematically evaluates time-series forecasting methods at the module level.\nTimeRecipe conducts over 10,000 experiments to assess the effectiveness of\nindividual components across a diverse range of datasets, forecasting horizons,\nand task settings. Our results reveal that exhaustive exploration of the design\nspace can yield models that outperform existing state-of-the-art methods and\nuncover meaningful intuitions linking specific design choices to forecasting\nscenarios. Furthermore, we release a practical toolkit within TimeRecipe that\nrecommends suitable model architectures based on these empirical insights. The\nbenchmark is available at: https://github.com/AdityaLab/TimeRecipe.", "AI": {"tldr": "TimeRecipe\u662f\u4e00\u4e2a\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u7ea7\u522b\u7684\u5b9e\u9a8c\u8bc4\u4f30\u53ef\u4f18\u5316\u6a21\u578b\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6df1\u5165\u5206\u6790\u4e0d\u540c\u8bbe\u8ba1\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u63d0\u51faTimeRecipe\u6846\u67b6\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "TimeRecipe\u8fdb\u884c\u8d85\u8fc710,000\u6b21\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u7ec4\u4ef6\u5728\u5404\u79cd\u6570\u636e\u96c6\u3001\u9884\u6d4b\u8303\u56f4\u548c\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u901a\u8fc7\u5168\u9762\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0cTimeRecipe\u53d1\u73b0\u53ef\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u6a21\u578b\uff0c\u5e76\u63ed\u793a\u8bbe\u8ba1\u9009\u62e9\u4e0e\u9884\u6d4b\u573a\u666f\u7684\u5177\u4f53\u5173\u8054\u3002\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e2a\u5b9e\u9645\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u63a8\u8350\u5408\u9002\u7684\u6a21\u578b\u67b6\u6784\u3002", "conclusion": "\u63d0\u51faTimeRecipe\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u7ec4\u4ef6\u6a21\u5757\uff0c\u63d0\u9ad8\u6a21\u578b\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2506.06868", "pdf": "https://arxiv.org/pdf/2506.06868", "abs": "https://arxiv.org/abs/2506.06868", "authors": ["Razieh Arshadizadeh", "Mahmoud Asgari", "Zeinab Khosravi", "Yiannis Papadopoulos", "Koorosh Aslansefat"], "title": "Incorporating Failure of Machine Learning in Dynamic Probabilistic Safety Assurance", "categories": ["cs.AI"], "comment": null, "summary": "Machine Learning (ML) models are increasingly integrated into safety-critical\nsystems, such as autonomous vehicle platooning, to enable real-time\ndecision-making. However, their inherent imperfection introduces a new class of\nfailure: reasoning failures often triggered by distributional shifts between\noperational and training data. Traditional safety assessment methods, which\nrely on design artefacts or code, are ill-suited for ML components that learn\nbehaviour from data. SafeML was recently proposed to dynamically detect such\nshifts and assign confidence levels to the reasoning of ML-based components.\nBuilding on this, we introduce a probabilistic safety assurance framework that\nintegrates SafeML with Bayesian Networks (BNs) to model ML failures as part of\na broader causal safety analysis. This allows for dynamic safety evaluation and\nsystem adaptation under uncertainty. We demonstrate the approach on an\nsimulated automotive platooning system with traffic sign recognition. The\nfindings highlight the potential broader benefits of explicitly modelling ML\nfailures in safety assessment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06SafeML\u4e0eBayesian Networks\u7ed3\u5408\u7684\u6982\u7387\u5b89\u5168\u4fdd\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u5b89\u5168\u8bc4\u4f30\u548c\u7cfb\u7edf\u9002\u5e94\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u673a\u5668\u5b66\u4e60\u7ec4\u4ef6\u7684\u56fa\u6709\u7f3a\u9677\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u7531\u4e8e\u64cd\u4f5c\u548c\u8bad\u7ec3\u6570\u636e\u95f4\u7684\u5206\u5e03\u53d8\u5316\u6240\u5bfc\u81f4\u7684\u63a8\u7406\u5931\u8d25\u95ee\u9898\u3002", "method": "\u4f7f\u7528Bayesian Networks\uff08BNs\uff09\u5c06SafeML\u4e0e\u673a\u5668\u5b66\u4e60\u5931\u8d25\u7684\u6982\u7387\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u8fdb\u884c\u5e7f\u6cdb\u7684\u56e0\u679c\u5b89\u5168\u5206\u6790\u3002", "result": "\u901a\u8fc7\u8be5\u65b9\u6cd5\uff0c\u5728\u4eff\u771f\u7684\u6c7d\u8f66\u961f\u5217\u7cfb\u7edf\u4e2d\u5bf9\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u660e\u786e\u5efa\u6a21\u673a\u5668\u5b66\u4e60\u5931\u8d25\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u5177\u6709\u8f83\u5927\u7684\u6f5c\u5728\u597d\u5904\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u4e3b\u52a8\u5efa\u6a21\u548c\u68c0\u6d4b\u673a\u5668\u5b66\u4e60\u5931\u8d25\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5b9e\u73b0\u7cfb\u7edf\u9002\u5e94\u3002"}}
{"id": "2506.06657", "pdf": "https://arxiv.org/pdf/2506.06657", "abs": "https://arxiv.org/abs/2506.06657", "authors": ["Nikhita Vedula", "Dushyanta Dhyani", "Laleh Jalali", "Boris Oreshkin", "Mohsen Bayati", "Shervin Malmasi"], "title": "Quantile Regression with Large Language Models for Price Prediction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Findings of ACL, 2025", "summary": "Large Language Models (LLMs) have shown promise in structured prediction\ntasks, including regression, but existing approaches primarily focus on point\nestimates and lack systematic comparison across different methods. We\ninvestigate probabilistic regression using LLMs for unstructured inputs,\naddressing challenging text-to-distribution prediction tasks such as price\nestimation where both nuanced text understanding and uncertainty quantification\nare critical. We propose a novel quantile regression approach that enables LLMs\nto produce full predictive distributions, improving upon traditional point\nestimates. Through extensive experiments across three diverse price prediction\ndatasets, we demonstrate that a Mistral-7B model fine-tuned with quantile heads\nsignificantly outperforms traditional approaches for both point and\ndistributional estimations, as measured by three established metrics each for\nprediction accuracy and distributional calibration. Our systematic comparison\nof LLM approaches, model architectures, training approaches, and data scaling\nreveals that Mistral-7B consistently outperforms encoder architectures,\nembedding-based methods, and few-shot learning methods. Our experiments also\nreveal the effectiveness of LLM-assisted label correction in achieving\nhuman-level accuracy without systematic bias. Our curated datasets are made\navailable at https://github.com/vnik18/llm-price-quantile-reg/ to support\nfuture research.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u91cf\u5316\u56de\u5f52\u63d0\u5347LLM\u5728\u4ef7\u683c\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793aMistral-7B\u6a21\u578b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5176\u4ed6\u5b66\u4e60\u65b9\u5f0f\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u975e\u7ed3\u6784\u5316\u8f93\u5165\u7684\u6982\u7387\u56de\u5f52\u4e2d\u53d1\u6325\u6f5c\u529b\uff0c\u89e3\u51b3\u5982\u4ef7\u683c\u4f30\u7b97\u9700\u8981\u7406\u89e3\u6587\u672c\u7ec6\u5fae\u5dee\u522b\u53ca\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u4efb\u52a1\u3002", "method": "\u91c7\u7528\u91cf\u5316\u56de\u5f52\u65b9\u6cd5\u5bf9LLM\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u5176\u80fd\u751f\u6210\u5b8c\u6574\u7684\u9884\u6d4b\u5206\u5e03\uff0c\u5e76\u7ed3\u5408\u4e0d\u540c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\u5bf9\u6bd4\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u4ef7\u683c\u9884\u6d4b\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684Mistral-7B\u6a21\u578b\u5728\u70b9\u4f30\u8ba1\u548c\u5206\u5e03\u4f30\u8ba1\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5728\u540e\u7eed\u5b9e\u9a8c\u4e2d\u6301\u7eed\u8d85\u8d8a\u5176\u4ed6\u6a21\u578b\u67b6\u6784\u53ca\u65b9\u6cd5\u3002", "conclusion": "Mistral-7B\u6a21\u578b\u5728\u4ef7\u683c\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u591f\u663e\u8457\u8d85\u8fc7\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u53ef\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u7684\u51c6\u786e\u5ea6\u3002"}}
{"id": "2506.06486", "pdf": "https://arxiv.org/pdf/2506.06486", "abs": "https://arxiv.org/abs/2506.06486", "authors": ["Umit Yigit Basaran", "Sk Miraj Ahmed", "Amit Roy-Chowdhury", "Basak Guler"], "title": "A Certified Unlearning Approach without Access to Source Data", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Accepted by ICML 2025", "summary": "With the growing adoption of data privacy regulations, the ability to erase\nprivate or copyrighted information from trained models has become a crucial\nrequirement. Traditional unlearning methods often assume access to the complete\ntraining dataset, which is unrealistic in scenarios where the source data is no\nlonger available. To address this challenge, we propose a certified unlearning\nframework that enables effective data removal \\final{without access to the\noriginal training data samples}. Our approach utilizes a surrogate dataset that\napproximates the statistical properties of the source data, allowing for\ncontrolled noise scaling based on the statistical distance between the two.\n\\updated{While our theoretical guarantees assume knowledge of the exact\nstatistical distance, practical implementations typically approximate this\ndistance, resulting in potentially weaker but still meaningful privacy\nguarantees.} This ensures strong guarantees on the model's behavior\npost-unlearning while maintaining its overall utility. We establish theoretical\nbounds, introduce practical noise calibration techniques, and validate our\nmethod through extensive experiments on both synthetic and real-world datasets.\nThe results demonstrate the effectiveness and reliability of our approach in\nprivacy-sensitive settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u7684\u8ba4\u8bc1\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u66ff\u4ee3\u6570\u636e\u96c6\u8fdb\u884c\u6570\u636e\u5220\u9664\uff0c\u540c\u65f6\u786e\u4fdd\u6a21\u578b\u7684\u9690\u79c1\u548c\u6548\u7528\u3002", "motivation": "\u4f20\u7edf\u7684\u9057\u5fd8\u65b9\u6cd5\u9700\u8981\u8bbf\u95ee\u5b8c\u6574\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u800c\u5728\u65e0\u6cd5\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u65f6\uff0c\u8fd9\u662f\u4e0d\u73b0\u5b9e\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u80fd\u591f\u5728\u6ca1\u6709\u539f\u59cb\u8bad\u7ec3\u6570\u636e\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u5220\u9664\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u4e00\u4e2a\u66ff\u4ee3\u6570\u636e\u96c6\u6765\u8fd1\u4f3c\u6e90\u6570\u636e\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u5e76\u6839\u636e\u4e24\u8005\u4e4b\u95f4\u7684\u7edf\u8ba1\u8ddd\u79bb\u8fdb\u884c\u566a\u58f0\u7f29\u653e\u63a7\u5236\u3002\u6211\u4eec\u8fd8\u5efa\u7acb\u7406\u8bba\u754c\u9650\uff0c\u5f15\u5165\u5b9e\u9645\u566a\u58f0\u6821\u51c6\u6280\u672f\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u6548\u679c\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u65b9\u6cd5\u5728\u9690\u79c1\u654f\u611f\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u7406\u8bba\u4e0a\u7ed9\u51fa\u4e86\u754c\u9650\uff0c\u5b9e\u9645\u4e2d\u8fdb\u884c\u4e86\u566a\u58f0\u6821\u51c6\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u5728\u9690\u79c1\u654f\u611f\u7684\u73af\u5883\u4e2d\u6709\u6548\u4e14\u53ef\u9760\uff0c\u786e\u4fdd\u6a21\u578b\u5728\u5b66\u4e60\u540e\u884c\u4e3a\u7684\u5f3a\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u6548\u7528\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.06881", "pdf": "https://arxiv.org/pdf/2506.06881", "abs": "https://arxiv.org/abs/2506.06881", "authors": ["Zixuan Li", "Wenxuan Liu", "Long Bai", "Chunmao Zhang", "Wei Li", "Fenghui Zhang", "Quanxin Jin", "Ruoyun He", "Zhuo Chen", "Zhilei Hu", "Fei Wang", "Bingbing Xu", "Xuhui Jiang", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "KnowCoder-V2: Deep Knowledge Analysis", "categories": ["cs.AI"], "comment": null, "summary": "Deep knowledge analysis tasks always involve the systematic extraction and\nassociation of knowledge from large volumes of data, followed by logical\nreasoning to discover insights. However, to solve such complex tasks, existing\ndeep research frameworks face three major challenges: 1) They lack systematic\norganization and management of knowledge; 2) They operate purely online, making\nit inefficient for tasks that rely on shared and large-scale knowledge; 3) They\ncannot perform complex knowledge computation, limiting their abilities to\nproduce insightful analytical results. Motivated by these, in this paper, we\npropose a \\textbf{K}nowledgeable \\textbf{D}eep \\textbf{R}esearch (\\textbf{KDR})\nframework that empowers deep research with deep knowledge analysis capability.\nSpecifically, it introduces an independent knowledge organization phase to\npreprocess large-scale, domain-relevant data into systematic knowledge offline.\nBased on this knowledge, it extends deep research with an additional kind of\nreasoning steps that perform complex knowledge computation in an online manner.\nTo enhance the abilities of LLMs to solve knowledge analysis tasks in the above\nframework, we further introduce \\textbf{\\KCII}, an LLM that bridges knowledge\norganization and reasoning via unified code generation. For knowledge\norganization, it generates instantiation code for predefined classes,\ntransforming data into knowledge objects. For knowledge computation, it\ngenerates analysis code and executes on the above knowledge objects to obtain\ndeep analysis results. Experimental results on more than thirty datasets across\nsix knowledge analysis tasks demonstrate the effectiveness of \\KCII. Moreover,\nwhen integrated into the KDR framework, \\KCII can generate high-quality reports\nwith insightful analytical results compared to the mainstream deep research\nframework.", "AI": {"tldr": "\u63d0\u51fa\u4e86KDR\u6846\u67b6\u548c\\KCII\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u52a0\u5f3a\u77e5\u8bc6\u7ec4\u7ec7\u548c\u8ba1\u7b97\uff0c\u5b9e\u9a8c\u663e\u793a\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u6846\u67b6\u5728\u7cfb\u7edf\u5316\u77e5\u8bc6\u7ba1\u7406\u3001\u5171\u4eab\u5927\u89c4\u6a21\u77e5\u8bc6\u5904\u7406\u548c\u590d\u6742\u77e5\u8bc6\u8ba1\u7b97\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86KDR\u6846\u67b6\uff0c\u5f15\u5165\u72ec\u7acb\u7684\u77e5\u8bc6\u7ec4\u7ec7\u9636\u6bb5\u6765\u9884\u5904\u7406\u6570\u636e\uff0c\u4f7f\u7528\\KCII\u751f\u6210\u4ee3\u7801\u7528\u4e8e\u77e5\u8bc6\u7ec4\u7ec7\u548c\u590d\u6742\u77e5\u8bc6\u8ba1\u7b97\u3002", "result": "\u5728\u516d\u4e2a\u77e5\u8bc6\u5206\u6790\u4efb\u52a1\u7684\u8d85\u8fc7\u4e09\u5341\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\\KCII\u7684\u6709\u6548\u6027\u3002KDR\u6846\u67b6\u4e2d\u7684\\KCII\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5206\u6790\u62a5\u544a\u3002", "conclusion": "KDR\u6846\u67b6\u80fd\u591f\u6709\u6548\u7ec4\u7ec7\u548c\u8ba1\u7b97\u5927\u89c4\u6a21\u77e5\u8bc6\uff0c\u4e0e\u73b0\u6709\u6846\u67b6\u76f8\u6bd4\uff0c\u53ef\u4ee5\u751f\u6210\u66f4\u5177\u6d1e\u5bdf\u529b\u7684\u5206\u6790\u7ed3\u679c\u3002"}}
{"id": "2506.06686", "pdf": "https://arxiv.org/pdf/2506.06686", "abs": "https://arxiv.org/abs/2506.06686", "authors": ["Chunyuan Deng", "Ruidi Chang", "Hanjie Chen"], "title": "Learning Distribution-Wise Control in Representation Space for Language Models", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "Interventions in language models (LMs) are applied strategically to steer\nmodel behavior during the forward pass. Learnable interventions, also known as\nrepresentation fine-tuning, aim to apply pointwise control within the concept\nsubspace and have proven effective in altering high-level behaviors. In this\nwork, we extend this approach to the distribution level, enabling the model to\nlearn not only pointwise transformations but also the surrounding regions of\nthe concept subspace. We demonstrate that these methods perform effectively in\nearly layers, with larger standard deviations correlating strongly with\nimproved performance. Across eight commonsense reasoning and seven arithmetic\nreasoning benchmarks, our distribution-wise interventions consistently\noutperform pointwise interventions in controllability and robustness. These\nresults illustrate that distribution-wise interventions provide a more\ncomprehensive method for steering model behavior and enabling finer-grained\ncontrol over language models. The code is at:\n\\href{https://github.com/chili-lab/D-Intervention}{https://github.com/chili-lab/D-Intervention}.", "AI": {"tldr": "\u7814\u7a76\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u5f15\u5bfc\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5206\u5e03\u7ea7\u5e72\u9884\u6bd4\u9010\u70b9\u5e72\u9884\u8868\u73b0\u66f4\u4f18\uff0c\u5c24\u5176\u5728\u53ef\u63a7\u6027\u548c\u5065\u58ee\u6027\u4e0a\u3002", "motivation": "\u5f3a\u5316\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\u5f15\u5bfc\u80fd\u529b\uff0c\u63d0\u5347\u5728\u6982\u5ff5\u5b50\u7a7a\u95f4\u5185\u8fdb\u884c\u70b9\u63a7\u7684\u6548\u679c\u3002", "method": "\u6269\u5927\u5230\u5206\u5e03\u7ea7\u522b\u7684\u6a21\u578b\u5e72\u9884\u65b9\u6cd5\uff0c\u5141\u8bb8\u6a21\u578b\u5b66\u4e60\u6982\u5ff5\u5b50\u7a7a\u95f4\u7684\u70b9\u53d8\u6362\u53ca\u5176\u5468\u56f4\u533a\u57df\u3002", "result": "\u5728\u516b\u4e2a\u5e38\u8bc6\u63a8\u7406\u548c\u4e03\u4e2a\u7b97\u672f\u63a8\u7406\u57fa\u51c6\u4e0a\uff0c\u5206\u5e03\u7ea7\u5e72\u9884\u65b9\u6cd5\u5728\u53ef\u63a7\u6027\u548c\u5065\u58ee\u6027\u65b9\u9762\u4f18\u4e8e\u9010\u70b9\u5e72\u9884\u65b9\u6cd5\u3002", "conclusion": "\u5206\u5e03\u5f0f\u5e72\u9884\u65b9\u6cd5\u6bd4\u9010\u70b9\u5e72\u9884\u5728\u53ef\u63a7\u6027\u548c\u5065\u58ee\u6027\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5168\u9762\u7684\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.06488", "pdf": "https://arxiv.org/pdf/2506.06488", "abs": "https://arxiv.org/abs/2506.06488", "authors": ["Pratiksha Thaker", "Neil Kale", "Zhiwei Steven Wu", "Virginia Smith"], "title": "Membership Inference Attacks for Unseen Classes", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": "Preprint", "summary": "Shadow model attacks are the state-of-the-art approach for membership\ninference attacks on machine learning models. However, these attacks typically\nassume an adversary has access to a background (nonmember) data distribution\nthat matches the distribution the target model was trained on. We initiate a\nstudy of membership inference attacks where the adversary or auditor cannot\naccess an entire subclass from the distribution -- a more extreme but realistic\nversion of distribution shift than has been studied previously. In this\nsetting, we first show that the performance of shadow model attacks degrades\ncatastrophically, and then demonstrate the promise of another approach,\nquantile regression, that does not have the same limitations. We show that\nquantile regression attacks consistently outperform shadow model attacks in the\nclass dropout setting -- for example, quantile regression attacks achieve up to\n11$\\times$ the TPR of shadow models on the unseen class on CIFAR-100, and\nachieve nontrivial TPR on ImageNet even with 90% of training classes removed.\nWe also provide a theoretical model that illustrates the potential and\nlimitations of this approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u91cf\u5316\u56de\u5f52\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\uff0c\u9488\u5bf9\u65e0\u6cd5\u8bbf\u95ee\u5b8c\u6574\u6570\u636e\u5206\u5e03\u60c5\u51b5\uff0c\u6bd4\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u66f4\u6709\u6548\u3002", "motivation": "\u5f53\u524d\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\u5047\u8bbe\u654c\u624b\u53ef\u4ee5\u8bbf\u95ee\u4e0e\u76ee\u6807\u6a21\u578b\u8bad\u7ec3\u5206\u5e03\u5339\u914d\u7684\u80cc\u666f\u6570\u636e\u5206\u5e03\uff0c\u4f46\u8fd9\u6837\u7684\u5047\u8bbe\u5728\u73b0\u5b9e\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5728\u65e0\u6cd5\u8bbf\u95ee\u6574\u4e2a\u5b50\u7c7b\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u5f53\u654c\u624b\u65e0\u6cd5\u8bbf\u95ee\u5206\u5e03\u4e2d\u7684\u6574\u4e2a\u5b50\u7c7b\u65f6\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5316\u56de\u5f52\u7684\u65b9\u6cd5\uff0c\u4e0d\u53d7\u4f20\u7edf\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u7684\u9650\u5236\u3002", "result": "\u91cf\u5316\u56de\u5f52\u653b\u51fb\u5728\u7c7b\u4e22\u5931\u73af\u5883\u4e0b\u4f18\u4e8e\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u3002\u4f8b\u5982\uff0c\u5728CIFAR-100\u7684\u6570\u636e\u96c6\u4e2d\uff0c\u91cf\u5316\u56de\u5f52\u653b\u51fb\u7684TPR\u6bd4\u5f71\u5b50\u6a21\u578b\u9ad8\u51fa11\u500d\uff1b\u5728ImageNet\u4e0a\uff0c\u5373\u4f7f\u79fb\u966490%\u8bad\u7ec3\u7c7b\uff0c\u4e5f\u80fd\u591f\u8fbe\u5230\u975e\u5e73\u51e1\u7684TPR\u3002", "conclusion": "\u91cf\u5316\u56de\u5f52\u80fd\u591f\u5728\u4e0d\u5b8c\u6574\u6570\u636e\u5206\u5e03\u60c5\u51b5\u4e0b\u6709\u6548\u8fdb\u884c\u6210\u5458\u63a8\u65ad\uff0c\u6bd4\u4f20\u7edf\u5f71\u5b50\u6a21\u578b\u653b\u51fb\u5728\u6781\u7aef\u5206\u5e03\u8f6c\u79fb\u60c5\u51b5\u4e0b\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2506.06905", "pdf": "https://arxiv.org/pdf/2506.06905", "abs": "https://arxiv.org/abs/2506.06905", "authors": ["Akash Gupta", "Amos Storkey", "Mirella Lapata"], "title": "Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to\nperform new tasks with minimal supervision. However, ICL performance,\nespecially in smaller LMMs, is inconsistent and does not always improve\nmonotonically with increasing examples. We hypothesize that this occurs due to\nthe LMM being overwhelmed by additional information present in the image\nembeddings, which is not required for the downstream task. To address this, we\npropose a meta-learning approach that provides an alternative for inducing\nfew-shot capabilities in LMMs, using a fixed set of soft prompts that are\ndistilled from task-relevant image features and can be adapted at test time\nusing a few examples. To facilitate this distillation, we introduce an\nattention-mapper module that can be easily integrated with the popular LLaVA\nv1.5 architecture and is jointly learned with soft prompts, enabling task\nadaptation in LMMs under low-data regimes with just a few gradient steps.\nEvaluation on the VL-ICL Bench shows that our method consistently outperforms\nICL and related prompt-tuning approaches, even under image perturbations,\nimproving task induction and reasoning across visual question answering tasks.", "AI": {"tldr": "\u4e3a\u4e86\u6539\u5584\u5c0f\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u6620\u5c04\u6a21\u5757\u548c\u8f6f\u63d0\u793a\u63d0\u9ad8\u4f4e\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u4efb\u52a1\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u5927\u591a\u6570\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u6267\u884c\u65b0\u7684\u4efb\u52a1\u65f6\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u4f46\u5b83\u5728\u8f83\u5c0f\u6a21\u578b\u4e2d\u7684\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u56e0\u6b64\u6211\u4eec\u63d0\u51fa\u6539\u5584\u6b64\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u4e00\u79cd\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u4efb\u52a1\u76f8\u5173\u7684\u56fe\u50cf\u7279\u5f81\u4e2d\u63d0\u70bc\u51fa\u7684\u56fa\u5b9a\u8f6f\u63d0\u793a\u6765\u8bf1\u5bfc LMMs \u7684\u5c0f\u6837\u672c\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u6ce8\u610f\u529b\u6620\u5c04\u6a21\u5757\u6765\u4fc3\u8fdb\u8fd9\u79cd\u63d0\u70bc\u8fc7\u7a0b\u3002", "result": "\u6211\u4eec\u7684\u6a21\u578b\u5728 VL-ICL \u57fa\u51c6\u4e0a\u6301\u7eed\u4f18\u4e8e ICL \u548c\u76f8\u5173\u63d0\u793a\u8c03\u6574\u65b9\u6cd5\uff0c\u5373\u4fbf\u5728\u56fe\u50cf\u53d7\u5230\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u4efb\u52a1\u5f15\u5bfc\u548c\u63a8\u7406\u80fd\u529b\u4e5f\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u5728\u4f4e\u6570\u636e\u6761\u4ef6\u4e0b\u6709\u6548\u5730\u63d0\u9ad8\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u7684\u4efb\u52a1\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2506.06704", "pdf": "https://arxiv.org/pdf/2506.06704", "abs": "https://arxiv.org/abs/2506.06704", "authors": ["Weihang Su", "Qingyao Ai", "Jingtao Zhan", "Qian Dong", "Yiqun Liu"], "title": "Dynamic and Parametric Retrieval-Augmented Generation", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has become a foundational paradigm for\nequipping large language models (LLMs) with external knowledge, playing a\ncritical role in information retrieval and knowledge-intensive applications.\nHowever, conventional RAG systems typically adopt a static\nretrieve-then-generate pipeline and rely on in-context knowledge injection,\nwhich can be suboptimal for complex tasks that require multihop reasoning,\nadaptive information access, and deeper integration of external knowledge.\nMotivated by these limitations, the research community has moved beyond static\nretrieval and in-context knowledge injection. Among the emerging directions,\nthis tutorial delves into two rapidly growing and complementary research areas\non RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when\nand what to retrieve during the LLM's generation process, enabling real-time\nadaptation to the LLM's evolving information needs. Parametric RAG rethinks how\nretrieved knowledge should be injected into LLMs, transitioning from\ninput-level to parameter-level knowledge injection for enhanced efficiency and\neffectiveness. This tutorial offers a comprehensive overview of recent advances\nin these emerging research areas. It also shares theoretical foundations and\npractical insights to support and inspire further research in RAG.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u52a8\u6001RAG\u548c\u53c2\u6570\u5316RAG\u4ee5\u6539\u8fdbLLM\u7684\u77e5\u8bc6\u68c0\u7d22\u4e0e\u6574\u5408\u6548\u7387\uff0c\u8d85\u8d8a\u4f20\u7edf\u9759\u6001\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684RAG\u7cfb\u7edf\u5728\u5904\u7406\u9700\u8981\u591a\u8df3\u63a8\u7406\u548c\u6df1\u5165\u77e5\u8bc6\u6574\u5408\u7684\u590d\u6742\u4efb\u52a1\u65f6\u6548\u679c\u6b20\u4f73\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u4eba\u5458\u63a2\u7d22\u65b0\u7684\u65b9\u5411\u6765\u589e\u5f3aLLM\u7684\u77e5\u8bc6\u6574\u5408\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u6df1\u5165\u7814\u7a76\u52a8\u6001RAG\u548c\u53c2\u6570\u5316RAG\uff0c\u63a2\u8ba8\u5728LLM\u751f\u6210\u8fc7\u7a0b\u4e2d\u5982\u4f55\u9002\u5e94\u6027\u5730\u8fdb\u884c\u5b9e\u65f6\u77e5\u8bc6\u68c0\u7d22\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u53c2\u6570\u5c42\u800c\u975e\u8f93\u5165\u5c42\u8fdb\u884c\u77e5\u8bc6\u6ce8\u5165\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u5bf9\u52a8\u6001\u548c\u53c2\u6570\u5316RAG\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\u7684\u5168\u9762\u6982\u8ff0\uff0c\u5e76\u5206\u4eab\u4e86\u76f8\u5173\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u89c1\u89e3\u3002\u8fd9\u5c06\u652f\u6301\u5e76\u6fc0\u53d1\u672a\u6765\u5728RAG\u9886\u57df\u7684\u7814\u7a76\u3002", "conclusion": "\u8be5\u8bba\u6587\u5bf9RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210)\u8fdb\u884c\u4e86\u7814\u7a76\uff0c\u7279\u522b\u662f\u4f20\u7edf\u9759\u6001\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u52a8\u6001RAG\u548c\u53c2\u6570\u5316RAG\uff0c\u4e24\u8005\u90fd\u80fd\u6539\u8fdbLLM\u7684\u77e5\u8bc6\u6574\u5408\u4e0e\u4f7f\u7528\u6548\u7387\u3002"}}
{"id": "2506.06489", "pdf": "https://arxiv.org/pdf/2506.06489", "abs": "https://arxiv.org/abs/2506.06489", "authors": ["Daniel Kunin", "Giovanni Luca Marchetti", "Feng Chen", "Dhruva Karkada", "James B. Simon", "Michael R. DeWeese", "Surya Ganguli", "Nina Miolane"], "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks", "categories": ["cs.LG", "stat.ML"], "comment": "35 pages, 7 figures", "summary": "What features neural networks learn, and how, remains an open question. In\nthis paper, we introduce Alternating Gradient Flows (AGF), an algorithmic\nframework that describes the dynamics of feature learning in two-layer networks\ntrained from small initialization. Prior works have shown that gradient flow in\nthis regime exhibits a staircase-like loss curve, alternating between plateaus\nwhere neurons slowly align to useful directions and sharp drops where neurons\nrapidly grow in norm. AGF approximates this behavior as an alternating two-step\nprocess: maximizing a utility function over dormant neurons and minimizing a\ncost function over active ones. AGF begins with all neurons dormant. At each\nround, a dormant neuron activates, triggering the acquisition of a feature and\na drop in the loss. AGF quantifies the order, timing, and magnitude of these\ndrops, matching experiments across architectures. We show that AGF unifies and\nextends existing saddle-to-saddle analyses in fully connected linear networks\nand attention-only linear transformers, where the learned features are singular\nmodes and principal components, respectively. In diagonal linear networks, we\nprove AGF converges to gradient flow in the limit of vanishing initialization.\nApplying AGF to quadratic networks trained to perform modular addition, we give\nthe first complete characterization of the training dynamics, revealing that\nnetworks learn Fourier features in decreasing order of coefficient magnitude.\nAltogether, AGF offers a promising step towards understanding feature learning\nin neural networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4ea4\u66ff\u68af\u5ea6\u6d41\uff08AGF\uff09\uff0c\u4e00\u79cd\u63cf\u8ff0\u795e\u7ecf\u7f51\u7edc\u7279\u5f81\u5b66\u4e60\u52a8\u6001\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u6210\u529f\u91cf\u5316\u4e86\u635f\u5931\u4e0b\u964d\u6a21\u5f0f\uff0c\u5e76\u6269\u5c55\u4e86\u73b0\u6709\u5206\u6790\u3002", "motivation": "\u4e86\u89e3\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7279\u5f81\u7684\u65b9\u5f0f\u53ca\u5176\u52a8\u6001\u8fc7\u7a0b\u4ecd\u7136\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4ea4\u66ff\u68af\u5ea6\u6d41\uff08AGF\uff09\u4f5c\u4e3a\u4e00\u79cd\u7b97\u6cd5\u6846\u67b6\uff0c\u63cf\u8ff0\u4e86\u4e24\u5c42\u7f51\u7edc\u4e2d\u7279\u5f81\u5b66\u4e60\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u8be5\u7f51\u7edc\u4ece\u5c0f\u521d\u59cb\u5316\u5f00\u59cb\u8bad\u7ec3\u3002", "result": "AGF\u51c6\u786e\u91cf\u5316\u4e86\u635f\u5931\u4e0b\u964d\u7684\u987a\u5e8f\u3001\u65f6\u95f4\u548c\u5e45\u5ea6\uff0c\u5e76\u6210\u529f\u5339\u914d\u4e0d\u540c\u67b6\u6784\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\u5728\u5bf9\u89d2\u7ebf\u7ebf\u6027\u7f51\u7edc\u4e2d\uff0c\u8bc1\u660eAGF\u5728\u6d88\u5931\u521d\u59cb\u5316\u7684\u6781\u9650\u4e0b\u6536\u655b\u5230\u68af\u5ea6\u6d41\u3002\u5728\u4e8c\u6b21\u7f51\u7edc\u4e2d\uff0c\u9996\u6b21\u5b8c\u6574\u523b\u753b\u4e86\u8bad\u7ec3\u52a8\u6001\uff0c\u63ed\u793a\u7f51\u7edc\u5b66\u4e60\u5085\u91cc\u53f6\u7279\u5f81\u7684\u987a\u5e8f\u3002", "conclusion": "AGF\u63d0\u4f9b\u4e86\u4e00\u79cd\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u4e2d\u7279\u5f81\u5b66\u4e60\u52a8\u6001\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6269\u5c55\u4e86\u73b0\u6709\u7684\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2506.06910", "pdf": "https://arxiv.org/pdf/2506.06910", "abs": "https://arxiv.org/abs/2506.06910", "authors": ["Mahnaz Koupaee", "Xueying Bai", "Mudan Chen", "Greg Durrett", "Nathanael Chambers", "Niranjan Balasubramanian"], "title": "Causal Graph based Event Reasoning using Semantic Relation Experts", "categories": ["cs.AI"], "comment": null, "summary": "Understanding how events in a scenario causally connect with each other is\nimportant for effectively modeling and reasoning about events. But event\nreasoning remains a difficult challenge, and despite recent advances, Large\nLanguage Models (LLMs) still struggle to accurately identify causal connections\nbetween events. This struggle leads to poor performance on deeper reasoning\ntasks like event forecasting and timeline understanding. To address this\nchallenge, we investigate the generation of causal event graphs (e.g., A\nenables B) as a parallel mechanism to help LLMs explicitly represent causality\nduring inference. This paper evaluates both how to generate correct graphs as\nwell as how graphs can assist reasoning. We propose a collaborative approach to\ncausal graph generation where we use LLMs to simulate experts that focus on\nspecific semantic relations. The experts engage in multiple rounds of\ndiscussions which are then consolidated by a final expert. Then, to demonstrate\nthe utility of causal graphs, we use them on multiple downstream applications,\nand also introduce a new explainable event prediction task that requires a\ncausal chain of events in the explanation. These explanations are more\ninformative and coherent than baseline generations. Finally, our overall\napproach not finetuned on any downstream task, achieves competitive results\nwith state-of-the-art models on both forecasting and next event prediction\ntasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u751f\u6210\u56e0\u679c\u4e8b\u4ef6\u56fe\u7684\u534f\u4f5c\u65b9\u6cd5\u5e2e\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6539\u5584\u4e8b\u4ef6\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4e0d\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u9884\u6d4b\u4efb\u52a1\u7684\u7ade\u4e89\u6027\u6548\u679c\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e8b\u4ef6\u63a8\u7406\u65b9\u9762\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u4ecd\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u4e8b\u4ef6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u8fd9\u5bfc\u81f4\u5728\u4e8b\u4ef6\u9884\u6d4b\u548c\u65f6\u95f4\u7ebf\u7406\u89e3\u8fd9\u7c7b\u6df1\u5c42\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u534f\u4f5c\u7684\u65b9\u6cd5\u751f\u6210\u56e0\u679c\u4e8b\u4ef6\u56fe\uff0c\u5e94\u7528\u4e8e\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8f85\u52a9\u8bed\u8a00\u6a21\u578b\u3002\u4f7f\u7528\u6a21\u62df\u4e13\u5bb6\u5173\u6ce8\u5177\u4f53\u8bed\u4e49\u5173\u7cfb\uff0c\u901a\u8fc7\u591a\u8f6e\u8ba8\u8bba\uff0c\u4e00\u4e2a\u6700\u7ec8\u4e13\u5bb6\u6574\u5408\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u751f\u6210\u7684\u56e0\u679c\u4e8b\u4ef6\u56fe\u7528\u4e8e\u591a\u4e0b\u6e38\u5e94\u7528\uff0c\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u53ef\u89e3\u91ca\u4e8b\u4ef6\u9884\u6d4b\u4efb\u52a1\uff0c\u8be5\u4efb\u52a1\u5728\u89e3\u91ca\u4e2d\u9700\u8981\u56e0\u679c\u4e8b\u4ef6\u94fe\u3002\u751f\u6210\u7684\u89e3\u91ca\u6bd4\u57fa\u51c6\u66f4\u5177\u4fe1\u606f\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u672a\u5728\u4efb\u4f55\u4e0b\u6e38\u4efb\u52a1\u4e0a\u5fae\u8c03\u7684\u6574\u4f53\u65b9\u6cd5\u5728\u4e8b\u4ef6\u9884\u6d4b\u548c\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u534f\u4f5c\u751f\u6210\u56e0\u679c\u4e8b\u4ef6\u56fe\u7684\u65b9\u6cd5\uff0c\u4ee5\u8865\u5145\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5bf9\u4e8b\u4ef6\u95f4\u56e0\u679c\u5173\u7cfb\u7684\u8868\u793a\u3002\u901a\u8fc7\u591a\u4e2a\u4e13\u5bb6\u7684\u8ba8\u8bba\u548c\u6574\u5408\uff0c\u751f\u6210\u7684\u56e0\u679c\u56fe\u80fd\u7528\u4e8e\u591a\u79cd\u4e0b\u6e38\u5e94\u7528\uff0c\u5e76\u5728\u4e0d\u7ecf\u8fc7\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e8b\u4ef6\u9884\u6d4b\u548c\u4e0b\u4e00\u4e8b\u4ef6\u9884\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u7ade\u4e89\u7ed3\u679c\u3002"}}
{"id": "2506.06705", "pdf": "https://arxiv.org/pdf/2506.06705", "abs": "https://arxiv.org/abs/2506.06705", "authors": ["Zhihui Chen", "Kai He", "Yucheng Huang", "Yunxiao Zhu", "Mengling Feng"], "title": "DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains", "categories": ["cs.CL", "cs.AI"], "comment": "Zhihui Chen and Kai He contributed equally to this work, Mengling\n  Feng is the corresponding author", "summary": "Detecting LLM-generated text in specialized and high-stakes domains like\nmedicine and law is crucial for combating misinformation and ensuring\nauthenticity. However, current zero-shot detectors, while effective on general\ntext, often fail when applied to specialized content due to domain shift. We\nprovide a theoretical analysis showing this failure is fundamentally linked to\nthe KL divergence between human, detector, and source text distributions. To\naddress this, we propose DivScore, a zero-shot detection framework using\nnormalized entropy-based scoring and domain knowledge distillation to robustly\nidentify LLM-generated text in specialized domains. We also release a\ndomain-specific benchmark for LLM-generated text detection in the medical and\nlegal domains. Experiments on our benchmark show that DivScore consistently\noutperforms state-of-the-art detectors, with 14.4% higher AUROC and 64.0%\nhigher recall (0.1% false positive rate threshold). In adversarial settings,\nDivScore demonstrates superior robustness than other baselines, achieving on\naverage 22.8% advantage in AUROC and 29.5% in recall. Code and data are\npublicly available.", "AI": {"tldr": "DivScore\u662f\u4e00\u4e2a\u4e13\u4e3a\u4e13\u4e1a\u9886\u57df\u8bbe\u8ba1\u7684LLM\u6587\u672c\u68c0\u6d4b\u5668\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u63d0\u4f9b\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5728\u533b\u5b66\u548c\u6cd5\u5f8b\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u68c0\u6d4bLLM\u751f\u6210\u6587\u672c\u5bf9\u4e8e\u6253\u51fb\u9519\u8bef\u4fe1\u606f\u548c\u786e\u4fdd\u771f\u5b9e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7684\u96f6\u6837\u672c\u68c0\u6d4b\u5668\u5e38\u56e0\u9886\u57df\u8f6c\u53d8\u800c\u5931\u6548\u3002", "method": "\u63d0\u51faDivScore\uff0c\u5229\u7528\u5f52\u4e00\u5316\u71b5\u8bc4\u5206\u548c\u9886\u57df\u77e5\u8bc6\u63d0\u70bc\u8fdb\u884c\u96f6\u6837\u672c\u68c0\u6d4b\u6846\u67b6\uff0c\u4ee5\u8bc6\u522b\u4e13\u4e1a\u9886\u57df\u4e2d\u7684LLM\u751f\u6210\u6587\u672c\u3002", "result": "\u5728\u533b\u5b66\u548c\u6cd5\u5f8b\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDivScore\u5728AUROC\u548c\u53ec\u56de\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u68c0\u6d4b\u5668\uff0c\u5e76\u5728\u5bf9\u6297\u6027\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa22.8%\u7684AUROC\u4f18\u52bf\u548c29.5%\u7684\u53ec\u56de\u7387\u4f18\u52bf\u3002", "conclusion": "DivScore\u5728\u68c0\u6d4b\u4e13\u4e1a\u9886\u57df\u7684LLM\u751f\u6210\u6587\u672c\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u68c0\u6d4b\u5668\uff0c\u5e76\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.06499", "pdf": "https://arxiv.org/pdf/2506.06499", "abs": "https://arxiv.org/abs/2506.06499", "authors": ["Alex Havrilla", "Edward Hughes", "Mikayel Samvelyan", "Jacob Abernethy"], "title": "Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language model (LLM) driven synthetic data generation has emerged as a\npowerful method for improving model reasoning capabilities. However, most\nmethods either distill large state-of-the-art models into small students or use\nnatural ground-truth problem statements to guarantee problem statement quality.\nThis limits the scalability of these approaches to more complex and diverse\nproblem domains. To address this, we present SPARQ: Synthetic Problem\nGeneration for Reasoning via Quality-Diversity Algorithms, a novel approach for\ngenerating high-quality and diverse synthetic math problem and solution pairs\nusing only a single model by measuring a problem's solve-rate: a proxy for\nproblem difficulty. Starting from a seed dataset of 7.5K samples, we generate\nover 20 million new problem-solution pairs. We show that filtering the\ngenerated data by difficulty and then fine-tuning the same model on the\nresulting data improves relative model performance by up to 24\\%. Additionally,\nwe conduct ablations studying the impact of synthetic data quantity, quality\nand diversity on model generalization. We find that higher quality, as measured\nby problem difficulty, facilitates better in-distribution performance. Further,\nwhile generating diverse synthetic data does not as strongly benefit\nin-distribution performance, filtering for more diverse data facilitates more\nrobust OOD generalization. We also confirm the existence of model and data\nscaling laws for synthetically generated problems, which positively benefit\ndownstream model generalization.", "AI": {"tldr": "SPARQ\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u5316\u7684\u5408\u6210\u6570\u636e\u6765\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684\u65b9\u6cd5\u5bf9\u4e8e\u590d\u6742\u548c\u591a\u6837\u5316\u7684\u95ee\u9898\u57df\u7684\u6269\u5c55\u6027\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6570\u636e\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPARQ\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u8d28\u91cf-\u591a\u6837\u6027\u7b97\u6cd5\u901a\u8fc7\u6d4b\u91cf\u95ee\u9898\u7684\u89e3\u9898\u7387\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u5316\u7684\u5408\u6210\u6570\u5b66\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u5bf9\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\uff0c\u76f8\u5bf9\u6027\u80fd\u63d0\u9ad8\u4e8624%\u3002\u53d1\u73b0\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u6709\u52a9\u4e8e\u63d0\u9ad8\u5206\u5e03\u5185\u6027\u80fd\uff0c\u800c\u66f4\u591a\u6837\u5316\u7684\u6570\u636e\u5219\u6709\u52a9\u4e8e\u63d0\u9ad8\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u5316\u7684\u5408\u6210\u6570\u5b66\u95ee\u9898\u548c\u89e3\u51b3\u65b9\u6848\u6570\u636e\u6709\u52a9\u4e8e\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u89e3\u51b3\u5206\u5e03\u5916\u95ee\u9898\u65f6\u8868\u73b0\u66f4\u4e3a\u51fa\u8272\u3002"}}
{"id": "2506.06923", "pdf": "https://arxiv.org/pdf/2506.06923", "abs": "https://arxiv.org/abs/2506.06923", "authors": ["Xutong Zhao", "Tengyu Xu", "Xuewei Wang", "Zhengxing Chen", "Di Jin", "Liang Tan", "Yen-Ting", "Zishun Yu", "Zhuokai Zhao", "Yun He", "Sinong Wang", "Han Fang", "Sarath Chandar", "Chen Zhu"], "title": "Boosting LLM Reasoning via Spontaneous Self-Correction", "categories": ["cs.AI"], "comment": null, "summary": "While large language models (LLMs) have demonstrated remarkable success on a\nbroad range of tasks, math reasoning remains a challenging one. One of the\napproaches for improving math reasoning is self-correction, which designs\nself-improving loops to let the model correct its own mistakes. However,\nexisting self-correction approaches treat corrections as standalone\npost-generation refinements, relying on extra prompt and system designs to\nelicit self-corrections, instead of performing real-time, spontaneous\nself-corrections in a single pass. To address this, we propose SPOC, a\nspontaneous self-correction approach that enables LLMs to generate interleaved\nsolutions and verifications in a single inference pass, with generation\ndynamically terminated based on verification outcomes, thereby effectively\nscaling inference time compute. SPOC considers a multi-agent perspective by\nassigning dual roles -- solution proposer and verifier -- to the same model. We\nadopt a simple yet effective approach to generate synthetic data for\nfine-tuning, enabling the model to develop capabilities for self-verification\nand multi-agent collaboration. We further improve its solution proposal and\nverification accuracy through online reinforcement learning. Experiments on\nmathematical reasoning benchmarks show that SPOC significantly improves\nperformance. Notably, SPOC boosts the accuracy of Llama-3.1-8B and 70B Instruct\nmodels, achieving gains of 8.8% and 11.6% on MATH500, 10.0% and 20.0% on AMC23,\nand 3.3% and 6.7% on AIME24, respectively.", "AI": {"tldr": "SPOC\u901a\u8fc7\u542f\u7528\u6a21\u578b\u5728\u4e00\u6b21\u63a8\u7406\u4e2d\u8fdb\u884c\u81ea\u6211\u7ea0\u6b63\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u6211\u7ea0\u6b63\u65b9\u6cd5\u901a\u5e38\u4f5c\u4e3a\u5355\u72ec\u7684\u751f\u6210\u540e\u4fee\u6b63\uff0c\u4f9d\u8d56\u989d\u5916\u7684\u63d0\u793a\u548c\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u800c\u4e0d\u662f\u5728\u4e00\u6b21\u63a8\u7406\u4e2d\u8fdb\u884c\u5b9e\u65f6\u7684\u81ea\u6211\u4fee\u6b63\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aSPOC\u7684\u81ea\u53d1\u6027\u81ea\u6211\u7ea0\u6b63\u65b9\u6cd5\uff0c\u4f7fLLMs\u5728\u4e00\u6b21\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u4ea4\u7ec7\u7684\u89e3\u7b54\u548c\u9a8c\u8bc1\uff0c\u7531\u9a8c\u8bc1\u7ed3\u679c\u52a8\u6001\u7ec8\u6b62\u751f\u6210\u3002\u91c7\u7528\u7b80\u5355\u6709\u6548\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6cd5\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u51c6\u786e\u6027\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSPOC\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5982Llama-3.1-8B\u548c70B Instruct\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e86\u663e\u8457\u7684\u7cbe\u5ea6\u63d0\u5347\u3002", "conclusion": "SPOC\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06708", "pdf": "https://arxiv.org/pdf/2506.06708", "abs": "https://arxiv.org/abs/2506.06708", "authors": ["Haiqi Yang", "Zhiyuan Li", "Yi Chang", "Yuan Wu"], "title": "A Survey of Retentive Network", "categories": ["cs.CL"], "comment": "15 pages, 3 figures", "summary": "Retentive Network (RetNet) represents a significant advancement in neural\nnetwork architecture, offering an efficient alternative to the Transformer.\nWhile Transformers rely on self-attention to model dependencies, they suffer\nfrom high memory costs and limited scalability when handling long sequences due\nto their quadratic complexity. To mitigate these limitations, RetNet introduces\na retention mechanism that unifies the inductive bias of recurrence with the\nglobal dependency modeling of attention. This mechanism enables linear-time\ninference, facilitates efficient modeling of extended contexts, and remains\ncompatible with fully parallelizable training pipelines. RetNet has garnered\nsignificant research interest due to its consistently demonstrated cross-domain\neffectiveness, achieving robust performance across machine learning paradigms\nincluding natural language processing, speech recognition, and time-series\nanalysis. However, a comprehensive review of RetNet is still missing from the\ncurrent literature. This paper aims to fill that gap by offering the first\ndetailed survey of the RetNet architecture, its key innovations, and its\ndiverse applications. We also explore the main challenges associated with\nRetNet and propose future research directions to support its continued\nadvancement in both academic research and practical deployment.", "AI": {"tldr": "RetNet\u4f5c\u4e3a\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u663e\u8457\u8fdb\u6b65\uff0c\u514b\u670d\u4e86Transformer\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u4fdd\u7559\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\uff0c\u662f\u4e00\u4e2a\u503c\u5f97\u6df1\u5165\u7814\u7a76\u7684\u9886\u57df\u3002", "motivation": "Transformer\u7531\u4e8e\u81ea\u8eab\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u6027\uff0c\u5bfc\u81f4\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u9ad8\u5185\u5b58\u6210\u672c\u548c\u6709\u9650\u7684\u53ef\u6269\u5c55\u6027\u3002RetNet\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4fdd\u7559\u673a\u5236\u6765\u514b\u670dTransformer\u7684\u8fd9\u4e9b\u5c40\u9650\u6027\u3002", "method": "RetNet\u5f15\u5165\u4e86\u4e00\u79cd\u4fdd\u7559\u673a\u5236\uff0c\u8be5\u673a\u5236\u5c06\u9012\u5f52\u7684\u5f52\u7eb3\u504f\u5dee\u4e0e\u6ce8\u610f\u529b\u7684\u5168\u5c40\u4f9d\u8d56\u5efa\u6a21\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u65f6\u95f4\u63a8\u7406\u548c\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u3002", "result": "RetNet\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8bed\u97f3\u8bc6\u522b\u548c\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7b49\u673a\u5668\u5b66\u4e60\u8303\u5f0f\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u8fd9\u79cd\u8868\u73b0\u8de8\u9886\u57df\u4e00\u81f4\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u4f9b\u4e86RetNet\u67b6\u6784\u7684\u8be6\u7ec6\u7efc\u8ff0\uff0c\u586b\u8865\u4e86\u5f53\u524d\u6587\u732e\u7684\u7a7a\u767d\u3002\u540c\u65f6\u63a2\u8ba8\u4e86RetNet\u76f8\u5173\u7684\u4e3b\u8981\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.06501", "pdf": "https://arxiv.org/pdf/2506.06501", "abs": "https://arxiv.org/abs/2506.06501", "authors": ["Ran Levinstein", "Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren", "Daniel Soudry", "Itay Evron"], "title": "Optimal Rates in Continual Linear Regression via Increasing Regularization", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study realizable continual linear regression under random task orderings,\na common setting for developing continual learning theory. In this setup, the\nworst-case expected loss after $k$ learning iterations admits a lower bound of\n$\\Omega(1/k)$. However, prior work using an unregularized scheme has only\nestablished an upper bound of $O(1/k^{1/4})$, leaving a significant gap. Our\npaper proves that this gap can be narrowed, or even closed, using two\nfrequently used regularization schemes: (1) explicit isotropic $\\ell_2$\nregularization, and (2) implicit regularization via finite step budgets. We\nshow that these approaches, which are used in practice to mitigate forgetting,\nreduce to stochastic gradient descent (SGD) on carefully defined surrogate\nlosses. Through this lens, we identify a fixed regularization strength that\nyields a near-optimal rate of $O(\\log k / k)$. Moreover, formalizing and\nanalyzing a generalized variant of SGD for time-varying functions, we derive an\nincreasing regularization strength schedule that provably achieves an optimal\nrate of $O(1/k)$. This suggests that schedules that increase the regularization\ncoefficient or decrease the number of steps per task are beneficial, at least\nin the worst case.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u6b63\u786e\u7684\u6b63\u5219\u5316\u7b56\u7565\uff0c\u53ef\u663e\u8457\u63d0\u9ad8\u968f\u673a\u4efb\u52a1\u6392\u5e8f\u4e0b\u8fde\u7eed\u7ebf\u6027\u56de\u5f52\u7684\u5b66\u4e60\u901f\u7387\u3002", "motivation": "\u7f29\u5c0f\u6700\u574f\u60c5\u51b5\u4e0b\u635f\u5931\u7684\u4e0a\u4e0b\u9650\u5dee\u8ddd\uff0c\u63d0\u9ad8\u8fde\u7eed\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u5b66\u4e60\u6548\u7387\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u6b63\u5219\u5316\u65b9\u6cd5\uff1a\uff081\uff09\u663e\u5f0f\u5404\u5411\u540c\u6027$\\ell_2$\u6b63\u5219\u5316\uff0c\uff082\uff09\u901a\u8fc7\u6709\u9650\u6b65\u9884\u7b97\u9690\u5f0f\u6b63\u5219\u5316\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u8fc7\u5bf9\u7ecf\u8fc7\u7cbe\u5fc3\u5b9a\u4e49\u7684\u66ff\u4ee3\u635f\u5931\u6267\u884c\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u6765\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u56fa\u5b9a\u6b63\u5219\u5316\u5f3a\u5ea6\uff0c\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684$O(\\log k / k)$\u52a0\u5feb\u5b66\u4e60\u901f\u7387\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u65f6\u95f4\u53d8\u5316\u51fd\u6570\u7684\u4e00\u822c\u5316SGD\u53d8\u4f53\u5206\u6790\uff0c\u5f97\u5230\u4e86\u968f\u65f6\u95f4\u589e\u52a0\u7684\u6b63\u5219\u5316\u5f3a\u5ea6\u5b89\u6392\u4ee5\u5b9e\u73b0\u6700\u4f18\u7684$O(1/k)$\u901f\u7387\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u589e\u52a0\u6b63\u5219\u5316\u5f3a\u5ea6\u6216\u51cf\u5c11\u6bcf\u4e2a\u4efb\u52a1\u7684\u6b65\u9aa4\u6570\uff0c\u53ef\u4ee5\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u63d0\u9ad8\u5b66\u4e60\u901f\u7387\u3002"}}
{"id": "2506.06935", "pdf": "https://arxiv.org/pdf/2506.06935", "abs": "https://arxiv.org/abs/2506.06935", "authors": ["Darui Lu", "Jordan M. Malof", "Willie J. Padilla"], "title": "An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design", "categories": ["cs.AI", "cond-mat.mtrl-sci"], "comment": "22 pages, 6 figures", "summary": "Recent significant advances in integrating multiple Large Language Model\n(LLM) systems have enabled Agentic Frameworks capable of performing complex\ntasks autonomously, including novel scientific research. We develop and\ndemonstrate such a framework specifically for the inverse design of photonic\nmetamaterials. When queried with a desired optical spectrum, the Agent\nautonomously proposes and develops a forward deep learning model, accesses\nexternal tools via APIs for tasks like simulation and optimization, utilizes\nmemory, and generates a final design via a deep inverse method. The framework's\neffectiveness is demonstrated in its ability to automate, reason, plan, and\nadapt. Notably, the Agentic Framework possesses internal reflection and\ndecision flexibility, permitting highly varied and potentially novel outputs.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2aAgentic\u6846\u67b6\u7528\u4e8e\u5149\u5b50\u8d85\u6750\u6599\u7684\u9006\u5411\u8bbe\u8ba1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u81ea\u52a8\u5316\u3001\u63a8\u7406\u3001\u8ba1\u5212\u548c\u9002\u5e94\u65b9\u9762\u7684\u80fd\u529b\u548c\u65b0\u9896\u8f93\u51fa\u3002", "motivation": "\u6574\u5408\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u91cd\u5927\u8fdb\u5c55\u4fc3\u8fdb\u4e86\u80fd\u591f\u81ea\u4e3b\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u7684Agentic\u6846\u67b6\u7684\u53d1\u5c55\u3002", "method": "\u6846\u67b6\u901a\u8fc7\u63d0\u51fa\u548c\u5f00\u53d1\u6b63\u5411\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528API\u8bbf\u95ee\u5916\u90e8\u5de5\u5177\u5982\u4eff\u771f\u548c\u4f18\u5316\uff0c\u4f7f\u7528\u5b58\u50a8\u5668\uff0c\u5e76\u901a\u8fc7\u6df1\u5ea6\u9006\u5411\u65b9\u6cd5\u751f\u6210\u6700\u7ec8\u8bbe\u8ba1\u3002", "result": "Agentic\u6846\u67b6\u5728\u5149\u5b50\u8d85\u6750\u6599\u7684\u9006\u5411\u8bbe\u8ba1\u4e2d\u6709\u6548\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u3001\u63a8\u7406\u3001\u8ba1\u5212\u548c\u9002\u5e94\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u81ea\u52a8\u5316\u3001\u63a8\u7406\u3001\u8ba1\u5212\u548c\u9002\u5e94\u80fd\u529b\uff0c\u53ef\u4ee5\u5728\u5149\u5b50\u8d85\u6750\u6599\u7684\u9006\u5411\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u4e0d\u540c\u4e14\u65b0\u9896\u7684\u8f93\u51fa\u3002"}}
{"id": "2506.06737", "pdf": "https://arxiv.org/pdf/2506.06737", "abs": "https://arxiv.org/abs/2506.06737", "authors": ["Qi Shi", "Qiwei Han", "Cl\u00e1udia Soares"], "title": "C-PATH: Conversational Patient Assistance and Triage in Healthcare System", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted in IEEE ICDH 2025, 10 pages, 8 figures, 5 tables", "summary": "Navigating healthcare systems can be complex and overwhelming, creating\nbarriers for patients seeking timely and appropriate medical attention. In this\npaper, we introduce C-PATH (Conversational Patient Assistance and Triage in\nHealthcare), a novel conversational AI system powered by large language models\n(LLMs) designed to assist patients in recognizing symptoms and recommending\nappropriate medical departments through natural, multi-turn dialogues. C-PATH\nis fine-tuned on medical knowledge, dialogue data, and clinical summaries using\na multi-stage pipeline built on the LLaMA3 architecture. A core contribution of\nthis work is a GPT-based data augmentation framework that transforms structured\nclinical knowledge from DDXPlus into lay-person-friendly conversations,\nallowing alignment with patient communication norms. We also implement a\nscalable conversation history management strategy to ensure long-range\ncoherence. Evaluation with GPTScore demonstrates strong performance across\ndimensions such as clarity, informativeness, and recommendation accuracy.\nQuantitative benchmarks show that C-PATH achieves superior performance in\nGPT-rewritten conversational datasets, significantly outperforming\ndomain-specific baselines. C-PATH represents a step forward in the development\nof user-centric, accessible, and accurate AI tools for digital health\nassistance and triage.", "AI": {"tldr": "C-PATH\u662f\u4e00\u79cd\u65b0\u578b\u5bf9\u8bddAI\u7cfb\u7edf\uff0c\u5229\u7528LLMs\u5e2e\u52a9\u60a3\u8005\u8bc6\u522b\u75c7\u72b6\u548c\u63a8\u8350\u533b\u52a1\u90e8\u95e8\uff0c\u8868\u73b0\u4f18\u4e8e\u9886\u57df\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u60a3\u8005\u5728\u5bfb\u6c42\u53ca\u65f6\u548c\u9002\u5f53\u533b\u7597\u5173\u6ce8\u65f6\u9762\u4e34\u7684\u590d\u6742\u548c\u538b\u5012\u6027\u969c\u788d\uff0c\u901a\u8fc7AI\u7cfb\u7edf\u63d0\u9ad8\u5bf9\u8bdd\u7684\u6e05\u6670\u5ea6\u3001\u4fe1\u606f\u6027\u548c\u63a8\u8350\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u5bf9\u8bddAI\u7cfb\u7edf\u7684\u5f00\u53d1\uff0c\u901a\u8fc7\u81ea\u7136\u591a\u8f6e\u5bf9\u8bdd\u5e2e\u52a9\u60a3\u8005\u8bc6\u522b\u75c7\u72b6\u5e76\u63a8\u8350\u9002\u5f53\u7684\u533b\u7597\u79d1\u5ba4\u3002C-PATH\u8fdb\u884c\u4e86\u533b\u7597\u77e5\u8bc6\u3001\u5bf9\u8bdd\u6570\u636e\u548c\u4e34\u5e8a\u6458\u8981\u7684\u5fae\u8c03\uff0c\u5e76\u91c7\u7528\u57fa\u4e8eLLaMA3\u67b6\u6784\u7684\u591a\u9636\u6bb5\u7ba1\u9053\u3002\u8fd8\u4f7f\u7528\u4e86GPT\u7684\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u4e34\u5e8a\u77e5\u8bc6\u8f6c\u53d8\u4e3a\u60a3\u8005\u5bb9\u6613\u7406\u89e3\u7684\u5bf9\u8bdd\uff0c\u5e76\u5b9e\u65bd\u4e86\u53ef\u6269\u5c55\u7684\u5bf9\u8bdd\u5386\u53f2\u7ba1\u7406\u7b56\u7565\u3002", "result": "\u901a\u8fc7GPTScore\u8bc4\u4f30\u663e\u793a\u5728\u6e05\u6670\u5ea6\u3001\u4fe1\u606f\u6027\u548c\u63a8\u8350\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5b9a\u91cf\u57fa\u51c6\u6d4b\u8bd5\u663e\u793aC-PATH\u5728GPT\u91cd\u5199\u7684\u5bf9\u8bdd\u6570\u636e\u96c6\u4e2d\u8d85\u8fc7\u4e86\u7279\u5b9a\u9886\u57df\u57fa\u7ebf\u3002", "conclusion": "C-PATH\u7cfb\u7edf\u5728\u6570\u5b57\u5065\u5eb7\u8f85\u52a9\u548c\u5206\u8bca\u65b9\u9762\u7684\u7528\u6237\u53cb\u597d\u3001\u6613\u8bbf\u95ee\u548c\u51c6\u786e\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2506.06505", "pdf": "https://arxiv.org/pdf/2506.06505", "abs": "https://arxiv.org/abs/2506.06505", "authors": ["Keisuke Sugiura", "Hiroki Matsutani"], "title": "InstantFT: An FPGA-Based Runtime Subsecond Fine-tuning of CNN Models", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Training deep neural networks (DNNs) requires significantly more computation\nand memory than inference, making runtime adaptation of DNNs challenging on\nresource-limited IoT platforms. We propose InstantFT, an FPGA-based method for\nultra-fast CNN fine-tuning on IoT devices, by optimizing the forward and\nbackward computations in parameter-efficient fine-tuning (PEFT). Experiments on\ndatasets with concept drift demonstrate that InstantFT fine-tunes a pre-trained\nCNN 17.4x faster than existing Low-Rank Adaptation (LoRA)-based approaches,\nwhile achieving comparable accuracy. Our FPGA-based InstantFT reduces the\nfine-tuning time to just 0.36s and improves energy-efficiency by 16.3x,\nenabling on-the-fly adaptation of CNNs to non-stationary data distributions.", "AI": {"tldr": "\u57fa\u4e8eFPGA\u7684InstantFT\u65b9\u6cd5\u80fd\u5728\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u5b9e\u73b0\u8d85\u5feb\u901fCNN\u5fae\u8c03\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb17.4\u500d\uff0c\u4e14\u80fd\u6548\u63d0\u9ad816.3\u500d\u3002", "motivation": "\u4e3a\u4e86\u5728\u8d44\u6e90\u6709\u9650\u7684\u7269\u8054\u7f51\u5e73\u53f0\u4e0a\u5b9e\u73b0\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5373\u65f6\u9002\u5e94\uff0c\u514b\u670d\u8bad\u7ec3\u6240\u9700\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3aInstantFT\uff0c\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e2d\u7684\u524d\u5411\u548c\u540e\u5411\u8ba1\u7b97\uff0c\u5b9e\u73b0\u7269\u8054\u7f51\u8bbe\u5907\u4e0a\u7684\u8d85\u5feb\u901fCNN\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cInstantFT\u5728\u6709\u6982\u5ff5\u6f02\u79fb\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u9884\u8bad\u7ec3CNN\u7684\u901f\u5ea6\u6bd4\u73b0\u6709\u7684\u57fa\u4e8e\u4f4e\u79e9\u9002\u5e94\u7684\u65b9\u6cd5\u5feb17.4\u500d\uff0c\u540c\u65f6\u8fbe\u5230\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "InstantFT\u663e\u8457\u51cf\u5c11\u4e86\u5fae\u8c03\u65f6\u95f4\uff0c\u63d0\u9ad8\u4e86\u80fd\u6548\uff0c\u4f7fCNN\u80fd\u591f\u5728\u52a8\u6001\u6570\u636e\u5206\u5e03\u4e0b\u8fdb\u884c\u5b9e\u65f6\u9002\u5e94\u3002"}}
{"id": "2506.06941", "pdf": "https://arxiv.org/pdf/2506.06941", "abs": "https://arxiv.org/abs/2506.06941", "authors": ["Parshin Shojaee", "Iman Mirzadeh", "Keivan Alizadeh", "Maxwell Horton", "Samy Bengio", "Mehrdad Farajtabar"], "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "preprint", "summary": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from contamination and does not provide\ninsights into the reasoning traces. In this work, we systematically investigate\nthese gaps with the help of controllable puzzle environments that allow precise\nmanipulation of complexity while maintaining consistent logical structures.\nThis setup enables the analysis of not only final answers but also the internal\nreasoning traces, offering insights into how LRMs think. Through extensive\nexperiments, we show that LRMs face a complete accuracy collapse beyond certain\ncomplexities. Moreover, they exhibit a counterintuitive scaling limit: their\nreasoning effort increases with problem complexity up to a point, then declines\ndespite having remaining token budget. By comparing LRMs with their standard\nLLM counterparts under same inference compute, we identify three performance\nregimes: (1) low-complexity tasks where standard models outperform LRMs, (2)\nmedium-complexity tasks where LRMs demonstrates advantage, and (3)\nhigh-complexity tasks where both models face complete collapse. We found that\nLRMs have limitations in exact computation: they fail to use explicit\nalgorithms and reason inconsistently across scales. We also investigate the\nreasoning traces in more depth, studying the patterns of explored solutions and\nanalyzing the models' computational behavior, shedding light on their\nstrengths, limitations, and raising questions about their reasoning\ncapabilities.", "AI": {"tldr": "This paper analyzes LRMs' reasoning using puzzle environments, revealing their strengths and limits in different task complexities, and discovers their struggle in maintaining accuracy and consistency at high problem complexities.", "motivation": "The research aims to address the lack of understanding of LRMs' fundamental capabilities, scaling properties, and limitations by investigating their reasoning beyond final answer accuracy.", "method": "The study uses controllable puzzle environments to manipulate problem complexity and analyze both the final answers and the reasoning traces of LRMs, providing insights into their thinking processes.", "result": "Findings show LRMs' complete accuracy collapse at high complexities and a counterintuitive scaling limit, where reasoning effort decreases despite having remaining token budget.", "conclusion": "LRMs have three performance regimes based on task complexity; they outperform standard LLMs only in medium-complexity tasks and struggle with high-complexity tasks, suggesting limitations in reasoning and computation consistency."}}
{"id": "2506.06751", "pdf": "https://arxiv.org/pdf/2506.06751", "abs": "https://arxiv.org/abs/2506.06751", "authors": ["Mikhail Salnikov", "Dmitrii Korzh", "Ivan Lazichny", "Elvir Karimov", "Artyom Iudin", "Ivan Oseledets", "Oleg Y. Rogov", "Alexander Panchenko", "Natalia Loukachevitch", "Elena Tutubalina"], "title": "Geopolitical biases in LLMs: what are the \"good\" and the \"bad\" countries according to contemporary language models", "categories": ["cs.CL"], "comment": null, "summary": "This paper evaluates geopolitical biases in LLMs with respect to various\ncountries though an analysis of their interpretation of historical events with\nconflicting national perspectives (USA, UK, USSR, and China). We introduce a\nnovel dataset with neutral event descriptions and contrasting viewpoints from\ndifferent countries. Our findings show significant geopolitical biases, with\nmodels favoring specific national narratives. Additionally, simple debiasing\nprompts had a limited effect in reducing these biases. Experiments with\nmanipulated participant labels reveal models' sensitivity to attribution,\nsometimes amplifying biases or recognizing inconsistencies, especially with\nswapped labels. This work highlights national narrative biases in LLMs,\nchallenges the effectiveness of simple debiasing methods, and offers a\nframework and dataset for future geopolitical bias research.", "AI": {"tldr": "LLMs show strong geopolitical biases, favoring certain national narratives, and simple debiasing techniques are largely ineffective.", "motivation": "To explore geopolitical biases in large language models (LLMs) concerning different national interpretations of historical events.", "method": "Evaluation was conducted by analyzing LLMs' interpretations of historical events with contradictory national perspectives, utilizing a novel dataset containing neutral event descriptions and contrasting viewpoints from USA, UK, USSR, and China.", "result": "The study revealed significant geopolitical biases, with LLMs showing a preference for specific national narratives. It also found that simple debiasing techniques were insufficient in reducing these biases, and models were sensitive to attribution manipulations, which sometimes increased biases or highlighted inconsistencies.", "conclusion": "LLMs exhibit significant geopolitical biases, favoring specific national narratives. Simple debiasing prompts are not very effective in mitigating these biases."}}
{"id": "2506.06521", "pdf": "https://arxiv.org/pdf/2506.06521", "abs": "https://arxiv.org/abs/2506.06521", "authors": ["Shulun Chen", "Runlong Zhou", "Zihan Zhang", "Maryam Fazel", "Simon S. Du"], "title": "Sharp Gap-Dependent Variance-Aware Regret Bounds for Tabular MDPs", "categories": ["cs.LG", "stat.ML"], "comment": "30 pages", "summary": "We consider the gap-dependent regret bounds for episodic MDPs. We show that\nthe Monotonic Value Propagation (MVP) algorithm achieves a variance-aware\ngap-dependent regret bound of $$\\tilde{O}\\left(\\left(\\sum_{\\Delta_h(s,a)>0}\n\\frac{H^2 \\log K \\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\n+\\sum_{\\Delta_h(s,a)=0}\\frac{ H^2 \\land\n\\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_{\\mathrm{min}}} + SAH^4 (S \\lor H)\n\\right) \\log K\\right),$$ where $H$ is the planning horizon, $S$ is the number\nof states, $A$ is the number of actions, and $K$ is the number of episodes.\nHere, $\\Delta_h(s,a) =V_h^* (a) - Q_h^* (s, a)$ represents the suboptimality\ngap and $\\Delta_{\\mathrm{min}} := \\min_{\\Delta_h (s,a) > 0} \\Delta_h(s,a)$. The\nterm $\\mathtt{Var}_{\\max}^{\\text{c}}$ denotes the maximum conditional total\nvariance, calculated as the maximum over all $(\\pi, h, s)$ tuples of the\nexpected total variance under policy $\\pi$ conditioned on trajectories visiting\nstate $s$ at step $h$. $\\mathtt{Var}_{\\max}^{\\text{c}}$ characterizes the\nmaximum randomness encountered when learning any $(h, s)$ pair. Our result\nstems from a novel analysis of the weighted sum of the suboptimality gap and\ncan be potentially adapted for other algorithms. To complement the study, we\nestablish a lower bound of $$\\Omega \\left( \\sum_{\\Delta_h(s,a)>0} \\frac{H^2\n\\land \\mathtt{Var}_{\\max}^{\\text{c}}}{\\Delta_h(s,a)}\\cdot \\log K\\right),$$\ndemonstrating the necessity of dependence on $\\mathtt{Var}_{\\max}^{\\text{c}}$\neven when the maximum unconditional total variance (without conditioning on\n$(h, s)$) approaches zero.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMVP\u7b97\u6cd5\uff0c\u5206\u6790\u5176\u5728episodic MDP\u4e2d\u5b9e\u73b0\u7684\u65b9\u5dee\u611f\u77e5\u9057\u61be\u754c\uff0c\u53d1\u73b0\u8be5\u754c\u4f9d\u8d56\u4e8e\u6700\u5927\u6761\u4ef6\u603b\u65b9\u5dee\u3002", "motivation": "\u5206\u6790episodic MDP\u4e2d\u4e0e\u95f4\u9699\u76f8\u5173\u7684\u9057\u61be\u754c\uff0c\u7279\u522b\u662f\u5982\u4f55\u901a\u8fc7\u53d8\u5316\u548c\u95f4\u9699\u7684\u7edf\u8ba1\u7279\u6027\u6765\u4f18\u5316\u7b97\u6cd5\u7684\u9057\u61be\u754c\u3002", "method": "\u63d0\u51faMonotonic Value Propagation (MVP)\u7b97\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6b21\u4f18\u95f4\u9699\u7684\u52a0\u6743\u548c\u8fdb\u884c\u65b0\u9896\u5206\u6790\u6765\u83b7\u5f97\u4e0e\u65b9\u5dee\u611f\u77e5\u7684\u95f4\u9699\u76f8\u5173\u7684\u9057\u61be\u754c\u3002", "result": "MVP\u7b97\u6cd5\u5b9e\u73b0\u4e86\u4e00\u79cd\u65b9\u5dee\u611f\u77e5\u7684\u95f4\u9699\u76f8\u5173\u9057\u61be\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u79cd\u754c\u4e0e\u6700\u5927\u6761\u4ef6\u603b\u65b9\u5dee\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u5373\u4f7f\u5728\u6700\u5927\u65e0\u6761\u4ef6\u603b\u65b9\u5dee\u63a5\u8fd1\u96f6\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u5fc5\u987b\u4f9d\u8d56\u6700\u5927\u6761\u4ef6\u603b\u65b9\u5dee\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u4f9d\u8d56\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2506.06959", "pdf": "https://arxiv.org/pdf/2506.06959", "abs": "https://arxiv.org/abs/2506.06959", "authors": ["Alena Makarova", "Houssam Abbas"], "title": "Deontically Constrained Policy Improvement in Reinforcement Learning Agents", "categories": ["cs.AI", "60J10 (Primary), 60J20 (Primary), 60J22 (Primary), 93E20 (Secondary)", "D.2.4; F.3.1; I.2.8"], "comment": "20 pages, 11 figures, DEON2025 conference", "summary": "Markov Decision Processes (MDPs) are the most common model for decision\nmaking under uncertainty in the Machine Learning community. An MDP captures\nnon-determinism, probabilistic uncertainty, and an explicit model of action. A\nReinforcement Learning (RL) agent learns to act in an MDP by maximizing a\nutility function. This paper considers the problem of learning a decision\npolicy that maximizes utility subject to satisfying a constraint expressed in\ndeontic logic. In this setup, the utility captures the agent's mission - such\nas going quickly from A to B. The deontic formula represents (ethical, social,\nsituational) constraints on how the agent might achieve its mission by\nprohibiting classes of behaviors. We use the logic of Expected Act\nUtilitarianism, a probabilistic stit logic that can be interpreted over\ncontrolled MDPs. We develop a variation on policy improvement, and show that it\nreaches a constrained local maximum of the mission utility. Given that in stit\nlogic, an agent's duty is derived from value maximization, this can be seen as\na way of acting to simultaneously maximize two value functions, one of which is\nimplicit, in a bi-level structure. We illustrate these results with experiments\non sample MDPs.", "AI": {"tldr": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u7814\u7a76\u4e86\u5982\u4f55\u5728\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u4e0b\u6700\u5927\u5316\u6548\u7528\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u57fa\u4e8e\u671f\u671b\u884c\u4e3a\u6548\u7528\u4e3b\u4e49\u7684\u7b56\u7565\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u5728\u6ee1\u8db3\u4f26\u7406\u3001\u793e\u4f1a\u6216\u60c5\u5883\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6548\u7528\u6700\u5927\u5316\u3002", "method": "\u5229\u7528\u671f\u671b\u884c\u4e3a\u6548\u7528\u4e3b\u4e49\u7684\u903b\u8f91\u548c\u6982\u7387stit\u903b\u8f91\uff0c\u5728\u53d7\u63a7MDP\u73af\u5883\u4e2d\u8fdb\u884c\u7b56\u7565\u6539\u8fdb\uff0c\u627e\u5230\u6ee1\u8db3\u7ea6\u675f\u7684\u4efb\u52a1\u6548\u7528\u5c40\u90e8\u6700\u5927\u503c\u3002", "result": "\u901a\u8fc7\u5728\u6837\u672cMDPs\u4e0a\u7684\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u65e2\u5b9a\u7ea6\u675f\u4e0b\u4f18\u5316\u7b56\u7565\u5e76\u5b9e\u73b0\u4efb\u52a1\u6548\u7528\u6700\u5927\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u52a8\u4f5c\u9009\u62e9\u65f6\uff0c\u517c\u987e\u5b9e\u73b0\u65e2\u5b9a\u76ee\u6807\u5e76\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u6761\u4ef6\u3002"}}
{"id": "2506.06775", "pdf": "https://arxiv.org/pdf/2506.06775", "abs": "https://arxiv.org/abs/2506.06775", "authors": ["Walter Paci", "Alessandro Panunzi", "Sandro Pezzelle"], "title": "They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse", "categories": ["cs.CL"], "comment": "Accepted to the ACL2025 Findings", "summary": "Implicit content plays a crucial role in political discourse, where speakers\nsystematically employ pragmatic strategies such as implicatures and\npresuppositions to influence their audiences. Large Language Models (LLMs) have\ndemonstrated strong performance in tasks requiring complex semantic and\npragmatic understanding, highlighting their potential for detecting and\nexplaining the meaning of implicit content. However, their ability to do this\nwithin political discourse remains largely underexplored. Leveraging, for the\nfirst time, the large IMPAQTS corpus, which comprises Italian political\nspeeches with the annotation of manipulative implicit content, we propose\nmethods to test the effectiveness of LLMs in this challenging problem. Through\na multiple-choice task and an open-ended generation task, we demonstrate that\nall tested models struggle to interpret presuppositions and implicatures. We\nconclude that current LLMs lack the key pragmatic capabilities necessary for\naccurately interpreting highly implicit language, such as that found in\npolitical discourse. At the same time, we highlight promising trends and future\ndirections for enhancing model performance. We release our data and code at\nhttps://github.com/WalterPaci/IMPAQTS-PID", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u548c\u89e3\u91ca\u653f\u6cbb\u8bdd\u8bed\u4e2d\u7684\u9690\u542b\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u653f\u6cbb\u8bdd\u8bed\u4e2d\u7684\u9690\u542b\u5185\u5bb9\u68c0\u6d4b\u548c\u89e3\u91ca\u80fd\u529b\uff0c\u56e0\u4e3a\u8fd9\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5229\u7528IMPAQTS\u8bed\u6599\u5e93\u8fdb\u884c\u591a\u9879\u9009\u62e9\u4efb\u52a1\u548c\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\uff0c\u68c0\u9a8cLLMs\u5728\u89e3\u91ca\u542b\u84c4\u8bed\u8a00\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6240\u6709\u6d4b\u8bd5\u7684\u6a21\u578b\u5728\u89e3\u91ca\u9884\u8bbe\u548c\u542b\u84c4\u5185\u5bb9\u4e0a\u5747\u8868\u73b0\u4e0d\u4f73\uff0c\u663e\u793a\u51fa\u5f53\u524dLLMs\u5728\u5904\u7406\u590d\u6742\u9690\u542b\u8bed\u8a00\u65f6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u51c6\u786e\u89e3\u91ca\u9ad8\u5ea6\u9690\u542b\u8bed\u8a00\uff08\u5982\u653f\u6cbb\u8bdd\u8bed\uff09\u6240\u9700\u7684\u5173\u952e\u8bed\u7528\u80fd\u529b\u3002"}}
{"id": "2506.06532", "pdf": "https://arxiv.org/pdf/2506.06532", "abs": "https://arxiv.org/abs/2506.06532", "authors": ["Zijiang Yan", "Hao Zhou", "Jianhua Pei", "Hina Tabassum"], "title": "Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks", "categories": ["cs.LG", "cs.AI", "cs.NI", "cs.RO", "cs.SY", "eess.SY"], "comment": "Accepted in ICML 2025 Workshop on Machine Learning for Wireless\n  Communication and Networks (ML4Wireless)", "summary": "Unmanned aerial vehicles (UAVs) have been widely adopted in various\nreal-world applications. However, the control and optimization of multi-UAV\nsystems remain a significant challenge, particularly in dynamic and constrained\nenvironments. This work explores the joint motion and communication control of\nmultiple UAVs operating within integrated terrestrial and non-terrestrial\nnetworks that include high-altitude platform stations (HAPS). Specifically, we\nconsider an aerial highway scenario in which UAVs must accelerate, decelerate,\nand change lanes to avoid collisions and maintain overall traffic flow.\nDifferent from existing studies, we propose a novel hierarchical and\ncollaborative method based on large language models (LLMs). In our approach, an\nLLM deployed on the HAPS performs UAV access control, while another LLM onboard\neach UAV handles motion planning and control. This LLM-based framework\nleverages the rich knowledge embedded in pre-trained models to enable both\nhigh-level strategic planning and low-level tactical decisions. This\nknowledge-driven paradigm holds great potential for the development of\nnext-generation 3D aerial highway systems. Experimental results demonstrate\nthat our proposed collaborative LLM-based method achieves higher system\nrewards, lower operational costs, and significantly reduced UAV collision rates\ncompared to baseline approaches.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e8c\u7ef4\u548c\u4e09\u7ef4\u7f51\u7edc\u4e2d\u591a\u65e0\u4eba\u673a\u7684\u8fd0\u52a8\u548c\u901a\u4fe1\u63a7\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5206\u5c42\u534f\u4f5c\u63a7\u5236\u3002", "motivation": "\u5728\u52a8\u6001\u7ea6\u675f\u73af\u5883\u4e2d\u4f18\u5316\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u63a7\u5236\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5c42\u534f\u4f5c\u63a7\u5236\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cfb\u7edf\u5956\u52b1\uff0c\u66f4\u4f4e\u7684\u8fd0\u884c\u6210\u672c\uff0c\u4ee5\u53ca\u663e\u8457\u964d\u4f4e\u7684\u65e0\u4eba\u673a\u78b0\u649e\u7387\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u534f\u4f5c\u65b9\u6cd5\u5728\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u4e2d\u5c55\u73b0\u51fa\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2506.06965", "pdf": "https://arxiv.org/pdf/2506.06965", "abs": "https://arxiv.org/abs/2506.06965", "authors": ["Cuong Manh Hoang"], "title": "Long-Tailed Learning for Generalized Category Discovery", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Generalized Category Discovery (GCD) utilizes labeled samples of known\nclasses to discover novel classes in unlabeled samples. Existing methods show\neffective performance on artificial datasets with balanced distributions.\nHowever, real-world datasets are always imbalanced, significantly affecting the\neffectiveness of these methods. To solve this problem, we propose a novel\nframework that performs generalized category discovery in long-tailed\ndistributions. We first present a self-guided labeling technique that uses a\nlearnable distribution to generate pseudo-labels, resulting in less biased\nclassifiers. We then introduce a representation balancing process to derive\ndiscriminative representations. By mining sample neighborhoods, this process\nencourages the model to focus more on tail classes. We conduct experiments on\npublic datasets to demonstrate the effectiveness of the proposed framework. The\nresults show that our model exceeds previous state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5904\u7406\u957f\u5c3e\u5206\u5e03\u7684\u65b0\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u5bfc\u6807\u6ce8\u548c\u8868\u793a\u5e73\u8861\u6280\u672f\uff0c\u63d0\u5347\u4e86\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0\u65b9\u6cd5\u5728\u7c7b\u5e73\u8861\u7684\u4eba\u5de5\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\uff0c\u7531\u4e8e\u6570\u636e\u96c6\u7684\u957f\u5c3e\u5206\u5e03\uff0c\u8868\u73b0\u53d7\u5230\u663e\u8457\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u9996\u5148\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u5206\u5e03\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u51cf\u5c11\u5206\u7c7b\u5668\u504f\u5dee\uff0c\u7136\u540e\u901a\u8fc7\u91c7\u6837\u90bb\u57df\u52a0\u5f3a\u5c3e\u7c7b\u805a\u7126\u3002", "result": "\u5728\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u5728\u5904\u7406\u957f\u5c3e\u5206\u5e03\u65f6\u6709\u6548\uff0c\u53ef\u4ee5\u5728\u672a\u6807\u8bb0\u6837\u672c\u4e2d\u53d1\u73b0\u65b0\u7684\u7c7b\u522b\u3002"}}
{"id": "2506.06785", "pdf": "https://arxiv.org/pdf/2506.06785", "abs": "https://arxiv.org/abs/2506.06785", "authors": ["Hiram Ring"], "title": "Extending dependencies to the taggedPBC: Word order in transitive clauses", "categories": ["cs.CL"], "comment": null, "summary": "The taggedPBC (Ring 2025a) contains more than 1,800 sentences of pos-tagged\nparallel text data from over 1,500 languages, representing 133 language\nfamilies and 111 isolates. While this dwarfs previously available resources,\nand the POS tags achieve decent accuracy, allowing for predictive\ncrosslinguistic insights (Ring 2025b), the dataset was not initially annotated\nfor dependencies. This paper reports on a CoNLLU-formatted version of the\ndataset which transfers dependency information along with POS tags to all\nlanguages in the taggedPBC. Although there are various concerns regarding the\nquality of the tags and the dependencies, word order information derived from\nthis dataset regarding the position of arguments and predicates in transitive\nclauses correlates with expert determinations of word order in three\ntypological databases (WALS, Grambank, Autotyp). This highlights the usefulness\nof corpus-based typological approaches (as per Baylor et al. 2023; Bjerva 2024)\nfor extending comparisons of discrete linguistic categories, and suggests that\nimportant insights can be gained even from noisy data, given sufficient\nannotation. The dependency-annotated corpora are also made available for\nresearch and collaboration via GitHub.", "AI": {"tldr": "A CoNLLU-formatted version of taggedPBC is created to include dependency information, enhancing its use for typological linguistic studies.", "motivation": "To enhance the taggedPBC dataset by adding dependency annotations in order to gain more predictive crosslinguistic insights and improve the utility of the dataset for typological studies.", "method": "The method involves converting the taggedPBC dataset into a CoNLLU-formatted version, transferring dependency information along with POS tags for all languages.", "result": "Word order information derived from the enhanced dataset correlates with expert determinations in three major typological databases, validating the approach despite concerns over data quality.", "conclusion": "This study demonstrates the utility of corpus-based typological approaches for linguistic category comparison, indicating that valuable insights can be obtained from noisy data if adequately annotated."}}
{"id": "2506.06549", "pdf": "https://arxiv.org/pdf/2506.06549", "abs": "https://arxiv.org/abs/2506.06549", "authors": ["Atefeh Gilani", "Naima Tasnim", "Lalitha Sankar", "Oliver Kosut"], "title": "GeoClip: Geometry-Aware Clipping for Differentially Private SGD", "categories": ["cs.LG", "cs.CR", "cs.IT", "math.IT"], "comment": null, "summary": "Differentially private stochastic gradient descent (DP-SGD) is the most\nwidely used method for training machine learning models with provable privacy\nguarantees. A key challenge in DP-SGD is setting the per-sample gradient\nclipping threshold, which significantly affects the trade-off between privacy\nand utility. While recent adaptive methods improve performance by adjusting\nthis threshold during training, they operate in the standard coordinate system\nand fail to account for correlations across the coordinates of the gradient. We\npropose GeoClip, a geometry-aware framework that clips and perturbs gradients\nin a transformed basis aligned with the geometry of the gradient distribution.\nGeoClip adaptively estimates this transformation using only previously released\nnoisy gradients, incurring no additional privacy cost. We provide convergence\nguarantees for GeoClip and derive a closed-form solution for the optimal\ntransformation that minimizes the amount of noise added while keeping the\nprobability of gradient clipping under control. Experiments on both tabular and\nimage datasets demonstrate that GeoClip consistently outperforms existing\nadaptive clipping methods under the same privacy budget.", "AI": {"tldr": "GeoClip is a geometry-aware method for DP-SGD that improves performance by adaptively estimating gradient transformations, reducing noise and enhancing privacy-utility balance.", "motivation": "The motivation is to address the challenge of setting the per-sample gradient clipping threshold in DP-SGD, which affects the privacy-utility trade-off and to improve on existing methods that fail to account for correlations across gradient coordinates.", "method": "GeoClip adapts a geometry-aware framework that clips and perturbs gradients in a transformed basis aligned with the geometry of the gradient distribution, using previously released noisy gradients to estimate the transformation without incurring additional privacy costs.", "result": "GeoClip provides convergence guarantees and a closed-form solution for the optimal transformation, minimizing noise addition while controlling gradient clipping probability, as demonstrated through experiments on tabular and image datasets.", "conclusion": "GeoClip consistently outperforms existing adaptive clipping methods under the same privacy budget."}}
{"id": "2506.06981", "pdf": "https://arxiv.org/pdf/2506.06981", "abs": "https://arxiv.org/abs/2506.06981", "authors": ["Riley Simmons-Edler", "Ryan P. Badman", "Felix Baastad Berg", "Raymond Chua", "John J. Vastola", "Joshua Lunger", "William Qian", "Kanaka Rajan"], "title": "Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Understanding the behavior of deep reinforcement learning (DRL) agents --\nparticularly as task and agent sophistication increase -- requires more than\nsimple comparison of reward curves, yet standard methods for behavioral\nanalysis remain underdeveloped in DRL. We apply tools from neuroscience and\nethology to study DRL agents in a novel, complex, partially observable\nenvironment, ForageWorld, designed to capture key aspects of real-world animal\nforaging -- including sparse, depleting resource patches, predator threats, and\nspatially extended arenas. We use this environment as a platform for applying\njoint behavioral and neural analysis to agents, revealing detailed,\nquantitatively grounded insights into agent strategies, memory, and planning.\nContrary to common assumptions, we find that model-free RNN-based DRL agents\ncan exhibit structured, planning-like behavior purely through emergent dynamics\n-- without requiring explicit memory modules or world models. Our results show\nthat studying DRL agents like animals -- analyzing them with\nneuroethology-inspired tools that reveal structure in both behavior and neural\ndynamics -- uncovers rich structure in their learning dynamics that would\notherwise remain invisible. We distill these tools into a general analysis\nframework linking core behavioral and representational features to diagnostic\nmethods, which can be reused for a wide range of tasks and agents. As agents\ngrow more complex and autonomous, bridging neuroscience, cognitive science, and\nAI will be essential -- not just for understanding their behavior, but for\nensuring safe alignment and maximizing desirable behaviors that are hard to\nmeasure via reward. We show how this can be done by drawing on lessons from how\nbiological intelligence is studied.", "AI": {"tldr": "\u501f\u52a9\u795e\u7ecf\u751f\u7269\u5b66\u5de5\u5177\uff0c\u7814\u7a76\u63ed\u793aDRL\u4ee3\u7406\u7684\u590d\u6742\u884c\u4e3a\u6a21\u5f0f\uff0c\u5c55\u793a\u5728\u786e\u4fdd\u667a\u80fd\u4f53\u884c\u4e3a\u5b89\u5168\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u884c\u4e3a\u5206\u6790\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u7406\u89e3\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u590d\u6742\u884c\u4e3a\u6a21\u5f0f\uff0c\u9700\u8981\u5f15\u5165\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u5c06\u795e\u7ecf\u79d1\u5b66\u548c\u52a8\u7269\u884c\u4e3a\u5b66\u5e94\u7528\u4e8e\u590d\u6742\u7684\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u60c5\u5883\u4e2d\uff0c\u5bf9DRL\u4ee3\u7406\u8fdb\u884c\u8054\u5408\u884c\u4e3a\u548c\u795e\u7ecf\u5206\u6790\u3002", "result": "\u53d1\u73b0\u65e0\u6a21\u578b\u7684RNN\u57fa\u7840\u7684DRL\u4ee3\u7406\u80fd\u591f\u5c55\u73b0\u51fa\u7ed3\u6784\u5316\u7684\u3001\u7c7b\u4f3c\u8ba1\u5212\u7684\u884c\u4e3a\uff0c\u800c\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u8bb0\u5fc6\u6a21\u5757\u6216\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u4f7f\u7528\u795e\u7ecf\u751f\u7269\u5b66\u548c\u52a8\u7269\u884c\u4e3a\u5b66\u7684\u5de5\u5177\u53ef\u4ee5\u63ed\u793aDRL\u4ee3\u7406\u7684\u8be6\u7ec6\u884c\u4e3a\u6a21\u5f0f\u548c\u795e\u7ecf\u52a8\u529b\u5b66\u7ed3\u6784\uff0c\u800c\u8fd9\u4e9b\u5728\u4f20\u7edf\u65b9\u6cd5\u4e0b\u53ef\u80fd\u4e0d\u6613\u89c2\u5bdf\u5230\u3002"}}
{"id": "2506.06800", "pdf": "https://arxiv.org/pdf/2506.06800", "abs": "https://arxiv.org/abs/2506.06800", "authors": ["Tianjie Ju", "Yujia Chen", "Hao Fei", "Mong-Li Lee", "Wynne Hsu", "Pengzhou Cheng", "Zongru Wu", "Zhuosheng Zhang", "Gongshen Liu"], "title": "On the Adaptive Psychological Persuasion of Large Language Models", "categories": ["cs.CL"], "comment": "Working in progress", "summary": "Previous work has showcased the intriguing capabilities of Large Language\nModels (LLMs) in instruction-following and rhetorical fluency. However,\nsystematic exploration of their dual capabilities to autonomously persuade and\nresist persuasion, particularly in contexts involving psychological rhetoric,\nremains unexplored. In this paper, we first evaluate four commonly adopted LLMs\nby tasking them to alternately act as persuaders and listeners in adversarial\ndialogues. Empirical results show that persuader LLMs predominantly employ\nrepetitive strategies, leading to low success rates. Then we introduce eleven\ncomprehensive psychological persuasion strategies, finding that explicitly\ninstructing LLMs to adopt specific strategies such as Fluency Effect and\nRepetition Effect significantly improves persuasion success rates. However, no\n``one-size-fits-all'' strategy proves universally effective, with performance\nheavily dependent on contextual counterfactuals. Motivated by these\nobservations, we propose an adaptive framework based on direct preference\noptimization that trains LLMs to autonomously select optimal strategies by\nleveraging persuasion results from strategy-specific responses as preference\npairs. Experiments on three open-source LLMs confirm that the proposed adaptive\npsychological persuasion method effectively enables persuader LLMs to select\noptimal strategies, significantly enhancing their success rates while\nmaintaining general capabilities. Our code is available at\nhttps://github.com/KalinaEine/PsychologicalPersuasion.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5fc3\u7406\u8bf4\u670d\u7b56\u7565\u663e\u8457\u63d0\u9ad8LLMs\u7684\u6210\u529f\u7387\u3002", "motivation": "\u8bc4\u4f30\u56db\u79cd\u5e38\u7528LLMs\u5e76\u89c2\u5bdf\u5176\u5728\u8bf4\u670d\u6210\u529f\u7387\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5bfb\u627e\u63d0\u9ad8\u8bf4\u670d\u6210\u529f\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u7b56\u7565\u7279\u5b9a\u54cd\u5e94\u4e2d\u7684\u8bf4\u670d\u7ed3\u679c\u4f5c\u4e3a\u504f\u597d\u5bf9\u6765\u8bad\u7ec3LLMs\u81ea\u4e3b\u9009\u62e9\u6700\u4f73\u7b56\u7565\u3002", "result": "\u81ea\u9002\u5e94\u5fc3\u7406\u8bf4\u670d\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u8bf4\u670d\u8005LLMs\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u4e00\u822c\u80fd\u529b\u3002\u5b9e\u9a8c\u5df2\u5728\u4e09\u4e2a\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u81ea\u9002\u5e94\u6846\u67b6\u4f7f\u8bf4\u670d\u8005LLMs\u80fd\u591f\u6709\u6548\u5730\u9009\u62e9\u6700\u4f73\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u4e00\u822c\u80fd\u529b\u3002"}}
{"id": "2506.06556", "pdf": "https://arxiv.org/pdf/2506.06556", "abs": "https://arxiv.org/abs/2506.06556", "authors": ["Long Dang", "Thushari Hapuarachchi", "Kaiqi Xiong", "Yi Li"], "title": "SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks", "categories": ["cs.LG", "cs.CR"], "comment": "The 34th International Conference on Computer Communications and\n  Networks (ICCCN 2025)", "summary": "As the development of autonomous and connected vehicles advances, the\ncomplexity of modern vehicles increases, with numerous Electronic Control Units\n(ECUs) integrated into the system. In an in-vehicle network, these ECUs\ncommunicate with one another using an standard protocol called Controller Area\nNetwork (CAN). Securing communication among ECUs plays a vital role in\nmaintaining the safety and security of the vehicle. This paper proposes a\nrobust SDN-based False Data Detection and Mitigation System (FDDMS) for\nin-vehicle networks. Leveraging the unique capabilities of Software-Defined\nNetworking (SDN), FDDMS is designed to monitor and detect false data injection\nattacks in real-time. Specifically, we focus on brake-related ECUs within an\nSDN-enabled in-vehicle network. First, we decode raw CAN data to create an\nattack model that illustrates how false data can be injected into the system.\nThen, FDDMS, incorporating a Long Short Term Memory (LSTM)-based detection\nmodel, is used to identify false data injection attacks. We further propose an\neffective variant of DeepFool attack to evaluate the model's robustness. To\ncountermeasure the impacts of four adversarial attacks including Fast gradient\ndescent method, Basic iterative method, DeepFool, and the DeepFool variant, we\nfurther enhance a re-training technique method with a threshold based selection\nstrategy. Finally, a mitigation scheme is implemented to redirect attack\ntraffic by dynamically updating flow rules through SDN. Our experimental\nresults show that the proposed FDDMS is robust against adversarial attacks and\neffectively detects and mitigates false data injection attacks in real-time.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSDN\u7684\u5f3a\u5065\u865a\u5047\u6570\u636e\u68c0\u6d4b\u548c\u7f13\u89e3\u7cfb\u7edf\uff08FDDMS\uff09\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u8f66\u8f7d\u7f51\u7edc\u4e2d\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u548c\u8054\u7f51\u8f66\u8f86\u7684\u53d1\u5c55\uff0c\u8f66\u8f7d\u7f51\u7edc\u4e2d\u7535\u5b50\u63a7\u5236\u5355\u5143\uff08ECU\uff09\u7684\u65e5\u76ca\u590d\u6742\uff0c\u786e\u4fddECU\u4e4b\u95f4\u901a\u4fe1\u7684\u5b89\u5168\u5728\u7ef4\u62a4\u8f66\u8f86\u7684\u5b89\u5168\u6027\u548c\u5b89\u4fdd\u4e0a\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u8f6f\u4ef6\u5b9a\u4e49\u7f51\u7edc\uff08SDN\uff09\u7684\u80fd\u529b\uff0c\u8bbe\u8ba1\u4e86FDDMS\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86\u57fa\u4e8e\u957f\u77ed\u671f\u8bb0\u5fc6\uff08LSTM\uff09\u7684\u68c0\u6d4b\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u53d8\u4f53\u7684DeepFool\u653b\u51fb\u8bc4\u4f30\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\u540c\u65f6\uff0c\u91c7\u7528\u91cd\u65b0\u8bad\u7ec3\u6280\u672f\u65b9\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u9608\u503c\u7684\u9009\u62e9\u7b56\u7565\uff0c\u5e76\u5b9e\u65bd\u4e86\u4e00\u79cd\u7f13\u89e3\u65b9\u6848\uff0c\u901a\u8fc7SDN\u52a8\u6001\u66f4\u65b0\u6d41\u89c4\u5219\u6765\u91cd\u5b9a\u5411\u653b\u51fb\u6d41\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFDDMS\u7cfb\u7edf\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u5b9e\u65f6\u6709\u6548\u5730\u68c0\u6d4b\u548c\u7f13\u89e3\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\u3002", "conclusion": "FDDMS\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u5b9e\u65f6\u7684\u865a\u5047\u6570\u636e\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u5176\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.06991", "pdf": "https://arxiv.org/pdf/2506.06991", "abs": "https://arxiv.org/abs/2506.06991", "authors": ["Yichi Zhang", "Jinlong Pang", "Zhaowei Zhu", "Yang Liu"], "title": "Evaluating LLM-corrupted Crowdsourcing Data Without Ground Truth", "categories": ["cs.AI", "cs.GT", "cs.HC"], "comment": "33 pages, 9 figures", "summary": "The recent success of generative AI highlights the crucial role of\nhigh-quality human feedback in building trustworthy AI systems. However, the\nincreasing use of large language models (LLMs) by crowdsourcing workers poses a\nsignificant challenge: datasets intended to reflect human input may be\ncompromised by LLM-generated responses. Existing LLM detection approaches often\nrely on high-dimension training data such as text, making them unsuitable for\nannotation tasks like multiple-choice labeling. In this work, we investigate\nthe potential of peer prediction -- a mechanism that evaluates the information\nwithin workers' responses without using ground truth -- to mitigate\nLLM-assisted cheating in crowdsourcing with a focus on annotation tasks. Our\napproach quantifies the correlations between worker answers while conditioning\non (a subset of) LLM-generated labels available to the requester. Building on\nprior research, we propose a training-free scoring mechanism with theoretical\nguarantees under a crowdsourcing model that accounts for LLM collusion. We\nestablish conditions under which our method is effective and empirically\ndemonstrate its robustness in detecting low-effort cheating on real-world\ncrowdsourcing datasets.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u68c0\u6d4b\u4f17\u5305\u4efb\u52a1\u4e2dLLM\u8f85\u52a9\u4f5c\u5f0a\u7684\u8bc4\u5206\u673a\u5236\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u4f4e\u52aa\u529b\u6b3a\u9a97\u68c0\u6d4b\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f AI \u7684\u6210\u529f\uff0c\u786e\u4fdd\u6570\u636e\u96c6\u4e2d\u4eba\u7c7b\u8f93\u5165\u7684\u8d28\u91cf\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u800cLLM\u7684\u5e7f\u6cdb\u4f7f\u7528\u53ef\u80fd\u4f1a\u5f71\u54cd\u6570\u636e\u7684\u771f\u5b9e\u6027\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u4e86\u4e00\u79cd\u65e0\u8bad\u7ec3\u8bc4\u5206\u673a\u5236\uff0c\u901a\u8fc7\u5206\u6790\u5de5\u4eba\u56de\u7b54\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5e76\u7ed3\u5408\u8bf7\u6c42\u8005\u53ef\u7528\u7684\u90e8\u5206LLM\u751f\u6210\u6807\u7b7e\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u8bc1\u4e0a\u8bc1\u660e\u4e86\u5176\u5728\u68c0\u6d4b\u4f4e\u52aa\u529b\u6b3a\u9a97\u65b9\u9762\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4f17\u5305\u4efb\u52a1\u4e2d\u68c0\u6d4bLLM\u8f85\u52a9\u4f5c\u5f0a\u7684\u673a\u5236\uff0c\u5e76\u8bc1\u660e\u8fd9\u79cd\u65b9\u6cd5\u5728\u68c0\u6d4b\u4f4e\u52aa\u529b\u6b3a\u9a97\u65f6\u662f\u6709\u6548\u548c\u53ef\u9760\u7684\u3002"}}
{"id": "2506.06806", "pdf": "https://arxiv.org/pdf/2506.06806", "abs": "https://arxiv.org/abs/2506.06806", "authors": ["Subhendu Khatuya", "Shashwat Naidu", "Saptarshi Ghosh", "Pawan Goyal", "Niloy Ganguly"], "title": "Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This work has been accepted to appear at the Association for\n  Computational Linguistics (ACL), 2025", "summary": "The explosion of textual data has made manual document classification\nincreasingly challenging. To address this, we introduce a robust, efficient\ndomain-agnostic generative model framework for multi-label text classification.\nInstead of treating labels as mere atomic symbols, our approach utilizes\npredefined label descriptions and is trained to generate these descriptions\nbased on the input text. During inference, the generated descriptions are\nmatched to the pre-defined labels using a finetuned sentence transformer. We\nintegrate this with a dual-objective loss function, combining cross-entropy\nloss and cosine similarity of the generated sentences with the predefined\ntarget descriptions, ensuring both semantic alignment and accuracy. Our\nproposed model LAGAMC stands out for its parameter efficiency and versatility\nacross diverse datasets, making it well-suited for practical applications. We\ndemonstrate the effectiveness of our proposed model by achieving new\nstate-of-the-art performances across all evaluated datasets, surpassing several\nstrong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in\nMacro-F1 compared to the closest baseline across all datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u6a21\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u6587\u672c\u63cf\u8ff0\u8fdb\u884c\u591a\u6807\u7b7e\u5206\u7c7b\uff0c\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u6587\u672c\u6570\u636e\u7206\u70b8\u6027\u589e\u957f\u4f7f\u5f97\u624b\u52a8\u6587\u6863\u5206\u7c7b\u6108\u53d1\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u5206\u7c7b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u7684\u751f\u6210\u6a21\u578b\u6846\u67b6\uff0c\u5229\u7528\u9884\u5b9a\u4e49\u7684\u6807\u7b7e\u63cf\u8ff0\u5e76\u901a\u8fc7\u8f93\u5165\u6587\u672c\u751f\u6210\u8fd9\u4e9b\u63cf\u8ff0\uff0c\u7136\u540e\u901a\u8fc7\u5fae\u8c03\u7684\u53e5\u5b50\u8f6c\u6362\u5668\u5c06\u751f\u6210\u7684\u63cf\u8ff0\u4e0e\u9884\u5b9a\u4e49\u6807\u7b7e\u5339\u914d\uff0c\u7ed3\u5408\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u53cc\u76ee\u6807\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728\u6240\u6709\u8bc4\u4f30\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0cMicro-F1\u63d0\u534713.94%\uff0cMacro-F1\u63d0\u534724.85%\u3002", "conclusion": "LAGAMC\u6a21\u578b\u53c2\u6570\u9ad8\u6548\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u6570\u636e\u96c6\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5728\u5404\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u591a\u4e2a\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2506.06558", "pdf": "https://arxiv.org/pdf/2506.06558", "abs": "https://arxiv.org/abs/2506.06558", "authors": ["Atamert Rahma", "Chinmay Datar", "Ana Cukarska", "Felix Dietrich"], "title": "Rapid training of Hamiltonian graph networks without gradient descent", "categories": ["cs.LG", "cs.NE", "68T07", "I.2.6"], "comment": "10 pages, 7 figures, 2 tables, and an appendix", "summary": "Learning dynamical systems that respect physical symmetries and constraints\nremains a fundamental challenge in data-driven modeling. Integrating physical\nlaws with graph neural networks facilitates principled modeling of complex\nN-body dynamics and yields accurate and permutation-invariant models. However,\ntraining graph neural networks with iterative, gradient-based optimization\nalgorithms (e.g., Adam, RMSProp, LBFGS) often leads to slow training,\nespecially for large, complex systems. In comparison to 15 different\noptimizers, we demonstrate that Hamiltonian Graph Networks (HGN) can be trained\nup to 600x faster--but with comparable accuracy--by replacing iterative\noptimization with random feature-based parameter construction. We show robust\nperformance in diverse simulations, including N-body mass-spring systems in up\nto 3 dimensions with different geometries, while retaining essential physical\ninvariances with respect to permutation, rotation, and translation. We reveal\nthat even when trained on minimal 8-node systems, the model can generalize in a\nzero-shot manner to systems as large as 4096 nodes without retraining. Our work\nchallenges the dominance of iterative gradient-descent-based optimization\nalgorithms for training neural network models for physical systems.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u968f\u673a\u7279\u5f81\u7528\u4e8e\u53c2\u6570\u6784\u9020\u800c\u975e\u4f20\u7edf\u7684\u8fed\u4ee3\u4f18\u5316\uff0cHGN\u6a21\u578b\u5728\u8bad\u7ec3\u901f\u5ea6\u4e0a\u63d0\u9ad8\u4e86600\u500d\uff0c\u4e14\u4fdd\u6301\u4e86\u7c7b\u4f3c\u7684\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u4ece\u5c0f\u7cfb\u7edf\u6cdb\u5316\u5230\u66f4\u5927\u7684\u7cfb\u7edf\u3002", "motivation": "\u5b66\u4e60\u5c0a\u91cd\u7269\u7406\u5bf9\u79f0\u6027\u548c\u7ea6\u675f\u7684\u52a8\u6001\u7cfb\u7edf\u5728\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u4e2d\u4ecd\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002\u901a\u8fc7\u96c6\u6210\u7269\u7406\u5b9a\u5f8b\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5efa\u6a21\u590d\u6742\u7684N\u4f53\u52a8\u529b\u5b66\uff0c\u5e76\u4ea7\u751f\u51c6\u786e\u4e14\u6392\u5217\u4e0d\u53d8\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528Hamiltonian Graph Networks (HGN)\u66ff\u4ee3\u8fed\u4ee3\u4f18\u5316\uff0c\u901a\u8fc7\u968f\u673a\u7279\u5f81\u53c2\u6570\u6784\u9020\u6765\u52a0\u901f\u8bad\u7ec3\u3002", "result": "\u5373\u4fbf\u5728\u6700\u5c0f\u503c\u76848\u8282\u70b9\u7cfb\u7edf\u4e0a\u8bad\u7ec3\uff0c\u8be5\u6a21\u578b\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee5\u96f6\u6b21\u6cdb\u5316\u7684\u65b9\u5f0f\u63a8\u5e7f\u5230\u591a\u8fbe4096\u4e2a\u8282\u70b9\u7684\u7cfb\u7edf\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u6311\u6218\u4e86\u57fa\u4e8e\u8fed\u4ee3\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u7b97\u6cd5\u5728\u7269\u7406\u7cfb\u7edf\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2506.07047", "pdf": "https://arxiv.org/pdf/2506.07047", "abs": "https://arxiv.org/abs/2506.07047", "authors": ["Yu Xuejun", "Jianyuan Zhong", "Zijin Feng", "Pengyi Zhai", "Roozbeh Yousefzadeh", "Wei Chong Ng", "Haoxiong Liu", "Ziyi Shou", "Jing Xiong", "Yudong Zhou", "Claudia Beth Ong", "Austen Jeremy Sugiarto", "Yaoxi Zhang", "Wai Ming Tai", "Huan Cao", "Dongcai Lu", "Jiacheng Sun", "Qiang Xu", "Shen Xin", "Zhenguo Li"], "title": "Mathesis: Towards Formal Theorem Proving from Natural Languages", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models show strong promise for formal\nreasoning. However, most LLM-based theorem provers have long been constrained\nby the need for expert-written formal statements as inputs, limiting their\napplicability to real-world problems expressed in natural language. We tackle\nthis gap with Mathesis, the first end-to-end theorem proving pipeline\nprocessing informal problem statements. It contributes Mathesis-Autoformalizer,\nthe first autoformalizer using reinforcement learning to enhance the\nformalization ability of natural language problems, aided by our novel\nLeanScorer framework for nuanced formalization quality assessment. It also\nproposes a Mathesis-Prover, which generates formal proofs from the formalized\nstatements. To evaluate the real-world applicability of end-to-end formal\ntheorem proving, we introduce Gaokao-Formal, a benchmark of 488 complex\nproblems from China's national college entrance exam. Our approach is carefully\ndesigned, with a thorough study of each component. Experiments demonstrate\nMathesis's effectiveness, with the autoformalizer outperforming the best\nbaseline by 22% in pass-rate on Gaokao-Formal. The full system surpasses other\nmodel combinations, achieving 64% accuracy on MiniF2F with pass@32 and a\nstate-of-the-art 18% on Gaokao-Formal.", "AI": {"tldr": "Mathesis advances theorem proving by processing informal statements, introducing an autoformalizer and prover, achieving high performance on new benchmarks.", "motivation": "To overcome limitations of LLM-based theorem provers which require expert-written formal statements as inputs, hindering real-world applicability.", "method": "Mathesis introduces an autoformalizer using reinforcement learning to improve formalization of natural language problems and a prover to generate formal proofs, supported by LeanScorer for quality assessment.", "result": "Mathesis's autoformalizer surpasses the best baseline by 22% in pass-rate on Gaokao-Formal, with the full system achieving 64% accuracy on MiniF2F and 18% on Gaokao-Formal.", "conclusion": "Mathesis demonstrates significant advancements in end-to-end formal theorem proving from informal problem statements, showing state-of-the-art performance on challenging benchmarks."}}
{"id": "2506.06808", "pdf": "https://arxiv.org/pdf/2506.06808", "abs": "https://arxiv.org/abs/2506.06808", "authors": ["James A. Michaelov", "Reeka Estacio", "Zhien Zhang", "Benjamin K. Bergen"], "title": "Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Findings of ACL 2025", "summary": "Can language models reliably predict that possible events are more likely\nthan merely improbable ones? By teasing apart possibility, typicality, and\ncontextual relatedness, we show that despite the results of previous work,\nlanguage models' ability to do this is far from robust. In fact, under certain\nconditions, all models tested - including Llama 3, Gemma 2, and Mistral NeMo -\nperform at worse-than-chance level, assigning higher probabilities to\nimpossible sentences such as 'the car was given a parking ticket by the brake'\nthan to merely unlikely sentences such as 'the car was given a parking ticket\nby the explorer'.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u5206\u89e3\u53ef\u80fd\u6027\u3001\u5178\u578b\u6027\u3001\u548c\u4e0a\u4e0b\u6587\u5173\u7cfb\u65f6\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u5224\u65ad\u4e8b\u4ef6\u53ef\u80fd\u6027\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u751a\u81f3\u53ef\u80fd\u8868\u73b0\u5f97\u6bd4\u968f\u673a\u9009\u62e9\u66f4\u5dee\u3002", "motivation": "\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u53ef\u9760\u5730\u533a\u5206\u53ef\u80fd\u4e8b\u4ef6\u548c\u4ec5\u4e0d\u5927\u53ef\u80fd\u4e8b\u4ef6\uff0c\u6311\u6218\u5148\u524d\u7684\u7814\u7a76\u7ed3\u8bba\u3002", "method": "\u901a\u8fc7\u5c06\u53ef\u80fd\u6027\u3001\u5178\u578b\u6027\u548c\u4e0a\u4e0b\u6587\u5173\u8054\u6027\u5206\u5f00\u5206\u6790\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u5728\u4e00\u4e9b\u60c5\u5f62\u4e0b\uff0c\u6a21\u578b\u9519\u8bef\u5730\u5c06\u4e0d\u53ef\u80fd\u7684\u53e5\u5b50\u8d4b\u4e88\u66f4\u9ad8\u6982\u7387\uff0c\u800c\u975e\u4ec5\u4ec5\u4e0d\u5927\u53ef\u80fd\u7684\u53e5\u5b50\u3002", "conclusion": "\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u9884\u6d4b\u4e8b\u4ef6\u53ef\u80fd\u6027\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u6d4b\u8bd5\u7684\u6a21\u578b\uff0c\u5305\u62ecLlama 3\u3001Gemma 2\u548cMistral NeMo\uff0c\u90fd\u4f1a\u5728\u6982\u7387\u5224\u65ad\u4e0a\u8868\u73b0\u5f97\u6bd4\u968f\u673a\u9009\u62e9\u8fd8\u5dee\u3002"}}
{"id": "2506.06571", "pdf": "https://arxiv.org/pdf/2506.06571", "abs": "https://arxiv.org/abs/2506.06571", "authors": ["Mattie Ji", "Amauri H. Souza", "Vikas Garg"], "title": "Graph Persistence goes Spectral", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "24 pages, 4 figures, 6 tables", "summary": "Including intricate topological information (e.g., cycles) provably enhances\nthe expressivity of message-passing graph neural networks (GNNs) beyond the\nWeisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods\nare increasingly employed for graph representation learning. In this context,\nrecent works have proposed decorating classical PH diagrams with vertex and\nedge features for improved expressivity. However, due to their dependence on\nfeatures, these methods still fail to capture basic graph structural\ninformation. In this paper, we propose SpectRe -- a new topological descriptor\nfor graphs that integrates spectral information into PH diagrams. Notably,\nSpectRe is strictly more expressive than existing descriptors on graphs. We\nalso introduce notions of global and local stability to analyze existing\ndescriptors and establish that SpectRe is locally stable. Finally, experiments\non synthetic and real-world datasets demonstrate the effectiveness of SpectRe\nand its potential to enhance the capabilities of graph models in relevant\nlearning tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SpectRe\uff0c\u4e00\u4e2a\u6574\u5408\u5149\u8c31\u4fe1\u606f\u5230PH\u56fe\u7684\u65b0\u62d3\u6251\u63cf\u8ff0\u7b26\uff0c\u62e5\u6709\u66f4\u5f3a\u7684\u8868\u73b0\u529b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u793a\u51fa\u4f18\u5f02\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u7279\u5f81\u589e\u5f3a\u7ecf\u5178PH\u56fe\u7684\u65b9\u6cd5\u5728\u8868\u8fbe\u6027\u4e0a\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u65e0\u6cd5\u6355\u6349\u57fa\u7840\u7684\u56fe\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86SpectRe\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684\u62d3\u6251\u63cf\u8ff0\u7b26\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u5168\u5c40\u548c\u5c40\u90e8\u7a33\u5b9a\u6027\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u5206\u6790\u8bc1\u660eSpectRe\u5728\u5c40\u90e8\u662f\u7a33\u5b9a\u7684\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eSpectRe\u7684\u8868\u73b0\u8d85\u51fa\u5df2\u6709\u7684\u56fe\u63cf\u8ff0\u7b26\uff0c\u5c55\u793a\u5176\u589e\u5f3a\u56fe\u6a21\u578b\u80fd\u529b\u7684\u6f5c\u529b\u3002", "conclusion": "SpectRe\u5c55\u793a\u51fa\u5728\u56fe\u6a21\u578b\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6548\u679c\u548c\u6f5c\u529b\u3002"}}
{"id": "2506.07075", "pdf": "https://arxiv.org/pdf/2506.07075", "abs": "https://arxiv.org/abs/2506.07075", "authors": ["Liwen Zheng", "Chaozhuo Li", "Haoran Jia", "Xi Zhang"], "title": "Reasoning Paths as Signals: Augmenting Multi-hop Fact Verification through Structural Reasoning Progression", "categories": ["cs.AI"], "comment": null, "summary": "The growing complexity of factual claims in real-world scenarios presents\nsignificant challenges for automated fact verification systems, particularly in\naccurately aggregating and reasoning over multi-hop evidence. Existing\napproaches often rely on static or shallow models that fail to capture the\nevolving structure of reasoning paths, leading to fragmented retrieval and\nlimited interpretability. To address these issues, we propose a Structural\nReasoning framework for Multi-hop Fact Verification that explicitly models\nreasoning paths as structured graphs throughout both evidence retrieval and\nclaim verification stages. Our method comprises two key modules: a\nstructure-enhanced retrieval mechanism that constructs reasoning graphs to\nguide evidence collection, and a reasoning-path-guided verification module that\nincrementally builds subgraphs to represent evolving inference trajectories. We\nfurther incorporate a structure-aware reasoning mechanism that captures\nlong-range dependencies across multi-hop evidence chains, enabling more precise\nverification. Extensive experiments on the FEVER and HoVer datasets demonstrate\nthat our approach consistently outperforms strong baselines, highlighting the\neffectiveness of reasoning-path modeling in enhancing retrieval precision and\nverification accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ed3\u6784\u63a8\u7406\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u591a\u8df3\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u8df3\u8bc1\u636e\u805a\u5408\u548c\u63a8\u7406\u73af\u8282\u4e2d\u7ed3\u6784\u6355\u83b7\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u63a8\u7406\u6846\u67b6\uff0c\u5305\u62ec\u7ed3\u6784\u589e\u5f3a\u7684\u68c0\u7d22\u673a\u5236\u548c\u63a8\u7406\u8def\u5f84\u5f15\u5bfc\u7684\u9a8c\u8bc1\u6a21\u5757\uff0c\u5e76\u7ed3\u5408\u4e86\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u63a8\u7406\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6211\u4eec\u7684\u65b9\u6cd5\u5728FEVER\u548cHoVer\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u7ed3\u6784\u63a8\u7406\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u591a\u8df3\u4e8b\u5b9e\u9a8c\u8bc1\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u68c0\u7d22\u7cbe\u5ea6\u3002"}}
{"id": "2506.06812", "pdf": "https://arxiv.org/pdf/2506.06812", "abs": "https://arxiv.org/abs/2506.06812", "authors": ["Bernardo Leite", "Henrique Lopes Cardoso"], "title": "Advancing Question Generation with Joint Narrative and Difficulty Control", "categories": ["cs.CL"], "comment": "Preprint. Accepted to the BEA 2025 Workshop (ACL)", "summary": "Question Generation (QG), the task of automatically generating questions from\na source input, has seen significant progress in recent years.\nDifficulty-controllable QG (DCQG) enables control over the difficulty level of\ngenerated questions while considering the learner's ability. Additionally,\nnarrative-controllable QG (NCQG) allows control over the narrative aspects\nembedded in the questions. However, research in QG lacks a focus on combining\nthese two types of control, which is important for generating questions\ntailored to educational purposes. To address this gap, we propose a strategy\nfor Joint Narrative and Difficulty Control, enabling simultaneous control over\nthese two attributes in the generation of reading comprehension questions. Our\nevaluation provides preliminary evidence that this approach is feasible, though\nit is not effective across all instances. Our findings highlight the conditions\nunder which the strategy performs well and discuss the trade-offs associated\nwith its application.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b56\u7565\uff0c\u7ed3\u5408\u53d9\u8ff0\u548c\u96be\u5ea6\u63a7\u5236\uff0c\u751f\u6210\u9002\u5408\u6559\u80b2\u7528\u9014\u7684\u9605\u8bfb\u7406\u89e3\u95ee\u9898\uff0c\u5e76\u83b7\u5f97\u521d\u6b65\u6709\u6548\u6027\u8bc1\u636e\u3002", "motivation": "\u73b0\u6709\u95ee\u9898\u751f\u6210\u7814\u7a76\u7f3a\u4e4f\u5bf9\u7ed3\u5408\u53d9\u8ff0\u63a7\u5236\u548c\u96be\u5ea6\u63a7\u5236\u7684\u91cd\u8981\u5173\u6ce8\uff0c\u6211\u4eec\u7684\u52a8\u673a\u662f\u586b\u8865\u8fd9\u4e00\u7814\u7a76\u7a7a\u767d\uff0c\u4ee5\u4fbf\u4e3a\u6559\u80b2\u76ee\u7684\u751f\u6210\u91cf\u8eab\u5b9a\u5236\u7684\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u53d9\u8ff0\u548c\u96be\u5ea6\u63a7\u5236\u7684\u7b56\u7565\uff0c\u7528\u4e8e\u5728\u751f\u6210\u9605\u8bfb\u7406\u89e3\u95ee\u9898\u65f6\u540c\u65f6\u63a7\u5236\u8fd9\u4e24\u4e2a\u5c5e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u521d\u6b65\u663e\u793a\u6211\u4eec\u7684\u7b56\u7565\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u4e3a\u540c\u65f6\u63a7\u5236\u751f\u6210\u9605\u8bfb\u7406\u89e3\u95ee\u9898\u4e2d\u7684\u53d9\u8ff0\u6027\u548c\u96be\u5ea6\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\uff0c\u8fd9\u8868\u660e\u8fd9\u9879\u7b56\u7565\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2506.06579", "pdf": "https://arxiv.org/pdf/2506.06579", "abs": "https://arxiv.org/abs/2506.06579", "authors": ["Adarsh Prasad Behera", "Jaya Prakash Champati", "Roberto Morabito", "Sasu Tarkoma", "James Gross"], "title": "Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC"], "comment": null, "summary": "Recent progress in Language Models (LMs) has dramatically advanced the field\nof natural language processing (NLP), excelling at tasks like text generation,\nsummarization, and question answering. However, their inference remains\ncomputationally expensive and energy intensive, especially in settings with\nlimited hardware, power, or bandwidth. This makes it difficult to deploy LMs in\nmobile, edge, or cost sensitive environments. To address these challenges,\nrecent approaches have introduced multi LLM intelligent model selection\nstrategies that dynamically allocate computational resources based on query\ncomplexity -- using lightweight models for simpler queries and escalating to\nlarger models only when necessary. This survey explores two complementary\nstrategies for efficient LLM inference: (i) routing, which selects the most\nsuitable model based on the query, and (ii) cascading or hierarchical inference\n(HI), which escalates queries through a sequence of models until a confident\nresponse is found. Both approaches aim to reduce computation by using\nlightweight models for simpler tasks while offloading only when needed. We\nprovide a comparative analysis of these techniques across key performance\nmetrics, discuss benchmarking efforts, and outline open challenges. Finally, we\noutline future research directions to enable faster response times, adaptive\nmodel selection based on task complexity, and scalable deployment across\nheterogeneous environments, making LLM based systems more efficient and\naccessible for real world applications.", "AI": {"tldr": "\u591aLLM\u9009\u62e9\u7b56\u7565\u548c\u7ea7\u8054\u63a8\u7406\u5728\u6709\u9650\u8d44\u6e90\u73af\u5883\u4e2d\u63d0\u5347LLM\u63a8\u7406\u6548\u7387\uff0c\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5728\u6709\u9650\u786c\u4ef6\u3001\u4f9b\u7535\u6216\u5e26\u5bbd\u7684\u8bbe\u7f6e\u4e2d\uff0cLMs\u7684\u63a8\u7406\u6210\u672c\u9ad8\u4e14\u8017\u80fd\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u79fb\u52a8\u8bbe\u5907\u3001\u8fb9\u7f18\u8ba1\u7b97\u6216\u5bf9\u4ef7\u683c\u654f\u611f\u7684\u73af\u5883\u4e2d\u7684\u90e8\u7f72\uff0c\u63d0\u51fa\u7684\u7b56\u7565\u65e8\u5728\u901a\u8fc7\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8c03\u67e5\u73b0\u6709\u4e24\u79cd\u7b56\u7565\uff1a\u8def\u7531\u9009\u62e9\u548c\u7ea7\u8054\u63a8\u7406\uff0c\u5bf9\u6bd4\u5206\u6790\u8fd9\u4e24\u79cd\u7b56\u7565\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u57fa\u51c6\u6d4b\u8bd5\u5de5\u4f5c\u548c\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\u8fd9\u4e24\u79cd\u7b56\u7565\u901a\u8fc7\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\u5904\u7406\u7b80\u5355\u4efb\u52a1\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8f6c\u5411\u8f83\u5927\u6a21\u578b\uff0c\u4ece\u800c\u51cf\u5c11\u4e86\u8ba1\u7b97\u91cf\u3002", "conclusion": "\u591aLLM\u667a\u80fd\u6a21\u578b\u9009\u62e9\u7b56\u7565\u548c\u7ea7\u8054\u63a8\u7406\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u5728\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u4e0b\u7684\u63a8\u7406\u6548\u7387\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u53ca\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2506.07116", "pdf": "https://arxiv.org/pdf/2506.07116", "abs": "https://arxiv.org/abs/2506.07116", "authors": ["Liyang Chen", "Yujun Cai", "Jieqiong Dong", "Yiwei Wang"], "title": "BRIGHT+: Upgrading the BRIGHT Benchmark with MARCUS, a Multi-Agent RAG Clean-Up Suite", "categories": ["cs.AI"], "comment": "8 pages, 7 figures, 4 tables. Submitted to EMNLP 2025", "summary": "Retrieval-Augmented Generation (RAG) systems require corpora that are both\nstructurally clean and semantically coherent. BRIGHT is a recent and\ninfluential benchmark designed to evaluate complex multi-hop retrieval across\ndiverse, high-reasoning domains. However, its practical effectiveness is\nlimited by common web-crawled artifacts - such as content redundancy and\nsemantic discontinuity - that impair retrieval accuracy and downstream\nreasoning. Notably, we find that such issues are concentrated in seven\nStackExchange-derived subdomains, while other domains (e.g., Coding and\nTheorem-based content) remain relatively clean.\n  In this study, we present MARCUS, a multi-agent pipeline that leverages large\nlanguage models (LLMs) to systematically clean and re-chunk BRIGHT into a\nhigher-quality corpus: BRIGHT-Plus. MARCUS applies dedicated agents for\nstructural noise removal and semantic segmentation, preserving answer-bearing\nspans while improving contextual integrity. Experimental evaluations\ndemonstrate that BRIGHT-Plus yields consistent and significant improvements in\nboth retrieval accuracy and multi-hop reasoning across a diverse set of\nretrievers. We release both the BRIGHT-Plus corpus and the MARCUS pipeline to\nsupport future research on robust, reasoning-centric retrieval.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMARCUS\u7ba1\u9053\uff0c\u6e05\u7406BRIGHT\u8bed\u6599\u5e93\uff0c\u751f\u6210BRIGHT-Plus\uff0c\u63d0\u9ad8\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684RAG\u7cfb\u7edf\u53d7\u9650\u4e8e\u8bed\u6599\u5e93\u4e2d\u7684\u5e38\u89c1\u7f51\u7edc\u722c\u866b\u6587\u732e\u4f2a\u5f71\u95ee\u9898\uff0c\u5982\u5185\u5bb9\u5197\u4f59\u548c\u8bed\u4e49\u4e0d\u8fde\u7eed\u6027\uff0c\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5c24\u5176\u5728BRIGHT\u7684\u67d0\u4e9b\u5b50\u57df\u4e2d\u95ee\u9898\u5c24\u4e3a\u660e\u663e\u3002", "method": "\u4f7f\u7528\u591a\u4ee3\u7406\u7cfb\u7edfMARCUS\uff0c\u501f\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53bb\u9664\u7ed3\u6784\u566a\u58f0\u548c\u5b9e\u73b0\u8bed\u4e49\u5206\u5272\uff0c\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684BRIGHT-Plus\u8bed\u6599\u5e93\u3002", "result": "\u7ecf\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\uff0cBRIGHT-Plus\u5728\u591a\u79cd\u68c0\u7d22\u5668\u4e0a\u8868\u73b0\u51fa\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u591a\u8dc3\u70b9\u63a8\u7406\u65b9\u9762\u7684\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "BRIGHT-Plus\u901a\u8fc7\u4f7f\u7528MARCUS\u7ba1\u9053\u8fdb\u884c\u6e05\u7406\u548c\u91cd\u65b0\u5206\u5757\uff0c\u663e\u8457\u6539\u5584\u4e86\u68c0\u7d22\u51c6\u786e\u6027\u548c\u591a\u8dc3\u70b9\u63a8\u7406\u3002"}}
{"id": "2506.06813", "pdf": "https://arxiv.org/pdf/2506.06813", "abs": "https://arxiv.org/abs/2506.06813", "authors": ["Dipto Das", "Syed Ishtiaque Ahmed", "Shion Guha"], "title": "BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities", "categories": ["cs.CL", "cs.CY", "cs.HC"], "comment": null, "summary": "Understanding political discourse in online spaces is crucial for analyzing\npublic opinion and ideological polarization. While social computing and\ncomputational linguistics have explored such discussions in English, such\nresearch efforts are significantly limited in major yet under-resourced\nlanguages like Bengali due to the unavailability of datasets. In this paper, we\npresent a multilingual dataset of Bengali transnational political discourse\n(BTPD) collected from three online platforms, each representing distinct\ncommunity structures and interaction dynamics. Besides describing how we\nhand-curated the dataset through community-informed keyword-based retrieval,\nthis paper also provides a general overview of its topics and multilingual\ncontent.", "AI": {"tldr": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b5f\u52a0\u62c9\u8bed\u8de8\u56fd\u653f\u6cbb\u8bdd\u8bed\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u5176\u4e3b\u9898\u548c\u5185\u5bb9\u7684\u6982\u8ff0\u3002", "motivation": "\u653f\u6cbb\u8bdd\u8bed\u7684\u7814\u7a76\u6709\u52a9\u4e8e\u5206\u6790\u516c\u4f17\u8206\u8bba\u548c\u610f\u8bc6\u5f62\u6001\u6781\u5316\u3002\u5728\u82f1\u8bed\u4e2d\u5df2\u7ecf\u6709\u76f8\u5173\u7814\u7a76\uff0c\u4f46\u5728\u5982\u5b5f\u52a0\u62c9\u8bed\u8fd9\u6837\u7684\u91cd\u8981\u4f46\u8d44\u6e90\u4e0d\u8db3\u7684\u8bed\u8a00\u4e2d\uff0c\u7814\u7a76\u53d7\u5230\u9650\u5236\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u7f3a\u4e4f\u6570\u636e\u96c6\u3002", "method": "\u901a\u8fc7\u793e\u533a\u77e5\u60c5\u7684\u5173\u952e\u8bcd\u68c0\u7d22\u624b\u52a8\u6574\u7406\u6570\u636e\u96c6\uff0c\u5e76\u4ece\u4e09\u4e2a\u5728\u7ebf\u5e73\u53f0\u6536\u96c6\u5b5f\u52a0\u62c9\u8bed\u8de8\u56fd\u653f\u6cbb\u8bdd\u8bed\u6570\u636e\u3002", "result": "\u63d0\u4f9b\u4e86\u5b5f\u52a0\u62c9\u8de8\u56fd\u653f\u6cbb\u8bdd\u8bed\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5e76\u6982\u8ff0\u5176\u4e3b\u9898\u548c\u591a\u8bed\u8a00\u5185\u5bb9\u3002", "conclusion": "\u4e3a\u5b5f\u52a0\u62c9\u8bed\u653f\u6cbb\u8bdd\u8bed\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9d\u8d35\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\u5de5\u5177\uff0c\u586b\u8865\u4e86\u76f8\u5173\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2506.06582", "pdf": "https://arxiv.org/pdf/2506.06582", "abs": "https://arxiv.org/abs/2506.06582", "authors": ["Diaaeldin Taha", "James Chapman", "Marzieh Eidi", "Karel Devriendt", "Guido Mont\u00fafar"], "title": "Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing", "categories": ["cs.LG", "stat.ML", "I.5.1"], "comment": "50 pages, 12 figures, published at ICLR 2025. The Thirteenth\n  International Conference on Learning Representations. 2025", "summary": "Topological deep learning (TDL) has emerged as a powerful tool for modeling\nhigher-order interactions in relational data. However, phenomena such as\noversquashing in topological message-passing remain understudied and lack\ntheoretical analysis. We propose a unifying axiomatic framework that bridges\ngraph and topological message-passing by viewing simplicial and cellular\ncomplexes and their message-passing schemes through the lens of relational\nstructures. This approach extends graph-theoretic results and algorithms to\nhigher-order structures, facilitating the analysis and mitigation of\noversquashing in topological message-passing networks. Through theoretical\nanalysis and empirical studies on simplicial networks, we demonstrate the\npotential of this framework to advance TDL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6865\u63a5\u56fe\u548c\u62d3\u6251\u4fe1\u606f\u4f20\u9012\u7684\u7edf\u4e00\u6846\u67b6\u4ee5\u89e3\u51b3\u8fc7\u5ea6\u538b\u7f29\u7b49\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u5176\u6f5c\u529b\u3002", "motivation": "\u89e3\u51b3\u62d3\u6251\u4fe1\u606f\u4f20\u9012\u7f51\u7edc\u4e2d\u7684\u8fc7\u5ea6\u538b\u7f29\u95ee\u9898\u3002", "method": "\u4ece\u5173\u7cfb\u7ed3\u6784\u7684\u89d2\u5ea6\u770b\u5355\u7eaf\u590d\u5f62\u548c\u7ec6\u80de\u590d\u5f62\u53ca\u5176\u6d88\u606f\u4f20\u9012\u65b9\u6848\u7684\u7edf\u4e00\u516c\u7406\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u4e2d\u5bf9\u62d3\u6251\u6df1\u5ea6\u5b66\u4e60\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u6846\u67b6\u80fd\u591f\u63a8\u8fdb\u62d3\u6251\u6df1\u5ea6\u5b66\u4e60\u7684\u7814\u7a76\u3002"}}
{"id": "2506.07173", "pdf": "https://arxiv.org/pdf/2506.07173", "abs": "https://arxiv.org/abs/2506.07173", "authors": ["Miroslav Popovic", "Marko Popovic", "Miodrag Djukic", "Ilija Basicevic"], "title": "Translating Federated Learning Algorithms in Python into CSP Processes Using ChatGPT", "categories": ["cs.AI"], "comment": "6 pages, 4 tables", "summary": "The Python Testbed for Federated Learning Algorithms is a simple Python FL\nframework that is easy to use by ML&AI developers who do not need to be\nprofessional programmers and is also amenable to LLMs. In the previous\nresearch, generic federated learning algorithms provided by this framework were\nmanually translated into the CSP processes and algorithms' safety and liveness\nproperties were automatically verified by the model checker PAT. In this paper,\na simple translation process is introduced wherein the ChatGPT is used to\nautomate the translation of the mentioned federated learning algorithms in\nPython into the corresponding CSP processes. Within the process, the minimality\nof the used context is estimated based on the feedback from ChatGPT. The\nproposed translation process was experimentally validated by successful\ntranslation (verified by the model checker PAT) of both generic centralized and\ndecentralized federated learning algorithms.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528ChatGPT\u81ea\u52a8\u5316\u7ffb\u8bd1\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u4e3aCSP\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u4e86\u81ea\u52a8\u5316\u7ffb\u8bd1\u7684\u53ef\u884c\u6027\u548c\u6210\u529f\u6027\u3002", "motivation": "\u4e4b\u524d\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u7ffb\u8bd1\u9700\u8981\u624b\u52a8\u64cd\u4f5c\uff0c\u672c\u6587\u5f15\u5165ChatGPT\u8fdb\u884c\u81ea\u52a8\u5316\u7ffb\u8bd1\u4ee5\u7b80\u5316\u6d41\u7a0b\u3002", "method": "\u4f7f\u7528ChatGPT\u81ea\u52a8\u5316\u7ffb\u8bd1\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u7528PAT\u6a21\u578b\u68c0\u67e5\u5668\u9a8c\u8bc1\u7ffb\u8bd1\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4f7f\u7528ChatGPT\u7684\u7ffb\u8bd1\u8fc7\u7a0b\u6210\u529f\u5b9e\u73b0\u4e86\u4ecePython\u5230CSP\u7684\u8f6c\u6362\uff0c\u5e76\u901a\u8fc7\u4e86\u6a21\u578b\u68c0\u67e5\u5668PAT\u7684\u9a8c\u8bc1\u3002", "conclusion": "\u4f7f\u7528ChatGPT\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u5c06Python\u4e2d\u7684\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u7ffb\u8bd1\u4e3aCSP\u8fc7\u7a0b\u7684\u7b80\u5316\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7PAT\u6a21\u578b\u68c0\u67e5\u5668\u9a8c\u8bc1\u4e86\u96c6\u4e2d\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u3002"}}
{"id": "2506.06816", "pdf": "https://arxiv.org/pdf/2506.06816", "abs": "https://arxiv.org/abs/2506.06816", "authors": ["Dipto Das", "Shion Guha", "Bryan Semaan"], "title": "How do datasets, developers, and models affect biases in a low-resourced language?", "categories": ["cs.CL", "cs.CY", "cs.HC"], "comment": null, "summary": "Sociotechnical systems, such as language technologies, frequently exhibit\nidentity-based biases. These biases exacerbate the experiences of historically\nmarginalized communities and remain understudied in low-resource contexts.\nWhile models and datasets specific to a language or with multilingual support\nare commonly recommended to address these biases, this paper empirically tests\nthe effectiveness of such approaches in the context of gender, religion, and\nnationality-based identities in Bengali, a widely spoken but low-resourced\nlanguage. We conducted an algorithmic audit of sentiment analysis models built\non mBERT and BanglaBERT, which were fine-tuned using all Bengali sentiment\nanalysis (BSA) datasets from Google Dataset Search. Our analyses showed that\nBSA models exhibit biases across different identity categories despite having\nsimilar semantic content and structure. We also examined the inconsistencies\nand uncertainties arising from combining pre-trained models and datasets\ncreated by individuals from diverse demographic backgrounds. We connected these\nfindings to the broader discussions on epistemic injustice, AI alignment, and\nmethodological decisions in algorithmic audits.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5ba1\u89c6\u4e86\u8bed\u8a00\u6280\u672f\u4e2d\u7684\u8eab\u4efd\u504f\u89c1\uff0c\u7279\u522b\u662f\u7f05\u7538\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u6027\u522b\u3001\u5b97\u6559\u3001\u56fd\u7c4d\u504f\u89c1\uff0c\u5e76\u901a\u8fc7\u7b97\u6cd5\u5ba1\u8ba1\u8868\u660e\u8fd9\u4e9b\u504f\u89c1\u7684\u5b58\u5728\uff0c\u8fdb\u800c\u8ba8\u8bba\u4e86\u8ba4\u8bc6\u4e0d\u516c\u548cAI\u5bf9\u9f50\u7b49\u95ee\u9898\u3002", "motivation": "\u8bed\u8a00\u6280\u672f\u7b49\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u5e38\u5e38\u8868\u73b0\u51fa\u57fa\u4e8e\u8eab\u4efd\u7684\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u52a0\u5267\u4e86\u5386\u53f2\u4e0a\u8fb9\u7f18\u5316\u793e\u533a\u7684\u7ecf\u5386\uff0c\u5e76\u4e14\u5728\u8d44\u6e90\u7a00\u7f3a\u7684\u80cc\u666f\u4e0b\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u867d\u7136\u5e38\u5e38\u5efa\u8bae\u91c7\u7528\u7279\u5b9a\u4e8e\u8bed\u8a00\u6216\u5177\u6709\u591a\u8bed\u8a00\u652f\u6301\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u6765\u89e3\u51b3\u8fd9\u4e9b\u504f\u89c1\uff0c\u4f46\u5728\u7f05\u7538\u8bed\u8fd9\u79cd\u5e7f\u6cdb\u4f7f\u7528\u4f46\u8d44\u6e90\u7a00\u7f3a\u7684\u8bed\u8a00\u73af\u5883\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6d4b\u8bd5\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u91cd\u70b9\u5173\u6ce8\u6027\u522b\u3001\u5b97\u6559\u548c\u56fd\u7c4d\u7684\u8eab\u4efd\u3002", "method": "\u6211\u4eec\u5bf9\u4f7f\u7528mBERT\u548cBanglaBERT\u7ec6\u5316\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u8fdb\u884c\u4e86\u7b97\u6cd5\u5ba1\u8ba1\uff0c\u8fd9\u4e9b\u6a21\u578b\u4f7f\u7528\u8c37\u6b4c\u6570\u636e\u96c6\u641c\u7d22\u4e2d\u6240\u6709\u7684\u7f05\u7538\u60c5\u611f\u5206\u6790\uff08BSA\uff09\u6570\u636e\u96c6\u8fdb\u884c\u7ec6\u5316\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u5c3d\u7ba1\u6709\u7c7b\u4f3c\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u7ed3\u6784\uff0c\u7f05\u7538\u60c5\u611f\u5206\u6790\uff08BSA\uff09\u6a21\u578b\u5728\u4e0d\u540c\u8eab\u4efd\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u504f\u89c1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7814\u7a76\u4e86\u7ed3\u5408\u7531\u4e0d\u540c\u4eba\u53e3\u80cc\u666f\u7684\u4eba\u521b\u5efa\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u6570\u636e\u96c6\u6240\u4ea7\u751f\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e0e\u5173\u4e8e\u8ba4\u8bc6\u4e0d\u516c\u3001AI\u5bf9\u9f50\u4ee5\u53ca\u7b97\u6cd5\u5ba1\u8ba1\u4e2d\u7684\u65b9\u6cd5\u9009\u62e9\u7b49\u66f4\u5e7f\u6cdb\u7684\u8ba8\u8bba\u5f62\u6210\u5173\u8054\u3002"}}
{"id": "2506.06584", "pdf": "https://arxiv.org/pdf/2506.06584", "abs": "https://arxiv.org/abs/2506.06584", "authors": ["Mo Zhou", "Weihang Xu", "Maryam Fazel", "Simon S. Du"], "title": "Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixtures", "categories": ["cs.LG", "stat.ML"], "comment": "77 pages", "summary": "Learning Gaussian Mixture Models (GMMs) is a fundamental problem in machine\nlearning, with the Expectation-Maximization (EM) algorithm and its popular\nvariant gradient EM being arguably the most widely used algorithms in practice.\nIn the exact-parameterized setting, where both the ground truth GMM and the\nlearning model have the same number of components $m$, a vast line of work has\naimed to establish rigorous recovery guarantees for EM. However, global\nconvergence has only been proven for the case of $m=2$, and EM is known to fail\nto recover the ground truth when $m\\geq 3$.\n  In this paper, we consider the $\\textit{over-parameterized}$ setting, where\nthe learning model uses $n>m$ components to fit an $m$-component ground truth\nGMM. In contrast to the exact-parameterized case, we provide a rigorous global\nconvergence guarantee for gradient EM. Specifically, for any well separated\nGMMs in general position, we prove that with only mild over-parameterization $n\n= \\Omega(m\\log m)$, randomly initialized gradient EM converges globally to the\nground truth at a polynomial rate with polynomial samples. Our analysis\nproceeds in two stages and introduces a suite of novel tools for Gaussian\nMixture analysis. We use Hermite polynomials to study the dynamics of gradient\nEM and employ tensor decomposition to characterize the geometric landscape of\nthe likelihood loss. This is the first global convergence and recovery result\nfor EM or Gradient EM beyond the special case of $m=2$.", "AI": {"tldr": "\u672c\u6587\u5728\u8fc7\u53c2\u6570\u5316\u8bbe\u7f6e\u4e0b\uff0c\u4e3aGradient EM\u63d0\u4f9b\u4e86\u5168\u5c40\u6536\u655b\u6027\u4fdd\u8bc1\u3002", "motivation": "\u5728EM\u7b97\u6cd5\u65e0\u6cd5\u4fdd\u8bc1\u5bf9m\u22653\u7684\u786e\u5207\u53c2\u6570\u5316GMM\u8fdb\u884c\u5168\u7403\u6536\u655b\u7684\u60c5\u51b5\u4e0b\uff0c\u63a2\u8ba8\u8fc7\u53c2\u6570\u5316\u662f\u5426\u80fd\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u4f9b\u6536\u655b\u4fdd\u8bc1\u3002", "method": "\u901a\u8fc7Herimit\u591a\u9879\u5f0f\u7814\u7a76Gradient EM\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u5e76\u5229\u7528\u5f20\u91cf\u5206\u89e3\u63cf\u8ff0\u4f3c\u7136\u635f\u5931\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u8fdb\u884c\u4e24\u9636\u6bb5\u5206\u6790\uff0c\u5f15\u5165\u4e00\u7cfb\u5217\u65b0\u7684\u5de5\u5177\u8fdb\u884c\u9ad8\u65af\u6df7\u5408\u5206\u6790\u3002", "result": "\u5bf9\u4e8e\u4e00\u822c\u4f4d\u7f6e\u7684\u826f\u597d\u5206\u79bb\u7684GMM\uff0c\u6d45\u5ea6\u8fc7\u53c2\u6570\u5316\uff08n=\u03a9(m log m)\uff09\u65f6\uff0c\u968f\u673a\u521d\u59cb\u5316\u7684Gradient EM\u80fd\u4ee5\u591a\u9879\u5f0f\u901f\u7387\u6536\u655b\u5230\u771f\u5b9e\u503c\uff0c\u5e76\u4f7f\u7528\u591a\u9879\u5f0f\u6837\u672c\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5728\u8fc7\u53c2\u6570\u5316\u4e0b\u4e3aGradient EM\u63d0\u4f9b\u4e86\u5168\u5c40\u6536\u655b\u548c\u6062\u590d\u7ed3\u679c\uff0c\u7a81\u7834\u4e86\u4ec5\u5728m=2\u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\u83b7\u5f97\u5168\u5c40\u6536\u655b\u7684\u9650\u5236\u3002"}}
{"id": "2506.07184", "pdf": "https://arxiv.org/pdf/2506.07184", "abs": "https://arxiv.org/abs/2506.07184", "authors": ["Liangliang You", "Junchi Yao", "Shu Yang", "Guimin Hu", "Lijie Hu", "Di Wang"], "title": "Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "While multimodal large language models excel at various tasks, they still\nsuffer from hallucinations, which limit their reliability and scalability for\nbroader domain applications. To address this issue, recent research mainly\nfocuses on objective hallucination. However, for sequential images, besides\nobjective hallucination, there is also behavioral hallucination, which is less\nstudied. This work aims to fill in the gap. We first reveal that behavioral\nhallucinations mainly arise from two key factors: prior-driven bias and the\nsnowball effect. Based on these observations, we introduce SHE (Sequence\nHallucination Eradication), a lightweight, two-stage framework that (1) detects\nhallucinations via visual-textual alignment check using our proposed adaptive\ntemporal window and (2) mitigates them via orthogonal projection onto the joint\nembedding space. We also propose a new metric (BEACH) to quantify behavioral\nhallucination severity. Empirical results on standard benchmarks demonstrate\nthat SHE reduces behavioral hallucination by over 10% on BEACH while\nmaintaining descriptive accuracy.", "AI": {"tldr": "\u63d0\u51faSHE\u6846\u67b6\u9488\u5bf9\u884c\u4e3a\u5e7b\u89c9\u95ee\u9898\u8fdb\u884c\u68c0\u6d4b\u548c\u89e3\u51b3\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5bf9\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u884c\u4e3a\u5e7b\u89c9\u7f3a\u4e4f\u7814\u7a76\uff0c\u4e3a\u6b64\u63d0\u51fa\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5f15\u5165SHE\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u6587\u672c\u5bf9\u9f50\u68c0\u67e5\u68c0\u6d4b\u5e7b\u89c9\uff0c\u5e76\u901a\u8fc7\u6b63\u4ea4\u6295\u5f71\u5728\u8054\u5408\u5d4c\u5165\u7a7a\u95f4\u4e2d\u51cf\u8f7b\u5b83\u4eec\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\uff0cSHE\u6846\u67b6\u5728BEACH\u6307\u6807\u4e0a\u5c06\u884c\u4e3a\u5e7b\u89c9\u51cf\u5c11\u4e86\u8d85\u8fc710%\u3002", "conclusion": "\u63d0\u51faSHE\u6846\u67b6\u6210\u529f\u51cf\u5c11\u4e86\u884c\u4e3a\u5e7b\u89c9\u5e76\u4e14\u4fdd\u6301\u63cf\u8ff0\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06820", "pdf": "https://arxiv.org/pdf/2506.06820", "abs": "https://arxiv.org/abs/2506.06820", "authors": ["Wenyu Zhang", "Yingxu He", "Geyu Lin", "Zhuohan Liu", "Shuo Sun", "Bin Wang", "Xunlong Zou", "Jeremy H. M. Wong", "Qiongqiong Wang", "Hardik B. Sailor", "Nancy F. Chen", "Ai Ti Aw"], "title": "Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Audio Large Language Models (AudioLLMs) have achieved strong results in\nsemantic tasks like speech recognition and translation, but remain limited in\nmodeling paralinguistic cues such as emotion. Existing approaches often treat\nemotion understanding as a classification problem, offering little insight into\nthe underlying rationale behind predictions. In this work, we explore emotion\nreasoning, a strategy that leverages the generative capabilities of AudioLLMs\nto enhance emotion recognition by producing semantically aligned,\nevidence-grounded explanations. To support this in multitask AudioLLMs, we\nintroduce a unified framework combining reasoning-augmented data supervision,\ndual-encoder architecture, and task-alternating training. This approach enables\nAudioLLMs to effectively learn different tasks while incorporating emotional\nreasoning. Experiments on IEMOCAP and MELD show that our approach not only\nimproves emotion prediction accuracy but also enhances the coherence and\nevidential grounding of the generated responses.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u878d\u5408\u63a8\u7406\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u6539\u5584\u4e86\u97f3\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u8bc6\u522b\u80fd\u529b\u548c\u751f\u6210\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u97f3\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u4efb\u52a1\u5982\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5efa\u6a21\u526f\u8bed\u8a00\u7ebf\u7d22\u5982\u60c5\u611f\u65b9\u9762\u4ecd\u6709\u9650\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u60c5\u611f\u7406\u89e3\u89c6\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u5bf9\u9884\u6d4b\u80cc\u540e\u7684\u539f\u56e0\u63d0\u4f9b\u7684\u89c1\u89e3\u6709\u9650\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u4e00\u79cd\u80fd\u591f\u751f\u6210\u8bed\u4e49\u5bf9\u9f50\u3001\u8bc1\u636e\u652f\u6301\u7684\u89e3\u91ca\uff0c\u4ee5\u589e\u5f3a\u60c5\u611f\u8bc6\u522b\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7ed3\u5408\u63a8\u7406\u589e\u5f3a\u6570\u636e\u76d1\u7763\u3001\u53cc\u7f16\u7801\u67b6\u6784\u548c\u4efb\u52a1\u8f6e\u66ff\u8bad\u7ec3\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4f7f\u591a\u4efb\u52a1\u97f3\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u4e0d\u540c\u4efb\u52a1\u5e76\u7ed3\u5408\u60c5\u611f\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u60c5\u611f\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u751f\u6210\u54cd\u5e94\u7684\u4e00\u81f4\u6027\u548c\u8bc1\u636e\u652f\u6301\u6027\u3002", "conclusion": "\u901a\u8fc7\u5728\u591a\u4efb\u52a1\u97f3\u9891\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5f15\u5165\u60c5\u611f\u63a8\u7406\u589e\u5f3a\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5730\u63d0\u9ad8\u60c5\u611f\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.06599", "pdf": "https://arxiv.org/pdf/2506.06599", "abs": "https://arxiv.org/abs/2506.06599", "authors": ["Yuanjie Shi", "Hooman Shahrokhi", "Xuesong Jia", "Xiongzhi Chen", "Janardhan Rao Doppa", "Yan Yan"], "title": "Direct Prediction Set Minimization via Bilevel Conformal Classifier Training", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted for Publication at International Conference on Machine\n  Learning (ICML), 2025", "summary": "Conformal prediction (CP) is a promising uncertainty quantification framework\nwhich works as a wrapper around a black-box classifier to construct prediction\nsets (i.e., subset of candidate classes) with provable guarantees. However,\nstandard calibration methods for CP tend to produce large prediction sets which\nmakes them less useful in practice. This paper considers the problem of\nintegrating conformal principles into the training process of deep classifiers\nto directly minimize the size of prediction sets. We formulate conformal\ntraining as a bilevel optimization problem and propose the {\\em Direct\nPrediction Set Minimization (DPSM)} algorithm to solve it. The key insight\nbehind DPSM is to minimize a measure of the prediction set size (upper level)\nthat is conditioned on the learned quantile of conformity scores (lower level).\nWe analyze that DPSM has a learning bound of $O(1/\\sqrt{n})$ (with $n$ training\nsamples), while prior conformal training methods based on stochastic\napproximation for the quantile has a bound of $\\Omega(1/s)$ (with batch size\n$s$ and typically $s \\ll \\sqrt{n}$). Experiments on various benchmark datasets\nand deep models show that DPSM significantly outperforms the best prior\nconformal training baseline with $20.46\\%\\downarrow$ in the prediction set size\nand validates our theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u76f4\u63a5\u9884\u6d4b\u96c6\u6700\u5c0f\u5316\uff08DPSM\uff09\u7b97\u6cd5\uff0c\u6210\u529f\u51cf\u5c11\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u63d0\u9ad8\u4fdd\u5e8f\u9884\u6d4b\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4fdd\u5e8f\u9884\u6d4b\u6821\u51c6\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u8f83\u5927\u7684\u9884\u6d4b\u96c6\uff0c\u5728\u5b9e\u8df5\u4e2d\u4e0d\u592a\u5b9e\u7528\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u76f4\u63a5\u6700\u5c0f\u5316\u9884\u6d4b\u96c6\u5927\u5c0f\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u4fdd\u5e8f\u539f\u5219\u878d\u5165\u6df1\u5ea6\u5206\u7c7b\u5668\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u91c7\u7528\u76f4\u63a5\u9884\u6d4b\u96c6\u6700\u5c0f\u5316\u7b97\u6cd5\uff08DPSM\uff09\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u95ee\u9898\u89e3\u51b3\u3002", "result": "\u5728\u5404\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u548c\u6df1\u5ea6\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDPSM\u7b97\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u9884\u6d4b\u96c6\u5927\u5c0f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7406\u8bba\u3002", "conclusion": "DPSM\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u4fdd\u5e8f\u8bad\u7ec3\u57fa\u7ebf\uff0c\u5728\u9884\u6d4b\u96c6\u5927\u5c0f\u4e0a\u964d\u4f4e\u4e8620.46%\u3002"}}
{"id": "2506.07194", "pdf": "https://arxiv.org/pdf/2506.07194", "abs": "https://arxiv.org/abs/2506.07194", "authors": ["Luwei Bai", "Dongkeun Han", "Sara Hennessy"], "title": "Exploring Effective Strategies for Building a Customised GPT Agent for Coding Classroom Dialogues", "categories": ["cs.AI"], "comment": "Draft technical report. 39 pages, 2 figures. Not yet submitted for\n  publication. Update expected", "summary": "This study investigates effective strategies for developing a customised GPT\nagent to code classroom dialogue. While classroom dialogue is widely recognised\nas a crucial element of education, its analysis remains challenging due to the\nneed for a nuanced understanding of dialogic functions and the labour-intensive\nnature of manual transcript coding. Recent advancements in large language\nmodels offer promising avenues for automating this process. However, existing\nstudies predominantly focus on training large-scale models or evaluating\npre-trained models with fixed codebooks, which are often not applicable or\nreplicable for dialogue researchers working with small datasets or customised\ncoding schemes. Using GPT-4's MyGPT agent as a case, this study evaluates its\nbaseline performance in coding classroom dialogue with a human codebook and\nexamines how performance varies with different example inputs through a\nvariable control method. Through a design-based research approach, it\nidentifies a set of practical strategies, based on MyGPT's unique features, for\nconfiguring effective agents with limited data. The findings suggest that,\ndespite some limitations, a MyGPT agent developed with these strategies can\nserve as a useful coding assistant by generating coding suggestions.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86MyGPT\u5728\u8bfe\u5802\u5bf9\u8bdd\u7f16\u7801\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u6709\u9650\u6570\u636e\u4e0b\u914d\u7f6e\u6709\u6548\u4ee3\u7406\u7684\u5b9e\u7528\u7b56\u7565\u3002", "motivation": "\u7531\u4e8e\u8bfe\u5802\u5bf9\u8bdd\u5206\u6790\u9700\u8981\u5bf9\u8bdd\u529f\u80fd\u7684\u7ec6\u81f4\u7406\u89e3\u4e14\u4eba\u5de5\u8f6c\u5f55\u7f16\u7801\u8017\u65f6\uff0c\u7814\u7a76\u63a2\u7d22\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5316\u8fc7\u7a0b\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u4f7f\u7528\u8bbe\u8ba1\u578b\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u91cf\u63a7\u5236\u65b9\u6cd5\u8bc4\u4f30MyGPT\u4ee3\u7406\u5728\u8bfe\u5802\u5bf9\u8bdd\u7f16\u7801\u4e2d\u7684\u57fa\u7ebf\u8868\u73b0\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u793a\u4f8b\u8f93\u5165\u5982\u4f55\u5f71\u54cd\u5176\u8868\u73b0\u3002", "result": "\u8bc6\u522b\u4e86\u4e00\u5957\u57fa\u4e8eMyGPT\u72ec\u7279\u529f\u80fd\u7684\u5b9e\u7528\u7b56\u7565\uff0c\u7528\u4e8e\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u914d\u7f6e\u9ad8\u6548\u4ee3\u7406\u3002", "conclusion": "MyGPT\u4ee3\u7406\u7ecf\u8fc7\u5b9a\u5236\u7b56\u7565\u540e\uff0c\u5c3d\u7ba1\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4ecd\u7136\u53ef\u4ee5\u6210\u4e3a\u6709\u7528\u7684\u7f16\u7801\u52a9\u624b\uff0c\u901a\u8fc7\u751f\u6210\u7f16\u7801\u5efa\u8bae\u652f\u6301\u7528\u6237\u3002"}}
{"id": "2506.06821", "pdf": "https://arxiv.org/pdf/2506.06821", "abs": "https://arxiv.org/abs/2506.06821", "authors": ["Yuhan Cao", "Zian Chen", "Kun Quan", "Ziliang Zhang", "Yu Wang", "Xiaoning Dong", "Yeqi Feng", "Guanzhong He", "Jingcheng Huang", "Jianhao Li", "Yixuan Tan", "Jiafu Tang", "Yilin Tang", "Junlei Wu", "Qianyu Xiao", "Can Zheng", "Shouchen Zhou", "Yuxiang Zhu", "Yiming Huang", "Tian Xie", "Tianxing He"], "title": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "37 pages, 22 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation, capable of tackling complex tasks during inference. However,\nthe extent to which LLMs can be utilized for code checking or debugging through\ntest case generation remains largely unexplored. We investigate this problem\nfrom the perspective of competition-level programming (CP) programs and propose\nTCGBench, a Benchmark for (LLM generation of) Test Case Generators. This\nbenchmark comprises two tasks, aimed at studying the capabilities of LLMs in\n(1) generating valid test case generators for a given CP problem, and further\n(2) generating targeted test case generators that expose bugs in human-written\ncode. Experimental results indicate that while state-of-the-art LLMs can\ngenerate valid test case generators in most cases, most LLMs struggle to\ngenerate targeted test cases that reveal flaws in human code effectively.\nEspecially, even advanced reasoning models (e.g., o3-mini) fall significantly\nshort of human performance in the task of generating targeted generators.\nFurthermore, we construct a high-quality, manually curated dataset of\ninstructions for generating targeted generators. Analysis demonstrates that the\nperformance of LLMs can be enhanced with the aid of this dataset, by both\nprompting and fine-tuning.", "AI": {"tldr": "Study on LLMs' ability in test case generation for debugging finds potential yet highlights struggles in creating targeted test cases to find code flaws. TCGBench and datasets improve performance.", "motivation": "To explore the unexplored area of using LLMs for code checking or debugging through test case generation, especially in complex competition-level programming environments.", "method": "The paper proposes a benchmark named TCGBench to evaluate the ability of LLMs in generating test case generators. It involves experimental studies where the capabilities of LLMs are analyzed in two tasks.", "result": "State-of-the-art LLMs can usually generate valid test case generators, yet they have difficulty in creating targeted ones that effectively expose coding flaws. Enhanced performance is possible with a high-quality dataset for model prompting and fine-tuning.", "conclusion": "LLMs exhibit potential in generating valid test case generators for competition-level programming problems but struggle to effectively generate targeted test cases that can uncover bugs in human-written code."}}
{"id": "2506.06603", "pdf": "https://arxiv.org/pdf/2506.06603", "abs": "https://arxiv.org/abs/2506.06603", "authors": ["Joseph T Colonel", "Carolyn Hagler", "Guiselle Wismer", "Laura Curtis", "Jacqueline Becker", "Juan Wisnivesky", "Alex Federman", "Gaurav Pandey"], "title": "CAtCh: Cognitive Assessment through Cookie Thief", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "Several machine learning algorithms have been developed for the prediction of\nAlzheimer's disease and related dementia (ADRD) from spontaneous speech.\nHowever, none of these algorithms have been translated for the prediction of\nbroader cognitive impairment (CI), which in some cases is a precursor and risk\nfactor of ADRD. In this paper, we evaluated several speech-based open-source\nmethods originally proposed for the prediction of ADRD, as well as methods from\nmultimodal sentiment analysis for the task of predicting CI from patient audio\nrecordings. Results demonstrated that multimodal methods outperformed unimodal\nones for CI prediction, and that acoustics-based approaches performed better\nthan linguistics-based ones. Specifically, interpretable acoustic features\nrelating to affect and prosody were found to significantly outperform\nBERT-based linguistic features and interpretable linguistic features,\nrespectively. All the code developed for this study is available at\nhttps://github.com/JTColonel/catch.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u58f0\u5b66\u7279\u5f81\u548c\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u8ba4\u77e5\u969c\u788d\u9884\u6d4b\u4e2d\u4f18\u4e8e\u8bed\u8a00\u7279\u5f81\u548c\u5355\u6a21\u6001\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u591a\u7528\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c7\u53ca\u76f8\u5173\u75f4\u5446\u7684\u9884\u6d4b\uff0c\u5c1a\u672a\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u8ba4\u77e5\u969c\u788d\u9884\u6d4b\u3002", "method": "\u8bc4\u4f30\u591a\u79cd\u57fa\u4e8e\u8bed\u97f3\u7684\u5f00\u6e90\u65b9\u6cd5\u548c\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u9884\u6d4b\u60a3\u8005\u5f55\u97f3\u4e2d\u7684\u8ba4\u77e5\u969c\u788d\u3002", "result": "\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u8ba4\u77e5\u969c\u788d\u9884\u6d4b\u4e2d\u6bd4\u5355\u6a21\u6001\u65b9\u6cd5\u6548\u679c\u66f4\u597d\uff0c\u58f0\u5b66\u7279\u5f81\u5c24\u5176\u662f\u4e0e\u60c5\u611f\u548c\u8bed\u8c03\u76f8\u5173\u7684\u89e3\u91ca\u6027\u7279\u5f81\u4f18\u4e8e\u57fa\u4e8eBERT\u7684\u8bed\u8a00\u7279\u5f81\u3002", "conclusion": "\u58f0\u5b66\u7279\u5f81\u5728\u8ba4\u77e5\u969c\u788d\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u8bed\u8a00\u7279\u5f81\uff0c\u4e14\u591a\u6a21\u6001\u65b9\u6cd5\u4f18\u4e8e\u5355\u6a21\u6001\u65b9\u6cd5\u3002"}}
{"id": "2506.07202", "pdf": "https://arxiv.org/pdf/2506.07202", "abs": "https://arxiv.org/abs/2506.07202", "authors": ["Ming Liu", "Wensheng Zhang"], "title": "Reasoning Multimodal Large Language Model: Data Contamination and Dynamic Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show impressive vision-language\nbenchmark performance, yet growing concerns about data contamination (test set\nexposure during training) risk masking true generalization. This concern\nextends to reasoning MLLMs, often fine-tuned via reinforcement learning from\npotentially contaminated base models. We propose a novel dynamic evaluation\nframework to rigorously assess MLLM generalization, moving beyond static\nbenchmarks. Instead of perturbing inputs, we perturb the task itself. Using the\nsame visual input, models are evaluated across a family of tasks (e.g., QA,\ncaptioning, question posing, verification) to probe diverse capabilities. This\ntask perturbation reveals whether model performance is robust or reliant on\nsuperficial task-specific cues. Our approach is analogous to loss landscape\nsharpness: models overfit or contaminated for a single task (sharp minima)\nfalter under task shifts, unlike models with generalizable solutions (flatter\nminima). We developed an automated pipeline with a calibrated judge scoring\nopen-ended generations (captions, questions) using paraphrase and corruption\nsampling. Applying this framework to leading image/video MLLMs on benchmarks\nincluding MME, RealWorldQA, and CVRR-ES, we analyze each model's cross-task\n\"ability vector.\" We demonstrate that fine-tuning on simulated test data\n(extreme contamination) drastically sharpens task-specific performance but\nharms overall generalization. Our dynamic task perturbation offers deeper\ninsights into MLLM generalization, distinguishing genuine understanding from\nspurious leakage or overfitting.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u901a\u8fc7\u4efb\u52a1\u6270\u52a8\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u63ed\u793a\u5176\u771f\u6b63\u7406\u89e3\u6c34\u5e73\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u6570\u636e\u6c61\u67d3\u95ee\u9898\u53ef\u80fd\u63a9\u76d6\u5176\u771f\u5b9e\u7684\u6cdb\u5316\u80fd\u529b\u3002\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u65b9\u5f0f\u6765\u63ed\u793a\u6a21\u578b\u7684\u771f\u6b63\u7406\u89e3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4efb\u52a1\u6270\u52a8\u800c\u975e\u8f93\u5165\u6270\u52a8\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u89c6\u89c9\u8f93\u5165\uff0c\u5bf9\u6a21\u578b\u8fdb\u884c\u591a\u4efb\u52a1\u8bc4\u4f30\uff08\u5982\u95ee\u7b54\u3001\u56fe\u7247\u8bf4\u660e\u3001\u95ee\u9898\u63d0\u51fa\u3001\u9a8c\u8bc1\uff09\u6765\u63a2\u6d4b\u5176\u591a\u6837\u5316\u80fd\u529b\u3002", "result": "\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5bf9\u73b0\u6709\u56fe\u50cf/\u89c6\u9891\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d1\u73b0\u6781\u7aef\u6c61\u67d3\u4f1a\u5bfc\u81f4\u4efb\u52a1\u8868\u73b0\u9510\u5316\u4f46\u635f\u5bb3\u6574\u4f53\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8bc4\u4f30\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u52a0\u4e25\u683c\u5730\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63ed\u793a\u6a21\u578b\u6027\u80fd\u7684\u771f\u5b9e\u6027\u3002"}}
{"id": "2506.06842", "pdf": "https://arxiv.org/pdf/2506.06842", "abs": "https://arxiv.org/abs/2506.06842", "authors": ["Arkadiusz Modzelewski", "Witold Sosnowski", "Tiziano Labruna", "Adam Wierzbicki", "Giovanni Da San Martino"], "title": "PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Disinformation detection is a key aspect of media literacy. Psychological\nstudies have shown that knowledge of persuasive fallacies helps individuals\ndetect disinformation. Inspired by these findings, we experimented with large\nlanguage models (LLMs) to test whether infusing persuasion knowledge enhances\ndisinformation detection. As a result, we introduce the Persuasion-Augmented\nChain of Thought (PCoT), a novel approach that leverages persuasion to improve\ndisinformation detection in zero-shot classification. We extensively evaluate\nPCoT on online news and social media posts. Moreover, we publish two novel,\nup-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets\nenable the evaluation of PCoT on content entirely unseen by the LLMs used in\nour experiments, as the content was published after the models' knowledge\ncutoffs. We show that, on average, PCoT outperforms competitive methods by 15%\nacross five LLMs and five datasets. These findings highlight the value of\npersuasion in strengthening zero-shot disinformation detection.", "AI": {"tldr": "PCoT uses persuasion knowledge to enhance LLMs for disinformation detection, yielding significant improvements.", "motivation": "Improve media literacy by enhancing disinformation detection through the integration of persuasion knowledge in LLMs.", "method": "Introduction of Persuasion-Augmented Chain of Thought (PCoT) for zero-shot classification in disinformation detection, leveraging large language models with persuasion knowledge.", "result": "PCoT demonstrated a 15% improvement over competitive methods across five LLMs and five datasets, proving its effectiveness in unseen disinformation detection.", "conclusion": "PCoT significantly improves disinformation detection by using persuasion knowledge, outperforming other methods by 15% on average."}}
{"id": "2506.06606", "pdf": "https://arxiv.org/pdf/2506.06606", "abs": "https://arxiv.org/abs/2506.06606", "authors": ["Xinyu Luo", "Cedar Site Bai", "Bolian Li", "Petros Drineas", "Ruqi Zhang", "Brian Bullins"], "title": "Stacey: Promoting Stochastic Steepest Descent via Accelerated $\\ell_p$-Smooth Nonconvex Optimization", "categories": ["cs.LG"], "comment": null, "summary": "While popular optimization methods such as SGD, AdamW, and Lion depend on\nsteepest descent updates in either $\\ell_2$ or $\\ell_\\infty$ norms, there\nremains a critical gap in handling the non-Euclidean structure observed in\nmodern deep networks training. In this work, we address this need by\nintroducing a new accelerated $\\ell_p$ steepest descent algorithm, called\nStacey, which uses interpolated primal-dual iterate sequences to effectively\nnavigate non-Euclidean smooth optimization tasks. In addition to providing\nnovel theoretical guarantees for the foundations of our algorithm, we\nempirically compare our approach against these popular methods on tasks\nincluding image classification and language model (LLM) pretraining,\ndemonstrating both faster convergence and higher final accuracy. We further\nevaluate different values of $p$ across various models and datasets,\nunderscoring the importance and efficiency of non-Euclidean approaches over\nstandard Euclidean methods. Code can be found at\nhttps://github.com/xinyuluo8561/Stacey .", "AI": {"tldr": "\u5f15\u5165\u4e86\u65b0\u7684\u52a0\u901f $\\ell_p$ \u6700\u901f\u4e0b\u964d\u7b97\u6cd5Stacey\uff0c\u5728\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u4f18\u5316\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u6bd4SGD\u3001AdamW\u7b49\u66f4\u9ad8\u7684\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u4f18\u5316\u65b9\u6cd5\u5982SGD\u3001AdamW\u548cLion\u5728\u5904\u7406\u73b0\u4ee3\u6df1\u5ea6\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u7ed3\u6784\u65f6\u5b58\u5728\u91cd\u8981\u7684\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u52a0\u901f $\\ell_p$ \u6700\u901f\u4e0b\u964d\u7b97\u6cd5Stacey\uff0c\u91c7\u7528\u63d2\u503c\u7684\u539f\u59cb-\u5bf9\u5076\u8fed\u4ee3\u5e8f\u5217\u6765\u5bfc\u822a\u975e\u6b27\u51e0\u91cc\u5f97\u5e73\u6ed1\u4f18\u5316\u4efb\u52a1\u3002", "result": "\u901a\u8fc7\u4e0e\u6d41\u884c\u7684\u65b9\u6cd5\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e0a\u7684\u6bd4\u8f83\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86Stacey\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u7684\u66f4\u5feb\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u7cbe\u5ea6\u3002\u4e0d\u540c$p$\u503c\u5bf9\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u7ed3\u679c\u8868\u660e\uff0c\u975e\u6b27\u51e0\u91cc\u5f97\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u548c\u6548\u7387\u9ad8\u4e8e\u6807\u51c6\u6b27\u51e0\u91cc\u5f97\u65b9\u6cd5\u3002", "conclusion": "\u4e0e\u73b0\u6709\u7684\u4f18\u5316\u7b97\u6cd5\u76f8\u6bd4\uff0cStacey\u5728\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u4f18\u5316\u4efb\u52a1\u4e0a\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u7cbe\u5ea6\u3002"}}
{"id": "2506.07217", "pdf": "https://arxiv.org/pdf/2506.07217", "abs": "https://arxiv.org/abs/2506.07217", "authors": ["Zihan Deng", "Changyu Du", "Stavros Nousias", "Andr\u00e9 Borrmann"], "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents", "categories": ["cs.AI"], "comment": "ICML 2025 Workshop on Computer Use Agents", "summary": "Existing computer-use agents primarily focus on general-purpose desktop\nautomation tasks, with limited exploration of their application in highly\nspecialized domains. In particular, the 3D building modeling process in the\nArchitecture, Engineering, and Construction (AEC) sector involves open-ended\ndesign tasks and complex interaction patterns within Building Information\nModeling (BIM) authoring software, which has yet to be thoroughly addressed by\ncurrent studies. In this paper, we propose BIMgent, an agentic framework\npowered by multimodal large language models (LLMs), designed to enable\nautonomous building model authoring via graphical user interface (GUI)\noperations. BIMgent automates the architectural building modeling process,\nincluding multimodal input for conceptual design, planning of software-specific\nworkflows, and efficient execution of the authoring GUI actions. We evaluate\nBIMgent on real-world building modeling tasks, including both text-based\nconceptual design generation and reconstruction from existing building design.\nThe design quality achieved by BIMgent was found to be reasonable. Its\noperations achieved a 32% success rate, whereas all baseline models failed to\ncomplete the tasks (0% success rate). Results demonstrate that BIMgent\neffectively reduces manual workload while preserving design intent,\nhighlighting its potential for practical deployment in real-world architectural\nmodeling scenarios.", "AI": {"tldr": "BIMgent\u662f\u4e00\u4e2a\u7528\u4e8e3D\u5efa\u7b51\u5efa\u6a21\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u8bbe\u8ba1\u610f\u56fe\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u624b\u5de5\u5de5\u4f5c\u91cf\uff0c\u6210\u529f\u7387\u4e3a32%\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u7528\u684c\u9762\u81ea\u52a8\u5316\u4efb\u52a1\u4e0a\uff0c\u800c\u5728\u5efa\u7b51\u4fe1\u606f\u5efa\u6a21\u8f6f\u4ef6\u4e2d\u76843D\u5efa\u6a21\u8fc7\u7a0b\u4e2d\u6d89\u53ca\u5f00\u653e\u6027\u8bbe\u8ba1\u4efb\u52a1\u548c\u590d\u6742\u4ea4\u4e92\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u9886\u57df\u5e94\u7528\u63a2\u7d22\u5c1a\u672a\u5b8c\u5168\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684agentic\u6846\u67b6\uff0c\u5373BIMgent\uff0c\u53ef\u4ee5\u901a\u8fc7\u56fe\u5f62\u7528\u6237\u754c\u9762\u5b9e\u73b0\u81ea\u4e3b\u7684\u5efa\u7b51\u6a21\u578b\u521b\u4f5c\uff0c\u5305\u62ec\u6982\u5ff5\u8bbe\u8ba1\u3001\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u7a0b\u89c4\u5212\u548c\u56fe\u5f62\u7528\u6237\u754c\u9762\u64cd\u4f5c\u7684\u6267\u884c\u3002", "result": "\u5728\u5b9e\u9645\u5efa\u7b51\u5efa\u6a21\u4efb\u52a1\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0cBIMgent\u5728\u6587\u672c\u4e3a\u57fa\u7840\u7684\u6982\u5ff5\u8bbe\u8ba1\u751f\u6210\u548c\u73b0\u6709\u5efa\u7b51\u8bbe\u8ba1\u91cd\u6784\u65b9\u9762\u5747\u8868\u73b0\u51fa\u5408\u7406\u7684\u8bbe\u8ba1\u8d28\u91cf\uff0c\u5176\u64cd\u4f5c\u8fbe\u5230\u4e8632%\u7684\u6210\u529f\u7387\uff0c\u800c\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u5728\u4efb\u52a1\u4e0a\u5747\u672a\u6210\u529f\uff080%\u6210\u529f\u7387\uff09\u3002", "conclusion": "BIMgent\u901a\u8fc7\u81ea\u52a8\u5316\u7b56\u7565\u663e\u8457\u964d\u4f4e\u4e86\u5efa\u7b51\u5efa\u6a21\u8fc7\u7a0b\u4e2d\u7684\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bbe\u8ba1\u610f\u56fe\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5efa\u7b51\u5efa\u6a21\u573a\u666f\u4e2d\u90e8\u7f72\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.06844", "pdf": "https://arxiv.org/pdf/2506.06844", "abs": "https://arxiv.org/abs/2506.06844", "authors": ["Naibin Gu", "Peng Fu", "Xiyu Liu", "Ke Ma", "Zheng Lin", "Weiping Wang"], "title": "Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Parameter-efficient fine-tuning (PEFT) has become a common method for\nfine-tuning large language models, where a base model can serve multiple users\nthrough PEFT module switching. To enhance user experience, base models require\nperiodic updates. However, once updated, PEFT modules fine-tuned on previous\nversions often suffer substantial performance degradation on newer versions.\nRe-tuning these numerous modules to restore performance would incur significant\ncomputational costs. Through a comprehensive analysis of the changes that occur\nduring base model updates, we uncover an interesting phenomenon: continual\ntraining primarily affects task-specific knowledge stored in Feed-Forward\nNetworks (FFN), while having less impact on the task-specific pattern in the\nAttention mechanism. Based on these findings, we introduce Trans-PEFT, a novel\napproach that enhances the PEFT module by focusing on the task-specific pattern\nwhile reducing its dependence on certain knowledge in the base model. Further\ntheoretical analysis supports our approach. Extensive experiments across 7 base\nmodels and 12 datasets demonstrate that Trans-PEFT trained modules can maintain\nperformance on updated base models without re-tuning, significantly reducing\nmaintenance overhead in real-world applications.", "AI": {"tldr": "Trans-PEFT\u65b9\u6cd5\u6539\u8fdb\u4e86PEFT\u6a21\u5757\uff0c\u4f7f\u5176\u5728\u66f4\u65b0\u540e\u7684\u57fa\u7840\u6a21\u578b\u4e0a\u4fdd\u6301\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u91cd\u65b0\u8c03\u6574\u7684\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u66f4\u65b0\u57fa\u7840\u6a21\u578b\u540e\uff0cPEFT\u6a21\u5757\u5728\u6027\u80fd\u4e0a\u51fa\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u5bfb\u627e\u65b9\u6cd5\u4fdd\u6301\u9ad8\u6548\u6027\u80fd\u800c\u4e0d\u91cd\u65b0\u8c03\u6574\u3002", "method": "\u901a\u8fc7\u5206\u6790\u57fa\u7840\u6a21\u578b\u66f4\u65b0\u8fc7\u7a0b\u7684\u53d8\u5316\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u96c6\u4e2d\u4e8e\u4efb\u52a1\u7279\u5b9a\u6a21\u5f0f\u7684\u65b9\u6cd5Trans-PEFT\uff0c\u51cf\u5c11\u4e86\u5bf9\u57fa\u7840\u6a21\u578b\u7279\u5b9a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "result": "Trans-PEFT\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u7840\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u5728\u4e0d\u9700\u91cd\u65b0\u8c03\u6574\u7684\u60c5\u51b5\u4e0b\uff0c\u4fdd\u6301\u6027\u80fd\u5e76\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u3002", "conclusion": "Trans-PEFT\u65b9\u6cd5\u80fd\u591f\u5728\u66f4\u65b0\u540e\u7684\u57fa\u7840\u6a21\u578b\u4e2d\u4fdd\u6301PEFT\u6a21\u5757\u7684\u6027\u80fd\uff0c\u51cf\u5c0f\u4e86\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u7684\u6d88\u8017\u3002"}}
{"id": "2506.06632", "pdf": "https://arxiv.org/pdf/2506.06632", "abs": "https://arxiv.org/abs/2506.06632", "authors": ["Shubham Parashar", "Shurui Gui", "Xiner Li", "Hongyi Ling", "Sushil Vemuri", "Blake Olson", "Eric Li", "Yu Zhang", "James Caverlee", "Dileep Kalathil", "Shuiwang Ji"], "title": "Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We aim to improve the reasoning capabilities of language models via\nreinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1\nhave demonstrated reasoning abilities on mathematical and coding tasks.\nHowever, prior studies suggest that using RL alone to improve reasoning on\ninherently difficult tasks is less effective. Here, we draw inspiration from\ncurriculum learning and propose to schedule tasks from easy to hard (E2H),\nallowing LLMs to build reasoning skills gradually. Our method is termed E2H\nReasoner. Empirically, we observe that, although easy tasks are important\ninitially, fading them out through appropriate scheduling is essential in\npreventing overfitting. Theoretically, we establish convergence guarantees for\nE2H Reasoner within an approximate policy iteration framework. We derive\nfinite-sample complexity bounds and show that when tasks are appropriately\ndecomposed and conditioned, learning through curriculum stages requires fewer\ntotal samples than direct learning. Experiments across multiple domains show\nthat E2H Reasoner significantly improves the reasoning ability of small LLMs\n(1.5B to 3B), which otherwise struggle when trained with vanilla RL alone,\nhighlighting the effectiveness of our method.", "AI": {"tldr": "\u901a\u8fc7\u4ece\u6613\u5230\u96be\u7684\u4efb\u52a1\u8c03\u5ea6\u7b56\u7565\u6765\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u8d85\u8d8a\u4f20\u7edfRL\u65b9\u6cd5\u3002", "motivation": "\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u662f\u5173\u952e\u3002\u4f20\u7edfRL\u65b9\u6cd5\u5728\u5904\u7406\u96be\u5ea6\u5927\u7684\u4efb\u52a1\u65f6\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u65b0\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4ece\u6613\u5230\u96be\u7684\u4efb\u52a1\u8c03\u5ea6\u65b9\u6cd5(E2H)\uff0c\u7ed3\u5408\u589e\u5f3a\u5b66\u4e60\u548c\u8bfe\u7a0b\u5b66\u4e60\u4ee5\u4f18\u5316\u63a8\u7406\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u8bfe\u7a0b\u8c03\u5ea6\u4ee5\u51cf\u5c11\u8fc7\u62df\u5408\uff0c\u5b9e\u9a8c\u8868\u660e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "E2H Reasoner\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u96be\u5ea6\u8f83\u9ad8\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u6bd4\u4f20\u7edfRL\u65b9\u6cd5\u9700\u8981\u66f4\u5c11\u7684\u6837\u672c\u3002"}}
{"id": "2506.07223", "pdf": "https://arxiv.org/pdf/2506.07223", "abs": "https://arxiv.org/abs/2506.07223", "authors": ["Yangqing Zheng", "Shunqi Mao", "Dingxin Zhang", "Weidong Cai"], "title": "LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments", "categories": ["cs.AI"], "comment": "Accepted by the CVPR 2025 Embodied AI Workshop", "summary": "In the realm of embodied intelligence, the evolution of large language models\n(LLMs) has markedly enhanced agent decision making. Consequently, researchers\nhave begun exploring agent performance in dynamically changing high-risk\nscenarios, i.e., fire, flood, and wind scenarios in the HAZARD benchmark. Under\nthese extreme conditions, the delay in decision making emerges as a crucial yet\ninsufficiently studied issue. We propose a Time Conversion Mechanism (TCM) that\ntranslates inference delays in decision-making into equivalent simulation\nframes, thus aligning cognitive and physical costs under a single FPS-based\nmetric. By extending HAZARD with Respond Latency (RL) and Latency-to-Action\nRatio (LAR), we deliver a fully latency-aware evaluation protocol. Moreover, we\npresent the Rapid-Reflex Async-Reflect Agent (RRARA), which couples a\nlightweight LLM-guided feedback module with a rule-based agent to enable\nimmediate reactive behaviors and asynchronous reflective refinements in situ.\nExperiments on HAZARD show that RRARA substantially outperforms existing\nbaselines in latency-sensitive scenarios.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u548c\u4ee3\u7406\u6a21\u578bRRARA\uff0c\u4ee5\u89e3\u51b3\u9ad8\u98ce\u9669\u52a8\u6001\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u5ef6\u8fdf\u95ee\u9898\uff0c\u62a5\u544a\u663e\u793aRRARA\u5728\u5ef6\u8fdf\u654f\u611f\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u63a2\u8ba8\u5728\u9ad8\u98ce\u9669\u52a8\u6001\u73af\u5883\u4e0b\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5904\u7406\u51b3\u7b56\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u65f6\u95f4\u8f6c\u6362\u673a\u5236\uff08TCM\uff09\u548c\u6269\u5c55\u7684HAZARD\u8bc4\u4f30\u534f\u8bae\uff0c\u4f7f\u5f97\u8ba4\u77e5\u548c\u7269\u7406\u6210\u672c\u5728\u5355\u4e00FPS\u57fa\u7840\u6307\u6807\u4e0b\u5bf9\u9f50\u3002\u5f15\u5165\u5feb\u901f\u53cd\u5c04\u5f02\u6b65\u53cd\u601d\u4ee3\u7406\uff08RRARA\uff09\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7LLM\u5f15\u5bfc\u7684\u53cd\u9988\u6a21\u5757\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u4ee3\u7406\u3002", "result": "RRARA\u5728\u5ef6\u8fdf\u654f\u611f\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u548c\u4ee3\u7406\u6a21\u578bRRARA\uff0c\u5728\u9ad8\u98ce\u9669\u52a8\u6001\u573a\u666f\u4e0b\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.06877", "pdf": "https://arxiv.org/pdf/2506.06877", "abs": "https://arxiv.org/abs/2506.06877", "authors": ["Jiaxing Guo", "Wenjie Yang", "Shengzhong Zhang", "Tongshan Xu", "Lun Du", "Da Zheng", "Zengfeng Huang"], "title": "Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Outcome-rewarded Large Language Models (LLMs) have demonstrated remarkable\nsuccess in mathematical problem-solving. However, this success often masks a\ncritical issue: models frequently achieve correct answers through fundamentally\nunsound reasoning processes, a phenomenon indicative of reward hacking. We\nintroduce MathOlympiadEval, a new dataset with fine-grained annotations, which\nreveals a significant gap between LLMs' answer correctness and their low\nprocess correctness. Existing automated methods like LLM-as-a-judge struggle to\nreliably detect these reasoning flaws. To address this, we propose\nParaStepVerifier, a novel methodology for meticulous, step-by-step verification\nof mathematical solutions. ParaStepVerifier identifies incorrect reasoning\nsteps. Empirical results demonstrate that ParaStepVerifier substantially\nimproves the accuracy of identifying flawed solutions compared to baselines,\nespecially for complex, multi-step problems. This offers a more robust path\ntowards evaluating and training LLMs with genuine mathematical reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u5177\u5907\u771f\u6b63\u89c4\u5219\u63a8\u7406\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5ParaStepVerifier\uff0c\u901a\u8fc7\u9010\u6b65\u9a8c\u8bc1\u6570\u5b66\u89e3\u7b54\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc6\u522b\u9519\u8bef\u89e3\u7b54\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e0a\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6210\u529f\uff0c\u4f46\u8fd9\u79cd\u6210\u529f\u5f80\u5f80\u63a9\u76d6\u4e86\u6a21\u578b\u901a\u8fc7\u57fa\u672c\u4e0d\u5408\u7406\u7684\u63a8\u7406\u8fc7\u7a0b\u83b7\u5f97\u6b63\u786e\u7b54\u6848\u7684\u5173\u952e\u95ee\u9898\uff0c\u8fd9\u662f\u4e00\u79cd\u5956\u52b1\u673a\u5236\u6ee5\u7528\u7684\u73b0\u8c61\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aParaStepVerifier\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ed4\u7ec6\u7684\u9010\u6b65\u9a8c\u8bc1\u6570\u5b66\u89e3\u7b54\uff0c\u4ee5\u8bc6\u522b\u4e0d\u6b63\u786e\u7684\u63a8\u7406\u6b65\u9aa4\u3002", "result": "ParaStepVerifier\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u8bc6\u522b\u6709\u7f3a\u9677\u7684\u89e3\u7b54\u65b9\u9762\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "ParaStepVerifier\u80fd\u591f\u663e\u8457\u63d0\u5347\u8bc6\u522b\u9519\u8bef\u89e3\u7b54\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7684\u591a\u6b65\u9aa4\u95ee\u9898\u4e0a\u3002"}}
{"id": "2506.06633", "pdf": "https://arxiv.org/pdf/2506.06633", "abs": "https://arxiv.org/abs/2506.06633", "authors": ["Chi-Sheng Chen"], "title": "Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Recent advancements in quantum machine learning have shown promise in\nenhancing classical neural network architectures, particularly in domains\ninvolving complex, high-dimensional data. Building upon prior work in temporal\nsequence modeling, this paper introduces Vision-QRWKV, a hybrid\nquantum-classical extension of the Receptance Weighted Key Value (RWKV)\narchitecture, applied for the first time to image classification tasks. By\nintegrating a variational quantum circuit (VQC) into the channel mixing\ncomponent of RWKV, our model aims to improve nonlinear feature transformation\nand enhance the expressive capacity of visual representations.\n  We evaluate both classical and quantum RWKV models on a diverse collection of\n14 medical and standard image classification benchmarks, including MedMNIST\ndatasets, MNIST, and FashionMNIST. Our results demonstrate that the\nquantum-enhanced model outperforms its classical counterpart on a majority of\ndatasets, particularly those with subtle or noisy class distinctions (e.g.,\nChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first\nsystematic application of quantum-enhanced RWKV in the visual domain, offering\ninsights into the architectural trade-offs and future potential of quantum\nmodels for lightweight and efficient vision tasks.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u6a21\u578bVision-QRWKV\uff0c\u5e76\u572814\u4e2a\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u8bc4\u4f30\u5176\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u91cf\u5b50\u589e\u5f3a\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5fae\u5999\u6216\u566a\u97f3\u8f83\u5927\u7684\u7c7b\u522b\u65f6\u3002", "motivation": "\u91cf\u5b50\u673a\u5b66\u4e60\u5728\u5904\u7406\u590d\u6742\u9ad8\u7ef4\u6570\u636e\u65b9\u9762\u663e\u793a\u51fa\u4e86\u6f5c\u529b\u3002\u672c\u7814\u7a76\u65e8\u5728\u8fdb\u4e00\u6b65\u5c06\u91cf\u5b50\u6280\u672f\u5e94\u7528\u5230\u89c6\u89c9\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4ee5\u63d0\u5347\u975e\u7ebf\u6027\u7279\u5f81\u8f6c\u6362\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u96c6\u6210\u5230RWKV\u6a21\u578b\u7684\u901a\u9053\u6df7\u5408\u7ec4\u4ef6\u4e2d\uff0c\u5e76\u5bf9\u6bd4\u7ecf\u5178\u7684RWKV\u6a21\u578b\u3002", "result": "\u91cf\u5b50\u589e\u5f3a\u6a21\u578b\u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u5fae\u5999\u6216\u566a\u58f0\u7c7b\u533a\u5206\u7684\u6570\u636e\u96c6\u4e0a\u3002", "conclusion": "\u91cf\u5b50\u589e\u5f3aRWKV\u6a21\u578b\u5728\u89c6\u89c9\u9886\u57df\u7684\u5e94\u7528\u9996\u6b21\u5f97\u5230\u7cfb\u7edf\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u91cf\u5b50\u6a21\u578b\u5728\u8f7b\u91cf\u7ea7\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u67b6\u6784\u6743\u8861\u548c\u672a\u6765\u6f5c\u529b\u3002"}}
{"id": "2506.07255", "pdf": "https://arxiv.org/pdf/2506.07255", "abs": "https://arxiv.org/abs/2506.07255", "authors": ["Jake Tuero", "Michael Buro", "Levi H. S. Lelis"], "title": "Subgoal-Guided Policy Heuristic Search with Learned Subgoals", "categories": ["cs.AI"], "comment": "Accepted to ICML-25", "summary": "Policy tree search is a family of tree search algorithms that use a policy to\nguide the search. These algorithms provide guarantees on the number of\nexpansions required to solve a given problem that are based on the quality of\nthe policy. While these algorithms have shown promising results, the process in\nwhich they are trained requires complete solution trajectories to train the\npolicy. Search trajectories are obtained during a trial-and-error search\nprocess. When the training problem instances are hard, learning can be\nprohibitively costly, especially when starting from a randomly initialized\npolicy. As a result, search samples are wasted in failed attempts to solve\nthese hard instances. This paper introduces a novel method for learning\nsubgoal-based policies for policy tree search algorithms. The subgoals and\npolicies conditioned on subgoals are learned from the trees that the search\nexpands while attempting to solve problems, including the search trees of\nfailed attempts. We empirically show that our policy formulation and training\nmethod improve the sample efficiency of learning a policy and heuristic\nfunction in this online setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u5b50\u76ee\u6807\u6765\u63d0\u9ad8\u653f\u7b56\u6811\u641c\u7d22\u7b97\u6cd5\u7684\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u653f\u7b56\u6811\u641c\u7d22\u7b97\u6cd5\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9700\u8981\u5b8c\u6574\u7684\u89e3\u51b3\u65b9\u6848\u8f68\u8ff9\uff0c\u8fd9\u5bfc\u81f4\u5728\u8f83\u96be\u7684\u5b9e\u4f8b\u4e2d\u5b66\u4e60\u6210\u672c\u975e\u5e38\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u968f\u673a\u521d\u59cb\u5316\u653f\u7b56\u65f6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5b50\u76ee\u6807\u653f\u7b56\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u653f\u7b56\u6811\u641c\u7d22\u7b97\u6cd5\u3002\u5b50\u76ee\u6807\u53ca\u5176\u76f8\u5173\u653f\u7b56\u662f\u4ece\u641c\u7d22\u6269\u5c55\u7684\u6811\u4e2d\u5b66\u4e60\u7684\uff0c\u5305\u62ec\u5931\u8d25\u5c1d\u8bd5\u7684\u641c\u7d22\u6811\u3002", "result": "\u7ecf\u8fc7\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u672c\u6587\u63d0\u51fa\u7684\u653f\u7b56\u5236\u5b9a\u548c\u8bad\u7ec3\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5728\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u5b66\u4e60\u4e00\u4e2a\u653f\u7b56\u548c\u542f\u53d1\u51fd\u6570\u7684\u6837\u672c\u6548\u7387\u3002", "conclusion": "\u4f7f\u7528\u5b50\u76ee\u6807\u53ef\u4ee5\u6539\u5584\u653f\u7b56\u6811\u641c\u7d22\u7b97\u6cd5\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002"}}
{"id": "2506.06887", "pdf": "https://arxiv.org/pdf/2506.06887", "abs": "https://arxiv.org/abs/2506.06887", "authors": ["Ziheng Qiao", "Houquan Zhou", "Zhenghua Li"], "title": "Mixture of Small and Large Models for Chinese Spelling Check", "categories": ["cs.CL"], "comment": null, "summary": "In the era of large language models (LLMs), the Chinese Spelling Check (CSC)\ntask has seen various LLM methods developed, yet their performance remains\nunsatisfactory. In contrast, fine-tuned BERT-based models, relying on\nhigh-quality in-domain data, show excellent performance but suffer from edit\npattern overfitting. This paper proposes a novel dynamic mixture approach that\neffectively combines the probability distributions of small models and LLMs\nduring the beam search decoding phase, achieving a balanced enhancement of\nprecise corrections from small models and the fluency of LLMs. This approach\nalso eliminates the need for fine-tuning LLMs, saving significant time and\nresources, and facilitating domain adaptation. Comprehensive experiments\ndemonstrate that our mixture approach significantly boosts error correction\ncapabilities, achieving state-of-the-art results across multiple datasets. Our\ncode is available at https://github.com/zhqiao-nlp/MSLLM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u5c0f\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e2d\u6587\u62fc\u5199\u68c0\u67e5\u4efb\u52a1\u7684\u7ea0\u9519\u80fd\u529b\uff0c\u5e76\u8282\u7701\u4e86\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2d\u6587\u62fc\u5199\u68c0\u67e5\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0d\u5c3d\u5982\u4eba\u610f\uff0c\u800c\u7ecf\u8fc7\u5fae\u8c03\u7684\u57fa\u4e8eBERT\u7684\u5c0f\u6a21\u578b\u5728\u7ec6\u5206\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5bb9\u6613\u8fc7\u62df\u5408\u4e8e\u7f16\u8f91\u6a21\u5f0f\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u4ee5\u540c\u65f6\u63d0\u5347\u5c0f\u6a21\u578b\u7684\u7ea0\u9519\u7cbe\u5ea6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u7545\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u52a8\u6001\u6df7\u5408\u65b9\u6cd5\u5728\u675f\u641c\u7d22\u89e3\u7801\u9636\u6bb5\u7ed3\u5408\u4e86\u5c0f\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6982\u7387\u5206\u5e03\uff0c\u5229\u7528\u5c0f\u6a21\u578b\u7684\u7cbe\u786e\u7ea0\u9519\u80fd\u529b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u7545\u6027\uff0c\u4ece\u800c\u907f\u514d\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u672c\u6587\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u65e0\u9700\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8282\u7701\u4e86\u5927\u91cf\u65f6\u95f4\u548c\u8d44\u6e90\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u675f\u641c\u7d22\u89e3\u7801\u9636\u6bb5\u6709\u6548\u7ed3\u5408\u5c0f\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6982\u7387\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7ea0\u9519\u80fd\u529b\u7684\u663e\u8457\u589e\u5f3a\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06637", "pdf": "https://arxiv.org/pdf/2506.06637", "abs": "https://arxiv.org/abs/2506.06637", "authors": ["Olimjon Toirov", "Wei Yu"], "title": "Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.SP"], "comment": "10 pages, 3 figures, 2025 2nd International Conference on Digital\n  Society and Artificial Intelligence (DSAI 2025), Conference dates: May 23-25,\n  2025", "summary": "Non-Intrusive Load Monitoring (NILM) identifies the operating status and\nenergy consumption of each electrical device in the circuit by analyzing the\nelectrical signals at the bus, which is of great significance for smart power\nmanagement. However, the complex and changeable load combinations and\napplication environments lead to the challenges of poor feature robustness and\ninsufficient model generalization of traditional NILM methods. To this end,\nthis paper proposes a new non-intrusive load monitoring method that integrates\n\"image load signature\" and continual learning. This method converts\nmulti-dimensional power signals such as current, voltage, and power factor into\nvisual image load feature signatures, and combines deep convolutional neural\nnetworks to realize the identification and classification of multiple devices;\nat the same time, self-supervised pre-training is introduced to improve feature\ngeneralization, and continual online learning strategies are used to overcome\nmodel forgetting to adapt to the emergence of new loads. This paper conducts a\nlarge number of experiments on high-sampling rate load datasets, and compares a\nvariety of existing methods and model variants. The results show that the\nproposed method has achieved significant improvements in recognition accuracy.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u7ed3\u5408\u56fe\u50cf\u7279\u5f81\u4e0e\u6301\u7eed\u5b66\u4e60\u7684\u65b0NILM\u65b9\u6cd5\uff0c\u5927\u5e45\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u6027\u3002", "motivation": "\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u76d1\u63a7 (NILM) \u5bf9\u667a\u80fd\u7535\u529b\u7ba1\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u4f20\u7edfNILM\u65b9\u6cd5\u9762\u4e34\u7279\u5f81\u9c81\u68d2\u6027\u5dee\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u201c\u56fe\u50cf\u8d1f\u8f7d\u7279\u5f81\u201d\u548c\u6301\u7eed\u5b66\u4e60\u76f8\u7ed3\u5408\u7684\u975e\u4fb5\u5165\u5f0f\u8d1f\u8f7d\u76d1\u63a7\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u8bc6\u522b\u548c\u5206\u7c7b\u591a\u79cd\u8bbe\u5907\uff0c\u5e76\u5f15\u5165\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u548c\u6301\u7eed\u5728\u7ebf\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728\u9ad8\u91c7\u6837\u7387\u8d1f\u8f7d\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u63d0\u8bae\u7684\u65b9\u6cd5\u5728\u8bc6\u522b\u51c6\u786e\u6027\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5c06\u591a\u7ef4\u7535\u529b\u4fe1\u53f7\u8f6c\u5316\u4e3a\u89c6\u89c9\u56fe\u50cf\u8d1f\u8f7d\u7279\u5f81\u5e76\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8bbe\u5907\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNILM\u65b9\u6cd5\u7684\u7f3a\u9677\u3002"}}
{"id": "2506.07390", "pdf": "https://arxiv.org/pdf/2506.07390", "abs": "https://arxiv.org/abs/2506.07390", "authors": ["Xin-Cheng Wen", "Yijun Yang", "Cuiyun Gao", "Yang Xiao", "Deheng Ye"], "title": "Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data", "categories": ["cs.AI", "cs.SE"], "comment": "Accepted by ACL 2025 Findings", "summary": "Large language models (LLMs) demonstrate considerable proficiency in numerous\ncoding-related tasks; however, their capabilities in detecting software\nvulnerabilities remain limited. This limitation primarily stems from two\nfactors: (1) the absence of reasoning data related to vulnerabilities, which\nhinders the models' ability to capture underlying vulnerability patterns; and\n(2) their focus on learning semantic representations rather than the reason\nbehind them, thus failing to recognize semantically similar vulnerability\nsamples. Furthermore, the development of LLMs specialized in vulnerability\ndetection is challenging, particularly in environments characterized by the\nscarcity of high-quality datasets. In this paper, we propose a novel framework\nReVD that excels at mining vulnerability patterns through reasoning data\nsynthesizing and vulnerability-specific preference optimization. Specifically,\nwe construct forward and backward reasoning processes for vulnerability and\ncorresponding fixed code, ensuring the synthesis of high-quality reasoning\ndata. Moreover, we design the triplet supervised fine-tuning followed by\ncurriculum online preference optimization for enabling ReVD to better\nunderstand vulnerability patterns. The extensive experiments conducted on\nPrimeVul and SVEN datasets demonstrate that ReVD sets new state-of-the-art for\nLLM-based software vulnerability detection, e.g., 12.24\\%-22.77\\% improvement\nin the accuracy. The source code and data are available at\nhttps://github.com/Xin-Cheng-Wen/PO4Vul.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aReVD\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u6570\u636e\u5408\u6210\u548c\u504f\u597d\u4f18\u5316\u6765\u63d0\u9ad8LLM\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u83b7\u5f97\u663e\u8457\u7cbe\u5ea6\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u8f6f\u4ef6\u6f0f\u6d1e\u4e0a\u7684\u80fd\u529b\u6709\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u7f3a\u4e4f\u6f0f\u6d1e\u76f8\u5173\u7684\u63a8\u7406\u6570\u636e\u548c\u8fc7\u4e8e\u5173\u6ce8\u8bed\u4e49\u8868\u793a\u800c\u5ffd\u7565\u6f0f\u6d1e\u6a21\u5f0f\u3002", "method": "ReVD\u6846\u67b6\u901a\u8fc7\u63a8\u7406\u6570\u636e\u5408\u6210\u548c\u6f0f\u6d1e\u7279\u5b9a\u7684\u504f\u597d\u4f18\u5316\u6765\u6316\u6398\u6f0f\u6d1e\u6a21\u5f0f\uff0c\u5305\u62ec\u6784\u5efa\u6f0f\u6d1e\u53ca\u4fee\u590d\u4ee3\u7801\u7684\u6b63\u53cd\u5411\u63a8\u7406\u8fc7\u7a0b\u3001\u9ad8\u8d28\u91cf\u63a8\u7406\u6570\u636e\u5408\u6210\uff0c\u4ee5\u53ca\u4e09\u91cd\u76d1\u7763\u5fae\u8c03\u548c\u8bfe\u7a0b\u5728\u7ebf\u504f\u597d\u4f18\u5316\u3002", "result": "ReVD\u6846\u67b6\u5728PrimeVul\u548cSVEN\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u8457\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u7387\uff0c\u63d0\u5347\u5e45\u5ea6\u8fbe12.24%-22.77%\u3002", "conclusion": "ReVD\u5728LLM\u57fa\u7840\u4e0a\u4e3a\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u8bbe\u7acb\u4e86\u65b0\u6807\u6746\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06888", "pdf": "https://arxiv.org/pdf/2506.06888", "abs": "https://arxiv.org/abs/2506.06888", "authors": ["Hamid Mojarad", "Kevin Tang"], "title": "Automatic Speech Recognition of African American English: Lexical and Contextual Effects", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "submitted to Interspeech 2025", "summary": "Automatic Speech Recognition (ASR) models often struggle with the phonetic,\nphonological, and morphosyntactic features found in African American English\n(AAE). This study focuses on two key AAE variables: Consonant Cluster Reduction\n(CCR) and ING-reduction. It examines whether the presence of CCR and\nING-reduction increases ASR misrecognition. Subsequently, it investigates\nwhether end-to-end ASR systems without an external Language Model (LM) are more\ninfluenced by lexical neighborhood effect and less by contextual predictability\ncompared to systems with an LM. The Corpus of Regional African American\nLanguage (CORAAL) was transcribed using wav2vec 2.0 with and without an LM. CCR\nand ING-reduction were detected using the Montreal Forced Aligner (MFA) with\npronunciation expansion. The analysis reveals a small but significant effect of\nCCR and ING on Word Error Rate (WER) and indicates a stronger presence of\nlexical neighborhood effect in ASR systems without LMs.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cAAE\u4e2d\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\u5f71\u54cdASR\u7684\u8bc6\u522b\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u65e0\u8bed\u8a00\u6a21\u578bASR\u7cfb\u7edf\u53d7\u8bcd\u6c47\u90bb\u8fd1\u6548\u5e94\u5f71\u54cd\u66f4\u5927\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u4e86\u89e3\u975e\u6d32\u88d4\u7f8e\u56fd\u82f1\u8bed\u7684\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\u662f\u5426\u5bf9ASR\u7684\u8bef\u8bc6\u522b\u6709\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5bf9\u4e0d\u4f7f\u7528\u5916\u90e8\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aefASR\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u91c7\u7528CORAAL\u8bed\u6599\u5e93\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528wav2vec 2.0\u6a21\u578b\u5728\u6709\u548c\u6ca1\u6709\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u7684\u6761\u4ef6\u4e0b\u5bf9\u6570\u636e\u8fdb\u884c\u8f6c\u5f55\uff0c\u901a\u8fc7\u8499\u7279\u5229\u5c14\u5f3a\u5236\u5bf9\u9f50\u5668\uff08MFA\uff09\u68c0\u6d4bCCR\u548cING-\u7f29\u51cf\u3002", "result": "\u5b9e\u9a8c\u5206\u6790\u663e\u793a\uff0cCCR\u548cING\u5bf9\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u6709\u663e\u8457\u4f46\u8f83\u5c0f\u7684\u5f71\u54cd\uff0c\u4e14\u6ca1\u6709\u8bed\u8a00\u6a21\u578b\u7684ASR\u7cfb\u7edf\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u8bcd\u6c47\u90bb\u8fd1\u6548\u5e94\u3002", "conclusion": "\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\u5728\u5904\u7406\u975e\u6d32\u88d4\u7f8e\u56fd\u82f1\u8bed\uff08AAE\uff09\u7684\u97f3\u7d20\u3001\u97f3\u97f5\u548c\u5f62\u6001\u53e5\u6cd5\u7279\u5f81\u65f6\u8868\u73b0\u8f83\u5dee\u3002"}}
{"id": "2506.06644", "pdf": "https://arxiv.org/pdf/2506.06644", "abs": "https://arxiv.org/abs/2506.06644", "authors": ["Chong You", "Kan Wu", "Zhipeng Jia", "Lin Chen", "Srinadh Bhojanapalli", "Jiaxian Guo", "Utku Evci", "Jan Wassenberg", "Praneeth Netrapalli", "Jeremiah J. Willcock", "Suvinay Subramanian", "Felix Chern", "Alek Andreev", "Shreya Pathak", "Felix Yu", "Prateek Jain", "David E. Culler", "Henry M. Levy", "Sanjiv Kumar"], "title": "Spark Transformer: Reactivating Sparsity in FFN and Attention", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The discovery of the lazy neuron phenomenon in trained Transformers, where\nthe vast majority of neurons in their feed-forward networks (FFN) are inactive\nfor each token, has spurred tremendous interests in activation sparsity for\nenhancing large model efficiency. While notable progress has been made in\ntranslating such sparsity to wall-time benefits, modern Transformers have moved\naway from the ReLU activation function crucial to this phenomenon. Existing\nefforts on re-introducing activation sparsity often degrade model quality,\nincrease parameter count, complicate or slow down training. Sparse attention,\nthe application of sparse activation to the attention mechanism, often faces\nsimilar challenges.\n  This paper introduces the Spark Transformer, a novel architecture that\nachieves a high level of activation sparsity in both FFN and the attention\nmechanism while maintaining model quality, parameter count, and standard\ntraining procedures. Our method realizes sparsity via top-k masking for\nexplicit control over sparsity level. Crucially, we introduce statistical\ntop-k, a hardware-accelerator-friendly, linear-time approximate algorithm that\navoids costly sorting and mitigates significant training slowdown from standard\ntop-$k$ operators. Furthermore, Spark Transformer reallocates existing FFN\nparameters and attention key embeddings to form a low-cost predictor for\nidentifying activated entries. This design not only mitigates quality loss from\nenforced sparsity, but also enhances wall-time benefit. Pretrained with the\nGemma-2 recipe, Spark Transformer demonstrates competitive performance on\nstandard benchmarks while exhibiting significant sparsity: only 8% of FFN\nneurons are activated, and each token attends to a maximum of 256 tokens. This\nsparsity translates to a 2.5x reduction in FLOPs, leading to decoding wall-time\nspeedups of up to 1.79x on CPU and 1.40x on GPU.", "AI": {"tldr": "Spark Transformer\u662f\u4e00\u79cd\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u5b9e\u73b0\u9ad8\u6c34\u5e73\u6fc0\u6d3b\u7a00\u758f\u6027\u6765\u63d0\u9ad8\u6a21\u578b\u6548\u7387\uff0c\u4fdd\u6301\u8d28\u91cf\u548c\u6027\u80fd\uff0c\u540c\u65f6\u5728CPU\u548cGPU\u4e0a\u5b9e\u73b0\u663e\u8457\u7684\u5899\u65f6\u95f4\u52a0\u901f\u3002", "motivation": "\u53d1\u73b0\u8bad\u7ec3\u540e\u7684Transformer\u4e2d\u61d2\u60f0\u795e\u7ecf\u5143\u73b0\u8c61\uff0c\u5373FFN\u4e2d\u7684\u7edd\u5927\u591a\u6570\u795e\u7ecf\u5143\u5bf9\u6bcf\u4e2atoken\u90fd\u662f\u4e0d\u6d3b\u8dc3\u7684\u3002\u8fd9\u6fc0\u53d1\u4e86\u5bf9\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u5e7f\u6cdb\u5174\u8da3\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u6a21\u578b\u6548\u7387\u3002\u7136\u800c\uff0c\u73b0\u4ee3Transformer\u5df2\u7ecf\u4ece\u5bf9\u8be5\u73b0\u8c61\u81f3\u5173\u91cd\u8981\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\u4e2d\u8131\u79bb\uff0c\u73b0\u6709\u91cd\u65b0\u5f15\u5165\u6fc0\u6d3b\u7a00\u758f\u6027\u7684\u52aa\u529b\u901a\u5e38\u4f1a\u635f\u5bb3\u6a21\u578b\u8d28\u91cf\u3001\u589e\u52a0\u53c2\u6570\u6570\u91cf\u3001\u590d\u6742\u5316\u6216\u51cf\u6162\u8bad\u7ec3\u901f\u5ea6\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u88ab\u79f0\u4e3aSpark Transformer\u7684\u65b0\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u5728FFN\u548c\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u5b9e\u73b0\u9ad8\u6c34\u5e73\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\u6765\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3001\u53c2\u6570\u6570\u91cf\u548c\u6807\u51c6\u8bad\u7ec3\u7a0b\u5e8f\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7top-k\u63a9\u7801\u5b9e\u73b0\u7a00\u758f\u6027\uff0c\u5bf9\u7a00\u758f\u6027\u7ea7\u522b\u8fdb\u884c\u663e\u5f0f\u63a7\u5236\u3002\u7279\u522b\u662f\u5f15\u5165\u4e86\u7edf\u8ba1top-k\uff0c\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u5668\u53cb\u597d\u3001\u7ebf\u6027\u65f6\u95f4\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u6602\u8d35\u7684\u6392\u5e8f\uff0c\u7f13\u89e3\u4e86\u4ece\u6807\u51c6top-k\u7b97\u5b50\u6765\u7684\u663e\u8457\u8bad\u7ec3\u51cf\u901f\u3002\u6b64\u5916\uff0cSpark Transformer\u91cd\u65b0\u5206\u914d\u73b0\u6709\u7684FFN\u53c2\u6570\u548c\u6ce8\u610f\u529b\u5173\u952e\u5d4c\u5165\uff0c\u5f62\u6210\u4e00\u4e2a\u4f4e\u6210\u672c\u9884\u6d4b\u5668\u4ee5\u8bc6\u522b\u6fc0\u6d3b\u6761\u76ee\u3002", "result": "\u53ea\u67098%\u7684FFN\u795e\u7ecf\u5143\u88ab\u6fc0\u6d3b\uff0c\u4e14\u6bcf\u4e2atoken\u6700\u591a\u5173\u6ce8256\u4e2atokens\u3002\u8fd9\u79cd\u7a00\u758f\u6027\u53ef\u4ee5\u8f6c\u5316\u4e3aFLOPs\u51cf\u5c112.5\u500d\uff0c\u5728CPU\u4e0a\u89e3\u7801\u65f6\u5899\u65f6\u95f4\u52a0\u901f\u53ef\u8fbe1.79\u500d\uff0c\u5728GPU\u4e0a\u8fbe\u52301.40\u500d\u3002", "conclusion": "Spark Transformer\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u663e\u8457\u7684\u7a00\u758f\u6027\uff0c\u5e26\u6765\u4e86\u5899\u65f6\u95f4\u6548\u7387\u7684\u63d0\u5347\u3002"}}
{"id": "2506.07411", "pdf": "https://arxiv.org/pdf/2506.07411", "abs": "https://arxiv.org/abs/2506.07411", "authors": ["Ze Yang", "Yihong Jin", "Juntian Liu", "Xinhe Xu"], "title": "An Intelligent Fault Self-Healing Mechanism for Cloud AI Systems via Integration of Large Language Models and Deep Reinforcement Learning", "categories": ["cs.AI"], "comment": "Proceedings of 2025 IEEE 8th International Conference on Advanced\n  Electronic Materials, Computers and Software Engineering (AEMCSE 2025)", "summary": "As the scale and complexity of cloud-based AI systems continue to increase,\nthe detection and adaptive recovery of system faults have become the core\nchallenges to ensure service reliability and continuity. In this paper, we\npropose an Intelligent Fault Self-Healing Mechanism (IFSHM) that integrates\nLarge Language Model (LLM) and Deep Reinforcement Learning (DRL), aiming to\nrealize a fault recovery framework with semantic understanding and policy\noptimization capabilities in cloud AI systems. On the basis of the traditional\nDRL-based control model, the proposed method constructs a two-stage hybrid\narchitecture: (1) an LLM-driven fault semantic interpretation module, which can\ndynamically extract deep contextual semantics from multi-source logs and system\nindicators to accurately identify potential fault modes; (2) DRL recovery\nstrategy optimizer, based on reinforcement learning, learns the dynamic\nmatching of fault types and response behaviors in the cloud environment. The\ninnovation of this method lies in the introduction of LLM for environment\nmodeling and action space abstraction, which greatly improves the exploration\nefficiency and generalization ability of reinforcement learning. At the same\ntime, a memory-guided meta-controller is introduced, combined with\nreinforcement learning playback and LLM prompt fine-tuning strategy, to achieve\ncontinuous adaptation to new failure modes and avoid catastrophic forgetting.\nExperimental results on the cloud fault injection platform show that compared\nwith the existing DRL and rule methods, the IFSHM framework shortens the system\nrecovery time by 37% with unknown fault scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6574\u5408LLM\u548cDRL\u7684\u667a\u80fd\u6545\u969c\u81ea\u6108\u673a\u5236\uff0c\u5927\u5e45\u63d0\u9ad8\u4e91AI\u7cfb\u7edf\u6545\u969c\u6062\u590d\u6548\u7387\u3002", "motivation": "\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u4e91AI\u7cfb\u7edf\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u6311\u6218\uff0c\u5c24\u5176\u662f\u7cfb\u7edf\u6545\u969c\u7684\u68c0\u6d4b\u53ca\u81ea\u9002\u5e94\u6062\u590d\uff0c\u4ee5\u4fdd\u969c\u670d\u52a1\u53ef\u9760\u6027\u548c\u8fde\u7eed\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u548cDRL\u7684\u53cc\u9636\u6bb5\u6df7\u5408\u67b6\u6784\uff0c\u5305\u62ec\u6545\u969c\u8bed\u4e49\u89e3\u6790\u6a21\u5757\u548cDRL\u6062\u590d\u7b56\u7565\u4f18\u5316\u5668\uff0c\u4ee5\u53ca\u5f15\u5165\u8bb0\u5fc6\u5f15\u5bfc\u7684\u5143\u63a7\u5236\u5668\u3002", "result": "\u5728\u4e91\u6545\u969c\u6ce8\u5165\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684DRL\u548c\u89c4\u5219\u65b9\u6cd5\uff0cIFSHM\u6846\u67b6\u5728\u672a\u77e5\u6545\u969c\u573a\u666f\u4e0b\u5c06\u7cfb\u7edf\u6062\u590d\u65f6\u95f4\u7f29\u77ed\u4e8637%\u3002", "conclusion": "IFSHM\u6846\u67b6\u5728\u672a\u77e5\u6545\u969c\u573a\u666f\u4e2d\u80fd\u591f\u663e\u8457\u7f29\u77ed\u7cfb\u7edf\u6062\u590d\u65f6\u95f4\u3002"}}
{"id": "2506.06929", "pdf": "https://arxiv.org/pdf/2506.06929", "abs": "https://arxiv.org/abs/2506.06929", "authors": ["Mikhail Krasitskii", "Grigori Sidorov", "Olga Kolesnikova", "Liliana Chanona Hernandez", "Alexander Gelbukh"], "title": "Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis", "categories": ["cs.CL"], "comment": "6 pages", "summary": "We propose a hybrid approach for multilingual sentiment analysis that\ncombines extractive and abstractive summarization to address the limitations of\nstandalone methods. The model integrates TF-IDF-based extraction with a\nfine-tuned XLM-R abstractive module, enhanced by dynamic thresholding and\ncultural adaptation. Experiments across 10 languages show significant\nimprovements over baselines, achieving 0.90 accuracy for English and 0.84 for\nlow-resource languages. The approach also demonstrates 22% greater\ncomputational efficiency than traditional methods. Practical applications\ninclude real-time brand monitoring and cross-cultural discourse analysis.\nFuture work will focus on optimization for low-resource languages via 8-bit\nquantization.", "AI": {"tldr": "A hybrid method improves multilingual sentiment analysis accuracy and efficiency, with applications in brand monitoring and discourse analysis, achieving 0.90 accuracy for English and 0.84 for low-resource languages.", "motivation": "The motivation is to address the limitations of standalone methods in multilingual sentiment analysis, such as low accuracy and high computational cost.", "method": "The method combines TF-IDF-based extraction with a fine-tuned XLM-R abstractive module, utilizing dynamic thresholding and cultural adaptation.", "result": "Experiments demonstrate significant improvements in accuracy, achieving 0.90 for English and 0.84 for low-resource languages, and a 22% increase in computational efficiency.", "conclusion": "The proposed hybrid approach for multilingual sentiment analysis effectively improves accuracy and computational efficiency compared to traditional methods, showing potential for practical applications such as brand monitoring and discourse analysis."}}
{"id": "2506.06649", "pdf": "https://arxiv.org/pdf/2506.06649", "abs": "https://arxiv.org/abs/2506.06649", "authors": ["Yishan Shen", "Yuyang Ye", "Hui Xiong", "Yong Chen"], "title": "SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by ICML 2025", "summary": "Dynamic treatment regimes (DTRs) are critical to precision medicine,\noptimizing long-term outcomes through personalized, real-time decision-making\nin evolving clinical contexts, but require careful supervision for unsafe\ntreatment risks. Existing efforts rely primarily on clinician-prescribed gold\nstandards despite the absence of a known optimal strategy, and predominantly\nusing structured EHR data without extracting valuable insights from clinical\nnotes, limiting their reliability for treatment recommendations. In this work,\nwe introduce SAFER, a calibrated risk-aware tabular-language recommendation\nframework for DTR that integrates both structured EHR and clinical notes,\nenabling them to learn from each other, and addresses inherent label\nuncertainty by assuming ambiguous optimal treatment solution for deceased\npatients. Moreover, SAFER employs conformal prediction to provide statistical\nguarantees, ensuring safe treatment recommendations while filtering out\nuncertain predictions. Experiments on two publicly available sepsis datasets\ndemonstrate that SAFER outperforms state-of-the-art baselines across multiple\nrecommendation metrics and counterfactual mortality rate, while offering robust\nformal assurances. These findings underscore SAFER potential as a trustworthy\nand theoretically grounded solution for high-stakes DTR applications.", "AI": {"tldr": "SAFER\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u5316EHR\u6570\u636e\u4e0e\u4e34\u5e8a\u7b14\u8bb0\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u52a8\u6001\u6cbb\u7597\u65b9\u6848\u63a8\u8350\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709DTR\u7cfb\u7edf\u4e3b\u8981\u4f9d\u8d56\u4e8e\u7ed3\u6784\u5316EHR\u6570\u636e\u548c\u7f3a\u4e4f\u6700\u4f18\u7b56\u7565\u7684\u533b\u751f\u63a8\u8350\uff0c\u5bfc\u81f4\u5176\u5728\u63a8\u8350\u6cbb\u7597\u65f6\u7684\u53ef\u9760\u6027\u53d7\u5230\u9650\u5236\u3002", "method": "SAFER\u4f7f\u7528\u6821\u51c6\u7684\u98ce\u9669\u611f\u77e5\u8868\u683c-\u8bed\u8a00\u63a8\u8350\u6846\u67b6\uff0c\u5c06\u7ed3\u6784\u5316\u7684EHR\u6570\u636e\u4e0e\u4e34\u5e8a\u7b14\u8bb0\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u969c\u3002", "result": "SAFER\u5728\u4e24\u4e2a\u516c\u5f00\u7684\u8113\u6bd2\u75c7\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5728\u591a\u4e2a\u63a8\u8350\u6307\u6807\u548c\u53cd\u4e8b\u5b9e\u6b7b\u4ea1\u7387\u4e0a\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002", "conclusion": "SAFER\u5728\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u7684\u52a8\u6001\u6cbb\u7597\u65b9\u6848\u5e94\u7528\u4e2d\u3002"}}
{"id": "2506.07418", "pdf": "https://arxiv.org/pdf/2506.07418", "abs": "https://arxiv.org/abs/2506.07418", "authors": ["Arnau Igualde S\u00e1ez", "Lamyae Rhomrasi", "Yusef Ahsini", "Ricardo Vinuesa", "Sergio Hoyas", "Jose P. Garc\u00eda Sabater", "Marius J. Fullana i Alfonso", "J. Alberto Conejero"], "title": "Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests", "categories": ["cs.AI", "68T05, 68T45", "I.2.10; I.2.7"], "comment": "16 pages, 4 figures", "summary": "Multimodal Large Language Models (MLLMs) promise advanced vision language\ncapabilities, yet their effectiveness in visually presented mathematics remains\nunderexplored. This paper analyzes the development and evaluation of MLLMs for\nmathematical problem solving, focusing on diagrams, multilingual text, and\nsymbolic notation. We then assess several models, including GPT 4o, Pixtral,\nQwen VL, Llama 3.2 Vision variants, and Gemini 2.0 Flash in a multilingual\nKangaroo style benchmark spanning English, French, Spanish, and Catalan. Our\nexperiments reveal four key findings. First, overall precision remains moderate\nacross geometry, visual algebra, logic, patterns, and combinatorics: no single\nmodel excels in every topic. Second, while most models see improved accuracy\nwith questions that do not have images, the gain is often limited; performance\nfor some remains nearly unchanged without visual input, indicating\nunderutilization of diagrammatic information. Third, substantial variation\nexists across languages and difficulty levels: models frequently handle easier\nitems but struggle with advanced geometry and combinatorial reasoning. Notably,\nGemini 2.0 Flash achieves the highest precision on image based tasks, followed\nby Qwen VL 2.5 72B and GPT 4o, though none approach human level performance.\nFourth, a complementary analysis aimed at distinguishing whether models reason\nor simply recite reveals that Gemini and GPT 4o stand out for their structured\nreasoning and consistent accuracy. In contrast, Pixtral and Llama exhibit less\nconsistent reasoning, often defaulting to heuristics or randomness when unable\nto align their outputs with the given answer options.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5728\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u8868\u73b0\u4e2d\u7b49\uff0c\u4e14\u5728\u9ad8\u7ea7\u63a8\u7406\u65b9\u9762\u6709\u5f85\u63d0\u9ad8\u3002", "motivation": "\u63a2\u8ba8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u5448\u73b0\u7684\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u56fe\u8868\u3001\u591a\u8bed\u8a00\u6587\u672c\u548c\u7b26\u53f7\u8868\u793a\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8bc4\u4f30\u591a\u4e2aMLLMs\u6a21\u578b\u5728\u591a\u8bed\u8a00Kangaroo\u98ce\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u6d4b\u8bd5\u8bed\u8a00\u5305\u62ec\u82f1\u8bed\u3001\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\uff0c\u4e3b\u8981\u5173\u6ce8\u51e0\u4f55\u3001\u89c6\u89c9\u4ee3\u6570\u3001\u903b\u8f91\u3001\u6a21\u5f0f\u548c\u7ec4\u5408\u5b66\u7b49\u9886\u57df\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u56db\u9879\u4e3b\u8981\u53d1\u73b0\uff1a1. \u603b\u4f53\u7cbe\u5ea6\u5728\u5404\u4e2a\u8bdd\u9898\u4e0a\u8868\u73b0\u4e2d\u7b49\uff0c\u65e0\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u4e3b\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\u30022. \u5728\u7f3a\u5c11\u56fe\u50cf\u7684\u95ee\u9898\u4e0a\uff0c\u5927\u591a\u6570\u6a21\u578b\u51c6\u786e\u6027\u7565\u5fae\u6539\u5584\uff0c\u4f46\u589e\u5e45\u6709\u9650\u30023. \u5b58\u5728\u8bed\u8a00\u548c\u96be\u5ea6\u7ea7\u522b\u5dee\u5f02\uff1a\u6a21\u578b\u5728\u7b80\u5355\u9879\u76ee\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9ad8\u7ea7\u51e0\u4f55\u548c\u7ec4\u5408\u63a8\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\u30024. Gemini 2.0 Flash\u5728\u57fa\u4e8e\u56fe\u50cf\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u597d\uff0c\u5c3d\u7ba1\u6ca1\u6709\u6a21\u578b\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002\u5206\u6790\u8868\u660e\uff0cGemini\u548cGPT 4o\u5728\u7ed3\u6784\u5316\u63a8\u7406\u548c\u4e00\u81f4\u6027\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u5b58\u5728\u663e\u8457\u7684\u6539\u8fdb\u7a7a\u95f4\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ea7\u63a8\u7406\u548c\u591a\u8bed\u8a00\u80fd\u529b\u65b9\u9762\u3002"}}
{"id": "2506.06930", "pdf": "https://arxiv.org/pdf/2506.06930", "abs": "https://arxiv.org/abs/2506.06930", "authors": ["Alexander Spangher", "Tenghao Huang", "Jialiang Gu", "Jiatong Shi", "Muhao Chen"], "title": "DiscoSum: Discourse-aware News Summarization", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 3 figures, 10 pages in Appendix", "summary": "Recent advances in text summarization have predominantly leveraged large\nlanguage models to generate concise summaries. However, language models often\ndo not maintain long-term discourse structure, especially in news articles,\nwhere organizational flow significantly influences reader engagement. We\nintroduce a novel approach to integrating discourse structure into\nsummarization processes, focusing specifically on news articles across various\nmedia. We present a novel summarization dataset where news articles are\nsummarized multiple times in different ways across different social media\nplatforms (e.g. LinkedIn, Facebook, etc.). We develop a novel news discourse\nschema to describe summarization structures and a novel algorithm, DiscoSum,\nwhich employs beam search technique for structure-aware summarization, enabling\nthe transformation of news stories to meet different stylistic and structural\ndemands. Both human and automatic evaluation results demonstrate the efficacy\nof our approach in maintaining narrative fidelity and meeting structural\nrequirements.", "AI": {"tldr": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06\u8bed\u7bc7\u7ed3\u6784\u6574\u5408\u5230\u65b0\u95fb\u6587\u7ae0\u7684\u603b\u7ed3\u8fc7\u7a0b\u4e2d\uff0c\u5f00\u53d1\u4e86\u540d\u4e3aDiscoSum\u7684\u7b97\u6cd5\uff0c\u7ed3\u679c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u901a\u5e38\u4e0d\u80fd\u7ef4\u6301\u957f\u671f\u7684\u8bed\u7bc7\u7ed3\u6784\uff0c\u800c\u5728\u65b0\u95fb\u6587\u7ae0\u4e2d\uff0c\u7ec4\u7ec7\u6d41\u5bf9\u8bfb\u8005\u53c2\u4e0e\u5ea6\u6709\u663e\u8457\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aDiscoSum\u7684\u65b0\u7b97\u6cd5\uff0c\u5229\u7528\u675f\u641c\u7d22\u6280\u672f\u8fdb\u884c\u7ed3\u6784\u611f\u77e5\u603b\u7ed3\u3002", "result": "\u4eba\u7c7b\u548c\u81ea\u52a8\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u53d9\u4e8b\u5fe0\u5b9e\u6027\u548c\u6ee1\u8db3\u7ed3\u6784\u9700\u6c42\u65b9\u9762\u5177\u6709\u6210\u6548\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u6709\u6548\u5730\u5728\u65b0\u95fb\u603b\u7ed3\u4e2d\u4fdd\u6301\u53d9\u4e8b\u7684\u5fe0\u5b9e\u6027\u548c\u6ee1\u8db3\u7ed3\u6784\u6027\u9700\u6c42\u3002"}}
{"id": "2506.06656", "pdf": "https://arxiv.org/pdf/2506.06656", "abs": "https://arxiv.org/abs/2506.06656", "authors": ["Ittai Rubinstein", "Samuel B. Hopkins"], "title": "Rescaled Influence Functions: Accurate Data Attribution in High Dimension", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "How does the training data affect a model's behavior? This is the question we\nseek to answer with data attribution. The leading practical approaches to data\nattribution are based on influence functions (IF). IFs utilize a first-order\nTaylor approximation to efficiently predict the effect of removing a set of\nsamples from the training set without retraining the model, and are used in a\nwide variety of machine learning applications. However, especially in the\nhigh-dimensional regime (# params $\\geq \\Omega($# samples$)$), they are often\nimprecise and tend to underestimate the effect of sample removals, even for\nsimple models such as logistic regression. We present rescaled influence\nfunctions (RIF), a new tool for data attribution which can be used as a drop-in\nreplacement for influence functions, with little computational overhead but\nsignificant improvement in accuracy. We compare IF and RIF on a range of\nreal-world datasets, showing that RIFs offer significantly better predictions\nin practice, and present a theoretical analysis explaining this improvement.\nFinally, we present a simple class of data poisoning attacks that would fool\nIF-based detections but would be detected by RIF.", "AI": {"tldr": "\u5f15\u5165\u4e86\u91cd\u65b0\u6807\u5ea6\u7684\u5f71\u54cd\u51fd\u6570\uff08RIF\uff09\u4ee5\u63d0\u9ad8\u6570\u636e\u5f52\u56e0\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u5728\u9ad8\u7ef4\u5ea6\u6570\u636e\u96c6\u4e0a\u7684\u4e0d\u7cbe\u786e\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u5728\u9ad8\u7ef4\u5ea6\u6570\u636e\u96c6\u4e0a\u4e0d\u51c6\u786e\uff0c\u5e38\u5e38\u4f4e\u4f30\u6837\u672c\u79fb\u9664\u5f71\u54cd\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e86\u91cd\u65b0\u6807\u5ea6\u7684\u5f71\u54cd\u51fd\u6570\u8fdb\u884c\u6570\u636e\u5f52\u56e0\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5c55\u793a\u5176\u6548\u679c\u548c\u4f18\u8d8a\u6027\u3002", "result": "RIF\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e2d\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u6210\u529f\u68c0\u6d4b\u51fa\u4f20\u7edf\u5f71\u54cd\u51fd\u6570\u96be\u4ee5\u63a2\u6d4b\u7684\u6295\u6bd2\u653b\u51fb\u3002", "conclusion": "\u63d0\u51fa\u7684RIF\u5728\u6570\u636e\u5f52\u56e0\u4e0a\u6bd4\u4f20\u7edf\u7684\u5f71\u54cd\u51fd\u6570\u66f4\u51c6\u786e\uff0c\u5c24\u5176\u5728\u9ad8\u7ef4\u5ea6\u60c5\u51b5\u4e0b\u8868\u73b0\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2506.07428", "pdf": "https://arxiv.org/pdf/2506.07428", "abs": "https://arxiv.org/abs/2506.07428", "authors": ["Yuling Wang", "Zihui Chen", "Pengfei Jiao", "Xiao Wang"], "title": "HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the\nneed for tailored attacks to assess their robustness and ensure security.\nHowever, existing HGNN attacks often require complex retraining of parameters\nto generate specific perturbations for new scenarios. Recently, foundation\nmodels have opened new horizons for the generalization of graph neural networks\nby capturing shared semantics across various graph distributions. This leads us\nto ask:Can we design a foundation attack model for HGNNs that enables\ngeneralizable perturbations across different HGNNs, and quickly adapts to new\nheterogeneous graphs (HGs)? Empirical findings reveal that, despite significant\ndifferences in model design and parameter space, different HGNNs surprisingly\nshare common vulnerability patterns from a relation-aware perspective.\nTherefore, we explore how to design foundation HGNN attack criteria by mining\nshared attack units. In this paper, we propose a novel relation-wise\nheterogeneous graph foundation attack model, HeTa. We introduce a foundation\nsurrogate model to align heterogeneity and identify the importance of shared\nrelation-aware attack units. Building on this, we implement a serialized\nrelation-by-relation attack based on the identified relational weights. In this\nway, the perturbation can be transferred to various target HGNNs and easily\nfine-tuned for new HGs. Extensive experiments exhibit powerful attack\nperformances and generalizability of our method.", "AI": {"tldr": "\u63d0\u51fa\u4e86HeTa\uff0c\u4e00\u79cd\u80fd\u591f\u5728\u4e0d\u540cHGNNs\u95f4\u4e00\u822c\u5316\u7684\u5173\u7cfb\u611f\u77e5\u5f02\u6784\u56fe\u57fa\u7840\u653b\u51fb\u6a21\u578b\uff0c\u5177\u6709\u5f3a\u5927\u7684\u653b\u51fb\u6027\u80fd\u548c\u666e\u904d\u6027\u3002", "motivation": "\u9274\u4e8eHGNNs\u7684\u8106\u5f31\u6027\u548c\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u7684\u590d\u6742\u6027\uff0c\u6211\u4eec\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u53ef\u4ee5\u5728\u4e0d\u540cHGNNs\u95f4\u8fdb\u884c\u4e00\u822c\u5316\u5e76\u9002\u5e94\u65b0\u73af\u5883\u7684\u57fa\u7840\u653b\u51fb\u6a21\u578b\u3002", "method": "\u91c7\u7528\u57fa\u7840\u4ee3\u7406\u6a21\u578b\u6765\u5bf9\u9f50\u5f02\u8d28\u6027\u5e76\u8bc6\u522b\u91cd\u8981\u7684\u5171\u4eab\u5173\u7cfb\u611f\u77e5\u653b\u51fb\u5355\u5143\uff0c\u8fdb\u800c\u5b9e\u73b0\u57fa\u4e8e\u5173\u7cfb\u6743\u91cd\u7684\u5e8f\u5217\u5316\u5173\u7cfb\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5177\u6709\u5f3a\u5927\u7684\u653b\u51fb\u6027\u80fd\u548c\u666e\u904d\u6027\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5173\u7cfb\u611f\u77e5\u5f02\u6784\u56fe\u57fa\u7840\u653b\u51fb\u6a21\u578bHeTa\uff0c\u80fd\u591f\u9488\u5bf9\u4e0d\u540c\u7684HGNNs\u8fdb\u884c\u4e00\u822c\u5316\u6270\u52a8\uff0c\u5e76\u5feb\u901f\u9002\u5e94\u65b0\u7684\u5f02\u6784\u56fe\u3002"}}
{"id": "2506.06950", "pdf": "https://arxiv.org/pdf/2506.06950", "abs": "https://arxiv.org/abs/2506.06950", "authors": ["Do Xuan Long", "Duy Dinh", "Ngoc-Hai Nguyen", "Kenji Kawaguchi", "Nancy F. Chen", "Shafiq Joty", "Min-Yen Kan"], "title": "What Makes a Good Natural Language Prompt?", "categories": ["cs.CL"], "comment": "ACL 2025 Main Conference", "summary": "As large language models (LLMs) have progressed towards more human-like and\nhuman--AI communications have become prevalent, prompting has emerged as a\ndecisive component. However, there is limited conceptual consensus on what\nexactly quantifies natural language prompts. We attempt to address this\nquestion by conducting a meta-analysis surveying more than 150\nprompting-related papers from leading NLP and AI conferences from 2022 to 2025\nand blogs. We propose a property- and human-centric framework for evaluating\nprompt quality, encompassing 21 properties categorized into six dimensions. We\nthen examine how existing studies assess their impact on LLMs, revealing their\nimbalanced support across models and tasks, and substantial research gaps.\nFurther, we analyze correlations among properties in high-quality natural\nlanguage prompts, deriving prompting recommendations. We then empirically\nexplore multi-property prompt enhancements in reasoning tasks, observing that\nsingle-property enhancements often have the greatest impact. Finally, we\ndiscover that instruction-tuning on property-enhanced prompts can result in\nbetter reasoning models. Our findings establish a foundation for\nproperty-centric prompt evaluation and optimization, bridging the gaps between\nhuman--AI communication and opening new prompting research directions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86150\u591a\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u63d0\u51fa\u4e86\u4ee5\u6027\u8d28\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u63d0\u793a\u8d28\u91cf\uff0c\u5e76\u53d1\u73b0\u5355\u4e00\u6027\u8d28\u589e\u5f3a\u901a\u5e38\u662f\u63d0\u5347\u6548\u679c\u7684\u5173\u952e\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u8868\u73b0\u51fa\u66f4\u7c7b\u4eba\u5316\u7684\u7279\u5f81\uff0c\u56e0\u6b64\u63d0\u793a\u5728\u5176\u4e2d\u6210\u4e3a\u4e00\u4e2a\u51b3\u5b9a\u6027\u56e0\u7d20\u3002\u4f46\u5bf9\u4e8e\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u91cf\u5316\u76ee\u524d\u7f3a\u4e4f\u5171\u8bc6\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u7814\u7a76\u3002", "method": "\u8fdb\u884c\u4e86\u5143\u5206\u6790\uff0c\u8c03\u67e5\u4e86150\u591a\u7bc7\u4e0e\u63d0\u793a\u76f8\u5173\u7684\u8bba\u6587\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u6027\u8d28\u548c\u4eba\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\u6765\u8bc4\u4f30\u63d0\u793a\u8d28\u91cf\u3002\u968f\u540e\u5206\u6790\u73b0\u6709\u7814\u7a76\u5982\u4f55\u8bc4\u4f30\u5176\u5bf9LLM\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u8bc1\u63a2\u7d22\u3002", "result": "\u53d1\u73b0\u7eaf\u7cb9\u57fa\u4e8e\u5355\u4e00\u6027\u8d28\u7684\u63d0\u5347\u5f80\u5f80\u4ea7\u751f\u6700\u5927\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u5728\u63d0\u793a\u4e2d\u8fdb\u884c\u6027\u8d28\u589e\u5f3a\u7684\u6307\u4ee4\u8c03\u6574\u53ef\u4ee5\u5bfc\u81f4\u66f4\u597d\u7684\u63a8\u7406\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u5960\u5b9a\u4e86\u4ee5\u6027\u8d28\u4e3a\u4e2d\u5fc3\u7684\u63d0\u793a\u8bc4\u4f30\u548c\u4f18\u5316\u7684\u57fa\u7840\uff0c\u5e76\u5728\u6c9f\u901a\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u7684\u6865\u6881\u4e0a\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.06665", "pdf": "https://arxiv.org/pdf/2506.06665", "abs": "https://arxiv.org/abs/2506.06665", "authors": ["Hong-Ming Chiu", "Hao Chen", "Huan Zhang", "Richard Y. Zhang"], "title": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Neural network verifiers based on linear bound propagation scale impressively\nto massive models but can be surprisingly loose when neuron coupling is\ncrucial. Conversely, semidefinite programming (SDP) verifiers capture\ninter-neuron coupling naturally, but their cubic complexity restricts them to\nonly small models. In this paper, we propose SDP-CROWN, a novel hybrid\nverification framework that combines the tightness of SDP relaxations with the\nscalability of bound-propagation verifiers. At the core of SDP-CROWN is a new\nlinear bound, derived via SDP principles, that explicitly captures\n$\\ell_{2}$-norm-based inter-neuron coupling while adding only one extra\nparameter per layer. This bound can be integrated seamlessly into any linear\nbound-propagation pipeline, preserving the inherent scalability of such methods\nyet significantly improving tightness. In theory, we prove that our\ninter-neuron bound can be up to a factor of $\\sqrt{n}$ tighter than traditional\nper-neuron bounds. In practice, when incorporated into the state-of-the-art\n$\\alpha$-CROWN verifier, we observe markedly improved verification performance\non large models with up to 65 thousand neurons and 2.47 million parameters,\nachieving tightness that approaches that of costly SDP-based methods.", "AI": {"tldr": "SDP-CROWN\u7ed3\u5408\u4e86\u534a\u5b9a\u89c4\u5212\u548c\u7ebf\u6027\u8fb9\u754c\u4f20\u64ad\u4f18\u70b9\uff0c\u63d0\u5347\u4e86\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u5668\u7684\u7d27\u5ea6\u548c\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u5668\u5728\u5904\u7406\u5927\u578b\u6a21\u578b\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u795e\u7ecf\u5143\u8026\u5408\u65f6\u5374\u53ef\u80fd\u4e0d\u591f\u7cbe\u786e\u3002\u800c\u534a\u5b9a\u89c4\u5212\u9a8c\u8bc1\u5668\u80fd\u5f88\u81ea\u7136\u5730\u5904\u7406\u795e\u7ecf\u5143\u8026\u5408\uff0c\u4f46\u7531\u4e8e\u5176\u590d\u6742\u6027\uff0c\u53ea\u80fd\u7528\u4e8e\u5c0f\u89c4\u6a21\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4eba\u5458\u5e0c\u671b\u5f00\u53d1\u51fa\u4e00\u79cd\u65e2\u80fd\u7ed3\u5408\u534a\u5b9a\u89c4\u5212\u7d27\u5ea6\uff0c\u53c8\u5177\u6709\u7ebf\u6027\u8fb9\u754c\u4f20\u64ad\u9a8c\u8bc1\u5668\u53ef\u6269\u5c55\u6027\u7684\u9a8c\u8bc1\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSDP-CROWN\u7684\u65b0\u578b\u6df7\u5408\u9a8c\u8bc1\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u662f\u901a\u8fc7SDP\u539f\u7406\u63a8\u5bfc\u7684\u65b0\u7ebf\u6027\u8fb9\u754c\uff0c\u8be5\u8fb9\u754c\u663e\u5f0f\u6355\u83b7\u57fa\u4e8eL2\u8303\u6570\u7684\u795e\u7ecf\u5143\u95f4\u8026\u5408\uff0c\u540c\u65f6\u6bcf\u5c42\u4ec5\u589e\u52a0\u4e00\u4e2a\u989d\u5916\u53c2\u6570\u3002\u8be5\u8fb9\u754c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u4efb\u4f55\u7ebf\u6027\u8fb9\u754c\u4f20\u64ad\u7ba1\u9053\u4e2d\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u8be5\u795e\u7ecf\u5143\u95f4\u8fb9\u754c\u6bd4\u4f20\u7edf\u7684\u6bcf\u795e\u7ecf\u5143\u8fb9\u754c\u53ef\u4ee5\u7d27\u5230\u221an\u500d\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u5c06\u5176\u6574\u5408\u5230\u5148\u8fdb\u7684\u03b1-CROWN\u9a8c\u8bc1\u5668\u4e2d\u65f6\uff0c\u5728\u5904\u7406\u591a\u8fbe65\u5343\u4e2a\u795e\u7ecf\u5143\u548c2.47\u767e\u4e07\u4e2a\u53c2\u6570\u7684\u5927\u578b\u6a21\u578b\u65f6\uff0c\u9a8c\u8bc1\u6027\u80fd\u663e\u8457\u63d0\u9ad8\uff0c\u8fbe\u5230\u4e86\u63a5\u8fd1\u6602\u8d35\u7684SDP\u65b9\u6cd5\u7684\u7d27\u5ea6\u3002", "conclusion": "SDP-CROWN\u6846\u67b6\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u90fd\u5c55\u793a\u4e86\u5176\u5728\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u4e2d\u7684\u4f18\u52bf\uff0c\u7ed3\u5408\u4e86SDP\u548c\u7ebf\u6027\u8fb9\u754c\u4f20\u64ad\u9a8c\u8bc1\u5668\u7684\u4f18\u70b9\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9a8c\u8bc1\u7d27\u5ea6\u548c\u6027\u80fd\u3002"}}
{"id": "2506.07443", "pdf": "https://arxiv.org/pdf/2506.07443", "abs": "https://arxiv.org/abs/2506.07443", "authors": ["Weijie Shi", "Han Zhu", "Jiaming Ji", "Mengze Li", "Jipeng Zhang", "Ruiyuan Zhang", "Jia Zhu", "Jiajie Xu", "Sirui Han", "Yike Guo"], "title": "LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Legal judgment prediction (LJP) aims to function as a judge by making final\nrulings based on case claims and facts, which plays a vital role in the\njudicial domain for supporting court decision-making and improving judicial\nefficiency. However, existing methods often struggle with logical errors when\nconducting complex legal reasoning. We propose LegalReasoner, which enhances\nLJP reliability through step-wise verification and correction of the reasoning\nprocess. Specifically, it first identifies dispute points to decompose complex\ncases, and then conducts step-wise reasoning while employing a process verifier\nto validate each step's logic from correctness, progressiveness, and potential\nperspectives. When errors are detected, expert-designed attribution and\nresolution strategies are applied for correction. To fine-tune LegalReasoner,\nwe release the LegalHK dataset, containing 58,130 Hong Kong court cases with\ndetailed annotations of dispute points, step-by-step reasoning chains, and\nprocess verification labels. Experiments demonstrate that LegalReasoner\nsignificantly improves concordance with court decisions from 72.37 to 80.27 on\nLLAMA-3.1-70B. The data is available at\nhttps://huggingface.co/datasets/weijiezz/LegalHK.", "AI": {"tldr": "LegalReasoner\u901a\u8fc7\u9010\u6b65\u9a8c\u8bc1\u548c\u7ea0\u6b63\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7684\u53ef\u9760\u6027\uff0c\u663e\u8457\u6539\u5584\u4e86\u4e0e\u6cd5\u9662\u5224\u51b3\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8fdb\u884c\u590d\u6742\u6cd5\u5f8b\u63a8\u7406\u65f6\u5f80\u5f80\u51fa\u73b0\u903b\u8f91\u9519\u8bef\u3002", "method": "\u901a\u8fc7\u9010\u6b65\u9a8c\u8bc1\u548c\u7ea0\u6b63\u63a8\u7406\u8fc7\u7a0b\u6765\u589e\u5f3a\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u7684\u53ef\u9760\u6027\u3002\u9996\u5148\u8bc6\u522b\u4e89\u8bae\u70b9\u4ee5\u5206\u89e3\u590d\u6742\u6848\u4ef6\uff0c\u7136\u540e\u8fdb\u884c\u9010\u6b65\u63a8\u7406\uff0c\u5e76\u5229\u7528\u8fc7\u7a0b\u9a8c\u8bc1\u5668\u4ece\u6b63\u786e\u6027\u3001\u8fdb\u5c55\u548c\u6f5c\u5728\u6027\u89d2\u5ea6\u9a8c\u8bc1\u6bcf\u4e00\u6b65\u903b\u8f91\u3002\u5f53\u68c0\u6d4b\u5230\u9519\u8bef\u65f6\uff0c\u5e94\u7528\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5f52\u56e0\u548c\u89e3\u51b3\u7b56\u7565\u8fdb\u884c\u7ea0\u6b63\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0cLegalReasoner\u663e\u8457\u63d0\u9ad8\u4e86\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u4e0e\u6cd5\u9662\u51b3\u7b56\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "LegalReasoner\u663e\u8457\u63d0\u9ad8\u4e86\u4e0e\u6cd5\u9662\u5224\u51b3\u7684\u4e00\u81f4\u6027\uff0c\u4ece72.37\u63d0\u5347\u523080.27\u3002"}}
{"id": "2506.06955", "pdf": "https://arxiv.org/pdf/2506.06955", "abs": "https://arxiv.org/abs/2506.06955", "authors": ["Ha-Thanh Nguyen", "Chaoran Liu", "Hirokazu Kiyomaru", "Koichi Takeda", "Yusuke Miyao", "Maki Matsuda", "Yusuke Oda", "Pontus Stenetorp", "Qianying Liu", "Su Myat Noe", "Hideyuki Tachibana", "Kouta Nakayama", "Sadao Kurohashi"], "title": "BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present BIS Reasoning 1.0, the first large-scale Japanese dataset of\nsyllogistic reasoning problems explicitly designed to evaluate\nbelief-inconsistent reasoning in large language models (LLMs). Unlike prior\ndatasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned\nreasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent\nsyllogisms to uncover reasoning biases in LLMs trained on human-aligned\ncorpora. We benchmark state-of-the-art models - including GPT models, Claude\nmodels, and leading Japanese LLMs - revealing significant variance in\nperformance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies\ncritical weaknesses in current LLMs when handling logically valid but\nbelief-conflicting inputs. These findings have important implications for\ndeploying LLMs in high-stakes domains such as law, healthcare, and scientific\nliterature, where truth must override intuitive belief to ensure integrity and\nsafety.", "AI": {"tldr": "\u63a8\u51fa\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4fe1\u5ff5\u4e0d\u4e00\u81f4\u63a8\u7406\u7684\u6570\u636e\u96c6\uff0c\u5e76\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u903b\u8f91\u4e0e\u4fe1\u5ff5\u51b2\u7a81\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u521b\u5efa\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u4fe1\u5ff5\u4e0d\u4e00\u81f4\u63a8\u7406\u7684\u65e5\u8bed\u6570\u636e\u96c6\u3002", "method": "\u5f00\u53d1\u5e76\u4f7f\u7528BIS Reasoning 1.0\u6570\u636e\u96c6\uff0c\u5bf9\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u903b\u8f91\u6709\u6548\u4f46\u4e0e\u4fe1\u5ff5\u51b2\u7a81\u7684\u8f93\u5165\u65f6\u5b58\u5728\u663e\u8457\u7684\u504f\u5dee\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u9ad8\u98ce\u9669\u9886\u57df\u4e2d\uff0c\u5fc5\u987b\u4f18\u5148\u8003\u8651\u771f\u5b9e\u7684\u63a8\u7406\u80fd\u529b\u800c\u4e0d\u662f\u76f4\u89c9\u6027\u4fe1\u5ff5\u3002"}}
{"id": "2506.06666", "pdf": "https://arxiv.org/pdf/2506.06666", "abs": "https://arxiv.org/abs/2506.06666", "authors": ["Oktay Karaku\u015f", "Hasan Arkada\u015f"], "title": "Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering", "categories": ["cs.LG", "stat.ML"], "comment": "12 pages and 5 figures", "summary": "Line-breaking passes (LBPs) are crucial tactical actions in football,\nallowing teams to penetrate defensive lines and access high-value spaces. In\nthis study, we present an unsupervised, clustering-based framework for\ndetecting and analysing LBPs using synchronised event and tracking data from\nelite matches. Our approach models opponent team shape through vertical spatial\nsegmentation and identifies passes that disrupt defensive lines within open\nplay. Beyond detection, we introduce several tactical metrics, including the\nspace build-up ratio (SBR) and two chain-based variants, LBPCh$^1$ and\nLBPCh$^2$, which quantify the effectiveness of LBPs in generating immediate or\nsustained attacking threats. We evaluate these metrics across teams and players\nin the 2022 FIFA World Cup, revealing stylistic differences in vertical\nprogression and structural disruption. The proposed methodology is explainable,\nscalable, and directly applicable to modern performance analysis and scouting\nworkflows.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u8db3\u7403\u6bd4\u8d5b\u4e2d\u7834\u9632\u4f20\u7403\u7684\u68c0\u6d4b\u548c\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b0\u7684\u6218\u672f\u6307\u6807\u4ee5\u91cf\u5316\u5176\u6548\u80fd\u3002", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u7403\u961f\u6218\u672f\u5206\u6790\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6bd4\u8d5b\u4e2d\u653b\u7834\u5bf9\u65b9\u9632\u5b88\u7ebf\u7684\u4f20\u7403\u6218\u672f\u4e0a\uff0c\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u5206\u6790\u6307\u6807\u548c\u65b9\u6cd5\u6765\u63d0\u9ad8\u8bc4\u4f30\u7cbe\u51c6\u5ea6\u548c\u6548\u80fd\u3002", "method": "\u91c7\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u805a\u7c7b\u5206\u6790\uff0c\u901a\u8fc7\u5782\u76f4\u7a7a\u95f4\u5206\u5272\u6a21\u578b\u5316\u5bf9\u624b\u961f\u5f62\uff0c\u5e76\u4ee5\u4e8b\u4ef6\u548c\u8ffd\u8e2a\u6570\u636e\u68c0\u6d4b\u7834\u9632\u4f20\u7403\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u4e2a\u6218\u672f\u6307\u6807\u6765\u91cf\u5316\u4f20\u7403\u7684\u6548\u80fd\u3002", "result": "\u901a\u8fc72022\u5e74\u4e16\u754c\u676f\u7684\u6570\u636e\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u7403\u961f\u548c\u7403\u5458\u7684\u6218\u672f\u98ce\u683c\u5dee\u5f02\uff0c\u5c24\u5176\u662f\u7eb5\u5411\u63a8\u8fdb\u548c\u7ed3\u6784\u7834\u574f\u65b9\u9762\u7684\u5dee\u5f02\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u805a\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u5206\u6790\u8db3\u7403\u6bd4\u8d5b\u4e2d\u7684\u7834\u9632\u4f20\u7403\uff0c\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u6218\u672f\u6307\u6807\u6765\u91cf\u5316\u5176\u6218\u672f\u5f71\u54cd\uff0c\u5e76\u57282022\u5e74\u4e16\u754c\u676f\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002"}}
{"id": "2506.07446", "pdf": "https://arxiv.org/pdf/2506.07446", "abs": "https://arxiv.org/abs/2506.07446", "authors": ["Liwen Zheng", "Chaozhuo Li", "Zheng Liu", "Feiran Huang", "Haoran Jia", "Zaisheng Ye", "Xi Zhang"], "title": "Fact in Fragments: Deconstructing Complex Claims via LLM-based Atomic Fact Extraction and Verification", "categories": ["cs.AI"], "comment": null, "summary": "Fact verification plays a vital role in combating misinformation by assessing\nthe veracity of claims through evidence retrieval and reasoning. However,\ntraditional methods struggle with complex claims requiring multi-hop reasoning\nover fragmented evidence, as they often rely on static decomposition strategies\nand surface-level semantic retrieval, which fail to capture the nuanced\nstructure and intent of the claim. This results in accumulated reasoning\nerrors, noisy evidence contamination, and limited adaptability to diverse\nclaims, ultimately undermining verification accuracy in complex scenarios. To\naddress this, we propose Atomic Fact Extraction and Verification (AFEV), a\nnovel framework that iteratively decomposes complex claims into atomic facts,\nenabling fine-grained retrieval and adaptive reasoning. AFEV dynamically\nrefines claim understanding and reduces error propagation through iterative\nfact extraction, reranks evidence to filter noise, and leverages\ncontext-specific demonstrations to guide the reasoning process. Extensive\nexperiments on five benchmark datasets demonstrate that AFEV achieves\nstate-of-the-art performance in both accuracy and interpretability.", "AI": {"tldr": "AFEV\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u63d0\u9ad8\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u5206\u89e3\u590d\u6742\u7684\u4e3b\u5f20\u6765\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u8bc1\u636e\u68c0\u7d22\u548c\u81ea\u9002\u5e94\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u7684\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7684\u591a\u8df3\u63a8\u7406\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6838\u67e5\u7684\u51c6\u786e\u6027\u3002", "method": "AFEV\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u7684\u4e8b\u5b9e\u63d0\u53d6\u548c\u91cd\u65b0\u6392\u5e8f\u8bc1\u636e\u6765\u51cf\u5c11\u9519\u8bef\u4f20\u64ad\u3002", "result": "AFEV\u5728\u4e94\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u4e86\u6700\u65b0\u7684\u6027\u80fd\u3002", "conclusion": "AFEV\u6846\u67b6\u63d0\u9ad8\u4e86\u590d\u6742\u4e8b\u5b9e\u6838\u67e5\u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.06964", "pdf": "https://arxiv.org/pdf/2506.06964", "abs": "https://arxiv.org/abs/2506.06964", "authors": ["Subhojyoti Mukherjee", "Viet Dac Lai", "Raghavendra Addanki", "Ryan Rossi", "Seunghyun Yoon", "Trung Bui", "Anup Rao", "Jayakumar Subramanian", "Branislav Kveton"], "title": "Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning", "categories": ["cs.CL", "cs.LG"], "comment": "39 pages", "summary": "Question answering (QA) agents automatically answer questions posed in\nnatural language. In this work, we learn to ask clarifying questions in QA\nagents. The key idea in our method is to simulate conversations that contain\nclarifying questions and learn from them using reinforcement learning (RL). To\nmake RL practical, we propose and analyze offline RL objectives that can be\nviewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in\nlarge language models. Our work stands in a stark contrast to recently proposed\nmethods, based on SFT and direct preference optimization, which have additional\nhyper-parameters and do not directly optimize rewards. We compare to these\nmethods empirically and report gains in both optimized rewards and language\nquality.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u79cd\u4f7f\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6765\u4f18\u5316\u95ee\u7b54\u4ee3\u7406\u751f\u6210\u6f84\u6e05\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u53d6\u5f97\u4e86\u66f4\u597d\u5956\u52b1\u548c\u8bed\u8a00\u8d28\u91cf\u3002", "motivation": "\u5728\u73b0\u6709\u95ee\u7b54\u4ee3\u7406\u4e2d\u589e\u52a0\u6f84\u6e05\u95ee\u9898\u751f\u6210\u529f\u80fd\uff0c\u4ee5\u63d0\u9ad8\u56de\u7b54\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u5c06\u5176\u89c6\u4e3a\u5956\u52b1\u52a0\u6743\u7684\u76d1\u7763\u5fae\u8c03\u4ee5\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u53d1\u73b0\u672c\u6587\u65b9\u6cd5\u5728\u4f18\u5316\u5956\u52b1\u548c\u8bed\u8a00\u8d28\u91cf\u4e0a\u53d6\u5f97\u4e86\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4f18\u5316QA\u4ee3\u7406\u4eba\u751f\u6210\u6f84\u6e05\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u76f8\u8f83\u4e8e\u6700\u8fd1\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u66f4\u597d\u7684\u5956\u52b1\u4e0e\u8bed\u8a00\u8d28\u91cf\u3002"}}
{"id": "2506.06682", "pdf": "https://arxiv.org/pdf/2506.06682", "abs": "https://arxiv.org/abs/2506.06682", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "title": "Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics", "categories": ["cs.LG"], "comment": null, "summary": "In graph self-supervised learning, masked autoencoders (MAE) and contrastive\nlearning (CL) are two prominent paradigms. MAE focuses on reconstructing masked\nelements, while CL maximizes similarity between augmented graph views. Recent\nstudies highlight their complementarity: MAE excels at local feature capture,\nand CL at global information extraction. Hybrid frameworks for homogeneous\ngraphs have been proposed, but face challenges in designing shared encoders to\nmeet the semantic requirements of both tasks. In semantically sparse scenarios,\nCL struggles with view construction, and gradient imbalance between positive\nand negative samples persists. This paper introduces HetCRF, a novel\ndual-channel self-supervised learning framework for heterogeneous graphs.\nHetCRF uses a two-stage aggregation strategy to adapt embedding semantics,\nmaking it compatible with both MAE and CL. To address semantic sparsity, it\nenhances encoder output for view construction instead of relying on raw\nfeatures, improving efficiency. Two positive sample augmentation strategies are\nalso proposed to balance gradient contributions. Node classification\nexperiments on four real-world heterogeneous graph datasets demonstrate that\nHetCRF outperforms state-of-the-art baselines. On datasets with missing node\nfeatures, such as Aminer and Freebase, at a 40% label rate in node\nclassification, HetCRF improves the Macro-F1 score by 2.75% and 2.2%\nrespectively compared to the second-best baseline, validating its effectiveness\nand superiority.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HetCRF\uff0c\u4e00\u4e2a\u7528\u4e8e\u5f02\u6784\u56fe\u7684\u53cc\u901a\u9053\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\uff0c\u7279\u522b\u662f\u5728\u7f3a\u5c11\u8282\u70b9\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u8bed\u4e49\u7a00\u758f\u7684\u573a\u666f\u4e2d\uff0cCL\u5728\u89c6\u56fe\u6784\u5efa\u4e0a\u6709\u56f0\u96be\uff0c\u5e76\u4e14\u5728\u6b63\u8d1f\u6837\u672c\u4e4b\u95f4\u7684\u68af\u5ea6\u4e0d\u5e73\u8861\u4f9d\u7136\u5b58\u5728\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86HetCRF\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5f02\u6784\u56fe\u7684\u53cc\u901a\u9053\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6HetCRF\u3002\u5b83\u91c7\u7528\u4e24\u9636\u6bb5\u805a\u5408\u7b56\u7565\u6765\u9002\u914d\u5d4c\u5165\u8bed\u4e49\uff0c\u4f7f\u5176\u517c\u5bb9\u4e8eMAE\u548cCL\uff0c\u5e76\u589e\u5f3a\u7f16\u7801\u5668\u8f93\u51fa\u4ee5\u8fdb\u884c\u89c6\u56fe\u6784\u5efa\uff0c\u63d0\u9ad8\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cd\u6b63\u6837\u672c\u589e\u5f3a\u7b56\u7565\u4ee5\u5e73\u8861\u68af\u5ea6\u8d21\u732e\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u5f02\u6784\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHetCRF\u6bd4\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u8868\u73b0\u66f4\u4f73\u3002\u5728\u7f3a\u5931\u8282\u70b9\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\uff0cHetCRF\u63d0\u9ad8\u4e86Macro-F1\u5f97\u5206\uff0c\u8fd9\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "Node classification\u5b9e\u9a8c\u8868\u660e\uff0cHetCRF\u5728\u56db\u4e2a\u771f\u5b9e\u7684\u5f02\u6784\u56fe\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6700\u4f18\u57fa\u7ebf\u3002\u5728\u7f3a\u5c11\u8282\u70b9\u7279\u5f81\u7684\u6570\u636e\u96c6\uff08\u5982Aminer\u548cFreebase\uff09\u4e2d\uff0cHetCRF\u5728\u8282\u70b9\u5206\u7c7b\u4e2d\u7684Macro-F1\u5f97\u5206\u5206\u522b\u63d0\u9ad8\u4e862.75%\u548c2.2%\u3002"}}
{"id": "2506.07450", "pdf": "https://arxiv.org/pdf/2506.07450", "abs": "https://arxiv.org/abs/2506.07450", "authors": ["Yi Loo", "Akshunn Trivedi", "Malika Meghjani"], "title": "Efficient Generation of Diverse Cooperative Agents with World Models", "categories": ["cs.AI"], "comment": null, "summary": "A major bottleneck in the training process for Zero-Shot Coordination (ZSC)\nagents is the generation of partner agents that are diverse in collaborative\nconventions. Current Cross-play Minimization (XPM) methods for population\ngeneration can be very computationally expensive and sample inefficient as the\ntraining objective requires sampling multiple types of trajectories. Each\npartner agent in the population is also trained from scratch, despite all of\nthe partners in the population learning policies of the same coordination task.\nIn this work, we propose that simulated trajectories from the dynamics model of\nan environment can drastically speed up the training process for XPM methods.\nWe introduce XPM-WM, a framework for generating simulated trajectories for XPM\nvia a learned World Model (WM). We show XPM with simulated trajectories removes\nthe need to sample multiple trajectories. In addition, we show our proposed\nmethod can effectively generate partners with diverse conventions that match\nthe performance of previous methods in terms of SP population training reward\nas well as training partners for ZSC agents. Our method is thus, significantly\nmore sample efficient and scalable to a larger number of partners.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e16\u754c\u6a21\u578b\u751f\u6210\u6a21\u62df\u8f68\u8ff9\u7684XPM-WM\u65b9\u6cd5\uff0c\u63d0\u9ad8XPM\u7684\u91c7\u6837\u6548\u7387\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u4e14\u9ad8\u6548\u7684\u4f19\u4f34\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u53c9\u6e38\u620f\u6700\u5c0f\u5316\uff08XPM\uff09\u65b9\u6cd5\u5728\u79cd\u7fa4\u751f\u6210\u65f6\u8017\u8d39\u5de8\u5927\u800c\u4e14\u91c7\u6837\u6548\u7387\u4f4e\u4e0b\uff0c\u6240\u6709\u4f19\u4f34\u90fd\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\uff0c\u672a\u80fd\u5229\u7528\u76f8\u540c\u4efb\u52a1\u7684\u534f\u8c03\u5b66\u4e60\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aXPM-WM\u7684\u6846\u67b6\uff0c\u5229\u7528\u901a\u8fc7\u5b66\u4e60\u5f97\u6765\u7684\u4e16\u754c\u6a21\u578b\uff08World Model\uff09\u751f\u6210XPM\u7684\u6a21\u62df\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u6a21\u62df\u8f68\u8ff9\u7684XPM\u65b9\u6cd5\u80fd\u591f\u53bb\u9664\u591a\u91cd\u8f68\u8ff9\u91c7\u6837\u9700\u6c42\uff0c\u5e76\u751f\u6210\u5177\u6709\u591a\u6837\u6027\u534f\u4f5c\u4e60\u60ef\u7684\u4f19\u4f34\uff0c\u5176\u5728SP\u79cd\u7fa4\u8bad\u7ec3\u5956\u52b1\u65b9\u9762\u7684\u8868\u73b0\u53ef\u4e0e\u4ee5\u5f80\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u540c\u65f6\u66f4\u9ad8\u6548\u5e76\u5177\u5907\u66f4\u5927\u7684\u89c4\u6a21\u62d3\u5c55\u80fd\u529b\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684XPM-WM\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u8f68\u8ff9\u53ef\u4ee5\u5927\u5927\u52a0\u901f\u4ee5\u5f80XPM\u65b9\u6cd5\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u91c7\u6837\u6548\u7387\u5e76\u80fd\u591f\u66f4\u5927\u89c4\u6a21\u5730\u751f\u6210\u591a\u6837\u6027\u5408\u4f5c\u4f19\u4f34\u3002"}}
{"id": "2506.06968", "pdf": "https://arxiv.org/pdf/2506.06968", "abs": "https://arxiv.org/abs/2506.06968", "authors": ["Pavel Kovalev", "Carlo Angiuli"], "title": "A dependently-typed calculus of event telicity and culminativity", "categories": ["cs.CL", "cs.LO"], "comment": "52 pages, Agda formalization available at\n  https://doi.org/10.5281/zenodo.15602617", "summary": "We present a dependently-typed cross-linguistic framework for analyzing the\ntelicity and culminativity of events, accompanied by examples of using our\nframework to model English sentences. Our framework consists of two parts. In\nthe nominal domain, we model the boundedness of noun phrases and its\nrelationship to subtyping, delimited quantities, and adjectival modification.\nIn the verbal domain we define a dependent event calculus, modeling telic\nevents as those whose undergoer is bounded, culminating events as telic events\nthat achieve their inherent endpoint, and consider adverbial modification. In\nboth domains we pay particular attention to associated entailments. Our\nframework is defined as an extension of intensional Martin-L\\\"of dependent type\ntheory, and the rules and examples in this paper have been formalized in the\nAgda proof assistant.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f9d\u8d56\u7c7b\u578b\u8de8\u8bed\u8a00\u6846\u67b6\u5206\u6790\u4e8b\u4ef6\u7684\u6307\u5411\u6027\u548c\u7ec8\u7ed3\u6027\uff0c\u5229\u7528 Agda \u5f62\u5f0f\u5316\uff0c\u88ab\u7528\u4e8e\u82f1\u8bed\u53e5\u5b50\u5efa\u6a21\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u8de8\u8bed\u8a00\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u4e8b\u4ef6\u7684\u6307\u5411\u6027\u548c\u7ec8\u7ed3\u6027\uff0c\u65e8\u5728\u901a\u8fc7\u6df1\u5165\u8bed\u8a00\u7ed3\u6784\u548c\u4e8b\u4ef6\u63a8\u7406\u6765\u589e\u5f3a\u8bed\u4e49\u5206\u6790\u3002", "method": "\u6211\u4eec\u9996\u5148\u5206\u6790\u540d\u8bcd\u77ed\u8bed\u7684\u754c\u9650\u6027\u4ee5\u53ca\u5b83\u4e0e\u5b50\u7c7b\u578b\u3001\u9650\u5b9a\u6570\u91cf\u548c\u5f62\u5bb9\u8bcd\u4fee\u9970\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5728\u52a8\u8bcd\u57df\u4e2d\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4f9d\u8d56\u4e8b\u4ef6\u6f14\u7b97\uff0c\u5c06\u6307\u5411\u4e8b\u4ef6\u6a21\u578b\u5316\u4e3a\u5176\u7ecf\u5386\u8005\u5df2\u754c\u5b9a\u7684\u4e8b\u4ef6\uff0c\u5e76\u5c06\u8fbe\u5230\u56fa\u6709\u7ec8\u70b9\u7684\u6307\u5411\u4e8b\u4ef6\u89c6\u4e3a\u7ec8\u7ed3\u4e8b\u4ef6\uff0c\u540c\u65f6\u8003\u8651\u526f\u8bcd\u4fee\u9970\u3002", "result": "\u6211\u4eec\u5b9e\u73b0\u4e86\u4ee5 Agda \u8bc1\u660e\u52a9\u7406\u5f62\u5f0f\u5316\u8be5\u6846\u67b6\u7684\u89c4\u5219\u548c\u793a\u4f8b\uff0c\u8fd9\u589e\u5f3a\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u9002\u7528\u6027\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u6846\u67b6\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u4e0d\u540c\u8bed\u8a00\u4e2d\u7684\u4e8b\u4ef6\u7279\u6027\uff0c\u5982\u4e8b\u4ef6\u7684\u6307\u5411\u6027\u548c\u7ec8\u7ed3\u6027\uff0c\u4fc3\u8fdb\u4e86\u8de8\u8bed\u8a00\u7684\u8bed\u4e49\u5206\u6790\u3002"}}
{"id": "2506.06694", "pdf": "https://arxiv.org/pdf/2506.06694", "abs": "https://arxiv.org/abs/2506.06694", "authors": ["Yuan Yuan", "Yukun Liu", "Chonghua Han", "Jie Feng", "Yong Li"], "title": "Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Foundation models have revolutionized fields such as natural language\nprocessing and computer vision by enabling general-purpose learning across\ndiverse tasks and datasets. However, building analogous models for human\nmobility remains challenging due to the privacy-sensitive nature of mobility\ndata and the resulting data silos across institutions. To bridge this gap, we\npropose MoveGCL, a scalable and privacy-preserving framework for training\nmobility foundation models via generative continual learning. Without sharing\nraw data, MoveGCL enables decentralized and progressive model evolution by\nreplaying synthetic trajectories generated from a frozen teacher model, and\nreinforces knowledge retention through a tailored distillation strategy that\nmitigates catastrophic forgetting. To address the heterogeneity of mobility\npatterns, MoveGCL incorporates a Mixture-of-Experts Transformer with a\nmobility-aware expert routing mechanism, and employs a layer-wise progressive\nadaptation strategy to stabilize continual updates. Experiments on six\nreal-world urban datasets demonstrate that MoveGCL achieves performance\ncomparable to joint training and significantly outperforms federated learning\nbaselines, while offering strong privacy protection. MoveGCL marks a crucial\nstep toward unlocking foundation models for mobility, offering a practical\nblueprint for open, scalable, and privacy-preserving model development in the\nera of foundation models.", "AI": {"tldr": "MoveGCL\u662f\u4e00\u79cd\u7528\u4e8e\u8bad\u7ec3\u51fa\u884c\u57fa\u7840\u6a21\u578b\u7684\u53ef\u6269\u5c55\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u6846\u67b6\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u663e\u793a\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u9488\u5bf9\u51fa\u884c\u6570\u636e\u7684\u9690\u79c1\u654f\u611f\u6027\u548c\u5bfc\u81f4\u7684\u6570\u636e\u5b64\u5c9b\u73b0\u8c61\uff0c\u63d0\u51faMoveGCL\u6846\u67b6\uff0c\u65e8\u5728\u5f00\u53d1\u53ef\u4f38\u7f29\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u51fa\u884c\u57fa\u7840\u6a21\u578b\u3002", "method": "MoveGCL\u901a\u8fc7\u751f\u6210\u6301\u7eed\u5b66\u4e60\u7684\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u51bb\u7ed3\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u8f68\u8ff9\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u548c\u6e10\u8fdb\u7684\u6a21\u578b\u6f14\u53d8\uff0c\u5e76\u901a\u8fc7\u5b9a\u5236\u7684\u84b8\u998f\u7b56\u7565\u52a0\u5f3a\u77e5\u8bc6\u4fdd\u7559\uff0c\u540c\u65f6\u4f7f\u7528\u4e13\u5bb6\u6df7\u5408Transformer\u548c\u9010\u5c42\u6e10\u8fdb\u9002\u5e94\u7b56\u7565\u4ee5\u7a33\u5b9a\u6301\u7eed\u66f4\u65b0\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u57ce\u5e02\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMoveGCL\u7684\u8868\u73b0\u4e0e\u8054\u5408\u8bad\u7ec3\u76f8\u5f53\uff0c\u663e\u8457\u4f18\u4e8e\u8054\u90a6\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "MoveGCL\u6846\u67b6\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u53ef\u4ee5\u4e0e\u8054\u5408\u8bad\u7ec3\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\uff0c\u5e76\u663e\u8457\u8d85\u8d8a\u8054\u90a6\u5b66\u4e60\u57fa\u7ebf\uff0c\u540c\u65f6\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u3002\u8fd9\u6807\u5fd7\u7740\u4e3a\u4eba\u7c7b\u51fa\u884c\u5efa\u7acb\u57fa\u7840\u6a21\u578b\u7684\u4e00\u4e2a\u5173\u952e\u8fdb\u5c55\u3002"}}
{"id": "2506.07527", "pdf": "https://arxiv.org/pdf/2506.07527", "abs": "https://arxiv.org/abs/2506.07527", "authors": ["Lu Ma", "Hao Liang", "Meiyi Qiang", "Lexiang Tang", "Xiaochen Ma", "Zhen Hao Wong", "Junbo Niu", "Chengyu Shen", "Runming He", "Bin Cui", "Wentao Zhang"], "title": "Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions", "categories": ["cs.AI", "cs.LG"], "comment": "12 pages, 5 figures", "summary": "Recent advances in large language model (LLM) reasoning have shown that\nsophisticated behaviors such as planning and self-reflection can emerge through\nreinforcement learning (RL). However, despite these successes, RL in its\ncurrent form remains insufficient to induce capabilities that exceed the\nlimitations of the base model, as it is primarily optimized based on existing\nknowledge of the model rather than facilitating the acquisition of new\ninformation. To address this limitation, we employ supervised fine-tuning (SFT)\nto learn what RL cannot, which enables the incorporation of new knowledge and\nreasoning patterns by leveraging high-quality demonstration data. We analyze\nthe training dynamics of RL and SFT for LLM reasoning and find that RL excels\nat maintaining and improving performance on questions within the model's\noriginal capabilities, while SFT is more effective at enabling progress on\nquestions beyond the current scope of the model. Motivated by the complementary\nstrengths of RL and SFT, we introduce a novel training approach,\n\\textbf{ReLIFT} (\\textbf{Re}inforcement \\textbf{L}earning \\textbf{I}nterleaved\nwith Online \\textbf{F}ine-\\textbf{T}uning). In ReLIFT, the model is primarily\ntrained using RL, but when it encounters challenging questions, high-quality\nsolutions are collected for fine-tuning, and the training process alternates\nbetween RL and fine-tuning to enhance the model's reasoning abilities. ReLIFT\nachieves an average improvement of over +5.2 points across five\ncompetition-level benchmarks and one out-of-distribution benchmark compared to\nother zero-RL models. Furthermore, we demonstrate that ReLIFT outperforms both\nRL and SFT while using only 13\\% of the detailed demonstration data,\nhighlighting its scalability. These results provide compelling evidence that\nReLIFT overcomes the fundamental limitations of RL and underscores the\nsignificant potential.", "AI": {"tldr": "ReLIFT\u7ed3\u5408RL\u548c\u76d1\u7763\u5fae\u8c03\uff0c\u5927\u5e45\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u8d85\u8fc7\u5355\u4e00\u65b9\u6cd5\uff0c\u5e76\u663e\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u65e0\u6cd5\u4fc3\u4f7f\u6a21\u578b\u7a81\u7834\u5176\u56fa\u6709\u9650\u5236\u3002\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff0c\u53ef\u4ee5\u5f25\u8865RL\u4e0d\u80fd\u4e60\u5f97\u7684\u65b0\u77e5\u8bc6\u548c\u63a8\u7406\u6a21\u5f0f\u3002", "method": "\u4f7f\u7528ReLIFT\u65b9\u6cd5\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u9ad8\u8d28\u91cf\u6570\u636e\u7684\u76d1\u7763\u5fae\u8c03\u4ea4\u66ff\u8fdb\u884c\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "ReLIFT\u5728\u4e94\u4e2a\u7ade\u8d5b\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e00\u4e2a\u5206\u5e03\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u5347\u8d85\u8fc75.2\u5206\uff0c\u5e76\u4e14\u5728\u4ec5\u4f7f\u752813%\u7684\u6f14\u793a\u6570\u636e\u60c5\u51b5\u4e0b\uff0c\u8d85\u8fc7\u4e86\u5355\u7eaf\u4f7f\u7528RL\u548cSFT\u7684\u65b9\u6cd5\u3002", "conclusion": "ReLIFT\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7a81\u7834\u4e86RL\u7684\u56fa\u6709\u5c40\u9650\uff0c\u5e76\u4e14\u5728\u6709\u9650\u6570\u636e\u7684\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.06971", "pdf": "https://arxiv.org/pdf/2506.06971", "abs": "https://arxiv.org/abs/2506.06971", "authors": ["Jaechul Roh", "Varun Gandhi", "Shivani Anilkumar", "Arin Garg"], "title": "Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in tasks\nrequiring complex reasoning, such as code generation, mathematical problem\nsolving, and algorithmic synthesis -- especially when aided by reasoning tokens\nand Chain-of-Thought prompting. Yet, a core question remains: do these models\ntruly reason, or do they merely exploit shallow statistical patterns? In this\npaper, we systematically investigate the robustness of reasoning LLMs by\nintroducing a suite of semantically faithful yet adversarially structured\nprompt perturbations. Our evaluation -- spanning 700 perturbed code generations\nderived from LeetCode-style problems -- applies transformations such as\nstorytelling reframing, irrelevant constraint injection, example reordering,\nand numeric perturbation. We observe that while certain modifications severely\ndegrade performance (with accuracy drops up to -42.1%), others surprisingly\nimprove model accuracy by up to 35.3%, suggesting sensitivity not only to\nsemantics but also to surface-level prompt dynamics. These findings expose the\nfragility and unpredictability of current reasoning systems, underscoring the\nneed for more principles approaches to reasoning alignments and prompting\nrobustness. We release our perturbation datasets and evaluation framework to\npromote further research in trustworthy and resilient LLM reasoning.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u63d0\u793a\u6270\u52a8\u65f6\u8868\u73b0\u51fa\u8106\u5f31\u6027\uff0c\u63ed\u793a\u5176\u5bf9\u8bed\u4e49\u548c\u63d0\u793a\u52a8\u6001\u7684\u654f\u611f\u6027\u3002", "motivation": "\u63a2\u8ba8\u8fd9\u4e9b\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u5177\u5907\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5229\u7528\u6d45\u5c42\u7edf\u8ba1\u6a21\u5f0f\u3002", "method": "\u5f15\u5165\u4e00\u7cfb\u5217\u5177\u6709\u8bed\u4e49\u6027\u4f46\u7ed3\u6784\u4e0a\u5b58\u5728\u5bf9\u6297\u6027\u7684\u63d0\u793a\u6270\u52a8\uff0c\u8bc4\u4f30\u8fd9\u4e9b\u6270\u52a8\u5bf9LLMs\u7684\u63a8\u7406\u80fd\u529b\u5f71\u54cd\u3002", "result": "\u90e8\u5206\u4fee\u6539\u4f1a\u663e\u8457\u964d\u4f4e\u5176\u8868\u73b0\uff0c\u800c\u53e6\u4e00\u4e9b\u4fee\u6539\u5219\u610f\u5916\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\uff0c\u63ed\u793a\u6a21\u578b\u5bf9\u8bed\u4e49\u548c\u63d0\u793a\u8868\u9762\u5c42\u52a8\u6001\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u63a8\u7406\u7cfb\u7edf\u5b58\u5728\u8106\u5f31\u6027\u548c\u4e0d\u53ef\u9884\u77e5\u6027\uff0c\u9700\u5f00\u53d1\u66f4\u5177\u539f\u5219\u6027\u7684\u63a8\u7406\u5bf9\u9f50\u548c\u63d0\u793a\u7a33\u5065\u6027\u65b9\u6cd5\u3002"}}
{"id": "2506.06699", "pdf": "https://arxiv.org/pdf/2506.06699", "abs": "https://arxiv.org/abs/2506.06699", "authors": ["Rajeev Bhatt Ambati", "James Lester", "Shashank Srivastava", "Snigdha Chaturvedi"], "title": "MarginSel : Max-Margin Demonstration Selection for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel at few-shot learning via in-context\nlearning (ICL). However, the effectiveness of ICL is often sensitive to the\nselection and ordering of demonstration examples. To address this, we present\nMarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that\nselects hard demonstration examples for the ICL prompt, adapting to each test\ninstance. Our approach achieves 2-7% absolute improvement in F1-score across\nclassification tasks, compared to a random selection of examples. We also\nprovide theoretical insights and empirical evidence showing that MarginSel\ninduces max-margin behavior in LLMs by effectively increasing the margin for\nhard examples, analogous to support vectors, thereby shifting the decision\nboundary in a beneficial direction.", "AI": {"tldr": "MarginSel\u901a\u8fc7\u9009\u62e9\u8fb9\u754c\u96be\u4f8b\u5b50\u63d0\u9ad8LLM\u7684ICL\u6027\u80fd\uff0cF1-score\u63d0\u53472-7%\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728ICL\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u6027\u80fd\u5bf9\u793a\u8303\u4f8b\u5b50\u7684\u9009\u62e9\u548c\u987a\u5e8f\u975e\u5e38\u654f\u611f\uff0cMarginSel\u65e8\u5728\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u793a\u8303\u4f8b\u5b50\uff0c\u6539\u5584ICL\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMarginSel\u7684\u4e24\u6b65\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u56f0\u96be\u7684\u793a\u8303\u5b9e\u4f8b\u6765\u63d0\u9ad8LLM\u5728ICL\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u4e0e\u968f\u673a\u9009\u62e9\u793a\u4f8b\u76f8\u6bd4\uff0cMarginSel\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684F1-score\u63d0\u9ad8\u4e862-7%\u3002", "conclusion": "MarginSel\u901a\u8fc7\u9009\u62e9\u56f0\u96be\u7684\u793a\u8303\u4f8b\u5b50\uff0c\u4ee5\u6700\u5927\u7684\u8fb9\u8ddd\u63d0\u9ad8\u4e86LLMs\u7684\u6027\u80fd\uff0c\u663e\u8457\u6539\u5584\u4e86ICL\u7684\u8868\u73b0\u3002"}}
{"id": "2506.07528", "pdf": "https://arxiv.org/pdf/2506.07528", "abs": "https://arxiv.org/abs/2506.07528", "authors": ["Qisheng Hu", "Quanyu Long", "Wenya Wang"], "title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "categories": ["cs.AI"], "comment": "19 pages, 9 figures", "summary": "Multi-hop claim verification is inherently challenging, requiring multi-step\nreasoning to construct verification chains while iteratively searching for\ninformation to uncover hidden bridging facts. This process is fundamentally\ninterleaved, as effective reasoning relies on dynamically retrieved evidence,\nwhile effective search demands reasoning to refine queries based on partial\ninformation. To achieve this, we propose Hierarchical Agent Reasoning and\nInformation Search (HARIS), explicitly modeling the coordinated process of\nreasoning-driven searching and search-informed reasoning. HARIS consists of a\nhigh-level reasoning agent that focuses on constructing the main verification\nchain, generating factual questions when more information is needed, and a\nlow-level search agent that iteratively retrieves more information, refining\nits search based on intermediate findings. This design allows each agent to\nspecialize in its respective task, enhancing verification accuracy and\ninterpretability. HARIS is trained using reinforcement learning with\noutcome-based rewards. Experimental results on the EX-FEVER and HOVER\nbenchmarks demonstrate that HARIS achieves strong performance, greatly\nadvancing multi-hop claim verification.", "AI": {"tldr": "\u63d0\u51faHARIS\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u5c42\u4ee3\u7406\u63a8\u7406\u4e0e\u641c\u7d22\u63d0\u9ad8\u591a\u8df3\u58f0\u660e\u9a8c\u8bc1\u6027\u80fd\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6548\u679c\u663e\u8457\u3002", "motivation": "\u591a\u8df3\u58f0\u660e\u9a8c\u8bc1\u9700\u8981\u591a\u6b65\u9aa4\u63a8\u7406\uff0c\u6784\u5efa\u786e\u8ba4\u94fe\u5e76\u641c\u7d22\u4fe1\u606f\u4ee5\u63ed\u793a\u9690\u85cf\u7684\u4e8b\u5b9e\uff0c\u63a8\u7406\u4e0e\u641c\u7d22\u8fc7\u7a0b\u662f\u4ea4\u7ec7\u7684\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u534f\u8c03\u8fd9\u4e9b\u8fc7\u7a0b\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5c42\u4ee3\u7406\u63a8\u7406\u4e0e\u4fe1\u606f\u641c\u7d22(HARIS)\u6a21\u578b\uff0c\u5305\u62ec\u4e00\u4e2a\u9ad8\u5c42\u63a8\u7406\u4ee3\u7406\u548c\u4e00\u4e2a\u4f4e\u5c42\u641c\u7d22\u4ee3\u7406\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\u5e76\u6839\u636e\u7ed3\u679c\u7ed9\u4e88\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728EX-FEVER\u548cHOVER\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cHARIS\u6a21\u578b\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "HARIS\u6a21\u578b\u63d0\u5347\u4e86\u591a\u8df3\u58f0\u660e\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728EX-FEVER\u548cHOVER\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2506.06972", "pdf": "https://arxiv.org/pdf/2506.06972", "abs": "https://arxiv.org/abs/2506.06972", "authors": ["Yuji Zhang", "Qingyun Wang", "Cheng Qian", "Jiateng Liu", "Chenkai Sun", "Denghui Zhang", "Tarek Abdelzaher", "Chengxiang Zhai", "Preslav Nakov", "Heng Ji"], "title": "Atomic Reasoning for Scientific Table Claim Verification", "categories": ["cs.CL"], "comment": null, "summary": "Scientific texts often convey authority due to their technical language and\ncomplex data. However, this complexity can sometimes lead to the spread of\nmisinformation. Non-experts are particularly susceptible to misleading claims\nbased on scientific tables due to their high information density and perceived\ncredibility. Existing table claim verification models, including\nstate-of-the-art large language models (LLMs), often struggle with precise\nfine-grained reasoning, resulting in errors and a lack of precision in\nverifying scientific claims. Inspired by Cognitive Load Theory, we propose that\nenhancing a model's ability to interpret table-based claims involves reducing\ncognitive load by developing modular, reusable reasoning components (i.e.,\natomic skills). We introduce a skill-chaining schema that dynamically composes\nthese skills to facilitate more accurate and generalizable reasoning with a\nreduced cognitive load. To evaluate this, we create SciAtomicBench, a\ncross-domain benchmark with fine-grained reasoning annotations. With only 350\nfine-tuning examples, our model trained by atomic reasoning outperforms\nGPT-4o's chain-of-thought method, achieving state-of-the-art results with far\nless training data.", "AI": {"tldr": "\u5f15\u5165\u6280\u80fd\u94fe\u6027\u6a21\u5f0f\u4ee5\u51cf\u5c11\u8ba4\u77e5\u8d1f\u8377\uff0c\u63d0\u9ad8\u8868\u683c\u8bba\u636e\u9a8c\u8bc1\u7684\u7cbe\u786e\u6027\uff0c\u4f7f\u7528350\u4e2a\u5fae\u8c03\u793a\u4f8b\u5b9e\u73b0\u4e86\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u79d1\u5b66\u6587\u672c\u7684\u590d\u6742\u6027\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u4fe1\u606f\u7684\u4f20\u64ad\uff0c\u800c\u975e\u4e13\u4e1a\u4eba\u58eb\u5c24\u5176\u5bb9\u6613\u56e0\u79d1\u5b66\u8868\u683c\u611f\u5230\u8bef\u5bfc\u3002\u73b0\u6709\u6a21\u578b\u5728\u7cbe\u7ec6\u5316\u63a8\u7406\u4e0a\u5b58\u5728\u56f0\u96be\u3002", "method": "\u53d7\u5230\u8ba4\u77e5\u8d1f\u8377\u7406\u8bba\u542f\u53d1\uff0c\u5f00\u53d1\u4e86\u6a21\u5757\u5316\u7684\u3001\u53ef\u91cd\u7528\u7684\u63a8\u7406\u7ec4\u4ef6\uff0c\u79f0\u4e3a\u539f\u5b50\u6280\u80fd\uff0c\u5e76\u5f15\u5165\u6280\u80fd\u94fe\u6a21\u5f0f\u4ee5\u51cf\u5c11\u8ba4\u77e5\u8d1f\u8377\u3002", "result": "\u4ec5\u901a\u8fc7350\u4e2a\u5fae\u8c03\u793a\u4f8b\uff0c\u901a\u8fc7\u539f\u5b50\u63a8\u7406\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u79d1\u5b66\u8868\u683c\u8bba\u8bc1\u9a8c\u8bc1\u4e2d\u4f18\u4e8eGPT-4o\u7684\u94fe\u5f0f\u601d\u7ef4\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6210\u679c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u6280\u80fd\u94fe\u6027\u6a21\u5f0f\u5e76\u521b\u5efa\u8de8\u9886\u57df\u57fa\u51c6SciAtomicBench\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u79d1\u5b66\u8bba\u636e\u9a8c\u8bc1\u4e2d\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.06701", "pdf": "https://arxiv.org/pdf/2506.06701", "abs": "https://arxiv.org/abs/2506.06701", "authors": ["Fudong Lin", "Wanrou Du", "Jinchan Liu", "Tarikul Milon", "Shelby Meche", "Wu Xu", "Xiaoqi Qin", "Xu Yuan"], "title": "Do Protein Transformers Have Biological Intelligence?", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "Accepted by European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD 2025)", "summary": "Deep neural networks, particularly Transformers, have been widely adopted for\npredicting the functional properties of proteins. In this work, we focus on\nexploring whether Protein Transformers can capture biological intelligence\namong protein sequences. To achieve our goal, we first introduce a protein\nfunction dataset, namely Protein-FN, providing over 9000 protein data with\nmeaningful labels. Second, we devise a new Transformer architecture, namely\nSequence Protein Transformers (SPT), for computationally efficient protein\nfunction predictions. Third, we develop a novel Explainable Artificial\nIntelligence (XAI) technique called Sequence Score, which can efficiently\ninterpret the decision-making processes of protein models, thereby overcoming\nthe difficulty of deciphering biological intelligence bided in Protein\nTransformers. Remarkably, even our smallest SPT-Tiny model, which contains only\n5.4M parameters, demonstrates impressive predictive accuracy, achieving 94.3%\non the Antibiotic Resistance (AR) dataset and 99.6% on the Protein-FN dataset,\nall accomplished by training from scratch. Besides, our Sequence Score\ntechnique helps reveal that our SPT models can discover several meaningful\npatterns underlying the sequence structures of protein data, with these\npatterns aligning closely with the domain knowledge in the biology community.\nWe have officially released our Protein-FN dataset on Hugging Face Datasets\nhttps://huggingface.co/datasets/Protein-FN/Protein-FN. Our code is available at\nhttps://github.com/fudong03/BioIntelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSequence Protein Transformers\uff08SPT\uff09\u7528\u4e8e\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\uff0c\u5e76\u5229\u7528Sequence Score\u6280\u672f\u89e3\u91ca\u9884\u6d4b\u7ed3\u679c\u3002\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u53d1\u73b0\u4e86\u7b26\u5408\u751f\u7269\u9886\u57df\u77e5\u8bc6\u7684\u5e8f\u5217\u6a21\u5f0f\u3002", "motivation": "\u7814\u7a76Protein Transformers\u80fd\u5426\u5728\u86cb\u767d\u8d28\u5e8f\u5217\u95f4\u6355\u83b7\u751f\u7269\u667a\u80fd\u3002", "method": "\u5f15\u5165\u4e86\u65b0\u7684\u53d8\u538b\u5668\u67b6\u6784Sequence Protein Transformers\uff08SPT\uff09\uff0c\u4ee5\u53ca\u89e3\u91ca\u6027\u4eba\u5de5\u667a\u80fd\u6280\u672fSequence Score\uff0c\u7528\u4e8e\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u548c\u7ed3\u679c\u89e3\u91ca\u3002", "result": "\u6700\u5c0f\u7684SPT-Tiny\u6a21\u578b\u5728\u6297\u751f\u7d20\u8010\u836f\u6027\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e8694.3%\u7684\u51c6\u786e\u7387\uff0c\u5728Protein-FN\u6570\u636e\u96c6\u4e0a\u8fbe\u523099.6%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u80fd\u591f\u53d1\u73b0\u4e0e\u751f\u7269\u5b66\u9886\u57df\u77e5\u8bc6\u4e00\u81f4\u7684\u5e8f\u5217\u7ed3\u6784\u6a21\u5f0f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u65b0\u7684\u53d8\u538b\u5668\u67b6\u6784\u548c\u89e3\u91ca\u6027\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u800c\u4e14\u63ed\u793a\u4e86\u86cb\u767d\u8d28\u5e8f\u5217\u4e2d\u7684\u751f\u7269\u5b66\u6a21\u5f0f\u3002"}}
{"id": "2506.07548", "pdf": "https://arxiv.org/pdf/2506.07548", "abs": "https://arxiv.org/abs/2506.07548", "authors": ["Weiqiang Jin", "Hongyang Du", "Guizhong Liu", "Dong In Kim"], "title": "Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.RO"], "comment": "16 pages; 12figures", "summary": "Multi-agent reinforcement learning (MARL) has achieved strong performance in\ncooperative adversarial tasks. However, most existing methods typically train\nagents against fixed opponent strategies and rely on such meta-static\ndifficulty conditions, which limits their adaptability to changing environments\nand often leads to suboptimal policies. Inspired by the success of curriculum\nlearning (CL) in supervised tasks, we propose a dynamic CL framework for MARL\nthat employs an self-adaptive difficulty adjustment mechanism. This mechanism\ncontinuously modulates opponent strength based on real-time agent training\nperformance, allowing agents to progressively learn from easier to more\nchallenging scenarios. However, the dynamic nature of CL introduces instability\ndue to nonstationary environments and sparse global rewards. To address this\nchallenge, we develop a Counterfactual Group Relative Policy Advantage (CGRPA),\nwhich is tightly coupled with the curriculum by providing intrinsic credit\nsignals that reflect each agent's impact under evolving task demands. CGRPA\nconstructs a counterfactual advantage function that isolates individual\ncontributions within group behavior, facilitating more reliable policy updates\nthroughout the curriculum. CGRPA evaluates each agent's contribution through\nconstructing counterfactual action advantage function, providing intrinsic\nrewards that enhance credit assignment and stabilize learning under\nnon-stationary conditions. Extensive experiments demonstrate that our method\nimproves both training stability and final performance, achieving competitive\nresults against state-of-the-art methods. The code is available at\nhttps://github.com/NICE-HKU/CL2MARL-SMAC.", "AI": {"tldr": "\u5f15\u5165\u52a8\u6001\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\u53ca\u53cd\u4e8b\u5b9e\u4f18\u52bf\u673a\u5236\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7edd\u5927\u591a\u6570\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u503e\u5411\u4e8e\u5728\u56fa\u5b9a\u5bf9\u624b\u7b56\u7565\u4e0b\u8bad\u7ec3\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u9002\u5e94\u52a8\u6001\u73af\u5883\u7684\u80fd\u529b\uff0c\u5e76\u5bfc\u81f4\u6b21\u4f18\u7b56\u7565\u7684\u51fa\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u7a33\u5b9a\u5b66\u4e60\u8fc7\u7a0b\u7684\u53cd\u4e8b\u5b9e\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u52bf\uff08CGRPA\uff09\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u6027\u80fd\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u5e76\u5728\u4e0e\u6700\u65b0\u65b9\u6cd5\u5bf9\u6bd4\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "conclusion": "\u52a8\u6001\u8bfe\u7a0b\u5b66\u4e60\u6846\u67b6\u7ed3\u5408\u53cd\u4e8b\u5b9e\u4f18\u52bf\u673a\u5236\u80fd\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\u548c\u8868\u73b0\u3002"}}
{"id": "2506.06982", "pdf": "https://arxiv.org/pdf/2506.06982", "abs": "https://arxiv.org/abs/2506.06982", "authors": ["Cong Liu", "Jie Wu", "Weigang Wu", "Xu Chen", "Liang Lin", "Wei-Shi Zheng"], "title": "Chain of Methodologies: Scaling Test Time Computation without Training", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) often struggle with complex reasoning tasks due\nto insufficient in-depth insights in their training data, which are typically\nabsent in publicly available documents. This paper introduces the Chain of\nMethodologies (CoM), an innovative and intuitive prompting framework that\nenhances structured thinking by integrating human methodological insights,\nenabling LLMs to tackle complex tasks with extended reasoning. CoM leverages\nthe metacognitive abilities of advanced LLMs, activating systematic reasoning\nthrought user-defined methodologies without explicit fine-tuning. Experiments\nshow that CoM surpasses competitive baselines, demonstrating the potential of\ntraining-free prompting methods as robust solutions for complex reasoning tasks\nand bridging the gap toward human-level reasoning through human-like\nmethodological insights.", "AI": {"tldr": "CoM\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u65b9\u6cd5\u8bba\u89c1\u89e3\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5c31\u80fd\u5b9e\u73b0\u8d85\u8d8a\u7ade\u4e89\u57fa\u7ebf\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u91cf\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u662f\u7531\u4e8e\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u7f3a\u4e4f\u6df1\u5165\u7684\u89c1\u89e3\uff0c\u800c\u8fd9\u4e9b\u89c1\u89e3\u901a\u5e38\u5728\u516c\u5f00\u7684\u6587\u6863\u4e2d\u662f\u7f3a\u5931\u7684\u3002", "method": "\u4f7f\u7528Chain of Methodologies (CoM)\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4eba\u7c7b\u7684\u65b9\u6cd5\u8bba\u89c1\u89e3\uff0c\u542f\u7528\u9ad8\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u5143\u8ba4\u77e5\u80fd\u529b\uff0c\u6fc0\u6d3b\u7528\u6237\u5b9a\u4e49\u7684\u65b9\u6cd5\u8bba\u8fdb\u884c\u7cfb\u7edf\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCoM\u8d85\u8fc7\u4e86\u7ade\u4e89\u57fa\u7ebf\uff0c\u8bc1\u660e\u4e86\u65e0\u9700\u8bad\u7ec3\u7684\u63d0\u793a\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "CoM\u6846\u67b6\u80fd\u591f\u8d85\u8d8a\u7ade\u4e89\u57fa\u7ebf\uff0c\u4f5c\u4e3a\u4e00\u79cd\u8bad\u7ec3\u81ea\u7531\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7f29\u5c0f\u4e86\u901a\u5411\u4eba\u7c7b\u6c34\u5e73\u63a8\u7406\u7684\u5dee\u8ddd\u3002"}}
{"id": "2506.06715", "pdf": "https://arxiv.org/pdf/2506.06715", "abs": "https://arxiv.org/abs/2506.06715", "authors": ["Minh-Duc Nguyen", "Dung D. Le"], "title": "A Framework for Controllable Multi-objective Learning with Annealed Stein Variational Hypernetworks", "categories": ["cs.LG", "stat.ML"], "comment": "Paper is under review", "summary": "Pareto Set Learning (PSL) is popular as an efficient approach to obtaining\nthe complete optimal solution in Multi-objective Learning (MOL). A set of\noptimal solutions approximates the Pareto set, and its mapping is a set of\ndense points in the Pareto front in objective space. However, some current\nmethods face a challenge: how to make the Pareto solution is diverse while\nmaximizing the hypervolume value. In this paper, we propose a novel method to\naddress this challenge, which employs Stein Variational Gradient Descent (SVGD)\nto approximate the entire Pareto set. SVGD pushes a set of particles towards\nthe Pareto set by applying a form of functional gradient descent, which helps\nto converge and diversify optimal solutions. Additionally, we employ diverse\ngradient direction strategies to thoroughly investigate a unified framework for\nSVGD in multi-objective optimization and adapt this framework with an annealing\nschedule to promote stability. We introduce our method, SVH-MOL, and validate\nits effectiveness through extensive experiments on multi-objective problems and\nmulti-task learning, demonstrating its superior performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5SVH-MOL\uff0c\u4f7f\u7528SVGD\u8fd1\u4f3cPareto\u96c6\u5408\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5353\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4e00\u4e9b\u65b9\u6cd5\u5728\u591a\u76ee\u6807\u5b66\u4e60\u4e2d\u9762\u4e34\u7684\u6311\u6218\u662f\u5982\u4f55\u8ba9Pareto\u89e3\u5728\u6700\u5927\u5316\u4f53\u79ef\u503c\u7684\u540c\u65f6\u4fdd\u6301\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528Stein Variational Gradient Descent (SVGD) \u6765\u8fd1\u4f3c\u6574\u4e2aPareto\u96c6\u5408\u3002", "result": "\u901a\u8fc7\u5728\u591a\u76ee\u6807\u95ee\u9898\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5353\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "SVH-MOL\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3Pareto\u89e3\u7684\u591a\u6837\u6027\u548c\u6700\u5927\u5316\u4f53\u79ef\u503c\u7684\u95ee\u9898\u3002"}}
{"id": "2506.07553", "pdf": "https://arxiv.org/pdf/2506.07553", "abs": "https://arxiv.org/abs/2506.07553", "authors": ["Jingchao Wang", "Haote Yang", "Jiang Wu", "Yifan He", "Xingjian Wei", "Yinfan Wang", "Chengjin Liu", "Lingli Ge", "Lijun Wu", "Bin Wang", "Dahua Lin", "Conghui He"], "title": "GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "Optical Chemical Structure Recognition (OCSR) is crucial for digitizing\nchemical knowledge by converting molecular images into machine-readable\nformats. While recent vision-language models (VLMs) have shown potential in\nthis task, their image-captioning approach often struggles with complex\nmolecular structures and inconsistent annotations. To overcome these\nchallenges, we introduce GTR-Mol-VLM, a novel framework featuring two key\ninnovations: (1) the \\textit{Graph Traversal as Visual Chain of Thought}\nmechanism that emulates human reasoning by incrementally parsing molecular\ngraphs through sequential atom-bond predictions, and (2) the data-centric\nprinciple of \\textit{Faithfully Recognize What You've Seen}, which addresses\nthe mismatch between abbreviated structures in images and their expanded\nannotations. To support model development, we constructed GTR-CoT-1.3M, a\nlarge-scale instruction-tuning dataset with meticulously corrected annotations,\nand introduced MolRec-Bench, the first benchmark designed for a fine-grained\nevaluation of graph-parsing accuracy in OCSR. Comprehensive experiments\ndemonstrate that GTR-Mol-VLM achieves superior results compared to specialist\nmodels, chemistry-domain VLMs, and commercial general-purpose VLMs. Notably, in\nscenarios involving molecular images with functional group abbreviations,\nGTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage\npoints, both in SMILES-based and graph-based metrics. We hope that this work\nwill drive OCSR technology to more effectively meet real-world needs, thereby\nadvancing the fields of cheminformatics and AI for Science. We will release\nGTR-CoT at https://github.com/opendatalab/GTR-CoT.", "AI": {"tldr": "GTR-Mol-VLM is a new framework for optical chemical structure recognition, offering improved accuracy over existing models by implementing a novel graph traversal mechanism and data-centric principles.", "motivation": "To address the challenges in current VLMs' image-captioning approaches, which struggle with complex molecular structures and inconsistent annotations in optical chemical structure recognition.", "method": "The paper introduces the GTR-Mol-VLM framework with two key innovations: the 'Graph Traversal as Visual Chain of Thought' mechanism and the 'Faithfully Recognize What You've Seen' principle. It also develops a large-scale dataset (GTR-CoT-1.3M) and a benchmark (MolRec-Bench) for evaluating graph-parsing accuracy.", "result": "GTR-Mol-VLM outperforms the second-best baseline by approximately 14 percentage points in both SMILES-based and graph-based metrics when dealing with molecular images featuring functional group abbreviations.", "conclusion": "GTR-Mol-VLM significantly outperforms existing models in Optical Chemical Structure Recognition (OCSR), particularly in handling molecular images with functional group abbreviations."}}
{"id": "2506.06987", "pdf": "https://arxiv.org/pdf/2506.06987", "abs": "https://arxiv.org/abs/2506.06987", "authors": ["Senqi Yang", "Dongyu Zhang", "Jing Ren", "Ziqi Xu", "Xiuzhen Zhang", "Yiliao Song", "Hongfei Lin", "Feng Xia"], "title": "Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors", "categories": ["cs.CL"], "comment": "This paper has been accepted to the 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025), Main Conference", "summary": "Metaphors are pervasive in communication, making them crucial for natural\nlanguage processing (NLP). Previous research on automatic metaphor processing\npredominantly relies on training data consisting of English samples, which\noften reflect Western European or North American biases. This cultural skew can\nlead to an overestimation of model performance and contributions to NLP\nprogress. However, the impact of cultural bias on metaphor processing,\nparticularly in multimodal contexts, remains largely unexplored. To address\nthis gap, we introduce MultiMM, a Multicultural Multimodal Metaphor dataset\ndesigned for cross-cultural studies of metaphor in Chinese and English. MultiMM\nconsists of 8,461 text-image advertisement pairs, each accompanied by\nfine-grained annotations, providing a deeper understanding of multimodal\nmetaphors beyond a single cultural domain. Additionally, we propose\nSentiment-Enriched Metaphor Detection (SEMD), a baseline model that integrates\nsentiment embeddings to enhance metaphor comprehension across cultural\nbackgrounds. Experimental results validate the effectiveness of SEMD on\nmetaphor detection and sentiment analysis tasks. We hope this work increases\nawareness of cultural bias in NLP research and contributes to the development\nof fairer and more inclusive language models. Our dataset and code are\navailable at https://github.com/DUTIR-YSQ/MultiMM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MultiMM\u591a\u5143\u6587\u5316\u591a\u6a21\u6001\u9690\u55bb\u6570\u636e\u96c6\u548cSEMD\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u8de8\u6587\u5316\u9690\u55bb\u7406\u89e3\uff0c\u89e3\u51b3\u73b0\u6709\u9690\u55bb\u5904\u7406\u7684\u6587\u5316\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u76ee\u524d\u7684\u9690\u55bb\u5904\u7406\u5927\u591a\u57fa\u4e8e\u82f1\u8bed\u6837\u672c\uff0c\u5f80\u5f80\u53cd\u6620\u51fa\u897f\u6b27\u6216\u5317\u7f8e\u7684\u6587\u5316\u504f\u89c1\u3002\u4ece\u800c\u5bfc\u81f4\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u8fc7\u9ad8\u4f30\u8ba1\uff0c\u5f71\u54cdNLP\u7684\u8fdb\u5c55\u3002\u7f3a\u4e4f\u5bf9\u6587\u5316\u504f\u89c1\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u4e2d\u5f71\u54cd\u7684\u7814\u7a76\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMultiMM\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b8461\u5bf9\u6587\u672c-\u56fe\u50cf\u5e7f\u544a\u6837\u672c\uff0c\u4ee5\u53ca\u4e00\u4e2a\u540d\u4e3aSEMD\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5c06\u60c5\u611f\u5d4c\u5165\u6574\u5408\u5230\u9690\u55bb\u7406\u89e3\u4e2d\u3002", "result": "SEMD\u6a21\u578b\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u5176\u5728\u9690\u55bb\u68c0\u6d4b\u548c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u8be5\u6a21\u578b\u53ef\u63d0\u9ad8\u8de8\u6587\u5316\u9690\u55bb\u7406\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u5f15\u5165\u4e86MultiMM\u6570\u636e\u96c6\u548cSEMD\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u8de8\u6587\u5316\u80cc\u666f\u4e0b\u9690\u55bb\u5904\u7406\u4e0a\u7684\u6587\u5316\u504f\u89c1\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86SEMD\u5728\u9690\u55bb\u68c0\u6d4b\u548c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.06761", "pdf": "https://arxiv.org/pdf/2506.06761", "abs": "https://arxiv.org/abs/2506.06761", "authors": ["Adri\u00e0 Molina Rodr\u00edguez", "Oriol Ramos Terrades", "Josep Llad\u00f3s"], "title": "The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Achieving robustness in recognition systems across diverse domains is crucial\nfor their practical utility. While ample data availability is usually assumed,\nlow-resource languages, such as ancient manuscripts and non-western languages,\ntend to be kept out of the equations of massive pretraining and foundational\ntechniques due to an under representation. In this work, we aim for building\nmodels which can generalize to new distributions of data, such as alphabets,\nfaster than centralized fine-tune strategies. For doing so, we take advantage\nof the recent advancements in model editing to enhance the incorporation of\nunseen scripts (low-resource learning). In contrast to state-of-the-art\nmeta-learning, we showcase the effectiveness of domain merging in sparse\ndistributions of data, with agnosticity of its relation to the overall\ndistribution or any other prototyping necessity. Even when using the same exact\ntraining data, our experiments showcase significant performance boosts in\n\\textbf{transfer learning} to new alphabets and \\textbf{out-of-domain\nevaluation} in challenging domain shifts, including historical ciphered texts\nand non-Latin scripts. This research contributes a novel approach into building\nmodels that can easily adopt under-represented alphabets and, therefore, enable\ndocument recognition to a wider set of contexts and cultures.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u63d0\u9ad8\u8bc6\u522b\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u8f6c\u79fb\u5b66\u4e60\u548c\u57df\u5916\u8bc4\u4f30\u6027\u80fd\u3002", "motivation": "\u8bc6\u522b\u7cfb\u7edf\u5728\u9762\u5bf9\u4e0d\u540c\u9886\u57df\u65f6\u9700\u8981\u5177\u5907\u9c81\u68d2\u6027\uff0c\u7136\u800c\u4f4e\u8d44\u6e90\u8bed\u8a00\u901a\u5e38\u5728\u5927\u91cf\u9884\u8bad\u7ec3\u548c\u57fa\u7840\u6280\u672f\u4e2d\u88ab\u4f4e\u4f30\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u80fd\u5feb\u901f\u9002\u5e94\u65b0\u6570\u636e\u5206\u5e03\u7684\u6a21\u578b\u3002", "method": "\u5229\u7528\u6700\u65b0\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u901a\u8fc7\u57df\u5408\u5e76\uff0c\u5728\u7a00\u758f\u6570\u636e\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\u5c55\u793a\u5176\u6709\u6548\u6027\uff0c\u800c\u4e0d\u4f9d\u8d56\u603b\u4f53\u5206\u5e03\u5173\u7cfb\u6216\u5176\u4ed6\u539f\u578b\u9700\u6c42\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4ee5\u76f8\u540c\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u8f6c\u79fb\u5b66\u4e60\u4f53\u9a8c\u65b0\u7684\u5b57\u6bcd\u8868\u548c\u57df\u5916\u8bc4\u4f30\u4e2d\u5c55\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u9002\u7528\u4e8e\u5305\u62ec\u5386\u53f2\u52a0\u5bc6\u6587\u672c\u548c\u975e\u62c9\u4e01\u5b57\u6bcd\u7684\u6311\u6218\u6027\u57df\u79fb\u4f4d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u6784\u5efa\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u8f83\u8f7b\u677e\u5730\u9002\u5e94\u672a\u88ab\u5145\u5206\u4ee3\u8868\u7684\u5b57\u6bcd\u7cfb\u7edf\uff0c\u4ece\u800c\u652f\u6301\u6587\u6863\u8bc6\u522b\u5728\u66f4\u5e7f\u6cdb\u7684\u80cc\u666f\u548c\u6587\u5316\u4e2d\u5e94\u7528\u3002"}}
{"id": "2506.07564", "pdf": "https://arxiv.org/pdf/2506.07564", "abs": "https://arxiv.org/abs/2506.07564", "authors": ["Peiran Li", "Xinkai Zou", "Zhuohang Wu", "Ruifeng Li", "Shuo Xing", "Hanwen Zheng", "Zhikai Hu", "Yuping Wang", "Haoxi Li", "Qin Yuan", "Yingmo Zhang", "Zhengzhong Tu"], "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-grained information flow control (IFC),\nprecisely tracking provenance, integrity, and confidentiality of all the data\nexchanged between agents, tools, users, and environments. By constraining LLM\nreasoning to respect these security labels, SAFEFLOW prevents untrusted or\nadversarial inputs from contaminating high-integrity decisions. To ensure\nrobustness in concurrent multi-agent settings, SAFEFLOW introduces\ntransactional execution, conflict resolution, and secure scheduling over shared\nstate, preserving global consistency across agents. We further introduce\nmechanisms, including write-ahead logging, rollback, and secure caches, that\nfurther enhance resilience against runtime errors and policy violations. To\nvalidate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark\nsuite designed to evaluate agent reliability under adversarial, noisy, and\nconcurrent operational conditions. Extensive experiments demonstrate that\nagents built with SAFEFLOW maintain impressive task performance and security\nguarantees even in hostile environments, substantially outperforming\nstate-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for\nprincipled, robust, and secure agent ecosystems, advancing the frontier of\nreliable autonomy.", "AI": {"tldr": "SAFEFLOW\u662f\u4e00\u4e2a\u7528\u4e8eLLM/VLM\u4ee3\u7406\u6784\u5efa\u7684\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u4fe1\u606f\u6d41\u63a7\u5236\u53ca\u5b89\u5168\u6027\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u5b83\u5728\u590d\u6742\u73af\u5883\u4e2d\u6bd4\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u4ee3\u7406\u6846\u67b6\u7f3a\u4e4f\u5b89\u5168\u7684\u4fe1\u606f\u6d41\u3001\u53ef\u9760\u6027\u548c\u591a\u4ee3\u7406\u534f\u8c03\u673a\u5236\u3002", "method": "SAFEFLOW\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u4fe1\u606f\u6d41\u63a7\u5236\u3001\u4e8b\u52a1\u6267\u884c\u548c\u51b2\u7a81\u89e3\u51b3\u7b49\u673a\u5236\uff0c\u786e\u4fdd\u4ee3\u7406\u80fd\u591f\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u8fdb\u884c\u53ef\u9760\u64cd\u4f5c\u3002", "result": "\u4f7f\u7528SAFEFLOW\u6784\u5efa\u7684\u4ee3\u7406\u5728\u6076\u52a3\u73af\u5883\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u4efb\u52a1\u6027\u80fd\u548c\u5b89\u5168\u4fdd\u969c\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "SAFEFLOW\u53ca\u5176\u8bc4\u4f30\u57fa\u51c6SAFEFLOWBENCH\u4e3a\u6784\u5efa\u53ef\u9760\u81ea\u6cbb\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.06998", "pdf": "https://arxiv.org/pdf/2506.06998", "abs": "https://arxiv.org/abs/2506.06998", "authors": ["Ming Li", "Zhengyuan Yang", "Xiyao Wang", "Dianqi Li", "Kevin Lin", "Tianyi Zhou", "Lijuan Wang"], "title": "What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models (LRMs) achieve strong reasoning performance by\nemitting long chains of thought. Yet, these verbose traces slow down inference\nand often drift into unnecessary detail, known as the overthinking phenomenon.\nTo better understand LRMs' behavior, we systematically analyze the token-level\nmisalignment between reasoning and non-reasoning models. While it is expected\nthat their primary difference lies in the stylistic \"thinking cues\", LRMs\nuniquely exhibit two pivotal, previously under-explored phenomena: a Global\nMisalignment Rebound, where their divergence from non-reasoning models persists\nor even grows as response length increases, and more critically, a Local\nMisalignment Diminish, where the misalignment concentrates at the \"thinking\ncues\" each sentence starts with but rapidly declines in the remaining of the\nsentence. Motivated by the Local Misalignment Diminish, we propose\nFoReaL-Decoding, a collaborative fast-slow thinking decoding method for\ncost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few\ntokens for each sentence, and then a weaker draft model completes the following\ntokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to\nsmoothly interpolate between the small and the large model. On four popular\nmath-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23),\nFoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by\nup to 40%, while preserving 86 to 100% of model performance. These results\nestablish FoReaL-Decoding as a simple, plug-and-play route to controllable\ncost-quality trade-offs in reasoning-centric tasks.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5e76\u63d0\u51faFoReaL-Decoding\u65b9\u6cd5\u4ee5\u6539\u5584\u6210\u672c\u8d28\u91cf\u6bd4\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u6709\u6548\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u591a\u4f59\u7ec6\u8282\u7684\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5e76\u5206\u6790\u63a8\u7406\u4e0e\u975e\u63a8\u7406\u6a21\u578b\u4e4b\u95f4\u7684token\u7ea7\u522b\u9519\u4f4d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u79f0\u4e3aFoReaL-Decoding\u7684\u534f\u4f5c\u6027\u5feb\u6162\u601d\u7ef4\u89e3\u7801\u65b9\u6cd5\uff0c\u4ee5\u5728\u6210\u672c\u548c\u8d28\u91cf\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u65b9\u6cd5\u5305\u62ec\u8ba9\u4e00\u4e2a\u9886\u5148\u6a21\u578b\u5f15\u5bfc\u6bcf\u4e2a\u53e5\u5b50\u7684\u524d\u51e0\u4e2atoken\uff0c\u7136\u540e\u7531\u8f83\u5f31\u7684\u8349\u7a3f\u6a21\u578b\u5b8c\u6210\u5269\u4f59\u7684token\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u968f\u673a\u95e8\uff0c\u5e73\u6ed1\u5730\u5728\u5c0f\u6a21\u578b\u548c\u5927\u6a21\u578b\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\u3002", "result": "FoReaL-Decoding\u5728\u56db\u4e2a\u6d41\u884c\u7684\u6570\u5b66\u63a8\u7406\u57fa\u51c6(AIME24, GPQA-Diamond, MATH500, AMC23)\u4e0a\u5c06\u7406\u8bbaFLOPs\u51cf\u5c11\u4e8630\u523050%\uff0c\u5c06\u601d\u7ef4\u94fe\u957f\u5ea6\u4fee\u526a\u4e86\u6700\u591a40%\uff0c\u540c\u65f6\u4fdd\u7559\u4e8686\u5230100%\u7684\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "FoReaL-Decoding\u662f\u4e00\u79cd\u7b80\u5355\u3001\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u63a8\u7406\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u4e2d\u5b9e\u73b0\u53ef\u63a7\u7684\u6210\u672c\u8d28\u91cf\u6743\u8861\u3002"}}
{"id": "2506.06782", "pdf": "https://arxiv.org/pdf/2506.06782", "abs": "https://arxiv.org/abs/2506.06782", "authors": ["Qinting Jiang", "Chuyang Ye", "Dongyan Wei", "Bingli Wang", "Yuan Xue", "Jingyan Jiang", "Zhi Wang"], "title": "Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Despite progress, deep neural networks still suffer performance declines\nunder distribution shifts between training and test domains, leading to a\nsubstantial decrease in Quality of Experience (QoE) for applications. Existing\ntest-time adaptation (TTA) methods are challenged by dynamic, multiple test\ndistributions within batches. We observe that feature distributions across\ndifferent domains inherently cluster into distinct groups with varying means\nand variances. This divergence reveals a critical limitation of previous global\nnormalization strategies in TTA, which inevitably distort the original data\ncharacteristics. Based on this insight, we propose Feature-based Instance\nNeighbor Discovery (FIND), which comprises three key components: Layer-wise\nFeature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and\nSelective FABN (S-FABN). LFD stably captures features with similar\ndistributions at each layer by constructing graph structures. While FABN\noptimally combines source statistics with test-time distribution specific\nstatistics for robust feature representation. Finally, S-FABN determines which\nlayers require feature partitioning and which can remain unified, thereby\nenhancing inference efficiency. Extensive experiments demonstrate that FIND\nsignificantly outperforms existing methods, achieving a 30\\% accuracy\nimprovement in dynamic scenarios while maintaining computational efficiency.", "AI": {"tldr": "\u63d0\u51faFIND\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ec4\u4ef6\u63d0\u9ad8\u52a8\u6001\u6d4b\u8bd5\u573a\u666f\u4e2d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u57df\u7684\u5206\u5e03\u8f6c\u53d8\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u5e94\u7528\u4f53\u9a8c\u8d28\u91cf\u4e0b\u964d\u3002\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\u5728\u52a8\u6001\u3001\u591a\u91cd\u7684\u6d4b\u8bd5\u5206\u5e03\u4e2d\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Feature-based Instance Neighbor Discovery (FIND)\u65b9\u6cd5\uff0c\u5305\u542b\u4e86Layer-wise Feature Disentanglement (LFD)\u3001Feature Aware Batch Normalization (FABN)\u548cSelective FABN (S-FABN)\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\u3002", "result": "\u5728\u52a8\u6001\u573a\u666f\u4e2d\u5b9e\u73b0\u4e8630\uff05\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "FIND significantly enhances performance in dynamic test scenarios, outperforming existing methods by 30% in accuracy while maintaining computational efficiency."}}
{"id": "2506.07591", "pdf": "https://arxiv.org/pdf/2506.07591", "abs": "https://arxiv.org/abs/2506.07591", "authors": ["Shang Qu", "Ning Ding", "Linhai Xie", "Yifei Li", "Zaoqu Liu", "Kaiyan Zhang", "Yibai Xiong", "Yuxin Zuo", "Zhangren Chen", "Ermo Hua", "Xingtai Lv", "Youbang Sun", "Yang Li", "Dong Li", "Fuchu He", "Bowen Zhou"], "title": "Automating Exploratory Multiomics Research via Language Models", "categories": ["cs.AI", "q-bio.QM"], "comment": null, "summary": "This paper introduces PROTEUS, a fully automated system that produces\ndata-driven hypotheses from raw data files. We apply PROTEUS to clinical\nproteogenomics, a field where effective downstream data analysis and hypothesis\nproposal is crucial for producing novel discoveries. PROTEUS uses separate\nmodules to simulate different stages of the scientific process, from open-ended\ndata exploration to specific statistical analysis and hypothesis proposal. It\nformulates research directions, tools, and results in terms of relationships\nbetween biological entities, using unified graph structures to manage complex\nresearch processes. We applied PROTEUS to 10 clinical multiomics datasets from\npublished research, arriving at 360 total hypotheses. Results were evaluated\nthrough external data validation and automatic open-ended scoring. Through\nexploratory and iterative research, the system can navigate high-throughput and\nheterogeneous multiomics data to arrive at hypotheses that balance reliability\nand novelty. In addition to accelerating multiomic analysis, PROTEUS represents\na path towards tailoring general autonomous systems to specialized scientific\ndomains to achieve open-ended hypothesis generation from data.", "AI": {"tldr": "PROTEUS automates hypothesis generation in clinical proteogenomics, producing 360 hypotheses from 10 datasets, and showing promise in automating specialized scientific research.", "motivation": "Effective downstream data analysis and hypothesis proposal are critical for novel discoveries in clinical proteogenomics, necessitating an automated system like PROTEUS.", "method": "PROTEUS simulates scientific processes using separate modules for data exploration, statistical analysis, and hypothesis proposal, managing these with unified graph structures.", "result": "Applied to 10 published datasets, PROTEUS generated 360 hypotheses, which were evaluated using external data validation and scoring.", "conclusion": "PROTEUS successfully generates hypotheses from complex multiomics datasets and represents a promising approach for automating scientific research in specialized domains."}}
{"id": "2506.07001", "pdf": "https://arxiv.org/pdf/2506.07001", "abs": "https://arxiv.org/abs/2506.07001", "authors": ["Yize Cheng", "Vinu Sankar Sadasivan", "Mehrdad Saberi", "Shoumik Saha", "Soheil Feizi"], "title": "Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text", "categories": ["cs.CL"], "comment": null, "summary": "The increasing capabilities of Large Language Models (LLMs) have raised\nconcerns about their misuse in AI-generated plagiarism and social engineering.\nWhile various AI-generated text detectors have been proposed to mitigate these\nrisks, many remain vulnerable to simple evasion techniques such as\nparaphrasing. However, recent detectors have shown greater robustness against\nsuch basic attacks. In this work, we introduce Adversarial Paraphrasing, a\ntraining-free attack framework that universally humanizes any AI-generated text\nto evade detection more effectively. Our approach leverages an off-the-shelf\ninstruction-following LLM to paraphrase AI-generated content under the guidance\nof an AI text detector, producing adversarial examples that are specifically\noptimized to bypass detection. Extensive experiments show that our attack is\nboth broadly effective and highly transferable across several detection\nsystems. For instance, compared to simple paraphrasing attack--which,\nironically, increases the true positive at 1% false positive (T@1%F) by 8.57%\non RADAR and 15.03% on Fast-DetectGPT--adversarial paraphrasing, guided by\nOpenAI-RoBERTa-Large, reduces T@1%F by 64.49% on RADAR and a striking 98.96% on\nFast-DetectGPT. Across a diverse set of detectors--including neural\nnetwork-based, watermark-based, and zero-shot approaches--our attack achieves\nan average T@1%F reduction of 87.88% under the guidance of\nOpenAI-RoBERTa-Large. We also analyze the tradeoff between text quality and\nattack success to find that our method can significantly reduce detection\nrates, with mostly a slight degradation in text quality. Our adversarial setup\nhighlights the need for more robust and resilient detection strategies in the\nlight of increasingly sophisticated evasion techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5bf9\u6297\u6027\u6539\u5199\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u8eb2\u907fAI\u6587\u672c\u68c0\u6d4b\u5668\u7684\u68c0\u6d4b\uff0c\u4e14\u5bf9\u6297\u6027\u6539\u5199\u6bd4\u7b80\u5355\u6539\u5199\u653b\u51fb\u5b9e\u73b0\u66f4\u663e\u8457\u7684\u68c0\u51fa\u7387\u964d\u4f4e\u3002", "motivation": "\u89e3\u51b3AI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u5668\u5bb9\u6613\u88ab\u7b80\u5355\u7684\u6539\u5199\u6280\u672f\u7ed5\u8fc7\u95ee\u9898\uff0c\u5f00\u53d1\u65b0\u7684\u653b\u51fb\u6846\u67b6\u6765\u5c55\u793a\u68c0\u6d4b\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u65e0\u8bad\u7ec3\u653b\u51fb\u6846\u67b6\uff0c\u5373\u5bf9\u6297\u6027\u6539\u5199\uff0c\u4f7f\u7528\u73b0\u6210\u7684\u9075\u5faa\u6307\u4ee4\u7684LLM\u5728AI\u6587\u672c\u68c0\u6d4b\u5668\u7684\u6307\u5bfc\u4e0b\uff0c\u5c06AI\u751f\u6210\u6587\u672c\u8fdb\u884c\u6539\u5199\u4ee5\u8eb2\u907f\u68c0\u6d4b\u3002", "result": "\u5bf9\u6297\u6027\u6539\u5199\u5728\u591a\u4e2a\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u5e7f\u6cdb\u7684\u6709\u6548\u6027\u548c\u9ad8\u8f6c\u79fb\u6027\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u68c0\u51fa\u7387\uff0c\u901a\u5e38\u4ec5\u5bfc\u81f4\u6587\u672c\u8d28\u91cf\u7565\u5fae\u4e0b\u964d\u3002", "conclusion": "\u73b0\u6709\u7684\u68c0\u6d4b\u7cfb\u7edf\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u7ecf\u8fc7\u5bf9\u6297\u6027\u6539\u5199\u7684AI\u751f\u6210\u6587\u672c\u3002"}}
{"id": "2506.06784", "pdf": "https://arxiv.org/pdf/2506.06784", "abs": "https://arxiv.org/abs/2506.06784", "authors": ["Marek \u010cern\u00fd"], "title": "Caterpillar GNN: Replacing Message Passing with Efficient Aggregation", "categories": ["cs.LG", "68T07 (Primary), 05C60, 05C85 (Secondary)", "I.2.6; G.2.2"], "comment": "40 pages, 9 figures, 3 tables", "summary": "Message-passing graph neural networks (MPGNNs) dominate modern graph\nlearning, typically prioritizing maximal expressive power. In contrast, we\nintroduce an \\emph{efficient aggregation} mechanism, deliberately trading off\nsome expressivity for stronger and more structured aggregation capabilities.\nOur approach allows seamless scaling between classical message-passing and\nsimpler methods based on colored or plain walks. We rigorously characterize the\nexpressive power at each intermediate step using homomorphism counts from a\nhierarchy of generalized \\emph{caterpillar graphs}. Based on this foundation,\nwe propose the \\emph{Caterpillar GNN}, whose robust graph-level aggregation\nenables it to successfully tackle synthetic graph-level task specifically\ndesigned to be challenging for classical MPGNNs. Moreover, we demonstrate that,\non real-world datasets, the Caterpillar GNN achieves comparable predictive\nperformance while significantly reducing the number of nodes in the hidden\nlayers of the computational graph.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u9ad8\u6548\u805a\u5408\u673a\u5236\uff0c\u5728\u727a\u7272\u4e00\u4e9b\u8868\u8fbe\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u52a0\u5f3a\u4e86\u805a\u5408\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86Caterpillar GNN\u6a21\u578b\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e0e\u73b0\u6709\u6a21\u578b\u76f8\u4f3c\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u56fe\u4e2d\u9690\u85cf\u5c42\u7684\u8282\u70b9\u6570\u3002", "motivation": "\u76ee\u524d\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u8fc7\u4e8e\u8ffd\u6c42\u6700\u5927\u5316\u8868\u8fbe\u80fd\u529b\uff0c\u56e0\u6b64\u6211\u4eec\u5e0c\u671b\u80fd\u627e\u5230\u4e00\u79cd\u5728\u8868\u8fbe\u80fd\u529b\u548c\u805a\u5408\u80fd\u529b\u4e4b\u95f4\u8fbe\u5230\u6709\u6548\u5e73\u8861\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u805a\u5408\u673a\u5236\uff0c\u901a\u8fc7\u4f7f\u7528\u5e7f\u4e49\u6bdb\u866b\u56fe\u7684\u540c\u6001\u8ba1\u6570\u6765\u5bf9\u6bcf\u4e2a\u4e2d\u95f4\u6b65\u9aa4\u7684\u8868\u8fbe\u80fd\u529b\u8fdb\u884c\u4e25\u683c\u7684\u523b\u753b\u3002", "result": "Caterpillar GNN\u5728\u8bbe\u8ba1\u590d\u6742\u7684\u5408\u6210\u56fe\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u56fe\u795e\u7ecf\u7f51\u7edc\u76f8\u5f53\u7684\u9884\u6d4b\u6548\u679c\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u56fe\u4e2d\u9690\u85cf\u5c42\u8282\u70b9\u7684\u6570\u91cf\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u9ad8\u6548\u805a\u5408\u673a\u5236\uff0cCaterpillar GNN\u6a21\u578b\u5728\u4fdd\u6301\u826f\u597d\u7684\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u4e86\u56fe\u7ea7\u522b\u7684\u805a\u5408\u80fd\u529b\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.07636", "pdf": "https://arxiv.org/pdf/2506.07636", "abs": "https://arxiv.org/abs/2506.07636", "authors": ["Haoran Wang", "Zhenyu Hou", "Yao Wei", "Jie Tang", "Yuxiao Dong"], "title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "categories": ["cs.AI"], "comment": "Accepted to Findings of ACL'25", "summary": "Large language models (LLMs) have advanced rapidly from conversational\nproblem solving to addressing real-world tasks involving tool use, such as\nsoftware engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex\nand Cursor, have offered end-to-end automation of the software development\nprocess. However, building effective SWE agents remains challenging due to the\nlack of high-quality training data and effective test cases. To address this\nissue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we\ndevelop a robust pipeline to synthesize test cases for patch evaluation.\nSecond, we scale up agent trajectories to construct the training data for\nbuilding SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the\nSWE-Dev models can achieve top performance among all open SWE agents.\nSpecifically, the success rates of the SWE-Dev 7B and 32B parameter models\nreach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source\nmodels. All code, models, and datasets are publicly available at\nhttps://github.com/THUDM/SWE-Dev.", "AI": {"tldr": "SWE-Dev\u662f\u57fa\u4e8e\u5f00\u6e90LLM\u6784\u5efa\u7684SWE\u4ee3\u7406\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6d4b\u8bd5\u7528\u4f8b\u5408\u6210\u6d41\u7a0b\u548c\u9ad8\u6548\u7684\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u65b9\u6cd5\uff0c\u5728SWE-bench-Verified\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6027\u80fd\u3002", "motivation": "\u76ee\u524d\u6784\u5efa\u6709\u6548\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u662f\u7531\u4e8e\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u548c\u6709\u6548\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u5957\u575a\u5b9e\u7684\u6d41\u7a0b\u6765\u5408\u6210\u7528\u4e8e\u8865\u4e01\u8bc4\u4f30\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u6269\u5927\u4e86\u4ee3\u7406\u8f68\u8ff9\u4ee5\u6784\u5efaSWE-Dev\u7684\u8bad\u7ec3\u6570\u636e\u3002", "result": "SWE-Dev\u6a21\u578b\u5728SWE-bench-Verified\u57fa\u51c6\u4e0a\u8868\u73b0\u5353\u8d8a\uff0c\u8d85\u8fc7\u4e86\u6240\u6709\u73b0\u6709\u7684\u5f00\u6e90\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u3002", "conclusion": "SWE-Dev\u5728SWE-bench-Verified\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c7B\u548c32B\u53c2\u6570\u6a21\u578b\u7684\u6210\u529f\u7387\u5206\u522b\u8fbe\u523023.4%\u548c36.6%\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u5f00\u6e90\u6a21\u578b\u3002"}}
{"id": "2506.07032", "pdf": "https://arxiv.org/pdf/2506.07032", "abs": "https://arxiv.org/abs/2506.07032", "authors": ["Bhuiyan Sanjid Shafique", "Ashmal Vayani", "Muhammad Maaz", "Hanoona Abdul Rasheed", "Dinura Dissanayake", "Mohammed Irfan Kurpath", "Yahya Hmaiti", "Go Inoue", "Jean Lahoud", "Md. Safirur Rashid", "Shadid Intisar Quasem", "Maheen Fatima", "Franco Vidal", "Mykola Maslych", "Ketan Pravin More", "Sanoojan Baliah", "Hasindri Watawana", "Yuhao Li", "Fabian Farestam", "Leon Schaller", "Roman Tymtsiv", "Simon Weber", "Hisham Cholakkal", "Ivan Laptev", "Shin'ichi Satoh", "Michael Felsberg", "Mubarak Shah", "Salman Khan", "Fahad Shahbaz Khan"], "title": "A Culturally-diverse Multilingual Multimodal Video Benchmark & Model", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Large multimodal models (LMMs) have recently gained attention due to their\neffectiveness to understand and generate descriptions of visual content. Most\nexisting LMMs are in English language. While few recent works explore\nmultilingual image LMMs, to the best of our knowledge, moving beyond the\nEnglish language for cultural and linguistic inclusivity is yet to be\ninvestigated in the context of video LMMs. In pursuit of more inclusive video\nLMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, to\nevaluate Video LMMs across 14 languages, including both low- and high-resource\nlanguages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,\nBengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench is\ndesigned to rigorously test video LMMs across 15 categories including eight\nculturally diverse categories, ranging from lifestyles and festivals to foods\nand rituals and from local landmarks to prominent cultural personalities.\nViMUL-Bench comprises both open-ended (short and long-form) and multiple-choice\nquestions spanning various video durations (short, medium, and long) with 8k\nsamples that are manually verified by native language speakers. In addition, we\nalso introduce a machine translated multilingual video training set comprising\n1.2 million samples and develop a simple multilingual video LMM, named ViMUL,\nthat is shown to provide a better tradeoff between high-and low-resource\nlanguages for video understanding. We hope our ViMUL-Bench and multilingual\nvideo LMM along with a large-scale multilingual video training set will help\nease future research in developing cultural and linguistic inclusive\nmultilingual video LMMs. Our proposed benchmark, video LMM and training data\nwill be publicly released at https://mbzuai-oryx.github.io/ViMUL/.", "AI": {"tldr": "\u5f15\u5165ViMUL-Bench\u8fdb\u884c\u591a\u8bed\u8a00\u89c6\u9891LMM\u8bc4\u4f30\uff0c\u5e76\u5f00\u53d1ViMUL\u4ee5\u63a8\u8fdb\u6587\u5316\u548c\u8bed\u8a00\u5305\u5bb9\u6027\u7814\u7a76\u3002", "motivation": "\u63a2\u7d22\u8d85\u8d8a\u82f1\u8bed\u7684\u591a\u8bed\u8a00\u89c6\u9891LMM\uff0c\u4ee5\u5b9e\u73b0\u6587\u5316\u548c\u8bed\u8a00\u5305\u5bb9\u6027\u3002", "method": "\u5f15\u5165ViMUL-Bench\u57fa\u51c6\u6765\u8bc4\u4f30\u89c6\u9891LMM\uff0c\u5e76\u5f00\u53d1\u4e86ViMUL\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5f00\u53d1\u4e86ViMUL-Bench\u6765\u6d4b\u8bd5\u89c6\u9891LMM\uff0c\u5e76\u5f15\u5165\u4e86\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u89c6\u9891\u8bad\u7ec3\u96c6\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002", "conclusion": "ViMUL-Bench\u548cViMUL\u7684\u5f00\u53d1\u65e8\u5728\u4fc3\u8fdb\u6587\u5316\u548c\u8bed\u8a00\u5305\u5bb9\u7684\u591a\u8bed\u8a00\u89c6\u9891LMM\u7814\u7a76\u3002"}}
{"id": "2506.06787", "pdf": "https://arxiv.org/pdf/2506.06787", "abs": "https://arxiv.org/abs/2506.06787", "authors": ["Qiyun Zhao"], "title": "FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "As integrated circuit scale grows and design complexity rises, effective\ncircuit representation helps support logic synthesis, formal verification, and\nother automated processes in electronic design automation. And-Inverter Graphs\n(AIGs), as a compact and canonical structure, are widely adopted for\nrepresenting Boolean logic in these workflows. However, the increasing\ncomplexity and integration density of modern circuits introduce structural\nheterogeneity and global logic information loss in AIGs, posing significant\nchallenges to accurate circuit modeling. To address these issues, we propose\nFuncGNN, which integrates hybrid feature aggregation to extract\nmulti-granularity topological patterns, thereby mitigating structural\nheterogeneity and enhancing logic circuit representations. FuncGNN further\nintroduces gate-aware normalization that adapts to circuit-specific gate\ndistributions, improving robustness to structural heterogeneity. Finally,\nFuncGNN employs multi-layer integration to merge intermediate features across\nlayers, effectively synthesizing local and global semantic information for\ncomprehensive logic representations. Experimental results on two logic-level\nanalysis tasks (i.e., signal probability prediction and truth-table distance\nprediction) demonstrate that FuncGNN outperforms existing state-of-the-art\nmethods, achieving improvements of 2.06% and 18.71%, respectively, while\nreducing training time by approximately 50.6% and GPU memory usage by about\n32.8%.", "AI": {"tldr": "FuncGNN enhances logic circuit representation by addressing heterogeneity and merging semantic information, outperforming existing methods in performance and efficiency.", "motivation": "The increasing complexity and density of modern integrated circuits cause structural heterogeneity and global logic information loss in And-Inverter Graphs (AIGs), challenging accurate circuit modeling.", "method": "FuncGNN integrates hybrid feature aggregation, gate-aware normalization, and multi-layer integration to enhance logic circuit representations. It addresses structural heterogeneity and merges local and global semantic information effectively.", "result": "FuncGNN outperforms state-of-the-art methods in signal probability prediction and truth-table distance prediction, improving performance by 2.06% and 18.71%, respectively. It also reduces training time by 50.6% and GPU memory usage by 32.8%.", "conclusion": "FuncGNN significantly improves the representation of complex logic circuits, demonstrated by its superior performance in logic-level analysis tasks while reducing computational resources."}}
{"id": "2506.07672", "pdf": "https://arxiv.org/pdf/2506.07672", "abs": "https://arxiv.org/abs/2506.07672", "authors": ["Yunhe Yan", "Shihe Wang", "Jiajun Du", "Yexuan Yang", "Yuxuan Shan", "Qichen Qiu", "Xianqing Jia", "Xinge Wang", "Xin Yuan", "Xu Han", "Mao Qin", "Yinxiao Chen", "Chen Peng", "Shangguang Wang", "Mengwei Xu"], "title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents", "categories": ["cs.AI"], "comment": null, "summary": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative\ntechnique to automate human-computer interaction. However, existing CUA\nbenchmarks predominantly target GUI agents, whose evaluation methods are\nsusceptible to UI changes and ignore function interactions exposed by\napplication APIs, e.g., Model Context Protocol (MCP). To this end, we propose\nMCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid\nagents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those\nwith source code availability and can be revised/re-compiled as needed (e.g.,\nadding MCP support), with two notable advantages:\n  (1) It greatly broadens the design space of CUA, such as what and how the app\nfeatures to be exposed/extracted as CUA-callable APIs.\n  (2) It allows MCPWorld to programmatically verify task completion by directly\nmonitoring application behavior through techniques like dynamic code\ninstrumentation, offering robust, accurate CUA evaluation decoupled from\nspecific agent implementations or UI states.\n  Currently, MCPWorld includes 201 well curated and annotated user tasks,\ncovering diversified use cases and difficulty levels. MCPWorld is also fully\ncontainerized with GPU acceleration support for flexible adoption on different\nOS/hardware environments. Our preliminary experiments, using a representative\nLLM-powered CUA framework, achieve 75.12% task completion accuracy,\nsimultaneously providing initial evidence on the practical effectiveness of\nagent automation leveraging MCP. Overall, we anticipate MCPWorld to facilitate\nand standardize the benchmarking of next-generation computer use agents that\ncan leverage rich external tools. Our code and dataset are publicly available\nat https://github.com/SAAgent/MCPWorld.", "AI": {"tldr": "MCPWorld\u662f\u4e00\u4e2a\u65b0\u9896\u7684CUA\u6d4b\u8bd5\u5e73\u53f0\uff0c\u652f\u6301API\u3001GUI\u548c\u6df7\u5408\u4ee3\u7406\u3002\u5b83\u4f7f\u7528\u767d\u76d2\u5e94\u7528\u7a0b\u5e8f\u4ee5\u589e\u52a0\u8bbe\u8ba1\u7a7a\u95f4\u548c\u9a8c\u8bc1\u4efb\u52a1\u5b8c\u6210\u5ea6\uff0c\u4fc3\u8fdb\u548c\u6807\u51c6\u5316\u4e0b\u4e00\u4ee3CUA\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\u51fa\u826f\u597d\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "motivation": "\u73b0\u6709\u7684CUA\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9GUI\u4ee3\u7406\uff0c\u5176\u8bc4\u4f30\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230UI\u66f4\u6539\u7684\u5f71\u54cd\uff0c\u5e76\u5ffd\u7565\u4e86\u901a\u8fc7\u5e94\u7528\u7a0b\u5e8fAPI\u66b4\u9732\u7684\u529f\u80fd\u4ea4\u4e92, \u5bf9\u6b64\uff0c\u6211\u4eec\u63d0\u8baeMCPWorld\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86MCPWorld\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf9API\u3001GUI\u548cAPI-GUI\u6df7\u5408\u4ee3\u7406\u7684\u81ea\u52a8\u5316CUA\u8bd5\u9a8c\u53f0\u3002MCPWorld\u7684\u4e00\u4e2a\u6838\u5fc3\u539f\u5219\u662f\u4f7f\u7528\"\u767d\u76d2\u5e94\u7528\u7a0b\u5e8f\"\uff0c\u5373\u90a3\u4e9b\u5177\u6709\u6e90\u4ee3\u7801\u53ef\u7528\u6027\u5e76\u53ef\u4ee5\u6839\u636e\u9700\u8981\u4fee\u8ba2/\u91cd\u65b0\u7f16\u8bd1\u7684\u5e94\u7528\u7a0b\u5e8f\u3002", "result": "MCPWorld\u5f53\u524d\u5305\u62ec201\u4e2a\u7cbe\u5fc3\u7b56\u5212\u548c\u6ce8\u91ca\u7684\u7528\u6237\u4efb\u52a1\uff0c\u6db5\u76d6\u591a\u6837\u5316\u7684\u7528\u4f8b\u548c\u96be\u5ea6\u7b49\u7ea7\u3002\u7cfb\u7edf\u8fd8\u5b8c\u5168\u5bb9\u5668\u5316\uff0c\u652f\u6301GPU\u52a0\u901f\uff0c\u4ee5\u4fbf\u5728\u4e0d\u540c\u64cd\u4f5c\u7cfb\u7edf/\u786c\u4ef6\u73af\u5883\u4e0b\u7075\u6d3b\u4f7f\u7528\u3002\u521d\u6b65\u5b9e\u9a8c\u663e\u793a\uff0c\u4f7f\u7528LLM\u9a71\u52a8\u7684CUA\u6846\u67b6\u53ef\u8fbe\u523075.12%\u7684\u4efb\u52a1\u5b8c\u6210\u51c6\u786e\u7387\u3002", "conclusion": "\u6211\u4eec\u7684\u521d\u6b65\u5b9e\u9a8c\u4f7f\u7528\u4e00\u4e2a\u6709\u4ee3\u8868\u6027\u7684LLM\u9a71\u52a8CUA\u6846\u67b6\uff0c\u8fbe\u5230\u4e8675.12%\u7684\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u8fd9\u4e3a\u5229\u7528MCP\u8fdb\u884c\u4ee3\u7406\u81ea\u52a8\u5316\u7684\u5b9e\u9645\u6548\u679c\u63d0\u4f9b\u4e86\u521d\u6b65\u8bc1\u636e\u3002\u6211\u4eec\u9884\u671fMCPWorld\u80fd\u591f\u4fc3\u8fdb\u548c\u6807\u51c6\u5316\u4e0b\u4e00\u4ee3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u4ee3\u7406\u80fd\u5229\u7528\u4e30\u5bcc\u7684\u5916\u90e8\u5de5\u5177\u3002"}}
{"id": "2506.07037", "pdf": "https://arxiv.org/pdf/2506.07037", "abs": "https://arxiv.org/abs/2506.07037", "authors": ["Zhongze Luo", "Weixuan Wan", "Qizhi Zheng", "Yanhong Bai", "Jingyun Sun", "Jian Wang", "Dan Wang"], "title": "KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering", "categories": ["cs.CL"], "comment": "23 pages", "summary": "There are many types of standards in the field of communication. The\ntraditional consulting model has a long cycle and relies on the knowledge and\nexperience of experts, making it difficult to meet the rapidly developing\ntechnological demands. This paper combines the fine-tuning of large language\nmodels with the construction of knowledge graphs to implement an intelligent\nconsultation and question-answering system for communication standards. The\nexperimental results show that after LoRA tuning on the constructed dataset of\n6,587 questions and answers in the field of communication standards,\nQwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the\nfield of communication standards on the test set. BLEU-4 rose from 18.8564 to\n66.8993, and evaluation indicators such as ROUGE also increased significantly,\noutperforming the fine-tuning effect of the comparison model\nLlama-3-8B-Instruct. Based on the ontology framework containing 6 entity\nattributes and 10 relation attributes, a knowledge graph of the communication\nstandard domain containing 13,906 entities and 13,524 relations was\nconstructed, showing a relatively good query accuracy rate. The intelligent\nconsultation and question-answering system enables the fine-tuned model on the\nserver side to access the locally constructed knowledge graph and conduct\ngraphical retrieval of key information first, which is conducive to improving\nthe question-answering effect. The evaluation using DeepSeek as the Judge on\nthe test set shows that our RAG framework enables the fine-tuned model to\nimprove the scores at all five angles, with an average score increase of 2.26%.\nAnd combined with web services and API interfaces, it has achieved very good\nresults in terms of interaction experience and back-end access, and has very\ngood practical application value.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u667a\u80fd\u54a8\u8be2\u548c\u95ee\u7b54\u7cfb\u7edf\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6807\u51c6\u9886\u57df\u7684\u54a8\u8be2\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u54a8\u8be2\u6a21\u578b\u5468\u671f\u8f83\u957f\u4e14\u4f9d\u8d56\u4e13\u5bb6\u7684\u77e5\u8bc6\u4e0e\u7ecf\u9a8c\uff0c\u96be\u4ee5\u6ee1\u8db3\u5feb\u901f\u53d1\u5c55\u7684\u6280\u672f\u9700\u6c42\u3002", "method": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u4e0e\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u76f8\u7ed3\u5408\uff0c\u5f00\u53d1\u9762\u5411\u901a\u4fe1\u6807\u51c6\u7684\u667a\u80fd\u54a8\u8be2\u548c\u95ee\u7b54\u7cfb\u7edf\u3002", "result": "\u7ecf\u8fc7\u5728\u901a\u4fe1\u6807\u51c6\u9886\u57df\u6784\u5efa\u76846587\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8fdb\u884cLoRA\u5fae\u8c03\u540e\uff0cQwen2.5-7B-Instruct\u5728\u6d4b\u8bd5\u96c6\u4e0a\u663e\u793a\u51fa\u4f18\u5f02\u7684\u4e13\u4e1a\u80fd\u529b\u3002BLEU-4\u4ece18.8564\u63d0\u9ad8\u523066.8993\uff0cROUGE\u7b49\u8bc4\u4f30\u6307\u6807\u663e\u8457\u63d0\u9ad8\uff0c\u8d85\u8fc7\u4e86\u6bd4\u8f83\u6a21\u578bLlama-3-8B-Instruct\u7684\u5fae\u8c03\u6548\u679c\u3002\u6b64\u5916\uff0c\u6784\u5efa\u4e86\u5305\u542b13906\u4e2a\u5b9e\u4f53\u548c13524\u4e2a\u5173\u7cfb\u7684\u901a\u4fe1\u6807\u51c6\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u793a\u51fa\u8f83\u597d\u7684\u67e5\u8be2\u51c6\u786e\u7387\u3002\u7ed3\u5408DeepSeek\u8bc4\u4f30\uff0cRAG\u6846\u67b6\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8bc4\u5206\uff0c\u5e73\u5747\u63d0\u9ad82.26%\uff1b\u7ed3\u5408Web\u670d\u52a1\u548cAPI\u63a5\u53e3\uff0c\u4ea4\u4e92\u4f53\u9a8c\u548c\u540e\u7aef\u63a5\u5165\u6548\u679c\u4f18\u826f\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u7ed3\u5408\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u7684\u667a\u80fd\u54a8\u8be2\u95ee\u7b54\u7cfb\u7edf\u5728\u901a\u4fe1\u6807\u51c6\u9886\u57df\u5c55\u73b0\u51fa\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.06793", "pdf": "https://arxiv.org/pdf/2506.06793", "abs": "https://arxiv.org/abs/2506.06793", "authors": ["Zixuan Dong", "Yumi Omori", "Keith Ross"], "title": "Is Optimal Transport Necessary for Inverse Reinforcement Learning?", "categories": ["cs.LG", "cs.AI"], "comment": "19 pages, 10 tables", "summary": "Inverse Reinforcement Learning (IRL) aims to recover a reward function from\nexpert demonstrations. Recently, Optimal Transport (OT) methods have been\nsuccessfully deployed to align trajectories and infer rewards. While OT-based\nmethods have shown strong empirical results, they introduce algorithmic\ncomplexity, hyperparameter sensitivity, and require solving the OT optimization\nproblems. In this work, we challenge the necessity of OT in IRL by proposing\ntwo simple, heuristic alternatives: (1) Minimum-Distance Reward, which assigns\nrewards based on the nearest expert state regardless of temporal order; and (2)\nSegment-Matching Reward, which incorporates lightweight temporal alignment by\nmatching agent states to corresponding segments in the expert trajectory. These\nmethods avoid optimization, exhibit linear-time complexity, and are easy to\nimplement. Through extensive evaluations across 32 online and offline\nbenchmarks with three reinforcement learning algorithms, we show that our\nsimple rewards match or outperform recent OT-based approaches. Our findings\nsuggest that the core benefits of OT may arise from basic proximity alignment\nrather than its optimal coupling formulation, advocating for reevaluation of\ncomplexity in future IRL design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7b80\u5355\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u66ff\u4ee3OT\u65b9\u6cd5\u7528\u4e8e\u9006\u5411\u5f3a\u5316\u5b66\u4e60\uff0c\u5c55\u73b0\u51fa\u5b83\u4eec\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0eOT\u65b9\u6cd5\u7684\u7b49\u6548\u6216\u66f4\u4f18\u6548\u679c\uff0c\u5efa\u8bae\u91cd\u65b0\u5ba1\u89c6\u672a\u6765\u9006\u5411\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u4e2d\u7684\u590d\u6742\u6027\u3002", "motivation": "\u8d28\u7591\u5728\u9006\u5411\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f7f\u7528OT\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u7b80\u5355\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u89e3\u51b3OT\u65b9\u6cd5\u6240\u5f15\u5165\u7684\u7b97\u6cd5\u590d\u6742\u6027\u548c\u8d85\u53c2\u6570\u654f\u611f\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b80\u5355\u7684\u542f\u53d1\u5f0f\u66ff\u4ee3\u65b9\u6cd5\uff1aMinimum-Distance Reward \u548c Segment-Matching Reward\uff0c\u907f\u514d\u4e86\u4f18\u5316\u95ee\u9898\uff0c\u4e14\u5b9e\u73b0\u7b80\u4fbf\uff0c\u590d\u6742\u5ea6\u4e3a\u7ebf\u6027\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u4e0e\u4e09\u4e2a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u8bc1\u660e\u7b80\u5355\u5956\u52b1\u7684\u65b9\u6cd5\u6709\u6548\u5730\u5339\u914d\u6216\u8d85\u8d8a\u4e86OT\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u7b80\u5355\u65b9\u6cd5\u572832\u4e2a\u5728\u7ebf\u548c\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e0e\u6216\u4f18\u4e8e\u6700\u8fd1\u7684\u57fa\u4e8eOT\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.07731", "pdf": "https://arxiv.org/pdf/2506.07731", "abs": "https://arxiv.org/abs/2506.07731", "authors": ["Mouadh Yagoubi", "Yasser Dahou", "Billel Mokeddem", "Younes Belkada", "Phuc H. Le-Khac", "Basma El Amel Boussaha", "Reda Alami", "Jingwei Zuo", "Damiano Marsili", "Mugariya Farooq", "Mounia Lalmas", "Georgia Gkioxari", "Patrick Gallinari", "Philip Torr", "Hakim Hacid"], "title": "NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks have proven effective for assessing the performance of\nfully trained large language models. However, we find striking differences in\nthe early training stages of small models, where benchmarks often fail to\nprovide meaningful or discriminative signals. To explore how these differences\narise, this competition tackles the challenge of designing scientific knowledge\nevaluation tasks specifically tailored for measuring early training progress of\nlanguage models. Participants are invited to develop novel evaluation\nmethodologies or adapt existing benchmarks to better capture performance\ndifferences among language models. To support this effort, we provide three\npre-trained small models (0.5B, 1B, and 3B parameters), along with intermediate\ncheckpoints sampled during training up to 200B tokens. All experiments and\ndevelopment work can be run on widely available free cloud-based GPU platforms,\nmaking participation accessible to researchers with limited computational\nresources. Submissions will be evaluated based on three criteria: the quality\nof the performance signal they produce, the consistency of model rankings at 1\ntrillion tokens of training, and their relevance to the scientific knowledge\ndomain. By promoting the design of tailored evaluation strategies for early\ntraining, this competition aims to attract a broad range of participants from\nvarious disciplines, including those who may not be machine learning experts or\nhave access to dedicated GPU resources. Ultimately, this initiative seeks to\nmake foundational LLM research more systematic and benchmark-informed from the\nearliest phases of model development.", "AI": {"tldr": "\u63d0\u51fa\u7ade\u8d5b\u4ee5\u8bbe\u8ba1\u4e13\u95e8\u7528\u4e8e\u6d4b\u91cf\u8bed\u8a00\u6a21\u578b\u65e9\u671f\u8bad\u7ec3\u8fdb\u5c55\u7684\u79d1\u5b66\u77e5\u8bc6\u8bc4\u4f30\u4efb\u52a1\uff0c\u63d0\u4f9b\u5c0f\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u4e2d\u95f4\u68c0\u67e5\u70b9\uff0c\u9f13\u52b1\u5f00\u53d1\u65b0\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f7f\u7814\u7a76\u66f4\u7cfb\u7edf\u548c\u57fa\u51c6\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5728\u8bc4\u4f30\u5b8c\u5168\u8bad\u7ec3\u7684\u8f83\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u65b9\u9762\u6548\u679c\u663e\u8457\u3002\u7136\u800c\uff0c\u5c0f\u578b\u6a21\u578b\u5728\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u7684\u8bc4\u4f30\u4fe1\u53f7\u5f80\u5f80\u4e0d\u5177\u5907\u663e\u8457\u6216\u80fd\u533a\u5206\u7684\u7279\u6027\u3002\u56e0\u6b64\uff0c\u8be5\u7ade\u4e89\u4e13\u6ce8\u4e8e\u8bbe\u8ba1\u79d1\u5b66\u77e5\u8bc6\u8bc4\u4f30\u4efb\u52a1\uff0c\u4ee5\u4e13\u95e8\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u7684\u65e9\u671f\u8bad\u7ec3\u8fdb\u7a0b\u3002", "method": "\u63d0\u4f9b\u4e86\u4e09\u4e2a\u9884\u8bad\u7ec3\u7684\u5c0f\u6a21\u578b\uff0c\u5e76\u5b89\u6392\u4e2d\u95f4\u68c0\u67e5\u70b9\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91c7\u6837\u8fbe200B\u4e2atokens\u3002\u5141\u8bb8\u6240\u6709\u5b9e\u9a8c\u548c\u5f00\u53d1\u5de5\u4f5c\u5728\u5e7f\u6cdb\u53ef\u7528\u7684\u514d\u8d39\u4e91GPU\u5e73\u53f0\u4e0a\u8fd0\u884c\uff0c\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u5373\u4f7f\u62e5\u6709\u6709\u9650\u7684\u8ba1\u7b97\u8d44\u6e90\u4e5f\u80fd\u53c2\u4e0e\u3002", "result": "\u9f13\u52b1\u53c2\u4e0e\u8005\u5f00\u53d1\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u6216\u8c03\u6574\u73b0\u6709\u57fa\u51c6\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\u3002\u63d0\u4ea4\u4f5c\u54c1\u7684\u8bc4\u4f30\u6807\u51c6\u5305\u62ec\uff1a\u5b83\u4eec\u751f\u6210\u7684\u6027\u80fd\u4fe1\u53f7\u7684\u8d28\u91cf\u3001\u57281\u4e07\u4ebftokens\u8bad\u7ec3\u65f6\u7684\u6a21\u578b\u6392\u540d\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u5b83\u4eec\u4e0e\u79d1\u5b66\u77e5\u8bc6\u9886\u57df\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u901a\u8fc7\u4fc3\u8fdb\u4e3a\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u8bbe\u8ba1\u91cf\u8eab\u5b9a\u5236\u7684\u8bc4\u4f30\u7b56\u7565\uff0c\u8be5\u7ade\u8d5b\u65e8\u5728\u5438\u5f15\u6765\u81ea\u5404\u79cd\u5b66\u79d1\u7684\u5e7f\u6cdb\u53c2\u4e0e\u8005\u3002\u6700\u7ec8\uff0c\u8be5\u5021\u8bae\u65e8\u5728\u4f7f\u57fa\u7840\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u81ea\u6a21\u578b\u5f00\u53d1\u7684\u6700\u65e9\u9636\u6bb5\u66f4\u5177\u7cfb\u7edf\u6027\u548c\u57fa\u51c6\u53c2\u8003\u6027\u3002"}}
{"id": "2506.07042", "pdf": "https://arxiv.org/pdf/2506.07042", "abs": "https://arxiv.org/abs/2506.07042", "authors": ["Stergios Chatzikyriakidis"], "title": "Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants", "categories": ["cs.CL"], "comment": null, "summary": "Extracting structured computational representations of historical events from\nnarrative text remains computationally expensive when constructed manually.\nWhile RDF/OWL reasoners enable graph-based reasoning, they are limited to\nfragments of first-order logic, preventing deeper temporal and semantic\nanalysis. This paper addresses both challenges by developing automatic\nhistorical event extraction models using multiple LLMs (GPT-4, Claude, Llama\n3.2) with three enhancement strategies: pure base generation, knowledge graph\nenhancement, and Retrieval-Augmented Generation (RAG). We conducted\ncomprehensive evaluations using historical texts from Thucydides. Our findings\nreveal that enhancement strategies optimize different performance dimensions\nrather than providing universal improvements. For coverage and historical\nbreadth, base generation achieves optimal performance with Claude and GPT-4\nextracting comprehensive events. However, for precision, RAG enhancement\nimproves coordinate accuracy and metadata completeness. Model architecture\nfundamentally determines enhancement sensitivity: larger models demonstrate\nrobust baseline performance with incremental RAG improvements, while Llama 3.2\nshows extreme variance from competitive performance to complete failure. We\nthen developed an automated translation pipeline converting extracted RDF\nrepresentations into Coq proof assistant specifications, enabling higher-order\nreasoning beyond RDF capabilities including multi-step causal verification,\ntemporal arithmetic with BC dates, and formal proofs about historical\ncausation. The Coq formalization validates that RAG-discovered event types\nrepresent legitimate domain-specific semantic structures rather than\nontological violations.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u589e\u5f3a\u7b56\u7565\u81ea\u52a8\u63d0\u53d6\u5386\u53f2\u4e8b\u4ef6\uff0c\u589e\u5f3a\u4e0d\u540c\u7ef4\u5ea6\u7684\u8868\u73b0\uff0c\u5f00\u53d1\u4e86\u5c06RDF\u8f6c\u4e3aCoq\u7684\u6d41\u6c34\u7ebf\u4ee5\u8fdb\u884c\u6df1\u5165\u63a8\u7406\u3002", "motivation": "\u624b\u52a8\u6784\u5efa\u5386\u53f2\u4e8b\u4ef6\u7684\u8ba1\u7b97\u8868\u793a\u8fc7\u4e8e\u8017\u65f6\u4e14\u6602\u8d35\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u66f4\u6df1\u5165\u7684\u65f6\u95f4\u548c\u8bed\u4e49\u5206\u6790\u3002", "method": "\u91c7\u7528\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5305\u62ecGPT-4\u3001Claude\u3001Llama 3.2\uff0c\u5e76\u4f7f\u7528\u4e09\u79cd\u589e\u5f3a\u7b56\u7565\uff1a\u7eaf\u57fa\u7840\u751f\u6210\u3001\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3002", "result": "\u4e0d\u540c\u7684\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u4e86\u4e0d\u540c\u7684\u6027\u80fd\u7ef4\u5ea6\uff1a\u57fa\u7840\u751f\u6210\u5728\u8303\u56f4\u548c\u5386\u53f2\u5e7f\u5ea6\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800cRAG\u589e\u5f3a\u5219\u6539\u5584\u4e86\u5750\u6807\u7cbe\u5ea6\u548c\u5143\u6570\u636e\u5b8c\u6574\u6027\u3002\u6a21\u578b\u67b6\u6784\u5bf9\u589e\u5f3a\u654f\u611f\u6027\u6709\u6839\u672c\u5f71\u54cd\uff0c\u5176\u4e2d\u5927\u578b\u6a21\u578b\u8868\u73b0\u7a33\u5b9a\uff0c\u800c\u8f83\u5c0f\u6a21\u578b\u5982Llama 3.2\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u6700\u7ec8\u5f00\u53d1\u7684\u7ffb\u8bd1\u6d41\u6c34\u7ebf\u80fd\u591f\u5c06\u63d0\u53d6\u7684RDF\u8868\u793a\u8f6c\u6362\u4e3aCoq\u8bc1\u660e\u52a9\u7406\u89c4\u8303\uff0c\u4ee5\u5b9e\u73b0\u8d85\u8d8aRDF\u7684\u9ad8\u9636\u63a8\u7406\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u5c06\u5386\u53f2\u4e8b\u4ef6\u4ece\u53d9\u8ff0\u6587\u672c\u4e2d\u63d0\u53d6\u5e76\u8f6c\u6362\u4e3a\u53ef\u8ba1\u7b97\u8868\u793a\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u6df1\u5c42\u6b21\u65f6\u95f4\u548c\u8bed\u4e49\u5206\u6790\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.06809", "pdf": "https://arxiv.org/pdf/2506.06809", "abs": "https://arxiv.org/abs/2506.06809", "authors": ["Di Lin", "Wanjing Ren", "Xuanbin Li", "Rui Zhang"], "title": "IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-supervised learning (SSL) methods have been increasingly applied to\ndiverse downstream tasks due to their superior generalization capabilities and\nlow annotation costs. However, most existing heterogeneous graph SSL models\nconvert heterogeneous graphs into homogeneous ones via meta-paths for training,\nwhich only leverage information from nodes at both ends of meta-paths while\nunderutilizing the heterogeneous node information along the meta-paths. To\naddress this limitation, this paper proposes a novel framework named IMPA-HGAE\nto enhance target node embeddings by fully exploiting internal node information\nalong meta-paths. Experimental results validate that IMPA-HGAE achieves\nsuperior performance on heterogeneous datasets. Furthermore, this paper\nintroduce innovative masking strategies to strengthen the representational\ncapacity of generative SSL models on heterogeneous graph data. Additionally,\nthis paper discuss the interpretability of the proposed method and potential\nfuture directions for generative self-supervised learning in heterogeneous\ngraphs. This work provides insights into leveraging meta-path-guided structural\nsemantics for robust representation learning in complex graph scenarios.", "AI": {"tldr": "IMPA-HGAE framework improves node embeddings in heterogeneous graphs using full node information along meta-paths, showing superior performance in experiments.", "motivation": "Existing heterogeneous graph SSL models convert heterogeneous graphs to homogeneous ones via meta-paths, underutilizing heterogeneous node information along the meta-paths, which this paper addresses.", "method": "Proposes a framework named IMPA-HGAE that fully exploits internal node information along meta-paths to enhance target node embeddings. Introduces innovative masking strategies to strengthen generative SSL models.", "result": "IMPA-HGAE demonstrates superior performance in experimental results on heterogeneous datasets, providing robust representation learning in complex graph scenarios.", "conclusion": "IMPA-HGAE achieves superior performance on heterogeneous datasets and enhances target node embeddings by utilizing internal node information along meta-paths."}}
{"id": "2506.07736", "pdf": "https://arxiv.org/pdf/2506.07736", "abs": "https://arxiv.org/abs/2506.07736", "authors": ["Jingnan Zheng", "Xiangtian Ji", "Yijun Lu", "Chenhang Cui", "Weixiang Zhao", "Gelei Deng", "Zhenkai Liang", "An Zhang", "Tat-Seng Chua"], "title": "RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) continue to exhibit vulnerabilities despite\ndeliberate safety alignment efforts, posing significant risks to users and\nsociety. To safeguard against the risk of policy-violating content,\nsystem-level moderation via external guard models-designed to monitor LLM\ninputs and outputs and block potentially harmful content-has emerged as a\nprevalent mitigation strategy. Existing approaches of training guard models\nrely heavily on extensive human curated datasets and struggle with\nout-of-distribution threats, such as emerging harmful categories or jailbreak\nattacks. To address these limitations, we propose RSafe, an adaptive\nreasoning-based safeguard that conducts guided safety reasoning to provide\nrobust protection within the scope of specified safety policies. RSafe operates\nin two stages: 1) guided reasoning, where it analyzes safety risks of input\ncontent through policy-guided step-by-step reasoning, and 2) reinforced\nalignment, where rule-based RL optimizes its reasoning paths to align with\naccurate safety prediction. This two-stage training paradigm enables RSafe to\ninternalize safety principles to generalize safety protection capability over\nunseen or adversarial safety violation scenarios. During inference, RSafe\naccepts user-specified safety policies to provide enhanced safeguards tailored\nto specific safety requirements.", "AI": {"tldr": "RSafe\u662f\u4e00\u79cd\u901a\u8fc7\u63a8\u7406\u8fdb\u884c\u5f15\u5bfc\u5e76\u5f3a\u5316\u5bf9\u9f50\u7684\u5b89\u5168\u4fdd\u62a4\u65b9\u6cd5\uff0c\u53ef\u63d0\u9ad8\u5e94\u5bf9\u65b0\u51fa\u73b0\u6216\u5bf9\u6297\u6027\u5b89\u5168\u5a01\u80c1\u7684\u80fd\u529b\u3002", "motivation": "LLMs\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u4ecd\u5b58\u5728\u6f0f\u6d1e\uff0c\u53ef\u80fd\u5bf9\u7528\u6237\u548c\u793e\u4f1a\u5e26\u6765\u663e\u8457\u98ce\u9669\u3002\u73b0\u6709\u7684\u4fdd\u62a4\u63aa\u65bd\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u7b56\u5212\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5206\u5e03\u5916\u5a01\u80c1\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "RSafe\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6a21\u5f0f\uff1a\u9996\u5148\u8fdb\u884c\u5f15\u5bfc\u63a8\u7406\uff0c\u5206\u6790\u8f93\u5165\u5185\u5bb9\u7684\u5b89\u5168\u98ce\u9669\uff1b\u5176\u6b21\u901a\u8fc7\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u63a8\u7406\u8def\u5f84\uff0c\u4f7f\u5176\u4e0e\u51c6\u786e\u7684\u5b89\u5168\u9884\u6d4b\u4fdd\u6301\u4e00\u81f4\u3002", "result": "RSafe\u80fd\u591f\u5728\u63a8\u7406\u9636\u6bb5\u63a5\u53d7\u7528\u6237\u6307\u5b9a\u7684\u5b89\u5168\u7b56\u7565\uff0c\u6839\u636e\u5177\u4f53\u7684\u5b89\u5168\u9700\u6c42\u63d0\u4f9b\u589e\u5f3a\u7684\u4fdd\u62a4\u63aa\u65bd\u3002", "conclusion": "RSafe\u901a\u8fc7\u57fa\u4e8e\u63a8\u7406\u7684\u9002\u5e94\u6027\u4fdd\u62a4\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5728\u672a\u89c1\u6216\u5bf9\u6297\u6027\u5b89\u5168\u8fdd\u89c4\u573a\u666f\u4e0b\u7684\u5b89\u5168\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2506.07044", "pdf": "https://arxiv.org/pdf/2506.07044", "abs": "https://arxiv.org/abs/2506.07044", "authors": ["LASA Team", "Weiwen Xu", "Hou Pong Chan", "Long Li", "Mahani Aljunied", "Ruifeng Yuan", "Jianyu Wang", "Chenghao Xiao", "Guizhen Chen", "Chaoqun Liu", "Zhaodonghui Li", "Yu Sun", "Junao Shen", "Chaojun Wang", "Jie Tan", "Deli Zhao", "Tingyang Xu", "Hao Zhang", "Yu Rong"], "title": "Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "Technical Report, 53 pages, 25 tables, and 16 figures", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated impressive\ncapabilities in understanding common visual elements, largely due to their\nlarge-scale datasets and advanced training strategies. However, their\neffectiveness in medical applications remains limited due to the inherent\ndiscrepancies between data and tasks in medical scenarios and those in the\ngeneral domain. Concretely, existing medical MLLMs face the following critical\nlimitations: (1) limited coverage of medical knowledge beyond imaging, (2)\nheightened susceptibility to hallucinations due to suboptimal data curation\nprocesses, (3) lack of reasoning capabilities tailored for complex medical\nscenarios. To address these challenges, we first propose a comprehensive data\ncuration procedure that (1) efficiently acquires rich medical knowledge data\nnot only from medical imaging but also from extensive medical texts and\ngeneral-domain data; and (2) synthesizes accurate medical captions, visual\nquestion answering (VQA), and reasoning samples. As a result, we build a\nmultimodal dataset enriched with extensive medical knowledge. Building on the\ncurated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu\nundergoes multi-stage training to embed medical expertise and enhance its\ntask-solving capabilities progressively. Besides, we preliminarily explore the\npotential of applying reinforcement learning with verifiable rewards paradigm\nto enhance Lingshu's medical reasoning ability. Additionally, we develop\nMedEvalKit, a unified evaluation framework that consolidates leading multimodal\nand textual medical benchmarks for standardized, fair, and efficient model\nassessment. We evaluate the performance of Lingshu on three fundamental medical\ntasks, multimodal QA, text-based QA, and medical report generation. The results\nshow that Lingshu consistently outperforms the existing open-source multimodal\nmodels on most tasks ...", "AI": {"tldr": "\u7814\u7a76\u89e3\u51b3\u4e86\u533b\u5b66MLLM\u5728\u77e5\u8bc6\u8986\u76d6\u4e0e\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u51faLingshu\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u53ca\u4e30\u5bcc\u6570\u636e\u96c6\uff0c\u63d0\u5347\u5176\u5728\u533b\u7597\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u533b\u5b66MLLMs\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u9650\u5236\uff1a\uff081\uff09\u533b\u5b66\u77e5\u8bc6\u8986\u76d6\u6709\u9650\uff0c\u5c24\u5176\u5728\u56fe\u50cf\u4e4b\u5916\uff1b\uff082\uff09\u6570\u636e\u7b56\u5212\u8fc7\u7a0b\u6b20\u4f73\u5bfc\u81f4\u5e7b\u89c9\u95ee\u9898\uff1b\uff083\uff09\u7f3a\u4e4f\u9488\u5bf9\u590d\u6742\u533b\u5b66\u573a\u666f\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5168\u9762\u7684\u6570\u636e\u7b56\u5212\u7a0b\u5e8f\uff0c\u4ece\u533b\u5b66\u56fe\u50cf\u548c\u5e7f\u6cdb\u7684\u533b\u5b66\u6587\u672c\u53ca\u666e\u904d\u9886\u57df\u6570\u636e\u4e2d\u6709\u6548\u83b7\u53d6\u4e30\u5bcc\u533b\u5b66\u77e5\u8bc6\u6570\u636e\uff0c\u5e76\u7efc\u5408\u51c6\u786e\u7684\u533b\u5b66\u5b57\u5e55\u3001\u89c6\u89c9\u95ee\u7b54\u53ca\u63a8\u7406\u6837\u672c\u3002\u57fa\u4e8e\u6b64\u6784\u5efa\u4e00\u4e2a\u5bcc\u542b\u5e7f\u6cdb\u533b\u5b66\u77e5\u8bc6\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u8fdb\u4e13\u95e8\u533b\u5b66MLLM\uff1aLingshu\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u5d4c\u5165\u533b\u5b66\u4e13\u4e1a\u77e5\u8bc6\uff0c\u589e\u5f3a\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "result": "Lingshu\u5728\u591a\u6a21\u6001\u95ee\u7b54\u3001\u57fa\u4e8e\u6587\u672c\u7684\u95ee\u7b54\u548c\u533b\u5b66\u62a5\u544a\u751f\u6210\u4e09\u9879\u57fa\u7840\u533b\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u73b0\u6709\u5f00\u6e90\u591a\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "\u5f15\u5165Lingshu\u7cfb\u7edf\u5316\u89e3\u51b3\u4e86\u533b\u5b66MLLM\u5728\u77e5\u8bc6\u8986\u76d6\u3001\u6570\u636e\u7b56\u5212\u53ca\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u53ca\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5176\u533b\u7597\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2506.06815", "pdf": "https://arxiv.org/pdf/2506.06815", "abs": "https://arxiv.org/abs/2506.06815", "authors": ["Max McGuinness", "Eirik Fladmark", "Francisco Vargas"], "title": "Path Integral Optimiser: Global Optimisation via Neural Schr\u00f6dinger-F\u00f6llmer Diffusion", "categories": ["cs.LG"], "comment": "6 pages. Presented at the OPT Workshop, NeurIPS 2024, Vancouver, CA", "summary": "We present an early investigation into the use of neural diffusion processes\nfor global optimisation, focusing on Zhang et al.'s Path Integral Sampler. One\ncan use the Boltzmann distribution to formulate optimization as solving a\nSchr\\\"odinger bridge sampling problem, then apply Girsanov's theorem with a\nsimple (single-point) prior to frame it in stochastic control terms, and\ncompute the solution's integral terms via a neural approximation (a Fourier\nMLP). We provide theoretical bounds for this optimiser, results on toy\noptimisation tasks, and a summary of the stochastic theory motivating the\nmodel. Ultimately, we found the optimiser to display promising per-step\nperformance at optimisation tasks between 2 and 1,247 dimensions, but struggle\nto explore higher-dimensional spaces when faced with a 15.9k parameter model,\nindicating a need for work on adaptation in such environments.", "AI": {"tldr": "\u7814\u7a76\u795e\u7ecf\u6269\u6563\u8fc7\u7a0b\u5728\u8def\u5f84\u79ef\u5206\u91c7\u6837\u4e2d\u7684\u5e94\u7528\uff0c\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u9002\u5e94\u6027\u95ee\u9898\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u6269\u6563\u8fc7\u7a0b\u5728\u5168\u5c40\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5e94\u7528\u4e8e\u8def\u5f84\u79ef\u5206\u91c7\u6837\u5668\u3002", "method": "\u5229\u7528Schr\u00f6dinger\u6865\u91c7\u6837\u95ee\u9898\uff0c\u901a\u8fc7Girsanov\u5b9a\u7406\u548c\u7b80\u5355\u7684\uff08\u5355\u70b9\uff09\u5148\u9a8c\u5c06\u5176\u6846\u5b9a\u5728\u968f\u673a\u63a7\u5236\u672f\u8bed\u4e2d\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u8fd1\u4f3c\uff08\u5085\u91cc\u53f6MLP\uff09\u8ba1\u7b97\u89e3\u7684\u79ef\u5206\u9879\u3002", "result": "\u4f18\u5316\u5668\u5728\u5c3a\u5bf8\u4ece2\u52301247\u7ef4\u7684\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6bcf\u6b65\u6027\u80fd\uff0c\u4f46\u5728\u9762\u5bf915900\u4e2a\u53c2\u6570\u7684\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u5173\u6ce8\u9002\u5e94\u6027\u7684\u63d0\u5347\u3002", "conclusion": "\u795e\u7ecf\u6269\u6563\u8fc7\u7a0b\u5728\u7279\u5b9a\u7ef4\u5ea6\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u66f4\u9ad8\u7ef4\u7684\u4f18\u5316\u4efb\u52a1\u4e2d\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2506.07064", "pdf": "https://arxiv.org/pdf/2506.07064", "abs": "https://arxiv.org/abs/2506.07064", "authors": ["Kai Xiong", "Xiao Ding", "Yixin Cao", "Yuxiong Yan", "Li Du", "Yufei Zhang", "Jinglong Gao", "Jiaqian Liu", "Bing Qin", "Ting Liu"], "title": "Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Large language models (LLMs) have mastered abundant simple and explicit\ncommonsense knowledge through pre-training, enabling them to achieve human-like\nperformance in simple commonsense reasoning. Nevertheless, LLMs struggle to\nreason with complex and implicit commonsense knowledge that is derived from\nsimple ones (such as understanding the long-term effects of certain events), an\naspect humans tend to focus on more. Existing works focus on complex tasks like\nmath and code, while complex commonsense reasoning remains underexplored due to\nits uncertainty and lack of structure. To fill this gap and align with\nreal-world concerns, we propose a benchmark Com$^2$ focusing on complex\ncommonsense reasoning. We first incorporate causal event graphs to serve as\nstructured complex commonsense. Then we adopt causal theory~(e.g.,\nintervention) to modify the causal event graphs and obtain different scenarios\nthat meet human concerns. Finally, an LLM is employed to synthesize examples\nwith slow thinking, which is guided by the logical relationships in the\nmodified causal graphs. Furthermore, we use detective stories to construct a\nmore challenging subset. Experiments show that LLMs struggle in reasoning depth\nand breadth, while post-training and slow thinking can alleviate this. The code\nand data are available at https://github.com/Waste-Wood/Com2.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6Com^2\u6765\u89e3\u51b3\u590d\u6742\u5e38\u8bc6\u63a8\u7406\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u56e0\u679c\u4e8b\u4ef6\u56fe\u548c\u6162\u601d\u7ef4\u6765\u6307\u5bfc\u8bed\u8a00\u6a21\u578b\u3002\u5b9e\u9a8c\u663e\u793a\u540e\u8bad\u7ec3\u548c\u6162\u601d\u8003\u6709\u52a9\u4e8e\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4fa7\u91cd\u4e8e\u590d\u6742\u4efb\u52a1\u5982\u6570\u5b66\u548c\u4ee3\u7801\uff0c\u800c\u5bf9\u590d\u6742\u5e38\u8bc6\u63a8\u7406\u5173\u6ce8\u8f83\u5c11\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5e76\u4e0e\u771f\u5b9e\u4e16\u754c\u5173\u6ce8\u70b9\u4fdd\u6301\u4e00\u81f4\uff0c\u63d0\u51fa\u4e86\u4e00\u9879\u65e8\u5728\u590d\u6742\u5e38\u8bc6\u63a8\u7406\u7684\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u56e0\u679c\u7406\u8bba\uff08\u5982\u5e72\u9884\uff09\u6765\u4fee\u6539\u56e0\u679c\u4e8b\u4ef6\u56fe\uff0c\u5e76\u901a\u8fc7\u6162\u601d\u7ef4\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u793a\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u5e38\u8bc6\u63a8\u7406\u7684\u6df1\u5ea6\u548c\u5e7f\u5ea6\u4e0a\u4ecd\u6709\u56f0\u96be\uff0c\u4f46\u662f\u540e\u8bad\u7ec3\u548c\u6162\u601d\u8003\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\u3002\u4ee3\u7801\u548c\u6570\u636e\u516c\u5f00\u5728GitHub\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u5e38\u8bc6\u63a8\u7406\u7684\u6df1\u5ea6\u548c\u5e7f\u5ea6\u4e0a\u4ecd\u6709\u56f0\u96be\uff0c\u4f46\u662f\u540e\u8bad\u7ec3\u548c\u6162\u601d\u8003\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\u3002"}}
{"id": "2506.06853", "pdf": "https://arxiv.org/pdf/2506.06853", "abs": "https://arxiv.org/abs/2506.06853", "authors": ["Ilya Kaufman Sirot", "Omri Azencot"], "title": "Curvature Enhanced Data Augmentation for Regression", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted to ICML 2025", "summary": "Deep learning models with a large number of parameters, often referred to as\nover-parameterized models, have achieved exceptional performance across various\ntasks. Despite concerns about overfitting, these models frequently generalize\nwell to unseen data, thanks to effective regularization techniques, with data\naugmentation being among the most widely used. While data augmentation has\nshown great success in classification tasks using label-preserving\ntransformations, its application in regression problems has received less\nattention. Recently, a novel \\emph{manifold learning} approach for generating\nsynthetic data was proposed, utilizing a first-order approximation of the data\nmanifold. Building on this foundation, we present a theoretical framework and\npractical tools for approximating and sampling general data manifolds.\nFurthermore, we introduce the Curvature-Enhanced Manifold Sampling (CEMS)\nmethod for regression tasks. CEMS leverages a second-order representation of\nthe data manifold to enable efficient sampling and reconstruction of new data\npoints. Extensive evaluations across multiple datasets and comparisons with\nstate-of-the-art methods demonstrate that CEMS delivers superior performance in\nboth in-distribution and out-of-distribution scenarios, while introducing only\nminimal computational overhead. Code is available at\nhttps://github.com/azencot-group/CEMS.", "AI": {"tldr": "\u63d0\u51fa\u4e86Curvature-Enhanced Manifold Sampling (CEMS) \u65b9\u6cd5\u7528\u4e8e\u56de\u5f52\u4efb\u52a1\uff0c\u6709\u6548\u63d0\u9ad8\u56de\u5f52\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u8fc7\u53c2\u6570\u5316\u6a21\u578b\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u901a\u8fc7\u4fdd\u6301\u6807\u7b7e\u53d8\u6362\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5728\u56de\u5f52\u95ee\u9898\u4e2d\u7684\u5e94\u7528\u8f83\u5c11\u53d7\u5230\u5173\u6ce8\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f62\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u6d41\u5f62\u7684\u4e00\u7ea7\u8fd1\u4f3c\u6765\u751f\u6210\u5408\u6210\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u9645\u5de5\u5177\u7528\u4e8e\u8fd1\u4f3c\u548c\u91c7\u6837\u4e00\u822c\u6570\u636e\u6d41\u5f62\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8e\u7b2c\u4e8c\u9636\u6570\u636e\u6d41\u5f62\u8868\u793a\u7684Curvature-Enhanced Manifold Sampling\uff08CEMS\uff09\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCEMS\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u573a\u666f\u4e2d\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4ec5\u5f15\u5165\u4e86\u6700\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "CEMS\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u8fdb\u884c\u91c7\u6837\u548c\u91cd\u5efa\u65b0\u6570\u636e\u70b9\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0e\u6700\u65b0\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u63d0\u4f9b\u3002"}}
{"id": "2506.07759", "pdf": "https://arxiv.org/pdf/2506.07759", "abs": "https://arxiv.org/abs/2506.07759", "authors": ["Diego Forni\u00e9s-Tabuenca", "Alejandro Uribe", "Urtzi Otamendi", "Arkaitz Artetxe", "Juan Carlos Rivera", "Oier Lopez de Lacalle"], "title": "REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models", "categories": ["cs.AI", "cs.NE", "I.2.7; I.2.8; F.2.2"], "comment": "21 pages, 5 tables, 7 figures and 4 appendixes. Pre-print submitted\n  to IEEE Transactions on Evolutionary Computation", "summary": "Multi-objective optimization is fundamental in complex decision-making tasks.\nTraditional algorithms, while effective, often demand extensive\nproblem-specific modeling and struggle to adapt to nonlinear structures. Recent\nadvances in Large Language Models (LLMs) offer enhanced explainability,\nadaptability, and reasoning. This work proposes Reflective Evolution of\nMulti-objective Heuristics (REMoH), a novel framework integrating NSGA-II with\nLLM-based heuristic generation. A key innovation is a reflection mechanism that\nuses clustering and search-space reflection to guide the creation of diverse,\nhigh-quality heuristics, improving convergence and maintaining solution\ndiversity. The approach is evaluated on the Flexible Job Shop Scheduling\nProblem (FJSSP) in-depth benchmarking against state-of-the-art methods using\nthree instance datasets: Dauzere, Barnes, and Brandimarte. Results demonstrate\nthat REMoH achieves competitive results compared to state-of-the-art approaches\nwith reduced modeling effort and enhanced adaptability. These findings\nunderscore the potential of LLMs to augment traditional optimization, offering\ngreater flexibility, interpretability, and robustness in multi-objective\nscenarios.", "AI": {"tldr": "This paper introduces REMoH, combining NSGA-II and LLM-generated heuristics, to improve multi-objective optimization with reduced modeling effort and high adaptability.", "motivation": "Traditional multi-objective optimization algorithms require extensive problem-specific modeling and struggle with nonlinear structures. LLMs offer enhanced explainability and adaptability, motivating their use to improve traditional approaches.", "method": "This paper proposes the Reflective Evolution of Multi-objective Heuristics (REMoH) framework, which integrates NSGA-II with LLM-based heuristic generation, including a reflection mechanism using clustering and search-space reflection.", "result": "REMoH was evaluated on the Flexible Job Shop Scheduling Problem using three instance datasets and demonstrated competitive performance with state-of-the-art methods while requiring less modeling effort.", "conclusion": "REMoH achieves competitive results in multi-objective optimization with reduced modeling effort and enhanced adaptability, demonstrating the potential of LLMs to augment traditional optimization approaches."}}
{"id": "2506.07086", "pdf": "https://arxiv.org/pdf/2506.07086", "abs": "https://arxiv.org/abs/2506.07086", "authors": ["Yuanhe Tian", "Pengsen Cheng", "Guoqing Jin", "Lei Zhang", "Yan Song"], "title": "Representation Decomposition for Learning Similarity and Contrastness Across Modalities for Affective Computing", "categories": ["cs.CL"], "comment": "13 pages, 4 figures", "summary": "Multi-modal affective computing aims to automatically recognize and interpret\nhuman attitudes from diverse data sources such as images and text, thereby\nenhancing human-computer interaction and emotion understanding. Existing\napproaches typically rely on unimodal analysis or straightforward fusion of\ncross-modal information that fail to capture complex and conflicting evidence\npresented across different modalities. In this paper, we propose a novel\nLLM-based approach for affective computing that explicitly deconstructs visual\nand textual representations into shared (modality-invariant) and\nmodality-specific components. Specifically, our approach firstly encodes and\naligns input modalities using pre-trained multi-modal encoders, then employs a\nrepresentation decomposition framework to separate common emotional content\nfrom unique cues, and finally integrates these decomposed signals via an\nattention mechanism to form a dynamic soft prompt for a multi-modal LLM.\nExtensive experiments on three representative tasks for affective computing,\nnamely, multi-modal aspect-based sentiment analysis, multi-modal emotion\nanalysis, and hateful meme detection, demonstrate the effectiveness of our\napproach, which consistently outperforms strong baselines and state-of-the-art\nmodels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u89c6\u89c9\u548c\u6587\u672c\u8868\u793a\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u7684\u6548\u679c\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6a21\u6001\u5206\u6790\u6216\u7b80\u5355\u7684\u8de8\u6a21\u6001\u4fe1\u606f\u878d\u5408\uff0c\u672a\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u6a21\u6001\u95f4\u590d\u6742\u548c\u77db\u76fe\u7684\u8bc1\u636e\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u9996\u5148\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u7f16\u7801\u5668\u7f16\u7801\u5e76\u5bf9\u9f50\u8f93\u5165\u6a21\u6001\uff0c\u7136\u540e\u5229\u7528\u8868\u793a\u5206\u89e3\u6846\u67b6\u6765\u5206\u79bb\u5171\u6027\u60c5\u611f\u5185\u5bb9\u548c\u72ec\u7279\u7ebf\u7d22\uff0c\u6700\u540e\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u8fd9\u4e9b\u5206\u89e3\u7684\u4fe1\u53f7\u5f62\u6210\u591a\u6a21\u6001LLM\u7684\u52a8\u6001\u8f6f\u63d0\u793a\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u65b9\u9762\u60c5\u611f\u3001\u60c5\u611f\u5206\u6790\u548c\u4ec7\u6068\u8868\u60c5\u68c0\u6d4b\u4efb\u52a1\u4e0a\u6709\u6548\u6027\u4f18\u8d8a\uff0c\u6301\u7eed\u8d85\u8d8a\u5f3a\u52b2\u7684\u57fa\u51c6\u548c\u6700\u73b0\u4ee3\u5316\u7684\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eLLM\u7684\u591a\u6a21\u6001\u60c5\u611f\u8ba1\u7b97\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u65b9\u9762\u60c5\u611f\u3001\u60c5\u611f\u5206\u6790\u548c\u4ec7\u6068\u8868\u60c5\u68c0\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u57fa\u51c6\u6a21\u578b\u548c\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002"}}
{"id": "2506.06858", "pdf": "https://arxiv.org/pdf/2506.06858", "abs": "https://arxiv.org/abs/2506.06858", "authors": ["Ziwei Li", "Yuhan Duan", "Tianyu Xiong", "Yi-Tang Chen", "Wei-Lun Chao", "Han-Wei Shen"], "title": "High-Fidelity Scientific Simulation Surrogates via Adaptive Implicit Neural Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Effective surrogate models are critical for accelerating scientific\nsimulations. Implicit neural representations (INRs) offer a compact and\ncontinuous framework for modeling spatially structured data, but they often\nstruggle with complex scientific fields exhibiting localized, high-frequency\nvariations. Recent approaches address this by introducing additional features\nalong rigid geometric structures (e.g., grids), but at the cost of flexibility\nand increased model size. In this paper, we propose a simple yet effective\nalternative: Feature-Adaptive INR (FA-INR). FA-INR leverages cross-attention to\nan augmented memory bank to learn flexible feature representations, enabling\nadaptive allocation of model capacity based on data characteristics, rather\nthan rigid structural assumptions. To further improve scalability, we introduce\na coordinate-guided mixture of experts (MoE) that enhances the specialization\nand efficiency of feature representations. Experiments on three large-scale\nensemble simulation datasets show that FA-INR achieves state-of-the-art\nfidelity while significantly reducing model size, establishing a new trade-off\nfrontier between accuracy and compactness for INR-based surrogates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684FA-INR\u6a21\u578b\u901a\u8fc7\u7075\u6d3b\u7684\u7279\u5f81\u8868\u793a\u548c\u9ad8\u6548\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff0c\u5728\u7f29\u5c0f\u6a21\u578b\u89c4\u6a21\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86INR\u7684\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u8fbe\u5230\u4e86\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u6cd5\uff08INR\uff09\u867d\u7136\u5728\u5efa\u6a21\u7a7a\u95f4\u7ed3\u6784\u5316\u6570\u636e\u65b9\u9762\u63d0\u4f9b\u4e86\u7d27\u51d1\u4e14\u8fde\u7eed\u7684\u6846\u67b6\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u5c40\u90e8\u9ad8\u9891\u53d8\u5316\u7684\u590d\u6742\u79d1\u5b66\u9886\u57df\u65f6\u5f80\u5f80\u8868\u73b0\u4e0d\u4f73\u3002", "method": "FA-INR\u5229\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\u589e\u5f3a\u7684\u8bb0\u5fc6\u5e93\uff0c\u5b66\u4e60\u7075\u6d3b\u7684\u7279\u5f81\u8868\u793a\uff0c\u5e76\u5f15\u5165\u4e86\u5750\u6807\u5f15\u5bfc\u7684\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\uff08MoE\uff09\uff0c\u63d0\u9ad8\u4e86\u7279\u5f81\u8868\u793a\u7684\u4e13\u4e1a\u5316\u548c\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6a21\u62df\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0cFA-INR\u5728\u6a21\u578b\u89c4\u6a21\u663e\u8457\u51cf\u5c0f\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8eINR\u7684\u66ff\u4ee3\u6a21\u578b\u7684\u6700\u5148\u8fdb\u4fdd\u771f\u5ea6\u8868\u73b0\u3002", "conclusion": "FA-INR\u5b9e\u73b0\u4e86\u5148\u8fdb\u7684\u4fdd\u771f\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u89c4\u6a21\uff0c\u4e3a\u57fa\u4e8eINR\u7684\u66ff\u4ee3\u6a21\u578b\u5efa\u7acb\u4e86\u51c6\u786e\u6027\u548c\u7d27\u51d1\u6027\u4e4b\u95f4\u7684\u65b0\u6743\u8861\u524d\u6cbf\u3002"}}
{"id": "2506.07807", "pdf": "https://arxiv.org/pdf/2506.07807", "abs": "https://arxiv.org/abs/2506.07807", "authors": ["John Laird", "Christian Lebiere", "Paul Rosenbloom", "Andrea Stocco", "Robert Wray"], "title": "A Proposal to Extend the Common Model of Cognition with Metacognition", "categories": ["cs.AI"], "comment": null, "summary": "The Common Model of Cognition (CMC) provides an abstract characterization of\nthe structure and processing required by a cognitive architecture for\nhuman-like minds. We propose a unified approach to integrating metacognition\nwithin the CMC. We propose that metacognition involves reasoning over explicit\nrepresentations of an agent's cognitive capabilities and processes in working\nmemory. Our proposal exploits the existing cognitive capabilities of the CMC,\nmaking minimal extensions in the structure and information available within\nworking memory. We provide examples of metacognition within our proposal.", "AI": {"tldr": "\u6587\u4e2d\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5143\u8ba4\u77e5\u6574\u5408\u5230CMC\u4e2d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u7528\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\u7684\u8ba4\u77e5\u80fd\u529b\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u4f8b\u5b50\u3002", "motivation": "\u4e3a\u4e86\u901a\u8fc7\u5728\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\u505a\u6700\u5c0f\u7684\u7ed3\u6784\u548c\u4fe1\u606f\u6269\u5c55\uff0c\u5c06\u5143\u8ba4\u77e5\u6709\u6548\u96c6\u6210\u5165CMC\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8003\u5bdf\u4ee3\u7406\u4eba\u5728\u5de5\u4f5c\u8bb0\u5fc6\u4e2d\u5bf9\u8ba4\u77e5\u80fd\u529b\u548c\u8fc7\u7a0b\u7684\u663e\u5f0f\u8868\u5f81\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u672c\u63d0\u6848\u4e2d\u7684\u4f8b\u5b50\uff0c\u5c55\u793a\u4e86\u5143\u8ba4\u77e5\u7684\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5143\u8ba4\u77e5\u6574\u5408\u5230CMC\uff08\u8ba4\u77e5\u7684\u4e00\u822c\u6a21\u578b\uff09\u4e2d\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.07104", "pdf": "https://arxiv.org/pdf/2506.07104", "abs": "https://arxiv.org/abs/2506.07104", "authors": ["Jiaxuan Gao", "Shu Yan", "Qixin Tan", "Lu Yang", "Shusheng Xu", "Wei Fu", "Zhiyu Mei", "Kaifeng Lyu", "Yi Wu"], "title": "How Far Are We from Optimal Reasoning Efficiency?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate remarkable problem-solving\ncapabilities through extended Chain-of-Thought (CoT) reasoning but often\nproduce excessively verbose and redundant reasoning traces. This inefficiency\nincurs high inference costs and limits practical deployment. While existing\nfine-tuning methods aim to improve reasoning efficiency, assessing their\nefficiency gains remains challenging due to inconsistent evaluations. In this\nwork, we introduce the reasoning efficiency frontiers, empirical upper bounds\nderived from fine-tuning base LRMs across diverse approaches and training\nconfigurations. Based on these frontiers, we propose the Reasoning Efficiency\nGap (REG), a unified metric quantifying deviations of any fine-tuned LRMs from\nthese frontiers. Systematic evaluation on challenging mathematical benchmarks\nreveals significant gaps in current methods: they either sacrifice accuracy for\nshort length or still remain inefficient under tight token budgets. To reduce\nthe efficiency gap, we propose REO-RL, a class of Reinforcement Learning\nalgorithms that minimizes REG by targeting a sparse set of token budgets.\nLeveraging numerical integration over strategically selected budgets, REO-RL\napproximates the full efficiency objective with low error using a small set of\ntoken budgets. Through systematic benchmarking, we demonstrate that our\nefficiency metric, REG, effectively captures the accuracy-length trade-off,\nwith low-REG methods reducing length while maintaining accuracy. Our approach,\nREO-RL, consistently reduces REG by >=50 across all evaluated LRMs and matching\nQwen3-4B/8B efficiency frontiers under a 16K token budget with minimal accuracy\nloss. Ablation studies confirm the effectiveness of our exponential token\nbudget strategy. Finally, our findings highlight that fine-tuning LRMs to\nperfectly align with the efficiency frontiers remains an open challenge.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684REO-RL\u7b97\u6cd5\uff0c\u6709\u6548\u51cf\u5c11\u63a8\u7406\u6548\u7387\u5dee\u8ddd\uff08REG\uff09\uff0c\u572816K token\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e86\u4e0eQwen3-4B/8B\u7c7b\u4f3c\u7684\u6548\u7387\uff0c\u7ef4\u6301\u8f83\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u89e3\u51b3\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u63a8\u7406\u8def\u5f84\u901a\u5e38\u8fc7\u4e8e\u5197\u957f\uff0c\u5bfc\u81f4\u9ad8\u63a8\u7406\u6210\u672c\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u73b0\u6709\u7cbe\u8c03\u65b9\u6cd5\u867d\u7136\u65e8\u5728\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u4f46\u7531\u4e8e\u8bc4\u4f30\u4e0d\u4e00\u81f4\uff0c\u96be\u4ee5\u9a8c\u8bc1\u5176\u6548\u7387\u63d0\u5347\u3002\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u63a8\u7406\u6548\u7387\u524d\u6cbf\u548cREG\u6307\u6807\u6765\u7cfb\u7edf\u91cf\u5316\u548c\u8bc4\u4f30\u4e0d\u540c\u6a21\u578b\u7684\u6548\u7387\u5dee\u8ddd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86REO-RL\uff0c\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u7f29\u5c0f\u63a8\u7406\u6548\u7387\u5dee\u8ddd\uff08REG\uff09\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u4e00\u7ec4\u6218\u7565\u6027\u9009\u62e9\u7684 token \u9884\u7b97\u8fdb\u884c\u6570\u503c\u79ef\u5206\uff0c\u4ee5\u4f4e\u8bef\u5dee\u8fd1\u4f3c\u5b8c\u6574\u7684\u6548\u7387\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cREO-RL\u53ef\u4ee5\u5728\u8f83\u5c0f\u7684token\u9884\u7b97\u4e0b\uff0c\u663e\u8457\u964d\u4f4eREG\uff08\u63a8\u7406\u6548\u7387\u5dee\u8ddd\uff09\u800c\u7ef4\u6301\u9ad8\u51c6\u786e\u6027\u3002\u4e0eQwen3-4B/8B\u6548\u80fd\u524d\u6cbf\u76f8\u6bd4\uff0c\u572816K token\u9884\u7b97\u4e0b\uff0cREO-RL\u5b9e\u73b0\u4e86>=50\u7684REG\u51cf\u5c11\uff0c\u4e14\u7cbe\u5ea6\u635f\u5931\u6700\u5c0f\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u5728\u6570\u5b66\u57fa\u51c6\u4e0a\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u6548\u6027\u53d1\u73b0\uff0c\u5f53\u524d\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u6548\u7387\u7f3a\u53e3\u3002\u5e94\u7528REO-RL\u65b9\u6cd5\u540e\uff0c\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11REG\uff08\u63a8\u7406\u6548\u7387\u5dee\u8ddd\uff09\uff0c\u4f46\u5b8c\u5168\u5339\u914d\u6548\u80fd\u524d\u6cbf\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u6311\u6218\u3002"}}
{"id": "2506.06861", "pdf": "https://arxiv.org/pdf/2506.06861", "abs": "https://arxiv.org/abs/2506.06861", "authors": ["Xizhi Tian", "Meng Ding", "Touming Tao", "Zihang Xiang", "Di Wang"], "title": "Differentially Private Sparse Linear Regression with Heavy-tailed Responses", "categories": ["cs.LG", "cs.CR"], "comment": "Accepted at ECML 2025", "summary": "As a fundamental problem in machine learning and differential privacy (DP),\nDP linear regression has been extensively studied. However, most existing\nmethods focus primarily on either regular data distributions or low-dimensional\ncases with irregular data. To address these limitations, this paper provides a\ncomprehensive study of DP sparse linear regression with heavy-tailed responses\nin high-dimensional settings. In the first part, we introduce the DP-IHT-H\nmethod, which leverages the Huber loss and private iterative hard thresholding\nto achieve an estimation error bound of \\(\n  \\tilde{O}\\biggl(\n  s^{* \\frac{1 }{2}}\n  \\cdot \\biggl(\\frac{\\log d}{n}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  +\n  s^{* \\frac{1 + 2\\zeta}{2 + 2\\zeta}}\n  \\cdot \\biggl(\\frac{\\log^2 d}{n \\varepsilon}\\biggr)^{\\frac{\\zeta}{1 + \\zeta}}\n  \\biggr) \\) under the $(\\varepsilon, \\delta)$-DP model, where $n$ is the\nsample size, $d$ is the dimensionality, $s^*$ is the sparsity of the parameter,\nand $\\zeta \\in (0, 1]$ characterizes the tail heaviness of the data. In the\nsecond part, we propose DP-IHT-L, which further improves the error bound under\nadditional assumptions on the response and achieves \\(\n  \\tilde{O}\\Bigl(\\frac{(s^*)^{3/2} \\log d}{n \\varepsilon}\\Bigr). \\) Compared to\nthe first result, this bound is independent of the tail parameter $\\zeta$.\nFinally, through experiments on synthetic and real-world datasets, we\ndemonstrate that our methods outperform standard DP algorithms designed for\n``regular'' data.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u7ef4\u91cd\u5c3e\u54cd\u5e94\u4e0b\u7684\u5dee\u5206\u9690\u79c1\u7a00\u758f\u7ebf\u6027\u56de\u5f52\uff0c\u63d0\u51fa\u4e86 DP-IHT-H \u548c DP-IHT-L \u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u89c4\u5219\u6570\u636e\u5206\u5e03\u6216\u4f4e\u7ef4\u4e0d\u89c4\u5219\u6570\u636e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f25\u8865\u5176\u5728\u9ad8\u7ef4\u91cd\u5c3e\u54cd\u5e94\u4e0b\u7684\u4e0d\u8db3\u3002", "method": "\u672c\u6587\u63d0\u51fa DP-IHT-H \u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408 Huber \u635f\u5931\u548c\u79c1\u6709\u8fed\u4ee3\u786c\u9608\u503c\u6280\u672f\uff1b\u8fd8\u63d0\u51fa\u4e86 DP-IHT-L \u65b9\u6cd5\uff0c\u5728\u7279\u5b9a\u5047\u8bbe\u4e0b\u8fdb\u4e00\u6b65\u6539\u8fdb\u8bef\u5dee\u754c\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u6807\u51c6\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u7a00\u758f\u7ebf\u6027\u56de\u5f52\u65b9\u6cd5\uff08DP-IHT-H \u548c DP-IHT-L\uff09\uff0c\u5728\u9ad8\u7ef4\u6570\u636e\u548c\u91cd\u5c3e\u54cd\u5e94\u4e0b\uff0c\u5c55\u793a\u4e86\u4f18\u4e8e\u6807\u51c6\u5dee\u5206\u9690\u79c1\u7b97\u6cd5\u7684\u6548\u679c\u3002"}}
{"id": "2506.07820", "pdf": "https://arxiv.org/pdf/2506.07820", "abs": "https://arxiv.org/abs/2506.07820", "authors": ["Jiaxiang CHen", "Zhuo Wang", "Mingxi Zou", "Qifan Wang", "Zenglin Xu"], "title": "Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation", "categories": ["cs.AI"], "comment": null, "summary": "Human reasoning is flexible, adaptive, and grounded in prior\nexperience-qualities that large language models (LLMs) still struggle to\nemulate. Existing methods either explore diverse reasoning paths at inference\ntime or search for optimal workflows through expensive operations, but both\nfall short in leveraging multiple reusable strategies in a structured,\nefficient manner. We propose Guideline Forest, a framework that enhances LLMs\nreasoning by inducing structured reasoning strategies-called guidelines-from\nverified examples and executing them via step-wise aggregation. Unlike\ntest-time search or single-path distillation, our method draws on verified\nreasoning experiences by inducing reusable guidelines and expanding each into\ndiverse variants. Much like human reasoning, these variants reflect alternative\nthought patterns, are executed in parallel, refined via self-correction, and\naggregated step by step-enabling the model to adaptively resolve uncertainty\nand synthesize robust solutions.We evaluate Guideline Forest on four\nbenchmarks-GSM8K, MATH-500, MBPP, and HumanEval-spanning mathematical and\nprogrammatic reasoning. Guideline Forest consistently outperforms strong\nbaselines, including CoT, ReAct, ToT, FoT, and AFlow. Ablation studies further\nhighlight the effectiveness of multi-path reasoning and stepwise aggregation,\nunderscoring the Guideline Forest's adaptability and generalization potential.", "AI": {"tldr": "Guideline Forest\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u548c\u9010\u6b65\u805a\u5408\u7b56\u7565\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u591a\u6837\u6027\u548c\u9002\u5e94\u6027\u63a8\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u591a\u79cd\u53ef\u91cd\u7528\u7b56\u7565\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86Guideline Forest\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5bfc\u7ed3\u6784\u5316\u63a8\u7406\u7b56\u7565\u5e76\u901a\u8fc7\u9010\u6b65\u805a\u5408\u6267\u884c\u5b83\u4eec\uff0c\u4ee5\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\uff08GSM8K, MATH-500, MBPP, and HumanEval\uff09\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u9002\u5e94\u6027\u548c\u6cdb\u5316\u6f5c\u529b\u3002", "conclusion": "Guideline Forest\u6846\u67b6\u901a\u8fc7\u5229\u7528\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u63a8\u7406\u7ecf\u9a8c\u548c\u53ef\u91cd\u7528\u6307\u5357\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u548c\u7efc\u5408\u89e3\u51b3\u65b9\u6848\u7684\u80fd\u529b\u3002"}}
{"id": "2506.07106", "pdf": "https://arxiv.org/pdf/2506.07106", "abs": "https://arxiv.org/abs/2506.07106", "authors": ["Samir Abdaljalil", "Hasan Kurban", "Khalid Qaraqe", "Erchin Serpedin"], "title": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown strong performance across natural\nlanguage reasoning tasks, yet their reasoning processes remain brittle and\ndifficult to interpret. Prompting techniques like Chain-of-Thought (CoT)\nenhance reliability by eliciting intermediate reasoning steps or aggregating\nmultiple outputs. However, they lack mechanisms for enforcing logical structure\nand assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a\nnovel framework that models reasoning as collaboration among three parallel\nagents, each simulating a distinct mode of inference: abductive, deductive, and\ninductive. Each agent produces a reasoning trace, which is structured into a\nformal reasoning graph. To evaluate consistency, we apply Bayesian belief\npropagation guided by natural language inference (NLI), assigning confidence\nscores to each step. The most coherent graph is selected to derive the final\nanswer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)\nreasoning benchmarks show that ToTh consistently outperforms CoT,\nSelf-Consistency, and CoT-Decoding across multiple LLMs, while producing\ninterpretable and logically grounded reasoning chains. Our findings suggest a\npromising direction for building more robust and cognitively inspired LLM\nreasoning. The implementation is available at\nhttps://github.com/KurbanIntelligenceLab/theorem-of-thought.", "AI": {"tldr": "Theorem-of-Thought (ToTh) is a novel approach enhancing LLM reasoning through collaborative inference modes, outperforming existing methods on reasoning benchmarks with improved interpretability and logic.", "motivation": "Large language models (LLMs) currently exhibit strong performance in reasoning tasks but suffer from brittle and hard-to-interpret reasoning processes. Existing prompting techniques lack mechanisms for enforcing logical structure and evaluating internal coherence. To address these limitations, ToTh introduces a structured reasoning framework.", "method": "Theorem-of-Thought (ToTh) framework models reasoning as collaboration among three parallel agents simulating abductive, deductive, and inductive inference modes. Each agent produces a reasoning trace structured into a formal reasoning graph, evaluated for consistency using Bayesian belief propagation guided by natural language inference (NLI). The most coherent graph is used to derive the final answer.", "result": "Theorem-of-Thought (ToTh) achieves superior performance compared to Chain-of-Thought (CoT), Self-Consistency, and CoT-Decoding on symbolic (WebOfLies) and numerical (MultiArith) reasoning benchmarks, while also providing interpretable and logically grounded reasoning chains.", "conclusion": "Theorem-of-Thought (ToTh) consistently outperforms existing techniques such as Chain-of-Thought (CoT), Self-Consistency, and CoT-Decoding in both symbolic and numerical reasoning tasks, suggesting a promising direction for developing robust and cognitively inspired reasoning in LLMs."}}
{"id": "2506.06866", "pdf": "https://arxiv.org/pdf/2506.06866", "abs": "https://arxiv.org/abs/2506.06866", "authors": ["Dongyeop Lee", "Kwanhee Lee", "Jinseok Chung", "Namhoon Lee"], "title": "SAFE: Finding Sparse and Flat Minima to Improve Pruning", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Sparsifying neural networks often suffers from seemingly inevitable\nperformance degradation, and it remains challenging to restore the original\nperformance despite much recent progress. Motivated by recent studies in robust\noptimization, we aim to tackle this problem by finding subnetworks that are\nboth sparse and flat at the same time. Specifically, we formulate pruning as a\nsparsity-constrained optimization problem where flatness is encouraged as an\nobjective. We solve it explicitly via an augmented Lagrange dual approach and\nextend it further by proposing a generalized projection operation, resulting in\nnovel pruning methods called SAFE and its extension, SAFE$^+$. Extensive\nevaluations on standard image classification and language modeling tasks reveal\nthat SAFE consistently yields sparse networks with improved generalization\nperformance, which compares competitively to well-established baselines. In\naddition, SAFE demonstrates resilience to noisy data, making it well-suited for\nreal-world conditions.", "AI": {"tldr": "\u63d0\u51faSAFE\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u6027\u7ea6\u675f\u4f18\u5316\u5bfb\u6c42\u7a00\u758f\u53c8\u5e73\u6ed1\u7684\u5b50\u7f51\u7edc\uff0c\u6709\u6548\u63d0\u5347\u7f51\u7edc\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u53d7\u9c81\u68d2\u4f18\u5316\u7814\u7a76\u7684\u542f\u53d1\uff0c\u5e0c\u671b\u5bfb\u627e\u65e2\u7a00\u758f\u53c8\u5e73\u6ed1\u7684\u5b50\u7f51\u7edc\u6765\u89e3\u51b3\u526a\u679d\u540e\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u526a\u679d\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u7a00\u758f\u6027\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u6269\u5c55\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u65b9\u6cd5\u6c42\u89e3\uff0c\u63d0\u51fa\u4e86SAFE\u53ca\u5176\u6269\u5c55SAFE+\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSAFE\u65b9\u6cd5\u5728\u63d0\u5347\u7a00\u758f\u7f51\u7edc\u7684\u6cdb\u5316\u6027\u80fd\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u5e76\u80fd\u6709\u6548\u5904\u7406\u566a\u97f3\u6570\u636e\uff0c\u8868\u73b0\u4f18\u4e8e\u4e00\u4e9b\u77e5\u540d\u57fa\u7ebf\u3002", "conclusion": "SAFE\u65b9\u6cd5\u80fd\u591f\u627e\u5230\u65e2\u7a00\u758f\u53c8\u5e73\u6ed1\u7684\u5b50\u7f51\u7edc\uff0c\u5e76\u5728\u5e38\u89c1\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5e94\u6027\u5f3a\u3002"}}
{"id": "2506.07824", "pdf": "https://arxiv.org/pdf/2506.07824", "abs": "https://arxiv.org/abs/2506.07824", "authors": ["Yao Yan"], "title": "Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs", "categories": ["cs.AI"], "comment": "12 pages, including appendix, 7 figures. EMNLP 2025 submission (ARR\n  May 2025 cycle, reviews pending)", "summary": "Multi-digit addition is a clear probe of the computational power of large\nlanguage models. To dissect the internal arithmetic processes in\nLLaMA-3-8B-Instruct, we combine linear probing with logit-lens inspection.\nInspired by the step-by-step manner in which humans perform addition, we\npropose and analyze a coherent four-stage trajectory in the forward\npass:Formula-structure representations become linearly decodable first, while\nthe answer token is still far down the candidate list.Core computational\nfeatures then emerge prominently.At deeper activation layers, numerical\nabstractions of the result become clearer, enabling near-perfect detection and\ndecoding of the individual digits in the sum.Near the output, the model\norganizes and generates the final content, with the correct token reliably\noccupying the top rank.This trajectory suggests a hierarchical process that\nfavors internal computation over rote memorization. We release our code and\ndata to facilitate reproducibility.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578bLLaMA-3-8B-Instruct\u5728\u591a\u4f4d\u6570\u52a0\u6cd5\u4e2d\u5c55\u793a\u51fa\u5206\u5c42\u8ba1\u7b97\u8fc7\u7a0b\uff0c\u7ebf\u6027\u89e3\u7801\u5728\u65e9\u671f\u9636\u6bb5\u6709\u6548\uff0c\u4e2d\u540e\u671f\u51c6\u786e\u751f\u6210\u7ed3\u679c\uff0c\u8868\u660e\u5185\u90e8\u8ba1\u7b97\u4f18\u4e8e\u8bb0\u5fc6\u5316\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4f4d\u6570\u52a0\u6cd5\u4e0a\u7684\u8ba1\u7b97\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u7ebf\u6027\u63a2\u6d4b\u4e0elogit-lens\u68c0\u67e5\u5206\u6790\u6a21\u578b\u7684\u5185\u5728\u7b97\u672f\u8fc7\u7a0b\u3002", "result": "\u6df1\u5165\u6fc0\u6d3b\u5c42\u540e\uff0c\u7ed3\u679c\u7684\u6570\u503c\u62bd\u8c61\u53d8\u5f97\u6e05\u6670\uff0c\u5b9e\u73b0\u5bf9\u548c\u7684\u5404\u4e2a\u6570\u5b57\u7684\u63a5\u8fd1\u5b8c\u7f8e\u68c0\u6d4b\u548c\u89e3\u7801\uff1b\u4e34\u8fd1\u8f93\u51fa\u65f6\uff0c\u6a21\u578b\u53ef\u9760\u5730\u4ea7\u751f\u6b63\u786e\u7ed3\u679c\u3002", "conclusion": "\u6a21\u578b\u91c7\u7528\u5206\u5c42\u8fc7\u7a0b\uff0c\u5185\u90e8\u8ba1\u7b97\u4f18\u4e8e\u6b7b\u8bb0\u786c\u80cc\u3002"}}
{"id": "2506.07142", "pdf": "https://arxiv.org/pdf/2506.07142", "abs": "https://arxiv.org/abs/2506.07142", "authors": ["Lennart Meincke", "Ethan Mollick", "Lilach Mollick", "Dan Shapiro"], "title": "Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This is the second in a series of short reports that seek to help business,\neducation, and policy leaders understand the technical details of working with\nAI through rigorous testing. In this report, we investigate Chain-of-Thought\n(CoT) prompting, a technique that encourages a large language model (LLM) to\n\"think step by step\" (Wei et al., 2022). CoT is a widely adopted method for\nimproving reasoning tasks, however, our findings reveal a more nuanced picture\nof its effectiveness. We demonstrate two things:\n  - The effectiveness of Chain-of-Thought prompting can vary greatly depending\non the type of task and model. For non-reasoning models, CoT generally improves\naverage performance by a small amount, particularly if the model does not\ninherently engage in step-by-step processing by default. However, CoT can\nintroduce more variability in answers, sometimes triggering occasional errors\nin questions the model would otherwise get right. We also found that many\nrecent models perform some form of CoT reasoning even if not asked; for these\nmodels, a request to perform CoT had little impact. Performing CoT generally\nrequires far more tokens (increasing cost and time) than direct answers.\n  - For models designed with explicit reasoning capabilities, CoT prompting\noften results in only marginal, if any, gains in answer accuracy. However, it\nsignificantly increases the time and tokens needed to generate a response.", "AI": {"tldr": "CoT\u63d0\u793a\u6280\u672f\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u4e2d\u6548\u679c\u5404\u5f02\uff0c\u5bf9\u975e\u63a8\u7406\u6a21\u578b\u6709\u65f6\u6709\u52a9\u4e8e\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u4f1a\u589e\u52a0\u56de\u7b54\u53d8\u5316\u6027\u548c\u751f\u6210\u6210\u672c\u3002", "motivation": "\u5e2e\u52a9\u5546\u4e1a\u3001\u6559\u80b2\u548c\u653f\u7b56\u9886\u5bfc\u4eba\u901a\u8fc7\u4e25\u8c28\u7684\u6d4b\u8bd5\u4e86\u89e3\u4e0eAI\u76f8\u5173\u6280\u672f\u7ec6\u8282\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u7684\u6d4b\u8bd5\u5bf9Chain-of-Thought\u63d0\u793a\u6280\u672f\u8fdb\u884c\u8c03\u67e5\uff0c\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "result": "\u5373\u4f7f\u5728\u5177\u5907\u663e\u6027\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\u4e2d\uff0cCoT\u63d0\u793a\u5728\u7b54\u6848\u51c6\u786e\u6027\u4e0a\u7684\u63d0\u5347\u4e5f\u5f88\u6709\u9650\uff0c\u540c\u65f6\u589e\u52a0\u4e86\u751f\u6210\u54cd\u5e94\u6240\u9700\u7684\u65f6\u95f4\u548c\u4ee3\u4ef7\u3002", "conclusion": "Chain-of-Thought\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u4e2d\u6548\u679c\u76f8\u5dee\u5f88\u5927\uff0c\u5bf9\u4e8e\u975e\u63a8\u7406\u6a21\u578b\u6709\u65f6\u4f1a\u5c0f\u5e45\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u53ef\u80fd\u589e\u52a0\u56de\u7b54\u7684\u53d8\u5316\u6027\u548c\u9519\u8bef\u7387\u3002"}}
{"id": "2506.06873", "pdf": "https://arxiv.org/pdf/2506.06873", "abs": "https://arxiv.org/abs/2506.06873", "authors": ["Armin Behnamnia", "Gholamali Aminian", "Alireza Aghaei", "Chengchun Shi", "Vincent Y. F. Tan", "Hamid R. Rabiee"], "title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted as spotlight poster in ICML 2025", "summary": "Off-policy learning and evaluation leverage logged bandit feedback datasets,\nwhich contain context, action, propensity score, and feedback for each data\npoint. These scenarios face significant challenges due to high variance and\npoor performance with low-quality propensity scores and heavy-tailed reward\ndistributions. We address these issues by introducing a novel estimator based\non the log-sum-exponential (LSE) operator, which outperforms traditional\ninverse propensity score estimators. Our LSE estimator demonstrates variance\nreduction and robustness under heavy-tailed conditions. For off-policy\nevaluation, we derive upper bounds on the estimator's bias and variance. In the\noff-policy learning scenario, we establish bounds on the regret -- the\nperformance gap between our LSE estimator and the optimal policy -- assuming\nbounded $(1+\\epsilon)$-th moment of weighted reward. Notably, we achieve a\nconvergence rate of $O(n^{-\\epsilon/(1+ \\epsilon)})$ for the regret bounds,\nwhere $\\epsilon \\in [0,1]$ and $n$ is the size of logged bandit feedback\ndataset. Theoretical analysis is complemented by comprehensive empirical\nevaluations in both off-policy learning and evaluation scenarios, confirming\nthe practical advantages of our approach. The code for our estimator is\navailable at the following link:\nhttps://github.com/armin-behnamnia/lse-offpolicy-learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bLSE\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u548c\u8bc4\u4f30\u4e2d\u7684\u9ad8\u65b9\u5dee\u548c\u6027\u80fd\u95ee\u9898\uff0c\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u5176\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u89e3\u51b3\u9ad8\u65b9\u5dee\u548c\u4f4e\u8d28\u91cf\u503e\u5411\u8bc4\u5206\u4ee5\u53ca\u91cd\u5c3e\u5206\u5e03\u5bfc\u81f4\u7684\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u5f15\u5165\u57fa\u4e8e\u5bf9\u6570\u548c\u6307\u6570\uff08LSE\uff09\u7b97\u5b50\u7684\u4f30\u8ba1\u5668\uff0c\u4e0e\u4f20\u7edf\u7684\u9006\u503e\u5411\u8bc4\u5206\u4f30\u8ba1\u5668\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002\u4e3a\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u63a8\u5bfc\u4e86\u4f30\u8ba1\u5668\u7684\u504f\u5dee\u548c\u65b9\u5dee\u7684\u4e0a\u754c\uff0c\u5e76\u5728\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u573a\u666f\u4e2d\u5efa\u7acb\u4e86\u9057\u61be\u754c\u9650\u3002\u8fd9\u4e9b\u754c\u9650\u5047\u8bbe\u79f0\u52a0\u6743\u5956\u52b1\u7684$(1+\\epsilon)$-\u9636\u77e9\u662f\u6709\u754c\u7684\u3002", "result": "LSE\u4f30\u8ba1\u5668\u5728\u91cd\u5c3e\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u65b9\u5dee\u51cf\u5c11\u548c\u7a33\u5065\u6027\uff0c\u5e76\u53d6\u5f97\u6536\u655b\u901f\u5ea6\u4e3a$O(n^{-\\epsilon/(1+ \\epsilon)})$\u7684\u9057\u61be\u754c\u9650\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u5bf9\u6570\u548c\u6307\u6570\uff08LSE\uff09\u7b97\u5b50\u7684\u65b0\u4f30\u8ba1\u5668\u5728\u79bb\u7ebf\u7b56\u7565\u5b66\u4e60\u548c\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5b9e\u73b0\u4e86\u65b9\u5dee\u51cf\u5c11\uff0c\u5e76\u5728\u91cd\u5c3e\u6761\u4ef6\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u3002\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u8bc1\u8bc4\u4f30\u76f8\u7ed3\u5408\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u4f18\u52bf\u3002"}}
{"id": "2506.07837", "pdf": "https://arxiv.org/pdf/2506.07837", "abs": "https://arxiv.org/abs/2506.07837", "authors": ["Shijie Wang", "Yilun Zhang", "Zeyu Lai", "Dexing Kong"], "title": "HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains", "categories": ["cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have shown great potential in\ngeneral domains but perform poorly in some specific domains due to a lack of\ndomain-specific data, such as image-text data or vedio-text data. In some\nspecific domains, there is abundant graphic and textual data scattered around,\nbut lacks standardized arrangement. In the field of medical ultrasound, there\nare ultrasonic diagnostic books, ultrasonic clinical guidelines, ultrasonic\ndiagnostic reports, and so on. However, these ultrasonic materials are often\nsaved in the forms of PDF, images, etc., and cannot be directly used for the\ntraining of MLLMs. This paper proposes a novel image-text reasoning supervised\nfine-tuning data generation pipeline to create specific domain quadruplets\n(image, question, thinking trace, and answer) from domain-specific materials. A\nmedical ultrasound domain dataset ReMUD is established, containing over 45,000\nreasoning and non-reasoning supervised fine-tuning Question Answering (QA) and\nVisual Question Answering (VQA) data. The ReMUD-7B model, fine-tuned on\nQwen2.5-VL-7B-Instruct, outperforms general-domain MLLMs in medical ultrasound\nfield. To facilitate research, the ReMUD dataset, data generation codebase, and\nReMUD-7B parameters will be released at https://github.com/ShiDaizi/ReMUD,\naddressing the data shortage issue in specific domain MLLMs.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u9886\u57df\u7279\u5b9a\u6570\u636e\u751f\u6210\u7684\u7ba1\u9053\u5e76\u5efa\u7acb\u4e86 ReMUD \u6570\u636e\u96c6\uff0c\u6709\u6548\u63d0\u5347\u533b\u5b66\u8d85\u58f0\u9886\u57df\u7684\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u9886\u57df\u5c55\u793a\u4e86\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u7684\u6570\u636e\uff0c\u5728\u67d0\u4e9b\u7279\u5b9a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u4f8b\u5982\u533b\u5b66\u8d85\u58f0\u9886\u57df\u4e2d\u7684\u6570\u636e\u7f3a\u4e4f\u6807\u51c6\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56fe\u6587\u63a8\u7406\u76d1\u7763\u5fae\u8c03\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u4ece\u7279\u5b9a\u9886\u57df\u6750\u6599\u4e2d\u521b\u5efa\u56db\u5143\u7ec4\uff08\u56fe\u50cf\u3001\u95ee\u9898\u3001\u601d\u7ef4\u8fc7\u7a0b\u548c\u7b54\u6848\uff09\uff0c\u5e76\u5efa\u7acb\u4e86 ReMUD \u6570\u636e\u96c6\u3002", "result": "\u5efa\u7acb\u4e86 ReMUD \u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc7 45000 \u7684\u63a8\u7406\u548c\u975e\u63a8\u7406\u76d1\u7763\u7cbe\u8c03\u95ee\u7b54\u548c\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u3002\u5fae\u8c03\u7684 ReMUD-7B \u6a21\u578b\u5728\u533b\u5b66\u8d85\u58f0\u9886\u57df\u8d85\u8fc7\u4e86\u4e00\u822c\u9886\u57df\u7684\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "ReMUD-7B \u6a21\u578b\u5728\u533b\u5b66\u8d85\u58f0\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u4e00\u822c\u9886\u57df\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u8fd9\u901a\u8fc7\u751f\u6210\u4e00\u4e2a\u7279\u5b9a\u9886\u57df\u7684\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6a21\u578b\u6765\u5b9e\u73b0\u3002"}}
{"id": "2506.07148", "pdf": "https://arxiv.org/pdf/2506.07148", "abs": "https://arxiv.org/abs/2506.07148", "authors": ["Yaping Chai", "Haoran Xie", "Joe S. Qin"], "title": "Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis", "categories": ["cs.CL"], "comment": "10 pages, 7 figures, 4 tables", "summary": "Large language model (LLM) is an effective approach to addressing data\nscarcity in low-resource scenarios. Recent existing research designs\nhand-crafted prompts to guide LLM for data augmentation. We introduce a data\naugmentation strategy for the aspect category sentiment analysis (ACSA) task\nthat preserves the original sentence semantics and has linguistic diversity,\nspecifically by providing a structured prompt template for an LLM to generate\npredefined content. In addition, we employ a post-processing technique to\nfurther ensure semantic consistency between the generated sentence and the\noriginal sentence. The augmented data increases the semantic coverage of the\ntraining distribution, enabling the model better to understand the relationship\nbetween aspect categories and sentiment polarities, enhancing its inference\ncapabilities. Furthermore, we propose a confidence-weighted fine-tuning\nstrategy to encourage the model to generate more confident and accurate\nsentiment polarity predictions. Compared with powerful and recent works, our\nmethod consistently achieves the best performance on four benchmark datasets\nover all baselines.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528LLM\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u7684\u7b56\u7565\uff0c\u7ed3\u5408\u4fe1\u5fc3\u6c34\u5e73\u52a0\u6743\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u9ad8\u4e86ACSA\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u4f4e\u8d44\u6e90\u60c5\u51b5\u4e0b\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u9ad8ACSA\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u63d0\u793a\u6a21\u677f\u7ed9LLM\u6765\u751f\u6210\u9884\u5b9a\u4e49\u7684\u5185\u5bb9\uff0c\u5e76\u91c7\u7528\u540e\u5904\u7406\u6280\u672f\u4ee5\u786e\u4fdd\u751f\u6210\u53e5\u5b50\u4e0e\u539f\u59cb\u53e5\u5b50\u4e4b\u95f4\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4fe1\u5fc3\u6c34\u5e73\u52a0\u6743\u5fae\u8c03\u7b56\u7565\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u5747\u83b7\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684ACSA\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.06884", "pdf": "https://arxiv.org/pdf/2506.06884", "abs": "https://arxiv.org/abs/2506.06884", "authors": ["Divya Jyoti Bajpai", "Manjesh Kumar Hanawal"], "title": "FREE: Fast and Robust Vision Language Models with Early Exits", "categories": ["cs.LG", "cs.CV"], "comment": "To appear at the Association of Computational Linguistics (ACL) 2025\n  Conference", "summary": "In recent years, Vision-Language Models (VLMs) have shown remarkable\nperformance improvements in Vision-Language tasks. However, their large size\nposes challenges for real-world applications where inference latency is a\nconcern. To tackle this issue, we propose employing Early Exit (EE) strategies\nin VLMs. However, training exit classifiers in VLMs is challenging,\nparticularly with limited labeled training data. To address this, we introduce\nFREE, an adversarial training approach within a GAN-based framework. Here, each\nexit consists of a transformer layer and a classifier. The transformer layer is\nadversarially trained to produce feature representations similar to the final\nlayer, while a feature classifier serves as the discriminator. Our method\nfocuses on performing input-adaptive inference that increases inference speed\nwith minimal drop in performance. Experimental results demonstrate the\neffectiveness of our approach in enhancing accuracy and model robustness by\nmitigating overthinking and the phenomenon of mid-crisis that we highlight. We\nexperimentally validate that our method speeds up the inference process by more\nthan 1.51x while retaining comparable performance. The source code is available\nat https://github.com/Div290/FREE.", "AI": {"tldr": "\u4e3a\u4e86\u5e94\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7b56\u7565\uff0c\u901a\u8fc7\u65e9\u9000\u51fa\u673a\u5236\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6548\u679c\u826f\u597d\u3002", "motivation": "\u5927\u89c4\u6a21\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u63a8\u7406\u5ef6\u8fdf\u6210\u4e3a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u7684\u65e9\u9000\u51fa\u7b56\u7565\uff0c\u7ed3\u5408\u8f6c\u6362\u5668\u5c42\u548c\u5206\u7c7b\u5668\uff0c\u8fdb\u884c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u5c06\u63a8\u7406\u901f\u5ea6\u63d0\u9ad8\u8d85\u8fc71.51\u500d\uff0c\u5e76\u4fdd\u6301\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u6027\u80fd\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\u3002"}}
{"id": "2506.07853", "pdf": "https://arxiv.org/pdf/2506.07853", "abs": "https://arxiv.org/abs/2506.07853", "authors": ["Hudson de Martim"], "title": "A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Effectively representing legal norms for automated processing is a critical\nchallenge, particularly in tracking the diachronic evolution of their\nhierarchical components (e.g., articles, paragraphs). While foundational\nframeworks like FRBR/FRBRoo and standards like Akoma Ntoso model legal\ndocuments at a macro level, they lack native mechanisms for granular,\ncomponent-level versioning. This limitation hinders the deterministic\npoint-in-time reconstruction of legal texts, a fundamental capability for\nreliable Legal Tech and AI applications. This paper proposes a structured,\ntemporal model that extends the FRBRoo framework to address this gap. It\nintroduces specialized subclasses of Expressio - Temporal Version (TV) and\nLanguage Version (LV - to represent the state of a legal norm and its\nlinguistic variations at specific points in time. The model applies this same\nparadigm hierarchically, introducing Component Work (CW), Component Temporal\nVersion (CTV), and Component Language Version (CLV) to track the lifecycle of\nindividual articles, paragraphs, and clauses. Using the Brazilian Federal\nConstitution as a case study, the paper demonstrates how each amendment creates\nnew Component Temporal Versions for affected provisions, while unaffected\ncomponents retain their existing versions. This fine-grained, time-aware\narchitecture enables the precise, deterministic retrieval and reconstruction of\nany part of a legal text as it existed on a specific date. The model provides a\nrobust foundation for developing advanced legal information systems, knowledge\ngraphs, and AI tools capable of accurate historical analysis and impact\nassessment, overcoming the limitations of current generative models.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55FRBRoo\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u3001\u65f6\u95f4\u611f\u77e5\u7684\u6cd5\u5f8b\u6587\u672c\u7248\u672c\u7ba1\u7406\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5df4\u897f\u8054\u90a6\u5baa\u6cd5\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u53ef\u7528\u4e8e\u51c6\u786e\u7684\u5386\u53f2\u5206\u6790\u3002", "motivation": "\u73b0\u6709\u6cd5\u5f8b\u6587\u6863\u6a21\u578b\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u7248\u672c\u7ba1\u7406\uff0c\u96be\u4ee5\u5b9e\u73b0\u5bf9\u6cd5\u5f8b\u6587\u672c\u5728\u4e0d\u540c\u65f6\u70b9\u7684\u51c6\u786e\u91cd\u5efa\uff0c\u8fd9\u5bf9\u6cd5\u5f8b\u6280\u672f\u548c\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u65f6\u95f4\u6a21\u578b\uff0c\u6269\u5c55FRBRoo\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7279\u5b9a\u7684\u5b50\u7c7b\u5982Temporal Version (TV)\u548cLanguage Version (LV)\uff0c\u4ee5\u53caComponent Work (CW)\u3001Component Temporal Version (CTV)\u548cComponent Language Version (CLV)\uff0c\u5b9e\u73b0\u6cd5\u5f8b\u89c4\u8303\u7684\u7ec6\u7c92\u5ea6\u3001\u65f6\u95f4\u611f\u77e5\u7684\u7248\u672c\u7ba1\u7406\u3002", "result": "\u91c7\u7528\u5df4\u897f\u8054\u90a6\u5baa\u6cd5\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6f14\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6bcf\u6b21\u4fee\u6b63\u521b\u9020\u65b0\u7684\u7ec4\u4ef6\u65f6\u95f4\u7248\u672c\uff0c\u4f7f\u5f97\u4efb\u4f55\u6cd5\u5f8b\u6587\u672c\u7684\u4efb\u4e00\u90e8\u5206\u90fd\u53ef\u4ee5\u5728\u7279\u5b9a\u65e5\u671f\u8fdb\u884c\u7cbe\u786e\u3001\u786e\u5b9a\u6027\u7684\u68c0\u7d22\u548c\u91cd\u5efa\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u5f00\u53d1\u80fd\u591f\u8fdb\u884c\u51c6\u786e\u5386\u53f2\u5206\u6790\u548c\u5f71\u54cd\u8bc4\u4f30\u7684\u5148\u8fdb\u6cd5\u5f8b\u4fe1\u606f\u7cfb\u7edf\u3001\u77e5\u8bc6\u56fe\u8c31\u4ee5\u53caAI\u5de5\u5177\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2506.07154", "pdf": "https://arxiv.org/pdf/2506.07154", "abs": "https://arxiv.org/abs/2506.07154", "authors": ["Vicky Xefteri", "Tim Vieira", "Ryan Cotterell", "Afra Amini"], "title": "Syntactic Control of Language Models by Posterior Inference", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Controlling the syntactic structure of text generated by language models is\nvaluable for applications requiring clarity, stylistic consistency, or\ninterpretability, yet it remains a challenging task. In this paper, we argue\nthat sampling algorithms based on the posterior inference can effectively\nenforce a target constituency structure during generation. Our approach\ncombines sequential Monte Carlo, which estimates the posterior distribution by\nsampling from a proposal distribution, with a syntactic tagger that ensures\nthat each generated token aligns with the desired syntactic structure. Our\nexperiments with GPT2 and Llama3-8B models show that with an appropriate\nproposal distribution, we can improve syntactic accuracy, increasing the F1\nscore from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both\ncases without compromising the language model's fluency. These results\nunderscore both the complexity of syntactic control and the effectiveness of\nsampling algorithms, offering a promising approach for applications where\nprecise control over syntax is essential.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u6cd5\u548c\u53e5\u6cd5\u6807\u6ce8\u5668\uff0c\u53ef\u5728\u4fdd\u6301\u8bed\u8a00\u6d41\u7545\u6027\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u9ad8\u751f\u6210\u6587\u672c\u7684\u53e5\u6cd5\u51c6\u786e\u6027\u3002", "motivation": "\u63a7\u5236\u751f\u6210\u6587\u672c\u7684\u53e5\u6cd5\u7ed3\u6784\u5bf9\u4e8e\u90a3\u4e9b\u9700\u8981\u6e05\u6670\u5ea6\u3001\u98ce\u683c\u4e00\u81f4\u6027\u6216\u53ef\u89e3\u91ca\u6027\u7684\u5e94\u7528\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u8fd9\u4e00\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u7814\u7a76\u7ed3\u5408\u4e86\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u6cd5\uff08\u7528\u63d0\u8bae\u5206\u5e03\u8fdb\u884c\u91c7\u6837\u4ee5\u8bc4\u4f30\u540e\u9a8c\u5206\u5e03\uff09\u548c\u4e00\u79cd\u66f4\u52a0\u7cbe\u51c6\u7684\u53e5\u6cd5\u6807\u6ce8\u65b9\u6cd5\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2a\u751f\u6210\u7684\u6587\u672c\u6807\u8bb0\u90fd\u7b26\u5408\u6240\u9700\u7684\u53e5\u6cd5\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u4f7f\u7528\u9002\u5f53\u7684\u63d0\u8bae\u5206\u5e03\uff0c\u53ef\u4ee5\u63d0\u9ad8\u751f\u6210\u6587\u672c\u7684\u53e5\u6cd5\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u63d0\u5347F1\u5f97\u5206\u3002\u540c\u65f6\u4e0d\u5f71\u54cd\u8bed\u8a00\u6a21\u578b\u7684\u6d41\u7545\u6027\u3002", "conclusion": "\u91c7\u6837\u7b97\u6cd5\u53ef\u4ee5\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u6709\u6548\u5730\u5f3a\u5236\u6267\u884c\u76ee\u6807\u7684\u8bed\u6cd5\u7ed3\u6784\uff0c\u8fd9\u5728\u9700\u8981\u7cbe\u786e\u8bed\u6cd5\u63a7\u5236\u7684\u5e94\u7528\u4e2d\u975e\u5e38\u6709\u6548\u3002"}}
{"id": "2506.06891", "pdf": "https://arxiv.org/pdf/2506.06891", "abs": "https://arxiv.org/abs/2506.06891", "authors": ["Paulius Sasnauskas", "Yi\u011fit Yal\u0131n", "Goran Radanovi\u0107"], "title": "Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "We study the corruption-robustness of in-context reinforcement learning\n(ICRL), focusing on the Decision-Pretrained Transformer (DPT, Lee et al.,\n2023). To address the challenge of reward poisoning attacks targeting the DPT,\nwe propose a novel adversarial training framework, called Adversarially Trained\nDecision-Pretrained Transformer (AT-DPT). Our method simultaneously trains an\nattacker to minimize the true reward of the DPT by poisoning environment\nrewards, and a DPT model to infer optimal actions from the poisoned data. We\nevaluate the effectiveness of our approach against standard bandit algorithms,\nincluding robust baselines designed to handle reward contamination. Our results\nshow that the proposed method significantly outperforms these baselines in\nbandit settings, under a learned attacker. We additionally evaluate AT-DPT on\nan adaptive attacker, and observe similar results. Furthermore, we extend our\nevaluation to the MDP setting, confirming that the robustness observed in\nbandit scenarios generalizes to more complex environments.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u79cd\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6\uff08AT-DPT\uff09\u4ee5\u63d0\u9ad8\u51b3\u7b56\u9884\u8bad\u7ec3Transformer\uff08DPT\uff09\u5bf9\u5956\u52b1\u6295\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0cAT-DPT\u5728\u8d4c\u535a\u548cMDP\u73af\u5883\u4e2d\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u9488\u5bf9\u51b3\u7b56\u9884\u8bad\u7ec3Transformer\u7684\u5956\u52b1\u6295\u6bd2\u653b\u51fb\uff0c\u7814\u7a76ICRL\u7684\u8150\u8d25\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6297\u8bad\u7ec3\u6846\u67b6\uff0c\u5373\u5bf9\u6297\u8bad\u7ec3\u51b3\u7b56\u9884\u8bad\u7ec3Transformer\uff08AT-DPT\uff09\u3002\u8be5\u65b9\u6cd5\u540c\u65f6\u8bad\u7ec3\u653b\u51fb\u8005\u901a\u8fc7\u6c61\u67d3\u73af\u5883\u5956\u52b1\u6700\u5c0f\u5316DPT\u7684\u771f\u5b9e\u5956\u52b1\uff0c\u4ee5\u53ca\u8bad\u7ec3DPT\u6a21\u578b\u4ece\u6c61\u67d3\u6570\u636e\u4e2d\u63a8\u65ad\u6700\u4f18\u884c\u52a8\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5177\u6709\u5b66\u4e60\u653b\u51fb\u8005\u7684\u8d4c\u535a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u4f18\u8d8a\u7684\u6548\u679c\uff0c\u5e76\u5728\u9002\u5e94\u6027\u653b\u51fb\u8005\u4e0a\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5728MDP\u8bbe\u7f6e\u4e2d\u7684\u6269\u5c55\u8bc4\u4f30\u8bc1\u5b9e\u4e86\u5728\u8d4c\u535a\u573a\u666f\u4e2d\u89c2\u5bdf\u5230\u7684\u9c81\u68d2\u6027\u53ef\u4ee5\u63a8\u5e7f\u5230\u66f4\u590d\u6742\u7684\u73af\u5883\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5177\u6709\u5b66\u4e60\u653b\u51fb\u8005\u7684\u8d4c\u535a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u4f18\u4e8e\u57fa\u7ebf\u7684\u6548\u679c\uff0c\u5e76\u4e14\u5728\u9002\u5e94\u6027\u653b\u51fb\u8005\u4e0a\u89c2\u5bdf\u5230\u7c7b\u4f3c\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u8bc4\u4f30\u5728MDP\u73af\u5883\u4e2d\u786e\u8ba4\u4e86\u5728\u8d4c\u535a\u573a\u666f\u4e2d\u89c2\u5bdf\u5230\u7684\u9c81\u68d2\u6027\u53ef\u4ee5\u63a8\u5e7f\u5230\u66f4\u590d\u6742\u7684\u73af\u5883\u3002"}}
{"id": "2506.07896", "pdf": "https://arxiv.org/pdf/2506.07896", "abs": "https://arxiv.org/abs/2506.07896", "authors": ["Shoko Oka"], "title": "Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark", "categories": ["cs.AI", "cs.CL"], "comment": "52 pages, Additional resources available on GitHub repository", "summary": "Recent advancements in large language models (LLMs) have revitalized\nphilosophical debates surrounding artificial intelligence. Two of the most\nfundamental challenges - namely, the Frame Problem and the Symbol Grounding\nProblem - have historically been viewed as unsolvable within traditional\nsymbolic AI systems. This study investigates whether modern LLMs possess the\ncognitive capacities required to address these problems. To do so, I designed\ntwo benchmark tasks reflecting the philosophical core of each problem,\nadministered them under zero-shot conditions to 13 prominent LLMs (both closed\nand open-source), and assessed the quality of the models' outputs across five\ntrials each. Responses were scored along multiple criteria, including\ncontextual reasoning, semantic coherence, and information filtering. The\nresults demonstrate that while open-source models showed variability in\nperformance due to differences in model size, quantization, and instruction\ntuning, several closed models consistently achieved high scores. These findings\nsuggest that select modern LLMs may be acquiring capacities sufficient to\nproduce meaningful and stable responses to these long-standing theoretical\nchallenges.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u89e3\u51b3AI\u7684\u4e24\u4e2a\u6838\u5fc3\u54f2\u5b66\u95ee\u9898\uff0c\u53d1\u73b0\u90e8\u5206\u95ed\u6e90\u6a21\u578b\u5728\u7a33\u5b9a\u6027\u548c\u8868\u73b0\u4e0a\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u63a2\u8ba8\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u89e3\u51b3\u54f2\u5b66\u4e0a\u4eba\u5de5\u667a\u80fd\u7684\u6838\u5fc3\u96be\u9898\u201c\u6846\u67b6\u95ee\u9898\u201d\u548c\u201c\u7b26\u53f7\u624e\u6839\u95ee\u9898\u201d\u7684\u8ba4\u77e5\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e24\u4e2a\u57fa\u51c6\u4efb\u52a1\u4ee5\u53cd\u6620\u6bcf\u4e2a\u95ee\u9898\u7684\u54f2\u5b66\u6838\u5fc3\uff0c\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u5bf913\u4e2a\u77e5\u540d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u6a21\u578b\u8fdb\u884c\u4e94\u6b21\u8bd5\u9a8c\uff0c\u5e76\u6839\u636e\u591a\u9879\u6807\u51c6\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u7684\u8d28\u91cf\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5f00\u6e90\u6a21\u578b\u7531\u4e8e\u6a21\u578b\u5927\u5c0f\u3001\u91cf\u5316\u548c\u6307\u4ee4\u8c03\u6574\u7684\u5dee\u5f02\u800c\u8868\u73b0\u51fa\u6027\u80fd\u5dee\u5f02\uff0c\u800c\u82e5\u5e72\u95ed\u6e90\u6a21\u578b\u5219\u59cb\u7ec8\u83b7\u5f97\u9ad8\u5206\u3002", "conclusion": "\u90e8\u5206\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u5177\u5907\u8db3\u591f\u7684\u80fd\u529b\u6765\u5bf9\u957f\u671f\u5b58\u5728\u7684\u7406\u8bba\u6311\u6218\u4ea7\u751f\u6709\u610f\u4e49\u548c\u7a33\u5b9a\u7684\u53cd\u5e94\u3002"}}
{"id": "2506.07160", "pdf": "https://arxiv.org/pdf/2506.07160", "abs": "https://arxiv.org/abs/2506.07160", "authors": ["Yikun Wang", "Yibin Wang", "Dianyi Wang", "Zimian Peng", "Qipeng Guo", "Dacheng Tao", "Jiaqi Wang"], "title": "GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities across diverse domains, particularly in mathematical reasoning,\namid which geometry problem solving remains a challenging area where auxiliary\nconstruction plays a enssential role. Existing approaches either achieve\nsuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring\nmassive computational costs. We posit that reinforcement learning with\nverifiable reward (e.g., GRPO) offers a promising direction for training\nsmaller models that effectively combine auxiliary construction with robust\ngeometric reasoning. However, directly applying GRPO to geometric reasoning\npresents fundamental limitations due to its dependence on unconditional\nrewards, which leads to indiscriminate and counterproductive auxiliary\nconstructions. To address these challenges, we propose Group Contrastive Policy\nOptimization (GCPO), a novel reinforcement learning framework featuring two key\ninnovations: (1) Group Contrastive Masking, which adaptively provides positive\nor negative reward signals for auxiliary construction based on contextual\nutility, and a (2) length reward that promotes longer reasoning chains.\nBuilding on GCPO, we develop GeometryZero, a family of affordable-size\ngeometric reasoning models that judiciously determine when to employ auxiliary\nconstruction. Our extensive empirical evaluation across popular geometric\nbenchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models\nconsistently outperform baselines (e.g. GRPO), achieving an average improvement\nof 4.29% across all benchmarks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6GCPO\uff0c\u901a\u8fc7GeometryZero\u6a21\u578b\u5b9e\u73b0\u4e86\u5728\u51e0\u4f55\u63a8\u7406\u4e2d\u66f4\u9ad8\u6548\u7684\u8f85\u52a9\u6784\u5efa\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u51e0\u4f55\u95ee\u9898\u4e2d\u7684\u8f85\u52a9\u6784\u5efa\u6311\u6218\uff0c\u5e76\u51cf\u5c11\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u2014\u2014\u7fa4\u7ec4\u5bf9\u6bd4\u7b56\u7565\u4f18\u5316\uff08GCPO\uff09\uff0c\u5e76\u7ed3\u5408\u51e0\u4f55\u63a8\u7406\u6a21\u578bGeometryZero\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u8f85\u52a9\u6784\u5efa\u3002", "result": "GeometryZero\u6a21\u578b\u5728\u6d41\u884c\u7684\u51e0\u4f55\u57fa\u51c6\u6d4b\u8bd5\uff08Geometry3K\uff0cMathVista\uff09\u4e2d\u8f83\u5176\u4ed6\u65b9\u6cd5\u6709\u5e73\u57474.29%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5229\u7528GCPO\u6846\u67b6\u53ef\u4ee5\u5728\u8f83\u5c0f\u6a21\u578b\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u51e0\u4f55\u63a8\u7406\u548c\u8f85\u52a9\u6784\u5efa\uff0c\u5e76\u8d85\u8d8a\u5f53\u524d\u57fa\u51c6\u6027\u80fd\u3002"}}
{"id": "2506.06895", "pdf": "https://arxiv.org/pdf/2506.06895", "abs": "https://arxiv.org/abs/2506.06895", "authors": ["Jihao Andreas Lin", "Sebastian Ament", "Maximilian Balandat", "David Eriksson", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato", "Eytan Bakshy"], "title": "Scalable Gaussian Processes with Latent Kronecker Structure", "categories": ["cs.LG", "stat.ML"], "comment": "International Conference on Machine Learning 2025", "summary": "Applying Gaussian processes (GPs) to very large datasets remains a challenge\ndue to limited computational scalability. Matrix structures, such as the\nKronecker product, can accelerate operations significantly, but their\napplication commonly entails approximations or unrealistic assumptions. In\nparticular, the most common path to creating a Kronecker-structured kernel\nmatrix is by evaluating a product kernel on gridded inputs that can be\nexpressed as a Cartesian product. However, this structure is lost if any\nobservation is missing, breaking the Cartesian product structure, which\nfrequently occurs in real-world data such as time series. To address this\nlimitation, we propose leveraging latent Kronecker structure, by expressing the\nkernel matrix of observed values as the projection of a latent Kronecker\nproduct. In combination with iterative linear system solvers and pathwise\nconditioning, our method facilitates inference of exact GPs while requiring\nsubstantially fewer computational resources than standard iterative methods. We\ndemonstrate that our method outperforms state-of-the-art sparse and variational\nGPs on real-world datasets with up to five million examples, including\nrobotics, automated machine learning, and climate applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6f5c\u5728Kronecker\u7ed3\u6784\u6539\u8fdb\u5927\u6570\u636e\u96c6\u4e0a\u7684\u9ad8\u65af\u8fc7\u7a0b\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u6027\u80fd\u8d85\u8fc7\u6700\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5728\u5904\u7406\u975e\u5e38\u5927\u7684\u6570\u636e\u96c6\u65f6\uff0c\u9ad8\u65af\u8fc7\u7a0b\u9762\u4e34\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u7684\u95ee\u9898\u3002\u867d\u7136\u77e9\u9635\u7ed3\u6784\uff0c\u5982Kronecker\u4e58\u79ef\uff0c\u53ef\u4ee5\u663e\u8457\u52a0\u901f\u8ba1\u7b97\uff0c\u4f46\u5176\u5e94\u7528\u901a\u5e38\u9700\u8981\u8fd1\u4f3c\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u5047\u8bbe\u3002\u5c24\u5176\u662f\u5728\u5b9e\u9645\u6570\u636e\u4e2d\u5e38\u51fa\u73b0\u7684\u7f3a\u5931\u89c2\u5bdf\u4f1a\u7834\u574f\u7b1b\u5361\u5c14\u4e58\u79ef\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6f5c\u5728Kronecker\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u89c2\u6d4b\u503c\u7684\u6838\u77e9\u9635\u8868\u8fbe\u4e3a\u6f5c\u5728Kronecker\u4e58\u79ef\u7684\u6295\u5f71\u3002\u7ed3\u5408\u8fed\u4ee3\u7ebf\u6027\u7cfb\u7edf\u6c42\u89e3\u5668\u548c\u8def\u5f84\u6761\u4ef6\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u6d88\u8017\u8f83\u5c11\u8ba1\u7b97\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u7cbe\u786e\u9ad8\u65af\u8fc7\u7a0b\u63a8\u65ad\u3002", "result": "\u5728\u591a\u8fbe\u4e94\u767e\u4e07\u4e2a\u4f8b\u5b50\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e2d\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u673a\u5668\u4eba\u5b66\u3001\u81ea\u52a8\u5316\u673a\u5668\u5b66\u4e60\u548c\u6c14\u5019\u5e94\u7528\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u6700\u65b0\u7684\u7a00\u758f\u548c\u53d8\u5206\u9ad8\u65af\u8fc7\u7a0b\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u6f5c\u5728Kronecker\u7ed3\u6784\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u66f4\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u7cbe\u786e\u9ad8\u65af\u8fc7\u7a0b\u63a8\u65ad\uff0c\u5e76\u5728\u591a\u79cd\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2506.07915", "pdf": "https://arxiv.org/pdf/2506.07915", "abs": "https://arxiv.org/abs/2506.07915", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "title": "LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement", "categories": ["cs.AI", "cs.CL", "cs.SY", "eess.SY"], "comment": "12 pages, 4 Figures, 3 Tables, submitted to the IEEE for possible\n  publication", "summary": "In dynamic environments, the rapid obsolescence of pre-existing environmental\nknowledge creates a gap between an agent's internal model and the evolving\nreality of its operational context. This disparity between prior and updated\nenvironmental valuations fundamentally limits the effectiveness of autonomous\ndecision-making. To bridge this gap, the contextual bias of human domain\nstakeholders, who naturally accumulate insights through direct, real-time\nobservation, becomes indispensable. However, translating their nuanced, and\ncontext-rich input into actionable intelligence for autonomous systems remains\nan open challenge. To address this, we propose LUCIFER (Language Understanding\nand Context-Infused Framework for Exploration and Behavior Refinement), a\ndomain-agnostic framework that integrates a hierarchical decision-making\narchitecture with reinforcement learning (RL) and large language models (LLMs)\ninto a unified system. This architecture mirrors how humans decompose complex\ntasks, enabling a high-level planner to coordinate specialised sub-agents, each\nfocused on distinct objectives and temporally interdependent actions. Unlike\ntraditional applications where LLMs are limited to single role, LUCIFER\nintegrates them in two synergistic roles: as context extractors, structuring\nverbal stakeholder input into domain-aware representations that influence\ndecision-making through an attention space mechanism aligning LLM-derived\ninsights with the agent's learning process, and as zero-shot exploration\nfacilitators guiding the agent's action selection process during exploration.\nWe benchmark various LLMs in both roles and demonstrate that LUCIFER improves\nexploration efficiency and decision quality, outperforming flat,\ngoal-conditioned policies. Our findings show the potential of context-driven\ndecision-making, where autonomous systems leverage human contextual knowledge\nfor operational success.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728\u5feb\u901f\u53d8\u5316\u73af\u5883\u4e2d\u63d0\u9ad8\u81ea\u6cbb\u7cfb\u7edf\u51b3\u7b56\u6548\u679c\u7684LUCIFER\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u5c42\u6b21\u51b3\u7b56\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5728\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u81ea\u6cbb\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5185\u5728\u6a21\u578b\u4e0e\u64cd\u4f5c\u73af\u5883\u5feb\u901f\u53d8\u5316\u4e4b\u95f4\u7684\u9e3f\u6c9f\u95ee\u9898\uff0c\u76ee\u6807\u662f\u63d0\u5347\u51b3\u7b56\u6548\u80fd\u3002", "method": "\u63d0\u51faLUCIFER\u6846\u67b6\uff0c\u5c06\u5206\u5c42\u51b3\u7b56\u67b6\u6784\u4e0e\u5f3a\u5316\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u548c\u96f6\u6837\u672c\u63a2\u7d22\u6307\u5bfc\u884c\u52a8\u9009\u62e9\u8fc7\u7a0b\u3002", "result": "LUCIFER\u6846\u67b6\u5728\u5404\u79cd\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u63d0\u9ad8\u4e86\u63a2\u7d22\u6548\u7387\u548c\u51b3\u7b56\u8d28\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u3002", "conclusion": "LUCIFER\u6846\u67b6\u5229\u7528\u4eba\u7c7b\u7684\u4e0a\u4e0b\u6587\u77e5\u8bc6\u63d0\u9ad8\u81ea\u6cbb\u7cfb\u7edf\u7684\u51b3\u7b56\u8d28\u91cf\u548c\u63a2\u7d22\u6548\u7387\u3002"}}
{"id": "2506.07169", "pdf": "https://arxiv.org/pdf/2506.07169", "abs": "https://arxiv.org/abs/2506.07169", "authors": ["Washington Cunha", "Leonardo Rocha", "Marcos Andr\u00e9 Gon\u00e7alves"], "title": "CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Disserta\u00e7\u00f5es e Trabalhos de Gradua\u00e7\u00e3o em SI -- XXI Simp\u00f3sio Brasileiro de Sistemas de Informa\u00e7\u00e3o", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 5 figures, 2 tables", "summary": "Progress in Natural Language Processing (NLP) has been dictated by the rule\nof more: more data, more computing power and more complexity, best exemplified\nby the Large Language Models. However, training (or fine-tuning) large dense\nmodels for specific applications usually requires significant amounts of\ncomputing resources. This \\textbf{Ph.D. dissertation} focuses on an\nunder-investi\\-gated NLP data engineering technique, whose potential is\nenormous in the current scenario known as Instance Selection (IS). The IS goal\nis to reduce the training set size by removing noisy or redundant instances\nwhile maintaining the effectiveness of the trained models and reducing the\ntraining process cost. We provide a comprehensive and scientifically sound\ncomparison of IS methods applied to an essential NLP task -- Automatic Text\nClassification (ATC), considering several classification solutions and many\ndatasets. Our findings reveal a significant untapped potential for IS\nsolutions. We also propose two novel IS solutions that are noise-oriented and\nredundancy-aware, specifically designed for large datasets and transformer\narchitectures. Our final solution achieved an average reduction of 41\\% in\ntraining sets, while maintaining the same levels of effectiveness in all\ndatasets. Importantly, our solutions demonstrated speedup improvements of 1.67x\n(up to 2.46x), making them scalable for datasets with hundreds of thousands of\ndocuments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5b9e\u4f8b\u9009\u62e9\u6280\u672f\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u6210\u529f\u51cf\u5c11\u4e86\u8bad\u7ec3\u96c6\u89c4\u6a21\u548c\u63d0\u5347\u4e86\u8bad\u7ec3\u901f\u5ea6\u3002", "motivation": "\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u7684\u5927\u578b\u6a21\u578b\u8bad\u7ec3\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u672c\u8bba\u6587\u65e8\u5728\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5b9e\u4f8b\u9009\u62e9\u6280\u672f\u51cf\u5c11\u6570\u636e\u89c4\u6a21\u4ee5\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u5bf9\u591a\u79cd\u5b9e\u4f8b\u9009\u62e9\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u800c\u79d1\u5b66\u7684\u6bd4\u8f83\uff0c\u5c24\u5176\u662f\u5e94\u7528\u4e8e\u81ea\u52a8\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u9762\u5411\u566a\u58f0\u548c\u91cd\u590d\u6570\u636e\u7684\u5b9e\u4f8b\u9009\u62e9\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u4f8b\u96c6\u51cf\u5c11\u4e8641%\uff0c\u540c\u65f6\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u76f8\u540c\u7684\u6709\u6548\u6027\uff0c\u901f\u5ea6\u63d0\u5347\u8fbe1.67\u500d\u81f32.46\u500d\uff0c\u80fd\u591f\u9002\u7528\u4e8e\u5305\u542b\u6570\u5341\u4e07\u4e2a\u6587\u6863\u7684\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u9896\u7684\u5b9e\u4f8b\u9009\u62e9\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4fdd\u6301\u6a21\u578b\u6709\u6548\u6027\u7684\u540c\u65f6\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u96c6\u7684\u89c4\u6a21\u548c\u51cf\u5c11\u8bad\u7ec3\u8fc7\u7a0b\u7684\u6210\u672c\u3002"}}
{"id": "2506.06907", "pdf": "https://arxiv.org/pdf/2506.06907", "abs": "https://arxiv.org/abs/2506.06907", "authors": ["Fred Xu", "Thomas Markovich"], "title": "Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph Neural Networks have achieved impressive results across diverse network\nmodeling tasks, but accurately estimating uncertainty on graphs remains\ndifficult, especially under distributional shifts. Unlike traditional\nuncertainty estimation, graph-based uncertainty must account for randomness\narising from both the graph's structure and its label distribution, which adds\ncomplexity. In this paper, making an analogy between the evolution of a\nstochastic partial differential equation (SPDE) driven by Matern Gaussian\nProcess and message passing using GNN layers, we present a principled way to\ndesign a novel message passing scheme that incorporates spatial-temporal noises\nmotivated by the Gaussian Process approach to SPDE. Our method simultaneously\ncaptures uncertainty across space and time and allows explicit control over the\ncovariance kernel smoothness, thereby enhancing uncertainty estimates on graphs\nwith both low and high label informativeness. Our extensive experiments on\nOut-of-Distribution (OOD) detection on graph datasets with varying label\ninformativeness demonstrate the soundness and superiority of our model to\nexisting approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684SPDE\u65b9\u6cd5\u7528\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u6539\u5584\u4e86\u5728\u4e0d\u540c\u6807\u7b7e\u4fe1\u606f\u91cf\u4e0b\u7684\u5206\u5e03\u5916\u68c0\u6d4b\u3002", "motivation": "\u5728\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u51c6\u786e\u4f30\u8ba1\u56fe\u4e0a\u7684\u4e0d\u786e\u5b9a\u6027\u5341\u5206\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u3002\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u9700\u540c\u65f6\u8003\u8651\u56fe\u7ed3\u6784\u548c\u6807\u7b7e\u5206\u5e03\u5e26\u6765\u7684\u968f\u673a\u6027\uff0c\u8fd9\u589e\u52a0\u4e86\u590d\u6742\u6027\u3002", "method": "\u901a\u8fc7\u7c7b\u6bd4\u9a6c\u7279\u6069\u9ad8\u65af\u8fc7\u7a0b\u9a71\u52a8\u7684\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\uff08SPDE\uff09\u6f14\u5316\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5c42\u7684\u6d88\u606f\u4f20\u9012\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u5bf9SPDE\u7684\u7a7a\u95f4-\u65f6\u95f4\u566a\u58f0\u5904\u7406\u65b9\u6cd5\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u5728\u5177\u6709\u4e0d\u540c\u6807\u7b7e\u4fe1\u606f\u91cf\u7684\u56fe\u6570\u636e\u96c6\u4e0a\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u68c0\u6d4b\u4e2d\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u5408\u7406\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u540c\u65f6\u6355\u6349\u4e86\u7a7a\u95f4\u548c\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5141\u8bb8\u5bf9\u534f\u65b9\u5dee\u5185\u6838\u5e73\u6ed1\u5ea6\u7684\u660e\u786e\u63a7\u5236\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u5728\u4f4e\u548c\u9ad8\u6807\u7b7e\u4fe1\u606f\u91cf\u7684\u56fe\u4e0a\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002"}}
{"id": "2506.07927", "pdf": "https://arxiv.org/pdf/2506.07927", "abs": "https://arxiv.org/abs/2506.07927", "authors": ["Jiayi Sheng", "Luna Lyu", "Jikai Jin", "Tony Xia", "Alex Gu", "James Zou", "Pan Lu"], "title": "Solving Inequality Proofs with Large Language Models", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "52 pages, 16 figures", "summary": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulation, recasting inequality proving into two\nautomatically checkable subtasks: bound estimation and relation prediction.\nBuilding on this, we release IneqMath, an expert-curated dataset of\nOlympiad-level inequalities, including a test set and training corpus enriched\nwith step-wise solutions and theorem annotations. We also develop a novel\nLLM-as-judge evaluation framework, combining a final-answer judge with four\nstep-wise judges designed to detect common reasoning flaws. A systematic\nevaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even\ntop models like o1 achieve less than 10% overall accuracy under step-wise\nscrutiny; this is a drop of up to 65.5% from their accuracy considering only\nfinal answer equivalence. This discrepancy exposes fragile deductive chains and\na critical gap for current LLMs between merely finding an answer and\nconstructing a rigorous proof. Scaling model size and increasing test-time\ncomputation yield limited gains in overall proof correctness. Instead, our\nfindings highlight promising research directions such as theorem-guided\nreasoning and self-refinement. Code and data are available at\nhttps://ineqmath.github.io/.", "AI": {"tldr": "\u9488\u5bf9\u4e0d\u7b49\u5f0f\u8bc1\u660e\uff0c\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5\u548c\u6570\u636e\u96c6\uff0c\u4f46\u9876\u7ea7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u63a8\u7406\u94fe\u8584\u5f31\uff0c\u4ec5\u5728\u6700\u7ec8\u7b54\u6848\u4e0a\u8868\u73b0\u8f83\u597d\u3002", "motivation": "\u76ee\u524d\u7684\u4efb\u52a1\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u5408\u6210\u6216\u8fc7\u4e8e\u6b63\u5f0f\uff0c\u96be\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u771f\u6b63\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u975e\u6b63\u5f0f\u4f46\u53ef\u9a8c\u8bc1\u7684\u4efb\u52a1\uff0c\u5c06\u4e0d\u7b49\u5f0f\u8bc1\u660e\u4efb\u52a1\u91cd\u65b0\u8868\u8ff0\u4e3a\u754c\u9650\u4f30\u8ba1\u548c\u5173\u7cfb\u9884\u6d4b\u4e24\u90e8\u5206\u3002", "result": "29\u4e2a\u9886\u5148\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4fbf\u662f\u9876\u7ea7\u6a21\u578b\u5728\u9010\u6b65\u5ba1\u67e5\u4e0b\u51c6\u786e\u7387\u4e0d\u523010%\u3002", "conclusion": "\u5373\u4fbf\u662f\u6700\u9876\u5c16\u7684\u6a21\u578b\uff0c\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u7b49\u5f0f\u8bc1\u660e\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u6574\u4f53\u6b65\u9aa4\u51c6\u786e\u7387\u4e0d\u8db310%\u3002"}}
{"id": "2506.07171", "pdf": "https://arxiv.org/pdf/2506.07171", "abs": "https://arxiv.org/abs/2506.07171", "authors": ["Chenlong Zhang", "Zhuoran Jin", "Hongbang Yuan", "Jiaheng Wei", "Tong Zhou", "Kang Liu", "Jun Zhao", "Yubo Chen"], "title": "RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality", "categories": ["cs.CL", "cs.LG"], "comment": "Paper under review", "summary": "The widespread deployment of Large Language Models (LLMs) trained on massive,\nuncurated corpora has raised growing concerns about the inclusion of sensitive,\ncopyrighted, or illegal content. This has led to increasing interest in LLM\nunlearning: the task of selectively removing specific information from a model\nwithout retraining from scratch or degrading overall utility. However, existing\nmethods often rely on large-scale forget and retain datasets, and suffer from\nunnatural responses, poor generalization, or catastrophic utility loss. In this\nwork, we propose Reinforcement UnLearning (RULE), an efficient framework that\nformulates unlearning as a refusal boundary optimization problem. RULE is\ntrained with a small portion of the forget set and synthesized boundary\nqueries, using a verifiable reward function that encourages safe refusal on\nforget--related queries while preserving helpful responses on permissible\ninputs. We provide both theoretical and empirical evidence demonstrating the\neffectiveness of RULE in achieving targeted unlearning without compromising\nmodel utility. Experimental results show that, with only $12%$ forget set and\n$8%$ synthesized boundary data, RULE outperforms existing baselines by up to\n$17.5%$ forget quality and $16.3%$ naturalness response while maintaining\ngeneral utility, achieving forget--retain Pareto optimality. Remarkably, we\nfurther observe that RULE improves the naturalness of model outputs, enhances\ntraining efficiency, and exhibits strong generalization ability, generalizing\nrefusal behavior to semantically related but unseen queries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89c4\u5219\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u62d2\u7edd\u8fb9\u754c\u6765\u9009\u62e9\u6027\u79fb\u9664\u6a21\u578b\u4e2d\u7684\u7279\u5b9a\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u6548\u7528\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8d85\u8d8a\u73b0\u6709\u9057\u5fd8\u8d28\u91cf\u548c\u54cd\u5e94\u81ea\u7136\u6027\u57fa\u7ebf\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u672a\u7ecf\u7b5b\u9009\u7684\u6587\u6863\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5305\u542b\u654f\u611f\u3001\u53d7\u7248\u6743\u4fdd\u62a4\u6216\u975e\u6cd5\u5185\u5bb9\uff0c\u5f15\u53d1\u4e86\u5bf9LLM\u9057\u5fd8\u4efb\u52a1\u7684\u5173\u6ce8\uff0c\u5e0c\u671b\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6216\u964d\u4f4e\u6548\u7528\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u6027\u5730\u4ece\u6a21\u578b\u4e2d\u79fb\u9664\u7279\u5b9a\u4fe1\u606f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86RULE\uff08Reinforcement UnLearning\uff09\u6846\u67b6\uff0c\u5c06\u9057\u5fd8\u4efb\u52a1\u89c6\u4e3a\u62d2\u7edd\u8fb9\u754c\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u4f7f\u7528\u9057\u5fd8\u96c6\u7684\u4e00\u5c0f\u90e8\u5206\u548c\u5408\u6210\u8fb9\u754c\u67e5\u8be2\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u91c7\u7528\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u51fd\u6570\u6765\u9f13\u52b1\u5728\u76f8\u5173\u67e5\u8be2\u4e0a\u5b89\u5168\u62d2\u7edd\uff0c\u540c\u65f6\u4fdd\u7559\u5bf9\u5141\u8bb8\u8f93\u5165\u7684\u6709\u5e2e\u52a9\u54cd\u5e94\u3002", "result": "RULE\u5728\u5b9e\u73b0\u76ee\u6807\u9057\u5fd8\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6548\u7528\uff0c\u5e76\u63d0\u9ad8\u4e86\u6a21\u578b\u8f93\u51fa\u7684\u81ea\u7136\u6027\u3001\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5c06\u62d2\u7edd\u884c\u4e3a\u63a8\u5e7f\u5230\u8bed\u4e49\u76f8\u5173\u4f46\u672a\u89c1\u8fc7\u7684\u67e5\u8be2\u3002", "conclusion": "RULE\u80fd\u5728\u6a21\u578b\u6548\u7528\u4e0d\u53d7\u635f\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u76ee\u6807\u5316\u7684\u9057\u5fd8\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u53ea\u670912%\u7684\u9057\u5fd8\u6570\u636e\u96c6\u548c8%\u7684\u5408\u6210\u8fb9\u754c\u6570\u636e\uff0cRULE\u5728\u9057\u5fd8\u8d28\u91cf\u548c\u54cd\u5e94\u81ea\u7136\u6027\u65b9\u9762\u6bd4\u73b0\u6709\u57fa\u7ebf\u9ad8\u8fbe17.5%\u548c16.3%\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u6548\u7528\uff0c\u5b9e\u73b0\u9057\u5fd8-\u4fdd\u7559\u6700\u4f73\u89e3\u3002"}}
{"id": "2506.06917", "pdf": "https://arxiv.org/pdf/2506.06917", "abs": "https://arxiv.org/abs/2506.06917", "authors": ["Shangjie Du", "Hui Wei", "Dong Yoon Lee", "Zhizhang Hu", "Shijia Pan"], "title": "Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ACM Transactions on Sensor Networks (TOSN) 2025", "summary": "This work introduces GraPhy, a graph-based, physics-guided learning framework\nfor high-resolution and accurate air quality modeling in urban areas with\nlimited monitoring data. Fine-grained air quality monitoring information is\nessential for reducing public exposure to pollutants. However, monitoring\nnetworks are often sparse in socioeconomically disadvantaged regions, limiting\nthe accuracy and resolution of air quality modeling. To address this, we\npropose a physics-guided graph neural network architecture called GraPhy with\nlayers and edge features designed specifically for low-resolution monitoring\ndata. Experiments using data from California's socioeconomically disadvantaged\nSan Joaquin Valley show that GraPhy achieves the overall best performance\nevaluated by mean squared error (MSE), mean absolute error (MAE), and R-square\nvalue (R2), improving the performance by 9%-56% compared to various baseline\nmodels. Moreover, GraPhy consistently outperforms baselines across different\nspatial heterogeneity levels, demonstrating the effectiveness of our model\ndesign.", "AI": {"tldr": "GraPhy\u901a\u8fc7\u7269\u7406\u5f15\u5bfc\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u63d0\u9ad8\u4e86\u8d2b\u56f0\u5730\u533a\u7a7a\u6c14\u8d28\u91cf\u5efa\u6a21\u7684\u7cbe\u5ea6\u548c\u5206\u8fa8\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u7f51\u7edc\u5728\u793e\u4f1a\u7ecf\u6d4e\u4e0d\u53d1\u8fbe\u5730\u533a\u5f80\u5f80\u6bd4\u8f83\u7a00\u758f\uff0c\u5bfc\u81f4\u7a7a\u6c14\u8d28\u91cf\u5efa\u6a21\u7684\u7cbe\u5ea6\u548c\u5206\u8fa8\u7387\u53d7\u5230\u9650\u5236\u3002\u4e3a\u4e86\u51cf\u5c11\u516c\u4f17\u5bf9\u6c61\u67d3\u7269\u7684\u66b4\u9732\uff0c\u8feb\u5207\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u7a7a\u6c14\u8d28\u91cf\u76d1\u6d4b\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGraPhy\u7684\u7269\u7406\u5f15\u5bfc\u56fe\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u4e13\u4e3a\u4f4e\u5206\u8fa8\u7387\u76d1\u6d4b\u6570\u636e\u8bbe\u8ba1\u7684\u5c42\u548c\u8fb9\u7f18\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5404\u79cd\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cGraPhy\u53ef\u4ee5\u5728\u5e73\u5747\u5e73\u65b9\u8bef\u5dee\uff08MSE\uff09\u3001\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u548cR\u5e73\u65b9\u503c\uff08R2\uff09\u65b9\u9762\u5c06\u6027\u80fd\u63d0\u9ad89%\u523056%\u3002\u6b64\u5916\uff0cGraPhy\u5728\u4e0d\u540c\u7684\u7a7a\u95f4\u5f02\u8d28\u6027\u6c34\u5e73\u4e0a\u4e5f\u4e00\u81f4\u8d85\u8fc7\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "GraPhy\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u3001\u7269\u7406\u5f15\u5bfc\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u76d1\u6d4b\u6570\u636e\u6709\u9650\u7684\u57ce\u5e02\u533a\u57df\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u548c\u51c6\u786e\u7684\u7a7a\u6c14\u8d28\u91cf\u5efa\u6a21\uff0c\u5c24\u5176\u5728\u793e\u4f1a\u7ecf\u6d4e\u4e0d\u53d1\u8fbe\u5730\u533a\u4f18\u52bf\u660e\u663e\u3002"}}
{"id": "2506.07940", "pdf": "https://arxiv.org/pdf/2506.07940", "abs": "https://arxiv.org/abs/2506.07940", "authors": ["Christopher Subia-Waud"], "title": "Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Foundation model fine-tuning faces a fundamental challenge: existing AutoML\nplatforms rely on single optimisation strategies that explore only a fraction\nof viable hyperparameter configurations. In this white paper, We introduce\nGradients, a decentralised AutoML platform that transforms hyperparameter\noptimisation into a competitive marketplace where independent miners compete to\ndiscover optimal configurations. Economic incentives align individual\nexploration with collective optimisation goals, driving systematic\ninvestigation of hyperparameter regions that centralised methods miss. We\nevaluate our approach across 180 controlled experiments spanning diverse model\narchitectures (70M to 70B parameters) and task types. Gradients achieves an\n82.8\\% win rate against HuggingFace AutoTrain and 100\\% against TogetherAI,\nDatabricks, and Google Cloud, with mean improvements of 11.8\\% and 42.1\\%\nrespectively. Complex reasoning and retrieval tasks show particularly strong\ngains of 30-40\\%, whilst diffusion models achieve 23.4\\% improvements for\nperson-specific generation. These results demonstrate that competitive,\neconomically-driven approaches can systematically discover superior\nconfigurations that centralised AutoML consistently miss.", "AI": {"tldr": "\u53bb\u4e2d\u5fc3\u5316\u5e73\u53f0Gradients\u901a\u8fc7\u7ecf\u6d4e\u6fc0\u52b1\u4f7f\u8d85\u53c2\u6570\u4f18\u5316\u6210\u4e3a\u7ade\u4e89\u6027\u5e02\u573a\uff0c\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u4e2d\u592e\u5316\u65b9\u6cd5\u672a\u80fd\u53d1\u73b0\u7684\u914d\u7f6e\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u4e2a\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684AutoML\u5e73\u53f0\u4f9d\u8d56\u5355\u4e00\u4f18\u5316\u7b56\u7565\uff0c\u96be\u4ee5\u5168\u9762\u63a2\u7d22\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u5bfc\u81f4\u5fae\u8c03\u57fa\u7840\u6a21\u578b\u9762\u4e34\u6311\u6218\u3002", "method": "\u4f7f\u7528\u53bb\u4e2d\u5fc3\u5316\u7684\u5e73\u53f0Gradients\uff0c\u5c06\u8d85\u53c2\u6570\u4f18\u5316\u8f6c\u53d8\u4e3a\u4e00\u4e2a\u7ade\u4e89\u6027\u5e02\u573a\uff0c\u77ff\u5de5\u901a\u8fc7\u7ecf\u6d4e\u6fc0\u52b1\u4e89\u593a\u6700\u4f73\u914d\u7f6e\u3002", "result": "Gradients\u5728180\u6b21\u5b9e\u9a8c\u4e2d\u5bf9\u6bd4\u57fa\u51c6\u5e73\u53f0\u8868\u73b0\u51fa\u660e\u663e\u4f18\u52bf\uff0c\u5bf9HuggingFace AutoTrain\u53d6\u5f9782.8%\u7684\u80dc\u7387\uff0c\u5bf9TogetherAI\u3001Databricks\u548cGoogle Cloud\u53d6\u5f97100%\u7684\u80dc\u7387\uff0c\u5747\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u7ade\u4e89\u6027\u548c\u7ecf\u6d4e\u9a71\u52a8\u7684AutoML\u5e73\u53f0\u80fd\u591f\u7cfb\u7edf\u5730\u53d1\u73b0\u4e2d\u592e\u5316\u65b9\u6cd5\u672a\u80fd\u627e\u5230\u7684\u4f18\u5316\u914d\u7f6e\u3002"}}
{"id": "2506.07180", "pdf": "https://arxiv.org/pdf/2506.07180", "abs": "https://arxiv.org/abs/2506.07180", "authors": ["Wenrui Zhou", "Shu Yang", "Qingsong Yang", "Zikun Guo", "Lijie Hu", "Di Wang"], "title": "Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "24 pages", "summary": "As video large language models (Video-LLMs) become increasingly integrated\ninto real-world applications that demand grounded multimodal reasoning,\nensuring their factual consistency and reliability is of critical importance.\nHowever, sycophancy, the tendency of these models to align with user input even\nwhen it contradicts the visual evidence, undermines their trustworthiness in\nsuch contexts. Current sycophancy research has largely overlooked its specific\nmanifestations in the video-language domain, resulting in a notable absence of\nsystematic benchmarks and targeted evaluations to understand how Video-LLMs\nrespond under misleading user input. To fill this gap, we propose VISE\n(Video-LLM Sycophancy Benchmarking and Evaluation), the first dedicated\nbenchmark designed to evaluate sycophantic behavior in state-of-the-art\nVideo-LLMs across diverse question formats, prompt biases, and visual reasoning\ntasks. Specifically, VISE pioneeringly brings linguistic perspectives on\nsycophancy into the visual domain, enabling fine-grained analysis across\nmultiple sycophancy types and interaction patterns. In addition, we explore\nkey-frame selection as an interpretable, training-free mitigation strategy,\nwhich reveals potential paths for reducing sycophantic bias by strengthening\nvisual grounding.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165VISE\u57fa\u51c6\u4ee5\u8bc4\u4f30\u89c6\u9891LLM\u7684\u8fce\u5408\u884c\u4e3a\uff0c\u5e76\u63a2\u8ba8\u5173\u952e\u5e27\u9009\u62e9\u4f5c\u4e3a\u51cf\u8f7b\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08Video-LLMs\uff09\u5728\u9700\u8981\u57fa\u7840\u591a\u6a21\u6001\u63a8\u7406\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u65e5\u76ca\u96c6\u6210\uff0c\u786e\u4fdd\u5b83\u4eec\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u8fce\u5408\u6027\u95ee\u9898\uff0c\u5373\u8fd9\u4e9b\u6a21\u578b\u53ef\u80fd\u503e\u5411\u4e8e\u8fce\u5408\u7528\u6237\u8f93\u5165\uff0c\u5373\u4fbf\u8fd9\u4e0e\u89c6\u89c9\u8bc1\u636e\u76f8\u77db\u76fe\uff0c\u5f71\u54cd\u4e86\u5176\u5728\u8fd9\u4e9b\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002\u5f53\u524d\u7684\u7814\u7a76\u5927\u591a\u5ffd\u89c6\u4e86\u8fce\u5408\u6027\u5728\u89c6\u9891\u8bed\u8a00\u9886\u57df\u7684\u5177\u4f53\u8868\u73b0\uff0c\u56e0\u6b64\u7f3a\u4e4f\u7cfb\u7edf\u7684\u57fa\u51c6\u548c\u9488\u5bf9\u6027\u7684\u8bc4\u4f30\u6765\u7406\u89e3Video-LLMs\u5728\u8bef\u5bfc\u6027\u7528\u6237\u8f93\u5165\u4e0b\u7684\u53cd\u5e94\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86VISE\uff08Video-LLM Sycophancy Benchmarking and Evaluation\uff09\uff0c\u8fd9\u662f\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8fce\u5408\u884c\u4e3a\u7684\u57fa\u51c6\uff0c\u6db5\u76d6\u4e86\u4e0d\u540c\u7684\u95ee\u9898\u683c\u5f0f\u3001\u63d0\u793a\u504f\u89c1\u548c\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\u3002\u7279\u522b\u662f\uff0cVISE\u9996\u521b\u5730\u5c06\u8bed\u8a00\u5b66\u5bf9\u8fce\u5408\u6027\u7684\u89c6\u89d2\u5f15\u5165\u89c6\u89c9\u9886\u57df\uff0c\u652f\u6301\u5bf9\u591a\u79cd\u8fce\u5408\u7c7b\u578b\u548c\u4e92\u52a8\u6a21\u5f0f\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u5173\u952e\u5e27\u9009\u62e9\u4f5c\u4e3a\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u4ee5\u901a\u8fc7\u52a0\u5f3a\u89c6\u89c9\u57fa\u7840\u63ed\u793a\u51cf\u5c11\u8fce\u5408\u504f\u89c1\u7684\u6f5c\u5728\u8def\u5f84\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u9891-\u8bed\u8a00\u6a21\u578b\u8fce\u5408\u884c\u4e3a\u7684\u65b0\u57fa\u51c6\uff08VISE\uff09\uff0c\u5e76\u63a2\u8ba8\u4e86\u901a\u8fc7\u5173\u952e\u5e27\u9009\u62e9\u51cf\u8f7b\u8fce\u5408\u6027\u7684\u95ee\u9898\u3002", "conclusion": "VISE\u57fa\u51c6\u4e3a\u8bc4\u4f30\u548c\u7406\u89e3\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fce\u5408\u73b0\u8c61\u4e0b\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u65b9\u6cd5\u3002\u53e6\u5916\uff0c\u901a\u8fc7\u5173\u952e\u5e27\u9009\u62e9\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6f5c\u5728\u5730\u51cf\u5c11\u8fce\u5408\u6027\u504f\u89c1\u3002"}}
{"id": "2506.06926", "pdf": "https://arxiv.org/pdf/2506.06926", "abs": "https://arxiv.org/abs/2506.06926", "authors": ["Wei Min Loh", "Jiaqi Shang", "Pascal Poupart"], "title": "Basis Transformers for Multi-Task Tabular Regression", "categories": ["cs.LG"], "comment": null, "summary": "Dealing with tabular data is challenging due to partial information, noise,\nand heterogeneous structure. Existing techniques often struggle to\nsimultaneously address key aspects of tabular data such as textual information,\na variable number of columns, and unseen data without metadata besides column\nnames. We propose a novel architecture, \\textit{basis transformers},\nspecifically designed to tackle these challenges while respecting inherent\ninvariances in tabular data, including hierarchical structure and the\nrepresentation of numeric values. We evaluate our design on a multi-task\ntabular regression benchmark, achieving an improvement of 0.338 in the median\n$R^2$ score and the lowest standard deviation across 34 tasks from the\nOpenML-CTR23 benchmark. Furthermore, our model has five times fewer parameters\nthan the best-performing baseline and surpasses pretrained large language model\nbaselines -- even when initialized from randomized weights.", "AI": {"tldr": "\u5f15\u5165\u4e86\u65b0\u67b6\u6784basis transformers\uff0c\u4ee5\u89e3\u51b3\u8868\u683c\u6570\u636e\u5904\u7406\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u4f18\u5f02\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u5904\u7406\u8868\u683c\u6570\u636e\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8868\u683c\u6570\u636e\u901a\u5e38\u5b58\u5728\u4fe1\u606f\u4e0d\u5b8c\u6574\u3001\u566a\u58f0\u4ee5\u53ca\u5f02\u6784\u7ed3\u6784\u7b49\u95ee\u9898\u3002\u73b0\u6709\u6280\u672f\u5728\u5904\u7406\u6587\u672c\u4fe1\u606f\u3001\u53ef\u53d8\u6570\u91cf\u7684\u5217\u4ee5\u53ca\u7f3a\u4e4f\u5143\u6570\u636e\u7684\u672a\u89c1\u6570\u636e\u65f6\u5e38\u5e38\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\u2014\u2014basis transformers\uff0c\u65e8\u5728\u89e3\u51b3\u8868\u683c\u6570\u636e\u7684\u8fd9\u4e9b\u6311\u6218\uff0c\u540c\u65f6\u5c0a\u91cd\u8868\u683c\u6570\u636e\u56fa\u6709\u7684\u4e0d\u53d8\u6027\uff0c\u5305\u62ec\u5206\u5c42\u7ed3\u6784\u548c\u6570\u503c\u8868\u793a\u3002", "result": "\u5728\u591a\u4efb\u52a1\u8868\u683c\u56de\u5f52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc4\u4f30\u8bbe\u8ba1\uff0c\u53d6\u5f97\u4e86\u591a\u9879\u6539\u8fdb\uff0c\u5305\u62ec\u5728OpenML-CTR23\u57fa\u51c6\u6d4b\u8bd5\u768434\u4e2a\u4efb\u52a1\u4e2d\uff0c\u4e2d\u4f4d\u6570R^2\u5206\u6570\u63d0\u9ad8\u4e860.338\uff0c\u5e76\u4e14\u8868\u73b0\u51fa\u6700\u4f4e\u7684\u6807\u51c6\u5dee\u3002\u6b64\u5916\uff0c\u6a21\u578b\u53c2\u6570\u6570\u91cf\u6bd4\u6700\u4f73\u57fa\u7ebf\u5c11\u4e94\u500d\uff0c\u5e76\u8d85\u8d8a\u4e86\u9884\u8bad\u7ec3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\uff0c\u5373\u4fbf\u521d\u59cb\u5316\u4f7f\u7528\u968f\u673a\u6743\u91cd\u3002", "conclusion": "\u63d0\u51fa\u7684basis transformers\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u8868\u683c\u6570\u636e\u5904\u7406\u4e2d\u7684\u591a\u9879\u6311\u6218\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u51fa\u8272\u7684\u6027\u80fd\u548c\u6548\u7387\u4f18\u52bf\u3002"}}
{"id": "2506.07963", "pdf": "https://arxiv.org/pdf/2506.07963", "abs": "https://arxiv.org/abs/2506.07963", "authors": ["Jixiang Hong", "Yiran Zhang", "Guanzhong Wang", "Yi Liu", "Ji-Rong Wen", "Rui Yan"], "title": "Reinforcing Multimodal Understanding and Generation with Dual Self-rewards", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Building upon large language models (LLMs), recent large multimodal models\n(LMMs) unify cross-model understanding and generation into a single framework.\nHowever, LMMs still struggle to achieve accurate image-text alignment, prone to\ngenerating text responses contradicting the visual input or failing to follow\nthe text-to-image prompts. Current solutions require external supervision\n(e.g., human feedback or reward models) and only address unidirectional\ntasks-either understanding or generation. In this work, based on the\nobservation that understanding and generation are inverse dual tasks, we\nintroduce a self-supervised dual reward mechanism to reinforce the\nunderstanding and generation capabilities of LMMs. Specifically, we sample\nmultiple outputs for a given input in one task domain, then reverse the\ninput-output pairs to compute the dual likelihood of the model as self-rewards\nfor optimization. Extensive experimental results on visual understanding and\ngeneration benchmarks demonstrate that our method can effectively enhance the\nperformance of the model without any external supervision, especially achieving\nremarkable improvements in text-to-image tasks.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u81ea\u76d1\u7763\u7684\u53cc\u91cd\u5956\u52b1\u673a\u5236\uff0c\u63d0\u9ad8\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\uff0c\u7279\u522b\u63d0\u5347\u4e86\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5728\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u901a\u5e38\u4f1a\u751f\u6210\u4e0e\u89c6\u89c9\u8f93\u5165\u76f8\u77db\u76fe\u7684\u6587\u672c\u54cd\u5e94\u6216\u672a\u80fd\u9075\u5faa\u6587\u672c\u5230\u56fe\u50cf\u7684\u63d0\u793a\u3002\u5f53\u524d\u7684\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5916\u90e8\u76d1\u7763\uff0c\u5e76\u4e14\u4ec5\u89e3\u51b3\u5355\u5411\u4efb\u52a1\uff08\u7406\u89e3\u6216\u751f\u6210\uff09\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u7684\u53cc\u91cd\u5956\u52b1\u673a\u5236\uff0c\u901a\u8fc7\u5728\u4e00\u4e2a\u4efb\u52a1\u57df\u4e2d\u91c7\u6837\u591a\u4e2a\u8f93\u51fa\uff0c\u7136\u540e\u53cd\u5411\u8f93\u5165\u8f93\u51fa\u5bf9\u4ee5\u8ba1\u7b97\u6a21\u578b\u7684\u53cc\u91cd\u4f3c\u7136\u6027\u4f5c\u4e3a\u81ea\u6211\u5956\u52b1\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u6a21\u578b\u7684\u89c6\u89c9\u7406\u89e3\u548c\u751f\u6210\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6587\u672c\u5230\u56fe\u50cf\u7684\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u76d1\u7763\u5373\u53ef\u589e\u5f3a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u6027\u80fd\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002"}}
{"id": "2506.07245", "pdf": "https://arxiv.org/pdf/2506.07245", "abs": "https://arxiv.org/abs/2506.07245", "authors": ["Wenxuan Xie", "Yaxun Dai", "Wenhao Jiang"], "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have significantly\nimproved performance on the Text-to-SQL task. However, prior approaches\ntypically rely on static, pre-processed database information provided at\ninference time, which limits the model's ability to fully understand the\ndatabase contents. Without dynamic interaction, LLMs are constrained to fixed,\nhuman-provided context and cannot autonomously explore the underlying data. To\naddress this limitation, we propose SDE-SQL, a framework that enables large\nlanguage models to perform self-driven exploration of databases during\ninference. This is accomplished by generating and executing SQL probes, which\nallow the model to actively retrieve information from the database and\niteratively update its understanding of the data. Unlike prior methods, SDE-SQL\noperates in a zero-shot setting, without relying on any question-SQL pairs as\nin-context demonstrations. When evaluated on the BIRD benchmark with\nQwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in\nexecution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing\na new state-of-the-art among methods based on open-source models without\nsupervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the\nperformance of SDE-SQL can be further enhanced, yielding an additional 0.52%\nimprovement.", "AI": {"tldr": "SDE-SQL\u5141\u8bb8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u81ea\u6211\u63a2\u7d22\u6570\u636e\u5e93\uff0c\u5728BIRD\u57fa\u51c6\u4e0a\u63d0\u5347\u4e86\u6267\u884c\u7cbe\u5ea6\uff0c\u5e76\u6210\u4e3a\u65e0\u76d1\u7763\u5fae\u8c03\u60c5\u51b5\u4e0b\u5f00\u6e90\u6a21\u578b\u7684\u65b0\u6807\u6746\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u7684\u9884\u5904\u7406\u6570\u636e\u5e93\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7406\u89e3\u6570\u636e\u5e93\u5185\u5bb9\u7684\u80fd\u529b\uff0c\u65e0\u6cd5\u8fdb\u884c\u52a8\u6001\u4ea4\u4e92\u548c\u81ea\u4e3b\u63a2\u7d22\u6570\u636e\u3002", "method": "\u63d0\u51faSDE-SQL\u6846\u67b6\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u81ea\u6211\u63a2\u7d22\u6570\u636e\u5e93\u3002\u901a\u8fc7\u751f\u6210\u548c\u6267\u884cSQL\u63a2\u6d4b\uff0c\u4e3b\u52a8\u4ece\u6570\u636e\u5e93\u4e2d\u68c0\u7d22\u4fe1\u606f\uff0c\u4e0d\u65ad\u66f4\u65b0\u5bf9\u6570\u636e\u7684\u7406\u89e3\u3002", "result": "\u5728BIRD\u57fa\u51c6\u4e0a\u7684\u6267\u884c\u7cbe\u5ea6\u76f8\u8f83\u4e8e\u57fa\u7840\u6a21\u578b\u63d0\u9ad88.02%\uff0c\u5728\u76d1\u7763\u5fae\u8c03\u4e0b\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad80.52%\u3002", "conclusion": "SDE-SQL\u5b9e\u73b0\u4e86\u5728\u4e0d\u9700\u8981\u76d1\u7763\u5fae\u8c03\u6216\u6a21\u578b\u96c6\u6210\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5f00\u653e\u6e90\u4ee3\u7801\u6a21\u578b\u5b9e\u73b0\u65b0\u7684\u6280\u672f\u6c34\u5e73\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2506.06933", "pdf": "https://arxiv.org/pdf/2506.06933", "abs": "https://arxiv.org/abs/2506.06933", "authors": ["Mahdi Salmani", "Alireza Abdollahpoorrostam", "Seyed-Mohsen Moosavi-Dezfooli"], "title": "Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "comment": null, "summary": "Traditional decision-based black-box adversarial attacks on image classifiers\naim to generate adversarial examples by slightly modifying input images while\nkeeping the number of queries low, where each query involves sending an input\nto the model and observing its output. Most existing methods assume that all\nqueries have equal cost. However, in practice, queries may incur asymmetric\ncosts; for example, in content moderation systems, certain output classes may\ntrigger additional review, enforcement, or penalties, making them more costly\nthan others. While prior work has considered such asymmetric cost settings,\neffective algorithms for this scenario remain underdeveloped. In this paper, we\npropose a general framework for decision-based attacks under asymmetric query\ncosts, which we refer to as asymmetric black-box attacks. We modify two core\ncomponents of existing attacks: the search strategy and the gradient estimation\nprocess. Specifically, we propose Asymmetric Search (AS), a more conservative\nvariant of binary search that reduces reliance on high-cost queries, and\nAsymmetric Gradient Estimation (AGREST), which shifts the sampling distribution\nto favor low-cost queries. We design efficient algorithms that minimize total\nattack cost by balancing different query types, in contrast to earlier methods\nsuch as stealthy attacks that focus only on limiting expensive (high-cost)\nqueries. Our method can be integrated into a range of existing black-box\nattacks with minimal changes. We perform both theoretical analysis and\nempirical evaluation on standard image classification benchmarks. Across\nvarious cost regimes, our method consistently achieves lower total query cost\nand smaller perturbations than existing approaches, with improvements of up to\n40% in some settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u9488\u5bf9\u4e0d\u5bf9\u79f0\u67e5\u8be2\u6210\u672c\u7684\u51b3\u7b56\u578b\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u641c\u7d22\u7b56\u7565\u53ca\u68af\u5ea6\u4f30\u8ba1\uff0c\u80fd\u6709\u6548\u964d\u4f4e\u603b\u653b\u51fb\u6210\u672c\uff0c\u5e76\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u672a\u8003\u8651\u67e5\u8be2\u6210\u672c\u4e0d\u5bf9\u79f0\u6027\uff0c\u5c24\u5176\u662f\u5728\u5185\u5bb9\u5ba1\u6838\u7cfb\u7edf\u4e2d\uff0c\u67d0\u4e9b\u8f93\u51fa\u7ed3\u679c\u53ef\u80fd\u89e6\u53d1\u989d\u5916\u5904\u7406\uff0c\u5bfc\u81f4\u6210\u672c\u66f4\u9ad8\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u5173\u952e\u6539\u8fdb\uff1a\u4e0d\u5bf9\u79f0\u641c\u7d22(AS)\u548c\u4e0d\u5bf9\u79f0\u68af\u5ea6\u4f30\u8ba1(AGREST)\uff0c\u901a\u8fc7\u8c03\u6574\u641c\u7d22\u7b56\u7565\u548c\u91c7\u6837\u5206\u5e03\u6765\u964d\u4f4e\u67e5\u8be2\u6210\u672c\u3002", "result": "\u5728\u591a\u79cd\u6210\u672c\u8bbe\u7f6e\u4e0b\uff0c\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f4e\u7684\u603b\u67e5\u8be2\u6210\u672c\u548c\u66f4\u5c0f\u7684\u6270\u52a8\uff0c\u90e8\u5206\u8bbe\u7f6e\u4e0b\u6539\u8fdb\u53ef\u8fbe40%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u4e0d\u5bf9\u79f0\u67e5\u8be2\u6210\u672c\u573a\u666f\u7684\u901a\u7528\u6846\u67b6\uff1a\u4e0d\u5bf9\u79f0\u9ed1\u76d2\u653b\u51fb\uff0c\u53ef\u4ee5\u96c6\u6210\u5230\u73b0\u6709\u7684\u653b\u51fb\u4e2d\uff0c\u5e76\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u8fdb\u884c\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\u3002"}}
{"id": "2506.07982", "pdf": "https://arxiv.org/pdf/2506.07982", "abs": "https://arxiv.org/abs/2506.07982", "authors": ["Victor Barres", "Honghua Dong", "Soham Ray", "Xujie Si", "Karthik Narasimhan"], "title": "$\u03c4^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce $\\tau^2$-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both\nagent and user make use of tools to act in a shared, dynamic environment that\ntests both agent coordination and communication,\n  2) A compositional task generator that programmatically creates diverse,\nverifiable tasks from atomic components, ensuring domain coverage and\ncontrolled complexity,\n  3) A reliable user simulator tightly coupled with the environment, whose\nbehavior is constrained by tools and observable states, improving simulation\nfidelity,\n  4) Fine-grained analysis of agent performance through multiple ablations\nincluding separating errors arising from reasoning vs\ncommunication/coordination.\n  In particular, our experiments show significant performance drops when agents\nshift from no-user to dual-control, highlighting the challenges of guiding\nusers. Overall, $\\tau^2$-bench provides a controlled testbed for agents that\nmust both reason effectively and guide user actions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u5bf9\u8bddAI\u57fa\u51c6\uff0c$\tau^2$-bench\uff0c\u7528\u4e8e\u6d4b\u8bd5\u4ee3\u7406\u5728\u7528\u6237\u5171\u4eab\u73af\u5883\u4e2d\u7684\u534f\u4f5c\u548c\u901a\u4fe1\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u591a\u7528\u6237\u73af\u5883\u4e0b\u7684\u6311\u6218\u66f4\u5927\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u8bdd\u5f0fAI\u4ee3\u7406\u57fa\u51c6\u5927\u591a\u4e3a\u5355\u63a7\u5236\u73af\u5883\uff0c\u7528\u6237\u53ea\u662f\u88ab\u52a8\u7684\u4fe1\u606f\u63d0\u4f9b\u8005\u3002\u8fd9\u4e0e\u73b0\u5b9e\u4e16\u754c\u573a\u666f\uff08\u5982\u6280\u672f\u652f\u6301\uff09\u4e0d\u540c\uff0c\u7528\u6237\u9700\u8981\u4e3b\u52a8\u53c2\u4e0e\u4fee\u6539\u73af\u5883\u72b6\u6001\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "method": "1) \u521b\u9020\u4e86\u4e00\u4e2a\u65b0\u7684\u7535\u4fe1\u53cc\u63a7\u5236\u57df\uff0c\u901a\u8fc7Dec-POMDP\u6a21\u578b\u63cf\u8ff0\uff0c2) \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ec4\u6210\u5f0f\u4efb\u52a1\u751f\u6210\u5668\uff0c\u6765\u521b\u5efa\u591a\u6837\u5316\u4e14\u53ef\u9a8c\u8bc1\u7684\u4efb\u52a1\uff0c3) \u7814\u53d1\u4e86\u4e00\u4e2a\u4e0e\u73af\u5883\u7d27\u5bc6\u8026\u5408\u7684\u7528\u6237\u6a21\u62df\u5668\uff0c4) \u63d0\u4f9b\u4e86\u591a\u79cd\u6d88\u878d\u5b9e\u9a8c\u8fdb\u884c\u4ee3\u7406\u6027\u80fd\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5f53\u4ee3\u7406\u4ece\u65e0\u7528\u6237\u5230\u53cc\u63a7\u5236\u73af\u5883\u65f6\uff0c\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8bf4\u660e\u5728\u6307\u5bfc\u7528\u6237\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\uff0c$\tau^2$-bench\uff0c\u7528\u4e8e\u6d4b\u8bd5\u4ee3\u7406\u5728\u4e0e\u7528\u6237\u5171\u4eab\u63a7\u5236\u7684\u52a8\u6001\u73af\u5883\u4e2d\u8fdb\u884c\u534f\u8c03\u548c\u6c9f\u901a\u7684\u80fd\u529b\u3002"}}
{"id": "2506.07248", "pdf": "https://arxiv.org/pdf/2506.07248", "abs": "https://arxiv.org/abs/2506.07248", "authors": ["Prathamesh Kokate", "Mitali Sarnaik", "Manavi Khopade", "Raviraj Joshi"], "title": "Improving the Efficiency of Long Document Classification using Sentence Ranking Approach", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Long document classification poses challenges due to the computational\nlimitations of transformer-based models, particularly BERT, which are\nconstrained by fixed input lengths and quadratic attention complexity.\nMoreover, using the full document for classification is often redundant, as\nonly a subset of sentences typically carries the necessary information. To\naddress this, we propose a TF-IDF-based sentence ranking method that improves\nefficiency by selecting the most informative content. Our approach explores\nfixed-count and percentage-based sentence selection, along with an enhanced\nscoring strategy combining normalized TF-IDF scores and sentence length.\nEvaluated on the MahaNews LDC dataset of long Marathi news articles, the method\nconsistently outperforms baselines such as first, last, and random sentence\nselection. With MahaBERT-v2, we achieve near-identical classification accuracy\nwith just a 0.33 percent drop compared to the full-context baseline, while\nreducing input size by over 50 percent and inference latency by 43 percent.\nThis demonstrates that significant context reduction is possible without\nsacrificing performance, making the method practical for real-world long\ndocument classification tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTF-IDF\u7684\u53e5\u5b50\u6392\u5e8f\u65b9\u6cd5\u7528\u4e8e\u957f\u6587\u6863\u5206\u7c7b\uff0c\u63d0\u9ad8\u6548\u7387\u5e76\u51cf\u5c11\u5197\u4f59\u4fe1\u606f\uff0c\u6027\u80fd\u4e0e\u5b8c\u6574\u4e0a\u4e0b\u6587\u57fa\u7ebf\u76f8\u8fd1\uff0c\u4f46\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u5165\u5927\u5c0f\u548c\u63a8\u7406\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u957f\u6587\u6863\u5206\u7c7b\u95ee\u9898\uff0c\u4f20\u7edftransformer\u6a21\u578b\u5982BERT\u53d7\u8f93\u5165\u957f\u5ea6\u548c\u6ce8\u610f\u529b\u590d\u6742\u6027\u9650\u5236\u3002\u4f7f\u7528\u6574\u4e2a\u6587\u6863\u8fdb\u884c\u5206\u7c7b\u901a\u5e38\u8fc7\u4e8e\u5197\u4f59\uff0c\u56e0\u4e3a\u53ea\u6709\u90e8\u5206\u53e5\u5b50\u5305\u542b\u5fc5\u8981\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTF-IDF\u7684\u53e5\u5b50\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u6709\u4fe1\u606f\u91cf\u7684\u5185\u5bb9\u63d0\u9ad8\u6548\u7387\u3002\u63a2\u7d22\u4e86\u56fa\u5b9a\u6570\u91cf\u548c\u767e\u5206\u6bd4\u7684\u53e5\u5b50\u9009\u62e9\u65b9\u5f0f\uff0c\u5e76\u7ed3\u5408\u6807\u51c6\u5316TF-IDF\u5206\u6570\u548c\u53e5\u5b50\u957f\u5ea6\u7684\u589e\u5f3a\u8bc4\u5206\u7b56\u7565\u3002", "result": "\u5728\u957f\u9a6c\u62c9\u5730\u8bed\u65b0\u95fb\u6587\u7ae0\u7684MahaNews LDC\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u6027\u80fd\u4f18\u4e8e\u7b2c\u4e00\u53e5\u3001\u6700\u540e\u4e00\u53e5\u548c\u968f\u673a\u9009\u62e9\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002\u4f7f\u7528MahaBERT-v2\u6a21\u578b\uff0c\u5728\u51cf\u5c1150%\u7684\u8f93\u5165\u5927\u5c0f\u548c43%\u7684\u63a8\u7406\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u4ec5\u4e0b\u964d\u4e860.33%\u3002", "conclusion": "\u957f\u6587\u6863\u5206\u7c7b\u4efb\u52a1\u53ef\u4ee5\u663e\u7740\u51cf\u5c11\u4e0a\u4e0b\u6587\u800c\u4e0d\u727a\u7272\u6027\u80fd\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2506.06940", "pdf": "https://arxiv.org/pdf/2506.06940", "abs": "https://arxiv.org/abs/2506.06940", "authors": ["Geonhui Yoo", "Minhak Song", "Chulhee Yun"], "title": "Understanding Sharpness Dynamics in NN Training with a Minimalist Example: The Effects of Dataset Difficulty, Depth, Stochasticity, and More", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "When training deep neural networks with gradient descent, sharpness often\nincreases -- a phenomenon known as progressive sharpening -- before saturating\nat the edge of stability. Although commonly observed in practice, the\nunderlying mechanisms behind progressive sharpening remain poorly understood.\nIn this work, we study this phenomenon using a minimalist model: a deep linear\nnetwork with a single neuron per layer. We show that this simple model\neffectively captures the sharpness dynamics observed in recent empirical\nstudies, offering a simple testbed to better understand neural network\ntraining. Moreover, we theoretically analyze how dataset properties, network\ndepth, stochasticity of optimizers, and step size affect the degree of\nprogressive sharpening in the minimalist model. We then empirically demonstrate\nhow these theoretical insights extend to practical scenarios. This study offers\na deeper understanding of sharpness dynamics in neural network training,\nhighlighting the interplay between depth, training data, and optimizers.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u9510\u5ea6\u73b0\u8c61\uff0c\u4f7f\u7528\u6781\u7b80\u6a21\u578b\u63ed\u793a\u5176\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u589e\u5f3a\u7406\u89e3\u3002", "motivation": "\u5c3d\u7ba1\u5728\u5b9e\u8df5\u4e2d\u666e\u904d\u89c2\u5bdf\u5230\u6e10\u8fdb\u9510\u5316\u73b0\u8c61\uff0c\u5176\u80cc\u540e\u7684\u673a\u5236\u4ecd\u7136\u7f3a\u4e4f\u6df1\u5165\u4e86\u89e3\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e00\u4e2a\u6781\u7b80\u5316\u7684\u6a21\u578b\u8fdb\u884c\u5206\u6790\uff1a\u4e00\u4e2a\u6bcf\u5c42\u53ea\u6709\u4e00\u4e2a\u8282\u70b9\u7684\u7ebf\u6027\u6df1\u5ea6\u7f51\u7edc\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8be5\u6781\u7b80\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u6349\u5230\u6700\u8fd1\u5b9e\u8bc1\u7814\u7a76\u4e2d\u89c2\u5bdf\u5230\u7684\u9510\u5ea6\u52a8\u6001\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u5c55\u793a\u6570\u636e\u96c6\u7279\u6027\u3001\u7f51\u7edc\u6df1\u5ea6\u3001\u4f18\u5316\u5668\u7684\u968f\u673a\u6027\u548c\u6b65\u957f\u5982\u4f55\u5f71\u54cd\u6e10\u8fdb\u9510\u5316\u7684\u7a0b\u5ea6\u3002\u968f\u540e\uff0c\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e9b\u7406\u8bba\u89c1\u89e3\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u9510\u5ea6\u52a8\u6001\u7684\u66f4\u6df1\u523b\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u6df1\u5ea6\u3001\u8bad\u7ec3\u6570\u636e\u548c\u4f18\u5316\u5668\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002"}}
{"id": "2506.08012", "pdf": "https://arxiv.org/pdf/2506.08012", "abs": "https://arxiv.org/abs/2506.08012", "authors": ["Penghao Wu", "Shengnan Ma", "Bo Wang", "Jiaheng Yu", "Lewei Lu", "Ziwei Liu"], "title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior", "categories": ["cs.AI", "cs.CV"], "comment": "Project Page at https://penghao-wu.github.io/GUI_Reflection/", "summary": "Multimodal Large Language Models (MLLMs) have shown great potential in\nrevolutionizing Graphical User Interface (GUI) automation. However, existing\nGUI models mostly rely on learning from nearly error-free offline trajectories,\nthus lacking reflection and error recovery capabilities. To bridge this gap, we\npropose GUI-Reflection, a novel framework that explicitly integrates\nself-reflection and error correction capabilities into end-to-end multimodal\nGUI models throughout dedicated training stages: GUI-specific pre-training,\noffline supervised fine-tuning (SFT), and online reflection tuning.\nGUI-reflection enables self-reflection behavior emergence with fully automated\ndata generation and learning processes without requiring any human annotation.\nSpecifically, 1) we first propose scalable data pipelines to automatically\nconstruct reflection and error correction data from existing successful\ntrajectories. While existing GUI models mainly focus on grounding and UI\nunderstanding ability, we propose the GUI-Reflection Task Suite to learn and\nevaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a\ndiverse and efficient environment for online training and data collection of\nGUI models on mobile devices. 3) We also present an iterative online reflection\ntuning algorithm leveraging the proposed environment, enabling the model to\ncontinuously enhance its reflection and error correction abilities. Our\nframework equips GUI agents with self-reflection and correction capabilities,\npaving the way for more robust, adaptable, and intelligent GUI automation, with\nall data, models, environments, and tools to be released publicly.", "AI": {"tldr": "\u63d0\u51faGUI-Reflection\u6846\u67b6\uff0c\u589e\u5f3a\u591a\u6a21\u6001GUI\u6a21\u578b\u7684\u81ea\u53cd\u601d\u548c\u7ea0\u9519\u80fd\u529b\uff0c\u63d0\u5347GUI\u81ea\u52a8\u5316\u7684\u667a\u80fd\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709GUI\u6a21\u578b\u7f3a\u4e4f\u53cd\u601d\u548c\u9519\u8bef\u6062\u590d\u80fd\u529b\uff0c\u4e3b\u8981\u4f9d\u8d56\u4e8e\u51e0\u4e4e\u65e0\u9519\u8bef\u7684\u79bb\u7ebf\u8f68\u8ff9\u5b66\u4e60\u3002\u6211\u4eec\u5e0c\u671b\u514b\u670d\u8fd9\u4e00\u7f3a\u9677\u3002", "method": "\u91c7\u7528\u4e13\u95e8\u7684\u8bad\u7ec3\u9636\u6bb5\uff0c\u5305\u62ecGUI\u7279\u5b9a\u9884\u8bad\u7ec3\u3001\u79bb\u7ebf\u76d1\u7763\u5fae\u8c03\u548c\u5728\u7ebf\u53cd\u601d\u8c03\u4f18\uff0c\u96c6\u6210\u81ea\u53cd\u601d\u548c\u7ea0\u9519\u80fd\u529b\u3002", "result": "\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u5728\u7ebf\u8bad\u7ec3\u548c\u6570\u636e\u91c7\u96c6\u73af\u5883\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u5728\u7ebf\u53cd\u601d\u8c03\u4f18\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53cd\u601d\u548c\u7ea0\u9519\u80fd\u529b\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86GUI-Reflection\uff0c\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u4f7f\u5f97\u591a\u6a21\u6001GUI\u6a21\u578b\u5177\u5907\u81ea\u53cd\u601d\u548c\u7ea0\u9519\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u9ad8GUI\u81ea\u52a8\u5316\u7684\u5065\u58ee\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2506.07249", "pdf": "https://arxiv.org/pdf/2506.07249", "abs": "https://arxiv.org/abs/2506.07249", "authors": ["Lance Calvin Lim Gamboa", "Yue Feng", "Mark Lee"], "title": "Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages", "categories": ["cs.CL"], "comment": "Accepted into the Gender Bias in NLP Workshop at ACL 2025\n  (GeBNLP@ACL2025)", "summary": "Emerging research on bias attribution and interpretability have revealed how\ntokens contribute to biased behavior in language models processing English\ntexts. We build on this line of inquiry by adapting the information-theoretic\nbias attribution score metric for implementation on models handling\nagglutinative languages, particularly Filipino. We then demonstrate the\neffectiveness of our adapted method by using it on a purely Filipino model and\non three multilingual models: one trained on languages worldwide and two on\nSoutheast Asian data. Our results show that Filipino models are driven towards\nbias by words pertaining to people, objects, and relationships, entity-based\nthemes that stand in contrast to the action-heavy nature of bias-contributing\nthemes in English (i.e., criminal, sexual, and prosocial behaviors). These\nfindings point to differences in how English and non-English models process\ninputs linked to sociodemographic groups and bias.", "AI": {"tldr": "\u7814\u7a76\u9002\u5e94\u4e86\u504f\u5dee\u5f52\u56e0\u8bc4\u5206\u4ee5\u9002\u7528\u4e8e\u83f2\u5f8b\u5bbe\u8bed\u6a21\u578b\uff0c\u53d1\u73b0\u8be5\u6a21\u578b\u4e3b\u8981\u53d7\u5230\u7279\u5b9a\u4eba\u7269\u3001\u7269\u54c1\u548c\u5173\u7cfb\u8bcd\u6c47\u7684\u504f\u89c1\u9a71\u52a8\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u5728\u5904\u7406\u9ecf\u7740\u8bed\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u8bc4\u4f30\u548c\u89e3\u91ca\u504f\u89c1\u884c\u4e3a\u3002", "method": "\u5c06\u4fe1\u606f\u8bba\u504f\u5dee\u5f52\u56e0\u8bc4\u5206\u6307\u6807\u8c03\u6574\u4e3a\u53ef\u4ee5\u5728\u5904\u7406\u9ecf\u7740\u8bed\u7684\u6a21\u578b\u4e0a\u4f7f\u7528\uff0c\u7279\u522b\u662f\u83f2\u5f8b\u5bbe\u8bed\u3002", "result": "\u7814\u7a76\u5c55\u793a\u4e86\u9002\u7528\u4e8e\u7eaf\u83f2\u5f8b\u5bbe\u6a21\u578b\u548c\u4e09\u4e2a\u591a\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u83f2\u5f8b\u5bbe\u6a21\u578b\u4e2d\u504f\u89c1\u7684\u5177\u4f53\u8bcd\u6c47\u9a71\u52a8\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u83f2\u5f8b\u5bbe\u6a21\u578b\u7684\u504f\u89c1\u4e3b\u8981\u53d7\u5230\u4e0e\u4eba\u7269\u3001\u7269\u54c1\u548c\u5173\u7cfb\u76f8\u5173\u7684\u8bcd\u6c47\u9a71\u52a8\uff0c\u800c\u8fd9\u4e9b\u901a\u5e38\u5728\u82f1\u8bed\u6a21\u578b\u4e2d\u4e0e\u72af\u7f6a\u3001\u6027\u884c\u4e3a\u548c\u4eb2\u793e\u4f1a\u884c\u4e3a\u76f8\u5173\u3002"}}
{"id": "2506.06954", "pdf": "https://arxiv.org/pdf/2506.06954", "abs": "https://arxiv.org/abs/2506.06954", "authors": ["Clinton Enwerem", "Aniruddh G. Puranic", "John S. Baras", "Calin Belta"], "title": "Safety-Aware Reinforcement Learning for Control via Risk-Sensitive Action-Value Iteration and Quantile Regression", "categories": ["cs.LG", "cs.RO"], "comment": "13 pages, 4 figures. Submission under review", "summary": "Mainstream approximate action-value iteration reinforcement learning (RL)\nalgorithms suffer from overestimation bias, leading to suboptimal policies in\nhigh-variance stochastic environments. Quantile-based action-value iteration\nmethods reduce this bias by learning a distribution of the expected cost-to-go\nusing quantile regression. However, ensuring that the learned policy satisfies\nsafety constraints remains a challenge when these constraints are not\nexplicitly integrated into the RL framework. Existing methods often require\ncomplex neural architectures or manual tradeoffs due to combined cost\nfunctions. To address this, we propose a risk-regularized quantile-based\nalgorithm integrating Conditional Value-at-Risk (CVaR) to enforce safety\nwithout complex architectures. We also provide theoretical guarantees on the\ncontraction properties of the risk-sensitive distributional Bellman operator in\nWasserstein space, ensuring convergence to a unique cost distribution.\nSimulations of a mobile robot in a dynamic reach-avoid task show that our\napproach leads to more goal successes, fewer collisions, and better\nsafety-performance trade-offs compared to risk-neutral methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u98ce\u9669\u6b63\u5219\u5316\u7684\u5206\u4f4d\u6570\u7b97\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6761\u4ef6\u98ce\u9669\u503c\uff0c\u5728\u7b80\u5355\u67b6\u6784\u4e0b\u786e\u4fdd\u5b89\u5168\u7ea6\u675f\uff0c\u5e76\u5728\u4efb\u52a1\u6a21\u62df\u4e2d\u8868\u73b0\u4f18\u4e8e\u98ce\u9669\u4e2d\u6027\u65b9\u6cd5\u3002", "motivation": "\u4e3b\u6d41\u7684\u8fd1\u4f3c\u52a8\u4f5c\u503c\u8fed\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u9ad8\u65b9\u5dee\u968f\u673a\u73af\u5883\u4e2d\u5b58\u5728\u9ad8\u4f30\u504f\u5dee\uff0c\u5bfc\u81f4\u6b21\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u98ce\u9669\u6b63\u5219\u5316\u7684\u5206\u4f4d\u6570\u7b97\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6761\u4ef6\u98ce\u9669\u503c\uff08CVaR\uff09\u6765\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8e\u98ce\u9669\u654f\u611f\u5206\u5e03\u8d1d\u5c14\u66fc\u7b97\u5b50\u5728Wasserstein\u7a7a\u95f4\u4e2d\u6536\u7f29\u6027\u8d28\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5728\u52a8\u6001\u7684\u79fb\u52a8\u673a\u5668\u4eba\u5230\u8fbe-\u907f\u8ba9\u4efb\u52a1\u6a21\u62df\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u98ce\u9669\u4e2d\u6027\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u597d\u7684\u76ee\u6807\u6210\u529f\u7387\u3001\u66f4\u5c11\u7684\u78b0\u649e\u4ee5\u53ca\u66f4\u597d\u7684\u5b89\u5168\u6027\u80fd\u6743\u8861\u3002", "conclusion": "\u57fa\u4e8e\u98ce\u9669\u6b63\u5219\u5316\u7684\u5206\u4f4d\u6570\u7b97\u6cd5\u80fd\u6709\u6548\u51cf\u8f7b\u52a8\u4f5c\u503c\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u7684\u9ad8\u4f30\u504f\u5dee\uff0c\u540c\u65f6\u5728\u4e0d\u9700\u8981\u590d\u6742\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u6ee1\u8db3\u5b89\u5168\u7ea6\u675f\u3002"}}
{"id": "2309.11082", "pdf": "https://arxiv.org/pdf/2309.11082", "abs": "https://arxiv.org/abs/2309.11082", "authors": ["Chen Jiang", "Hong Liu", "Xuzheng Yu", "Qing Wang", "Yuan Cheng", "Jia Xu", "Zhongyi Liu", "Qingpei Guo", "Wei Chu", "Ming Yang", "Yuan Qi"], "title": "Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "comment": "Accepted by ACM MM 2023", "summary": "In recent years, the explosion of web videos makes text-video retrieval\nincreasingly essential and popular for video filtering, recommendation, and\nsearch. Text-video retrieval aims to rank relevant text/video higher than\nirrelevant ones. The core of this task is to precisely measure the cross-modal\nsimilarity between texts and videos. Recently, contrastive learning methods\nhave shown promising results for text-video retrieval, most of which focus on\nthe construction of positive and negative pairs to learn text and video\nrepresentations. Nevertheless, they do not pay enough attention to hard\nnegative pairs and lack the ability to model different levels of semantic\nsimilarity. To address these two issues, this paper improves contrastive\nlearning using two novel techniques. First, to exploit hard examples for robust\ndiscriminative power, we propose a novel Dual-Modal Attention-Enhanced Module\n(DMAE) to mine hard negative pairs from textual and visual clues. By further\nintroducing a Negative-aware InfoNCE (NegNCE) loss, we are able to adaptively\nidentify all these hard negatives and explicitly highlight their impacts in the\ntraining loss. Second, our work argues that triplet samples can better model\nfine-grained semantic similarity compared to pairwise samples. We thereby\npresent a new Triplet Partial Margin Contrastive Learning (TPM-CL) module to\nconstruct partial order triplet samples by automatically generating\nfine-grained hard negatives for matched text-video pairs. The proposed TPM-CL\ndesigns an adaptive token masking strategy with cross-modal interaction to\nmodel subtle semantic differences. Extensive experiments demonstrate that the\nproposed approach outperforms existing methods on four widely-used text-video\nretrieval datasets, including MSR-VTT, MSVD, DiDeMo and ActivityNet.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u5347\u4e86\u6587\u672c\u89c6\u9891\u68c0\u7d22\uff0c\u901a\u8fc7\u5f15\u5165DMAE\u548cTPM-CL\u4e24\u4e2a\u65b0\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u56f0\u96be\u8d1f\u6837\u672c\u6316\u6398\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5efa\u6a21\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u5bf9\u56f0\u96be\u8d1f\u6837\u672c\u5173\u6ce8\u4e0d\u8db3\uff0c\u4e14\u7f3a\u4e4f\u5efa\u6a21\u4e0d\u540c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Dual-Modal Attention-Enhanced Module(DMAE)\u7528\u4e8e\u6316\u6398\u56f0\u96be\u8d1f\u6837\u672c\uff0c\u5e76\u5f15\u5165\u4e86Negative-aware InfoNCE(NegNCE)\u635f\u5931\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86Triplet Partial Margin Contrastive Learning(TPM-CL)\u6a21\u5757\uff0c\u901a\u8fc7\u81ea\u751f\u6210\u7ec6\u7c92\u5ea6\u7684\u56f0\u96be\u8d1f\u6837\u672c\u6784\u5efa\u90e8\u5206\u987a\u5e8f\u4e09\u5143\u7ec4\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728MSR-VTT\u3001MSVD\u3001DiDeMo\u548cActivityNet\u56db\u4e2a\u6587\u672c\u89c6\u9891\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684TPM-CL\u548cDMAE\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6587\u672c\u89c6\u9891\u68c0\u7d22\u7684\u6027\u80fd\uff0c\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u4e0a\u8d85\u8fc7\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.07270", "pdf": "https://arxiv.org/pdf/2506.07270", "abs": "https://arxiv.org/abs/2506.07270", "authors": ["Atahan \u00d6zer", "\u00c7a\u011fatay Y\u0131ld\u0131z"], "title": "Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) exhibit remarkable capabilities in question\nanswering and reasoning thanks to their extensive parametric memory. However,\ntheir knowledge is inherently limited by the scope of their pre-training data,\nwhile real-world information evolves continuously. Updating this knowledge\ntypically requires costly and brittle re-training, or in-context learning\n(ICL), which becomes impractical at scale given the volume and volatility of\nmodern information. Motivated by these limitations, we investigate how LLMs\nperform when exposed to temporal text corpora, or documents that reflect\nevolving knowledge over time, such as sports biographies where facts like a\nplayer's \"current team\" change year by year. To this end, we introduce two new\nbenchmarks: Temporal Wiki, which captures factual drift across historical\nWikipedia snapshots, and Unified Clark, which aggregates timestamped news\narticles to simulate real-world information accumulation. Our analysis reveals\nthat LLMs often struggle to reconcile conflicting or outdated facts and can be\nmisled when multiple versions of a fact appear in context. To address these\nissues, we propose a lightweight, agentic framework that incrementally builds a\nstructured, external memory from source documents without requiring\nre-training. This knowledge organization strategy enables models to retrieve\nand reason over temporally filtered, relevant information at inference time.\nEmpirically, our method outperforms ICL and RAG baselines across both\nbenchmarks, especially on questions requiring more complex reasoning or\nintegration of conflicting facts.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5916\u90e8\u8bb0\u5fc6\u6765\u5e94\u5bf9LLMs\u5728\u5904\u7406\u6f14\u53d8\u77e5\u8bc6\u65f6\u7684\u9650\u5236\uff0c\u6210\u529f\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u53d7\u5230\u9884\u8bad\u7ec3\u6570\u636e\u8303\u56f4\u7684\u9650\u5236\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u7684\u4fe1\u606f\u4e0d\u65ad\u6f14\u53d8\uff0c\u4f20\u7edf\u7684\u66f4\u65b0\u65b9\u5f0f\u6210\u672c\u9ad8\u4e14\u4e0d\u7a33\u5b9a\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5904\u7406\u65f6\u95f4\u76f8\u5173\u7684\u6587\u672c\u8bed\u6599\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u4ece\u6e90\u6587\u6863\u4e2d\u589e\u91cf\u6784\u5efa\u7ed3\u6784\u5316\u7684\u5916\u90e8\u8bb0\u5fc6\uff0c\u4e0d\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\uff0c\u4f7f\u5f97\u6a21\u578b\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u68c0\u7d22\u548c\u63a8\u7406\u65f6\u95f4\u4e0a\u8fc7\u6ee4\u7684\u76f8\u5173\u4fe1\u606f\u3002", "result": "\u5728Temporal Wiki\u548cUnified Clark\u57fa\u51c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5c24\u5176\u5728\u9700\u8981\u590d\u6742\u63a8\u7406\u6216\u6574\u5408\u51b2\u7a81\u4e8b\u5b9e\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8eICL\u548cRAG\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u7ed3\u6784\u5316\u5916\u90e8\u8bb0\u5fc6\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u63a8\u7406\u65f6\u68c0\u7d22\u548c\u63a8\u7406\u65f6\u95f4\u4e0a\u8fc7\u6ee4\u7684\u76f8\u5173\u4fe1\u606f\uff0c\u6b64\u65b9\u6cd5\u4f18\u4e8eICL\u548cRAG\u57fa\u7ebf\u3002"}}
{"id": "2506.06977", "pdf": "https://arxiv.org/pdf/2506.06977", "abs": "https://arxiv.org/abs/2506.06977", "authors": ["Pengfei Hu", "Xiaoxue Han", "Fei Wang", "Yue Ning"], "title": "UdonCare: Hierarchy Pruning for Unseen Domain Discovery in Predictive Healthcare", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Domain generalization has become a critical challenge in clinical prediction,\nwhere patient cohorts often exhibit shifting data distributions that degrade\nmodel performance. Typical domain generalization approaches struggle in\nreal-world healthcare settings for two main reasons: (1) patient-specific\ndomain labels are typically unavailable, making domain discovery especially\ndifficult; (2) purely data-driven approaches overlook key clinical insights,\nleading to a gap in medical knowledge integration. To address these problems,\nwe leverage hierarchical medical ontologies like the ICD-9-CM hierarchy to\ngroup diseases into higher-level categories and discover more flexible latent\ndomains. In this paper, we introduce UdonCare, a hierarchy-guided framework\nthat iteratively prunes fine-grained domains, encodes these refined domains,\nand applies a Siamese-type inference mechanism to separate domain-related\nsignals from patient-level features. Experimental results on clinical datasets\n(MIMIC-III and MIMIC-IV) show that the proposed model achieves higher\nperformance compared to other domain generalization baselines when substantial\ndomain gaps presents, highlighting the untapped potential of medical knowledge\nfor enhancing domain generalization in practical healthcare applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u533b\u5b66\u77e5\u8bc6\u63d0\u9ad8\u4e34\u5e8a\u9884\u6d4b\u9886\u57df\u6cdb\u5316\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u79f0\u4e3aUdonCare\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u5728\u4e34\u5e8a\u9884\u6d4b\u4e2d\uff0c\u60a3\u8005\u7fa4\u4f53\u5e38\u5e38\u8868\u73b0\u51fa\u6570\u636e\u5206\u5e03\u7684\u53d8\u5316\uff0c\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002\u5178\u578b\u7684\u9886\u57df\u6cdb\u5316\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u7684\u533b\u7597\u73af\u5883\u4e2d\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\uff081\uff09\u901a\u5e38\u6ca1\u6709\u53ef\u7528\u7684\u60a3\u8005\u7279\u5b9a\u9886\u57df\u6807\u7b7e\uff0c\u4f7f\u5f97\u9886\u57df\u53d1\u73b0\u7279\u522b\u56f0\u96be\uff1b\uff082\uff09\u7eaf\u7cb9\u4ee5\u6570\u636e\u4e3a\u9a71\u52a8\u7684\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5173\u952e\u7684\u4e34\u5e8a\u6d1e\u5bdf\uff0c\u5bfc\u81f4\u533b\u5b66\u77e5\u8bc6\u6574\u5408\u7684\u5dee\u8ddd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aUdonCare\u7684\u5c42\u6b21\u5f15\u5bfc\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u8fed\u4ee3\u4fee\u526a\u7ec6\u7c92\u5ea6\u9886\u57df\u3001\u7f16\u7801\u8fd9\u4e9b\u7cbe\u7ec6\u9886\u57df\uff0c\u5e76\u5e94\u7528\u4e00\u79cdSiamese-type\u63a8\u7406\u673a\u5236\uff0c\u5c06\u9886\u57df\u76f8\u5173\u4fe1\u53f7\u4e0e\u60a3\u8005\u7ea7\u7279\u5f81\u5206\u79bb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u5728\u4e34\u5e8a\u6570\u636e\u96c6\uff08MIMIC-III\u548cMIMIC-IV\uff09\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6a21\u578b\u5728\u5b58\u5728\u663e\u8457\u9886\u57df\u5dee\u8ddd\u65f6\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u9886\u57df\u6cdb\u5316\u57fa\u7ebf\uff0c\u5f3a\u8c03\u4e86\u533b\u5b66\u77e5\u8bc6\u5728\u63d0\u9ad8\u5b9e\u9645\u533b\u7597\u5e94\u7528\u4e2d\u7684\u9886\u57df\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2406.00971", "pdf": "https://arxiv.org/pdf/2406.00971", "abs": "https://arxiv.org/abs/2406.00971", "authors": ["Vahid Azizi", "Fatemeh Koochaki"], "title": "MiniGPT-Reverse-Designing: Predicting Image Adjustments Utilizing MiniGPT-4", "categories": ["cs.CV", "cs.AI"], "comment": "8 pages, 7 figures", "summary": "Vision-Language Models (VLMs) have recently seen significant advancements\nthrough integrating with Large Language Models (LLMs). The VLMs, which process\nimage and text modalities simultaneously, have demonstrated the ability to\nlearn and understand the interaction between images and texts across various\nmulti-modal tasks. Reverse designing, which could be defined as a complex\nvision-language task, aims to predict the edits and their parameters, given a\nsource image, an edited version, and an optional high-level textual edit\ndescription. This task requires VLMs to comprehend the interplay between the\nsource image, the edited version, and the optional textual context\nsimultaneously, going beyond traditional vision-language tasks. In this paper,\nwe extend and fine-tune MiniGPT-4 for the reverse designing task. Our\nexperiments demonstrate the extensibility of off-the-shelf VLMs, specifically\nMiniGPT-4, for more complex tasks such as reverse designing. Code is available\nat this \\href{https://github.com/VahidAz/MiniGPT-Reverse-Designing}", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6269\u5c55\u548c\u5fae\u8c03MiniGPT-4\u6a21\u578b\u8fdb\u884c\u9006\u5411\u8bbe\u8ba1\u4efb\u52a1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u5177\u5907\u8f83\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u8fd1\u5e74\u6765\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\uff0c\u5c24\u5176\u662f\u5728\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u540e\u3002\u9006\u5411\u8bbe\u8ba1\u4f5c\u4e3a\u4e00\u79cd\u590d\u6742\u7684\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\uff0c\u65e8\u5728\u9884\u6d4b\u7ed9\u5b9a\u6e90\u56fe\u50cf\u3001\u7f16\u8f91\u7248\u672c\u548c\u53ef\u9009\u7684\u9ad8\u7ea7\u6587\u672c\u7f16\u8f91\u63cf\u8ff0\u7684\u7f16\u8f91\u53ca\u5176\u53c2\u6570\u3002\u8fd9\u4e2a\u4efb\u52a1\u9700\u8981\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u6e90\u56fe\u50cf\u3001\u7f16\u8f91\u7248\u672c\u548c\u53ef\u9009\u6587\u672c\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u8d85\u8d8a\u4f20\u7edf\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u3002", "method": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u6269\u5c55\u5e76\u5fae\u8c03\u4e86MiniGPT-4\uff0c\u7528\u4e8e\u9006\u5411\u8bbe\u8ba1\u4efb\u52a1\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6210\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u662fMiniGPT-4\uff0c\u5728\u5904\u7406\u66f4\u590d\u6742\u4efb\u52a1\uff08\u4f8b\u5982\u9006\u5411\u8bbe\u8ba1\uff09\u65b9\u9762\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "MiniGPT-4\u4e3a\u9006\u5411\u8bbe\u8ba1\u4efb\u52a1\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u6548\u679c\uff0c\u8fd9\u8868\u660e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u590d\u6742\u7684\u591a\u6a21\u6001\u4efb\u52a1\u5904\u7406\u3002"}}
{"id": "2506.07274", "pdf": "https://arxiv.org/pdf/2506.07274", "abs": "https://arxiv.org/abs/2506.07274", "authors": ["Olga Kellert", "Nemika Tyagi", "Muhammad Imran", "Nelvin Licona-Guevara", "Carlos G\u00f3mez-Rodr\u00edguez"], "title": "Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages", "summary": "Code-switching presents a complex challenge for syntactic analysis,\nespecially in low-resource language settings where annotated data is scarce.\nWhile recent work has explored the use of large language models (LLMs) for\nsequence-level tagging, few approaches systematically investigate how well\nthese models capture syntactic structure in code-switched contexts. Moreover,\nexisting parsers trained on monolingual treebanks often fail to generalize to\nmultilingual and mixed-language input. To address this gap, we introduce the\nBiLingua Parser, an LLM-based annotation pipeline designed to produce Universal\nDependencies (UD) annotations for code-switched text. First, we develop a\nprompt-based framework for Spanish-English and Spanish-Guaran\\'i data,\ncombining few-shot LLM prompting with expert review. Second, we release two\nannotated datasets, including the first Spanish-Guaran\\'i UD-parsed corpus.\nThird, we conduct a detailed syntactic analysis of switch points across\nlanguage pairs and communicative contexts. Experimental results show that\nBiLingua Parser achieves up to 95.29% LAS after expert revision, significantly\noutperforming prior baselines and multilingual parsers. These results show that\nLLMs, when carefully guided, can serve as practical tools for bootstrapping\nsyntactic resources in under-resourced, code-switched environments. Data and\nsource code are available at https://github.com/N3mika/ParsingProject", "AI": {"tldr": "BiLingua Parser effectively annotates code-switched text with high accuracy, leveraging LLMs with expert-guided few-shot prompting, and offers new annotated datasets for research.", "motivation": "Existing parsers trained on monolingual treebanks often fail in multilingual and code-switched scenarios, and there is a scarcity of annotated data for such contexts. The study aims to address these issues.", "method": "The paper introduces an LLM-based annotation pipeline called BiLingua Parser. It uses a prompt-based framework combining few-shot LLM prompting with expert review to generate Universal Dependencies annotations for code-switched text, particularly Spanish-English and Spanish-Guaran\u00ed.", "result": "BiLingua Parser achieves up to 95.29% LAS after expert revision, outperforming prior baselines and multilingual parsers significantly.", "conclusion": "BiLingua Parser achieves high LAS, showing that LLMs can effectively bootstrap syntactic resources in low-resource, code-switched environments when guided properly."}}
{"id": "2506.06978", "pdf": "https://arxiv.org/pdf/2506.06978", "abs": "https://arxiv.org/abs/2506.06978", "authors": ["Zitian Li", "Wang Chi Cheung"], "title": "Near Optimal Non-asymptotic Sample Complexity of 1-Identification", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Motivated by an open direction in existing literature, we study the\n1-identification problem, a fundamental multi-armed bandit formulation on pure\nexploration. The goal is to determine whether there exists an arm whose mean\nreward is at least a known threshold $\\mu_0$, or to output None if it believes\nsuch an arm does not exist. The agent needs to guarantee its output is correct\nwith probability at least $1-\\delta$. Degenne & Koolen 2019 has established the\nasymptotically tight sample complexity for the 1-identification problem, but\nthey commented that the non-asymptotic analysis remains unclear. We design a\nnew algorithm Sequential-Exploration-Exploitation (SEE), and conduct\ntheoretical analysis from the non-asymptotic perspective. Novel to the\nliterature, we achieve near optimality, in the sense of matching upper and\nlower bounds on the pulling complexity. The gap between the upper and lower\nbounds is up to a polynomial logarithmic factor. The numerical result also\nindicates the effectiveness of our algorithm, compared to existing benchmarks.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5SEE\uff0c\u7528\u4e8e\u89e3\u51b3\u7eaf\u63a2\u7d22\u4e2d\u76841-\u8bc6\u522b\u95ee\u9898\uff0c\u5e76\u5728\u975e\u6e10\u8fd1\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u754c\u8fd1\u4e4e\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "motivation": "\u53d7\u5230\u73b0\u6709\u6587\u732e\u4e2d\u7684\u4e00\u4e2a\u5f00\u653e\u65b9\u5411\u7684\u6fc0\u52b1\uff0c\u7814\u7a76\u7528\u4e8e\u7eaf\u63a2\u7d22\u7684\u57fa\u7840\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u76841-\u8bc6\u522b\u95ee\u9898\uff0c\u4ee5\u786e\u5b9a\u662f\u5426\u5b58\u5728\u81f3\u5c11\u8fbe\u5230\u5df2\u77e5\u9608\u503c\u7684\u5956\u52b1\u5e73\u5747\u503c\uff0c\u6216\u8f93\u51faNone\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5Sequential-Exploration-Exploitation\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u5728\u975e\u6e10\u8fd1\u60c5\u51b5\u4e0b\u7684\u8fd1\u4e4e\u6700\u4f18\u6027\u3002", "result": "\u65b0\u7b97\u6cd5\u8fbe\u5230\u4e86\u4e0a\u4e0b\u754c\u4e4b\u95f4\u7684\u8fd1\u4e4e\u6700\u4f18\u5339\u914d\uff0c\u6570\u503c\u7ed3\u679c\u663e\u793a\u8be5\u7b97\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u57fa\u51c6\u66f4\u4e3a\u6709\u6548\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5SEE\uff0c\u5e76\u5728\u975e\u6e10\u8fd1\u7684\u89c6\u89d2\u4e0b\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u663e\u793a\u5176\u6709\u6548\u6027\u548c\u63a5\u8fd1\u6700\u4f18\u6027\u3002"}}
{"id": "2411.12262", "pdf": "https://arxiv.org/pdf/2411.12262", "abs": "https://arxiv.org/abs/2411.12262", "authors": ["Raphael Merx", "Ad\u00e9rito Jos\u00e9 Guterres Correia", "Hanna Suominen", "Ekaterina Vylomova"], "title": "Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service", "categories": ["cs.CL", "cs.AI"], "comment": "to be published in LoResMT 2025", "summary": "Low-resource machine translation (MT) presents a diversity of community needs\nand application challenges that remain poorly understood. To complement surveys\nand focus groups, which tend to rely on small samples of respondents, we\npropose an observational study on actual usage patterns of tetun$.$org, a\nspecialized MT service for the Tetun language, which is the lingua franca in\nTimor-Leste. Our analysis of 100,000 translation requests reveals patterns that\nchallenge assumptions based on existing corpora. We find that users, many of\nthem students on mobile devices, typically translate text from a high-resource\nlanguage into Tetun across diverse domains including science, healthcare, and\ndaily life. This contrasts sharply with available Tetun corpora, which are\ndominated by news articles covering government and social issues. Our results\nsuggest that MT systems for institutionalized minority languages like Tetun\nshould prioritize accuracy on domains relevant to educational contexts, in the\nhigh-resource to low-resource direction. More broadly, this study demonstrates\nhow observational analysis can inform low-resource language technology\ndevelopment, by grounding research in practical community needs.", "AI": {"tldr": "\u901a\u8fc7\u5bf9Tetun.org\u7684\u4f7f\u7528\u6a21\u5f0f\u8fdb\u884c\u7814\u7a76\uff0c\u53d1\u73b0\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u7684\u5b9e\u9645\u9700\u6c42\u4e0e\u73b0\u6709\u8bed\u6599\u5e93\u4e0d\u540c\uff0c\u5f3a\u8c03\u4e86\u5728\u6559\u80b2\u76f8\u5173\u9886\u57df\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8c03\u67e5\u548c\u7126\u70b9\u5c0f\u7ec4\u65b9\u6cd5\u6837\u672c\u91cf\u5c0f\uff0c\u56e0\u6b64\u9700\u8981\u901a\u8fc7\u89c2\u5bdf\u6027\u7814\u7a76\u6765\u63ed\u793a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u7684\u771f\u5b9e\u9700\u6c42\u548c\u4f7f\u7528\u6a21\u5f0f\u3002", "method": "\u5bf9Tetun.org\u7684\u4f7f\u7528\u6a21\u5f0f\u8fdb\u884c\u4e86\u89c2\u5bdf\u6027\u7814\u7a76\uff0c\u5206\u6790\u4e86100,000\u4e2a\u7ffb\u8bd1\u8bf7\u6c42\u4ee5\u63ed\u793a\u7ffb\u8bd1\u9700\u6c42\u7684\u771f\u5b9e\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7528\u6237\u4e3b\u8981\u662f\u5b66\u751f\uff0c\u4ed6\u4eec\u901a\u5e38\u4f7f\u7528\u624b\u673a\u5c06\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u6587\u672c\u7ffb\u8bd1\u4e3aTetun\uff0c\u6d89\u53ca\u79d1\u5b66\u3001\u5065\u5eb7\u3001\u65e5\u5e38\u751f\u6d3b\u7b49\u591a\u79cd\u9886\u57df\uff0c\u8fd9\u4e0e\u73b0\u6709\u4ee5\u65b0\u95fb\u4e3a\u4e3b\u7684Tetun\u8bed\u6599\u5e93\u5f62\u6210\u5bf9\u6bd4\u3002", "conclusion": "\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u5c24\u5176\u662f\u5bf9\u50cfTetun\u8fd9\u6837\u7684\u5c11\u6570\u6c11\u65cf\u8bed\u8a00\uff0c\u5e94\u4f18\u5148\u8003\u8651\u5728\u6559\u80b2\u76f8\u5173\u9886\u57df\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u4ece\u9ad8\u8d44\u6e90\u8bed\u8a00\u5230\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u65b9\u5411\u3002"}}
{"id": "2506.07295", "pdf": "https://arxiv.org/pdf/2506.07295", "abs": "https://arxiv.org/abs/2506.07295", "authors": ["Lujun Li", "Lama Sleem", "Niccolo' Gentile", "Geoffrey Nichil", "Radu State"], "title": "Exploring the Impact of Temperature on Large Language Models:Hot or Cold?", "categories": ["cs.CL"], "comment": null, "summary": "The sampling temperature, a critical hyperparameter in large language models\n(LLMs), modifies the logits before the softmax layer, thereby reshaping the\ndistribution of output tokens. Recent studies have challenged the Stochastic\nParrots analogy by demonstrating that LLMs are capable of understanding\nsemantics rather than merely memorizing data and that randomness, modulated by\nsampling temperature, plays a crucial role in model inference. In this study,\nwe systematically evaluated the impact of temperature in the range of 0 to 2 on\ndata sets designed to assess six different capabilities, conducting statistical\nanalyses on open source models of three different sizes: small (1B--4B), medium\n(6B--13B), and large (40B--80B). Our findings reveal distinct skill-specific\neffects of temperature on model performance, highlighting the complexity of\noptimal temperature selection in practical applications. To address this\nchallenge, we propose a BERT-based temperature selector that takes advantage of\nthese observed effects to identify the optimal temperature for a given prompt.\nWe demonstrate that this approach can significantly improve the performance of\nsmall and medium models in the SuperGLUE datasets. Furthermore, our study\nextends to FP16 precision inference, revealing that temperature effects are\nconsistent with those observed in 4-bit quantized models. By evaluating\ntemperature effects up to 4.0 in three quantized models, we find that the\nMutation Temperature -- the point at which significant performance changes\noccur -- increases with model size.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91c7\u6837\u6e29\u5ea6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBERT\u7684\u6e29\u5ea6\u9009\u62e9\u5668\u6765\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u91c7\u6837\u6e29\u5ea6\u662f\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u8d85\u53c2\u6570\uff0c\u5176\u5f71\u54cd\u8f93\u51fa\u8bcd\u7684\u5206\u5e03\uff0c\u56e0\u6b64\u7406\u89e3\u5176\u5728\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u4e0b\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u57280\u81f32\u7684\u6e29\u5ea6\u8303\u56f4\u5185\uff0c\u5bf9\u516d\u79cd\u4e0d\u540c\u80fd\u529b\u6570\u636e\u96c6\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eBERT\u7684\u6e29\u5ea6\u9009\u62e9\u5668\uff0c\u7528\u4e8e\u9009\u62e9\u6700\u4f73\u6e29\u5ea6\u3002", "result": "\u63d0\u51fa\u7684BERT\u6e29\u5ea6\u9009\u62e9\u5668\u663e\u8457\u63d0\u9ad8\u4e86\u5728SuperGLUE\u6570\u636e\u96c6\u4e0a\u7684\u5c0f\u578b\u548c\u4e2d\u578b\u6a21\u578b\u6027\u80fd\u3002\u7814\u7a76\u8fd8\u8868\u660e\u6e29\u5ea6\u6548\u5e94\u5728FP16\u7cbe\u5ea6\u548c\u91cf\u5316\u6a21\u578b\u4e2d\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u5927\u5c0f\u4e0b\uff0c\u91c7\u6837\u6e29\u5ea6\u5bf9\u6a21\u578b\u6027\u80fd\u5b58\u5728\u7279\u5b9a\u5f71\u54cd\uff0c\u4f18\u5316\u91c7\u6837\u6e29\u5ea6\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.06980", "pdf": "https://arxiv.org/pdf/2506.06980", "abs": "https://arxiv.org/abs/2506.06980", "authors": ["Sajib Acharjee Dip", "Uddip Acharjee Shuvo", "Dipanwita Mallick", "Abrar Rahman Abir", "Liqing Zhang"], "title": "MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure, 6 tables", "summary": "Cancer subtype classification is crucial for personalized treatment and\nprognostic assessment. However, effectively integrating multi-omic data remains\nchallenging due to the heterogeneous nature of genomic, epigenomic, and\ntranscriptomic features. In this work, we propose Modality-Aware\nCross-Attention MoXGATE, a novel deep-learning framework that leverages\ncross-attention and learnable modality weights to enhance feature fusion across\nmultiple omics sources. Our approach effectively captures inter-modality\ndependencies, ensuring robust and interpretable integration. Through\nexperiments on Gastrointestinal Adenocarcinoma (GIAC) and Breast Cancer (BRCA)\ndatasets from TCGA, we demonstrate that MoXGATE outperforms existing methods,\nachieving 95\\% classification accuracy. Ablation studies validate the\neffectiveness of cross-attention over simple concatenation and highlight the\nimportance of different omics modalities. Moreover, our model generalizes well\nto unseen cancer types e.g., breast cancer, underscoring its adaptability. Key\ncontributions include (1) a cross-attention-based multi-omic integration\nframework, (2) modality-weighted fusion for enhanced interpretability, (3)\napplication of focal loss to mitigate data imbalance, and (4) validation across\nmultiple cancer subtypes. Our results indicate that MoXGATE is a promising\napproach for multi-omic cancer subtype classification, offering improved\nperformance and biological generalizability.", "AI": {"tldr": "MoXGATE \u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u591a\u7ec4\u5b66\u6570\u636e\u6574\u5408\u65b9\u6cd5\uff0c\u63d0\u9ad8\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u51c6\u786e\u6027\u5e76\u5177\u6709\u8f83\u597d\u7684\u751f\u7269\u5b66\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6709\u6548\u6574\u5408\u591a\u7ec4\u5b66\u6570\u636e\u5bf9\u4e8e\u4e2a\u6027\u5316\u6cbb\u7597\u548c\u9884\u540e\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u7ec4\u5b66\u7279\u5f81\u7684\u5f02\u8d28\u6027\uff0c\u6574\u5408\u4e00\u76f4\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8de8\u6ce8\u610f\u529b\u673a\u5236\u548c\u53ef\u5b66\u4e60\u6a21\u6001\u6743\u91cd\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 MoXGATE\uff0c\u7528\u4e8e\u589e\u5f3a\u591a\u7ec4\u5b66\u6570\u636e\u7684\u7279\u5f81\u878d\u5408\u3002", "result": "MoXGATE \u5728 GIAC \u548c BRCA \u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8fbe\u5230 95%\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5bf9\u672a\u89c1\u8fc7\u7684\u764c\u75c7\u7c7b\u578b\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MoXGATE \u662f\u4e00\u79cd\u901a\u8fc7\u8de8\u6a21\u6001\u7684\u591a\u7ec4\u5b66\u96c6\u6210\u6846\u67b6\u3001\u6a21\u6001\u52a0\u6743\u878d\u5408\u53ca\u7126\u635f\u5931\u7684\u5e94\u7528\u6765\u63d0\u9ad8\u764c\u75c7\u4e9a\u578b\u5206\u7c7b\u6027\u80fd\u7684\u6709\u524d\u9014\u65b9\u6cd5\u3002"}}
{"id": "2506.04762", "pdf": "https://arxiv.org/pdf/2506.04762", "abs": "https://arxiv.org/abs/2506.04762", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs)-based query expansion for information retrieval\naugments queries with generated hypothetical documents with LLMs. However, its\nperformance relies heavily on the scale of the language models (LMs),\nnecessitating larger, more advanced LLMs. This approach is costly,\ncomputationally intensive, and often has limited accessibility. To address\nthese limitations, we introduce GOLFer - Smaller LMs-Generated Documents\nHallucination Filter & Combiner - a novel method leveraging smaller open-source\nLMs for query expansion. GOLFer comprises two modules: a hallucination filter\nand a documents combiner. The former detects and removes non-factual and\ninconsistent sentences in generated documents, a common issue with smaller LMs,\nwhile the latter combines the filtered content with the query using a weight\nvector to balance their influence. We evaluate GOLFer alongside dominant\nLLM-based query expansion methods on three web search and ten low-resource\ndatasets. Experimental results demonstrate that GOLFer consistently outperforms\nother methods using smaller LMs, and maintains competitive performance against\nmethods using large-size LLMs, demonstrating its effectiveness.", "AI": {"tldr": "GOLFer uses smaller open-source LMs with a hallucination filter and documents combiner to effectively improve query expansion while reducing reliance on large LLMs.", "motivation": "The motivation is to address the cost, computational intensity, and limited accessibility associated with large-scale LLM-based query expansions by using smaller open-source LMs in a more efficient way.", "method": "GOLFer consists of two main modules: 1) a hallucination filter to detect and remove non-factual and inconsistent sentences in generated documents, and 2) a documents combiner that merges the filtered content with the query using a weight vector to balance their influences.", "result": "Experimental results show that GOLFer consistently outperforms other methods when using smaller LMs and maintains a competitive performance level compared with approaches using large-size LLMs.", "conclusion": "GOLFer consistently outperforms other query expansion methods using smaller LMs, while maintaining competitive performance against methods using larger LLMs, indicating its effectiveness."}}
{"id": "2506.07297", "pdf": "https://arxiv.org/pdf/2506.07297", "abs": "https://arxiv.org/abs/2506.07297", "authors": ["Lauren Levine", "Amir Zeldes"], "title": "Subjectivity in the Annotation of Bridging Anaphora", "categories": ["cs.CL", "I.2.7"], "comment": "LAW-XIX, ACL 2025 Workshop", "summary": "Bridging refers to the associative relationship between inferable entities in\na discourse and the antecedents which allow us to understand them, such as\nunderstanding what \"the door\" means with respect to an aforementioned \"house\".\nAs identifying associative relations between entities is an inherently\nsubjective task, it is difficult to achieve consistent agreement in the\nannotation of bridging anaphora and their antecedents. In this paper, we\nexplore the subjectivity involved in the annotation of bridging instances at\nthree levels: anaphor recognition, antecedent resolution, and bridging subtype\nselection. To do this, we conduct an annotation pilot on the test set of the\nexisting GUM corpus, and propose a newly developed classification system for\nbridging subtypes, which we compare to previously proposed schemes. Our results\nsuggest that some previous resources are likely to be severely under-annotated.\nWe also find that while agreement on the bridging subtype category was\nmoderate, annotator overlap for exhaustively identifying instances of bridging\nis low, and that many disagreements resulted from subjective understanding of\nthe entities involved.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u8054\u63a5\u5173\u7cfb\u6807\u6ce8\u7684\u4e3b\u89c2\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u7cfb\u7edf\uff0c\u53d1\u73b0\u539f\u6709\u8d44\u6e90\u53ef\u80fd\u6807\u6ce8\u4e0d\u8db3\uff0c\u6807\u6ce8\u8005\u5728\u5b9e\u4f8b\u8bc6\u522b\u4e0a\u91cd\u53e0\u5ea6\u4f4e\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u4e3a\u4e86\u63a2\u7a76\u5728\u6807\u6ce8\u5173\u8054\u5b9e\u4f8b\u65f6\u7684\u4e3b\u89c2\u6027\uff0c\u7279\u522b\u662f\u5728\u6307\u4ee3\u8bcd\u8bc6\u522b\u3001\u524d\u4ef6\u89e3\u51b3\u548c\u5173\u8054\u5b50\u7c7b\u578b\u9009\u62e9\u4e09\u4e2a\u5c42\u9762\u3002", "method": "\u4f5c\u8005\u5728\u73b0\u6709\u7684GUM\u8bed\u6599\u5e93\u7684\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u6807\u6ce8\u8bd5\u70b9\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u5f00\u53d1\u7684\u5173\u8054\u5b50\u7c7b\u578b\u5206\u7c7b\u7cfb\u7edf\uff0c\u4ee5\u4e0e\u5148\u524d\u63d0\u51fa\u7684\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136\u5173\u8054\u5b50\u7c7b\u578b\u7c7b\u522b\u4e0a\u7684\u4e00\u81f4\u6027\u9002\u4e2d\uff0c\u4f46\u5bf9\u5168\u9762\u8bc6\u522b\u5173\u8054\u5b9e\u4f8b\u7684\u6807\u6ce8\u8005\u91cd\u53e0\u8f83\u4f4e\uff0c\u8bb8\u591a\u5206\u6b67\u6e90\u4e8e\u5bf9\u76f8\u5173\u5b9e\u4f53\u7684\u4e3b\u89c2\u7406\u89e3\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u6807\u6ce8\u8005\u5728\u8bc6\u522b\u548c\u6807\u6ce8\u5173\u8054\u5173\u7cfb\u5b9e\u4f8b\u65b9\u9762\u5b58\u5728\u4e3b\u9898\u6027\u7406\u89e3\u5206\u6b67\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e00\u4e9b\u8d44\u6e90\u4e25\u91cd\u6807\u6ce8\u4e0d\u8db3\u3002"}}
{"id": "2506.06985", "pdf": "https://arxiv.org/pdf/2506.06985", "abs": "https://arxiv.org/abs/2506.06985", "authors": ["Anastasia Koloskova", "Youssef Allouah", "Animesh Jha", "Rachid Guerraoui", "Sanmi Koyejo"], "title": "Certified Unlearning for Neural Networks", "categories": ["cs.LG", "cs.CR", "stat.ML"], "comment": null, "summary": "We address the problem of machine unlearning, where the goal is to remove the\ninfluence of specific training data from a model upon request, motivated by\nprivacy concerns and regulatory requirements such as the \"right to be\nforgotten.\" Unfortunately, existing methods rely on restrictive assumptions or\nlack formal guarantees. To this end, we propose a novel method for certified\nmachine unlearning, leveraging the connection between unlearning and privacy\namplification by stochastic post-processing. Our method uses noisy fine-tuning\non the retain data, i.e., data that does not need to be removed, to ensure\nprovable unlearning guarantees. This approach requires no assumptions about the\nunderlying loss function, making it broadly applicable across diverse settings.\nWe analyze the theoretical trade-offs in efficiency and accuracy and\ndemonstrate empirically that our method not only achieves formal unlearning\nguarantees but also performs effectively in practice, outperforming existing\nbaselines. Our code is available at\nhttps://github.com/stair-lab/certified-unlearningneural-networks-icml-2025", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u4f7f\u7528\u566a\u58f0\u5fae\u8c03\u6765\u786e\u4fdd\u9057\u5fd8\u4fdd\u969c\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u6709\u6548\u4e14\u65e0\u9700\u5bf9\u635f\u5931\u51fd\u6570\u7684\u5047\u8bbe\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u95ee\u9898\u548c\u6cd5\u89c4\u8981\u6c42\uff08\u5982\u201c\u88ab\u9057\u5fd8\u6743\u201d\uff09\uff0c\u9700\u8981\u5728\u8bf7\u6c42\u65f6\u4ece\u6a21\u578b\u4e2d\u79fb\u9664\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u9650\u5236\u6027\u5047\u8bbe\u6216\u7f3a\u4e4f\u6b63\u5f0f\u4fdd\u8bc1\uff0c\u56e0\u6b64\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u4f7f\u7528\u5bf9\u4fdd\u7559\u6570\u636e\u7684\u566a\u58f0\u5fae\u8c03\uff0c\u5373\u4e0d\u9700\u8981\u5220\u9664\u7684\u6570\u636e\uff0c\u4ee5\u786e\u4fdd\u53ef\u9a8c\u8bc1\u7684\u9057\u5fd8\u4fdd\u969c\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5bf9\u6f5c\u5728\u635f\u5931\u51fd\u6570\u7684\u5047\u8bbe\uff0c\u4f7f\u5176\u5177\u5907\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u9057\u5fd8\u4fdd\u969c\uff0c\u8fd8\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\u8fd0\u884c\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ecf\u8fc7\u8ba4\u8bc1\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u968f\u673a\u540e\u5904\u7406\u6765\u52a0\u5f3a\u9690\u79c1\u4fdd\u62a4\u5e76\u786e\u4fdd\u53ef\u9a8c\u8bc1\u7684\u9057\u5fd8\u4fdd\u969c\u3002\u8be5\u65b9\u6cd5\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u5177\u6709\u7406\u8bba\u4e0a\u7684\u6743\u8861\uff0c\u5e76\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u51c6\u3002"}}
{"id": "2506.06276", "pdf": "https://arxiv.org/pdf/2506.06276", "abs": "https://arxiv.org/abs/2506.06276", "authors": ["Jiatao Gu", "Tianrong Chen", "David Berthelot", "Huangjie Zheng", "Yuyang Wang", "Ruixiang Zhang", "Laurent Dinh", "Miguel Angel Bautista", "Josh Susskind", "Shuangfei Zhai"], "title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TLDR: We show for the first time that normalizing flows can be scaled\n  for high-resolution and text-conditioned image synthesis", "summary": "We present STARFlow, a scalable generative model based on normalizing flows\nthat achieves strong performance in high-resolution image synthesis. The core\nof STARFlow is Transformer Autoregressive Flow (TARFlow), which combines the\nexpressive power of normalizing flows with the structured modeling capabilities\nof Autoregressive Transformers. We first establish the theoretical universality\nof TARFlow for modeling continuous distributions. Building on this foundation,\nwe introduce several key architectural and algorithmic innovations to\nsignificantly enhance scalability: (1) a deep-shallow design, wherein a deep\nTransformer block captures most of the model representational capacity,\ncomplemented by a few shallow Transformer blocks that are computationally\nefficient yet substantially beneficial; (2) modeling in the latent space of\npretrained autoencoders, which proves more effective than direct pixel-level\nmodeling; and (3) a novel guidance algorithm that significantly boosts sample\nquality. Crucially, our model remains an end-to-end normalizing flow, enabling\nexact maximum likelihood training in continuous spaces without discretization.\nSTARFlow achieves competitive performance in both class-conditional and\ntext-conditional image generation tasks, approaching state-of-the-art diffusion\nmodels in sample quality. To our knowledge, this work is the first successful\ndemonstration of normalizing flows operating effectively at this scale and\nresolution.", "AI": {"tldr": "STARFlow\u662f\u57fa\u4e8e\u5f52\u4e00\u5316\u6d41\u7684\u751f\u6210\u6a21\u578b\uff0c\u7ed3\u5408\u81ea\u56de\u5f52\u53d8\u538b\u5668\uff0c\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\uff0c\u6837\u672c\u8d28\u91cf\u63a5\u8fd1\u4e8e\u6700\u65b0\u6269\u6563\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u5728\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u4e2d\u5b9e\u73b0\u5f3a\u6027\u80fd\u7684\u53ef\u6269\u5c55\u751f\u6210\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u7ed3\u5408\u81ea\u56de\u5f52\u53d8\u538b\u5668\u7ed3\u6784\u8fdb\u884c\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u5408\u6210\u3002\u4e3b\u8981\u901a\u8fc7\u6df1\u6d45\u8bbe\u8ba1\u3001\u6f5c\u5728\u7a7a\u95f4\u5efa\u6a21\u4ee5\u53ca\u521b\u65b0\u6307\u5bfc\u7b97\u6cd5\u6765\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u6837\u672c\u8d28\u91cf\u3002", "result": "STARFlow\u5728\u7c7b\u6761\u4ef6\u548c\u6587\u672c\u6761\u4ef6\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u6269\u6563\u6a21\u578b\u76f8\u5f53\u7684\u6837\u672c\u8d28\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u6210\u529f\u5c55\u793a\u4e86\u5f52\u4e00\u5316\u6d41\u5728\u5982\u6b64\u89c4\u6a21\u548c\u5206\u8fa8\u7387\u4e0b\u6709\u6548\u8fd0\u884c\uff0c\u8bc1\u660e\u4e86TARFlow\u7684\u7406\u8bba\u666e\u904d\u6027\u4ee5\u53ca\u6a21\u578b\u67b6\u6784\u548c\u7b97\u6cd5\u521b\u65b0\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.07309", "pdf": "https://arxiv.org/pdf/2506.07309", "abs": "https://arxiv.org/abs/2506.07309", "authors": ["Yin Huang", "Yifan Ethan Xu", "Kai Sun", "Vera Yan", "Alicia Sun", "Haidar Khan", "Jimmy Nguyen", "Mohammad Kachuee", "Zhaojiang Lin", "Yue Liu", "Aaron Colak", "Anuj Kumar", "Wen-tau Yih", "Xin Luna Dong"], "title": "ConfQA: Answer Only If You Are Confident", "categories": ["cs.CL"], "comment": "10 pages main content, 10 pages appendix, 5 figures, 7 tables", "summary": "Can we teach Large Language Models (LLMs) to refrain from hallucinating\nfactual statements? In this paper we present a fine-tuning strategy that we\ncall ConfQA, which can reduce hallucination rate from 20-40% to under 5% across\nmultiple factuality benchmarks. The core idea is simple: when the LLM answers a\nquestion correctly, it is trained to continue with the answer; otherwise, it is\ntrained to admit \"I am unsure\". But there are two key factors that make the\ntraining highly effective. First, we introduce a dampening prompt \"answer only\nif you are confident\" to explicitly guide the behavior, without which\nhallucination remains high as 15%-25%. Second, we leverage simple factual\nstatements, specifically attribute values from knowledge graphs, to help LLMs\ncalibrate the confidence, resulting in robust generalization across domains and\nquestion types. Building on this insight, we propose the Dual Neural Knowledge\nframework, which seamlessly select between internally parameterized neural\nknowledge and externally recorded symbolic knowledge based on ConfQA's\nconfidence. The framework enables potential accuracy gains to beyond 95%, while\nreducing unnecessary external retrievals by over 30%.", "AI": {"tldr": "ConfQA\u5fae\u8c03\u7b56\u7565\u6709\u6548\u964d\u4f4e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u7387\uff0c\u5e76\u63d0\u51fa\u53cc\u795e\u7ecf\u77e5\u8bc6\u6846\u67b6\u63d0\u9ad8\u51c6\u786e\u6027\u53ca\u51cf\u5c11\u5916\u90e8\u68c0\u7d22\u3002", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u4e8b\u5b9e\u6027\u95ee\u9898\u65f6\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u9648\u8ff0\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528ConfQA\u5fae\u8c03\u7b56\u7565\uff0c\u901a\u8fc7\u5f15\u5165\u51cf\u5e45\u63d0\u793a \"\u53ea\u6709\u5f53\u4f60\u81ea\u4fe1\u65f6\u624d\u56de\u7b54\" \u548c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u7b80\u5355\u4e8b\u5b9e\u8bed\u53e5\u6765\u6821\u51c6\u6a21\u578b\u7684\u81ea\u4fe1\u5ea6\u3002", "result": "ConfQA\u7b56\u7565\u5b9e\u73b0\u4e86\u5728\u591a\u4e2a\u771f\u5b9e\u6027\u57fa\u51c6\u4e0a\u7684\u5e7b\u89c9\u7387\u964d\u4f4e\u52305%\u4ee5\u4e0b\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u53cc\u795e\u7ecf\u77e5\u8bc6\u6846\u67b6\uff0c\u4f7f\u5f97\u51c6\u786e\u6027\u63d0\u5347\u523095%\u4ee5\u4e0a\uff0c\u5e76\u51cf\u5c11\u4e8630%\u4ee5\u4e0a\u7684\u4e0d\u5fc5\u8981\u7684\u5916\u90e8\u68c0\u7d22\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5fae\u8c03\u7b56\u7565ConfQA\uff0c\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u4e8b\u5b9e\u6027\u95ee\u9898\u65f6\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u4ece20-40%\u51cf\u5c11\u52305%\u4ee5\u4e0b\u3002"}}
{"id": "2506.06986", "pdf": "https://arxiv.org/pdf/2506.06986", "abs": "https://arxiv.org/abs/2506.06986", "authors": ["Austin Snyder", "Ryan Gallagher", "Boris Kovalerchuk"], "title": "Fully Explainable Classification Models Using Hyperblocks", "categories": ["cs.LG"], "comment": "7 pages, 8 figures, 6 tables", "summary": "Building on existing work with Hyperblocks, which classify data using minimum\nand maximum bounds for each attribute, we focus on enhancing interpretability,\ndecreasing training time, and reducing model complexity without sacrificing\naccuracy. This system allows subject matter experts (SMEs) to directly inspect\nand understand the model's decision logic without requiring extensive machine\nlearning expertise. To reduce Hyperblock complexity while retaining\nperformance, we introduce a suite of algorithms for Hyperblock simplification.\nThese include removing redundant attributes, removing redundant blocks through\noverlap analysis, and creating disjunctive units. These methods eliminate\nunnecessary parameters, dramatically reducing model size without harming\nclassification power. We increase robustness by introducing an interpretable\nfallback mechanism using k-Nearest Neighbor (k-NN) classifiers for points not\ncovered by any block, ensuring complete data coverage while preserving model\ntransparency. Our results demonstrate that interpretable models can scale to\nhigh-dimensional, large-volume datasets while maintaining competitive accuracy.\nOn benchmark datasets such as WBC (9-D), we achieve strong predictive\nperformance with significantly reduced complexity. On MNIST (784-D), our method\ncontinues to improve through tuning and simplification, showing promise as a\ntransparent alternative to black-box models in domains where trust, clarity,\nand control are crucial.", "AI": {"tldr": "\u672c\u6587\u6539\u8fdb\u4e86Hyperblock\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u51cf\u5c11\u590d\u6742\u6027\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u5e76\u5728\u4e0d\u727a\u7272\u51c6\u786e\u5ea6\u7684\u60c5\u51b5\u4e0b\u964d\u4f4e\u6a21\u578b\u590d\u6742\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u5957Hyperblock\u7b80\u5316\u7b97\u6cd5\uff0c\u5305\u62ec\u53bb\u9664\u5197\u4f59\u5c5e\u6027\u3001\u901a\u8fc7\u91cd\u53e0\u5206\u6790\u53bb\u9664\u5197\u4f59\u5757\u4ee5\u53ca\u521b\u5efa\u6790\u53d6\u5355\u5143\uff0c\u8fd8\u5f15\u5165\u53ef\u89e3\u91ca\u7684k-\u8fd1\u90bb\u56de\u9000\u673a\u5236\u3002", "result": "\u5728WBC\u548cMNIST\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u578b\u590d\u6742\u6027\u3002", "conclusion": "\u901a\u8fc7\u7b80\u5316Hyperblock\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5353\u8d8a\u7684\u5206\u7c7b\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u9ad8\u7ef4\u3001\u5927\u91cf\u6570\u636e\u96c6\u7684\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u62d3\u5c55\u3002"}}
{"id": "2506.06283", "pdf": "https://arxiv.org/pdf/2506.06283", "abs": "https://arxiv.org/abs/2506.06283", "authors": ["Juexiao Zhou", "Zhongyi Han", "Mankun Xin", "Xingwei He", "Guotao Wang", "Jiaoyan Song", "Gongning Luo", "Wenjia He", "Xintong Li", "Yuetan Chu", "Juanwen Chen", "Bo Wang", "Xia Wu", "Wenwen Duan", "Zhixia Guo", "Liyan Bai", "Yilin Pan", "Xuefei Bi", "Lu Liu", "Long Feng", "Xiaonan He", "Xin Gao"], "title": "Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Global population aging presents increasing challenges to healthcare systems,\nwith coronary artery disease (CAD) responsible for approximately 17.8 million\ndeaths annually, making it a leading cause of global mortality. As CAD is\nlargely preventable, early detection and proactive management are essential. In\nthis work, we introduce DigitalShadow, an advanced early warning system for\nCAD, powered by a fine-tuned facial foundation model. The system is pre-trained\non 21 million facial images and subsequently fine-tuned into LiveCAD, a\nspecialized CAD risk assessment model trained on 7,004 facial images from 1,751\nsubjects across four hospitals in China. DigitalShadow functions passively and\ncontactlessly, extracting facial features from live video streams without\nrequiring active user engagement. Integrated with a personalized database, it\ngenerates natural language risk reports and individualized health\nrecommendations. With privacy as a core design principle, DigitalShadow\nsupports local deployment to ensure secure handling of user data.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aDigitalShadow\u7684\u5148\u8fdb\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\uff0c\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684\u9762\u90e8\u6a21\u578b\u6765\u8fdb\u884cCAD\u98ce\u9669\u8bc4\u4f30\uff0c\u53ef\u4ee5\u65e0\u63a5\u89e6\u5730\u5206\u6790\u9762\u90e8\u7279\u5f81\uff0c\u5e76\u751f\u6210\u5065\u5eb7\u5efa\u8bae\uff0c\u786e\u4fdd\u6570\u636e\u9690\u79c1\u3002", "motivation": "CAD\u662f\u5168\u7403\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\uff0c\u5e76\u4e14\u5927\u591a\u6570\u53ef\u4ee5\u9884\u9632\uff0c\u56e0\u6b64\u65e9\u671f\u68c0\u6d4b\u548c\u4e3b\u52a8\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u5fae\u8c03\u7684\u9762\u90e8\u57fa\u7840\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u9996\u5148\u57282100\u4e07\u5f20\u9762\u90e8\u56fe\u50cf\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u6765\u81ea\u4e2d\u56fd\u56db\u5bb6\u533b\u9662\u76841751\u540d\u53d7\u8bd5\u8005\u76847004\u5f20\u9762\u90e8\u56fe\u50cf\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u6210\u4e3a\u4e13\u95e8\u7684CAD\u98ce\u9669\u8bc4\u4f30\u6a21\u578bLiveCAD\u3002", "result": "DigitalShadow\u53ef\u4ee5\u88ab\u96c6\u6210\u5230\u4e2a\u6027\u5316\u6570\u636e\u5e93\u4e2d\uff0c\u4ee5\u751f\u6210\u81ea\u7136\u8bed\u8a00\u98ce\u9669\u62a5\u544a\u548c\u4e2a\u6027\u5316\u7684\u5065\u5eb7\u5efa\u8bae\uff0c\u65e0\u9700\u7528\u6237\u4e3b\u52a8\u53c2\u4e0e\u3002", "conclusion": "DigitalShadow\u7cfb\u7edf\u80fd\u591f\u88ab\u5b89\u5168\u5730\u672c\u5730\u90e8\u7f72\uff0c\u4ee5\u786e\u4fdd\u7528\u6237\u6570\u636e\u7684\u5b89\u5168\u5904\u7406\u3002"}}
