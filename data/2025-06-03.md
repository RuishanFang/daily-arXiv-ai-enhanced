<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 56]
- [cs.AI](#cs.AI) [Total: 56]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.LG](#cs.LG) [Total: 57]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Amadeus-Verbo Technical Report: The powerful Qwen2.5 family models trained in Portuguese](https://arxiv.org/abs/2506.00019)
*William Alberto Cruz-Castañeda,Marcellus Amadeus*

Main category: cs.CL

TL;DR: 介绍了Amadeus Verbo，巴西葡萄牙语的大型语言模型系列，展示了如何微调模型实现开源。


<details>
  <summary>Details</summary>
Motivation: 开发适用于巴西葡萄牙语的大型语言模型，并实现其开源化，以满足多样化的使用需求。

Method: 开发了一系列不同参数规模的语言模型，并进行基础微调、合并和指令微调。

Result: 成功开发了一个包含多个参数规模的巴西葡萄牙语大型语言模型系列，并在HuggingFace上开源。

Conclusion: 展示了如何轻松微调基础模型来实现巴西葡萄牙语的大型语言模型的开源开发。

Abstract: This report introduces the experience of developing Amadeus Verbo, a family
of large language models for Brazilian Portuguese. To handle diverse use cases,
Amadeus Verbo includes base-tuned, merged, and instruction-tuned models in
sizes of 0.5B, 1.5B, 3B, 7B, 14B, 32B, and 72B parameters. Thus, the main
objective is to show how easy it is to fine-tune foundation models to
democratize the open-source development of Brazilian Portuguese LLMs when data
and resources are available. Amadeus-Verbo family models are all available at
HuggingFace at
https://huggingface.co/collections/amadeusai/amadeus-verbo-qwen25-67cf2e7aae69ce2b3bcdcfda.

</details>


### [2] [Scaling Physical Reasoning with the PHYSICS Dataset](https://arxiv.org/abs/2506.00022)
*Shenghe Zheng,Qianjia Cheng,Junchi Yao,Mengsong Wu,haonan he,Ning Ding,Yu Cheng,Shuyue Hu,Lei Bai,Dongzhan Zhou,Ganqu Cui,Peng Ye*

Main category: cs.CL

TL;DR: 本文引入了PHYSICS数据集，为LLM在物理领域的能力提升提供了方法，并揭示了当前模型在物理任务处理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管物理在现实世界的理解中至关重要，但是在学术和工业界却没有得到足够的关注。本文通过引入一个名为PHYSICS的数据集来解决这一问题，促进模型物理推理能力的提升。

Method: 我们将数据集分为训练集和测试集，并为训练数据提供由强大的推理模型生成的推理路径以支持模型训练。同时，引入了针对物理问题的Rule+Model评价框架，以平衡效率与准确性。

Result: 我们通过评估当前最先进的开源和专有模型，揭示了这些模型在处理物理相关任务上的局限性。所引入的数据集和评价方法展示了其在物理领域推进LLM发展的潜力。

Conclusion: 当前最先进的模型在处理与物理相关的任务上存在局限性，希望通过这个数据集和评价方法能推动LLM在物理领域的发展。

Abstract: Large Language Models (LLMs) have achieved remarkable progress on advanced
reasoning tasks such as mathematics and coding competitions. Meanwhile,
physics, despite being both reasoning-intensive and essential to real-world
understanding, received limited academic and industrial attention. This paper
introduces PHYSICS, a dataset containing 16,568 high-quality physics problems
spanning subjects and difficulty levels, to facilitate this issue.
Specifically, PHYSICS is curated with exercises from over 100 textbooks through
a carefully designed pipeline for quality control. It covers five major physics
domains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern
Physics. It also spans a wide range of difficulty levels, from high school to
graduate-level physics courses. To utilize the data for improving and
evaluating the model's physical reasoning capabilities, we split the dataset
into training and test sets, and provide reasoning paths generated by powerful
reasoning models for the training data to facilitate model training. In
addition, for the evaluation part, we find that existing evaluation frameworks
exhibit biases in aspects such as units, simplification, and precision in
physics domain. To balance efficiency and accuracy, we introduce a Rule+Model
evaluation framework tailored to physics problems. Our evaluations on current
state-of-the-art open-source and proprietary models highlight the limitations
of current models in handling physics-related tasks. We hope that our dataset
and evaluation methodology will jointly advance the development of LLMs in the
field of physics.

</details>


### [3] [From Mathematical Reasoning to Code: Generalization of Process Reward Models in Test-Time Scaling](https://arxiv.org/abs/2506.00027)
*Zhengyu Chen,Yudong Wang,Teng Xiao,Ruochen Zhou,Xuesheng Yang,Wei Wang,Zhifang Sui,Jingang Wang*

Main category: cs.CL

TL;DR: 本研究分析了过程奖励模型（PRMs）的训练、可扩展性和泛化，发现随着规模增大，性能增益递减；数据集多样性提高效率；测试中蒙特卡洛树搜索最有效，Best-of-N Sampling为资源有限替代方案。PRMs在数学数据集上的表现显示强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 近期在提升大型语言模型推理能力方面的进展强调了过程奖励模型（PRMs）的有效性。通过结构化反馈机制来解决中间错误。

Method: 分析了PRMs的训练方法、可扩展性和泛化能力，并调查了预训练与奖励模型训练的FLOPs之间的相互作用，以及在复杂推理任务中的效率和准确性。

Result: 即使PRM规模增加，性能增益也会呈现递减模式，强调了平衡模型大小和计算成本的重要性。训练数据集的多样性显著影响PRM的性能，强调了多样化数据对提高准确性和效率的重要性。测试时的扩展策略中，蒙特卡洛树搜索在计算资源充裕时最有效，而Best-of-N Sampling在资源有限时提供实用替代方案。

Conclusion: PRMs在数学数据集上的性能与为代码生成量身定制的模型相当，展示了跨领域的强大泛化能力。研究发现，PRMs倾向于选择具有相似基础模式的响应，进一步推动其优化。

Abstract: Recent advancements in improving the reasoning capabilities of Large Language
Models have underscored the efficacy of Process Reward Models (PRMs) in
addressing intermediate errors through structured feedback mechanisms. This
study analyzes PRMs from multiple perspectives, including training
methodologies, scalability, and generalization capabilities. We investigate the
interplay between pre-training and reward model training FLOPs to assess their
influence on PRM efficiency and accuracy in complex reasoning tasks. Our
analysis reveals a pattern of diminishing returns in performance with
increasing PRM scale, highlighting the importance of balancing model size and
computational cost. Furthermore, the diversity of training datasets
significantly impacts PRM performance, emphasizing the importance of diverse
data to enhance both accuracy and efficiency. We further examine test-time
scaling strategies, identifying Monte Carlo Tree Search as the most effective
method when computational resources are abundant, while Best-of-N Sampling
serves as a practical alternative under resource-limited conditions. Notably,
our findings indicate that PRMs trained on mathematical datasets exhibit
performance comparable to those tailored for code generation, suggesting robust
cross-domain generalization. Employing a gradient-based metric, we observe that
PRMs exhibit a preference for selecting responses with similar underlying
patterns, further informing their optimization.

</details>


### [4] [Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists](https://arxiv.org/abs/2506.00042)
*Yue Cui,Liuyi Yao,Shuchang Tao,Weijie Shi,Yaliang Li,Bolin Ding,Xiaofang Zhou*

Main category: cs.CL

TL;DR: 论文提出了HiTEC框架，通过两级错误检查清单提高参数填写准确性，显著改善工具调用效果。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在调用外部工具和API时，由于参数填写错误而影响效率的问题。

Method: 该研究提出了HiTEC框架，包括HiTEC-In Context Learning和HiTEC-Kahneman-Tversky Optimization两种部署方法。

Result: 在五个公共数据集上的广泛实验表明，HiTEC框架显著提高了参数填写准确性和工具调用成功率。

Conclusion: 提出的HiTEC框架显著提高了参数填写的准确性和工具调用的成功率。

Abstract: Large language models (LLMs) have significantly advanced natural language
processing, particularly through the integration of external tools and APIs.
However, their effectiveness is frequently hampered by parameter mis-filling
during tool calling. In this paper, we propose the Hierarchical Tool Error
Checklist (HiTEC) framework to systematically diagnose and mitigate
tool-calling errors without relying on extensive real-world interactions. HiTEC
introduces a two-tiered approach: a global error checklist that identifies
common, cross-tool issues, and a local error checklist that targets
tool-specific and contextual failures. Building on this structure, we propose
two deployments: HiTEC-In Context Learning (HiTEC-ICL) and
HiTEC-Kahneman-Tversky Optimization (HiTEC-KTO). HiTEC-ICL embeds the global
checklist in the initial prompts and leverages a two-round conversational
interaction to dynamically refine parameter handling, while HiTEC-KTO generates
high-quality negative examples to drive fine-tuning via preference-based
optimization. Extensive experiments across five public datasets demonstrate
that our framework significantly improves parameter-filling accuracy and
tool-calling success rates compared to baseline methods.

</details>


### [5] [Unraveling SITT: Social Influence Technique Taxonomy and Detection with LLMs](https://arxiv.org/abs/2506.00061)
*Wiktoria Mieleszczenko-Kowszewicz,Beata Bajcar,Aleksander Szczęsny,Maciej Markiewicz,Jolanta Babiak,Berenika Dyczek,Przemysław Kazienko*

Main category: cs.CL

TL;DR: 研究提出了一种新的社会影响技术分类法（SITT），评估了LLMs在检测和分类自然对话中的社会影响策略上的能力，发现现有模型在处理细微语言线索方面能力有限。


<details>
  <summary>Details</summary>
Motivation: 构建和评估LLMs检测文本中细微社会影响能力，以识别当前模型的局限性并引发对领域特定微调的重视。

Method: 使用层级多标签分类设置，基准测试五种LLM，包括GPT-4o、Claude 3.5、Llama-3.1、Mixtral和PLLuM，通过SITT数据集进行评估。

Result: Claude 3.5在类别检测上取得一定成功，F1分数为0.45，然而总体性能有限，尤其是在上下文敏感的技术领域。

Conclusion: 研究表明当前的LLMs在检测复杂的社会影响技术时存在显著限制，尤其是对于敏感上下文技术不够敏感，强调了领域特定微调的重要性。

Abstract: In this work we present the Social Influence Technique Taxonomy (SITT), a
comprehensive framework of 58 empirically grounded techniques organized into
nine categories, designed to detect subtle forms of social influence in textual
content. We also investigate the LLMs ability to identify various forms of
social influence. Building on interdisciplinary foundations, we construct the
SITT dataset -- a 746-dialogue corpus annotated by 11 experts in Polish and
translated into English -- to evaluate the ability of LLMs to identify these
techniques. Using a hierarchical multi-label classification setup, we benchmark
five LLMs, including GPT-4o, Claude 3.5, Llama-3.1, Mixtral, and PLLuM. Our
results show that while some models, notably Claude 3.5, achieved moderate
success (F1 score = 0.45 for categories), overall performance of models remains
limited, particularly for context-sensitive techniques. The findings
demonstrate key limitations in current LLMs' sensitivity to nuanced linguistic
cues and underscore the importance of domain-specific fine-tuning. This work
contributes a novel resource and evaluation example for understanding how LLMs
detect, classify, and potentially replicate strategies of social influence in
natural dialogues.

</details>


### [6] [Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling](https://arxiv.org/abs/2506.00064)
*Jiayi Zeng,Yizhe Feng,Mengliang He,Wenhui Lei,Wei Zhang,Zeming Liu,Xiaoming Shi,Aimin Zhou*

Main category: cs.CL

TL;DR: The paper presents a new benchmark (Mis-prompt) for proactive error handling in LLMs, revealing current models' limitations and showing that error handling instances enhance performance.


<details>
  <summary>Details</summary>
Motivation: In real-world scenarios, explicit error-handling instructions are often unavailable, posing a challenge for LLMs to conduct proactive error handling.

Method: Introduce a new benchmark called Mis-prompt, which includes four evaluation tasks, an error category taxonomy, and an evaluation dataset. Analyze LLMs' performance on the benchmark.

Result: Current LLMs perform poorly on proactive error handling, but the inclusion of error handling instances improves their performance.

Conclusion: SFT on error handling instances can enhance LLMs' capabilities for proactive error handling.

Abstract: Large language models (LLMs) have demonstrated significant advancements in
error handling. Current error-handling works are performed in a passive manner,
with explicit error-handling instructions. However, in real-world scenarios,
explicit error-handling instructions are usually unavailable. In this paper,
our work identifies this challenge as how to conduct proactive error handling
without explicit error handling instructions. To promote further research, this
work introduces a new benchmark, termed Mis-prompt, consisting of four
evaluation tasks, an error category taxonomy, and a new evaluation dataset.
Furthermore, this work analyzes current LLMs' performance on the benchmark, and
the experimental results reveal that current LLMs show poor performance on
proactive error handling, and SFT on error handling instances improves LLMs'
proactive error handling capabilities. The dataset will be publicly available.

</details>


### [7] [You Prefer This One, I Prefer Yours: Using Reference Words is Harder Than Vocabulary Words for Humans and Multimodal Language Models](https://arxiv.org/abs/2506.00065)
*Dota Tianai Dong,Yifan Luo,Po-Ya Angela Wang,Asli Ozyurek,Paula Rubio-Fernandez*

Main category: cs.CL

TL;DR: 研究比较了人类与多模态语言模型对不同词类的使用，发现模型在使用物主代词和指示代词上困难重重，主要源于视角转换和空间推理的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态语言模型越来越具有人类交流的特性，但它们对参考词的使用能力仍然没有得到足够的关注，而参考词在日常交流中非常普遍。

Method: 将人类与七个最先进的多模态语言模型在三种认知需求逐渐增加的词类的使用上进行比较：词汇、物主代词（例如“我的”与“你的”）以及指示代词（例如“这个”与“那个”）。

Result: 多模态语言模型在词汇任务中接近人类水平表现，但在使用物主代词和指示代词上存在显著不足。这些困难源于模型在视角转换和空间推理上的局限性。尽管通过提示工程可以改善模型在物主代词使用上的表现，但指示代词的使用仍远低于人类水平。

Conclusion: 当前的自然语言处理系统在使用需要语用学和社会认知的语法形式上仍然面临明显挑战。

Abstract: Multimodal language models (MLMs) increasingly communicate in human-like
ways, yet their ability to use reference words remains largely overlooked
despite their ubiquity in everyday communication. Our study addresses this gap
by comparing human and MLM use of three word classes with increasing cognitive
demands: vocabulary words, possessive pronouns (`mine' vs `yours'), and
demonstrative pronouns (`this one' vs `that one'). Evaluating seven
state-of-the-art MLMs against human participants, we observe a clear difficulty
hierarchy: while MLMs approach human-level performance on the vocabulary task,
they show substantial deficits with possessives and demonstratives. Our
analysis reveals these difficulties stem from limitations in perspective-taking
and spatial reasoning. Although prompt engineering improved model performance
on possessive use, demonstrative use remained well below human-level
competence. These findings provide theoretical and empirical evidence that
producing grammatical forms requiring pragmatics and social cognition remains a
clear challenge in current NLP systems.

</details>


### [8] [Probing Politico-Economic Bias in Multilingual Large Language Models: A Cultural Analysis of Low-Resource Pakistani Languages](https://arxiv.org/abs/2506.00068)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该研究分析了13个LLMs在巴基斯坦五种语言中表现出的政治偏见，发现它们既受到西方数据的影响，又受文化调节影响，呼吁建立多语言偏见审计框架。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在非西方和低资源多语言环境中的政治经济偏见，特别是在巴基斯坦的五种语言中。

Method: 提出一个新的框架，将改编的政治罗盘测试与多层次的框架分析相结合。该方法结合了对经济（左右翼）和社会（自由主义-权威主义）轴上的政治倾向的定量评估，以及通过内容、风格和重点的框架定性分析。

Result: 结果显示，LLMs主要与自由左派价值观一致，反映了西方训练数据的影响，但在地区语言中表现出显著的向权威主义框架的转变，表明强烈的文化调节效应。同时识别出一致的特定模型偏见特征和由语言制约的意识形态表达变化。

Conclusion: 研究表明迫切需要文化基础的多语言偏见审计框架，以应对非西方和低资源环境下LLMs的偏见问题。

Abstract: Large Language Models (LLMs) are increasingly shaping public discourse, yet
their politico-economic biases remain underexamined in non-Western and
low-resource multilingual contexts. This paper presents a systematic analysis
of political bias in 13 state-of-the-art LLMs across five low-resource
languages spoken in Pakistan: Urdu, Punjabi, Sindhi, Balochi, and Pashto. We
propose a novel framework that integrates an adapted Political Compass Test
(PCT) with a multi-level framing analysis. Our method combines quantitative
assessment of political orientation across economic (left-right) and social
(libertarian-authoritarian) axes with qualitative analysis of framing through
content, style, and emphasis. We further contextualize this analysis by
aligning prompts with 11 key socio-political themes relevant to Pakistani
society. Our results reveal that LLMs predominantly align with liberal-left
values, echoing Western training data influences, but exhibit notable shifts
toward authoritarian framing in regional languages, suggesting strong cultural
modulation effects. We also identify consistent model-specific bias signatures
and language-conditioned variations in ideological expression. These findings
show the urgent need for culturally grounded, multilingual bias auditing
frameworks.

</details>


### [9] [Evaluating the Sensitivity of LLMs to Prior Context](https://arxiv.org/abs/2506.00069)
*Robert Hankache,Kingsley Nketia Acheampong,Liang Song,Marek Brynda,Raad Khraishi,Greig A. Cowan*

Main category: cs.CL

TL;DR: 研究开发了新的基准测试以评估LLM在多轮交互中的表现，结果表明上下文变化会导致显著性能下降，但可以通过策略性调整上下文来改善。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要集中在单轮QA任务上，未能捕捉多轮交互的影响，因此需要引入新的基准来系统地研究此前上下文的影响。

Method: 引入了一系列的新基准，系统地改变先前上下文的数量和性质，并评估多种LLM在这些基准下对上下文变化的敏感性。

Result: 研究发现，LLM在多轮交互中表现可能显著下降，某些模型下降幅度高达73%，即使是性能优异的模型如GPT-4o也出现了最高32%的准确率下降。然而，通过策略性地放置任务描述，准确率可提升至3.5倍。

Conclusion: 研究揭示了LLM在多轮对话中存在显著的性能下降，强调需要更强大的策略来设计、评估和减轻上下文相关的敏感性。

Abstract: As large language models (LLMs) are increasingly deployed in multi-turn
dialogue and other sustained interactive scenarios, it is essential to
understand how extended context affects their performance. Popular benchmarks,
focusing primarily on single-turn question answering (QA) tasks, fail to
capture the effects of multi-turn exchanges. To address this gap, we introduce
a novel set of benchmarks that systematically vary the volume and nature of
prior context. We evaluate multiple conventional LLMs, including GPT, Claude,
and Gemini, across these benchmarks to measure their sensitivity to contextual
variations. Our findings reveal that LLM performance on multiple-choice
questions can degrade dramatically in multi-turn interactions, with performance
drops as large as 73% for certain models. Even highly capable models such as
GPT-4o exhibit up to a 32% decrease in accuracy. Notably, the relative
performance of larger versus smaller models is not always predictable.
Moreover, the strategic placement of the task description within the context
can substantially mitigate performance drops, improving the accuracy by as much
as a factor of 3.5. These findings underscore the need for robust strategies to
design, evaluate, and mitigate context-related sensitivity in LLMs.

</details>


### [10] [Gaussian mixture models as a proxy for interacting language models](https://arxiv.org/abs/2506.00077)
*Edward Wang,Tianyu Wang,Avanti Athreya,Vince Lyzinski,Carey E. Priebe*

Main category: cs.CL

TL;DR: 本文提出互动高斯混合模型（GMMs）作为复杂LLMs的替代方案，并成功捕捉到LLMs的动态特征，分析了GMMs与LLMs的异同及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 利用检索增强生成（RAG）技术的LLMs在许多方面展示出与人类能力相匹配的行为，特别是在社会科学中用于研究大型实验不可行时的人类行为。但由于LLMs依赖复杂且耗费计算的算法，因而提出互动GMMs作为替代方案。

Method: 引入互动高斯混合模型（GMMs）并将其与LLMs的实验模拟进行对比分析，尤其是这些模型在接收到其他LLMs反馈时的更新和响应。

Result: 互动高斯混合模型能够成功捕捉互动大型语言模型中的重要动态特征，并揭示了LLMs和GMMs之间的关键相似性和差异。

Conclusion: 高斯混合模型（GMMs）可捕捉到互动大型语言模型（LLMs）的动态特征，并能用于替代复杂而耗费计算资源的LLMs框架。论文讨论了GMMs的优势、可能的修改以及未来的研究方向。

Abstract: Large language models (LLMs) are a powerful tool with the ability to match
human capabilities and behavior in many settings. Retrieval-augmented
generation (RAG) further allows LLMs to generate diverse output depending on
the contents of their RAG database. This motivates their use in the social
sciences to study human behavior between individuals when large-scale
experiments are infeasible. However, LLMs depend on complex, computationally
expensive algorithms. In this paper, we introduce interacting Gaussian mixture
models (GMMs) as an alternative to similar frameworks using LLMs. We compare a
simplified model of GMMs to select experimental simulations of LLMs whose
updating and response depend on feedback from other LLMs. We find that
interacting GMMs capture important features of the dynamics in interacting
LLMs, and we investigate key similarities and differences between interacting
LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture
models, potential modifications, and future research directions.

</details>


### [11] [COSMIC: Generalized Refusal Direction Identification in LLM Activations](https://arxiv.org/abs/2506.00085)
*Vincent Siu,Nicholas Crispino,Zihao Yu,Sam Pan,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: COSMIC通过余弦相似度独立于模型输出来识别和操控行为方向，提升了模型在广泛条件下的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预设模板或需要人工分析，难以有效识别行为。

Method: 使用余弦相似度进行方向选择，并自动识别可行的方向和目标层。

Result: 在不依赖特定拒绝行为假设的情况下，COSMIC表现出与现有方法相当的操控性能。

Conclusion: COSMIC identifies rejection directions and steers models towards safer behavior without increasing false refusals, proving robust in various alignment conditions.

Abstract: Large Language Models (LLMs) encode behaviors such as refusal within their
activation space, yet identifying these behaviors remains a significant
challenge. Existing methods often rely on predefined refusal templates
detectable in output tokens or require manual analysis. We introduce
\textbf{COSMIC} (Cosine Similarity Metrics for Inversion of Concepts), an
automated framework for direction selection that identifies viable steering
directions and target layers using cosine similarity - entirely independent of
model outputs. COSMIC achieves steering performance comparable to prior methods
without requiring assumptions about a model's refusal behavior, such as the
presence of specific refusal tokens. It reliably identifies refusal directions
in adversarial settings and weakly aligned models, and is capable of steering
such models toward safer behavior with minimal increase in false refusals,
demonstrating robustness across a wide range of alignment conditions.

</details>


### [12] [SwitchLingua: The First Large-Scale Multilingual and Multi-Ethnic Code-Switching Dataset](https://arxiv.org/abs/2506.00087)
*Peng Xie,Xingyuan Liu,Tsz Wai Chan,Yequan Bie,Yangqiu Song,Yang Wang,Hao Chen,Kani Chen*

Main category: cs.CL

TL;DR: 提出LinguaMaster框架和SwitchLingua数据集，并发明SAER评估指标。


<details>
  <summary>Details</summary>
Motivation: 面对全球对多语言应用的日益增长的需求以及现有单语言数据集的不足，亟需一个类似于图像领域ImageNet的大规模、多样化的基准。

Method: 引入LinguaMaster框架进行大规模多语言数据合成，并创建SwitchLingua数据集，同时提出SAER作为新的评估指标。

Result: 创建了第一个大规模多语言和多民族代码转换数据集SwitchLingua，同时提出了SAER作为新的评估指标，以提供更准确的系统性能评估。

Conclusion: LinguaMaster和SwitchLingua为多语言和多民族代码转换研究提供了一个重要的基础资源，且SAER可以更准确地评估ASR系统的性能。

Abstract: Code-switching (CS) is the alternating use of two or more languages within a
conversation or utterance, often influenced by social context and speaker
identity. This linguistic phenomenon poses challenges for Automatic Speech
Recognition (ASR) systems, which are typically designed for a single language
and struggle to handle multilingual inputs. The growing global demand for
multilingual applications, including Code-Switching ASR (CSASR), Text-to-Speech
(CSTTS), and Cross-Lingual Information Retrieval (CLIR), highlights the
inadequacy of existing monolingual datasets.
  Although some code-switching datasets exist, most are limited to bilingual
mixing within homogeneous ethnic groups, leaving a critical need for a
large-scale, diverse benchmark akin to ImageNet in computer vision.
  To bridge this gap, we introduce \textbf{LinguaMaster}, a multi-agent
collaboration framework specifically designed for efficient and scalable
multilingual data synthesis. Leveraging this framework, we curate
\textbf{SwitchLingua}, the first large-scale multilingual and multi-ethnic
code-switching dataset, including: (1) 420K CS textual samples across 12
languages, and (2) over 80 hours of audio recordings from 174 speakers
representing 18 countries/regions and 63 racial/ethnic backgrounds, based on
the textual data. This dataset captures rich linguistic and cultural diversity,
offering a foundational resource for advancing multilingual and multicultural
research. Furthermore, to address the issue that existing ASR evaluation
metrics lack sensitivity to code-switching scenarios, we propose the
\textbf{Semantic-Aware Error Rate (SAER)}, a novel evaluation metric that
incorporates semantic information, providing a more accurate and context-aware
assessment of system performance.

</details>


### [13] [HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs](https://arxiv.org/abs/2506.00088)
*Qing Li,Jiahui Geng,Zongxiong Chen,Derui Zhu,Yuxia Wang,Congbo Ma,Chenyang Lyu,Fakhri Karray*

Main category: cs.CL

TL;DR: HD-NDEs use neural differential equations to improve hallucination detection in LLMs, achieving over 14% AUC-ROC improvement on the True-False dataset.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of hallucination in large language models, especially when non-factual information occurs early or mid-sequence, where current methods like SAPLMA are less effective.

Method: The proposed method, HD-NDEs, utilizes neural differential equations to model the dynamic system in the latent space of large language models, which are then mapped to classify truthfulness.

Result: HD-NDEs prove to be highly effective in detecting hallucinations across various datasets and models, with significant improvements over current state-of-the-art methods.

Conclusion: HD-NDEs significantly improve the detection of hallucination in large language models, particularly outperforming existing methods by over 14% in AUC-ROC on the True-False dataset.

Abstract: In recent years, large language models (LLMs) have made remarkable
advancements, yet hallucination, where models produce inaccurate or non-factual
statements, remains a significant challenge for real-world deployment. Although
current classification-based methods, such as SAPLMA, are highly efficient in
mitigating hallucinations, they struggle when non-factual information arises in
the early or mid-sequence of outputs, reducing their reliability. To address
these issues, we propose Hallucination Detection-Neural Differential Equations
(HD-NDEs), a novel method that systematically assesses the truthfulness of
statements by capturing the full dynamics of LLMs within their latent space.
Our approaches apply neural differential equations (Neural DEs) to model the
dynamic system in the latent space of LLMs. Then, the sequence in the latent
space is mapped to the classification space for truth assessment. The extensive
experiments across five datasets and six widely used LLMs demonstrate the
effectiveness of HD-NDEs, especially, achieving over 14% improvement in AUC-ROC
on the True-False dataset compared to state-of-the-art techniques.

</details>


### [14] [Writing-Zero: Bridge the Gap Between Non-verifiable Problems and Verifiable Rewards](https://arxiv.org/abs/2506.00103)
*Xun Lu*

Main category: cs.CL

TL;DR: 该研究提出了一种基于RLVR的训练方法，通过写作原则为基础的生成奖励模型和自举相对策略优化算法，提高语言模型在非可验证任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法对于非可验证任务（如创意写作和开放式对话）的质量评估具有主观性，缺乏确定的参考，这导致了奖励黑客攻击问题，如过度解释和长度偏好。我们旨在弥合非可验证任务与可验证奖励之间的差距。

Method: 我们提出了一种基于RLVR的统一训练范式，通过引入写作原则为基础的成对生成奖励模型（GenRM）和一种新颖的自举相对策略优化（BRPO）算法来实现。

Result: 我们的研究表明，与标量奖励基线相比，Writing-Zero在鲁棒写作能力上表现出持续改进和对奖励黑客攻击的强大抵抗力。此外，我们的方法在内部和开源写作基准测试中取得了竞争性结果。

Conclusion: 我们的研究结果表明，可以在RLVR框架下统一基于规则、基于参考和无参考的奖励建模，从而为所有语言任务提供一个全面且可扩展的RL训练范式。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has enabled large
language models (LLMs) to achieve remarkable breakthroughs in reasoning tasks
with objective ground-truth answers, such as mathematics and code generation.
However, a significant gap remains for non-verifiable tasks, like creative
writing and open-ended dialogue, where quality assessment is inherently
subjective and lacks definitive references. Existing approaches for these
domains often rely on scalar reward models trained with human preferences,
which suffer from limited generalization and are prone to reward hacking, such
as over-explanation and length bias. In this work, we propose a unified
RLVR-based training paradigm that bridges the gap between non-verifiable tasks
and verifiable rewards. We introduce a writing-principle-based pairwise
Generative Reward Model (GenRM) and a novel Bootstrapped Relative Policy
Optimization (BRPO) algorithm. The pairwise writing GenRM leverages
self-principled critique to transform subjective assessments into reliable,
verifiable rewards, while BRPO enables dynamic, reference-free pairwise
comparison by leveraging a bootstrapped response as temporary reference from
within group rollouts during RL training. Our approach empowers LLMs to develop
robust writing capabilities without supervised fine-tuning, as demonstrated by
Writing-Zero, which shows consistent improvement and strong resistance to
reward hacking compared to scalar reward baselines. Furthermore, our method
achieves competitive results on both in-house and open-source writing
benchmarks. Our findings suggest the potential to unify rule-based,
reference-based, and reference-free reward modeling under the RLVR framework,
thus paving the way for a comprehensive and scalable RL training paradigm
applicable across all language tasks.

</details>


### [15] [Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models](https://arxiv.org/abs/2506.00134)
*Fardin Ahsan Sakib,Ziwei Zhu,Karen Trister Grace,Meliha Yetisgen,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 研究揭示了LLMs在提取SDOH时的错误和偏见，并评估了减少这些错误预测的策略。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在临床文本中提取社会健康决定因素的可靠性，特别是药物状态的提取。

Method: 使用SHAC数据集中的MIMIC部分，研究药物使用状态的提取。

Result: 发现仅仅提到酒精或吸烟时，模型可能错误预测为当前/过去的药物使用，同时揭示出性别上模型性能的不平等。

Conclusion: 通过研究发现，LLMs在提取社会健康决定因素（SDOH）时可能受表面线索的误导，从而导致错误预测。

Abstract: Social determinants of health (SDOH) extraction from clinical text is
critical for downstream healthcare analytics. Although large language models
(LLMs) have shown promise, they may rely on superficial cues leading to
spurious predictions. Using the MIMIC portion of the SHAC (Social History
Annotation Corpus) dataset and focusing on drug status extraction as a case
study, we demonstrate that mentions of alcohol or smoking can falsely induce
models to predict current/past drug use where none is present, while also
uncovering concerning gender disparities in model performance. We further
evaluate mitigation strategies - such as prompt engineering and
chain-of-thought reasoning - to reduce these false positives, providing
insights into enhancing LLM reliability in health domains.

</details>


### [16] [LaMP-QA: A Benchmark for Personalized Long-form Question Answering](https://arxiv.org/abs/2506.00137)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: 本文推出了LaMP-QA基准，用于评估个性化长文本回答生成，通过综合评估证明个性化背景能显著提升性能，并支持广泛的未来研究。


<details>
  <summary>Details</summary>
Motivation: 个性化在用户中心的问题回答系统中至关重要，但在回答生成中的研究相对较少，主要由于缺乏训练和评估资源。

Method: 我们提出了LaMP-QA基准，涵盖艺术与娱乐、生活方式与个人发展以及社会与文化三个主要类别的提问。我们进行了综合的人类和自动评估，比较多种评估策略以测量个性化回复与人类偏好的对齐度。

Result: 研究结果表明，利用所提供的个性化背景可以将性能提升高达39%，基准已公开发布以支持未来研究。

Conclusion: 引入的LaMP-QA基准有助于评估个性化长文本回答生成，从而弥补了个性化问答系统研究中的资源不足问题。通过综合评估，我们证明个性化背景显著提升性能。

Abstract: Personalization is essential for question answering systems that are
user-centric. Despite its importance, personalization in answer generation has
been relatively underexplored. This is mainly due to lack of resources for
training and evaluating personalized question answering systems. We address
this gap by introducing LaMP-QA -- a benchmark designed for evaluating
personalized long-form answer generation. The benchmark covers questions from
three major categories: (1) Arts & Entertainment, (2) Lifestyle & Personal
Development, and (3) Society & Culture, encompassing over 45 subcategories in
total. To assess the quality and potential impact of the LaMP-QA benchmark for
personalized question answering, we conduct comprehensive human and automatic
evaluations, to compare multiple evaluation strategies for evaluating generated
personalized responses and measure their alignment with human preferences.
Furthermore, we benchmark a number of non-personalized and personalized
approaches based on open-source and proprietary large language models (LLMs).
Our results show that incorporating the personalized context provided leads to
performance improvements of up to 39%. The benchmark is publicly released to
support future research in this area.

</details>


### [17] [Vedavani: A Benchmark Corpus for ASR on Vedic Sanskrit Poetry](https://arxiv.org/abs/2506.00145)
*Sujeet Kumar,Pretam Ray,Abhinay Beerukuri,Shrey Kamoji,Manoj Balaji Jagadeeshan,Pawan Goyal*

Main category: cs.CL

TL;DR: 本文介绍了首个专注于梵文吠陀诗歌的自动语音识别（ASR）研究，提供了大量的标记音频数据并进行了基准测试，发现IndicWhisper表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索如何开发一种有效的梵文自动语音识别（ASR）系统，尤其是能够捕捉其诗歌形式复杂特征的系统。

Method: 介绍了Vedavani，这是第一个专注于梵文吠陀诗歌的综合ASR研究，提出了一个54小时的梵文ASR数据集，包含来自《梨俱吠陀》和《阿闼婆吠陀》的30,779个标记音频样本。并在各种最新的多语言语音模型上进行了基准测试。

Result: 实验表明，IndicWhisper在多个最新技术模型中表现最佳。

Conclusion: 研究为梵文的ASR提出了一个新的方向，尤其是其诗歌形式的复杂特征，并提供了一个新的数据集以供基准测试。

Abstract: Sanskrit, an ancient language with a rich linguistic heritage, presents
unique challenges for automatic speech recognition (ASR) due to its phonemic
complexity and the phonetic transformations that occur at word junctures,
similar to the connected speech found in natural conversations. Due to these
complexities, there has been limited exploration of ASR in Sanskrit,
particularly in the context of its poetic verses, which are characterized by
intricate prosodic and rhythmic patterns. This gap in research raises the
question: How can we develop an effective ASR system for Sanskrit, particularly
one that captures the nuanced features of its poetic form? In this study, we
introduce Vedavani, the first comprehensive ASR study focused on Sanskrit Vedic
poetry. We present a 54-hour Sanskrit ASR dataset, consisting of 30,779
labelled audio samples from the Rig Veda and Atharva Veda. This dataset
captures the precise prosodic and rhythmic features that define the language.
We also benchmark the dataset on various state-of-the-art multilingual speech
models.$^{1}$ Experimentation revealed that IndicWhisper performed the best
among the SOTA models.

</details>


### [18] [Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement](https://arxiv.org/abs/2506.00160)
*Qihui Fan,Enfu Nan,Wenbo Li,Lei Lu,Pu Zhao,Yanzhi Wang*

Main category: cs.CL

TL;DR: 提出了一种新型基于LLM和TTS模型的狼人游戏系统，提高了用户参与度与兼容性，无需额外组件。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型的推理和说服能力为人类玩家在基于LLM代理的社交推理游戏（如狼人游戏）提供更具吸引力的体验。

Method: 提出了一种新的、简单的基于LLM的狼人游戏系统，使用调整过的文本到语音(TTS)模型，以增强与各种LLM模型的兼容性及提高用户参与度。

Result: 提出的游戏系统能够提高用户参与度，并与各种LLM模型实现增强兼容性。

Conclusion: 我们认为，随着LLM推理能力的不断增强，在狼人游戏中无需额外组件。

Abstract: The growing popularity of social deduction game systems for both business
applications and AI research has greatly benefited from the rapid advancements
in Large Language Models (LLMs), which now demonstrate stronger reasoning and
persuasion capabilities. Especially with the raise of DeepSeek R1 and V3
models, LLMs should enable a more engaging experience for human players in
LLM-agent-based social deduction games like Werewolf. Previous works either
fine-tuning, advanced prompting engineering, or additional experience pool to
achieve engaging text-format Werewolf game experience. We propose a novel yet
straightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)
models designed for enhanced compatibility with various LLM models, and
improved user engagement. We argue with ever enhancing LLM reasoning, extra
components will be unnecessary in the case of Werewolf.

</details>


### [19] [Let Them Down Easy! Contextual Effects of LLM Guardrails on User Perceptions and Preferences](https://arxiv.org/abs/2506.00195)
*Mingqian Zheng,Wenjia Hu,Patrick Zhao,Motahhare Eslami,Jena D. Hwang,Faeze Brahman,Carolyn Rose,Maarten Sap*

Main category: cs.CL

TL;DR: 研究发现部分合规策略是理想选择，可显著改善用户对LLM拒绝响应的负面看法。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在面对可能有害的输入查询时会拒绝，无论用户的实际意图是否有害，这导致了安全性和用户体验的权衡。

Method: 通过对480名参与者的研究，评估了3840个查询响应对。我们分析了9种最先进的LLM的响应模式，并评估了6种奖励模型如何对不同的拒绝策略进行评分。

Result: 部分合规拒绝策略——提供一般信息而不提供可操作的细节——被证明是最佳策略，将用户对直接拒绝的负面看法减少了50%以上。研究发现模型很少自然使用部分合规策略，而奖励模型目前对其评价偏低。

Conclusion: 本文认为有效的安全机制需要关注设计细致的拒绝策略，而不是仅仅检测用户意图，以确保安全和用户参与度。

Abstract: Current LLMs are trained to refuse potentially harmful input queries
regardless of whether users actually had harmful intents, causing a tradeoff
between safety and user experience. Through a study of 480 participants
evaluating 3,840 query-response pairs, we examine how different refusal
strategies affect user perceptions across varying motivations. Our findings
reveal that response strategy largely shapes user experience, while actual user
motivation has negligible impact. Partial compliance -- providing general
information without actionable details -- emerges as the optimal strategy,
reducing negative user perceptions by over 50% to flat-out refusals.
Complementing this, we analyze response patterns of 9 state-of-the-art LLMs and
evaluate how 6 reward models score different refusal strategies, demonstrating
that models rarely deploy partial compliance naturally and reward models
currently undervalue it. This work demonstrates that effective guardrails
require focusing on crafting thoughtful refusals rather than detecting intent,
offering a path toward AI safety mechanisms that ensure both safety and
sustained user engagement.

</details>


### [20] [Structuring Radiology Reports: Challenging LLMs with Lightweight Models](https://arxiv.org/abs/2506.00200)
*Johannes Moll,Louisa Fay,Asfandyar Azhar,Sophie Ostmeier,Tim Lueth,Sergios Gatidis,Curtis Langlotz,Jean-Benoit Delbrouck*

Main category: cs.CL

TL;DR: 通过轻量级模型优化医学报告结构化，可替代高计算需求的LLM，节约资源并提高隐私保护。


<details>
  <summary>Details</summary>
Motivation: 医学报告通常缺乏标准化，影响人类解读和机器学习应用。需发展高效模型克服LLM计算需求及隐私问题。

Method: 使用轻量级编码解码模型（如T5和BERT2BERT）进行医学报告的结构化处理，并对多种开放源LLM进行基准测试，采用前缀提示、ICL和LoRA微调技术。

Result: 最佳轻量级模型在包括BLEU、ROUGE-L、BERTScore等度量标准上的表现超越所有通过提示技术适配的LLM，而某些微调LLM虽在技术指标上有微小优势，但需要显著更多的计算资源。

Conclusion: 轻量级的编码解码模型在结构化医学报告方面具备可持续性和隐私保护优势，并在资源受限的医疗环境中表现出色。

Abstract: Radiology reports are critical for clinical decision-making but often lack a
standardized format, limiting both human interpretability and machine learning
(ML) applications. While large language models (LLMs) have shown strong
capabilities in reformatting clinical text, their high computational
requirements, lack of transparency, and data privacy concerns hinder practical
deployment. To address these challenges, we explore lightweight encoder-decoder
models (<300M parameters)-specifically T5 and BERT2BERT-for structuring
radiology reports from the MIMIC-CXR and CheXpert Plus datasets. We benchmark
these models against eight open-source LLMs (1B-70B), adapted using prefix
prompting, in-context learning (ICL), and low-rank adaptation (LoRA)
finetuning. Our best-performing lightweight model outperforms all LLMs adapted
using prompt-based techniques on a human-annotated test set. While some
LoRA-finetuned LLMs achieve modest gains over the lightweight model on the
Findings section (BLEU 6.4%, ROUGE-L 4.8%, BERTScore 3.6%, F1-RadGraph 1.1%,
GREEN 3.6%, and F1-SRR-BERT 4.3%), these improvements come at the cost of
substantially greater computational resources. For example, LLaMA-3-70B
incurred more than 400 times the inference time, cost, and carbon emissions
compared to the lightweight model. These results underscore the potential of
lightweight, task-specific models as sustainable and privacy-preserving
solutions for structuring clinical text in resource-constrained healthcare
settings.

</details>


### [21] [Structure-Aware Fill-in-the-Middle Pretraining for Code](https://arxiv.org/abs/2506.00204)
*Linyuan Gong,Alvin Cheung,Mostafa Elhoushi,Sida Wang*

Main category: cs.CL

TL;DR: AST-FIM uses Abstract Syntax Trees for better code LLM pretraining, improving real-world FIM tasks by up to 5 points over traditional methods.


<details>
  <summary>Details</summary>
Motivation: Improve pretraining of code language models (LLMs) by leveraging code structure and editing patterns, enhancing their real-world application.

Method: Propose and evaluate AST-FIM, utilizing Abstract Syntax Trees to mask syntactic structures during pretraining.

Result: AST-FIM demonstrates superior performance on infilling tasks in models with 1B and 8B parameters, showing up to 5-point improvement over random-character masking methods.

Conclusion: AST-FIM significantly improves code completion tasks by aligning better with code structures and editing patterns, outperforming traditional FIM methods.

Abstract: Fill-in-the-Middle (FIM) is a common pretraining method for code LLMs, where
models complete code segments given surrounding context. However, existing LLMs
treat code as plain text and mask random character spans. We propose and
evaluate AST-FIM, a pretraining strategy that leverages Abstract Syntax Trees
(ASTs) to mask complete syntactic structures at scale, ensuring coherent
training examples better aligned with universal code structures and common code
editing patterns such as blocks, expressions, or functions. To evaluate
real-world fill-in-the-middle (FIM) programming tasks, we introduce
Real-FIM-Eval, a benchmark derived from 30,000+ GitHub commits across 12
languages. On infilling tasks, experiments on 1B and 8B parameter models show
that AST-FIM is particularly beneficial for real-world code editing as it
outperforms standard random-character FIM by up to 5 pts on standard FIM
benchmarks. Our code is publicly available at
https://github.com/gonglinyuan/ast_fim.

</details>


### [22] [REIC: RAG-Enhanced Intent Classification at Scale](https://arxiv.org/abs/2506.00210)
*Ziji Zhang,Michael Yang,Zhiyu Chen,Yingying Zhuang,Shu-Ting Pi,Qun Liu,Rajashekar Maragoud,Vy Nguyen,Anurag Beniwal*

Main category: cs.CL

TL;DR: 提出了REIC方法，通过检索增强生成技术解决意图分类的可扩展性问题，实验表明该方法优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 由于企业产品线扩展带来的意图数量增多和分类体系变化，导致意图分类面临可扩展性问题。

Method: 引入REIC (Retrieval-augmented generation Enhanced Intent Classification) 方法，该方法利用检索增强生成（RAG）来动态结合相关知识，以实现高精度的意图分类。

Result: 通过在真实世界数据集上的大量实验，展示了REIC在大规模客户服务环境中优于传统微调、零样本和少样本方法。

Conclusion: REIC有效解决了随着公司产品线扩展而导致的意图分类可扩展性挑战，同时在大规模客户服务环境中表现卓越，具有部署潜力。

Abstract: Accurate intent classification is critical for efficient routing in customer
service, ensuring customers are connected with the most suitable agents while
reducing handling times and operational costs. However, as companies expand
their product lines, intent classification faces scalability challenges due to
the increasing number of intents and variations in taxonomy across different
verticals. In this paper, we introduce REIC, a Retrieval-augmented generation
Enhanced Intent Classification approach, which addresses these challenges
effectively. REIC leverages retrieval-augmented generation (RAG) to dynamically
incorporate relevant knowledge, enabling precise classification without the
need for frequent retraining. Through extensive experiments on real-world
datasets, we demonstrate that REIC outperforms traditional fine-tuning,
zero-shot, and few-shot methods in large-scale customer service settings. Our
results highlight its effectiveness in both in-domain and out-of-domain
scenarios, demonstrating its potential for real-world deployment in adaptive
and large-scale intent classification systems.

</details>


### [23] [ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering](https://arxiv.org/abs/2506.00232)
*Ruofan Wu,Youngwon Lee,Fan Shu,Danmei Xu,Seung-won Hwang,Zhewei Yao,Yuxiong He,Feng Yan*

Main category: cs.CL

TL;DR: ComposeRAG是一种模块化的RAG系统，通过分解流程和引入自我反思机制，提高多跳问答系统的准确性和基础真实性。在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 许多现有的RAG系统设计过于集成化，导致在解释性、系统评价和针对性改进方面表现有限，特别是在复杂的多跳问答中。因此，提出一种模块化抽象来提高系统的灵活性和性能。

Method: ComposeRAG通过将RAG流程分解为可组合的模块来改进问答系统，这些模块包括问题分解、查询重写、检索决策和答案验证，允许独立实施、升级和分析。此外，它借助自我反思机制来提高多步推理的鲁棒性。

Result: 在四项具有挑战性的多跳问答基准测试中，ComposeRAG在准确性和基础真实性方面始终优于强基线模型，相比微调方法提高了最高15%的准确性，且在相同检索条件下，较推理专用管道有最高5%的提升。此外，它显著优化了基础真实性，在低质量检索下减少了超过10%的不符实回答，即便在强势语料库中也减少约3%。

Conclusion: ComposeRAG展示了模块化架构在多跳问答方面的优势，通过验证先行设计，不仅提高了准确性，还显著减少了不符合实际的回答，验证了其作为高效、透明和灵活的系统的作用。

Abstract: Retrieval-Augmented Generation (RAG) systems are increasingly diverse, yet
many suffer from monolithic designs that tightly couple core functions like
query reformulation, retrieval, reasoning, and verification. This limits their
interpretability, systematic evaluation, and targeted improvement, especially
for complex multi-hop question answering. We introduce ComposeRAG, a novel
modular abstraction that decomposes RAG pipelines into atomic, composable
modules. Each module, such as Question Decomposition, Query Rewriting,
Retrieval Decision, and Answer Verification, acts as a parameterized
transformation on structured inputs/outputs, allowing independent
implementation, upgrade, and analysis. To enhance robustness against errors in
multi-step reasoning, ComposeRAG incorporates a self-reflection mechanism that
iteratively revisits and refines earlier steps upon verification failure.
Evaluated on four challenging multi-hop QA benchmarks, ComposeRAG consistently
outperforms strong baselines in both accuracy and grounding fidelity.
Specifically, it achieves up to a 15% accuracy improvement over
fine-tuning-based methods and up to a 5% gain over reasoning-specialized
pipelines under identical retrieval conditions. Crucially, ComposeRAG
significantly enhances grounding: its verification-first design reduces
ungrounded answers by over 10% in low-quality retrieval settings, and by
approximately 3% even with strong corpora. Comprehensive ablation studies
validate the modular architecture, demonstrating distinct and additive
contributions from each component. These findings underscore ComposeRAG's
capacity to deliver flexible, transparent, scalable, and high-performing
multi-hop reasoning with improved grounding and interpretability.

</details>


### [24] [MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility](https://arxiv.org/abs/2506.00235)
*Yexiao He,Ang Li,Boyi Liu,Zhewei Yao,Yuxiong He*

Main category: cs.CL

TL;DR: MedOrch是一个新框架，整合多种专业工具和推理代理，以支持医疗决策，展示了其在多种医疗任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统依赖于任务特定模型或一般语言模型，缺乏与专用外部知识和工具结合。需要一个能够整合多样化知识来源、复杂推理和各种外部分析工具的AI框架。

Method: MedOrch使用模块化的、基于代理的架构，以便灵活集成领域专用工具而不修改核心系统，并确保透明、可追踪的推理过程。

Result: 在阿尔茨海默症诊断上，MedOrch的准确率达到93.26%，在疾病进程预测上，其准确率为50.35%。在胸部X光分析中，MedOrch展示了卓越的性能，宏观AUC为61.2%，宏观F1评分为25.5%。在复杂的多模态视觉问答中，准确率为54.47%。

Conclusion: MedOrch展示了其在多种医疗任务中的竞争力，通过启用推理驱动的工具利用，促进多模态医学数据处理，支持临床决策中的复杂认知任务。

Abstract: Healthcare decision-making represents one of the most challenging domains for
Artificial Intelligence (AI), requiring the integration of diverse knowledge
sources, complex reasoning, and various external analytical tools. Current AI
systems often rely on either task-specific models, which offer limited
adaptability, or general language models without grounding with specialized
external knowledge and tools. We introduce MedOrch, a novel framework that
orchestrates multiple specialized tools and reasoning agents to provide
comprehensive medical decision support. MedOrch employs a modular, agent-based
architecture that facilitates the flexible integration of domain-specific tools
without altering the core system. Furthermore, it ensures transparent and
traceable reasoning processes, enabling clinicians to meticulously verify each
intermediate step underlying the system's recommendations. We evaluate MedOrch
across three distinct medical applications: Alzheimer's disease diagnosis,
chest X-ray interpretation, and medical visual question answering, using
authentic clinical datasets. The results demonstrate MedOrch's competitive
performance across these diverse medical tasks. Notably, in Alzheimer's disease
diagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the
state-of-the-art baseline by over four percentage points. For predicting
Alzheimer's disease progression, it attains a 50.35% accuracy, marking a
significant improvement. In chest X-ray analysis, MedOrch exhibits superior
performance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover,
in complex multimodal visual question answering (Image+Table), MedOrch achieves
an accuracy of 54.47%. These findings underscore MedOrch's potential to advance
healthcare AI by enabling reasoning-driven tool utilization for multimodal
medical data processing and supporting intricate cognitive tasks in clinical
decision-making.

</details>


### [25] [PersianMedQA: Language-Centric Evaluation of LLMs in the Persian Medical Domain](https://arxiv.org/abs/2506.00250)
*Mohammad Javad Ranjbar Kalahroodi,Amirhossein Sheikholselami,Sepehr Karimi,Sepideh Ranjbar Kalahroodi,Heshaam Faili,Azadeh Shakery*

Main category: cs.CL

TL;DR: 研究探讨大规模语言模型在医学领域的低资源语言表现，构建并使用了PersianMedQA数据集。结果表明，封闭源模型在准确率上大幅领先，波斯语微调模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探究大规模语言模型在医学等高风险领域的可靠性，尤其在低资源语言的表现。

Method: 引入了一个名为PersianMedQA的数据集，并对超过40种最先进的模型进行benchmark测试，包括常规模型、进行过波斯语微调的模型以及医学领域模型，在零样本和思维链条方法（CoT）下进行评估。

Result: 封闭源常规模型如GPT-4.1在波斯语和英语中的准确率分别达到83.3%和80.7%，而波斯语微调模型如Dorna表现较差（例如，波斯语中仅35.9%），在指令理解和领域推理上均存在困难。

Conclusion: 大规模语言模型在医学等高风险领域的表现仍有待探索，尤其是在低资源语言方面。构建和使用像PersianMedQA这样的专家验证数据集可以为评估多语言和文化背景医学推理提供基础。

Abstract: Large Language Models (LLMs) have achieved remarkable performance on a wide
range of NLP benchmarks, often surpassing human-level accuracy. However, their
reliability in high-stakes domains such as medicine, particularly in
low-resource languages, remains underexplored. In this work, we introduce
PersianMedQA, a large-scale, expert-validated dataset of multiple-choice
Persian medical questions, designed to evaluate LLMs across both Persian and
English. We benchmark over 40 state-of-the-art models, including
general-purpose, Persian fine-tuned, and medical LLMs, in zero-shot and
chain-of-thought (CoT) settings. Our results show that closed-source general
models (e.g., GPT-4.1) consistently outperform all other categories, achieving
83.3% accuracy in Persian and 80.7% in English, while Persian fine-tuned models
such as Dorna underperform significantly (e.g., 35.9% in Persian), often
struggling with both instruction-following and domain reasoning. We also
analyze the impact of translation, showing that while English performance is
generally higher, Persian responses are sometimes more accurate due to cultural
and clinical contextual cues. Finally, we demonstrate that model size alone is
insufficient for robust performance without strong domain or language
adaptation. PersianMedQA provides a foundation for evaluating multilingual and
culturally grounded medical reasoning in LLMs. The PersianMedQA dataset can be
accessed at:
https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA](https://huggingface.co/datasets/MohammadJRanjbar/PersianMedQA

</details>


### [26] [Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race](https://arxiv.org/abs/2506.00253)
*Lihao Sun,Chengzhi Mao,Valentin Hofmann,Xuechunzi Bai*

Main category: cs.CL

TL;DR: 对齐的语言模型在隐性任务中表现出偏见，提出通过在早期层次中表示种族概念来减少偏见的策略。


<details>
  <summary>Details</summary>
Motivation: 研究对齐的语言模型在隐性词汇关联任务中仍然表现出偏见的原因，希望通过新的方法来减少偏见。

Method: 提出一种新的偏见缓解策略，通过激励模型在早期层次中表示种族概念来减少隐性偏见。

Result: 通过让模型更加意识到种族概念，可以有效地减少语言模型中的隐性偏见。

Conclusion: 考虑到种族差异，能够有效减少语言模型中的隐性偏见。

Abstract: Although value-aligned language models (LMs) appear unbiased in explicit bias
evaluations, they often exhibit stereotypes in implicit word association tasks,
raising concerns about their fair usage. We investigate the mechanisms behind
this discrepancy and find that alignment surprisingly amplifies implicit bias
in model outputs. Specifically, we show that aligned LMs, unlike their
unaligned counterparts, overlook racial concepts in early internal
representations when the context is ambiguous. Not representing race likely
fails to activate safety guardrails, leading to unintended biases. Inspired by
this insight, we propose a new bias mitigation strategy that works by
incentivizing the representation of racial concepts in the early model layers.
In contrast to conventional mitigation methods of machine unlearning, our
interventions find that steering the model to be more aware of racial concepts
effectively mitigates implicit bias. Similar to race blindness in humans,
ignoring racial nuances can inadvertently perpetuate subtle biases in LMs.

</details>


### [27] [The Impact of Disability Disclosure on Fairness and Bias in LLM-Driven Candidate Selection](https://arxiv.org/abs/2506.00256)
*Mahammed Kamruzzaman,Gene Louis Kim*

Main category: cs.CL

TL;DR: 大语言模型在招聘中可能对披露残疾状态的候选人存在偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在招聘过程中的使用越来越广泛，人们对公平性的关注不断增加，尤其是关于残疾相关信息可能导致的候选人选择结果中的偏见。

Method: 研究方法包括对大语言模型如何在招聘过程中处理残疾相关信息进行分析。

Result: 研究结果显示，在性别、种族、资历、经验和背景条件相同的情况下，大语言模型更倾向于选择那些明确表示没有残疾的候选人。

Conclusion: 研究表明，当候选人在性别、种族、资历、经验和背景方面相同，并申请就业率差距较小的工作时，LLM倾向于选择那些披露没有残疾的候选人，即使候选人选择不披露残疾状态，LLM也不太可能选中他们。

Abstract: As large language models (LLMs) become increasingly integrated into hiring
processes, concerns about fairness have gained prominence. When applying for
jobs, companies often request/require demographic information, including
gender, race, and disability or veteran status. This data is collected to
support diversity and inclusion initiatives, but when provided to LLMs,
especially disability-related information, it raises concerns about potential
biases in candidate selection outcomes. Many studies have highlighted how
disability can impact CV screening, yet little research has explored the
specific effect of voluntarily disclosed information on LLM-driven candidate
selection. This study seeks to bridge that gap. When candidates shared
identical gender, race, qualifications, experience, and backgrounds, and sought
jobs with minimal employment rate gaps between individuals with and without
disabilities (e.g., Cashier, Software Developer), LLMs consistently favored
candidates who disclosed that they had no disability. Even in cases where
candidates chose not to disclose their disability status, the LLMs were less
likely to select them compared to those who explicitly stated they did not have
a disability.

</details>


### [28] [MultiHoax: A Dataset of Multi-hop False-Premise Questions](https://arxiv.org/abs/2506.00264)
*Mohammadamin Shafiei,Hamidreza Saffari,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 引入MultiHoax，评估LLM在多步骤推理中处理错误前提的能力。实验显示，现有模型在多方面表现不足，需改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在高风险领域的应用，其检测错误假设和进行批判性推理的能力对于确保可靠输出至关重要，因此需要一种评估模型处理多跳错误前提问题的方法。

Method: 介绍了一种名为MultiHoax的基准测试，专注于评估LLM在复杂、多步骤推理任务中处理错误前提的能力。

Result: 实验表明，最先进的LLM在检测跨国家、知识类别和多跳推理类型中的错误前提方面表现不足。

Conclusion: 当前的LLM在处理复杂的多步推理任务中识别错误前提方面存在困难，需要改进相关检测机制和增强多步推理能力。

Abstract: As Large Language Models are increasingly deployed in high-stakes domains,
their ability to detect false assumptions and reason critically is crucial for
ensuring reliable outputs. False-premise questions (FPQs) serve as an important
evaluation method by exposing cases where flawed assumptions lead to incorrect
responses. While existing benchmarks focus on single-hop FPQs, real-world
reasoning often requires multi-hop inference, where models must verify
consistency across multiple reasoning steps rather than relying on
surface-level cues. To address this gap, we introduce MultiHoax, a benchmark
for evaluating LLMs' ability to handle false premises in complex, multi-step
reasoning tasks. Our dataset spans seven countries and ten diverse knowledge
categories, using Wikipedia as the primary knowledge source to enable factual
reasoning across regions. Experiments reveal that state-of-the-art LLMs
struggle to detect false premises across different countries, knowledge
categories, and multi-hop reasoning types, highlighting the need for improved
false premise detection and more robust multi-hop reasoning capabilities in
LLMs.

</details>


### [29] [CASPER: A Large Scale Spontaneous Speech Dataset](https://arxiv.org/abs/2506.00267)
*Cihan Xiao,Ruixing Liang,Xiangyu Zhang,Mehmet Emre Tiryaki,Veronica Bae,Lavanya Shankar,Rong Yang,Ethan Poon,Emmanuel Dupoux,Sanjeev Khudanpur,Leibny Paola Garcia Perera*

Main category: cs.CL

TL;DR: 论文介绍了一种新流程，以促进自然对话，并提供一个200小时的自发语音数据集，旨在解决自发语音数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的成功激发了对类似语音处理能力的兴趣，而自发语音数据的稀缺是关键挑战。

Method: 我们提出了一种新的流程以引出和记录自然对话，并发布了包含200多个小时自发语音的Stage 1数据集。

Result: 我们的方法与传统方法不同，促进真正的互动，并为未来数据收集提供了可复制的框架。我们计划在未来阶段扩展此数据集，为研究界提供一个不断增长的资源。

Conclusion: 我们的方法促进了流畅、自然的对话，并鼓励多样化的话题和互动交流，为未来数据收集提供了可复制的框架。

Abstract: The success of large language models has driven interest in developing
similar speech processing capabilities. However, a key challenge is the
scarcity of high-quality spontaneous speech data, as most existing datasets
contain scripted dialogues. To address this, we present a novel pipeline for
eliciting and recording natural dialogues and release our Stage 1 dataset with
200+ hours of spontaneous speech. Our approach fosters fluid, natural
conversations while encouraging a diverse range of topics and interactive
exchanges. Unlike traditional methods, it facilitates genuine interactions,
providing a reproducible framework for future data collection. This paper
introduces our dataset and methodology, laying the groundwork for addressing
the shortage of spontaneous speech data. We plan to expand this dataset in
future stages, offering a growing resource for the research community.

</details>


### [30] [Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings](https://arxiv.org/abs/2506.00277)
*Hans W. A. Hanley,Zakir Durumeric*

Main category: cs.CL

TL;DR: 该论文提出了一种可扩展、可解释、层次化及多语言的新闻文章和社交媒体数据聚类方法，使用了一种新的多语言Matryoshka嵌入和相应的分层聚类算法。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在多语言环境中表现不佳，并且难以解释。我们希望开发一种可扩展、可解释的层次化和多语言的新闻文章和社交媒体数据聚类方法。

Method: 我们首先训练多语言的Matryoshka嵌入，用于确定故事相似性，然后开发了一种高效的分层聚类算法，利用Matryoshka嵌入的层次结构来识别独特的新闻故事、叙述和主题。

Result: 在SemEval 2022 Task 8测试数据集上，我们的嵌入模型达到了最先进的性能（Pearson ρ = 0.816）。

Conclusion: 我们的方法可以识别和聚类真实世界新闻数据集中的故事、叙述和主题。

Abstract: Contextual large language model embeddings are increasingly utilized for
topic modeling and clustering. However, current methods often scale poorly,
rely on opaque similarity metrics, and struggle in multilingual settings. In
this work, we present a novel, scalable, interpretable, hierarchical, and
multilingual approach to clustering news articles and social media data. To do
this, we first train multilingual Matryoshka embeddings that can determine
story similarity at varying levels of granularity based on which subset of the
dimensions of the embeddings is examined. This embedding model achieves
state-of-the-art performance on the SemEval 2022 Task 8 test dataset (Pearson
$\rho$ = 0.816). Once trained, we develop an efficient hierarchical clustering
algorithm that leverages the hierarchical nature of Matryoshka embeddings to
identify unique news stories, narratives, and themes. We conclude by
illustrating how our approach can identify and cluster stories, narratives, and
overarching themes within real-world news datasets.

</details>


### [31] [Emergent Abilities of Large Language Models under Continued Pretraining for Language Adaptation](https://arxiv.org/abs/2506.00288)
*Ahmed Elhady,Eneko Agirre,Mikel Artetxe*

Main category: cs.CL

TL;DR: 研究发现CPT中加入英语数据有助于目标语言能力的出现，引入课程学习和EMA方法可以减少对英语的依赖。


<details>
  <summary>Details</summary>
Motivation: 探讨在CPT中加入英语数据的作用，以及如何通过其他方法减轻对英语的依赖，以提高语言适应的效果。

Method: 引入语言无关的ICL基准测试来分析在不使用英语的条件下出现的灾难性遗忘，并提出课程学习和权重指数移动平均（EMA）作为有效替代方案。

Result: 发现英语数据对于目标语言的学习至关重要，其缺失会导致模型参数的大变动，从而影响下游任务的泛化能力。引入的解决方案如课程学习和EMA能够有效缓解这一问题。

Conclusion: 研究表明，在CPT过程中加入英语数据对目标语言下游任务能力的增强至关重要，虽然在验证困惑度上没有表现出显著影响。

Abstract: Continued pretraining (CPT) is a popular approach to adapt existing large
language models (LLMs) to new languages. When doing so, it is common practice
to include a portion of English data in the mixture, but its role has not been
carefully studied to date. In this work, we show that including English does
not impact validation perplexity, yet it is critical for the emergence of
downstream capabilities in the target language. We introduce a
language-agnostic benchmark for in-context learning (ICL), which reveals
catastrophic forgetting early on CPT when English is not included. This in turn
damages the ability of the model to generalize to downstream prompts in the
target language as measured by perplexity, even if it does not manifest in
terms of accuracy until later in training, and can be tied to a big shift in
the model parameters. Based on these insights, we introduce curriculum learning
and exponential moving average (EMA) of weights as effective alternatives to
mitigate the need for English. All in all, our work sheds light into the
dynamics by which emergent abilities arise when doing CPT for language
adaptation, and can serve as a foundation to design more effective methods in
the future.

</details>


### [32] [DLM-One: Diffusion Language Models for One-Step Sequence Generation](https://arxiv.org/abs/2506.00290)
*Tianqi Chen,Shujian Zhang,Mingyuan Zhou*

Main category: cs.CL

TL;DR: DLM-One significantly speeds up inference in language modeling by aligning student and teacher model scores, maintaining high performance without iterative refinement.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance sampling efficiency in language modeling by eliminating the need for iterative refinement processes.

Method: The method involves using a score-distillation-based framework for one-step sequence generation, aligning a student model's score with a pretrained teacher DLM's in the continuous token embedding space.

Result: DLM-One achieves up to ~500x speedup in inference time while maintaining competitive performance in the evaluated tasks.

Conclusion: DLM-One provides a substantial speedup in inference time while maintaining competitive performance on benchmark text generation tasks, showing its potential as a promising direction for efficient, high-quality language generation with continuous diffusion models.

Abstract: This paper introduces DLM-One, a score-distillation-based framework for
one-step sequence generation with continuous diffusion language models (DLMs).
DLM-One eliminates the need for iterative refinement by aligning the scores of
a student model's outputs in the continuous token embedding space with the
score function of a pretrained teacher DLM. We investigate whether DLM-One can
achieve substantial gains in sampling efficiency for language modeling. Through
comprehensive experiments on DiffuSeq -- a representative continuous DLM -- we
show that DLM-One achieves up to ~500x speedup in inference time while
maintaining competitive performance on benchmark text generation tasks used to
evaluate the teacher models. We further analyze the method's empirical behavior
across multiple datasets, providing initial insights into its generality and
practical applicability. Our findings position one-step diffusion as a
promising direction for efficient, high-quality language generation and broader
adoption of continuous diffusion models operating in embedding space for
natural language processing.

</details>


### [33] [Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs](https://arxiv.org/abs/2506.00304)
*Payal Mohapatra,Akash Pandey,Xiaoyuan Zhang,Qi Zhu*

Main category: cs.CL

TL;DR: 研究开发了一种创新的EMG适配器模块，将EMG特征映射到LLMs的输入空间，使得LLMs能够理解无声语言，并显著提高了EMG到文本转换的效果。


<details>
  <summary>Details</summary>
Motivation: 无声电肌图（EMG）为无法进行语言表达的个人提供了沟通手段，但传统方法依赖于有声与无声EMG信号的配对，以及语音数据，这对于无法发声的人来说不实用。随着大语言模型在语音识别中的崛起，研究者探索了其在理解无声语言方面的潜力。

Method: 研究者提出了一种新的EMG适配模块，能够将EMG特征映射到LLM的输入空间，并在封闭词汇的无声EMG到文本任务中实现平均词错误率（WER）为0.49。

Result: 在仅有六分钟数据的保守情况下，该方法在性能上比专业模型提高了近20%。

Conclusion: 这项研究展示了大语言模型（LLMs）在理解无声电肌图（EMG）方面的潜力，提出了一种新的EMG适配模块，可以将EMG特征映射到LLMs的输入空间，从而实现EMG到文本的转换。

Abstract: Unvoiced electromyography (EMG) is an effective communication tool for
individuals unable to produce vocal speech. However, most prior methods rely on
paired voiced and unvoiced EMG signals, along with speech data, for EMG-to-text
conversion, which is not practical for such individuals. Given the rise of
large language models (LLMs) in speech recognition, we explore their potential
to understand unvoiced speech. To this end, we address the challenge of
learning from unvoiced EMG alone and propose a novel EMG adaptor module that
maps EMG features into an LLM's input space, achieving an average word error
rate (WER) of 0.49 on a closed-vocabulary unvoiced EMG-to-text task. Even with
a conservative data availability of just six minutes, our approach improves
performance over specialized models by nearly 20%. While LLMs have been shown
to be extendable to new language modalities -- such as audio -- understanding
articulatory biosignals like unvoiced EMG remains more challenging. This work
takes a crucial first step toward enabling LLMs to comprehend unvoiced speech
using surface EMG.

</details>


### [34] [Lossless Token Sequence Compression via Meta-Tokens](https://arxiv.org/abs/2506.00307)
*John Harvill,Ziwei Fan,Hao Wang,Yizhou Sun,Hao Ding,Luke Huan,Anoop Deoras*

Main category: cs.CL

TL;DR: Introduced a lossless compression method reducing input sequences by 27% and 18%, leading to significant computation savings in LLMs without losing semantic meaning.


<details>
  <summary>Details</summary>
Motivation: The motivation is to reduce sequence length and encoding computation in transformer-based LLMs without losing any semantic information.

Method: We introduce a task-agnostic lossless compression technique similar to LZ77, which is reversible and preserves semantic information.

Result: The technique achieves a 27% and 18% reduction in sequence length for the evaluation tasks, corresponding to 47% and 33% less encoding computation, with minimal performance loss.

Conclusion: Our lossless compression technique allows for a significant reduction in input sequence length while preserving semantic information, resulting in less encoding computation.

Abstract: Existing work on prompt compression for Large Language Models (LLM) focuses
on lossy methods that try to maximize the retention of semantic information
that is relevant to downstream tasks while significantly reducing the sequence
length. In this paper, we introduce a task-agnostic lossless compression
technique similar to LZ77 that makes it possible to reduce the input token
sequence length on average by 27\% and 18\% for the two evaluation tasks
explored here. Given that we use transformer-based LLMs, this equates to 47\%
and 33\% less encoding computation, respectively, due to the quadratic nature
of attention. The token sequence transformation is trivial to reverse and
highlights that no semantic information is lost in the process. We evaluate our
proposed approach on two tasks that require strict preservation of
semantics/syntax and demonstrate that existing lossy compression methods
perform poorly in this setting. We find that our lossless compression technique
produces only a small gap in performance compared to using the uncompressed
input and posit that larger models and an expanded computing budget would
likely erase the gap entirely.

</details>


### [35] [An evaluation of LLMs for generating movie reviews: GPT-4o, Gemini-2.0 and DeepSeek-V3](https://arxiv.org/abs/2506.00312)
*Brendan Sands,Yining Wang,Chenhao Xu,Yuxuan Zhou,Lai Wei,Rohitash Chandra*

Main category: cs.CL

TL;DR: 研究分析了使用大型语言模型生成电影评论的效果，发现LLM生成的评论在语法上流畅但缺乏情感和风格的一致性，仍需改进。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在生成电影评论上的应用潜力，并评估其生成输出与IMDb用户评论相比的表现。

Method: 本文提出框架使用三个大型语言模型（GPT-4o、DeepSeek-V3和Gemini-2.0）生成电影评论，并通过比较生成的评论与IMDb用户评论来评估其表现。

Result: LLM生成的电影评论在语法和结构上较为完整流畅，但在情感丰富性和风格一致性方面与IMDb评论存在差距。调查显示，参与者难以区分LLM与IMDb用户评论，其中DeepSeek-V3生成的评论最为平衡，GPT-4o偏向正面情感，而Gemini-2.0更好地捕捉负面情感但表现情感强度过高。

Conclusion: 研究表明，尽管LLM可以生成在语法上流畅且结构完整的电影评论，但与IMDb用户评论相比，其情感丰富性和风格一致性仍有显著差距，需要进一步优化以提高电影评论生成的整体质量。

Abstract: Large language models (LLMs) have been prominent in various tasks, including
text generation and summarisation. The applicability of LLMs to the generation
of product reviews is gaining momentum, paving the way for the generation of
movie reviews. In this study, we propose a framework that generates movie
reviews using three LLMs (GPT-4o, DeepSeek-V3, and Gemini-2.0), and evaluate
their performance by comparing the generated outputs with IMDb user reviews. We
use movie subtitles and screenplays as input to the LLMs and investigate how
they affect the quality of reviews generated. We review the LLM-based movie
reviews in terms of vocabulary, sentiment polarity, similarity, and thematic
consistency in comparison to IMDB user reviews. The results demonstrate that
LLMs are capable of generating syntactically fluent and structurally complete
movie reviews. Nevertheless, there is still a noticeable gap in emotional
richness and stylistic coherence between LLM-generated and IMDb reviews,
suggesting that further refinement is needed to improve the overall quality of
movie review generation. We provided a survey-based analysis where participants
were told to distinguish between LLM and IMDb user reviews. The results show
that LLM-generated reviews are difficult to distinguish from IMDB user reviews.
We found that DeepSeek-V3 produced the most balanced reviews, closely matching
IMDb reviews. GPT-4o overemphasised positive emotions, while Gemini-2.0
captured negative emotions better but showed excessive emotional intensity.

</details>


### [36] [SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation](https://arxiv.org/abs/2506.00319)
*Yufei Tian,Jiao Sun,Nanyun Peng,Zizhao Zhang*

Main category: cs.CL

TL;DR: Introduction of SkillVerse for evaluating language models, demonstrating improved in-context learning and prediction of weaknesses.


<details>
  <summary>Details</summary>
Motivation: To provide a granular understanding of language models' capabilities to support better development strategies.

Method: SkillVerse evaluates model skills using LLM as a judge and organizes results into a tree-structured framework called dendrogram.

Result: SkillVerse improves model in-context learning by 25% and predicts model weaknesses with a 55% success rate, outperforming previous methods by 22%.

Conclusion: SkillVerse is effective in diagnosing the proficiency of language models in specific skills, enhancing in-context learning and predicting model weaknesses.

Abstract: As language models evolve to tackle complex, multifaceted tasks, their
evaluation must adapt to capture this intricacy. A granular, skill-specific
understanding of model capabilities can empower researchers to make informed
model development plans. In this paper, we introduce SkillVerse, an
unsupervised tree-structured diagnosis framework for understanding model
proficiency in specific abilities. With LLM as a judge, SkillVerse first
critiques the model responses, and then organizes them into a hierarchical
structure termed dendrogram. Given proficiency at arbitrary levels of
granularity, SkillVerse is flexible to produce insights of behaviors of modern
large models. We also demonstrate its efficacy in two downstream tasks: 1)
improving model in-context learning by 25% using a tree-search algorithm to
select more informative few-shot demonstrations, and 2) accurately predicting
new model weaknesses with a 55% success rate, 22% higher than without
SkillVerse.

</details>


### [37] [TreeRare: Syntax Tree-Guided Retrieval and Reasoning for Knowledge-Intensive Question Answering](https://arxiv.org/abs/2506.00331)
*Boyi Zhang,Zhuo Liu,Hangfeng He*

Main category: cs.CL

TL;DR: TreeRare通过语法树引导检索和推理，显著提升复杂问题的问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有的迭代检索框架性能受到推理错误累积和检索结果不匹配的限制。TreeRare提出用语法树来引导检索和推理，以解决复杂的知识密集型问题。

Method: TreeRare通过语法树引导检索和推理，采用从下到上遍历语法树的方法，在每个节点生成子组件查询并检索相关段落，然后通过子组件问答模块综合这些段落形成证据，最后聚合整个树的证据以形成最终答案。

Result: 在五个涉及模糊或多步推理的问题问答数据集上的实验表明，TreeRare在现有方法上取得了显著的性能改进。

Conclusion: TreeRare显著改善了复杂问题的问答性能，尤其是在涉及多步推理的情况下。通过树结构的引导，结合语言模型的能力，以更有效地检索和整合信息。

Abstract: In real practice, questions are typically complex and knowledge-intensive,
requiring Large Language Models (LLMs) to recognize the multifaceted nature of
the question and reason across multiple information sources. Iterative and
adaptive retrieval, where LLMs decide when and what to retrieve based on their
reasoning, has been shown to be a promising approach to resolve complex,
knowledge-intensive questions. However, the performance of such retrieval
frameworks is limited by the accumulation of reasoning errors and misaligned
retrieval results. To overcome these limitations, we propose TreeRare (Syntax
Tree-Guided Retrieval and Reasoning), a framework that utilizes syntax trees to
guide information retrieval and reasoning for question answering. Following the
principle of compositionality, TreeRare traverses the syntax tree in a
bottom-up fashion, and in each node, it generates subcomponent-based queries
and retrieves relevant passages to resolve localized uncertainty. A
subcomponent question answering module then synthesizes these passages into
concise, context-aware evidence. Finally, TreeRare aggregates the evidence
across the tree to form a final answer. Experiments across five question
answering datasets involving ambiguous or multi-hop reasoning demonstrate that
TreeRare achieves substantial improvements over existing state-of-the-art
methods.

</details>


### [38] [Disentangling Codemixing in Chats: The NUS ABC Codemixed Corpus](https://arxiv.org/abs/2506.00332)
*Svetlana Churina,Akshat Gupta,Insyirah Mujtahid,Kokil Jaidka*

Main category: cs.CL

TL;DR: 研究介绍了第一个标记的代码转换通用语料库，包含超过35万条信息，将成为语言学和NLP研究的基础。


<details>
  <summary>Details</summary>
Motivation: 尽管代码转换在诸如社交媒体、聊天信息和即时消息交流等非正式互动中很突出，但缺乏公开的、适合于建模人类对话和关系的作者标记语料库。

Method: 研究介绍了首个用于理解语境中代码转换的标记通用语料库，并持续性地收集、验证和整合代码转换消息成为结构化数据集，释放为JSON格式。

Result: 到目前为止，语料库包含超过355,641条信息，涵盖各种代码转换模式，主要集中在英语、普通话和其他语言。

Conclusion: Codemix Corpus将成为计算语言学、社会语言学和自然语言处理应用研究的基础数据集。

Abstract: Code-mixing involves the seamless integration of linguistic elements from
multiple languages within a single discourse, reflecting natural multilingual
communication patterns. Despite its prominence in informal interactions such as
social media, chat messages and instant-messaging exchanges, there has been a
lack of publicly available corpora that are author-labeled and suitable for
modeling human conversations and relationships. This study introduces the first
labeled and general-purpose corpus for understanding code-mixing in context
while maintaining rigorous privacy and ethical standards. Our live project will
continuously gather, verify, and integrate code-mixed messages into a
structured dataset released in JSON format, accompanied by detailed metadata
and linguistic statistics. To date, it includes over 355,641 messages spanning
various code-mixing patterns, with a primary focus on English, Mandarin, and
other languages. We expect the Codemix Corpus to serve as a foundational
dataset for research in computational linguistics, sociolinguistics, and NLP
applications.

</details>


### [39] [Beyond Context to Cognitive Appraisal: Emotion Reasoning as a Theory of Mind Benchmark for Large Language Models](https://arxiv.org/abs/2506.00334)
*Gerard Christopher Yeo,Kokil Jaidka*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型如何在理论心智框架内通过认知评价理论进行情感推理，发现其在与特定情感关联情境结果和评价方面表现较差，强调心理学理论的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了超越表层感知特征，调查大型语言模型如何使用上下文信息来推理他人的情感状态，因为文本中有时包含隐蔽的上下文线索，这需要更高阶的推理能力。

Method: 在一个理论心智 (ToM) 框架内，基于认知评价理论，我们策划了一个专门的 ToM 评估数据集来评估正向推理（从情境到情感）和逆向推理（从情感到推断情境）。

Result: 我们发现，LLMs 在一定程度上能够进行推理，但它们难以将情境结果和评价与特定情感进行关联。

Conclusion: 我们的研究突出了心理学理论在情感推理方面训练和评估大型语言模型（LLMs）时的重要性。

Abstract: Datasets used for emotion recognition tasks typically contain overt cues that
can be used in predicting the emotions expressed in a text. However, one
challenge is that texts sometimes contain covert contextual cues that are rich
in affective semantics, which warrant higher-order reasoning abilities to infer
emotional states, not simply the emotions conveyed. This study advances beyond
surface-level perceptual features to investigate how large language models
(LLMs) reason about others' emotional states using contextual information,
within a Theory-of-Mind (ToM) framework. Grounded in Cognitive Appraisal
Theory, we curate a specialized ToM evaluation dataset1 to assess both forward
reasoning - from context to emotion- and backward reasoning - from emotion to
inferred context. We showed that LLMs can reason to a certain extent, although
they are poor at associating situational outcomes and appraisals with specific
emotions. Our work highlights the need for psychological theories in the
training and evaluation of LLMs in the context of emotion reasoning.

</details>


### [40] [OWSM v4: Improving Open Whisper-Style Speech Models via Data Scaling and Cleaning](https://arxiv.org/abs/2506.00338)
*Yifan Peng,Shakeel Muhammad,Yui Sudo,William Chen,Jinchuan Tian,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: cs.CL

TL;DR: OWSM项目通过引入YODAS数据集改善模型性能，新版本在多语言基准测试中表现优秀，计划公开相关资源。


<details>
  <summary>Details</summary>
Motivation: 现有的OWSM训练数据不足，因此需要引入更大规模的数据集。

Method: 使用公开工具开发了一个可扩展的数据清理管线，并结合已有的OWSM数据进行训练。

Result: 处理后的数据集包含166,000小时的语音数据，支持75种语言。新系列的OWSM v4模型在多语言基准测试中表现优越，并将在ESPnet工具包中发布相关资源。

Conclusion: OWSM v4 model显著超越了以前的版本，并且在多种场景中与或超过主流工业模型。

Abstract: The Open Whisper-style Speech Models (OWSM) project has developed a series of
fully open speech foundation models using academic-scale resources, but their
training data remains insufficient. This work enhances OWSM by integrating
YODAS, a large-scale web-crawled dataset with a Creative Commons license.
However, incorporating YODAS is nontrivial due to its wild nature, which
introduces challenges such as incorrect language labels and audio-text
misalignments. To address this, we develop a scalable data-cleaning pipeline
using public toolkits, yielding a dataset with 166,000 hours of speech across
75 languages. Our new series of OWSM v4 models, trained on this curated dataset
alongside existing OWSM data, significantly outperform previous versions on
multilingual benchmarks. Our models even match or surpass frontier industrial
models like Whisper and MMS in multiple scenarios. We will publicly release the
cleaned YODAS data, pre-trained models, and all associated scripts via the
ESPnet toolkit.

</details>


### [41] [Efficient Latent Semantic Clustering for Scaling Test-Time Computation of LLMs](https://arxiv.org/abs/2506.00344)
*Sungjae Lee,Hoyoung Kim,Jeongyeon Hwang,Eunhyeok Park,Jungseul Ok*

Main category: cs.CL

TL;DR: 提出了一种轻量级的语义聚类方法（LSC），通过LLM的内部隐藏状态进行聚类，提高了测试时计算效率，无需外部模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高大型语言模型（LLMs）的可靠性和质量，扩展测试时的计算（针对单个输入生成并分析多个或连续的输出）成为一种有前景的策略。其中，语义聚类是一个关键的共享组件，但是现有方法依赖于外部模型，导致大量的计算开销且常常无法捕捉上下文相关的语义。

Method: 提出了潜在语义聚类（LSC）方法，该方法通过利用生成器LLM的内部隐藏状态进行聚类，避免了对外部模型的依赖。

Result: 实验表明，LSC显著提高了测试时扩展的计算效率，同时保持或超过了现有方法的性能。

Conclusion: 使用困关语义聚类（LSC）方法可以在保持或超越现有方法表现的同时，提高测试时扩展的计算效率。

Abstract: Scaling test-time computation--generating and analyzing multiple or
sequential outputs for a single input--has become a promising strategy for
improving the reliability and quality of large language models (LLMs), as
evidenced by advances in uncertainty quantification and multi-step reasoning. A
key shared component is semantic clustering, which groups outputs that differ
in form but convey the same meaning. Semantic clustering enables estimation of
the distribution over the semantics of outputs and helps avoid redundant
exploration of reasoning paths. However, existing approaches typically rely on
external models, which introduce substantial computational overhead and often
fail to capture context-aware semantics. We propose Latent Semantic Clustering
(LSC), a lightweight and context-sensitive method that leverages the generator
LLM's internal hidden states for clustering, eliminating the need for external
models. Our extensive experiment across various LLMs and datasets shows that
LSC significantly improves the computational efficiency of test-time scaling
while maintaining or exceeding the performance of existing methods.

</details>


### [42] [Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG](https://arxiv.org/abs/2506.00381)
*Siavash Shams,Richard Antonello,Gavin Mischler,Stephan Bickel,Ashesh Mehta,Nima Mesgarani*

Main category: cs.CL

TL;DR: Neuro2Semantic框架使用iEEG记录有效重构语音语义内容，具有强大的性能，适用于脑机接口。


<details>
  <summary>Details</summary>
Motivation: 在神经科学和人工智能的交叉领域，解码神经信号中的连续语言是一项重大挑战，因此需要开发一种能够重构感知语音语义内容的新框架。

Method: Neuro2Semantic包含两个阶段：首先，一个基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；其次，一个校正模块从这些对齐的嵌入中直接生成连续的自然文本。

Result: Neuro2Semantic在仅30分钟的神经数据情况下表现出色，且在低数据环境中优于最新的先进方法。

Conclusion: Neuro2Semantic框架能够在低数据情况下实现强大的语义内容重构性能，并且在脑机接口和神经解码技术的实际应用中具有潜力。

Abstract: Decoding continuous language from neural signals remains a significant
challenge in the intersection of neuroscience and artificial intelligence. We
introduce Neuro2Semantic, a novel framework that reconstructs the semantic
content of perceived speech from intracranial EEG (iEEG) recordings. Our
approach consists of two phases: first, an LSTM-based adapter aligns neural
signals with pre-trained text embeddings; second, a corrector module generates
continuous, natural text directly from these aligned embeddings. This flexible
method overcomes the limitations of previous decoding approaches and enables
unconstrained text generation. Neuro2Semantic achieves strong performance with
as little as 30 minutes of neural data, outperforming a recent state-of-the-art
method in low-data settings. These results highlight the potential for
practical applications in brain-computer interfaces and neural decoding
technologies.

</details>


### [43] [Adaptive-VP: A Framework for LLM-Based Virtual Patients that Adapts to Trainees' Dialogue to Facilitate Nurse Communication Training](https://arxiv.org/abs/2506.00386)
*Keyeun Lee,Seolhee Lee,Esther Hehsun Kim,Yena Ko,Jinsu Eun,Dahee Kim,Hyewon Cho,Haiyi Zhu,Robert E. Kraut,Eunyoung Suh,Eun-mee Kim,Hajin Lim*

Main category: cs.CL

TL;DR: Adaptive-VP系统利用大型语言模型，为护理沟通提供动态互动和适应性评估，被专家验证为更贴近真实的教学工具。


<details>
  <summary>Details</summary>
Motivation: 为了填补虚拟患者系统缺乏响应性互动的空白，提高护理人员的沟通训练质量。

Method: 介绍了一种利用大型语言模型（LLMs）动态适应VP行为的Adaptive-VP对话生成框架。

Result: 专家护士确认Adaptive-VP比现有方法产生更自然和逼真的互动，验证显示沟通技能评估机制反映了现实世界的熟练程度。

Conclusion: Adaptive-VP生成更自然和真实的互动，被认为是一种有效的护理沟通训练工具。

Abstract: Effective communication training is essential to preparing nurses for
high-quality patient care. While standardized patient (SP) simulations provide
valuable experiential learning, they are often costly and inflexible. Virtual
patient (VP) systems offer a scalable alternative, but most fail to adapt to
the varying communication skills of trainees. In particular, when trainees
respond ineffectively, VPs should escalate in hostility or become
uncooperative--yet this level of adaptive interaction remains largely
unsupported. To address this gap, we introduce Adaptive-VP, a VP dialogue
generation framework that leverages large language models (LLMs) to dynamically
adapt VP behavior based on trainee input. The framework features a pipeline for
constructing clinically grounded yet flexible VP scenarios and a modular system
for assessing trainee communication and adjusting VP responses in real time,
while ensuring learner safety. We validated Adaptive-VP by simulating
challenging patient conversations. Automated evaluation using a corpus from
practicing nurses showed that our communication skill evaluation mechanism
reflected real-world proficiency levels. Expert nurses further confirmed that
Adaptive-VP produced more natural and realistic interactions than existing
approaches, demonstrating its potential as a scalable and effective tool for
nursing communication training.

</details>


### [44] [SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL](https://arxiv.org/abs/2506.00391)
*Ge Qu,Jinyang Li,Bowen Qin,Xiaolong Li,Nan Huo,Chenhao Ma,Reynold Cheng*

Main category: cs.CL

TL;DR: SHARE通过分层行动纠正助理改善文本到SQL的错误定位和纠正，实验结果表明其高效性和稳健性，尤其在低资源和数据隐私限制环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前文本到SQL的自我纠正方法存在递归计算开销大和缺乏有效错误检测及纠正这两个局限性。

Method: SHARE使用基于SLMs的三个专用小语言模型，在一个顺序流水线中工作，首先将声明性SQL查询转换为逐步揭示底层推理的行动轨迹，然后进行两阶段细化。提出了一种新的分层自我进化策略以提高数据训练效率。

Result: 实验结果表明，SHARE有效提升了自我纠正能力，并且在各种LLMs上表现出色。

Conclusion: SHARE显著提高了LLMs的自我纠正能力，并在低资源训练环境中依然表现强劲，对数据隐私有限制的文本到SQL应用尤其有价值。

Abstract: Current self-correction approaches in text-to-SQL face two critical
limitations: 1) Conventional self-correction methods rely on recursive
self-calls of LLMs, resulting in multiplicative computational overhead, and 2)
LLMs struggle to implement effective error detection and correction for
declarative SQL queries, as they fail to demonstrate the underlying reasoning
path. In this work, we propose SHARE, an SLM-based Hierarchical Action
corREction assistant that enables LLMs to perform more precise error
localization and efficient correction. SHARE orchestrates three specialized
Small Language Models (SLMs) in a sequential pipeline, where it first
transforms declarative SQL queries into stepwise action trajectories that
reveal underlying reasoning, followed by a two-phase granular refinement. We
further propose a novel hierarchical self-evolution strategy for data-efficient
training. Experimental results demonstrate that SHARE effectively enhances
self-correction capabilities while proving robust across various LLMs.
Furthermore, our comprehensive analysis shows that SHARE maintains strong
performance even in low-resource training settings, which is particularly
valuable for text-to-SQL applications with data privacy constraints.

</details>


### [45] [Speculative Reward Model Boosts Decision Making Ability of LLMs Cost-Effectively](https://arxiv.org/abs/2506.00396)
*Jiawei Gu,Shangsong Liang*

Main category: cs.CL

TL;DR: 提出SRM模型，通过外部奖励及推测验证机制提升大语言模型决策效率，实验显示降低成本至原来的1/10。


<details>
  <summary>Details</summary>
Motivation: 现有方法在性能和计算成本之间的平衡上存在不足，为此提出更高效的决策框架。

Method: 引入3E准则评估策略性价比；提出推测性奖励模型与现有搜索策略结合，通过外部奖励分配器及推测性验证机制减少LLM自我评估依赖。

Result: SRM在复杂任务中将成本降低至原框架的1/10，同时保持有效性。

Conclusion: SRM能够显著降低决策成本，同时保持有效性，在复杂任务中表现优异。

Abstract: Effective decision-making in Large Language Models (LLMs) is essential for
handling intricate tasks. However, existing approaches prioritize performance
but often overlook the balance between effectiveness and computational cost. To
address this, we first introduce the 3E Criteria to systematically assess the
cost-effectiveness of search strategies, revealing that existing methods often
trade significant efficiency for marginal performance gains. To improve LLM
decision-making while maintaining efficiency, we propose the Speculative Reward
Model (SRM), a plug-and-play framework that seamlessly integrates with existing
search strategies. Specifically, SRM employs an external reward assigner to
predict optimal actions, reducing reliance on LLMs' internal self-evaluation.
And a speculative verification mechanism is used to prune suboptimal choices
and guide the search toward more promising steps. We evaluate SRM on several
complex decision-making tasks including mathematical reasoning, planning and
numerical reasoning in specialized domains. Experimental results show that SRM
reduces costs to 1/10 of the original search framework on average while
maintaining effectiveness.

</details>


### [46] [Scaling Textual Gradients via Sampling-Based Momentum](https://arxiv.org/abs/2506.00400)
*Zixin Ding,Junyuan Hong,Jiachen T. Wang,Zinan Lin,Zhangyang Wang,Yuxin Chen*

Main category: cs.CL

TL;DR: 本文提出了TSGD-M方法，通过重加权抽样改进TGD性能，在多个NLP任务中取得了更好表现并减少了方差。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型中提示的关键性增加，优化文本提示变得极为重要。现有的TGD框架在数据扩展后性能下降，并且增加了计算成本，因此需要一个更高效的方法。

Method: 本文提出了基于TSGD-M的方法，通过对过去批次分布的重加权抽样，促进上下文学习的可扩展性。

Result: 在跨越三个领域的九个NLP任务中，TSGD-M显著优于未包含重新加权抽样的TGD基线，同时在大部分任务中也减少了方差。

Conclusion: 本研究提出了TSGD-M方法，在多个NLP任务中显示出优越的性能，并减少了方差。

Abstract: As prompts play an increasingly critical role in large language models
(LLMs), optimizing textual prompts has become a crucial challenge. The Textual
Gradient Descent (TGD) framework has emerged as a promising data-driven
approach that iteratively refines textual prompts using LLM - suggested updates
(or textual gradients) over minibatches of training samples. In this paper, we
empirically demonstrate that scaling the number of training examples initially
improves but later degrades TGD's performance across multiple downstream NLP
tasks. However, while data scaling improves results for most tasks, it also
significantly increases the computational cost when leveraging LLMs. To address
this, we draw inspiration from numerical gradient descent and propose Textual
Stochastic Gradient Descent with Momentum (TSGD-M) - a method that facilitates
scalable in-context learning by reweighting prompt sampling based on past batch
distributions. Across nine NLP tasks spanning three domains - including
BIG-Bench Hard (BBH), natural language understanding tasks, and reasoning tasks
- TSGD-M significantly outperforms TGD baselines that do not incorporate
reweighted sampling, while also reducing variance in most tasks.

</details>


### [47] [Causal Structure Discovery for Error Diagnostics of Children's ASR](https://arxiv.org/abs/2506.00402)
*Vishwanath Pratap Singh,Md. Sahidullah,Tomi Kinnunen*

Main category: cs.CL

TL;DR: 本文通过因果结构发现分析影响儿童 ASR 的因素，并测量各因素影响，实验表明结果在不同 ASR 系统中具有广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法只考虑各因素的单独影响，忽视了相互之间的依赖关系。

Method: 因果结构发现和因果量化方法用于分析儿童 ASR 的影响因素。

Result: 在实验中，通过对模型的微调，辨识出哪些因素对儿童 ASR 的影响被减小，哪些因素仍然存在显著影响。

Conclusion: 通过因果结构发现和因果量化分析，识别出影响儿童 ASR 的关键因素，并分析在模型微调后仍然受到影响的因素。结果在不同的 ASR 系统中展示出广泛的适用性。

Abstract: Children's automatic speech recognition (ASR) often underperforms compared to
that of adults due to a confluence of interdependent factors: physiological
(e.g., smaller vocal tracts), cognitive (e.g., underdeveloped pronunciation),
and extrinsic (e.g., vocabulary limitations, background noise). Existing
analysis methods examine the impact of these factors in isolation, neglecting
interdependencies-such as age affecting ASR accuracy both directly and
indirectly via pronunciation skills. In this paper, we introduce a causal
structure discovery to unravel these interdependent relationships among
physiology, cognition, extrinsic factors, and ASR errors. Then, we employ
causal quantification to measure each factor's impact on children's ASR. We
extend the analysis to fine-tuned models to identify which factors are
mitigated by fine-tuning and which remain largely unaffected. Experiments on
Whisper and Wav2Vec2.0 demonstrate the generalizability of our findings across
different ASR systems.

</details>


### [48] [Accelerating Diffusion LLMs via Adaptive Parallel Decoding](https://arxiv.org/abs/2506.00413)
*Daniel Israel,Guy Van den Broeck,Aditya Grover*

Main category: cs.CL

TL;DR: 引入APD方法，通过混合dLLM和小型自回归模型的联合概率来动态调整并行生成速度，优化了性能，达到高吞吐量且质量损失小。


<details>
  <summary>Details</summary>
Motivation: 寻求解决扩散大语言模型（dLLMs）在实现并行令牌生成时难以在速度上超越自回归模型且不明显牺牲质量的问题。

Method: 引入自适应并行解码（APD）方法，通过定义dLLM边际概率与小型辅助自回归模型的序列联合概率的乘法混合来动态调整并行采样的令牌数量。

Result: APD可以灵活地在吞吐量和质量之间进行调整，优化了KV缓存并限制了输入遮罩的大小。

Conclusion: APD显著提高了吞吐量，并且在主要评测中质量仅有微小的下降。

Abstract: The generation speed of LLMs are bottlenecked by autoregressive decoding,
where tokens are predicted sequentially one by one. Alternatively, diffusion
large language models (dLLMs) theoretically allow for parallel token
generation, but in practice struggle to achieve the speed of autoregressive
models without significantly sacrificing quality. We therefore introduce
adaptive parallel decoding (APD), a novel method that dynamically adjusts the
number of tokens sampled in parallel. We achieve this by defining a
multiplicative mixture between the dLLM marginal probabilities and the joint
probability of sequences under a small auxiliary autoregressive model. This
inverts the standard setup of speculative decoding, where the goal is to sample
from a large autoregressive verifier by drafting from a smaller model. We
further optimize APD by enabling KV caching and limiting the size of the masked
input. Altogether, our method puts forward three tunable parameters to flexibly
tradeoff throughput and quality. We show that APD provides markedly higher
throughput with minimal quality degradations on downstream benchmarks.

</details>


### [49] [Dual Debiasing for Noisy In-Context Learning for Text Generation](https://arxiv.org/abs/2506.00418)
*Siqi Liang,Sumyeong Ahn,Paramveer S. Dhillon,Jiayu Zhou*

Main category: cs.CL

TL;DR: 提出一种双重去偏框架以改善噪声注释下的文本生成，实验结果表明其噪声检测能力优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理高噪声比例的语料库时存在缺陷，因此需要重新审视基于困惑度的文本生成范式，并克服困惑度中的偏差。

Method: 引入双重去偏框架，通过使用合成邻居来显式校正困惑度估计，产生稳健的样本清洁度评分。

Result: 实验表明，我们的方法具有优越的噪声检测能力，并且在噪声比例极高的情况下仍能维持良好性能。

Conclusion: 我们的方法能够在高噪声比率条件下保持稳健性，并且最终的ICL性能与完全干净的示例语料库相当。

Abstract: In context learning (ICL) relies heavily on high quality demonstrations drawn
from large annotated corpora. Existing approaches detect noisy annotations by
ranking local perplexities, presuming that noisy samples yield higher
perplexities than their clean counterparts. However, this assumption breaks
down when the noise ratio is high and many demonstrations are flawed. We
reexamine the perplexity based paradigm for text generation under noisy
annotations, highlighting two sources of bias in perplexity: the annotation
itself and the domain specific knowledge inherent in large language models
(LLMs). To overcome these biases, we introduce a dual debiasing framework that
uses synthesized neighbors to explicitly correct perplexity estimates, yielding
a robust Sample Cleanliness Score. This metric uncovers absolute sample
cleanliness regardless of the overall corpus noise level. Extensive experiments
demonstrate our method's superior noise detection capabilities and show that
its final ICL performance is comparable to that of a fully clean demonstration
corpus. Moreover, our approach remains robust even when noise ratios are
extremely high.

</details>


### [50] [Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions](https://arxiv.org/abs/2506.00421)
*Jihyoung Jang,Minwook Bae,Minji Kim,Dilek Hakkani-Tur,Hyounghun Kim*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种新的多模态对话模型和数据集M^3C，能够处理视觉和听觉信息，实现更丰富的互动体验。


<details>
  <summary>Details</summary>
Motivation: 随着聊天机器人的发展，研究人员希望将多模态性融入其中，以实现更贴近人类的真实世界互动。然而，以往的研究过于关注图像任务，而忽略了听觉方面。这项研究旨在解决这些挑战，提升聊天机器人的互动能力。

Method: 引入一个新的多模态对话数据集M^3C，并提出一种新颖的多模态对话模型，该模型具有多模态记忆检索功能。

Result: 模型在复杂的现实环境中表现良好，能够处理视觉和听觉输入，进行长时间、多方的互动。

Conclusion: 通过人类评估，证明了模型在保持连贯和动态互动方面的强大能力，展示了其作为先进多模态对话代理的潜力。

Abstract: As chatbots continue to evolve toward human-like, real-world, interactions,
multimodality remains an active area of research and exploration. So far,
efforts to integrate multimodality into chatbots have primarily focused on
image-centric tasks, such as visual dialogue and image-based instructions,
placing emphasis on the "eyes" of human perception while neglecting the "ears",
namely auditory aspects. Moreover, these studies often center around static
interactions that focus on discussing the modality rather than naturally
incorporating it into the conversation, which limits the richness of
simultaneous, dynamic engagement. Furthermore, while multimodality has been
explored in multi-party and multi-session conversations, task-specific
constraints have hindered its seamless integration into dynamic, natural
conversations. To address these challenges, this study aims to equip chatbots
with "eyes and ears" capable of more immersive interactions with humans. As
part of this effort, we introduce a new multimodal conversation dataset,
Multimodal Multi-Session Multi-Party Conversation ($M^3C$), and propose a novel
multimodal conversation model featuring multimodal memory retrieval. Our model,
trained on the $M^3C$, demonstrates the ability to seamlessly engage in
long-term conversations with multiple speakers in complex, real-world-like
settings, effectively processing visual and auditory inputs to understand and
respond appropriately. Human evaluations highlight the model's strong
performance in maintaining coherent and dynamic interactions, demonstrating its
potential for advanced multimodal conversational agents.

</details>


### [51] [DYNAC: Dynamic Vocabulary based Non-Autoregressive Contextualization for Speech Recognition](https://arxiv.org/abs/2506.00422)
*Yui Sudo,Yosuke Fukumoto,Muhammad Shakeel,Yifan Peng,Chyi-Jiunn Lin,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文提出DYNAC方法，将动态词汇集成到非自回归CTC模型中，有效降低实时因子并保持语境偏向准确。


<details>
  <summary>Details</summary>
Motivation: 动态词汇能够提高语境偏向精度，但在自回归模型中推理速度较慢。为了在非自回归模型中应用动态词汇并解决条件独立假设所导致的依赖关系捕捉问题，提出新的方法。

Method: 本文提出了一种自条件化CTC方法（DYNAC），将动态词汇整合到中间层，对编码器进行动态词汇条件化，以捕捉静态和动态词之间的依赖关系。

Result: 实验结果表明，DYNAC在LibriSpeech 960 test-clean集合上将实时因子降低了81%，同时词错误率仅略微下降了0.1个百分点。

Conclusion: 本文提出的DYNAC方法通过在中间层集成动态词汇，有效捕获了静态和动态词之间的依赖关系，同时显著降低了实时因子（RTF）。

Abstract: Contextual biasing (CB) improves automatic speech recognition for rare and
unseen phrases. Recent studies have introduced dynamic vocabulary, which
represents context phrases as expandable tokens in autoregressive (AR) models.
This method improves CB accuracy but with slow inference speed. While dynamic
vocabulary can be applied to non-autoregressive (NAR) models, such as
connectionist temporal classification (CTC), the conditional independence
assumption fails to capture dependencies between static and dynamic tokens.
This paper proposes DYNAC (Dynamic Vocabulary-based NAR Contextualization), a
self-conditioned CTC method that integrates dynamic vocabulary into
intermediate layers. Conditioning the encoder on dynamic vocabulary, DYNAC
effectively captures dependencies between static and dynamic tokens while
reducing the real-time factor (RTF). Experimental results show that DYNAC
reduces RTF by 81% with a 0.1-point degradation in word error rate on the
LibriSpeech 960 test-clean set.

</details>


### [52] [Inter-Passage Verification for Multi-evidence Multi-answer QA](https://arxiv.org/abs/2506.00425)
*Bingsen Chen,Shengjie Wang,Xi Ye,Chen Zhao*

Main category: cs.CL

TL;DR: RI$^2$VER enhances multi-answer QA by individually processing passages and using inter-passage verification, greatly improving F1 scores over existing systems.


<details>
  <summary>Details</summary>
Motivation: Existing retrieval-augmented generation-based QA systems struggle to manage large amounts of evidence due to multiple valid answers, motivating the need for an improved framework to handle multi-answer questions.

Method: The proposed method retrieves a large set of passages, processes each individually to generate initial answers, and then applies an inter-passage verification pipeline involving verification question generation, gathering additional evidence, and verification through inter-passage synthesis.

Result: Evaluations on the QAMPARI and RoMQA datasets show the proposed framework outperforms existing baselines across various model sizes, improving the average F1 score by 11.17%.

Conclusion: RI$^2$VER framework significantly improves multi-answer QA by effectively handling challenges of retrieving and synthesizing evidence from multiple passages, outperforming existing baselines with an average F1 score improvement of 11.17%.

Abstract: Multi-answer question answering (QA), where questions can have many valid
answers, presents a significant challenge for existing retrieval-augmented
generation-based QA systems, as these systems struggle to retrieve and then
synthesize a large number of evidence passages. To tackle these challenges, we
propose a new multi-answer QA framework -- Retrieval-augmented Independent
Reading with Inter-passage Verification (RI$^2$VER). Our framework retrieves a
large set of passages and processes each passage individually to generate an
initial high-recall but noisy answer set. Then we propose a new inter-passage
verification pipeline that validates every candidate answer through (1)
Verification Question Generation, (2) Gathering Additional Evidence, and (3)
Verification with inter-passage synthesis. Evaluations on the QAMPARI and RoMQA
datasets demonstrate that our framework significantly outperforms existing
baselines across various model sizes, achieving an average F1 score improvement
of 11.17%. Further analysis validates that our inter-passage verification
pipeline enables our framework to be particularly beneficial for questions
requiring multi-evidence synthesis.

</details>


### [53] [G2S: A General-to-Specific Learning Framework for Temporal Knowledge Graph Forecasting with Large Language Models](https://arxiv.org/abs/2506.00445)
*Long Bai,Zixuan Li,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 提出了一种新的学习框架G2S，通过分离一般模式和场景信息的学习过程，提高了大型语言模型在时间知识图谱（TKG）预测任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高模型在TKG预测任务中的泛化能力，现有研究引入了大型语言模型（LLMs），但这些模型在学习过程中将两种知识（一般模式和场景信息）混淆，互相干扰，影响泛化能力。因而提出一种新的学习框架，以分离这两种知识的学习过程，提高泛化能力。

Method: 提出了一种称为G2S的学习框架，它通过将学习过程分为两个阶段来解决问题。在第一个阶段，通过将场景信息掩盖，将其转换为匿名的时间结构，让模型捕捉不同TKG中的一般模式。在第二个阶段，使用情景信息，通过上下文学习或微调方式将其注入结构中。

Result: 实验结果表明，G2S框架有效提高了大型语言模型的泛化能力。

Conclusion: G2S学习框架成功地分离了一般模式和场景信息的学习过程，提高了大型语言模型在TKG预测任务中的泛化能力。通过实验验证了其有效性。

Abstract: Forecasting over Temporal Knowledge Graphs (TKGs) which predicts future facts
based on historical ones has received much attention. Recent studies have
introduced Large Language Models (LLMs) for this task to enhance the models'
generalization abilities. However, these models perform forecasting via
simultaneously learning two kinds of entangled knowledge in the TKG: (1)
general patterns, i.e., invariant temporal structures shared across different
scenarios; and (2) scenario information, i.e., factual knowledge engaged in
specific scenario, such as entities and relations. As a result, the learning
processes of these two kinds of knowledge may interfere with each other, which
potentially impact the generalization abilities of the models. To enhance the
generalization ability of LLMs on this task, in this paper, we propose a
General-to-Specific learning framework (G2S) that disentangles the learning
processes of the above two kinds of knowledge. In the general learning stage,
we mask the scenario information in different TKGs and convert it into
anonymous temporal structures. After training on these structures, the model is
able to capture the general patterns across different TKGs. In the specific
learning stage, we inject the scenario information into the structures via
either in-context learning or fine-tuning modes. Experimental results show that
G2S effectively improves the generalization abilities of LLMs.

</details>


### [54] [Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization](https://arxiv.org/abs/2506.00448)
*Suhas BN,Han-Chin Shing,Lei Xu,Mitch Strong,Jon Burnsky,Jessica Ofor,Jordan R. Mason,Susan Chen,Sundararajan Srinivasan,Chaitanya Shivade,Jack Moriarty,Joseph Paul Cohen*

Main category: cs.CL

TL;DR: 研究评估了医学领域的幻觉检测方法，开发的LLM检测器能有效检测真实世界的临床幻觉，而通用检测器表现不佳。


<details>
  <summary>Details</summary>
Motivation: 在患者-临床医生对话总结中，LLM出现幻觉对病人护理和临床决策造成重大风险，因此需要专门研究临床域中的幻觉检测方法。

Method: 我们评估了医学领域中的幻觉检测方法，构建了两个数据集：一个是通过系统地从源对话中删除事实以诱导在总结中出现幻觉内容的"fact-controlled Leave-N-out"数据集，另一个是自然产生的幻觉数据集。

Result: 我们开发的基于LLM的检测器在检测真实世界的临床幻觉方面表现良好，而通用领域的检测器在检测临床幻觉时表现不佳，并且在控制幻觉上表现良好的能力并不一定能有效预测其对自然幻觉的检测效率。

Conclusion: 我们的研究贡献了一套由专家标注的数据集支持的专业化指标，以推进可信的临床总结系统。

Abstract: Hallucinations in large language models (LLMs) during summarization of
patient-clinician dialogues pose significant risks to patient care and clinical
decision-making. However, the phenomenon remains understudied in the clinical
domain, with uncertainty surrounding the applicability of general-domain
hallucination detectors. The rarity and randomness of hallucinations further
complicate their investigation. In this paper, we conduct an evaluation of
hallucination detection methods in the medical domain, and construct two
datasets for the purpose: A fact-controlled Leave-N-out dataset -- generated by
systematically removing facts from source dialogues to induce hallucinated
content in summaries; and a natural hallucination dataset -- arising
organically during LLM-based medical summarization. We show that general-domain
detectors struggle to detect clinical hallucinations, and that performance on
fact-controlled hallucinations does not reliably predict effectiveness on
natural hallucinations. We then develop fact-based approaches that count
hallucinations, offering explainability not available with existing methods.
Notably, our LLM-based detectors, which we developed using fact-controlled
hallucinations, generalize well to detecting real-world clinical
hallucinations. This research contributes a suite of specialized metrics
supported by expert-annotated datasets to advance faithful clinical
summarization systems.

</details>


### [55] [Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data](https://arxiv.org/abs/2506.00469)
*Shaoxiong Ji,Zihao Li,Jaakko Paavola,Indraneil Paul,Hengyu Luo,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 该论文研究了双语翻译数据对Llama3模型多语言适应的影响，通过实验表明双语数据能提升语言迁移和性能，尤其是低资源语言。


<details>
  <summary>Details</summary>
Motivation: 研究多语言连续预训练的关键设计决策 -- 平行数据的包含，以及双语翻译数据对多语言语言适应的影响。

Method: 构建MaLA双语翻译语料库，开发EMMA-500 Llama 3套件，通过对多种数据组合进行连续预训练，研究双语翻译数据对语言适应的影响。

Result: 在7个任务和12个基准上的综合评估表明，双语数据可以增强语言迁移和性能。

Conclusion: 双语数据倾向于增强语言迁移和性能，特别是对低资源语言。

Abstract: This paper investigates a critical design decision in the practice of
massively multilingual continual pre-training -- the inclusion of parallel
data. Specifically, we study the impact of bilingual translation data for
massively multilingual language adaptation of the Llama3 family of models to
500 languages. To this end, we construct the MaLA bilingual translation corpus,
containing data from more than 2,500 language pairs. Subsequently, we develop
the EMMA-500 Llama 3 suite of four massively multilingual models -- continually
pre-trained from the Llama 3 family of base models extensively on diverse data
mixes up to 671B tokens -- and explore the effect of continual pre-training
with or without bilingual translation data. Comprehensive evaluation across 7
tasks and 12 benchmarks demonstrates that bilingual data tends to enhance
language transfer and performance, particularly for low-resource languages. We
open-source the MaLA corpus, EMMA-500 Llama 3 suite artefacts, code, and model
generations.

</details>


### [56] [EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models](https://arxiv.org/abs/2506.00479)
*Zekun Wang,Minghua Ma,Zexin Wang,Rongchuan Mu,Liping Shan,Ming Liu,Bing Qin*

Main category: cs.CL

TL;DR: 本文评估了LVLMs的加速技术，提出EffiVLM-Bench框架并揭示了优化策略。


<details>
  <summary>Details</summary>
Motivation: LVLMs尽管取得了巨大成功，但其计算需求高，影响了实际部署。因此需要系统评估以提升效率。

Method: 本文将LVLMs的加速技术分为‘token’压缩和‘parameter’压缩两类，介绍了一个统一的评估框架EffiVLM-Bench，用于评估绝对性能、泛化能力和忠诚性。

Result: 本文提供了全面的实验和深入分析，揭示了LVLMs加速技术的最优策略，并开源了EffiVLM-Bench的代码和指南。

Conclusion: 本文通过对主流加速技术进行系统评估，揭示了LVLMs加速的最优策略，促进了未来研究。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable success, yet
their significant computational demands hinder practical deployment. While
efforts to improve LVLM efficiency are growing, existing methods lack
comprehensive evaluation across diverse backbones, benchmarks, and metrics. In
this work, we systematically evaluate mainstream acceleration techniques for
LVLMs, categorized into token and parameter compression. We introduce
EffiVLM-Bench, a unified framework for assessing not only absolute performance
but also generalization and loyalty, while exploring Pareto-optimal trade-offs.
Our extensive experiments and in-depth analyses offer insights into optimal
strategies for accelerating LVLMs. We open-source code and recipes for
EffiVLM-Bench to foster future research.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human-AI Synergy](https://arxiv.org/abs/2506.00056)
*Hugon Lee,Hyeonbin Moon,Junhyeong Lee,Seunghwa RYu*

Main category: cs.AI

TL;DR: 提出通过将领域知识、物理启发学习与人机交互结合，提升逆向设计中的AI系统效率和智能水平。


<details>
  <summary>Details</summary>
Motivation: 当前的逆向设计过程中，完全依赖数据驱动的方法在稀疏数据、高维设计空间以及复杂物理约束的现实环境中表现不佳。

Method: 采用专家指导的采样策略、物理启发的机器学习，并探索大语言模型作为交互式设计代理。

Result: 提出了一种新的逆向设计系统框架，结合领域知识、物理先验和自适应推理，实现可扩展、可解释和可访问的AI驱动设计系统。

Conclusion: 逆向设计应发展为一个统一的生态系统，整合领域知识、物理启发和人类-AI交互，使设计系统更高效和智能。

Abstract: Artificial intelligence (AI) is reshaping inverse design across manufacturing
domain, enabling high-performance discovery in materials, products, and
processes. However, purely data-driven approaches often struggle in realistic
settings characterized by sparse data, high-dimensional design spaces, and
nontrivial physical constraints. This perspective argues for a new generation
of design systems that transcend black-box modeling by integrating domain
knowledge, physics-informed learning, and intuitive human-AI interfaces. We
first demonstrate how expert-guided sampling strategies enhance data efficiency
and model generalization. Next, we discuss how physics-informed machine
learning enables physically consistent modeling in data-scarce regimes.
Finally, we explore how large language models emerge as interactive design
agents connecting user intent with simulation tools, optimization pipelines,
and collaborative workflows. Through illustrative examples and conceptual
frameworks, we advocate that inverse design in manufacturing should evolve into
a unified ecosystem, where domain knowledge, physical priors, and adaptive
reasoning collectively enable scalable, interpretable, and accessible AI-driven
design systems.

</details>


### [58] [The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets](https://arxiv.org/abs/2506.00073)
*Shenzhe Zhu,Jiao Sun,Yi Nian,Tobin South,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: AI代理在消费市场中的自动化交易存在风险和效率问题，用户应谨慎委派决策。


<details>
  <summary>Details</summary>
Motivation: 探讨未来情境中消费者和商家授权AI代理完全自动化谈判和交易的可能性。

Method: 开发一个实验框架，用于评估各种LLM代理在现实世界中的谈判和交易环境中的表现。

Result: AI中介的交易存在固有的不平衡，不同代理为用户实现的结果差异显著。此外，LLM中的行为异常可能导致消费者和商家遭受财务损失，例如过度支出或接受不合理的交易。

Conclusion: 虽然自动化可以提高效率，但也带来了显著风险，用户在将业务决策委派给AI代理时应谨慎。

Abstract: AI agents are increasingly used in consumer-facing applications to assist
with tasks such as product search, negotiation, and transaction execution. In
this paper, we explore a future scenario where both consumers and merchants
authorize AI agents to fully automate negotiations and transactions. We aim to
answer two key questions: (1) Do different LLM agents vary in their ability to
secure favorable deals for users? (2) What risks arise from fully automating
deal-making with AI agents in consumer markets? To address these questions, we
develop an experimental framework that evaluates the performance of various LLM
agents in real-world negotiation and transaction settings. Our findings reveal
that AI-mediated deal-making is an inherently imbalanced game -- different
agents achieve significantly different outcomes for their users. Moreover,
behavioral anomalies in LLMs can result in financial losses for both consumers
and merchants, such as overspending or accepting unreasonable deals. These
results underscore that while automation can improve efficiency, it also
introduces substantial risks. Users should exercise caution when delegating
business decisions to AI agents.

</details>


### [59] [Balancing Profit and Fairness in Risk-Based Pricing Markets](https://arxiv.org/abs/2506.00140)
*Jesse Thibodeau,Hadi Nekoei,Afaf Taïk,Janarthanan Rajendran,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 研究提出通过学习的税收计划来解决动态定价带来的社会问题，展示了AI监管的实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 动态和风险为基础的定价可能导致弱势消费群体被系统性地排除在基本资源之外，研究希望通过学习的、可解释的税收计划将私人的激励与社会目标重新对齐。

Method: 使用强化学习（RL）社会计划者来选择分级的公平税，并通过\(\mathcal{L}_1\)正则化保持接近简单线性先验。

Result: 在两个经过实证校准的市场中（即美国健康保险和消费者信贷），计划者在不明确协调的情况下同时提高需求公平性最多达16%，社会福利表现优于固定线性计划。

Conclusion: AI辅助监管可以在不明确合作的情况下，提高社会福利和需求公平性，提供了一种公平市场监管的原则性和实用性框架。

Abstract: Dynamic, risk-based pricing can systematically exclude vulnerable consumer
groups from essential resources such as health insurance and consumer credit.
We show that a regulator can realign private incentives with social objectives
through a learned, interpretable tax schedule. First, we provide a formal
proposition that bounding each firm's \emph{local} demographic gap implicitly
bounds the \emph{global} opt-out disparity, motivating firm-level penalties.
Building on this insight we introduce \texttt{MarketSim} -- an open-source,
scalable simulator of heterogeneous consumers and profit-maximizing firms --
and train a reinforcement learning (RL) social planner (SP) that selects a
bracketed fairness-tax while remaining close to a simple linear prior via an
$\mathcal{L}_1$ regularizer. The learned policy is thus both transparent and
easily interpretable. In two empirically calibrated markets, i.e., U.S.
health-insurance and consumer-credit, our planner simultaneously raises
demand-fairness by up to $16\%$ relative to unregulated Free Market while
outperforming a fixed linear schedule in terms of social welfare without
explicit coordination. These results illustrate how AI-assisted regulation can
convert a competitive social dilemma into a win-win equilibrium, providing a
principled and practical framework for fairness-aware market oversight.

</details>


### [60] [Utilizing AI for Aviation Post-Accident Analysis Classification](https://arxiv.org/abs/2506.00169)
*Aziida Nanyonga,Graham Wild*

Main category: cs.AI

TL;DR: 研究如何通过NLP和深度学习提升航空安全报告分析的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 文本数据量庞大的航空安全报告在及时准确分析方面存在挑战，研究如何通过人工智能（AI）和自然语言处理（NLP）自动化数据洞察提取，以增进航空安全。

Method: 应用自然语言处理（NLP）、深度学习以及主题建模（TM）技术，对来自不同安全机构的数据集进行分析和比较。

Result: 应用NLP、深度学习和主题建模技术能够显著提高航空安全分析的效率和准确性。

Conclusion: 自然语言处理（NLP）和深度学习在航空安全分析中具有显著提高效率和准确性的潜力，有助于推进更主动的安全管理和风险缓解策略。

Abstract: The volume of textual data available in aviation safety reports presents a
challenge for timely and accurate analysis. This paper examines how Artificial
Intelligence (AI) and, specifically, Natural Language Processing (NLP) can
automate the process of extracting valuable insights from this data, ultimately
enhancing aviation safety. The paper reviews ongoing efforts focused on the
application of NLP and deep learning to aviation safety reports, with the goal
of classifying the level of damage to an aircraft and identifying the phase of
flight during which safety occurrences happen. Additionally, the paper explores
the use of Topic Modeling (TM) to uncover latent thematic structures within
aviation incident reports, aiming to identify recurring patterns and potential
areas for safety improvement. The paper compares and contrasts the performance
of various deep learning models and TM techniques applied to datasets from the
National Transportation Safety Board (NTSB) and the Australian Transport Safety
Bureau (ATSB), as well as the Aviation Safety Network (ASN), discussing the
impact of dataset size and source on the accuracy of the analysis. The findings
demonstrate that both NLP and deep learning, as well as TM, can significantly
improve the efficiency and accuracy of aviation safety analysis, paving the way
for more proactive safety management and risk mitigation strategies.

</details>


### [61] [Tournament of Prompts: Evolving LLM Instructions Through Structured Debates and Elo Ratings](https://arxiv.org/abs/2506.00178)
*Anirudh Nair,Adi Banerjee,Laurent Mombaerts,Matthew Hagen,Tarik Borogovac*

Main category: cs.AI

TL;DR: DEEVO是一种新的提示优化框架，通过辩论驱动的评估和基于Elo选择来优化提示，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型解决复杂任务的提示工程困难，需要专业知识、大量的试错和人工干预，特别是对主观质量评估任务而言。

Method: 引入DEEVO框架，通过辩论驱动的评估和基于Elo选择来指导提示演化，并通过智能交叉和战略突变操作来保持语义一致性。

Result: 实验结果表明，DEEVO在开放式和闭合式任务中显著优于人工提示工程和替代的优化方法。

Conclusion: DEEVO显著优于手动提示工程和替代的优化方法，无需真实反馈即可在开放式和闭合式任务中表现出色。

Abstract: Prompt engineering represents a critical bottleneck to harness the full
potential of Large Language Models (LLMs) for solving complex tasks, as it
requires specialized expertise, significant trial-and-error, and manual
intervention. This challenge is particularly pronounced for tasks involving
subjective quality assessment, where defining explicit optimization objectives
becomes fundamentally problematic. Existing automated prompt optimization
methods falter in these scenarios, as they typically require well-defined
task-specific numerical fitness functions or rely on generic templates that
cannot capture the nuanced requirements of complex use cases. We introduce
DEEVO (DEbate-driven EVOlutionary prompt optimization), a novel framework that
guides prompt evolution through a debate-driven evaluation with an Elo-based
selection. Contrary to prior work, DEEVOs approach enables exploration of the
discrete prompt space while preserving semantic coherence through intelligent
crossover and strategic mutation operations that incorporate debate-based
feedback, combining elements from both successful and unsuccessful prompts
based on identified strengths rather than arbitrary splicing. Using Elo ratings
as a fitness proxy, DEEVO simultaneously drives improvement and preserves
valuable diversity in the prompt population. Experimental results demonstrate
that DEEVO significantly outperforms both manual prompt engineering and
alternative state-of-the-art optimization approaches on open-ended tasks and
close-ended tasks despite using no ground truth feedback. By connecting LLMs
reasoning capabilities with adaptive optimization, DEEVO represents a
significant advancement in prompt optimization research by eliminating the need
of predetermined metrics to continuously improve AI systems.

</details>


### [62] [Control-R: Towards controllable test-time scaling](https://arxiv.org/abs/2506.00189)
*Di Zhang,Weida Wang,Junxian Li,Xunzhi Wang,Jiatong Li,Jianbo Wu,Jingdi Lei,Haonan He,Peng Ye,Shufei Zhang,Wanli Ouyang,Yuqiang Li,Dongzhan Zhou*

Main category: cs.AI

TL;DR: 提出了RCF和CDF方法来优化长链推理中的问题，实现了在32B规模上的最先进性能和可控测试时间推理。


<details>
  <summary>Details</summary>
Motivation: 解决在长链推理过程中因推理过度或不足而面临的挑战，并实现能够根据给定的控制条件调整推理力度的模型。

Method: 利用Reasoning Control Fields (RCF)和Conditional Distillation Finetuning (CDF)方法对推理过程进行控制和优化。RCF通过树搜索的视角注入结构化控制信号以指导推理，CDF通过训练模型在测试时有效调整推理努力。

Result: 实验结果表明，在如AIME2024和MATH500的基准测试中，该方法在32B规模上实现了最先进的性能，并允许可控的长链推理过程。

Conclusion: 本文提出了一种有效的可控测试时间推理缩放范式，从而实现在长链推理过程中的可控性。通过RCF和CDF方法，模型在32B规模上实现了最先进的性能，同时能够在复杂任务中调整推理力度。

Abstract: This paper target in addressing the challenges of underthinking and
overthinking in long chain-of-thought (CoT) reasoning for Large Reasoning
Models (LRMs) by introducing Reasoning Control Fields (RCF)--a novel test-time
approach that injects structured control signals to guide reasoning from a tree
search perspective. RCF enables models to adjust reasoning effort according to
given control conditions when solving complex tasks. Additionally, we present
the Control-R-4K dataset, which consists of challenging problems annotated with
detailed reasoning processes and corresponding control fields. To further
enhance reasoning control, we propose a Conditional Distillation Finetuning
(CDF) method, which trains model--particularly Control-R-32B--to effectively
adjust reasoning effort during test time. Experimental results on benchmarks
such as AIME2024 and MATH500 demonstrate that our approach achieves
state-of-the-art performance at the 32B scale while enabling a controllable
Long CoT reasoning process (L-CoT). Overall, this work introduces an effective
paradigm for controllable test-time scaling reasoning.

</details>


### [63] [What do professional software developers need to know to succeed in an age of Artificial Intelligence?](https://arxiv.org/abs/2506.00202)
*Matthew Kam,Cody Miller,Miaoxin Wang,Abey Tidwell,Irene A. Lee,Joyce Malyn-Smith,Beatriz Perez,Vikram Tiwari,Joshua Kenitzer,Andrew Macvean,Erin Barrar*

Main category: cs.AI

TL;DR: 研究了AI对开发人员的影响，分析了所需技能，提出了技能提升的建议，以应对可能的劳动力市场变化和技能退化。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI对软件开发人员的生产力提升，同时关注其对劳动力市场的影响及可能带来的技能退化。

Method: 研究了21名处于AI应用前沿的开发者，总结并分析了他们的工作目标、相关任务以及所需的技能和知识，从中提炼出五条见解。

Result: 得出了成功的AI增强开发人员的技能和知识分为四个领域，并在六步任务流程中的关键节点进行应用的研究结果。

Conclusion: 为了在AI时代保持开发人员的技术竞争力，工作中的学习计划和计算机科学学位项目需要同时关注“软”技能以及四个领域的技术技能和知识，以重塑、提升技能并防止技能退化。

Abstract: Generative AI is showing early evidence of productivity gains for software
developers, but concerns persist regarding workforce disruption and deskilling.
We describe our research with 21 developers at the cutting edge of using AI,
summarizing 12 of their work goals we uncovered, together with 75 associated
tasks and the skills & knowledge for each, illustrating how developers use AI
at work. From all of these, we distilled our findings in the form of 5
insights. We found that the skills & knowledge to be a successful AI-enhanced
developer are organized into four domains (using Generative AI effectively,
core software engineering, adjacent engineering, and adjacent non-engineering)
deployed at critical junctures throughout a 6-step task workflow. In order to
"future proof" developers for this age of AI, on-the-job learning initiatives
and computer science degree programs will need to target both "soft" skills and
the technical skills & knowledge in all four domains to reskill, upskill and
safeguard against deskilling.

</details>


### [64] [Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs](https://arxiv.org/abs/2506.00577)
*Yufa Zhou,Shaobo Wang,Xingyu Dong,Xiangqi Jin,Yifang Chen,Yue Min,Kexin Yang,Xingzhang Ren,Dayiheng Liu,Linfeng Zhang*

Main category: cs.AI

TL;DR: 该论文探讨通过监督微调和强化学习提高大型语言模型在多智能体系统中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 直接训练大型语言模型用于多智能体系统具有挑战性。这是由于复杂的奖励建模、动态的智能体交互以及严格的泛化要求。

Method: 该研究探讨了后训练技术，尤其是监督微调和基于可验证奖励的强化学习，是否能够有效泛化到多智能体场景中。它使用经济学推理作为试验平台，开发了一个名为Recon的7B参数开放源代码语言模型，后训练于2100个高质量经济学推理问题的数据集上。

Result: 在经济学推理基准和多智能体游戏的综合评估中，该模型在结构化推理和经济合理性方面显示出明显改进。

Conclusion: 域对齐的后训练技术能够提升模型的推理能力和智能体对齐能力，这也强调了监督微调和强化学习在塑造模型行为中的作用。

Abstract: Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS)
remains challenging due to intricate reward modeling, dynamic agent
interactions, and demanding generalization requirements. This paper explores
whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and
Reinforcement Learning with Verifiable Rewards (RLVR), can effectively
$\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a
testbed, leveraging its strong foundations in mathematics and game theory, its
demand for structured analytical reasoning, and its relevance to real-world
applications such as market design, resource allocation, and policy analysis.
We introduce $\textbf{Recon}$ ($\textbf{R}$easoning like an
$\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a
hand-curated dataset of 2,100 high-quality economic reasoning problems.
Comprehensive evaluation on economic reasoning benchmarks and multi-agent games
reveals clear improvements in structured reasoning and economic rationality.
These results underscore the promise of domain-aligned post-training for
enhancing reasoning and agent alignment, shedding light on the roles of SFT and
RL in shaping model behavior. Code is available at
https://github.com/MasterZhou1/Recon .

</details>


### [65] [Ethical AI: Towards Defining a Collective Evaluation Framework](https://arxiv.org/abs/2506.00233)
*Aasish Kumar Sharma,Dimitar Kyosev,Julian Kunkel*

Main category: cs.AI

TL;DR: 本文提出了一个基于本体论模块的伦理框架，以应对数据所有权、隐私、偏见问题，结合FAIR原则，可用于AI伦理评估，并通过一个案例展示了其实用性。


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速整合带来了有关数据所有权、隐私和系统偏见的紧迫伦理问题。

Method: 提出一个基于本体论模块的伦理评估框架，结合FAIR原则，用于评估AI伦理。

Result: 使用实际案例（AI驱动的投资者分析）展示了该框架如何实现动态、行为导向的风险分类。

Conclusion: 本体模块为可解释和可审计的AI伦理提供了有前景的途径，但在自动化和概率推理方面仍存在挑战。

Abstract: Artificial Intelligence (AI) is transforming sectors such as healthcare,
finance, and autonomous systems, offering powerful tools for innovation. Yet
its rapid integration raises urgent ethical concerns related to data ownership,
privacy, and systemic bias. Issues like opaque decision-making, misleading
outputs, and unfair treatment in high-stakes domains underscore the need for
transparent and accountable AI systems. This article addresses these challenges
by proposing a modular ethical assessment framework built on ontological blocks
of meaning-discrete, interpretable units that encode ethical principles such as
fairness, accountability, and ownership. By integrating these blocks with FAIR
(Findable, Accessible, Interoperable, Reusable) principles, the framework
supports scalable, transparent, and legally aligned ethical evaluations,
including compliance with the EU AI Act. Using a real-world use case in
AI-powered investor profiling, the paper demonstrates how the framework enables
dynamic, behavior-informed risk classification. The findings suggest that
ontological blocks offer a promising path toward explainable and auditable AI
ethics, though challenges remain in automation and probabilistic reasoning.

</details>


### [66] [SMELLNET: A Large-scale Dataset for Real-world Smell Recognition](https://arxiv.org/abs/2506.00239)
*Dewei Feng,Carol Li,Wei Dai,Paul Pu Liang*

Main category: cs.AI

TL;DR: 该论文提出SmellNet数据库，用于训练AI以基于嗅觉识别物质，取得了一定的准确率，但仍面临许多技术挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模的基准测试几乎不存在，因此AI系统在现实世界中进行嗅觉训练和评估的进展很少。

Method: 使用便携式气体和化学传感器创建了SmellNet，通过序列模型、对比学习和新的时间差方法训练AI模型，实现了实时基于嗅觉的物质分类。

Result: 最佳模型在预录数据上实现65.35%的准确率，在现实条件下，在坚果和香料的50种在线分类任务中，分别实现了10.71%和25.38%的准确率。

Conclusion: 尽管取得了一些成果，该研究表明构建用于嗅觉的AI仍存在许多技术挑战，包括更丰富的特征学习、边缘嗅觉模型以及对环境变化的鲁棒性。

Abstract: The ability of AI to sense and identify various substances based on their
smell alone can have profound impacts on allergen detection (e.g., smelling
gluten or peanuts in a cake), monitoring the manufacturing process, and sensing
hormones that indicate emotional states, stress levels, and diseases. Despite
these broad impacts, there are virtually no large scale benchmarks, and
therefore little progress, for training and evaluating AI systems' ability to
smell in the real world. In this paper, we use portable gas and chemical
sensors to create SmellNet, the first large-scale database that digitizes a
diverse range of smells in the natural world. SmellNet contains about 180,000
time steps of 50 substances (spanning nuts, spices, herbs, fruits, and
vegetables) with 50 hours of data. Using SmellNet, we train AI models for
real-time classification of substances based on their smell alone. Our best
methods leverage sequence models, contrastive learning to integrate
high-resolution Gas Chromatography-Mass Spectrometry molecular data, and a new
temporal difference method that identifies sharp changes in sensor readings.
Our best models achieve up to 65.35% accuracy on pre-recorded data, and
generalize to real-world conditions with 10.71% accuracy on nuts and 25.38% on
spices in the challenging 50-way online classification task. Despite these
promising results, SmellNet highlights many technical challenges in building AI
for smell, including richer feature learning, on-edge smell models, and
robustness to environmental changes.

</details>


### [67] [Whispers of Many Shores: Cultural Alignment through Collaborative Cultural Expertise](https://arxiv.org/abs/2506.00242)
*Shuai Feng,Wei-Chuang Chan,Srishti Chouhan,Junior Francisco Garcia Ayala,Srujananjali Medicherla,Kyle Clark,Mingwei Shi*

Main category: cs.AI

TL;DR: 提出了一种新的软提示微调框架，通过优化提示嵌入提升LLM的文化敏感性和适应性，不改变基础模型，提高契合度得分并促进多元文化交互。


<details>
  <summary>Details</summary>
Motivation: 目前的大型语言模型在多元文化背景下往往缺乏细致的理解，而调整它们通常需要昂贵的全面微调。

Method: 采用矢量化提示微调，通过优化软提示嵌入来动态地将查询路由到一个由文化专业'专家' LLM配置组成的委员会，而不改变基础模型的参数。

Result: 框架将文化契合度得分从0.208提升到0.820。

Conclusion: 研究成功地证明了软提示微调框架能够显著提高大型语言模型的文化敏感性和适应性，为文化意识的LLM部署提供了强有力的解决方案，并为未来关于文化覆盖和动态专家适应的深入研究铺平了道路。

Abstract: The integration of large language models (LLMs) into global applications
necessitates effective cultural alignment for meaningful and
culturally-sensitive interactions. Current LLMs often lack the nuanced
understanding required for diverse cultural contexts, and adapting them
typically involves costly full fine-tuning. To address this, we introduce a
novel soft prompt fine-tuning framework that enables efficient and modular
cultural alignment. Our method utilizes vectorized prompt tuning to dynamically
route queries to a committee of culturally specialized 'expert' LLM
configurations, created by optimizing soft prompt embeddings without altering
the base model's parameters. Extensive experiments demonstrate that our
framework significantly enhances cultural sensitivity and adaptability,
improving alignment scores from 0.208 to 0.820, offering a robust solution for
culturally-aware LLM deployment. This research paves the way for subsequent
investigations into enhanced cultural coverage and dynamic expert adaptation,
crucial for realizing autonomous AI with deeply nuanced understanding in a
globally interconnected world.

</details>


### [68] [An Empirical Study of Group Conformity in Multi-Agent Systems](https://arxiv.org/abs/2506.01332)
*Min Choi,Keonwoo Kim,Sungwon Chae,Sangyeob Baek*

Main category: cs.AI

TL;DR: 研究发现，LLM代理在辩论中会趋向群体一致性，强调了智能水平在话语中的作用，以及在在线交互中放大片面偏见的风险。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在关于社会争议性问题的辩论中如何影响公众意见。

Method: 通过模拟超过2500场辩论，分析LLM代理从中立立场逐渐采纳特定立场，并进行统计分析。

Result: 统计分析显示，LLM代理往往与数量优势群体或更聪明的代理保持一致，发挥更大影响力，从而反映出人类行为的群体一致性。

Conclusion: 本研究强调了在匿名在线环境中，为防止偏见传播，需要制定政策措施以促进多样性和透明度。

Abstract: Recent advances in Large Language Models (LLMs) have enabled multi-agent
systems that simulate real-world interactions with near-human reasoning. While
previous studies have extensively examined biases related to protected
attributes such as race, the emergence and propagation of biases on socially
contentious issues in multi-agent LLM interactions remain underexplored. This
study explores how LLM agents shape public opinion through debates on five
contentious topics. By simulating over 2,500 debates, we analyze how initially
neutral agents, assigned a centrist disposition, adopt specific stances over
time. Statistical analyses reveal significant group conformity mirroring human
behavior; LLM agents tend to align with numerically dominant groups or more
intelligent agents, exerting a greater influence. These findings underscore the
crucial role of agent intelligence in shaping discourse and highlight the risks
of bias amplification in online interactions. Our results emphasize the need
for policy measures that promote diversity and transparency in LLM-generated
discussions to mitigate the risks of bias propagation within anonymous online
environments.

</details>


### [69] [MIR: Methodology Inspiration Retrieval for Scientific Research Problems](https://arxiv.org/abs/2506.00249)
*Aniketh Garikaparthi,Manasi Patwardhan,Aditya Sanjiv Kanade,Aman Hassan,Lovekesh Vig,Arman Cohan*

Main category: cs.AI

TL;DR: This paper introduces Methodology Inspiration Retrieval (MIR) to aid scientific discovery by improving literature retrieval that can inspire research solutions, using a Methodology Adjacency Graph and LLM aiding in notable performance gains.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the process of retrieving literature that can inspire solutions for a given research problem, termed as Methodology Inspiration Retrieval (MIR), in order to harness the reasoning capabilities of Large Language Models (LLMs) for scientific discovery.

Method: Methodology Adjacency Graph (MAG) is constructed to capture methodological lineage through citation relationships. Use of dense retrievers and MAG allows embedding of 'intuitive prior' to improve the retrieval process beyond semantic similarity. LLM-based re-ranking strategies are adapted for further improvement.

Result: The proposed methods achieved significant improvements: gains of +5.4 in Recall@3 and +7.8 in Mean Average Precision (mAP) over strong baselines. The MIR process was further improved with +4.5 in Recall@3 and +4.8 in mAP by adapting LLM-based re-ranking strategies.

Conclusion: MIR shows promise in enhancing automated scientific discovery, with potential for further advancement in inspiration-driven retrieval.

Abstract: There has been a surge of interest in harnessing the reasoning capabilities
of Large Language Models (LLMs) to accelerate scientific discovery. While
existing approaches rely on grounding the discovery process within the relevant
literature, effectiveness varies significantly with the quality and nature of
the retrieved literature. We address the challenge of retrieving prior work
whose concepts can inspire solutions for a given research problem, a task we
define as Methodology Inspiration Retrieval (MIR). We construct a novel dataset
tailored for training and evaluating retrievers on MIR, and establish
baselines. To address MIR, we build the Methodology Adjacency Graph (MAG);
capturing methodological lineage through citation relationships. We leverage
MAG to embed an "intuitive prior" into dense retrievers for identifying
patterns of methodological inspiration beyond superficial semantic similarity.
This achieves significant gains of +5.4 in Recall@3 and +7.8 in Mean Average
Precision (mAP) over strong baselines. Further, we adapt LLM-based re-ranking
strategies to MIR, yielding additional improvements of +4.5 in Recall@3 and
+4.8 in mAP. Through extensive ablation studies and qualitative analyses, we
exhibit the promise of MIR in enhancing automated scientific discovery and
outline avenues for advancing inspiration-driven retrieval.

</details>


### [70] [Hidden in Plain Sight: Probing Implicit Reasoning in Multimodal Language Models](https://arxiv.org/abs/2506.00258)
*Qianqi Yan,Hongquan Li,Shan Jiang,Yang Zhao,Xinze Guan,Ching-Chen Kuo,Xin Eric Wang*

Main category: cs.AI

TL;DR: 多模态大型语言模型在隐性推理场景中存在不足，通过简单的干预可以改善其在不确定环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大型语言模型越来越多地被应用于开放性、真实世界的环境中，它们需要具备识别缺失对象或矛盾事实的能力，而不仅仅是完成任务。因此，研究其隐性推理能力具有重要意义。

Method: 使用了包含四类现实世界故障模式的诊断套件来评估六款多模态大型语言模型的性能，并通过显式提示和推理时干预来分析模型的隐性推理能力。

Result: 研究发现，尽管模型具备必要的感知和推理能力，但在隐性推理场景中常常无法识别出隐藏问题。通过简单的推理时干预，如谨慎设定角色和要求澄清问题，可以显著提高模型的表现。

Conclusion: 当前的多模态大型语言模型在处理隐性推理场景存在不足，即使模型具备必要的感知和推理能力，也常常无法识别出隐藏问题。然而，通过简单的推理时干预可以显著改善模型性能，增强其在不确定环境中的可信度。

Abstract: Multimodal large language models (MLLMs) are increasingly deployed in
open-ended, real-world environments where inputs are messy, underspecified, and
not always trustworthy. Unlike curated benchmarks, these settings frequently
involve instructions that refer to missing objects or contradictory facts, rely
on ambiguous references, or request infeasible actions. In such cases, success
hinges not on task execution alone, but on a model's ability to detect when
something is silently wrong. This paper presents a systematic analysis of how
current MLLMs handle such implicit reasoning scenarios: cases where the flaw is
not explicitly stated but must be inferred from context. Using a curated
diagnostic suite spanning four categories of real-world failure modes, we
evaluate six MLLMs, including o3 and GPT-4o, and find that models frequently
fail to surface hidden issues, even when they possess the necessary perceptual
and reasoning skills. Explicit prompting reveals that the underlying
capabilities exist but are often suppressed in favor of user compliance. We
further show that simple inference-time interventions, such as cautious persona
prompting and, in particular, requiring a clarifying question, can dramatically
recover performance. Our findings highlight a persistent gap between reasoning
competence and behavioral compliance in current MLLMs and suggest practical
strategies for making these models more trustworthy in underconstrained
environments.

</details>


### [71] [Sleep Brain and Cardiac Activity Predict Cognitive Flexibility and Conceptual Reasoning Using Deep Learning](https://arxiv.org/abs/2506.00279)
*Boshra Khajehpiri,Eric Granger,Massimiliano de Zambotti,Fiona C. Baker,Mohamad Forouzanfar*

Main category: cs.AI

TL;DR: 研究通过CogPSGFormer模型利用睡眠期间的生理数据预测个体的认知表现，达到高达80.3%的准确率。


<details>
  <summary>Details</summary>
Motivation: 探索睡眠微观结构与特定认知领域人类表现之间的关系，这一领域目前研究较少。

Method: 引入CogPSGFormer多尺度卷积-Transformer模型处理多模态多导睡眠监测数据，包括一通道ECG和EEG信号以及EEG功率波段和心率变异性参数，以捕捉跨模态的互补信息。

Result: 在817名来自STAGES数据集的个体上进行框架评估，使用交叉验证，模型在未见数据中的个体认知表现分类上取得了80.3%精度。

Conclusion: 该研究表明CogPSGFormer模型能够通过多模态睡眠数据有效预测认知表现，特别是认知适应性和概念推理能力的高低。

Abstract: Despite extensive research on the relationship between sleep and cognition,
the connection between sleep microstructure and human performance across
specific cognitive domains remains underexplored. This study investigates
whether deep learning models can predict executive functions, particularly
cognitive adaptability and conceptual reasoning from physiological processes
during a night's sleep. To address this, we introduce CogPSGFormer, a
multi-scale convolutional-transformer model designed to process multi-modal
polysomnographic data. This model integrates one-channel ECG and EEG signals
along with extracted features, including EEG power bands and heart rate
variability parameters, to capture complementary information across modalities.
A thorough evaluation of the CogPSGFormer architecture was conducted to
optimize the processing of extended sleep signals and identify the most
effective configuration. The proposed framework was evaluated on 817
individuals from the STAGES dataset using cross-validation. The model achieved
80.3\% accuracy in classifying individuals into low vs. high cognitive
performance groups on unseen data based on Penn Conditional Exclusion Test
(PCET) scores. These findings highlight the effectiveness of our multi-scale
feature extraction and multi-modal learning approach in leveraging
sleep-derived signals for cognitive performance prediction. To facilitate
reproducibility, our code is publicly accessible
(https://github.com/boshrakh95/CogPSGFormer.git).

</details>


### [72] [Evaluation of LLMs for mathematical problem solving](https://arxiv.org/abs/2506.00309)
*Ruonan Wang,Runxi Wang,Yunwen Shen,Chengfeng Wu,Qinglin Zhou,Rohitash Chandra*

Main category: cs.AI

TL;DR: 研究比较了三种大语言模型在不同数学数据集上的表现，发现GPT-4o总体最稳定，DeepSeek-V3和Gemini-2.0在某些领域有特长，但在其他方面有所欠缺。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在解决数学问题上的潜力，特别是比较GPT-4o、DeepSeek-V3和Gemini-2.0在不同复杂度数学数据集上的表现。

Method: 本文采用基于结构化思维链（SCoT）框架的五维度方法，评估LLMs在最终答案正确性、步骤完整性、步骤有效性、中间计算准确性和问题理解上的表现。

Result: 研究结果显示，GPT-4o在所有数据集上最稳定，特别是在UNSW数据集的高水平问题上表现优异；DeepSeek-V3在结构良好的领域如优化中具竞争力，但在统计推理任务中准确性波动较大；Gemini-2.0在多步骤推理和高级数学推理方面表现不佳。

Conclusion: GPT-4o在所有数据集上表现稳定，尤其在UNSW数据集的高难度问题上表现突出；DeepSeek-V3在优化领域表现强劲，但在统计推理任务中表现不稳定；Gemini-2.0在多步骤推理和符号逻辑上表现不佳。

Abstract: Large Language Models (LLMs) have shown impressive performance on a range of
educational tasks, but are still understudied for their potential to solve
mathematical problems. In this study, we compare three prominent LLMs,
including GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of
varying complexities (GSM8K, MATH500, and UNSW datasets). We take a
five-dimensional approach based on the Structured Chain-of-Thought (SCoT)
framework to assess final answer correctness, step completeness, step validity,
intermediate calculation accuracy, and problem comprehension. The results show
that GPT-4o is the most stable and consistent in performance across all the
datasets, but particularly it performs outstandingly in high-level questions of
the UNSW dataset. DeepSeek-V3 is competitively strong in well-structured
domains such as optimisation, but suffers from fluctuations in accuracy in
statistical inference tasks. Gemini-2.0 shows strong linguistic understanding
and clarity in well-structured problems but performs poorly in multi-step
reasoning and symbolic logic. Our error analysis reveals particular deficits in
each model: GPT-4o is at times lacking in sufficient explanation or precision;
DeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in
mathematical reasoning in higher dimensions.

</details>


### [73] [Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents](https://arxiv.org/abs/2506.00320)
*Xiao Yu,Baolin Peng,Ruize Xu,Michel Galley,Hao Cheng,Suman Nath,Jianfeng Gao,Zhou Yu*

Main category: cs.AI

TL;DR: Dyna-Think框架通过世界模型模拟提升AI代理的推理和行动能力，表现优于R1，降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（如DeepSeek-R1）在某些领域展示了复杂的认知行为，但在长视角任务中表现有效性尚不明确。本研究旨在通过集成规划和内在世界模型的思维框架提升AI代理性能。

Method: 提出了Dyna-Think框架，并通过Dyna-Think模仿学习（DIT）和Dyna-Think动态训练（DDT）方法实现。DIT重建思维过程以训练策略，DDT则通过两阶段训练过程提升代理的世界建模和行动能力。

Result: 在OSWorld的评估中，Dyna-Think在生成的tokens数量减少一半的情况下，实现了与R1相似的最佳性能，并且改进了代理的在域内和跨域表现。研究显示使用批判生成的世界模型训练有效提升了策略性能。

Conclusion: Dyna-Think框架通过集成规划、推理和行动，显著提高了AI代理的在域内和跨域性能。批判性生成能有效提高策略性能，并与世界建模能力有正相关性。

Abstract: Recent progress in reasoning with large language models (LLMs), such as
DeepSeek-R1, demonstrates impressive capabilities in domains like mathematics
and coding, by exhibiting complex cognitive behaviors such as verification,
goal decomposition, and self-reflection. However, it is unclear what behavior
is effective and what behavior is missing for long-horizon AI agents tasks. In
this work, we propose Dyna-Think, a thinking framework that integrates planning
with an internal world model with reasoning and acting to enhance AI agent
performance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning
(DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with
Dyna-Think, DIT reconstructs the thinking process of R1 to focus on performing
world model simulation relevant to the proposed (and planned) action, and
trains the policy using this reconstructed data. To enhance Dyna-Think, DDT
uses a two-stage training process to first improve the agent's world modeling
ability via objectives such as state prediction or critique generation, and
then improve the agent's action via policy training. We evaluate our methods on
OSWorld, and demonstrate that Dyna-Think improves the agent's in-domain and
out-of-domain performance, achieving similar best-of-n performance compared to
R1 while generating 2x less tokens on average. Our extensive empirical studies
reveal that 1) using critique generation for world model training is effective
to improve policy performance; and 2) AI agents with better performance
correlate with better world modeling abilities. We believe our results suggest
a promising research direction to integrate world model simulation into AI
agents to enhance their reasoning, planning, and acting capabilities.

</details>


### [74] [BASIL: Best-Action Symbolic Interpretable Learning for Evolving Compact RL Policies](https://arxiv.org/abs/2506.00328)
*Kourosh Shahnazari,Seyed Moein Ayyoubzadeh,Mohammadali Keshtparvar*

Main category: cs.AI

TL;DR: 引入BASIL，一种利用质量多样性优化的符号可解释学习方法，产生易于解释的紧凑决策策略，性能与深度强化学习相当。


<details>
  <summary>Details</summary>
Motivation: 现代深度强化学习方法虽强大，但容易产生不透明的策略，影响验证透明度和人类监督。需要能生成可解释决策策略的方法。

Method: 提出了BASIL，一种通过在线进化搜索和品质多样性优化生成符号、基于规则的策略的系统方法。

Result: BASIL能够持续生成可解释控制器，其紧凑表现与深度强化学习基准相当。

Conclusion: BASIL方法能够生成可解释的符号规则决策策略，这些策略在表现与深度强化学习基准相当的情况下具有简洁代表性。

Abstract: The quest for interpretable reinforcement learning is a grand challenge for
the deployment of autonomous decision-making systems in safety-critical
applications. Modern deep reinforcement learning approaches, while powerful,
tend to produce opaque policies that compromise verification, reduce
transparency, and impede human oversight. To address this, we introduce BASIL
(Best-Action Symbolic Interpretable Learning), a systematic approach for
generating symbolic, rule-based policies via online evolutionary search with
quality-diversity (QD) optimization. BASIL represents policies as ordered lists
of symbolic predicates over state variables, ensuring full interpretability and
tractable policy complexity. By using a QD archive, the methodology in the
proposed study encourages behavioral and structural diversity between
top-performing solutions, while a complexity-aware fitness encourages the
synthesis of compact representations. The evolutionary system supports the use
of exact constraints for rule count and system adaptability for balancing
transparency with expressiveness. Empirical comparisons with three benchmark
tasks CartPole-v1, MountainCar-v0, and Acrobot-v1 show that BASIL consistently
synthesizes interpretable controllers with compact representations comparable
to deep reinforcement learning baselines. Herein, this article introduces a new
interpretable policy synthesis method that combines symbolic expressiveness,
evolutionary diversity, and online learning through a unifying framework.

</details>


### [75] [Position: Olfaction Standardization is Essential for the Advancement of Embodied Artificial Intelligence](https://arxiv.org/abs/2506.00398)
*Kordel K. France,Rohith Peddi,Nik Dennler,Ovidiu Daescu*

Main category: cs.AI

TL;DR: 文章认为嗅觉在AI系统中被忽视，并主张跨学科合作以填补这一空白，实现更全面和具伦理性的超级人工智能。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能取得了显著进展，现代系统仍未能完全代表人类认知。视觉、听觉和语言因明确的基准和标准化数据集而受到过多关注，而嗅觉作为一种高带宽、进化上至关重要的感官被忽视。

Method: 本文呼吁跨学科合作，囊括神经科学、机器人学、机器学习和伦理学，以公式化嗅觉基准、开发多模态数据集，并定义机器在理解、导航和操作人类环境中所需的感官能力。

Result: 嗅觉与生物系统中的记忆、情感和情境推理紧密关联，但结构性挑战阻碍了其在AI中的发展。这些挑战包括未解决的嗅觉科学理论、异质传感技术、缺乏标准化的嗅觉数据集、缺少AI导向的基准，以及亚感知信号处理评价的困难。

Conclusion: 识别嗅觉作为核心模态并不仅仅是为科学完整性，而是为构建在全面人类体验中有道德基础的AI系统所必需的。

Abstract: Despite extraordinary progress in artificial intelligence (AI), modern
systems remain incomplete representations of human cognition. Vision, audition,
and language have received disproportionate attention due to well-defined
benchmarks, standardized datasets, and consensus-driven scientific foundations.
In contrast, olfaction - a high-bandwidth, evolutionarily critical sense - has
been largely overlooked. This omission presents a foundational gap in the
construction of truly embodied and ethically aligned super-human intelligence.
We argue that the exclusion of olfactory perception from AI architectures is
not due to irrelevance but to structural challenges: unresolved scientific
theories of smell, heterogeneous sensor technologies, lack of standardized
olfactory datasets, absence of AI-oriented benchmarks, and difficulty in
evaluating sub-perceptual signal processing. These obstacles have hindered the
development of machine olfaction despite its tight coupling with memory,
emotion, and contextual reasoning in biological systems. In this position
paper, we assert that meaningful progress toward general and embodied
intelligence requires serious investment in olfactory research by the AI
community. We call for cross-disciplinary collaboration - spanning
neuroscience, robotics, machine learning, and ethics - to formalize olfactory
benchmarks, develop multimodal datasets, and define the sensory capabilities
necessary for machines to understand, navigate, and act within human
environments. Recognizing olfaction as a core modality is essential not only
for scientific completeness, but for building AI systems that are ethically
grounded in the full scope of the human experience.

</details>


### [76] [World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks](https://arxiv.org/abs/2506.00417)
*Changyuan Zhao,Ruichen Zhang,Jiacheng Wang,Gaosheng Zhao,Dusit Niyato,Geng Sun,Shiwen Mao,Dong In Kim*

Main category: cs.AI

TL;DR: 本文介绍了世界模型在人工智能中的应用，并提出了无线梦想者框架，尤其在低空无线网络中提高了学习效率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 世界模型为数据受限或安全关键的场景提供了一种样本高效的框架，本文旨在全面概述这一领域，并提出适用于无线边缘智能优化的新框架。

Method: 在低空无线网络的气候感知无人机轨迹规划案例中，展示了无线梦想者框架的效果。

Result: 通过案例研究，表明无线梦想者框架在提高学习效率和决策质量方面的有效性。

Conclusion: 本文总结了世界模型的架构、训练范式及其在预测、生成、计划和因果推理中的应用，提出了无线梦想者作为一种新颖的基于世界模型的强化学习框架，以优化无线边缘智能，特别是在低空无线网络中的应用。

Abstract: World models are emerging as a transformative paradigm in artificial
intelligence, enabling agents to construct internal representations of their
environments for predictive reasoning, planning, and decision-making. By
learning latent dynamics, world models provide a sample-efficient framework
that is especially valuable in data-constrained or safety-critical scenarios.
In this paper, we present a comprehensive overview of world models,
highlighting their architecture, training paradigms, and applications across
prediction, generation, planning, and causal reasoning. We compare and
distinguish world models from related concepts such as digital twins, the
metaverse, and foundation models, clarifying their unique role as embedded
cognitive engines for autonomous agents. We further propose Wireless Dreamer, a
novel world model-based reinforcement learning framework tailored for wireless
edge intelligence optimization, particularly in low-altitude wireless networks
(LAWNs). Through a weather-aware UAV trajectory planning case study, we
demonstrate the effectiveness of our framework in improving learning efficiency
and decision quality.

</details>


### [77] [MIRROR: Cognitive Inner Monologue Between Conversational Turns for Persistent Reflection and Reasoning in Conversational LLMs](https://arxiv.org/abs/2506.00430)
*Nicole Hsing*

Main category: cs.AI

TL;DR: MIRROR is a cognitive architecture that enhances LLMs by mimicking human inner monologues, improving conversation consistency and addressing common LLM failures, with significant performance gains in challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve language models by implementing parallel reasoning capabilities similar to human cognitive processes, specifically those involving inner monologue for processing complex information.

Method: MIRROR operates as a cognitive architecture with two functional layers: the Thinker and the Talker. The Thinker includes the Inner Monologue Manager and Cognitive Controller for reasoning and narrative synthesis. The Talker utilizes this narrative for generating context-aware responses.

Result: MIRROR outperformed baseline models by 21% on average across scenarios and achieved up to 156% improvement in safety-critical scenarios, maintaining over 80% accuracy. It addresses failure modes like sycophancy and attentional issues.

Conclusion: MIRROR architecture significantly enhances large language models' ability to manage multi-turn conversations, especially under complex constraints. It bridges cognitive science and AI by addressing key LLM failure modes such as sycophancy, attentional deficits, and inconsistent prioritization, achieving substantial improvements over baseline models.

Abstract: Human intelligence relies on inner monologue to process complex information
through simultaneous reflection, memory retrieval, and response formulation. We
introduce MIRROR (Modular Internal Reasoning, Reflection, Orchestration, and
Response), a cognitive architecture that systematically implements these
parallel reasoning capabilities in large language models. MIRROR operates as a
unified system with two distinct functional layers: the Thinker and the Talker.
The Thinker encompasses: (1) the Inner Monologue Manager, coordinating
reasoning threads across cognitive dimensions (Goals, Reasoning, and Memory);
and (2) the Cognitive Controller, synthesizing these threads into a coherent
internal narrative maintained across conversation turns. The Talker component
then leverages this integrated narrative for context-aware responses. Evaluated
on the CuRaTe benchmark--testing personalized dialogue with safety-critical
constraints, conflicting preferences, and multi-turn consistency--LLMs
utilizing the MIRROR architecture achieve up to 156% relative improvement in
critical safety scenarios involving three persons with conflicting preferences,
maintaining an average accuracy of ~>80% on all scenarios. Across
scenario-specific comparisons, GPT-4o, Gemini 1.5 Pro, Claude 3.7 Sonnet, Llama
4 variants, and Mistral 3 variants with the MIRROR architecture outperformed
baseline models by 21% on average (15.5 percentage points absolute). MIRROR
directly addresses three critical LLM failure modes: sycophancy, attentional
deficits to critical information, and inconsistent prioritization of
conflicting constraints. This work bridges cognitive science and AI by
implementing modular internal reasoning inspired by human cognition, creating a
persistent internal model that significantly enhances multi-turn conversation
capabilities.

</details>


### [78] [Monitoring Robustness and Individual Fairness](https://arxiv.org/abs/2506.00496)
*Ashutosh Gupta,Thomas A. Henzinger,Konstantin Kueffner,Kaushik Mallik,David Pape*

Main category: cs.AI

TL;DR: 提出了一种监控黑盒AI模型输入输出鲁棒性的工具Clemont，利用固定半径最近邻搜索问题的方法，开发并行化技术提高计算效率，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 设计可以在运行时监控已部署的黑盒AI模型的输入输出鲁棒性，旨在当监测到过去两个相似输入结果不同输出时发出警报，从而提高AI决策的可信度。

Method: 论文将监控问题转化为固定半径最近邻搜索问题（FRNN），提出了一种基于二元决策图的新算法，并开发了一种高效的并行化技术来提高监控计算效率。

Result: 相关工具Clemont展示了其效力，通过标准基准进行比较研究，能够有效识别鲁棒性违例。

Conclusion: 论文在工具Clemont的实验中验证了不同监控器在运行时正确检测鲁棒性违例的有效性。

Abstract: Input-output robustness appears in various different forms in the literature,
such as robustness of AI models to adversarial or semantic perturbations and
individual fairness of AI models that make decisions about humans.
  We propose runtime monitoring of input-output robustness of deployed,
black-box AI models, where the goal is to design monitors that would observe
one long execution sequence of the model, and would raise an alarm whenever it
is detected that two similar inputs from the past led to dissimilar outputs.
  This way, monitoring will complement existing offline ``robustification''
approaches to increase the trustworthiness of AI decision-makers.
  We show that the monitoring problem can be cast as the fixed-radius nearest
neighbor (FRNN) search problem, which, despite being well-studied, lacks
suitable online solutions.
  We present our tool Clemont, which offers a number of lightweight monitors,
some of which use upgraded online variants of existing FRNN algorithms, and one
uses a novel algorithm based on binary decision diagrams -- a data-structure
commonly used in software and hardware verification.
  We have also developed an efficient parallelization technique that can
substantially cut down the computation time of monitors for which the distance
between input-output pairs is measured using the $L_\infty$ norm.
  Using standard benchmarks from the literature of adversarial and semantic
robustness and individual fairness, we perform a comparative study of different
monitors in \tool, and demonstrate their effectiveness in correctly detecting
robustness violations at runtime.

</details>


### [79] [CityLens: Benchmarking Large Language-Vision Models for Urban Socioeconomic Sensing](https://arxiv.org/abs/2506.00530)
*Tianhui Liu,Jie Feng,Hetian Pang,Xin Zhang,Tianjian Ouyang,Zhiyuan Zhang,Yong Li*

Main category: cs.AI

TL;DR: CityLens评估LLVMs在使用视觉数据预测城市社会经济指标的能力，提供了一个多模态数据集和基准测试，揭示了当前模型的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 通过可视化数据理解城市社会经济状况，是可持续城市发展和政策规划的一个具有挑战性但又至关重要的任务。

Method: 构建一个包含 17 个全球分布城市的多模态数据集，定义了11个预测任务，并利用三个评估范式：直接指标预测、标准化指标估计和基于特征的回归，对 17 个最先进的LLVMs进行基准测试。

Result: 结果显示，虽然LLVMs在感知和推理能力方面表现出色，但在预测城市社会经济指标方面仍然存在局限性。

Conclusion: CityLens提供了一个统一的框架来诊断LLVMs在预测城市社会经济指标方面的局限性，并指导未来如何使用LLVMs理解和预测城市社会经济模式。

Abstract: Understanding urban socioeconomic conditions through visual data is a
challenging yet essential task for sustainable urban development and policy
planning. In this work, we introduce $\textbf{CityLens}$, a comprehensive
benchmark designed to evaluate the capabilities of large language-vision models
(LLVMs) in predicting socioeconomic indicators from satellite and street view
imagery. We construct a multi-modal dataset covering a total of 17 globally
distributed cities, spanning 6 key domains: economy, education, crime,
transport, health, and environment, reflecting the multifaceted nature of urban
life. Based on this dataset, we define 11 prediction tasks and utilize three
evaluation paradigms: Direct Metric Prediction, Normalized Metric Estimation,
and Feature-Based Regression. We benchmark 17 state-of-the-art LLVMs across
these tasks. Our results reveal that while LLVMs demonstrate promising
perceptual and reasoning capabilities, they still exhibit limitations in
predicting urban socioeconomic indicators. CityLens provides a unified
framework for diagnosing these limitations and guiding future efforts in using
LLVMs to understand and predict urban socioeconomic patterns. Our codes and
datasets are open-sourced via https://github.com/tsinghua-fib-lab/CityLens.

</details>


### [80] [A "Wenlu" Brain System for Multimodal Cognition and Embodied Decision-Making: A Secure New Architecture for Deep Integration of Foundation Models and Domain Knowledge](https://arxiv.org/abs/2506.00570)
*Liang Geng*

Main category: cs.AI

TL;DR: 本文提出了"Wenlu"系统，融合私有知识和公共模型，用于多模态数据统一处理和闭环决策，实现硬件级代码的自动生成，展现出多方面优势。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在各行业和场景中的快速渗透，构建下一代智能核心的关键挑战在于如何有效整合基础模型的语言理解能力与领域特定知识库，以适应复杂的现实应用。

Method: 设计了一种多模态认知和体现决策的脑系统"Wenlu"，通过脑启发式的记忆标记和回放机制，实现用户私有数据、行业特定知识和通用语言模型的无缝集成，以便从认知到硬件级代码的自动生成进行闭环决策。

Result: 系统提供了精确、高效的多模态服务，支持企业决策、医疗分析、自动驾驶、机器人控制等多个领域。

Conclusion: "Wenlu"系统相比现有解决方案在多模态处理、隐私安全、硬件控制代码生成、自学习和可持续更新方面展现出显著优势，为构建下一代智能核心奠定了坚实的基础。

Abstract: With the rapid penetration of artificial intelligence across industries and
scenarios, a key challenge in building the next-generation intelligent core
lies in effectively integrating the language understanding capabilities of
foundation models with domain-specific knowledge bases in complex real-world
applications. This paper proposes a multimodal cognition and embodied
decision-making brain system, ``Wenlu", designed to enable secure fusion of
private knowledge and public models, unified processing of multimodal data such
as images and speech, and closed-loop decision-making from cognition to
automatic generation of hardware-level code. The system introduces a
brain-inspired memory tagging and replay mechanism, seamlessly integrating
user-private data, industry-specific knowledge, and general-purpose language
models. It provides precise and efficient multimodal services for enterprise
decision support, medical analysis, autonomous driving, robotic control, and
more. Compared with existing solutions, ``Wenlu" demonstrates significant
advantages in multimodal processing, privacy security, end-to-end hardware
control code generation, self-learning, and sustainable updates, thus laying a
solid foundation for constructing the next-generation intelligent core.

</details>


### [81] [Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs](https://arxiv.org/abs/2506.00582)
*Chenjun Xu,Bingbing Wen,Bin Han,Robert Wolfe,Lucy Lu Wang,Bill Howe*

Main category: cs.AI

TL;DR: 研究对比了三款大型语言模型在不同任务难度下的信心表现，引入无答案信心估计方法，实验结果表明该方法能有效改善模型的信心校准及其对任务难度的敏感性。


<details>
  <summary>Details</summary>
Motivation: 研究发现，现有大模型在回答不同难度的问题时的信心表现与人类不同，容易产生刻板印象且对任务难度的敏感性较低，故提出改进方法。

Method: 引入无答案信心估计方法，将信心评分与回答分开，通过两阶段的提示来评估信心校准。

Result: 实验表明，使用AFCE方法能够显著减少模型的过度自信现象，并增强对任务难度的敏感性，使其表现得更加符合人类特征。

Conclusion: 提出的无答案信心估计（AFCE）方法能够有效提高模型在不同任务难度下的信心校准能力，使其对任务难度的敏感性更接近人类。

Abstract: Psychology research has shown that humans are poor at estimating their
performance on tasks, tending towards underconfidence on easy tasks and
overconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct,
Claude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty, and
show that models exhibit subtle differences from human patterns of
overconfidence: less sensitive to task difficulty, and when prompted to answer
based on different personas -- e.g., expert vs layman, or different race,
gender, and ages -- the models will respond with stereotypically biased
confidence estimations even though their underlying answer accuracy remains the
same. Based on these observations, we propose Answer-Free Confidence Estimation
(AFCE) to improve confidence calibration and LLM interpretability in these
settings. AFCE is a self-assessment method that employs two stages of
prompting, first eliciting only confidence scores on questions, then asking
separately for the answer. Experiments on the MMLU and GPQA datasets spanning
subjects and difficulty show that this separation of tasks significantly
reduces overconfidence and delivers more human-like sensitivity to task
difficulty.

</details>


### [82] [RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents](https://arxiv.org/abs/2506.00618)
*Jingyi Yang,Shuai Shao,Dongrui Liu,Jing Shao*

Main category: cs.AI

TL;DR: 引入名为RiOSWorld的基准，以评估多模态语言模型代理在真实计算机任务中的风险。实验表明，这些代理面临重大安全风险，需紧急进行安全对齐。基准已公开发布。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型（MLLMs）的快速发展，它们越来越多地被部署为能够完成复杂计算任务的自主计算机使用代理。然而，现有研究在评估这些代理的安全风险时存在局限性，这促使作者引入新的基准来进行更为全面的风险评估。

Method: 引入了名为RiOSWorld的基准，该基准包括492个具有风险的任务，涵盖各种计算机应用程序，风险分为用户来源风险和环境风险两大类，评估从风险目标意图和风险目标完成两个角度进行。

Result: 在RiOSWorld进行的大量实验表明，当前的计算机使用代理在真实世界中面临显著的安全风险，这突显了对这些代理进行安全对齐的必要性和紧迫性。

Conclusion: 当前的计算机使用代理在真实环境中面临显著的安全风险，且需要紧急地进行安全对齐。此外，该基准为开发可信任的计算机使用代理提供了宝贵的见解。

Abstract: With the rapid development of multimodal large language models (MLLMs), they
are increasingly deployed as autonomous computer-use agents capable of
accomplishing complex computer tasks. However, a pressing issue arises: Can the
safety risk principles designed and aligned for general MLLMs in dialogue
scenarios be effectively transferred to real-world computer-use scenarios?
Existing research on evaluating the safety risks of MLLM-based computer-use
agents suffers from several limitations: it either lacks realistic interactive
environments, or narrowly focuses on one or a few specific risk types. These
limitations ignore the complexity, variability, and diversity of real-world
environments, thereby restricting comprehensive risk evaluation for
computer-use agents. To this end, we introduce \textbf{RiOSWorld}, a benchmark
designed to evaluate the potential risks of MLLM-based agents during real-world
computer manipulations. Our benchmark includes 492 risky tasks spanning various
computer applications, involving web, social media, multimedia, os, email, and
office software. We categorize these risks into two major classes based on
their risk source: (i) User-originated risks and (ii) Environmental risks. For
the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal
intention and (ii) Risk goal completion. Extensive experiments with multimodal
agents on \textbf{RiOSWorld} demonstrate that current computer-use agents
confront significant safety risks in real-world scenarios. Our findings
highlight the necessity and urgency of safety alignment for computer-use agents
in real-world computer manipulation, providing valuable insights for developing
trustworthy computer-use agents. Our benchmark is publicly available at
https://yjyddq.github.io/RiOSWorld.github.io/.

</details>


### [83] [AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents](https://arxiv.org/abs/2506.00641)
*Hanjun Luo,Shenyu Dai,Chiming Ni,Xinfeng Li,Guibin Zhang,Kun Wang,Tongliang Liu,Hanan Salam*

Main category: cs.AI

TL;DR: 本文提出了\sys，通过增强LLM的记忆和推理能力，提高了其在安全性评估中的准确性，并通过\data数据集设立了新的评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则或LLM的评估器在识别代理逐步行动中的危险、微妙意义、小问题的积累及不明确安全和安全性规则时存在不足。

Method: 提出\sys，一个无需训练的通用记忆增强推理框架，通过让LLM自适应提取结构化的语义特征并生成过去交互的链式推理流以构建经验记忆，通过多阶段的上下文感知检索增强生成过程来引导评估。

Result: \sys在所有基准测试中一致地提高了LLM的评估性能，并在人类水平的安全和安全性评估中设立了新的标杆。

Conclusion: 本研究提出的\sys框架有效地提高了LLM评估器在安全和安全性评估中的性能，在全部基准测试中实现了新的最先进水平，并达到了人类专家的准确性。

Abstract: Despite the rapid advancement of LLM-based agents, the reliable evaluation of
their safety and security remains a significant challenge. Existing rule-based
or LLM-based evaluators often miss dangers in agents' step-by-step actions,
overlook subtle meanings, fail to see how small issues compound, and get
confused by unclear safety or security rules. To overcome this evaluation
crisis, we introduce \sys, a universal, training-free, memory-augmented
reasoning framework that empowers LLM evaluators to emulate human expert
evaluators. \sys constructs an experiential memory by having an LLM adaptively
extract structured semantic features (e.g., scenario, risk, behavior) and
generate associated chain-of-thought reasoning traces for past interactions. A
multi-stage, context-aware retrieval-augmented generation process then
dynamically retrieves the most relevant reasoning experiences to guide the LLM
evaluator's assessment of new cases. Moreover, we developed \data, the first
benchmark designed to check how well LLM-based evaluators can spot both safety
risks and security threats. \data comprises \textbf{2293} meticulously
annotated interaction records, covering \textbf{15} risk types across
\textbf{29} application scenarios. A key feature of \data is its nuanced
approach to ambiguous risk situations, employing ``Strict'' and ``Lenient''
judgment standards. Experiments demonstrate that \sys not only consistently
improves the evaluation performance of LLMs across all benchmarks but also sets
a new state-of-the-art in LLM-as-a-judge for agent safety and security,
achieving human-level accuracy. Our work is openly openly accessible.

</details>


### [84] [OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases](https://arxiv.org/abs/2506.00664)
*Yash Tiwari,Owais Ahmad Lone,Mayukha Pal*

Main category: cs.AI

TL;DR: OntoRAG automatically creates ontologies from unstructured data, improving over traditional methods and enhancing semantic web vision with better comprehensiveness and diversity.


<details>
  <summary>Details</summary>
Motivation: Traditional ontology creation is manual, error-prone, time-intensive, especially for large dynamic knowledge domains.

Method: Integrates web scraping, PDF parsing, hybrid chunking, information extraction, knowledge graph construction, ontology creation into a single pipeline.

Result: OntoRAG demonstrated a win rate of 85% over vector RAG and 75% against GraphRAG's best configuration in comprehensiveness.

Conclusion: OntoRAG enhances ontology creation from unstructured data efficiently, outperforming conventional methods.

Abstract: Ontologies are pivotal for structuring knowledge bases to enhance question
answering (QA) systems powered by Large Language Models (LLMs). However,
traditional ontology creation relies on manual efforts by domain experts, a
process that is time intensive, error prone, and impractical for large, dynamic
knowledge domains. This paper introduces OntoRAG, an automated pipeline
designed to derive ontologies from unstructured knowledge bases, with a focus
on electrical relay documents. OntoRAG integrates advanced techniques,
including web scraping, PDF parsing, hybrid chunking, information extraction,
knowledge graph construction, and ontology creation, to transform unstructured
data into a queryable ontology. By leveraging LLMs and graph based methods,
OntoRAG enhances global sensemaking capabilities, outperforming conventional
Retrieval Augmented Generation (RAG) and GraphRAG approaches in
comprehensiveness and diversity. Experimental results demonstrate OntoRAGs
effectiveness, achieving a comprehensiveness win rate of 85% against vector RAG
and 75% against GraphRAGs best configuration. This work addresses the critical
challenge of automating ontology creation, advancing the vision of the semantic
web.

</details>


### [85] [DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains](https://arxiv.org/abs/2506.00708)
*Yongkang Xiao,Sinian Zhang,Yi Dai,Huixue Zhou,Jue Hou,Jie Ding,Rui Zhang*

Main category: cs.AI

TL;DR: DrKGC通过动态子图检索法和图卷积网络适配提升知识图谱完备性能，表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前大多数知识图谱完备方法通常以文本形式编码图的上下文，这种方式未能充分利用大语言模型在图结构感知和推理方面的潜力。为了解决这个局限性，提出了DrKGC。

Method: DrKGC通过灵活轻量的模型训练策略来学习知识图谱中的结构嵌入和逻辑规则，随后通过一种新颖的自底向上的图检索方法，根据学习到的规则为每个查询提取子图。最后，使用图卷积网络（GCN）适配器来增强结构嵌入，并将其整合到提示中，以有效进行大语言模型的微调。

Result: 在两个通用领域基准数据集和两个生物医学数据集上的实验结果展示了DrKGC的卓越性能。此外，生物医学领域的实际案例研究凸显了其可解释性和实用性。

Conclusion: DrKGC通过引入动态子图检索和增强的结构嵌入，有效提升了知识图谱完备任务中大语言模型的表现，并展示了良好的实际应用潜力。

Abstract: Knowledge graph completion (KGC) aims to predict missing triples in knowledge
graphs (KGs) by leveraging existing triples and textual information. Recently,
generative large language models (LLMs) have been increasingly employed for
graph tasks. However, current approaches typically encode graph context in
textual form, which fails to fully exploit the potential of LLMs for perceiving
and reasoning about graph structures. To address this limitation, we propose
DrKGC (Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph
Completion). DrKGC employs a flexible lightweight model training strategy to
learn structural embeddings and logical rules within the KG. It then leverages
a novel bottom-up graph retrieval method to extract a subgraph for each query
guided by the learned rules. Finally, a graph convolutional network (GCN)
adapter uses the retrieved subgraph to enhance the structural embeddings, which
are then integrated into the prompt for effective LLM fine-tuning. Experimental
results on two general domain benchmark datasets and two biomedical datasets
demonstrate the superior performance of DrKGC. Furthermore, a realistic case
study in the biomedical domain highlights its interpretability and practical
utility.

</details>


### [86] [Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?](https://arxiv.org/abs/2506.00751)
*Zhuojun Gu,Quan Wang,Shuchu Han*

Main category: cs.AI

TL;DR: 研究发现，LLMs在特定情境下的偏好选择可能偏离其声明的一般原则，并建议通过设计好的提示集进行量化测量。这一现象对LLMs的可信部署具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解和控制LLMs在具体情境中可能出现的偏好偏离现象，这对于LLMs的解释性、可信性、推理透明性及伦理部署，特别是在高风险应用中至关重要。

Method: 我们设计一个包含强制二选一任务的数据集，将其呈现给LLMs，以比较其在一般原则提示（声称偏好）与情境化提示（揭示偏好）下的反应，使用KL散度等指标量化偏差。

Result: 研究结果表明，在不同偏好类别和主流LLMs上，一个微小的提示格式变化常常会造成偏好选择的改变，这一普遍现象突显了对LLMs决策能力的理解和控制的缺乏。

Conclusion: 本研究表明大语言模型（LLMs）在面临具体上下文时，可能会偏离其先前声明的原则偏好，这表明当前对LLMs决策能力的理解和控制不足。在各种偏好和多款主流LLMs上的测试显示，提示格式的微小变化会导致偏好选择的变化。

Abstract: Recent advances in Large Language Models (LLMs) highlight the need to align
their behaviors with human values. A critical, yet understudied, issue is the
potential divergence between an LLM's stated preferences (its reported
alignment with general principles) and its revealed preferences (inferred from
decisions in contextualized scenarios). Such deviations raise fundamental
concerns for the interpretability, trustworthiness, reasoning transparency, and
ethical deployment of LLMs, particularly in high-stakes applications. This work
formally defines and proposes a method to measure this preference deviation. We
investigate how LLMs may activate different guiding principles in specific
contexts, leading to choices that diverge from previously stated general
principles. Our approach involves crafting a rich dataset of well-designed
prompts as a series of forced binary choices and presenting them to LLMs. We
compare LLM responses to general principle prompts stated preference with LLM
responses to contextualized prompts revealed preference, using metrics like KL
divergence to quantify the deviation. We repeat the analysis across different
categories of preferences and on four mainstream LLMs and find that a minor
change in prompt format can often pivot the preferred choice regardless of the
preference categories and LLMs in the test. This prevalent phenomenon
highlights the lack of understanding and control of the LLM decision-making
competence. Our study will be crucial for integrating LLMs into services,
especially those that interact directly with humans, where morality, fairness,
and social responsibilities are crucial dimensions. Furthermore, identifying or
being aware of such deviation will be critically important as LLMs are
increasingly envisioned for autonomous agentic tasks where continuous human
evaluation of all LLMs' intermediary decision-making steps is impossible.

</details>


### [87] [HouseTS: A Large-Scale, Multimodal Spatiotemporal U.S. Housing Dataset](https://arxiv.org/abs/2506.00765)
*Shengkun Wang,Yanshen Sun,Fanglan Chen,Linhan Wang,Naren Ramakrishnan,Chang-Tien Lu,Yinlin Chen*

Main category: cs.AI

TL;DR: 引入了一个新的名为HouseTS的大规模多模态数据集，用于住房价格预测，并利用多种模型进行了评估，展示了其在多模态分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于长时跨度预测中具备足够的时空深度和背景丰富的可复现基准稀缺，本文提供了一个新的多模态数据集，以帮助研究人员在住房价格预测中建立标准化性能基线。

Method: 通过引入HouseTS数据集，采用多种模型进行评估，包括经典统计方法、深度神经网络以及预训练时间序列模型。使用视觉语言模型从时间戳的卫星图像中提取地理变更的结构化文本描述，进行多模态分析。

Result: 利用新的HouseTS数据集在多种模型下进行了标准化的性能基线评估，表明这些模型在不同背景数据集上的有效性，并通过多模态案例研究展示了数据集的附加价值。

Conclusion: HouseTS数据集通过多样的模型测试，展示了其在研究住房价格预测中的独特价值，并在多模态案例研究中证明了其有效性。

Abstract: Accurate house-price forecasting is essential for investors, planners, and
researchers. However, reproducible benchmarks with sufficient spatiotemporal
depth and contextual richness for long horizon prediction remain scarce. To
address this, we introduce HouseTS a large scale, multimodal dataset covering
monthly house prices from March 2012 to December 2023 across 6,000 ZIP codes in
30 major U.S. metropolitan areas. The dataset includes over 890K records,
enriched with points of Interest (POI), socioeconomic indicators, and detailed
real estate metrics. To establish standardized performance baselines, we
evaluate 14 models, spanning classical statistical approaches, deep neural
networks (DNNs), and pretrained time-series foundation models. We further
demonstrate the value of HouseTS in a multimodal case study, where a vision
language model extracts structured textual descriptions of geographic change
from time stamped satellite imagery. This enables interpretable, grounded
insights into urban evolution. HouseTS is hosted on Kaggle, while all
preprocessing pipelines, benchmark code, and documentation are openly
maintained on GitHub to ensure full reproducibility and easy adoption.

</details>


### [88] [Do not Abstain! Identify and Solve the Uncertainty](https://arxiv.org/abs/2506.00780)
*Jingyu Liu,Jingquan Peng,xiaopeng Wu,Xubin Li,Tiezheng Ge,Bo Zheng,Yong Liu*

Main category: cs.AI

TL;DR: 研究引入ConfuseBench基准以评估和改善语言模型在不确定性识别和解决上的表现，并通过上下文相关询问和InteractDPO方法提高模型应对不确定性的能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在面临不确定性情境时往往过于自信，而主要以回避性回应为主，未能识别和解决不确定性，以生成更满意的回应。研究动机在于改进模型识别并解决不确定性的能力。

Method: 引入ConfuseBench基准，进行实验以评估当前大型语言模型在不确定性识别和应对上的表现，然后通过生成上下文相关的询问并使用在策略训练方法InteractDPO去生成更好的询问来应对不确定性。

Result: 实验结果证明了通过ConfuseBench基准测试和使用InteractDPO训练方法能够有效提高语言模型识别和解决不确定性的能力。

Conclusion: ConfuseBench通过系统测试揭示了当前大型语言模型难以有效识别并解决不确定性的根源，并提出了一种新的在策略训练方法InteractDPO，以生成更好的询问，从而改善模型应对不确定性的方法。

Abstract: Despite the widespread application of Large Language Models (LLMs) across
various domains, they frequently exhibit overconfidence when encountering
uncertain scenarios, yet existing solutions primarily rely on evasive responses
(e.g., "I don't know") overlooks the opportunity of identifying and addressing
the uncertainty to generate more satisfactory responses. To systematically
investigate and improve LLMs' ability of recognizing and addressing the source
of uncertainty, we introduce \textbf{ConfuseBench}, a benchmark mainly focus on
three types of uncertainty: document scarcity, limited capability, and query
ambiguity. Experiments with ConfuseBench reveal that current LLMs struggle to
accurately identify the root cause of uncertainty and solve it. They prefer to
attribute uncertainty to query ambiguity while overlooking capability
limitations, especially for those weaker models. To tackle this challenge, we
first generate context-aware inquiries that highlight the confusing aspect of
the original query. Then we judge the source of uncertainty based on the
uniqueness of the inquiry's answer. Further we use an on-policy training
method, InteractDPO to generate better inquiries. Experimental results
demonstrate the efficacy of our approach.

</details>


### [89] [CoP: Agentic Red-teaming for Large Language Models using Composition of Principles](https://arxiv.org/abs/2506.00781)
*Chen Xiong,Pin-Yu Chen,Tsung-Yi Ho*

Main category: cs.AI

TL;DR: 本文提出了一种CoP框架来自动化语言模型红队工作，揭示了前所未有的安全风险，并大幅提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 应对当前越来越严重的越狱攻击问题，这种攻击破坏语言模型的安全对齐和用户合规性。

Method: 提出了一种通过Composition-of-Principles (CoP)框架进行自动化红队工作的流程，人类用户提供原则指导AI进行策略生成。

Result: 对领先的大型语言模型进行了测试，发现新型越狱提示，并提高单次攻击成功率达19倍。

Conclusion: CoP框架在揭露大型语言模型中的安全风险方面表现优异，通过生成新型越狱提示并提高现有攻击成功率。

Abstract: Recent advances in Large Language Models (LLMs) have spurred transformative
applications in various domains, ranging from open-source to proprietary LLMs.
However, jailbreak attacks, which aim to break safety alignment and user
compliance by tricking the target LLMs into answering harmful and risky
responses, are becoming an urgent concern. The practice of red-teaming for LLMs
is to proactively explore potential risks and error-prone instances before the
release of frontier AI technology. This paper proposes an agentic workflow to
automate and scale the red-teaming process of LLMs through the
Composition-of-Principles (CoP) framework, where human users provide a set of
red-teaming principles as instructions to an AI agent to automatically
orchestrate effective red-teaming strategies and generate jailbreak prompts.
Distinct from existing red-teaming methods, our CoP framework provides a
unified and extensible framework to encompass and orchestrate human-provided
red-teaming principles to enable the automated discovery of new red-teaming
strategies. When tested against leading LLMs, CoP reveals unprecedented safety
risks by finding novel jailbreak prompts and improving the best-known
single-turn attack success rate by up to 19.0 times.

</details>


### [90] [Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.00782)
*Weiyang Guo,Zesheng Shi,Zhuo Li,Yequan Wang,Xuebo Liu,Wenya Wang,Fangming Liu,Min Zhang,Jing Li*

Main category: cs.AI

TL;DR: 提出一种使用强化学习的自动化红队训练框架，以提高攻击提示的有效性和多样性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，确保其安全性和防止有害输出变得至关重要。现有方法难以平衡红队生成攻击提示的有效性和多样性。

Method: 我们提出了一种使用强化学习探索和生成更有效攻击提示的自动化红队训练框架，包括三个训练阶段：冷启动、热身探索和增强破解。

Result: 实验表明，我们的方法在生成有效且多样的破解提示方面比现有方法更优。

Conclusion: 我们的工作显著提高了红队探索的效率，并为自动化红队提供了新的视角。

Abstract: As large language models (LLMs) grow in power and influence, ensuring their
safety and preventing harmful output becomes critical. Automated red teaming
serves as a tool to detect security vulnerabilities in LLMs without manual
labor. However, most existing methods struggle to balance the effectiveness and
diversity of red-team generated attack prompts. To address this challenge, we
propose \ourapproach, a novel automated red teaming training framework that
utilizes reinforcement learning to explore and generate more effective attack
prompts while balancing their diversity. Specifically, it consists of three
training stages: (1) Cold Start: The red team model is supervised and
fine-tuned on a jailbreak dataset obtained through imitation learning. (2)
Warm-up Exploration: The model is trained in jailbreak instruction following
and exploration, using diversity and consistency as reward signals. (3)
Enhanced Jailbreak: Progressive jailbreak rewards are introduced to gradually
enhance the jailbreak performance of the red-team model. Extensive experiments
on a variety of LLMs show that \ourapproach effectively balances the diversity
and effectiveness of jailbreak prompts compared to existing methods. Our work
significantly improves the efficiency of red team exploration and provides a
new perspective on automated red teaming.

</details>


### [91] [GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning](https://arxiv.org/abs/2506.00785)
*Sahiti Yerramilli,Nilay Pande,Rynaa Grover,Jayant Sravan Tamarapalli*

Main category: cs.AI

TL;DR: GeoChain is a benchmark for testing MLLMs in geographic reasoning, using annotated images and reasoning sequences. Models struggle with visual grounding and localization as task difficulty increases.


<details>
  <summary>Details</summary>
Motivation: The main motivation is to evaluate and improve the capability of multimodal large language models in step-by-step geographic reasoning, which remains challenging in current models.

Method: GeoChain uses a combination of step-by-step chain-of-thought reasoning and extensive annotated datasets, including semantic segmentation and visual locatability scores, to evaluate MLLMs across different reasoning categories.

Result: The study found that even advanced MLLMs face consistent challenges with visual grounding and accurate localization, particularly as reasoning tasks become more complex, highlighting areas for potential improvement in model development.

Conclusion: GeoChain provides a comprehensive benchmark for diagnosing and improving the ability of MLLMs to handle complex geographic reasoning, helping pinpoint specific challenges these models face in tasks of increasing difficulty.

Abstract: This paper introduces GeoChain, a large-scale benchmark for evaluating
step-by-step geographic reasoning in multimodal large language models (MLLMs).
Leveraging 1.46 million Mapillary street-level images, GeoChain pairs each
image with a 21-step chain-of-thought (CoT) question sequence (over 30 million
Q&A pairs). These sequences guide models from coarse attributes to fine-grained
localization across four reasoning categories - visual, spatial, cultural, and
precise geolocation - annotated by difficulty. Images are also enriched with
semantic segmentation (150 classes) and a visual locatability score. Our
benchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5
variants) on a diverse 2,088-image subset reveals consistent challenges: models
frequently exhibit weaknesses in visual grounding, display erratic reasoning,
and struggle to achieve accurate localization, especially as the reasoning
complexity escalates. GeoChain offers a robust diagnostic methodology, critical
for fostering significant advancements in complex geographic reasoning within
MLLMs.

</details>


### [92] [Predicting Empirical AI Research Outcomes with Language Models](https://arxiv.org/abs/2506.00794)
*Jiaxin Wen,Chenglei Si,Yueh-han Chen,He He,Shi Feng*

Main category: cs.AI

TL;DR: 该研究为预测AI研究想法的成功概率设立了首个基准，结合微调GPT-4.1和论文检索系统测试发现，比人类专家表现更佳，展示了语言模型在加速AI研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 很多有前途的AI研究想法没能实现，但其验证需要大量人力和计算资源。因此，预测一个想法成功的可能性对于加速经验性AI研究至关重要，这是一项即使是专家研究者也需要通过大量经验才能获得的能力。

Method: 建立首个用于预测研究想法成功概率的基准，并将语言模型（LMs）与人类专家进行比较。具体而言，给定两种研究想法（如两种破解方法），我们旨在预测哪种在一组基准上表现更好。我们从会议论文中获取想法和实验结果，共有1585对经过人类验证的想法对用于测试，还有6000对用于训练。随后开发了一种结合微调GPT-4.1和论文检索代理的系统，并招募25位人类专家进行比较。

Result: 在NLP领域，我们的系统远超人类专家（64.4%对48.9%）。在完整的测试集上，我们的系统实现了77%的准确率，而即使是同样添加了检索增强的现成前沿LMs如o3的表现也仅相当于随机猜测。我们通过广泛的人类编写和LM设计的鲁棒性测试验证了我们的系统并未利用如想法复杂性等表面特征。最终，我们在未发表的新想法上评估了我们的系统，包括由AI创意生成代理生成的想法，系统实现了63.6%的准确率，展示其作为改进创意生成模型的奖励模型的潜力。

Conclusion: 我们的结果为语言模型加速经验性AI研究开辟了一个新的有前途的方向。

Abstract: Many promising-looking ideas in AI research fail to deliver, but their
validation takes substantial human labor and compute. Predicting an idea's
chance of success is thus crucial for accelerating empirical AI research, a
skill that even expert researchers can only acquire through substantial
experience. We build the first benchmark for this task and compare LMs with
human experts. Concretely, given two research ideas (e.g., two jailbreaking
methods), we aim to predict which will perform better on a set of benchmarks.
We scrape ideas and experimental results from conference papers, yielding 1,585
human-verified idea pairs published after our base model's cut-off date for
testing, and 6,000 pairs for training. We then develop a system that combines a
fine-tuned GPT-4.1 with a paper retrieval agent, and we recruit 25 human
experts to compare with. In the NLP domain, our system beats human experts by a
large margin (64.4% v.s. 48.9%). On the full test set, our system achieves 77%
accuracy, while off-the-shelf frontier LMs like o3 perform no better than
random guessing, even with the same retrieval augmentation. We verify that our
system does not exploit superficial features like idea complexity through
extensive human-written and LM-designed robustness tests. Finally, we evaluate
our system on unpublished novel ideas, including ideas generated by an AI
ideation agent. Our system achieves 63.6% accuracy, demonstrating its potential
as a reward model for improving idea generation models. Altogether, our results
outline a promising new direction for LMs to accelerate empirical AI research.

</details>


### [93] [Enhancing LLM Reasoning for Time Series Classification by Tailored Thinking and Fused Decision](https://arxiv.org/abs/2506.00807)
*Jiahui Zhou,Dan Li,Lin Li,Zhuomin Chen,Shunyu Wu,Haozheng Ye,Jian Lou,Costas J. Spanos*

Main category: cs.AI

TL;DR: 本文提出ReasonTSC框架，通过利用大语言模型的推理能力，提升时间序列分类的性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理技术在时间序列分类任务中应用较少，本文旨在利用LLM在该领域的推理优势应对此类任务的挑战。

Method: 该框架通过多轮推理和融合决策程序利用LLM进行时间序列分类，同时利用插件分类器的预测和置信度评分提供上下文案例。

Result: 实验结果和系统性拆解研究表明，ReasonTSC能够持续超越现有的时间序列推理基准和插件模型，并且能够识别并纠正插件模型的错误预测。

Conclusion: ReasonTSC框架能够有效利用大语言模型推理提高时间序列分类性能，相比现有方法具有更高效和精准的分类优势。

Abstract: The reasoning capabilities of large language models (LLMs) have significantly
advanced their performance by enabling in-depth understanding of diverse tasks.
With growing interest in applying LLMs to the time series domain, this has
proven nontrivial, as evidenced by the limited efficacy of straightforwardly
adapting text-domain reasoning techniques. Although recent work has shown
promise in several time series tasks, further leveraging advancements in LLM
reasoning remains under-explored for time series classification (TSC) tasks,
despite their prevalence and significance in many real-world applications. In
this paper, we propose ReasonTSC, a novel framework designed to effectively
leverage LLM reasoning for time series classification through both a multi-turn
reasoning and a fused decision-making strategy tailored to TSC. Rather than
straightforwardly applying existing reasoning techniques or relying solely on
LLMs' built-in reasoning capabilities, ReasonTSC first steers the model to
think over the essential characteristics of time series data. Next, it
integrates predictions and confidence scores from plug-in classifiers, e.g.,
domain-specific time series models, as in-context examples. Finally, ReasonTSC
guides the LLM through a structured reasoning process: it evaluates the initial
assessment, backtracks to consider alternative hypotheses, and compares their
merits before arriving at a final classification. Extensive experiments and
systematic ablation studies demonstrate that ReasonTSC consistently outperforms
both existing time series reasoning baselines and plug-in models, and is even
capable of identifying and correcting plug-in models' false predictions.

</details>


### [94] [SynPO: Synergizing Descriptiveness and Preference Optimization for Video Detailed Captioning](https://arxiv.org/abs/2506.00835)
*Jisheng Dang,Yizhou Zhang,Hao Ye,Teng Wang,Siming Chen,Huicheng Zheng,Yulan Guo,Jianhuang Lai,Bin Hu*

Main category: cs.AI

TL;DR: The paper introduces SynPO, a method to improve fine-grained video captioning, outperforming existing methods and boosting efficiency by 20%.


<details>
  <summary>Details</summary>
Motivation: To enhance vision-language models' performance in fine-grained video captioning by overcoming limitations in capturing subtle video dynamics and detailed information.

Method: The paper proposes Synergistic Preference Optimization (SynPO), a novel optimization method, and a pipeline for constructing preference pairs using vision-language models and large language models.

Result: SynPO offers significant advantages over DPO, improving training efficiency and language capability preservation, and outperforms existing methods in benchmarks and NLP tasks.

Conclusion: SynPO consistently outperforms existing DPO variants in fine-grained video captioning and provides a 20% improvement in training efficiency.

Abstract: Fine-grained video captioning aims to generate detailed, temporally coherent
descriptions of video content. However, existing methods struggle to capture
subtle video dynamics and rich detailed information. In this paper, we leverage
preference learning to enhance the performance of vision-language models in
fine-grained video captioning, while mitigating several limitations inherent to
direct preference optimization (DPO). First, we propose a pipeline for
constructing preference pairs that leverages the intrinsic properties of VLMs
along with partial assistance from large language models, achieving an optimal
balance between cost and data quality. Second, we propose Synergistic
Preference Optimization (SynPO), a novel optimization method offering
significant advantages over DPO and its variants. SynPO prevents negative
preferences from dominating the optimization, explicitly preserves the model's
language capability to avoid deviation of the optimization objective, and
improves training efficiency by eliminating the need for the reference model.
We extensively evaluate SynPO not only on video captioning benchmarks (e.g.,
VDC, VDD, VATEX) but also across well-established NLP tasks, including general
language understanding and preference evaluation, using diverse pretrained
models. Results demonstrate that SynPO consistently outperforms DPO variants
while achieving 20\% improvement in training efficiency. Code is available at
https://github.com/longmalongma/SynPO

</details>


### [95] [MedBookVQA: A Systematic and Comprehensive Medical Benchmark Derived from Open-Access Book](https://arxiv.org/abs/2506.00855)
*Sau Lai Yip,Sunan He,Yuxiang Nie,Shu Pui Chan,Yilin Ye,Sum Ying Lam,Hao Chen*

Main category: cs.AI

TL;DR: 本文推出MedBookVQA，一个从开放医疗教科书中衍生的综合多模态基准，以评估和揭示GMAI系统在不同任务类型上的性能差距。


<details>
  <summary>Details</summary>
Motivation: 随着通用医学人工智能的发展，需要开发系统的评估基准，以评估性能并为技术发展提供指导。同时，医学教科书作为基准开发的宝贵知识来源，其潜力尚未被充分利用。

Method: 提出了一种标准化管道，通过自动提取医学图例并将其与相应的医学叙述进行上下文对齐来策划基准。基于策划的数据，生成了涵盖模态识别、疾病分类、解剖结构识别、症状诊断和外科手术的5000个临床相关问题。采用多层次注释系统将查询通过医学成像模态（42类）、身体解剖结构（125个）和临床专业（31个部门）的层次分类进行分类。

Result: 对许多MLLM进行了评估，包括专有、开源、医学和推理模型，揭示了任务类型和模型类别之间的显著性能差距。我们的研究结果突出显示了当前GMAI系统中的关键能力缺口，同时也确立了教科书衍生的多模态基准作为重要的评估工具。

Conclusion: MedBookVQA通过从开放获取的医学教科书中提取医学图例和对应的叙述，创建了一个系统的全面的多模态基准，揭示了现有GMAI系统的显著能力差距，并引入了医学教科书衍生的基准作为重要的评估工具。

Abstract: The accelerating development of general medical artificial intelligence
(GMAI), powered by multimodal large language models (MLLMs), offers
transformative potential for addressing persistent healthcare challenges,
including workforce deficits and escalating costs. The parallel development of
systematic evaluation benchmarks emerges as a critical imperative to enable
performance assessment and provide technological guidance. Meanwhile, as an
invaluable knowledge source, the potential of medical textbooks for benchmark
development remains underexploited. Here, we present MedBookVQA, a systematic
and comprehensive multimodal benchmark derived from open-access medical
textbooks. To curate this benchmark, we propose a standardized pipeline for
automated extraction of medical figures while contextually aligning them with
corresponding medical narratives. Based on this curated data, we generate 5,000
clinically relevant questions spanning modality recognition, disease
classification, anatomical identification, symptom diagnosis, and surgical
procedures. A multi-tier annotation system categorizes queries through
hierarchical taxonomies encompassing medical imaging modalities (42
categories), body anatomies (125 structures), and clinical specialties (31
departments), enabling nuanced analysis across medical subdomains. We evaluate
a wide array of MLLMs, including proprietary, open-sourced, medical, and
reasoning models, revealing significant performance disparities across task
types and model categories. Our findings highlight critical capability gaps in
current GMAI systems while establishing textbook-derived multimodal benchmarks
as essential evaluation tools. MedBookVQA establishes textbook-derived
benchmarking as a critical paradigm for advancing clinical AI, exposing
limitations in GMAI systems while providing anatomically structured performance
metrics across specialties.

</details>


### [96] [GIA-MIC: Multimodal Emotion Recognition with Gated Interactive Attention and Modality-Invariant Learning Constraints](https://arxiv.org/abs/2506.00865)
*Jiajun He,Jinyi Mi,Tomoki Toda*

Main category: cs.AI

TL;DR: 提出了一种新的多模态情感识别方法，能有效提取模态特定特征并对齐跨模态相似性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态情感识别研究主要由基于注意力的融合方法所主导，这些方法在分类性能上表现良好。然而，如何有效提取模态特定特征以及克服由模态异质性引起的分布差异，仍然是两个关键挑战。

Method: 我们提出了一种门控交互注意力机制和一种模态不变生成器。前者用于自适应提取模态特定特征，同时通过成对交互增强情感信息；后者用于学习模态不变的表示，并通过对齐跨模态相似性来限制领域转移。

Result: 我们在IEMOCAP数据集上的实验表明，所提出的方法优于现有的最先进多模态情感识别方法，达到了WA 80.7%和UA 81.3%的表现。

Conclusion: 我们的研究提出了一种新的机制，能有效改善现有多模态情感识别方法的性能。

Abstract: Multimodal emotion recognition (MER) extracts emotions from multimodal data,
including visual, speech, and text inputs, playing a key role in human-computer
interaction. Attention-based fusion methods dominate MER research, achieving
strong classification performance. However, two key challenges remain:
effectively extracting modality-specific features and capturing cross-modal
similarities despite distribution differences caused by modality heterogeneity.
To address these, we propose a gated interactive attention mechanism to
adaptively extract modality-specific features while enhancing emotional
information through pairwise interactions. Additionally, we introduce a
modality-invariant generator to learn modality-invariant representations and
constrain domain shifts by aligning cross-modal similarities. Experiments on
IEMOCAP demonstrate that our method outperforms state-of-the-art MER
approaches, achieving WA 80.7% and UA 81.3%.

</details>


### [97] [Toward a Theory of Agents as Tool-Use Decision-Makers](https://arxiv.org/abs/2506.00886)
*Hongru Wang,Cheng Qian,Manling Li,Jiahao Qiu,Boyang Xue,Mengdi Wang,Heng Ji,Kam-Fai Wong*

Main category: cs.AI

TL;DR: 论文讨论了大型语言模型作为自主代理时的认识基础，并提出了一种统一理论来提高代理的自主性和认识效率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型发展为更具自主性的代理，迫切需要解决其认识基础的问题。具体来说，如何定义一个代理？它应该如何决策？有哪些目标可以引导其行为？

Method: 提出一种统一理论，将内部推理和外部行动视为等同的认识工具。这使得代理能够系统地协调自省和互动。

Result: 该框架将代理的工具使用决策边界与其知识边界对齐，从而最小化不必要的工具使用并最大化认识效率。

Conclusion: 通过将代理设计为知识驱动的智能系统，该观点为构建具有适应性、高效且目标导向的基础代理提供了原则性途径。

Abstract: As Large Language Models (LLMs) evolve into increasingly autonomous agents,
fundamental questions about their epistemic foundations remain unresolved: What
defines an agent? How should it make decisions? And what objectives should
guide its behavior? In this position paper, we argue that true autonomy
requires agents to be grounded in a coherent epistemic framework that governs
what they know, what they need to know, and how to acquire that knowledge
efficiently. We propose a unified theory that treats internal reasoning and
external actions as equivalent epistemic tools, enabling agents to
systematically coordinate introspection and interaction. Building on this
framework, we advocate for aligning an agent's tool use decision-making
boundary with its knowledge boundary, thereby minimizing unnecessary tool use
and maximizing epistemic efficiency. This perspective shifts the design of
agents from mere action executors to knowledge-driven intelligence systems,
offering a principled path toward building foundation agents capable of
adaptive, efficient, and goal-directed behavior.

</details>


### [98] [Conformal Arbitrage: Risk-Controlled Balancing of Competing Objectives in Language Models](https://arxiv.org/abs/2506.00911)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 该论文提出了一种称为Conformal Arbitrage的框架，旨在通过数据驱动的阈值管理语言模型的多个目标之间的平衡。这种方法在API级别操作，确保不良事件的长远频率不超过用户设定的限额，并能与现有技术无缝集成。


<details>
  <summary>Details</summary>
Motivation: 在现代语言模型部署中，通常需要在多个竞争目标之间找到平衡，例如有用性与无害性、成本与准确性、奖励与安全性之间的平衡。

Method: 引入一种称为Conformal Arbitrage的方法，这是一种事后框架，用数据驱动的阈值来在优化主要目标的主模型和更保守的Guardian之间进行调解。阈值通过保角风险控制进行校准，确保不良事件的长远频率不超过用户规定的限额。该方法在API级别操作，无需访问模型logits或更新模型权重，因此能够与现有的基于权重的对齐技术和成本意识级联无缝集成。

Result: Empirically, Conformal Arbitrage traces an efficient frontier, allowing users to define an acceptable performance level for one objective while maximizing utility in another.我们观察到，该方法在与模型之间的随机路由匹配成本方面的准确性上表现得更好。

Conclusion: Conformal Arbitrage是一种实用且具有理论基础的工具，适用于在具有潜在竞争目标的广泛部署中实现大语言模型的可靠和经济部署。

Abstract: Modern language model deployments must often balance competing objectives,
for example, helpfulness versus harmlessness, cost versus accuracy, and reward
versus safety. We introduce Conformal Arbitrage, a post hoc framework that
learns a data driven threshold to mediate between a Primary model optimized for
a primary objective and a more conservative Guardian which could be another
model or a human domain expert aligned with a guardrail objective. The
threshold is calibrated with conformal risk control, yielding finite sample,
distribution free guarantees that the long run frequency of undesirable events,
such as factual errors or safety violations, does not exceed a user specified
quota. Because Conformal Arbitrage operates wholly at the API level, without
requiring access to model logits or updating model weights, it complements
weight based alignment techniques and integrates seamlessly with existing cost
aware cascades. Empirically, Conformal Arbitrage traces an efficient frontier,
allowing users to define an acceptable performance level for one objective
while maximizing utility in another. We observe that our method outperforms, in
terms of accuracy, cost matched random routing between models. These properties
make Conformal Arbitrage a practical, theoretically grounded tool for
trustworthy and economical deployment of large language models across a broad
range of potentially competing objectives.

</details>


### [99] [Aligning VLM Assistants with Personalized Situated Cognition](https://arxiv.org/abs/2506.00930)
*Yongqi Li,Shen Zhou,Xiaohu Li,Xin Miao,Jintao Wen,Mayi Xu,Jianhao Chen,Birong Pan,Hankun Kang,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.AI

TL;DR: 本文探讨将视觉语言模型（VLM）与个性化的情境认知进行对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 由于不同背景的人即使在同样的情况下也会有不同的认知，因此他们对VLM助手的期望可能是个性化的。这种差异化的需求使得需要紧急调整VLM助手以适应个性化的情境认知。

Method: 本文基于角色集合角色理论对个体进行简化，然后评估个体的行动来检查个性化对齐是否实现。构建了PCogAlignBench基准，包含18k实例和20个不同角色集合的个体，并提出了PCogAlign框架，通过认知感知和基于行为的奖励模型实现个性化对齐。

Result: 实验结果和人类评估证明了PCogAlignBench的可靠性以及PCogAlign方法的有效性。

Conclusion: PCogAlignBench基准和PCogAlign框架有效实现了视觉语言模型的个性化认知对齐，并将在GitHub上开源。

Abstract: Vision-language models (VLMs) aligned with general human objectives, such as
being harmless and hallucination-free, have become valuable assistants of
humans in managing visual tasks. However, people with diversified backgrounds
have different cognition even in the same situation. Consequently, they may
have personalized expectations for VLM assistants. This highlights the urgent
need to align VLM assistants with personalized situated cognition for
real-world assistance. To study this problem, we first simplify it by
characterizing individuals based on the sociological concept of Role-Set. Then,
we propose to evaluate the individuals' actions to examine whether the
personalized alignment is achieved. Further, we construct a benchmark named
PCogAlignBench, which includes 18k instances and 20 individuals with different
Role-Sets. Finally, we present a framework called PCogAlign, which constructs a
cognition-aware and action-based reward model for personalized alignment.
Experimental results and human evaluations demonstrate the reliability of the
PCogAlignBench and the effectiveness of our proposed PCogAlign. We will
open-source the constructed benchmark and code at
https://github.com/NLPGM/PCogAlign.

</details>


### [100] [Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues](https://arxiv.org/abs/2506.00958)
*Youngmin Kim,Jiwan Chung,Jisoo Kim,Sunghyun Lee,Sangkyu Lee,Junhyeok Kim,Cheoljong Yang,Youngjae Yu*

Main category: cs.AI

TL;DR: MARS是一种多模态语言模型，通过VENUS数据集整合非语言元素实现更沉浸式的对话体验，证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型未能有效整合非语言元素，限制了其创造完全沉浸式对话体验的能力，因此需要开发新的模型以弥补这一不足。

Method: 使用结合了文本与矢量量化的非语言表述的下一令牌预测目标方法对MARS进行训练，实现多模态理解和生成的统一框架。

Result: 实验结果表明，MARS能够成功生成与对话内容相匹配的文本和非语言信息，证明了其在实现多模态对话生成中的有效性。

Conclusion: MARS模型成功生成了与对话输入相对应的文本和非语言信息，证明了其在多模态理解和生成方面的有效性。

Abstract: Nonverbal communication is integral to human interaction, with gestures,
facial expressions, and body language conveying critical aspects of intent and
emotion. However, existing large language models (LLMs) fail to effectively
incorporate these nonverbal elements, limiting their capacity to create fully
immersive conversational experiences. We introduce MARS, a multimodal language
model designed to understand and generate nonverbal cues alongside text,
bridging this gap in conversational AI. Our key innovation is VENUS, a
large-scale dataset comprising annotated videos with time-aligned text, facial
expressions, and body language. Leveraging VENUS, we train MARS with a
next-token prediction objective, combining text with vector-quantized nonverbal
representations to achieve multimodal understanding and generation within a
unified framework. Based on various analyses of the VENUS datasets, we validate
its substantial scale and high effectiveness. Our quantitative and qualitative
results demonstrate that MARS successfully generates text and nonverbal
languages, corresponding to conversational input.

</details>


### [101] [Unlocking Personalized Knowledge in Federated Large Language Model: The Power of Mixture of Experts](https://arxiv.org/abs/2506.00965)
*Fan Liu,Bikang Pan,Zhongyi Wang,Xi Yao,Xiaoying Tang,Jingya Wang,Ye Shi*

Main category: cs.AI

TL;DR: 我们提出FLEx，为MoE模型设计了一个联邦学习框架，通过保留每个客户端的一个专家，并使用自适应门控机制重新整合这些专家。评估显示FLEx优于现有的基准。


<details>
  <summary>Details</summary>
Motivation: 当前的联邦学习方法主要设计用于密集模型，无法直接利用专家混合架构中的稀疏性。将MoE模型视为联邦场景中的密集网络会导致过多的通信和计算开销，削弱个性化知识共享的潜力。

Method: 我们提出了一种名为FLEx的联邦学习框架，通过调整剪枝全局MoE模型来保留每个客户端的一个专家，并使用自适应门控机制将这些个性化专家重新整合回预训练的MoE层。

Result: FLEx在非IID条件下对多种指令集数据进行的广泛评估中一贯表现优于现有的联邦基准。

Conclusion: FLEx证明可以有效个性化，通过修剪和门控机制保持原始架构不变，个性化专家在本地数据中训练，公共模块全球聚合。

Abstract: The Mixture of Experts (MoE) architecture has emerged as a prominent strategy
for scaling large language models (LLMs), effectively leveraging sparse
activation and facilitating task-specific personalization. However, current
federated learning (FL) approaches are primarily designed for dense models,
making them unable to directly exploit the sparsity inherent in MoE
architectures. Treating MoE models as dense networks in federated scenarios
results in excessive communication overhead and computational costs,
undermining the potential for personalized knowledge sharing. To address these
challenges, we propose FLEx (Federated LLMs with Personalized Experts), a novel
federated learning framework explicitly tailored for MoE-based LLMs. FLEx
efficiently personalizes by pruning the global MoE model to keep only one
expert per client, and employs an adaptive gating mechanism to reintegrate
these personalized experts into the pre-trained MoE layers, ensuring the
original backbone architecture remains unchanged. These personalized experts
are trained with local data and stored locally on each client, while the shared
modules are aggregated globally. Extensive evaluations on diverse
instruction-based datasets under non-IID conditions consistently demonstrate
that FLEx outperforms existing federated baselines. Our code is available at
https://anonymous.4open.science/r/FLEx-8F12.

</details>


### [102] [PolyBERT: Fine-Tuned Poly Encoder BERT-Based Model for Word Sense Disambiguation](https://arxiv.org/abs/2506.00968)
*Linhan Xia,Mingzhan Yang,Guohui Yuan,Shengnan Tao,Yujing Qiu,Guo Yu,Kai Lei*

Main category: cs.AI

TL;DR: PolyBERT is a BERT-based model using poly-encoder and batch contrastive learning to enhance performance and efficiency in WSD, outperforming existing methods by 2% in F1-score and saving 37.6% GPU hours.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations in existing BERT-based WSD approaches, specifically the imbalance between token-level and sequence-level semantics and the unnecessary computational cost from incorporating all possible senses of target words during training.

Method: The paper introduces a poly-encoder BERT-based model with batch contrastive learning, named PolyBERT. It employs a poly-encoder with a multi-head attention mechanism to fuse local and global semantics, and uses Batch Contrastive Learning to reduce training inputs by utilizing other target words in the batch as negative samples.

Result: PolyBERT improves F1-score by 2% compared to baseline methods like GlossBERT and BEM, and reduces GPU hours by 37.6% when using batch contrastive learning.

Conclusion: PolyBERT outperforms previous mainstream WSD methods and reduces computational costs by effectively balancing token-level and sequence-level semantics and by minimizing redundant training inputs.

Abstract: Mainstream Word Sense Disambiguation (WSD) approaches have employed BERT to
extract semantics from both context and definitions of senses to determine the
most suitable sense of a target word, achieving notable performance. However,
there are two limitations in these approaches. First, previous studies failed
to balance the representation of token-level (local) and sequence-level
(global) semantics during feature extraction, leading to insufficient semantic
representation and a performance bottleneck. Second, these approaches
incorporated all possible senses of each target word during the training phase,
leading to unnecessary computational costs. To overcome these limitations, this
paper introduces a poly-encoder BERT-based model with batch contrastive
learning for WSD, named PolyBERT. Compared with previous WSD methods, PolyBERT
has two improvements: (1) A poly-encoder with a multi-head attention mechanism
is utilized to fuse token-level (local) and sequence-level (global) semantics,
rather than focusing on just one. This approach enriches semantic
representation by balancing local and global semantics. (2) To avoid redundant
training inputs, Batch Contrastive Learning (BCL) is introduced. BCL utilizes
the correct senses of other target words in the same batch as negative samples
for the current target word, which reduces training inputs and computational
cost. The experimental results demonstrate that PolyBERT outperforms baseline
WSD methods such as Huang's GlossBERT and Blevins's BEM by 2\% in F1-score. In
addition, PolyBERT with BCL reduces GPU hours by 37.6\% compared with PolyBERT
without BCL.

</details>


### [103] [Boosting Bot Detection via Heterophily-Aware Representation Learning and Prototype-Guided Cluster Discovery](https://arxiv.org/abs/2506.00989)
*Buyun He,Xiaorui Jiang,Qi Wu,Hao Liu,Yingguang Yang,Yong Liao*

Main category: cs.AI

TL;DR: 提出了一种名为BotHP的生成式图自监督学习框架，通过异质性感知的表示学习和原型指导的聚类发现任务，提升图形基础的机器人检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前图形基础检测方法存在标签依赖和泛化能力局限的问题。GSL是一个解决这些问题的前景良好范式，但现有方法未能捕捉全球图形模式，影响其在机器人检测场景中的效果。

Method: BotHP采用双编码器架构，包括一个图形意识编码器和一个图形无关编码器，并结合原型指导的聚类发现任务来提高检测效果。

Result: 通过广泛的实验，BotHP证明能提升图形基础的机器人检测器，改善检测性能，减轻标签依赖，并增强泛化能力。

Conclusion: BotHP框架通过异质性敏感的表示学习和原型指导的聚类发现，有效提升了图形基础的机器人检测的性能。

Abstract: Detecting social media bots is essential for maintaining the security and
trustworthiness of social networks. While contemporary graph-based detection
methods demonstrate promising results, their practical application is limited
by label reliance and poor generalization capability across diverse
communities. Generative Graph Self-Supervised Learning (GSL) presents a
promising paradigm to overcome these limitations, yet existing approaches
predominantly follow the homophily assumption and fail to capture the global
patterns in the graph, which potentially diminishes their effectiveness when
facing the challenges of interaction camouflage and distributed deployment in
bot detection scenarios. To this end, we propose BotHP, a generative GSL
framework tailored to boost graph-based bot detectors through heterophily-aware
representation learning and prototype-guided cluster discovery. Specifically,
BotHP leverages a dual-encoder architecture, consisting of a graph-aware
encoder to capture node commonality and a graph-agnostic encoder to preserve
node uniqueness. This enables the simultaneous modeling of both homophily and
heterophily, effectively countering the interaction camouflage issue.
Additionally, BotHP incorporates a prototype-guided cluster discovery pretext
task to model the latent global consistency of bot clusters and identify
spatially dispersed yet semantically aligned bot collectives. Extensive
experiments on two real-world bot detection benchmarks demonstrate that BotHP
consistently boosts graph-based bot detectors, improving detection performance,
alleviating label reliance, and enhancing generalization capability.

</details>


### [104] [Higher-Order Responsibility](https://arxiv.org/abs/2506.01003)
*Junli Jiang,Pavel Naumov*

Main category: cs.AI

TL;DR: 研究高阶责任能否填补责任缺口，发现这是一个$\Pi_{2d+1}$-完全问题。


<details>
  <summary>Details</summary>
Motivation: 为解决传统责任定义在群体决策中导致的责任空缺问题，研究者提出了高阶责任这一新方法，并分析了其有效性。

Method: 作者对高阶责任进行了形式化分析，致力于研究在高达d级的责任下是否能够弥合责任缺口问题，并对其计算复杂性进行了分析。

Result: 研究的主要技术结果表明，确定高阶责任是否足以弥合责任缺口是一个$\Pi_{2d+1}$-完全问题，显示了问题的计算复杂性和挑战性。

Conclusion: 该研究得出结论，以高阶责任的方式，可以在一定程度上弥合传统责任界限所存在的责任缺口，但该计算问题的复杂性为$\Pi_{2d+1}$-完全。

Abstract: In ethics, individual responsibility is often defined through Frankfurt's
principle of alternative possibilities. This definition is not adequate in a
group decision-making setting because it often results in the lack of a
responsible party or "responsibility gap''. One of the existing approaches to
address this problem is to consider group responsibility. Another, recently
proposed, approach is "higher-order'' responsibility. The paper considers the
problem of deciding if higher-order responsibility up to degree $d$ is enough
to close the responsibility gap. The main technical result is that this problem
is $\Pi_{2d+1}$-complete.

</details>


### [105] [IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory](https://arxiv.org/abs/2506.01048)
*Wei Song,Zhenya Huang,Cheng Cheng,Weibo Gao,Bihan Xu,GuanHao Zhao,Fei Wang,Runze Wu*

Main category: cs.AI

TL;DR: 提出IRT-Router框架，通过项目反应理论优化LLM选择，提升查询响应性能与可解释性。实验结果证实其优越性。


<details>
  <summary>Details</summary>
Motivation: 在自然语言处理任务中选择最佳的LLM需在性能与成本之间进行权衡。为解决这一问题，提出了IRT-Router框架。

Method: IRT-Router使用心理测量方法中的项目反应理论来建模LLM能力与用户查询属性之间的关系，并设计了一种基于语义相似性的在线查询预热技术。

Result: 对20个LLM和12个数据集进行的广泛实验表明，IRT-Router在有效性和可解释性方面优于大多数基线方法，并在即时启动场景中表现出超强的可靠性与实用性。

Conclusion: IRT-Router在解决模型间性能与成本的权衡方面表现出优异的性能和可解释性。

Abstract: Large language models (LLMs) have demonstrated exceptional performance across
a wide range of natural language tasks. However, selecting the optimal LLM to
respond to a user query often necessitates a delicate balance between
performance and cost. While powerful models deliver better results, they come
at a high cost, whereas smaller models are more cost-effective but less
capable. To address this trade-off, we propose IRT-Router, a multi-LLM routing
framework that efficiently routes user queries to the most suitable LLM.
Inspired by Item Response Theory (IRT), a psychological measurement
methodology, IRT-Router explicitly models the relationship between LLM
capabilities and user query attributes. This not only enables accurate
prediction of response performance but also provides interpretable insights,
such as LLM abilities and query difficulty. Additionally, we design an online
query warm-up technique based on semantic similarity, further enhancing the
online generalization capability of IRT-Router. Extensive experiments on 20
LLMs and 12 datasets demonstrate that IRT-Router outperforms most baseline
methods in terms of effectiveness and interpretability. Its superior
performance in cold-start scenarios further confirms the reliability and
practicality of IRT-Router in real-world applications. Code is available at
https://github.com/Mercidaiha/IRT-Router.

</details>


### [106] [MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch](https://arxiv.org/abs/2506.01056)
*Xiang Fei,Xiawu Zheng,Hao Feng*

Main category: cs.AI

TL;DR: 引入MCP-Zero，一种能自行决定工具调用的框架，解决了上下文开销问题，准确选择工具并减少了令牌消耗。


<details>
  <summary>Details</summary>
Motivation: 对大模型进行工具调用时，大量工具模式注入导致的成本高和易出错的问题。

Method: 提出了一种主动代理框架MCP-Zero，包括主动工具请求、分层向量路由和迭代主动调用三个组件。

Result: MCP-Zero不仅有效解决了现有方法的上下文开销问题，而且在接近三千个候选工具池中准确选择，令牌消耗减少98%，并支持跨轮次工具调用。

Conclusion: MCP-Zero实现了在大规模工具池中高效、准确的工具选择和使用，还克服了现有方法中的上下文开销问题，并显著减少了令牌消耗。

Abstract: Function-calling has enabled large language models (LLMs) to act as
tool-using agents, but injecting thousands of tool schemas into the prompt is
costly and error-prone. We introduce MCP-Zero, a proactive agent framework that
lets the LLM itself decide when and which external tools to retrieve, thereby
assembling a task-specific toolchain from scratch. The framework is built upon
three components: (1) Proactive Tool Request, where the model emits a
structured $\left<\operatorname{tool\_assistant}\right>$ block that explicitly
specifies the desired server and task; (2) Hierarchical Vector Routing, a
coarse-to-fine retrieval algorithm that first selects candidate servers and
then ranks tools within each server based on the semantic similarity; (3)
Iterative Proactive Invocation, enabling multi-round, cross-domain toolchain
construction with minimal context overhead, and allowing the model to
iteratively revise its request when the returned tools are insufficient. To
evaluate our approach we also compile MCP-tools, a retrieval dataset comprising
308 MCP servers and 2,797 tools extracted from the official
Model-Context-Protocol repository and normalized into a unified JSON schema.
Experiments show that MCP-Zero (i) effectively addresses the context overhead
problem of existing methods and accurately selects the correct tool from a pool
of nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by
98\% on the APIbank while maintaining high accuracy; and (iii) supports
multi-turn tool invocation with consistent accuracy across rounds. The code and
dataset will be released soon.

</details>


### [107] [The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process](https://arxiv.org/abs/2506.01080)
*Florian Carichon,Aditi Khandelwal,Marylou Fauchard,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 本文探讨了AI在多代理系统中的对齐问题，强调了社会环境对代理对齐的影响，并呼吁结合人类价值观、偏好和目标作为互相关联的概念进行研究。


<details>
  <summary>Details</summary>
Motivation: 随着多代理系统在现实应用中的普及，它改变了代理如何追求目标和互动的动态。复杂的社会组织可能会导致代理与人类价值或用户偏好的偏差，因此需要新的方法来研究和解决这一问题。

Method: 文章从社会科学的视角分析了社会结构如何影响群体和个人价值观，并提出需要模拟环境和评估框架来研究多代理系统中的对齐问题。

Result: 分析了社会结构对代理系统中价值观的影响，并提出在多代理互动背景中评估对齐问题的方法。

Conclusion: 呼吁AI社区将人类、偏好和目标对齐视为相互依存的概念，而不是孤立的问题，并强调需要模拟环境、基准和评估框架，以便在多代理互动背景中评估对齐问题。

Abstract: This position paper states that AI Alignment in Multi-Agent Systems (MAS)
should be considered a dynamic and interaction-dependent process that heavily
depends on the social environment where agents are deployed, either
collaborative, cooperative, or competitive. While AI alignment with human
values and preferences remains a core challenge, the growing prevalence of MAS
in real-world applications introduces a new dynamic that reshapes how agents
pursue goals and interact to accomplish various tasks. As agents engage with
one another, they must coordinate to accomplish both individual and collective
goals. However, this complex social organization may unintentionally misalign
some or all of these agents with human values or user preferences. Drawing on
social sciences, we analyze how social structure can deter or shatter group and
individual values. Based on these analyses, we call on the AI community to
treat human, preferential, and objective alignment as an interdependent
concept, rather than isolated problems. Finally, we emphasize the urgent need
for simulation environments, benchmarks, and evaluation frameworks that allow
researchers to assess alignment in these interactive multi-agent contexts
before such dynamics grow too complex to control.

</details>


### [108] [Choices and their Provenance: Explaining Stable Solutions of Abstract Argumentation Frameworks](https://arxiv.org/abs/2506.01087)
*Bertram Ludäscher,Yilin Xia,Shawn Bowers*

Main category: cs.AI

TL;DR: 介绍了一种扩展稳定AF方案来源的新方法，识别关键攻击集，结合基础推导步骤与选择步骤以诊断并修复AF图。


<details>
  <summary>Details</summary>
Motivation: 对于稳定模型，寻求一种新的方式来扩展其推导过程，并更详细地理解论证状态的来源。

Method: 提出了一种新的方法，以生成并测试的方式扩展稳定AF方案的来源，识别最小的关键攻击集，结合基础推导步骤与选择步骤。通过识别每个论证状态的关键攻击边，提供了额外的见解。

Result: 所提出的方法能够识别稳定模型中的最小关键攻击集，并将其与基础AF模型结合，以提供关于论证状态的更详细的来源信息。

Conclusion: 提供了一种新的方法，扩展稳定AF方案的来源，并识别最小的关键攻击集，结合了基础推导步骤和选择步骤的见解。通过找到对AF图的最小"修复"，使之通过基础选择步骤与原始AF图的稳定模型一致。

Abstract: The rule $\mathrm{Defeated}(x) \leftarrow \mathrm{Attacks}(y,x),\, \neg \,
\mathrm{Defeated}(y)$, evaluated under the well-founded semantics (WFS), yields
a unique 3-valued (skeptical) solution of an abstract argumentation framework
(AF). An argument $x$ is defeated ($\mathrm{OUT}$) if there exists an
undefeated argument $y$ that attacks it. For 2-valued (stable) solutions, this
is the case iff $y$ is accepted ($\mathrm{IN}$), i.e., if all of $y$'s
attackers are defeated. Under WFS, arguments that are neither accepted nor
defeated are undecided ($\mathrm{UNDEC}$). As shown in prior work, well-founded
solutions (a.k.a. grounded labelings) "explain themselves": The provenance of
arguments is given by subgraphs (definable via regular path queries) rooted at
the node of interest. This provenance is closely related to winning strategies
of a two-player argumentation game.
  We present a novel approach for extending this provenance to stable AF
solutions. Unlike grounded solutions, which can be constructed via a bottom-up
alternating fixpoint procedure, stable models often involve non-deterministic
choice as part of the search for models. Thus, the provenance of stable
solutions is of a different nature, and reflects a more expressive generate &
test paradigm. Our approach identifies minimal sets of critical attacks,
pinpointing choices and assumptions made by a stable model. These critical
attack edges provide additional insights into the provenance of an argument's
status, combining well-founded derivation steps with choice steps. Our approach
can be understood as a form of diagnosis that finds minimal "repairs" to an AF
graph such that the well-founded solution of the repaired graph coincides with
the desired stable model of the original AF graph.

</details>


### [109] [Regulatory Graphs and GenAI for Real-Time Transaction Monitoring and Compliance Explanation in Banking](https://arxiv.org/abs/2506.01093)
*Kunal Khanvilkar,Kranthi Kommuru*

Main category: cs.AI

TL;DR: 本文提出了一种集成图模型化、叙述字段嵌入和生成性解释的实时交易监控框架，用于支持自动化金融合规性。在实验中，该方法表现出色，并获得专家认可。


<details>
  <summary>Details</summary>
Motivation: 为了支持自动化金融合规性，论文提出了一种实时交易监控框架。

Method: 该系统构建动态交易图，提取结构和上下文特征，并使用图神经网络分类可疑行为。然后，利用检索增强生成模块为每个标记的交易生成与法规条款一致的自然语言解释。

Result: 通过在模拟金融数据流上的实验，该方法实现了98.2%的F1-score、97.8%的精度和97.0%的召回率。专家评估进一步确认生成解释的质量和可解释性。

Conclusion: 该研究表明，将图智能与生成模型结合可以支持解释性强、可审计的高风险金融环境合规。

Abstract: This paper presents a real-time transaction monitoring framework that
integrates graph-based modeling, narrative field embedding, and generative
explanation to support automated financial compliance. The system constructs
dynamic transaction graphs, extracts structural and contextual features, and
classifies suspicious behavior using a graph neural network. A
retrieval-augmented generation module generates natural language explanations
aligned with regulatory clauses for each flagged transaction. Experiments
conducted on a simulated stream of financial data show that the proposed method
achieves superior results, with 98.2% F1-score, 97.8% precision, and 97.0%
recall. Expert evaluation further confirms the quality and interpretability of
generated justifications. The findings demonstrate the potential of combining
graph intelligence and generative models to support explainable, audit-ready
compliance in high-risk financial environments.

</details>


### [110] [Modular Speaker Architecture: A Framework for Sustaining Responsibility and Contextual Integrity in Multi-Agent AI Communication](https://arxiv.org/abs/2506.01095)
*Khe-Han Toh,Hong-Kuan Teo*

Main category: cs.AI

TL;DR: 提出了一种称为模块化说话者架构（MSA）的框架，解决多代理系统中的角色跟踪、责任连续性和上下文一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前框架缺乏明确的说话者责任机制，导致语境漂移、对齐不稳定以及可解释性下降。此研究旨在解决这些问题。

Method: 采用模块化的说话者架构，包括说话者角色模块、责任链跟踪器和上下文完整性验证器，通过手动和自动评分以及引导的统计分析来评估结果。

Result: MSA 在动态的多代理场景中实现稳定的沟通结构，且无需依赖情感信号或浅层启发。

Conclusion: MSA可以在多代理系统中提供稳定的交互结构，并且不依赖于情感信号或表面层级启发。

Abstract: Sustaining coherent, role-aware communication across multi-agent systems
remains a foundational challenge in AI. Current frameworks often lack explicit
mechanisms for speaker responsibility, leading to context drift, alignment
instability, and degraded interpretability over time. We propose the Modular
Speaker Architecture (MSA), a framework that decomposes speaker behavior into
modular components for role tracking, responsibility continuity, and contextual
coherence. Grounded in high-context human-AI dialogues, MSA includes three core
modules: a Speaker Role Module, a Responsibility Chain Tracker, and a
Contextual Integrity Validator. We evaluate MSA through annotated case studies
and introduce structural metrics-pragmatic consistency, responsibility flow,
and context stability-quantified via manual and automatic scoring and
bootstrapped statistical analysis. Our results show that MSA reliably maintains
interaction structure without reliance on affective signals or surface-level
heuristics. We further implement a prototype configuration language (G-Code)
and modular API to support MSA deployment in dynamic multi-agent scenarios.

</details>


### [111] [SuperRL: Reinforcement Learning with Supervision to Boost Language Model Reasoning](https://arxiv.org/abs/2506.01096)
*Yihao Liu,Shuocheng Li,Lang Cao,Yuhang Xie,Mengyu Zhou,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.AI

TL;DR: 提出SuperRL框架，通过结合离线监督和强化学习提升稀疏奖励环境下的学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决在稀疏奖励环境中，强化学习难以采样成功轨迹且标准策略强化学习方法未利用离线轨迹的问题。

Method: SuperRL引入了自适应开关和混合执行器，以在检测到稀疏奖励条件时集成策略梯度和监督学习目标。

Result: 实验证明，SuperRL在从稀疏奖励中提高样本效率、泛化和鲁棒性方面优于标准强化学习。

Conclusion: SuperRL能够在稀疏奖励条件下通过结合离线监督和强化学习来提高样本效率、泛化能力和鲁棒性。

Abstract: Large language models are increasingly used for complex reasoning tasks where
high-quality offline data such as expert-annotated solutions and distilled
reasoning traces are often available. However, in environments with sparse
rewards, reinforcement learning struggles to sample successful trajectories,
leading to inefficient learning. At the same time, these offline trajectories
that represent correct reasoning paths are not utilized by standard on-policy
reinforcement learning methods. To address this limitation, we propose SuperRL,
a unified training framework that adaptively incorporates offline supervision
into reinforcement learning. SuperRL introduces an Adaptive Switch to detect
sparse reward conditions and activates a Hybrid Actor when necessary. The
Hybrid Actor integrates policy gradient and supervised learning objectives at
the loss level, enabling the model to benefit from accurate offline reasoning
signals while maintaining the exploratory capacity of reinforcement learning.
Experiments on a range of reasoning benchmarks show that SuperRL consistently
outperforms standard reinforcement learning by improving sample efficiency,
generalization, and robustness under sparse rewards.

</details>


### [112] [ChemAU: Harness the Reasoning of LLMs in Chemical Research with Adaptive Uncertainty Estimation](https://arxiv.org/abs/2506.01116)
*Xinyi Liu,Lipeng Ma,Yixuan Li,Weidong Yang,Qingyuan Zhou,Jiayi Song,Shuhao Li,Ben Fei*

Main category: cs.AI

TL;DR: ChemAU enhances LLM performance in chemistry by adapting uncertainty estimation, addressing reasoning accuracy and knowledge gaps.


<details>
  <summary>Details</summary>
Motivation: To address the diminished effectiveness of LLMs in chemistry-related problem-solving due to hallucinations and lack of specific domain knowledge.

Method: ChemAU incorporates an adaptive uncertainty estimation method that applies varying uncertainty values based on the position of reasoning steps in the reasoning chain.

Result: ChemAU identifies gaps in chemistry knowledge and supplements chemical expertise, correcting flawed reasoning chains. Experiments show improvement in accuracy and uncertainty estimation.

Conclusion: ChemAU significantly enhances reasoning accuracy and uncertainty estimation for chemistry problems, addressing the shortcomings of LLMs.

Abstract: Large Language Models (LLMs) are widely used across various scenarios due to
their exceptional reasoning capabilities and natural language understanding.
While LLMs demonstrate strong performance in tasks involving mathematics and
coding, their effectiveness diminishes significantly when applied to
chemistry-related problems. Chemistry problems typically involve long and
complex reasoning steps, which contain specific terminology, including
specialized symbol systems and complex nomenclature conventions. These
characteristics often cause general LLMs to experience hallucinations during
the reasoning process due to their lack of specific knowledge. However,
existing methods are struggling to effectively leverage chemical expertise and
formulas. Moreover, current uncertainty estimation methods, designed to
mitigate potential reasoning errors, are unable to precisely identify specific
steps or key knowledge. In this work, we propose a novel framework called
ChemAU, which incorporates our adaptive uncertainty estimation method that
applies different uncertainty values based on the position of reasoning steps
within the whole reasoning chain. Leveraging this method, ChemAU identifies
gaps in chemistry knowledge and precisely supplements chemical expertise with
the specialized domain model, thereby correcting and updating the previously
flawed reasoning chain. Our experiments with three popular LLMs across three
chemistry datasets demonstrate that ChemAU significantly enhances both
reasoning accuracy and uncertainty estimation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [113] [Literature Review Of Multi-Agent Debate For Problem-Solving](https://arxiv.org/abs/2506.00066)
*Arne Tillmann*

Main category: cs.MA

TL;DR: 该文献综述研究多代理语言模型，分析其代理特性、通讯结构和决策过程，指出这些模型在提供优越结果的同时也面临计算成本和挑战。


<details>
  <summary>Details</summary>
Motivation: 解决领域中缺乏直接比较的问题，揭示因素如可扩展性、通讯结构和决策过程如何影响MA-LLM性能。

Method: 这篇文献综述综合了有关代理配置、通讯结构和决策过程的最新研究，同时借鉴了传统多代理系统和最先进的MA-LLM研究中的见解。

Result: 通过审视常见的实践并概述当前的挑战，这篇综述表明多代理方法可以产生更好的结果，但也面临着更高的计算成本和MA-LLM特有的未解决挑战。

Conclusion: 多代理语言模型（MA-LLM）能够提供优于单一代理模型的结果，但同时也面临更高的计算成本和尚待探索的挑战。这些发现为研究人员和从业者提供了开发强大且高效的多代理AI解决方案的路线图。

Abstract: Multi-agent large language models (MA-LLMs) are a rapidly growing research
area that leverages multiple interacting language agents to tackle complex
tasks, outperforming single-agent large language models. This literature review
synthesizes the latest research on agent profiles, communication structures,
and decision-making processes, drawing insights from both traditional
multi-agent systems and state-of-the-art MA-LLM studies. In doing so, it aims
to address the lack of direct comparisons in the field, illustrating how
factors like scalability, communication structure, and decision-making
processes influence MA-LLM performance. By examining frequent practices and
outlining current challenges, the review reveals that multi-agent approaches
can yield superior results but also face elevated computational costs and
under-explored challenges unique to MA-LLM. Overall, these findings provide
researchers and practitioners with a roadmap for developing robust and
efficient multi-agent AI solutions.

</details>


### [114] [Sorrel: A simple and flexible framework for multi-agent reinforcement learning](https://arxiv.org/abs/2506.00228)
*Rebekah A. Gelpí,Yibing Ju,Ethan C. Jackson,Yikai Tang,Shon Verch,Claas Voelcker,William A. Cunningham*

Main category: cs.MA

TL;DR: Sorrel是一个简化和直观的Python接口，适用于创建和测试多智能体强化学习环境，特别对社会科学家有用。


<details>
  <summary>Details</summary>
Motivation: 为了为社会科学家提供一个直观且易于使用的工具来研究多智能体强化学习环境中的群体动态。

Method: 本文介绍了Sorrel的基本设计理念和功能，强调其简单性和可访问性，并使用更符合心理学直觉的结构。

Result: 本文没有提供具体的实验结果，而是描述了Sorrel接口的设计特色。

Conclusion: Sorrel是一个有助于社会科学家研究学习和社会互动如何导致群体动态发展和变化的有用工具。

Abstract: We introduce Sorrel (https://github.com/social-ai-uoft/sorrel), a simple
Python interface for generating and testing new multi-agent reinforcement
learning environments. This interface places a high degree of emphasis on
simplicity and accessibility, and uses a more psychologically intuitive
structure for the basic agent-environment loop, making it a useful tool for
social scientists to investigate how learning and social interaction leads to
the development and change of group dynamics. In this short paper, we outline
the basic design philosophy and features of Sorrel.

</details>


### [115] [Adaptive Traffic-Following Scheme for Orderly Distributed Control of Multi-Vehicle Systems](https://arxiv.org/abs/2506.00703)
*Anahita Jain,Husni Idris,John-Paul Clarke,Daniel Delahaye*

Main category: cs.MA

TL;DR: 本研究提出了一种适应性控制方案，通过让飞机根据当前空域动态调整其交通跟随行为，在低飞行时间和较少空域失序间取得平衡，提高多智能体系统的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 早期研究表明，高密度条件下由交通跟随行为生成的秩序可减少旅行时间，而在低密度下，选择直接路径则更具优势。在此基础上，探索如何让飞机根据空气流量自主调整其交通跟随行为，从而优化飞行时间。

Method: 通过调整飞机自身追随交通行为的程度，使其能够动态适应当前空域状况，以实现低飞行时间与较少的空域失序之间的平衡。

Result: 动态交通跟随行为能在较低飞行时间的情况下，保持较低程度的空域失序。

Conclusion: 综合来看，在分布式自治多智能体系统中加入自组织行为有显著益处，并且在某些情况下可能是必要的。这种行为使系统更具可扩展性。

Abstract: We present an adaptive control scheme to enable the emergence of order within
distributed, autonomous multi-agent systems. Past studies showed that under
high-density conditions, order generated from traffic-following behavior
reduces travel times, while under low densities, choosing direct paths is more
beneficial. In this paper, we leveraged those findings to allow aircraft to
independently and dynamically adjust their degree of traffic-following behavior
based on the current state of the airspace. This enables aircraft to follow
other traffic only when beneficial. Quantitative analyses revealed that dynamic
traffic-following behavior results in lower aircraft travel times at the cost
of minimal levels of additional disorder to the airspace. The sensitivity of
these benefits to temporal and spatial horizons was also investigated. Overall,
this work highlights the benefits, and potential necessity, of incorporating
self-organizing behavior in making distributed, autonomous multi-agent systems
scalable.

</details>


### [116] [Agentic AI and Multiagentic: Are We Reinventing the Wheel?](https://arxiv.org/abs/2506.01463)
*V. Botti*

Main category: cs.MA

TL;DR: 本文分析了Agentic AI和Multiagentic AI的概念误用，呼吁正确使用传统AI术语以避免知识重建问题。


<details>
  <summary>Details</summary>
Motivation: 为了纠正当前在AI术语特别是Agentic AI和Multiagentic AI使用上的概念误用，并展示其与传统AI领域术语的关系。

Method: 通过回顾社交科学和哲学中的理论起源，以及对建立在此基础上的智能体和多智能体系统的经典作品进行分析与总结。

Result: 发现许多人将术语Agentic AI和Multiagentic AI宽泛使用为流行词，实际上它们分别对应于AI智能体和多智能体系统，忽视了该领域中自主演员和多智能体系统数十年的研究。

Conclusion: 本文强调了科学和技术严格性的重要性，呼吁在新的LLM时代正确使用AI术语，以避免重新发明轮子的问题。

Abstract: The terms Agentic AI and Multiagentic AI have recently gained popularity in
discussions on generative artificial intelligence, often used to describe
autonomous software agents and systems composed of such agents. However, the
use of these terms confuses these buzzwords with well-established concepts in
AI literature: intelligent agents and multi-agent systems. This article offers
a critical analysis of this conceptual misuse. We review the theoretical
origins of "agentic" in the social sciences (Bandura, 1986) and philosophical
notions of intentionality (Dennett, 1971), and then summarise foundational
works on intelligent agents and multi-agent systems by Wooldridge, Jennings and
others. We examine classic agent architectures, from simple reactive agents to
Belief-Desire-Intention (BDI) models, and highlight key properties (autonomy,
reactivity, proactivity, social capability) that define agency in AI. We then
discuss recent developments in large language models (LLMs) and agent platforms
based on LLMs, including the emergence of LLM-powered AI agents and open-source
multi-agent orchestration frameworks. We argue that the term AI Agentic is
often used as a buzzword for what are essentially AI agents, and AI
Multiagentic for what are multi-agent systems. This confusion overlooks decades
of research in the field of autonomous agents and multi-agent systems. The
article advocates for scientific and technological rigour and the use of
established terminology from the state of the art in AI, incorporating the
wealth of existing knowledge, including standards for multi-agent system
platforms, communication languages and coordination and cooperation algorithms,
agreement technologies (automated negotiation, argumentation, virtual
organisations, trust, reputation, etc.), into the new and promising wave of
LLM-based AI agents, so as not to end up reinventing the wheel.

</details>


### [117] [Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research](https://arxiv.org/abs/2506.01839)
*Jennifer Haase,Sebastian Pokutta*

Main category: cs.MA

TL;DR: 本文探讨了大规模语言模型从工具到代理系统的转变过程及其对社会科学研究的影响，提供了不同代理架构的框架，并讨论了相关的技术、伦理挑战和研究潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型（LLM）从静态工具转向完全代理化系统，其对社会科学研究的转型潜力日益显著。

Method: 本文通过分为六个层次的框架来理解LLM代理的应用，从简单的数据处理器到复杂的、多代理系统能够模拟社会动态，阐明不同代理架构之间的技术和方法界限，提供当前能力与未来潜力的全面概述。

Result: 本文强调了低级系统如何简化文本分类和数据标注等传统任务，而高级系统则允许新的探究形式，包括研究群体动态、规范形成和大规模社会过程。同时也提出了显著挑战，包括可重复性、伦理监督和潜在偏见等问题，强调了需要强有力的验证协议、跨学科合作和标准化评估指标。

Conclusion: 尽管基于大规模语言模型（LLM）的代理系统对社会科学研究具有变革潜力，但实现这一承诺需要仔细、情境敏感的部署和持续的方法改进。本文呼吁未来的研究在技术创新与伦理责任之间取得平衡，鼓励开发能够不仅仅复制而且扩展社会科学边界的代理系统，从而提供关于人类行为复杂性的新见解。

Abstract: As large language models (LLMs) transition from static tools to fully agentic
systems, their potential for transforming social science research has become
increasingly evident. This paper introduces a structured framework for
understanding the diverse applications of LLM-based agents, ranging from simple
data processors to complex, multi-agent systems capable of simulating emergent
social dynamics. By mapping this developmental continuum across six levels, the
paper clarifies the technical and methodological boundaries between different
agentic architectures, providing a comprehensive overview of current
capabilities and future potential. It highlights how lower-tier systems
streamline conventional tasks like text classification and data annotation,
while higher-tier systems enable novel forms of inquiry, including the study of
group dynamics, norm formation, and large-scale social processes. However,
these advancements also introduce significant challenges, including issues of
reproducibility, ethical oversight, and the risk of emergent biases. The paper
critically examines these concerns, emphasizing the need for robust validation
protocols, interdisciplinary collaboration, and standardized evaluation
metrics. It argues that while LLM-based agents hold transformative potential
for the social sciences, realizing this promise will require careful,
context-sensitive deployment and ongoing methodological refinement. The paper
concludes with a call for future research that balances technical innovation
with ethical responsibility, encouraging the development of agentic systems
that not only replicate but also extend the frontiers of social science,
offering new insights into the complexities of human behavior.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [118] [Modality Equilibrium Matters: Minor-Modality-Aware Adaptive Alternating for Cross-Modal Memory Enhancement](https://arxiv.org/abs/2506.00030)
*Xiang Shi,Rui Zhang,Jiawei Liu,Yinpeng Liu,Qikai Cheng,Wei Lu*

Main category: cs.LG

TL;DR: 提出了一种Shapley引导的交替训练框架，解决多模态融合中的模态不平衡问题，结果在多个数据集上取得了最新成绩并展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对多模态融合中容易发生的模态不平衡问题，尤其是对于模态不完整的情况，提出新方法以改善融合效果。

Method: 提出了一种Shapley引导的交替训练框架，该框架利用基于Shapley价值的调度自适应地改进训练序列，并引入记忆模块和跨模态映射机制，在特征和样本级别上对齐特征。

Result: 在四个多模态基准数据集上进行评估，提出的方法在平衡和准确性方面达到了最新的(SOTA)结果。同时，其在缺失模态下的鲁棒性分析突出了其强大的泛化能力。

Conclusion: 研究发现，交替训练中的战略性模态优先排序可以平衡并促进多模态学习，提出了优化多模态训练动态的新范式。

Abstract: Multimodal fusion is susceptible to modality imbalance, where dominant
modalities overshadow weak ones, easily leading to biased learning and
suboptimal fusion, especially for incomplete modality conditions. To address
this problem, we propose a Shapley-guided alternating training framework that
adaptively prioritizes minor modalities to balance and thus enhance the fusion.
Our method leverages Shapley Value-based scheduling to improve the training
sequence adaptively, ensuring that under-optimized modalities receive
sufficient learning. Additionally, we introduce the memory module to refine and
inherit modality-specific representations with a cross-modal mapping mechanism
to align features at both the feature and sample levels. To further validate
the adaptability of the proposed approach, the encoder module empirically
adopts both conventional and LLM-based backbones. With building up a novel
multimodal equilibrium metric, namely, equilibrium deviation metric (EDM), we
evaluate the performance in both balance and accuracy across four multimodal
benchmark datasets, where our method achieves state-of-the-art (SOTA) results.
Meanwhile, robustness analysis under missing modalities highlights its strong
generalization capabilities. Accordingly, our findings reveal the untapped
potential of alternating training, demonstrating that strategic modality
prioritization fundamentally balances and promotes multimodal learning,
offering a new paradigm for optimizing multimodal training dynamics.

</details>


### [119] [AbsoluteNet: A Deep Learning Neural Network to Classify Cerebral Hemodynamic Responses of Auditory Processing](https://arxiv.org/abs/2506.00039)
*Behtom Adeli,John Mclinden,Pankaj Pandey,Ming Shao,Yalda Shahriari*

Main category: cs.LG

TL;DR: AbsoluteNet is a novel deep learning model that outperforms existing models in classifying auditory event-related responses in fNIRS data, showing improved accuracy and specificity.


<details>
  <summary>Details</summary>
Motivation: To improve the classification accuracy of auditory event-related hemodynamic responses in brain-computer interface applications using fNIRS data.

Method: The study introduces AbsoluteNet, which employs spatio-temporal convolution and customized activation functions for classifying auditory event-related responses recorded using fNIRS.

Result: AbsoluteNet achieved 87.0% accuracy, 84.8% sensitivity, and 89.2% specificity in binary classification, outperforming the former leading model fNIRSNET by 3.8% in accuracy.

Conclusion: AbsoluteNet, a novel deep learning architecture, significantly improves the classification of auditory event-related hemodynamic responses in fNIRS data, achieving higher performance than existing models.

Abstract: In recent years, deep learning (DL) approaches have demonstrated promising
results in decoding hemodynamic responses captured by functional near-infrared
spectroscopy (fNIRS), particularly in the context of brain-computer interface
(BCI) applications. This work introduces AbsoluteNet, a novel deep learning
architecture designed to classify auditory event-related responses recorded
using fNIRS. The proposed network is built upon principles of spatio-temporal
convolution and customized activation functions. Our model was compared against
several models, namely fNIRSNET, MDNN, DeepConvNet, and ShallowConvNet. The
results showed that AbsoluteNet outperforms existing models, reaching 87.0%
accuracy, 84.8% sensitivity, and 89.2% specificity in binary classification,
surpassing fNIRSNET, the second-best model, by 3.8% in accuracy. These findings
underscore the effectiveness of our proposed deep learning model in decoding
hemodynamic responses related to auditory processing and highlight the
importance of spatio-temporal feature aggregation and customized activation
functions to better fit fNIRS dynamics.

</details>


### [120] [Adapting Offline Reinforcement Learning with Online Delays](https://arxiv.org/abs/2506.00131)
*Simon Sinong Zhan,Qingyuan Wu,Frank Yang,Xiangyu Shi,Chao Huang,Qi Zhu*

Main category: cs.LG

TL;DR: 提出了DT-CORL，使用transformer生成稳健的延迟动作，高效缩小sim-to-real延迟差距。


<details>
  <summary>Details</summary>
Motivation: 解决离线RL代理在实际系统中面临的sim-to-real和交互差距。

Method: DT-CORL框架使用transformer-based信任预测器生成稳健的延迟动作，无需在训练期间看到延迟观测。

Result: DT-CORL在D4RL基准测试的多种延迟设置中，始终优于历史增强和普通信任方法。

Conclusion: DT-CORL缩小了sim-to-real延迟差距，同时保持了数据效率。

Abstract: Offline-to-online deployment of reinforcement-learning (RL) agents must
bridge two gaps: (1) the sim-to-real gap, where real systems add latency and
other imperfections not present in simulation, and (2) the interaction gap,
where policies trained purely offline face out-of-distribution states during
online execution because gathering new interaction data is costly or risky.
Agents therefore have to generalize from static, delay-free datasets to
dynamic, delay-prone environments. Standard offline RL learns from delay-free
logs yet must act under delays that break the Markov assumption and hurt
performance. We introduce DT-CORL (Delay-Transformer belief policy Constrained
Offline RL), an offline-RL framework built to cope with delayed dynamics at
deployment. DT-CORL (i) produces delay-robust actions with a transformer-based
belief predictor even though it never sees delayed observations during
training, and (ii) is markedly more sample-efficient than na\"ive
history-augmentation baselines. Experiments on D4RL benchmarks with several
delay settings show that DT-CORL consistently outperforms both
history-augmentation and vanilla belief-based methods, narrowing the
sim-to-real latency gap while preserving data efficiency.

</details>


### [121] [Tradeoffs between Mistakes and ERM Oracle Calls in Online and Transductive Online Learning](https://arxiv.org/abs/2506.00135)
*Idan Attias,Steve Hanneke,Arvind Ramaswami*

Main category: cs.LG

TL;DR: 研究了在线学习中通过ERM和弱一致性预言机与概念类交互的效果，提出了多种情况下的错误下界及相应的学习结果。


<details>
  <summary>Details</summary>
Motivation: 探讨在线学习模型中的学习者在仅通过经验风险最小化（ERM）或弱一致性预言机与概念类交互的情况下，如何有效进行学习设置。

Method: 使用ERM预言机获取在给定集合上的损失最小化假设，以及弱一致性预言机判断集合是否可实现。分析了在这些不同设置下的错误数和预言机调用次数。

Result: 得出了在标准在线测与ERM访问情况下的严格下界；在传递在线模型中，通过增加弱一致性预言机调用，可实现最佳可实现和鲁棒错误界。限制查询可根据具体概念类使用随机算法减少预言机调用。

Conclusion: 提出在线学习和传递在线学习中使用ERM和弱一致性预言机与概念类交互的框架，证明了在多种情况下的错误下界，并展示了现有在线学习结果在弱一致性设置下的适用性。

Abstract: We study online and transductive online learning when the learner interacts
with the concept class only via Empirical Risk Minimization (ERM) or weak
consistency oracles on arbitrary instance subsets. This contrasts with standard
online models, where the learner knows the entire class. The ERM oracle returns
a hypothesis minimizing loss on a given subset, while the weak consistency
oracle returns a binary signal indicating whether the subset is realizable by
some concept. The learner is evaluated by the number of mistakes and oracle
calls. In the standard online setting with ERM access, we prove tight lower
bounds in both realizable and agnostic cases: $\Omega(2^{d_{VC}})$ mistakes and
$\Omega(\sqrt{T 2^{d_{LD}}})$ regret, where $T$ is the number of timesteps and
$d_{LD}$ is the Littlestone dimension. We further show that existing online
learning results with ERM access carry over to the weak consistency setting,
incurring an additional $O(T)$ in oracle calls. We then consider the
transductive online model, where the instance sequence is known but labels are
revealed sequentially. For general Littlestone classes, we show that optimal
realizable and agnostic mistake bounds can be achieved using $O(T^{d_{VC}+1})$
weak consistency oracle calls. On the negative side, we show that limiting the
learner to $\Omega(T)$ weak consistency queries is necessary for transductive
online learnability, and that restricting the learner to $\Omega(T)$ ERM
queries is necessary to avoid exponential dependence on the Littlestone
dimension. Finally, for certain concept classes, we reduce oracle calls via
randomized algorithms while maintaining similar mistake bounds. In particular,
for Thresholds on an unknown ordering, $O(\log T)$ ERM queries suffice; for
$k$-Intervals, $O(T^3 2^{2k})$ weak consistency queries suffice.

</details>


### [122] [On Designing Diffusion Autoencoders for Efficient Generation and Representation Learning](https://arxiv.org/abs/2506.00136)
*Magdalena Proszewska,Nikolay Malkin,N. Siddharth*

Main category: cs.LG

TL;DR: 通过设计DMZ模型，将不同扩散模型的优点结合，实现高效的生成和有效的表示。


<details>
  <summary>Details</summary>
Motivation: 扩散自动编码器依赖于能够良好建模和采样的潜变量，而改进生成模型的性能是另一类学习其前向过程的扩散模型的主要目标。本文旨在结合这两类模型的优点。

Method: 通过选择合适的潜变量和条件方法，将两类模型结合起来，以实现更高效的生成建模以及更有效的表示。

Result: 设计一种称为DMZ的模型，它可以在较少的去噪步骤中实现有效表示，并在下游任务中评估表现出色。

Conclusion: 本文提出的DMZ模型可以同时获得有效的表示和高效的生成能力，尤其在域转移任务中表现出色，同时相比标准的扩散模型，减少了去噪步骤。

Abstract: Diffusion autoencoders (DAs) are variants of diffusion generative models that
use an input-dependent latent variable to capture representations alongside the
diffusion process. These representations, to varying extents, can be used for
tasks such as downstream classification, controllable generation, and
interpolation. However, the generative performance of DAs relies heavily on how
well the latent variables can be modelled and subsequently sampled from. Better
generative modelling is also the primary goal of another class of diffusion
models -- those that learn their forward (noising) process. While effective at
adjusting the noise process in an input-dependent manner, they must satisfy
additional constraints derived from the terminal conditions of the diffusion
process. Here, we draw a connection between these two classes of models and
show that certain design decisions (latent variable choice, conditioning
method, etc.) in the DA framework -- leading to a model we term DMZ -- allow us
to obtain the best of both worlds: effective representations as evaluated on
downstream tasks, including domain transfer, as well as more efficient
modelling and generation with fewer denoising steps compared to standard DMs.

</details>


### [123] [Reinforcement Learning for Hanabi](https://arxiv.org/abs/2506.00458)
*Nina Cohen,Kordel K. France*

Main category: cs.LG

TL;DR: TD算法在Hanabi中整体表现更佳，特别是表格式预期SARSA和深度Q学习。


<details>
  <summary>Details</summary>
Motivation: Hanabi是一种具有不完全信息的合作卡牌游戏，给强化学习代理带来了挑战，因此研究其在加固学习中的表现。

Method: 研究比较了不同的表格式和深度强化学习算法在Hanabi游戏中的表现，测试了同类和不同类代理对决中的表现。

Result: 最终发现，时间差分（TD）算法在整体性能和游戏类型的平衡上优于表格式代理，其中表格化的预期SARSA和深度Q学习代理表现最佳。

Conclusion: 在Hanabi这个具有不完全信息的合作卡牌游戏中，深度Q学习算法和表格式预期SARSA算法在不同类型的对手面前表现出了最佳性能。

Abstract: Hanabi has become a popular game for research when it comes to reinforcement
learning (RL) as it is one of the few cooperative card games where you have
incomplete knowledge of the entire environment, thus presenting a challenge for
a RL agent. We explored different tabular and deep reinforcement learning
algorithms to see which had the best performance both against an agent of the
same type and also against other types of agents. We establish that certain
agents played their highest scoring games against specific agents while others
exhibited higher scores on average by adapting to the opposing agent's
behavior. We attempted to quantify the conditions under which each algorithm
provides the best advantage and identified the most interesting interactions
between agents of different types. In the end, we found that temporal
difference (TD) algorithms had better overall performance and balancing of play
types compared to tabular agents. Specifically, tabular Expected SARSA and deep
Q-Learning agents showed the best performance.

</details>


### [124] [Aligning Language Models with Observational Data: Opportunities and Risks from a Causal Perspective](https://arxiv.org/abs/2506.00152)
*Erfan Loghmani*

Main category: cs.LG

TL;DR: 研究了使用观察性数据微调大型语言模型的挑战和机会，提出了一种去除混淆因素影响的方法以优化因果关系恢复。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在与人类偏好或优化商业目标时存在不足，因此需要通过优质标记数据进行微调。

Method: 提出了DeconfoundLM方法，该方法通过去除奖励信号中的已知混淆因素的影响，改善因果关系的恢复。

Result: DeconfoundLM改善了因果关系的恢复，并减轻了忽视或天真地结合混淆变量的微调方法中的失效模式。

Conclusion: 观察性数据可以成为大模型对齐的强大信号来源，只要进行正确的因果校正。

Abstract: Large language models are being widely used across industries to generate
content that contributes directly to key performance metrics, such as
conversion rates. Pretrained models, however, often fall short when it comes to
aligning with human preferences or optimizing for business objectives. As a
result, fine-tuning with good-quality labeled data is essential to guide models
to generate content that achieves better results. Controlled experiments, like
A/B tests, can provide such data, but they are often expensive and come with
significant engineering and logistical challenges. Meanwhile, companies have
access to a vast amount of historical (observational) data that remains
underutilized. In this work, we study the challenges and opportunities of
fine-tuning LLMs using observational data. We show that while observational
outcomes can provide valuable supervision, directly fine-tuning models on such
data can lead them to learn spurious correlations. We present empirical
evidence of this issue using various real-world datasets and propose
DeconfoundLM, a method that explicitly removes the effect of known confounders
from reward signals. Using simulation experiments, we demonstrate that
DeconfoundLM improves the recovery of causal relationships and mitigates
failure modes found in fine-tuning methods that ignore or naively incorporate
confounding variables. Our findings highlight that while observational data
presents risks, with the right causal corrections, it can be a powerful source
of signal for LLM alignment. Please refer to the project page for code and
related resources.

</details>


### [125] [Privacy Amplification in Differentially Private Zeroth-Order Optimization with Hidden States](https://arxiv.org/abs/2506.00158)
*Eli Chien,Wei-Ning Chen,Pan Li*

Main category: cs.LG

TL;DR: 研究的重点是零阶优化的隐私分析，成功证明其收敛性隐私界并提出了更优算法设计。


<details>
  <summary>Details</summary>
Motivation: 零阶优化在大规模语言模型领域具有潜力，尤其是在差分隐私和内存限制条件下，但其隐私分析和算法设计仍需深入探索。

Method: 我们采用隐私放大的迭代框架来分析零阶优化的隐私界，证明其收敛特性。

Result: 提出了一种零阶优化的收敛的差分隐私界，并改善了零阶算法的设计。

Conclusion: 我们证明了零阶优化的隐私性收敛界，为此类方法提供了隐私放大迭代框架在平滑损失函数条件下的推广，从而提出了更优的零阶算法设计。

Abstract: Zeroth-order optimization has emerged as a promising approach for fine-tuning
large language models on domain-specific data, particularly under differential
privacy (DP) and memory constraints. While first-order methods have been
extensively studied from a privacy perspective, the privacy analysis and
algorithmic design for zeroth-order methods remain significantly underexplored.
A critical open question concerns hidden-state DP analysis: although convergent
privacy bounds are known for first-order methods, it has remained unclear
whether similar guarantees can be established for zeroth-order methods. In this
work, we provide an affirmative answer by proving a convergent DP bound for
zeroth-order optimization. Our analysis generalizes the celebrated privacy
amplification-by-iteration framework to the setting of smooth loss functions in
zeroth-order optimization. Furthermore, it induces better DP zeroth-order
algorithmic designs that are previously unknown to the literature.

</details>


### [126] [Disentangled Safety Adapters Enable Efficient Guardrails and Flexible Inference-Time Alignment](https://arxiv.org/abs/2506.00166)
*Kundan Krishna,Joseph Y Cheng,Charles Maalouf,Leon A Gatys*

Main category: cs.LG

TL;DR: DSA provides an efficient and flexible AI safety framework, outperforming standalone models in multiple safety tasks and reducing alignment tax while maintaining strong performance.


<details>
  <summary>Details</summary>
Motivation: The motivation behind the study is to create a safety framework that does not compromise inference efficiency or the flexibility of development, addressing the limitations of existing AI safety paradigms.

Method: The paper introduces Disentangled Safety Adapters (DSA), which decouple safety computations from task-optimized base models. DSA utilizes lightweight adapters leveraging the base model's representations to ensure safety with minimal inference cost.

Result: Empirical results show that DSA-based guardrails outperform standalone models, improving hallucination detection, hate speech classification, and unsafe input recognition. It also allows for dynamic adjustment of alignment at inference time, enhancing safety outcomes in various tests.

Conclusion: DSA represents a modular and efficient framework for AI safety, offering significant improvements in a variety of safety and alignment metrics without compromising on efficiency or flexibility.

Abstract: Existing paradigms for ensuring AI safety, such as guardrail models and
alignment training, often compromise either inference efficiency or development
flexibility. We introduce Disentangled Safety Adapters (DSA), a novel framework
addressing these challenges by decoupling safety-specific computations from a
task-optimized base model. DSA utilizes lightweight adapters that leverage the
base model's internal representations, enabling diverse and flexible safety
functionalities with minimal impact on inference cost. Empirically, DSA-based
safety guardrails substantially outperform comparably sized standalone models,
notably improving hallucination detection (0.88 vs. 0.61 AUC on Summedits) and
also excelling at classifying hate speech (0.98 vs. 0.92 on ToxiGen) and unsafe
model inputs and responses (0.93 vs. 0.90 on AEGIS2.0 & BeaverTails).
Furthermore, DSA-based safety alignment allows dynamic, inference-time
adjustment of alignment strength and a fine-grained trade-off between
instruction following performance and model safety. Importantly, combining the
DSA safety guardrail with DSA safety alignment facilitates context-dependent
alignment strength, boosting safety on StrongReject by 93% while maintaining
98% performance on MTBench -- a total reduction in alignment tax of 8
percentage points compared to standard safety alignment fine-tuning. Overall,
DSA presents a promising path towards more modular, efficient, and adaptable AI
safety and alignment.

</details>


### [127] [Breakpoint: Scalable evaluation of system-level reasoning in LLM code agents](https://arxiv.org/abs/2506.00172)
*Kaivalya Hariharan,Uzay Girit,Atticus Wang,Jacob Andreas*

Main category: cs.LG

TL;DR: Breakpoint是一种基准测试方法，通过自动生成对抗性的代码修复任务评估LLMs的长视距推理能力，并有效控制任务难度。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界任务，如软件工程或科研，需要智能体能够迅速理解和处理新颖、复杂的结构。评估这些能力需要能够构建大量多样化的问题集供智能体解决。现有长视距评估套件（如SWE-bench）依赖人工策划的问题，扩展或调节难度需要昂贵的人力投入，评估也很快达到饱和。

Method: Breakpoint是一种基准测试方法，通过对现实软件库中的函数进行对抗性的破坏，自动生成代码修复任务。它系统地控制任务难度，依据两个明确的维度来评估：局部推理（如圈复杂度）和系统级推理（如调用图中心性以及同时被破坏的相互依赖函数数量）。

Result: 在超过900个生成任务的实验中，我们证明了该方法论可以扩展到任意难度，最先进的模型的成功率从最容易的任务的55%下降到最困难任务的0%。

Conclusion: Breakpoint能够自动生成挑战性的代码修复任务，并有效评估语言模型在不同复杂度任务下的表现。

Abstract: Benchmarks for large language models (LLMs) have predominantly assessed
short-horizon, localized reasoning. Existing long-horizon suites (e.g.
SWE-bench) rely on manually curated issues, so expanding or tuning difficulty
demands expensive human effort and evaluations quickly saturate. However, many
real-world tasks, such as software engineering or scientific research, require
agents to rapidly comprehend and manipulate novel, complex structures
dynamically; evaluating these capabilities requires the ability to construct
large and varied sets of problems for agents to solve. We introduce Breakpoint,
a benchmarking methodology that automatically generates code-repair tasks by
adversarially corrupting functions within real-world software repositories.
Breakpoint systematically controls task difficulty along two clear dimensions:
local reasoning (characterized by code complexity metrics such as cyclomatic
complexity) and system-level reasoning (characterized by call-graph centrality
and the number of simultaneously corrupted interdependent functions). In
experiments across more than 900 generated tasks we demonstrate that our
methodology can scale to arbitrary difficulty, with state-of-the-art models'
success rates ranging from 55% on the easiest tasks down to 0% on the hardest.

</details>


### [128] [Accountability Attribution: Tracing Model Behavior to Training Processes](https://arxiv.org/abs/2506.00175)
*Shichang Zhang,Hongzhe Du,Karim Saraipour,Jiaqi W. Ma,Himabindu Lakkaraju*

Main category: cs.LG

TL;DR: 提出了一种框架追踪训练阶段对模型行为的影响，并通过估计器量化阶段效应，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 模型部署后成功或失败，如何追溯到训练过程中的具体阶段，这是一个问责问题。我们的目标是追溯模型行为至训练过程中的具体阶段。

Method: 我们引入了一种基于一阶近似的估计器，该估计器在不需要重新训练的情况下有效量化训练阶段的影响。

Result: 实验证明，我们的方法能够识别出导致模型出现具体行为的责任训练阶段。

Conclusion: 我们的方法可以有效识别出具体行为责任的训练阶段，为模型分析提供了实用工具，并推动了更负责任的AI发展。

Abstract: Modern AI development pipelines often involve multiple stages-pretraining,
fine-tuning rounds, and subsequent adaptation or alignment-with numerous model
update steps within each stage. This raises a critical question of
accountability: when a deployed model succeeds or fails, which stage is
responsible, and to what extent? We pose the problem of accountability
attribution, which aims to trace model behavior back to specific stages of the
training process. To address this, we propose a general framework that answers
counterfactual questions about stage effects: how would the model behavior have
changed if the updates from a training stage had not been executed?. Within
this framework, we introduce estimators based on first-order approximations
that efficiently quantify the stage effects without retraining. Our estimators
account for both the training data and key aspects of optimization dynamics,
including learning rate schedules, momentum, and weight decay. Empirically, we
demonstrate that our approach identifies training stages accountable for
specific behaviors, offering a practical tool for model analysis and a step
toward more accountable AI development.

</details>


### [129] [On the Interaction of Noise, Compression Role, and Adaptivity under $(L_0, L_1)$-Smoothness: An SDE-based Approach](https://arxiv.org/abs/2506.00181)
*Enea Monzio Compagnoni,Rustem Islamov,Antonio Orvieto,Eduard Gorbunov*

Main category: cs.LG

TL;DR: 研究表明，分布式SignSGD在噪声情况下能有效收敛，而分布式SGD需要适应性才能实现收敛。


<details>
  <summary>Details</summary>
Motivation: 通过分析批量噪声、随机梯度压缩和适应性之间的相互作用，以便更好地理解这些现代理论设置下的算法动态。

Method: 使用随机微分方程近似技术分析分布式SGD、压缩分布式SGD和分布式SignSGD的动态。

Result: 适应性方法如分布式SignSGD能够在标准学习率调度假设下成功收敛，而分布式压缩SGD则需要考虑渐进学习率与梯度范数的反向依赖。

Conclusion: 我们研究了各种分布式优化算法的动态行为，发现分布式SignSGD能够有效收敛，而分布式SGD需要考虑适应性才能收敛。

Abstract: Using stochastic differential equation (SDE) approximations, we study the
dynamics of Distributed SGD, Distributed Compressed SGD, and Distributed
SignSGD under $(L_0,L_1)$-smoothness and flexible noise assumptions. Our
analysis provides insights -- which we validate through simulation -- into the
intricate interactions between batch noise, stochastic gradient compression,
and adaptivity in this modern theoretical setup. For instance, we show that
\textit{adaptive} methods such as Distributed SignSGD can successfully converge
under standard assumptions on the learning rate scheduler, even under
heavy-tailed noise. On the contrary, Distributed (Compressed) SGD with
pre-scheduled decaying learning rate fails to achieve convergence, unless such
a schedule also accounts for an inverse dependency on the gradient norm -- de
facto falling back into an adaptive method.

</details>


### [130] [Quantitative Error Feedback for Quantization Noise Reduction of Filtering over Graphs](https://arxiv.org/abs/2506.01404)
*Xue Xian Zheng,Weihang Liu,Xin Lou,Stefan Vlaski,Tareq Al-Naffouri*

Main category: cs.LG

TL;DR: 本文提出了一种创新的误差反馈框架，旨在减少分布式图滤波中的量化噪声。通过定量反馈实现精确补偿，并在多个场景中验证了其有效性，数值实验显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式图滤波中由于通信约束为量化消息而引入的量化噪声问题，本文提出了一个创新的误差反馈框架，旨在大幅减少量化噪声的影响。

Method: 引入了一种创新的误差反馈框架，通过定量反馈量化噪声进行精确补偿，并进行严格的理论分析。我们还提供了最佳误差反馈系数的闭式解，并在数值实验中验证了该框架的有效性。

Result: 理论分析表明，该框架显著减少了量化噪声的影响。此外，数值实验显示，与传统量化策略相比，该方法在准确性和鲁棒性方面表现更优。

Conclusion: 定量的误差反馈机制可以无缝整合到通信高效的去中心化优化框架中，有效降低误差水平。数值实验验证了理论结果，显示出方法在精度和鲁棒性上优于传统量化策略。

Abstract: This paper introduces an innovative error feedback framework designed to
mitigate quantization noise in distributed graph filtering, where
communications are constrained to quantized messages. It comes from error
spectrum shaping techniques from state-space digital filters, and therefore
establishes connections between quantized filtering processes over different
domains. In contrast to existing error compensation methods, our framework
quantitatively feeds back the quantization noise for exact compensation. We
examine the framework under three key scenarios: (i) deterministic graph
filtering, (ii) graph filtering over random graphs, and (iii) graph filtering
with random node-asynchronous updates. Rigorous theoretical analysis
demonstrates that the proposed framework significantly reduces the effect of
quantization noise, and we provide closed-form solutions for the optimal error
feedback coefficients. Moreover, this quantitative error feedback mechanism can
be seamlessly integrated into communication-efficient decentralized
optimization frameworks, enabling lower error floors. Numerical experiments
validate the theoretical results, consistently showing that our method
outperforms conventional quantization strategies in terms of both accuracy and
robustness.

</details>


### [131] [Cluster-Aware Causal Mixer for Online Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2506.00188)
*Md Mahmuddun Nabi Murad,Yasin Yilmaz*

Main category: cs.LG

TL;DR: 提出了一种集群感知因果混合模型，用于实时检测多变量时间序列中的异常，能有效减少误报并获得更高的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有的MLP-based混合模型缺乏保留时间依赖的因果机制，且一种嵌入机制难以有效捕获多通道间复杂关系。

Method: 提出了一种集群感知的因果混合模型，通过基于相关性将通道分组为集群，每个集群经过专用嵌入层处理，并引入因果混合器来维持因果性。

Result: 在六个公开基准数据集上的实验评估表明，该模型能始终获得更高的F1评分。

Conclusion: 结合因果机制和集群感知嵌入可以有效提升时间序列异常检测的准确性。

Abstract: Early and accurate detection of anomalies in time series data is critical,
given the significant risks associated with false or missed detections. While
MLP-based mixer models have shown promise in time series analysis, they lack a
causality mechanism to preserve temporal dependencies inherent in the system.
Moreover, real-world multivariate time series often contain numerous channels
with diverse inter-channel correlations. A single embedding mechanism for all
channels does not effectively capture these complex relationships. To address
these challenges, we propose a novel cluster-aware causal mixer to effectively
detect anomalies in multivariate time series. Our model groups channels into
clusters based on their correlations, with each cluster processed through a
dedicated embedding layer. In addition, we introduce a causal mixer in our
model, which mixes the information while maintaining causality. Furthermore, we
present an anomaly detection framework that accumulates the anomaly evidence
over time to prevent false positives due to nominal outliers. Our proposed
model operates in an online fashion, making it suitable for real-time
time-series anomaly detection tasks. Experimental evaluations across six public
benchmark datasets demonstrate that our model consistently achieves superior F1
scores.

</details>


### [132] [MOFGPT: Generative Design of Metal-Organic Frameworks using Language Models](https://arxiv.org/abs/2506.00198)
*Srivathsan Badrinarayanan,Rishikesh Magar,Akshay Antony,Radheesh Sharma Meda,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 提出了一种结合强化学习和变压器的框架来设计MOFs，利用MOFid进行可扩展的生成建模，实践表明这种方式能加速逆向设计并推动MOF在计算材料发现中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于MOFs结构设计空间的巨大规模和复杂性，找到具有特定应用属性的MOFs一直是材料化学中的核心挑战。传统的计算筛选技术如分子模拟和密度泛函理论（DFT）虽然准确，但在规模上无法计算。机器学习提供了一种振奋人心的替代方案，通过利用数据驱动的方法加速材料发现。

Method: 我们提出了一种增强型强化学习的变压器框架，用于MOFs的全新设计。核心方法是MOFid，一种化学信息化的字符串表示，编码了连接性和拓扑结构，支持可扩展的生成建模。Pipeline包括三个组件：（1）在MOFid序列上训练的生成性GPT模型，（2）MOFormer，基于变压器的性质预测器，（3）一个通过性质引导的奖励函数优化生成候选物的强化学习模块。

Result: 通过将性质反馈整合到序列生成中，我们的方法推动模型朝向合成可行且拓扑结构有效的MOFs，且具有所需的功能属性。

Conclusion: 我们通过整合性质反馈到序列生成中，使模型能够生成具有所需功能属性的合成可行且拓扑结构有效的MOFs。这项工作展示了将大型语言模型与强化学习相结合的潜力，能够加速网状化学中的逆向设计，并在计算MOF发现中开启新的前沿。

Abstract: The discovery of Metal-Organic Frameworks (MOFs) with application-specific
properties remains a central challenge in materials chemistry, owing to the
immense size and complexity of their structural design space. Conventional
computational screening techniques such as molecular simulations and density
functional theory (DFT), while accurate, are computationally prohibitive at
scale. Machine learning offers an exciting alternative by leveraging
data-driven approaches to accelerate materials discovery. The complexity of
MOFs, with their extended periodic structures and diverse topologies, creates
both opportunities and challenges for generative modeling approaches. To
address these challenges, we present a reinforcement learning-enhanced,
transformer-based framework for the de novo design of MOFs. Central to our
approach is MOFid, a chemically-informed string representation encoding both
connectivity and topology, enabling scalable generative modeling. Our pipeline
comprises three components: (1) a generative GPT model trained on MOFid
sequences, (2) MOFormer, a transformer-based property predictor, and (3) a
reinforcement learning (RL) module that optimizes generated candidates via
property-guided reward functions. By integrating property feedback into
sequence generation, our method drives the model toward synthesizable,
topologically valid MOFs with desired functional attributes. This work
demonstrates the potential of large language models, when coupled with
reinforcement learning, to accelerate inverse design in reticular chemistry and
unlock new frontiers in computational MOF discovery.

</details>


### [133] [Unlocking the Power of Rehearsal in Continual Learning: A Theoretical Perspective](https://arxiv.org/abs/2506.00205)
*Junze Deng,Qinhang Wu,Peizhong Ju,Sen Lin,Yingbin Liang,Ness Shroff*

Main category: cs.LG

TL;DR: The study analyzes rehearsal strategies in continual learning, proposing a hybrid method that combines concurrent and sequential approaches for better performance and less forgetting, particularly with dissimilar tasks.


<details>
  <summary>Details</summary>
Motivation: To explore whether sequential revisiting of tasks, akin to human learning patterns, can improve continual learning performance by mitigating catastrophic forgetting more effectively than concurrent rehearsal methods.

Method: Conducted a theoretical analysis of rehearsal strategies in overparameterized linear models and introduced a Hybrid Rehearsal method that combines concurrent and sequential training approaches based on task similarity, validated through experiments with deep neural networks.

Result: Characterized the forgetting and generalization error of different rehearsal strategies and demonstrated through experiments that the hybrid rehearsal method outperforms standard concurrent rehearsal, especially with dissimilar tasks.

Conclusion: Sequential rehearsal performs better in rehearsal-based continual learning when tasks are less similar, and a hybrid method that combines concurrent and sequential strategies outperforms standard methods.

Abstract: Rehearsal-based methods have shown superior performance in addressing
catastrophic forgetting in continual learning (CL) by storing and training on a
subset of past data alongside new data in current task. While such a concurrent
rehearsal strategy is widely used, it remains unclear if this approach is
always optimal. Inspired by human learning, where sequentially revisiting tasks
helps mitigate forgetting, we explore whether sequential rehearsal can offer
greater benefits for CL compared to standard concurrent rehearsal. To address
this question, we conduct a theoretical analysis of rehearsal-based CL in
overparameterized linear models, comparing two strategies: 1) Concurrent
Rehearsal, where past and new data are trained together, and 2) Sequential
Rehearsal, where new data is trained first, followed by revisiting past data
sequentially. By explicitly characterizing forgetting and generalization error,
we show that sequential rehearsal performs better when tasks are less similar.
These insights further motivate a novel Hybrid Rehearsal method, which trains
similar tasks concurrently and revisits dissimilar tasks sequentially. We
characterize its forgetting and generalization performance, and our experiments
with deep neural networks further confirm that the hybrid approach outperforms
standard concurrent rehearsal. This work provides the first comprehensive
theoretical analysis of rehearsal-based CL.

</details>


### [134] [Intercept Cancer: Cancer Pre-Screening with Large Scale Healthcare Foundation Models](https://arxiv.org/abs/2506.00209)
*Liwen Sun,Hao-Ren Yao,Gary Gao,Ophir Frieder,Chenyan Xiong*

Main category: cs.LG

TL;DR: CATCH-FM is a new method for early cancer detection using EHR data, showing high efficacy and outperforming existing models. It's cost-effective, non-intrusive, and globally applicable, significantly improving early cancer risk prediction accuracy.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a cost-effective, non-intrusive, and globally accessible cancer pre-screening tool due to the limitations of current screening methods that rely on expensive and invasive procedures, hence losing many lives that could have been saved with early detection.

Method: CATCH-FM utilizes a cancer pre-screening methodology based on analyzing historical medical records of patients using large-scale electronic healthcare records (EHRs). It involves pretraining foundation models on medical code sequences and finetuning them on cancer risk prediction cohorts. The models boast up to 2.4 billion parameters and leverage pretrained compute-optimal foundation models to achieve predictions.

Result: CATCH-FM achieved a 60% sensitivity rate and a 99% specificity rate in predicting cancer risks, outperforming existing feature-based tree models and large language models significantly. It provided state-of-the-art pancreatic cancer risk predictions and demonstrated robustness across demographic and healthcare variations.

Conclusion: CATCH-FM demonstrates robust performance in predicting cancer risks using EHR data, achieving state-of-the-art results in pre-screening high-risk patients for further cancer screening processes with significant efficacy and specificity. The methodology can lead to significant life-saving potential by addressing limitations of current cancer screening methods.

Abstract: Cancer screening, leading to early detection, saves lives. Unfortunately,
existing screening techniques require expensive and intrusive medical
procedures, not globally available, resulting in too many lost would-be-saved
lives. We present CATCH-FM, CATch Cancer early with Healthcare Foundation
Models, a cancer pre-screening methodology that identifies high-risk patients
for further screening solely based on their historical medical records. With
millions of electronic healthcare records (EHR), we establish the scaling law
of EHR foundation models pretrained on medical code sequences, pretrain
compute-optimal foundation models of up to 2.4 billion parameters, and finetune
them on clinician-curated cancer risk prediction cohorts. In our retrospective
evaluation comprising of thirty thousand patients, CATCH-FM achieved strong
efficacy (60% sensitivity) with low risk (99% specificity and Negative
Predictive Value), outperforming feature-based tree models as well as general
and medical large language models by large margins. Despite significant
demographic, healthcare system, and EHR coding differences, CATCH-FM achieves
state-of-the-art pancreatic cancer risk prediction on the EHRSHOT few-shot
leaderboard, outperforming EHR foundation models pretrained using on-site
patient data. Our analysis demonstrates the robustness of CATCH-FM in various
patient distributions, the benefits of operating in the ICD code space, and its
ability to capture non-trivial cancer risk factors. Our code will be
open-sourced.

</details>


### [135] [Localized LoRA: A Structured Low-Rank Approximation for Efficient Fine-Tuning](https://arxiv.org/abs/2506.00236)
*Babak Barazandeh*

Main category: cs.LG

TL;DR: Localized LoRA通过在参数空间实现局部化更新，提高了微调的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法大多依赖于全局低秩结构，容易忽视参数空间中分散的空间模式。

Method: 提出了Localized LoRA框架，该框架将权重更新建模为应用于权重矩阵结构性块的一系列低秩矩阵之组合，实现更密集且局部化的更新。

Result: 通过合成和实际场景实验，Localized LoRA 在不增加参数量的情况下，相比现有方法，表现出更强的表达能力和适应性。

Conclusion: Localized LoRA 提供了一种更加适应性强的替代方案，通过在不增加可训练参数总数的情况下，实现全参数空间的局部化更新。实验证明，其在匹配的参数预算下取得了更低的近似误差，提升了微调效率和性能。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, offer compact
and effective alternatives to full model fine-tuning by introducing low-rank
updates to pretrained weights. However, most existing approaches rely on global
low-rank structures, which can overlook spatial patterns spread across the
parameter space. In this work, we propose Localized LoRA, a generalized
framework that models weight updates as a composition of low-rank matrices
applied to structured blocks of the weight matrix. This formulation enables
dense, localized updates throughout the parameter space-without increasing the
total number of trainable parameters. We provide a formal comparison between
global, diagonal-local, and fully localized low-rank approximations, and show
that our method consistently achieves lower approximation error under matched
parameter budgets. Experiments on both synthetic and practical settings
demonstrate that Localized LoRA offers a more expressive and adaptable
alternative to existing methods, enabling efficient fine-tuning with improved
performance.

</details>


### [136] [DeGLIF for Label Noise Robust Node Classification using GNNs](https://arxiv.org/abs/2506.00244)
*Pintu Kumar,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 提出DeGLIF，利用留一法影响函数提高图数据预测精度，实现高效去噪。


<details>
  <summary>Details</summary>
Motivation: 由于噪声标记数据集相比干净数据集更便宜，图数据也符合这个特点，因此需要一种高效的去噪方法来提高图数据的预测准确性。

Method: 提出了一种去噪技术DeGLIF，利用较少的干净数据和留一法影响函数来进行标签噪声鲁棒的节点级别预测。

Result: DeGLIF在多个数据集上的实验显示该技术比其他基线算法具有更高的准确性。

Conclusion: DeGLIF在去噪图数据方面表现优越，不依赖于噪声模型的信息或估计。

Abstract: Noisy labelled datasets are generally inexpensive compared to clean labelled
datasets, and the same is true for graph data. In this paper, we propose a
denoising technique DeGLIF: Denoising Graph Data using Leave-One-Out Influence
Function. DeGLIF uses a small set of clean data and the leave-one-out influence
function to make label noise robust node-level prediction on graph data.
Leave-one-out influence function approximates the change in the model
parameters if a training point is removed from the training dataset. Recent
advances propose a way to calculate the leave-one-out influence function for
Graph Neural Networks (GNNs). We extend that recent work to estimate the change
in validation loss, if a training node is removed from the training dataset. We
use this estimate and a new theoretically motivated relabelling function to
denoise the training dataset. We propose two DeGLIF variants to identify noisy
nodes. Both these variants do not require any information about the noise model
or the noise level in the dataset; DeGLIF also does not estimate these
quantities. For one of these variants, we prove that the noisy points detected
can indeed increase risk. We carry out detailed computational experiments on
different datasets to show the effectiveness of DeGLIF. It achieves better
accuracy than other baseline algorithms

</details>


### [137] [Beyond Semantic Entropy: Boosting LLM Uncertainty Quantification with Pairwise Semantic Similarity](https://arxiv.org/abs/2506.00245)
*Dang Nguyen,Ali Payani,Baharan Mirzasoleiman*

Main category: cs.LG

TL;DR: 提出了一种改进的熵估计方法，能更好地检测大语言模型生成长句时的不确定性，并在多个模型和任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的语义熵方法在处理现代大模型生成的长句时效果不佳，因为它忽略了簇内相似性和簇间相似性。

Method: 提出了一种基于最近邻熵估计思想的不确定性量化方法，能够在黑盒设置下使用，并且可以通过结合词概率轻松扩展到白盒设置中。

Result: 提出的方法在两个最新的大语言模型Phi3和Llama3以及三个常见文本生成任务（问答、文本摘要、机器翻译）上进行了验证，效果优于语义熵。

Conclusion: 提出的方法比传统语义熵更有效，可以更好地处理长句生成时的语义不确定性问题。

Abstract: Hallucination in large language models (LLMs) can be detected by assessing
the uncertainty of model outputs, typically measured using entropy. Semantic
entropy (SE) enhances traditional entropy estimation by quantifying uncertainty
at the semantic cluster level. However, as modern LLMs generate longer
one-sentence responses, SE becomes less effective because it overlooks two
crucial factors: intra-cluster similarity (the spread within a cluster) and
inter-cluster similarity (the distance between clusters). To address these
limitations, we propose a simple black-box uncertainty quantification method
inspired by nearest neighbor estimates of entropy. Our approach can also be
easily extended to white-box settings by incorporating token probabilities.
Additionally, we provide theoretical results showing that our method
generalizes semantic entropy. Extensive empirical results demonstrate its
effectiveness compared to semantic entropy across two recent LLMs (Phi3 and
Llama3) and three common text generation tasks: question answering, text
summarization, and machine translation. Our code is available at
https://github.com/BigML-CS-UCLA/SNNE.

</details>


### [138] [Performance Analysis of Convolutional Neural Network By Applying Unconstrained Binary Quadratic Programming](https://arxiv.org/abs/2506.00247)
*Aasish Kumar Sharma,Sanjeeb Prashad Pandey,Julian M. Kunkel*

Main category: cs.LG

TL;DR: 提出了一种结合量子计算和传统优化技术的方法，可提高CNN训练的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络在计算机视觉和大数据分析中的重要性以及其对计算资源的高需求是研究的动机。量子计算可以更高效地搜索复杂优化空间，提供了一种训练CNN的新方法。

Method: 提出了一种混合优化方法，将无约束二次规划（UBQP）与随机梯度下降（SGD）结合来加速卷积神经网络的训练。

Result: 在MNIST数据集上的评估显示，与标准反向传播CNN基线相比，所提出的方法准确率提高10-15%，执行时间相似。

Conclusion: 混合量子-经典技术在高性能计算环境下具有很大潜力，可以提高大数据和深度学习的模型性能。

Abstract: Convolutional Neural Networks (CNNs) are pivotal in computer vision and Big
Data analytics but demand significant computational resources when trained on
large-scale datasets. Conventional training via back-propagation (BP) with
losses like Mean Squared Error or Cross-Entropy often requires extensive
iterations and may converge sub-optimally. Quantum computing offers a promising
alternative by leveraging superposition, tunneling, and entanglement to search
complex optimization landscapes more efficiently. In this work, we propose a
hybrid optimization method that combines an Unconstrained Binary Quadratic
Programming (UBQP) formulation with Stochastic Gradient Descent (SGD) to
accelerate CNN training. Evaluated on the MNIST dataset, our approach achieves
a 10--15\% accuracy improvement over a standard BP-CNN baseline while
maintaining similar execution times. These results illustrate the potential of
hybrid quantum-classical techniques in High-Performance Computing (HPC)
environments for Big Data and Deep Learning. Fully realizing these benefits,
however, requires a careful alignment of algorithmic structures with underlying
quantum mechanisms.

</details>


### [139] [PerFormer: A Permutation Based Vision Transformer for Remaining Useful Life Prediction](https://arxiv.org/abs/2506.00259)
*Zhengyang Fan,Wanru Li,Kuo-chu Chang,Ting Yuan*

Main category: cs.LG

TL;DR: The paper introduces PerFormer, a vision transformer approach, enhancing RUL prediction accuracy by mimicking spatial characteristics of time series data, outperforming existing models.


<details>
  <summary>Details</summary>
Motivation: Explore the potential of Vision Transformer (ViT) in improving RUL prediction accuracy due to its demonstrated superiority over CNNs in computer vision.

Method: Introduce PerFormer, a permutation-based vision transformer that creates a permutation matrix mimicking spatial characteristics for ViT.

Result: PerFormer demonstrates superior RUL prediction performance on NASA's C-MAPSS dataset, surpassing state-of-the-art methods.

Conclusion: PerFormer shows superior performance in RUL prediction compared to CNNs, RNNs, and various Transformer models.

Abstract: Accurately estimating the remaining useful life (RUL) for degradation systems
is crucial in modern prognostic and health management (PHM). Convolutional
Neural Networks (CNNs), initially developed for tasks like image and video
recognition, have proven highly effectively in RUL prediction, demonstrating
remarkable performance. However, with the emergence of the Vision Transformer
(ViT), a Transformer model tailored for computer vision tasks such as image
classification, and its demonstrated superiority over CNNs, there is a natural
inclination to explore its potential in enhancing RUL prediction accuracy.
Nonetheless, applying ViT directly to multivariate sensor data for RUL
prediction poses challenges, primarily due to the ambiguous nature of spatial
information in time series data. To address this issue, we introduce the
PerFormer, a permutation-based vision transformer approach designed to permute
multivariate time series data, mimicking spatial characteristics akin to image
data, thereby making it suitable for ViT. To generate the desired permutation
matrix, we introduce a novel permutation loss function aimed at guiding the
convergence of any matrix towards a permutation matrix. Our experiments on
NASA's C-MAPSS dataset demonstrate the PerFormer's superior performance in RUL
prediction compared to state-of-the-art methods employing CNNs, Recurrent
Neural Networks (RNNs), and various Transformer models. This underscores its
effectiveness and potential in PHM applications.

</details>


### [140] [Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model](https://arxiv.org/abs/2506.00286)
*Oliver Mortensen,Mohammad Sadegh Talebi*

Main category: cs.LG

TL;DR: 论文分析了在具有风险偏好的马尔可夫决策过程中学习的样本复杂度，提出了MB-RS-QVI方法并提供PAC界限，且证明其界限的紧致性。


<details>
  <summary>Details</summary>
Motivation: 研究在具有递归熵风险偏好的折扣马尔可夫决策过程中，学习最优状态-动作值函数和最优策略的样本复杂度。

Method: 提出了一种简单的基于模型的方法，即基于模型的风险敏感Q值迭代（MB-RS-QVI），用于分析和提供PAC界限。

Result: 提供了$(\epsilon,\delta)$-PAC界限，并证明了指数依赖性无法避免，这表明这些界限是紧的。

Conclusion: 研究表明，在具有递归熵风险偏好的折扣马尔可夫决策过程（MDP）中，学习最优状态-动作值函数和最优策略的样本复杂度具有指数依赖性，而这种依赖性与学习者的风险敏感度和有效视野相关，并且不可避免。

Abstract: In this paper we analyze the sample complexities of learning the optimal
state-action value function $Q^*$ and an optimal policy $\pi^*$ in a discounted
Markov decision process (MDP) where the agent has recursive entropic
risk-preferences with risk-parameter $\beta\neq 0$ and where a generative model
of the MDP is available. We provide and analyze a simple model based approach
which we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which
leads to $(\epsilon,\delta)$-PAC-bounds on $\|Q^*-Q^k\|$, and
$\|V^*-V^{\pi_k}\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations
and $\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have
exponential dependence on the effective horizon $\frac{1}{1-\gamma}$ and the
strength of this dependence grows with the learners risk-sensitivity $|\beta|$.
We also provide two lower bounds which shows that exponential dependence on
$|\beta|\frac{1}{1-\gamma}$ is unavoidable in both cases. The lower bounds
reveal that the PAC-bounds are both tight in $\varepsilon$ and $\delta$ and
that the PAC-bound on $Q$-learning is tight in the number of actions $A$, and
that the PAC-bound on policy-learning is nearly tight in $A$.

</details>


### [141] [Improving Protein Sequence Design through Designability Preference Optimization](https://arxiv.org/abs/2506.00297)
*Fanglei Xue,Andrew Kubaney,Zhichun Guo,Joseph K. Min,Ge Liu,Yi Yang,David Baker*

Main category: cs.LG

TL;DR: 研究通过新的优化方法显著提高了蛋白质设计的成功率，特别是在酶设计上成功率提升三倍。


<details>
  <summary>Details</summary>
Motivation: 目前的蛋白质序列设计方法在序列生成中虽然表现良好，但由于其训练目标主要是序列恢复，并不能保证设计蛋白质能够准确折叠成期望的结构。因此，需要改进训练目标以提高设计能力。

Method: 本文通过引入直接偏好优化（DPO），利用AlphaFold的pLDDT分数作为偏好信号，并结合Residue-level Designability Preference Optimization (ResiDPO)以细化序列生成。

Result: 通过使用ResiDPO进行微调，研究获得了一种称为EnhancedMPNN的模型，在一个具有挑战性的酶设计基准上，其成功率几乎提高了三倍（从6.56%到17.57%）。

Conclusion: 通过引入ResiDPO优化和调优LigandMPNN至EnhancedMPNN，研究显著提高了酶设计领域蛋白质序列设计的成功率。

Abstract: Protein sequence design methods have demonstrated strong performance in
sequence generation for de novo protein design. However, as the training
objective was sequence recovery, it does not guarantee designability--the
likelihood that a designed sequence folds into the desired structure. To bridge
this gap, we redefine the training objective by steering sequence generation
toward high designability. To do this, we integrate Direct Preference
Optimization (DPO), using AlphaFold pLDDT scores as the preference signal,
which significantly improves the in silico design success rate. To further
refine sequence generation at a finer, residue-level granularity, we introduce
Residue-level Designability Preference Optimization (ResiDPO), which applies
residue-level structural rewards and decouples optimization across residues.
This enables direct improvement in designability while preserving regions that
already perform well. Using a curated dataset with residue-level annotations,
we fine-tune LigandMPNN with ResiDPO to obtain EnhancedMPNN, which achieves a
nearly 3-fold increase in in silico design success rate (from 6.56% to 17.57%)
on a challenging enzyme design benchmark.

</details>


### [142] [Inference-Time Alignment of Diffusion Models with Evolutionary Algorithms](https://arxiv.org/abs/2506.00299)
*Purvish Jajal,Nick John Eliopoulos,Benjamin Shiue-Hal Chou,George K. Thiruvathukal,James C. Davis,Yung-Hsiang Lu*

Main category: cs.LG

TL;DR: 利用基于进化算法的方法实现扩散模型的高效推断时间对齐，比现有方法更快、更省内存、更有效。


<details>
  <summary>Details</summary>
Motivation: 由于现有扩散模型生成的样本往往难以满足下游目标如安全约束或特定领域要求，因此我们需要一种在推断过程中进行对齐的高效方法。

Method: 我们基于进化算法提出了一种推断时的对齐框架，将扩散模型视为黑箱进行处理，搜索其潜在空间以最大化对齐目标。

Result: 在DrawBench和Open Image Preferences基准上，我们的方法不仅在内存消耗上比基于梯度的方法减少了55%到76%的GPU内存使用，还在运行时间上比基于梯度的方法快72%到80%，同时在对齐评分上超过了基于梯度和非梯度的方法。

Conclusion: 我们提出的新方法在不同的生成扩散模型中成功实现了推断时间的高效对齐，与现有的基于梯度和无梯度的推断时间方法相比表现更优。

Abstract: Diffusion models are state-of-the-art generative models in various domains,
yet their samples often fail to satisfy downstream objectives such as safety
constraints or domain-specific validity. Existing techniques for alignment
require gradients, internal model access, or large computational budgets. We
introduce an inference-time alignment framework based on evolutionary
algorithms. We treat diffusion models as black-boxes and search their latent
space to maximize alignment objectives. Our method enables efficient
inference-time alignment for both differentiable and non-differentiable
alignment objectives across a range of diffusion models. On the DrawBench and
Open Image Preferences benchmark, our EA methods outperform state-of-the-art
gradient-based and gradient-free inference-time methods. In terms of memory
consumption, we require 55% to 76% lower GPU memory than gradient-based
methods. In terms of running-time, we are 72% to 80% faster than gradient-based
methods. We achieve higher alignment scores over 50 optimization steps on Open
Image Preferences than gradient-based and gradient-free methods.

</details>


### [143] [Beyond Atomic Geometry Representations in Materials Science: A Human-in-the-Loop Multimodal Framework](https://arxiv.org/abs/2506.00302)
*Can Polat,Hasan Kurban,Erchin Serpedin,Mustafa Kurban*

Main category: cs.LG

TL;DR: MCS-Set expands materials datasets by combining atomic structures with 2D images and annotations, enabling advanced multimodal machine learning tasks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations of traditional materials science datasets that only include atomic geometries and hinder the use of advanced machine learning techniques.

Method: The method involves creating the MCS-Set framework that integrates atomic structures with 2D projections and structured textual annotations. It utilizes a human-in-the-loop pipeline to combine domain expertise with standardized descriptors for annotation.

Result: Evaluations show significant performance gaps specific to modality, and underscore the importance of annotation quality for generalization in model performance.

Conclusion: MCS-Set provides a foundation for benchmarking multimodal models, advancing annotation practices, and promoting more accessible and versatile datasets in materials science.

Abstract: Most materials science datasets are limited to atomic geometries (e.g., XYZ
files), restricting their utility for multimodal learning and comprehensive
data-centric analysis. These constraints have historically impeded the adoption
of advanced machine learning techniques in the field. This work introduces
MultiCrystalSpectrumSet (MCS-Set), a curated framework that expands materials
datasets by integrating atomic structures with 2D projections and structured
textual annotations, including lattice parameters and coordination metrics.
MCS-Set enables two key tasks: (1) multimodal property and summary prediction,
and (2) constrained crystal generation with partial cluster supervision.
Leveraging a human-in-the-loop pipeline, MCS-Set combines domain expertise with
standardized descriptors for high-quality annotation. Evaluations using
state-of-the-art language and vision-language models reveal substantial
modality-specific performance gaps and highlight the importance of annotation
quality for generalization. MCS-Set offers a foundation for benchmarking
multimodal models, advancing annotation practices, and promoting accessible,
versatile materials science datasets. The dataset and implementations are
available at https://github.com/KurbanIntelligenceLab/MultiCrystalSpectrumSet.

</details>


### [144] [Active Learning via Regression Beyond Realizability](https://arxiv.org/abs/2506.00316)
*Atul Ganju,Shashaank Aiyer,Ved Sriraman,Karthik Sridharan*

Main category: cs.LG

TL;DR: 我们开发了一种新的基于代理风险最小化的主动学习算法，能够在比可实现性假设更宽松的条件下有效工作，提供了与现有方法类似的样本和标签复杂度。


<details>
  <summary>Details</summary>
Motivation: 许多现有的基于代理的主动学习算法依赖于可实现性假设，这限制了它们在实际的错用设置中的适用性。我们的动机是突破这一限制，使算法在更广泛的条件下有效。

Method: 我们的算法使用一个基于历元的主动学习方法，在每个历元中从完整的模型类中拟合数据，并通过聚合这些模型返回一个不当分类器。

Result: 我们证明了在非可实现设置下，如果满足我们假设的条件，算法的标签和样本复杂度可以与之前的工作相媲美，而之前的方法在这些条件下会失败。

Conclusion: 我们提出了一种新的多类分类主动学习框架，它可以在比标准可实现性假设更广泛的条件下运行。尽管现有的基于代理风险最小化的主动学习算法依赖于可实现性，但我们展示了在弱于可实现性的条件下，如果考虑的模型类是凸的，仍然可以获得与之前工作相当的标签和样本复杂度。

Abstract: We present a new active learning framework for multiclass classification
based on surrogate risk minimization that operates beyond the standard
realizability assumption. Existing surrogate-based active learning algorithms
crucially rely on realizability$\unicode{x2014}$the assumption that the optimal
surrogate predictor lies within the model class$\unicode{x2014}$limiting their
applicability in practical, misspecified settings. In this work we show that
under conditions significantly weaker than realizability, as long as the class
of models considered is convex, one can still obtain a label and sample
complexity comparable to prior work. Despite achieving similar rates, the
algorithmic approaches from prior works can be shown to fail in non-realizable
settings where our assumption is satisfied. Our epoch-based active learning
algorithm departs from prior methods by fitting a model from the full class to
the queried data in each epoch and returning an improper classifier obtained by
aggregating these models.

</details>


### [145] [Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation](https://arxiv.org/abs/2506.00329)
*Muhammad Adnan,Nithesh Kurella,Akhil Arunkumar,Prashant J. Nair*

Main category: cs.LG

TL;DR: Foresight通过动态层重用技术，有效减少了视频生成中的计算冗余，实现了显著的速度提升且不影响质量。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformers在视频生成中由于模型规模大和时空注意力的平方代价所导致的计算开销问题。

Method: 提出了一种名为Foresight的自适应层重用技术，通过动态识别并重用跨步的DiT块输出，以减少去噪步骤中的计算冗余。

Result: Foresight在优化效率的同时保持了原有的基准性能，当应用于OpenSora、Latte和CogVideoX等模型时，达到了显著的加速效果。

Conclusion: Foresight在不影响视频生成质量的情况下，实现了高达1.63倍的端到端加速。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art results in
text-to-image, text-to-video generation, and editing. However, their large
model size and the quadratic cost of spatial-temporal attention over multiple
denoising steps make video generation computationally expensive. Static caching
mitigates this by reusing features across fixed steps but fails to adapt to
generation dynamics, leading to suboptimal trade-offs between speed and
quality.
  We propose Foresight, an adaptive layer-reuse technique that reduces
computational redundancy across denoising steps while preserving baseline
performance. Foresight dynamically identifies and reuses DiT block outputs for
all layers across steps, adapting to generation parameters such as resolution
and denoising schedules to optimize efficiency. Applied to OpenSora, Latte, and
CogVideoX, Foresight achieves up to 1.63x end-to-end speedup, while maintaining
video quality. The source code of Foresight is available at
\texttt{https://github.com/STAR-Laboratory/foresight}.

</details>


### [146] [Channel-Imposed Fusion: A Simple yet Effective Method for Medical Time Series Classification](https://arxiv.org/abs/2506.00337)
*Ming Hu,Jianfu Yin,Mingyu Dou,Yuqi Wang,Ruochen Dang,Siyi Liang,Cong Hu,Yao Wang,Bingliang Hu,Quan Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种新的分类方法，通过跨通道信息融合和时间卷积网络（TCN），有效提高了医学时间序列分类的透明性和准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然基于Transformer的模型通过自注意机制在隐式建模时间相关性方面取得了显著的性能，但其复杂的架构和不透明的推理过程削弱了其在高风险临床环境中的可信度。因此，本研究转向一种强调结构透明度的建模范式，更加符合医学数据的内在特性。

Method: 本文提出了一种新方法，称为“通道强加融合”（CIF），通过跨通道信息融合增强信噪比，有效减少冗余并提高分类性能。进一步地，将CIF与具有结构简单性和可控感受野的时间卷积网络（TCN）集成，构建了一个高效而明确的分类框架。

Result: 在多个公开的EEG和ECG数据集上的实验结果表明，所提出的方法不仅在各种分类指标上优于现有的最新方法，还显著增强了分类过程的透明性，为医学时间序列分类提供了新的视角。

Conclusion: 提出的方法在多个公共EEG和ECG数据集上的实验结果表明，该方法不仅在多种分类指标上优于现有的最新方法，还显著提高了分类过程的透明度。

Abstract: The automatic classification of medical time series signals, such as
electroencephalogram (EEG) and electrocardiogram (ECG), plays a pivotal role in
clinical decision support and early detection of diseases. Although Transformer
based models have achieved notable performance by implicitly modeling temporal
dependencies through self-attention mechanisms, their inherently complex
architectures and opaque reasoning processes undermine their trustworthiness in
high stakes clinical settings. In response to these limitations, this study
shifts focus toward a modeling paradigm that emphasizes structural
transparency, aligning more closely with the intrinsic characteristics of
medical data. We propose a novel method, Channel Imposed Fusion (CIF), which
enhances the signal-to-noise ratio through cross-channel information fusion,
effectively reduces redundancy, and improves classification performance.
Furthermore, we integrate CIF with the Temporal Convolutional Network (TCN),
known for its structural simplicity and controllable receptive field, to
construct an efficient and explicit classification framework. Experimental
results on multiple publicly available EEG and ECG datasets demonstrate that
the proposed method not only outperforms existing state-of-the-art (SOTA)
approaches in terms of various classification metrics, but also significantly
enhances the transparency of the classification process, offering a novel
perspective for medical time series classification.

</details>


### [147] [Exploring the Performance of Perforated Backpropagation through Further Experiments](https://arxiv.org/abs/2506.00356)
*Rorry Brenner,Evan Davis,Rushi Chaudhari,Rowan Morse,Jingyao Chen,Xirui Liu,Zhaoyi You,Laurent Itti*

Main category: cs.LG

TL;DR: Perforated Backpropagation, inspired by biological neurons, can compress models by 90% without losing accuracy and improve accuracy by up to 16%.


<details>
  <summary>Details</summary>
Motivation: To investigate the effectiveness of Perforated Backpropagation in optimizing neural networks based on biological neuron understanding.

Method: Exploration and experimentation with the Perforated Backpropagation algorithm on various datasets and models during a hackathon.

Result: The system achieved up to 90% model compression without loss of accuracy and up to 16% increased accuracy.

Conclusion: Perforated Backpropagation can enhance projects by offering significant model compression and accuracy improvements.

Abstract: Perforated Backpropagation is a neural network optimization technique based
on modern understanding of the computational importance of dendrites within
biological neurons. This paper explores further experiments from the original
publication, generated from a hackathon held at the Carnegie Mellon Swartz
Center in February 2025. Students and local Pittsburgh ML practitioners were
brought together to experiment with the Perforated Backpropagation algorithm on
the datasets and models which they were using for their projects. Results
showed that the system could enhance their projects, with up to 90% model
compression without negative impact on accuracy, or up to 16% increased
accuracy of their original models.

</details>


### [148] [FSNet: Feasibility-Seeking Neural Network for Constrained Optimization with Guarantees](https://arxiv.org/abs/2506.00362)
*Hoang T. Nguyen,Priya L. Donti*

Main category: cs.LG

TL;DR: FSNet通过集成可行性步骤，解决了机器学习方法的约束问题，以更快的速度提供可行解，质量媲美或优于传统求解器。


<details>
  <summary>Details</summary>
Motivation: 传统求解器在实时应用中往往在计算方面受到限制，而基于机器学习的方法虽然速度更快，但难以严格执行约束，导致解决方案在实践中不可行。因此，作者提出FSNet以确保约束满足。

Method: FSNet通过在其解决方案过程中直接集成一个寻求可行性步骤，解决无约束优化问题，以微分方式最小化约束违反，从而实现端到端训练，并提供关于可行性和收敛性的保证。

Result: FSNet在一系列不同的优化问题中进行了实验，包括光滑/非光滑和凸/非凸问题，证明其能提供与传统求解器相当（或更好）的解决方案，并且速度更快。

Conclusion: FSNet能够在比传统求解器显著更快的速度下提供具有可行性的解决方案，并且在解决方案质量方面可以与传统求解器媲美，甚至在某些情况下表现更好。

Abstract: Efficiently solving constrained optimization problems is crucial for numerous
real-world applications, yet traditional solvers are often computationally
prohibitive for real-time use. Machine learning-based approaches have emerged
as a promising alternative to provide approximate solutions at faster speeds,
but they struggle to strictly enforce constraints, leading to infeasible
solutions in practice. To address this, we propose the
Feasibility-Seeking-Integrated Neural Network (FSNet), which integrates a
feasibility-seeking step directly into its solution procedure to ensure
constraint satisfaction. This feasibility-seeking step solves an unconstrained
optimization problem that minimizes constraint violations in a differentiable
manner, enabling end-to-end training and providing guarantees on feasibility
and convergence. Our experiments across a range of different optimization
problems, including both smooth/nonsmooth and convex/nonconvex problems,
demonstrate that FSNet can provide feasible solutions with solution quality
comparable to (or in some cases better than) traditional solvers, at
significantly faster speeds.

</details>


### [149] [Spectral Insights into Data-Oblivious Critical Layers in Large Language Models](https://arxiv.org/abs/2506.00382)
*Xuyuan Liu,Lei Hsiung,Yaoqing Yang,Yujun Yan*

Main category: cs.LG

TL;DR: 研究通过CKA方法识别LLMs中的关键层，发现这些层在微调中受到显著影响，并在实际中可用于提高域适应效率和增强后门防御。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLMs）的可解释性和鲁棒性，明确了解不同层特征表示的演变过程及其对模型功能和行为的影响。

Method: 通过分析中心核对齐（CKA）的表示动态来识别未进行微调的大型语言模型(LLMs)中的内在关键层。

Result: 在微调关键层时，相较于非关键层造成的损失减小更大；在后门攻击防御中，冻结关键层可使攻击成功率降低至多40%。

Conclusion: 发现表示空间中发生显著变化的层在微调过程中受到的影响最大，这是在给定模型的任务中一致的现象。

Abstract: Understanding how feature representations evolve across layers in large
language models (LLMs) is key to improving their interpretability and
robustness. While recent studies have identified critical layers linked to
specific functions or behaviors, these efforts typically rely on data-dependent
analyses of fine-tuned models, limiting their use to post-hoc settings. In
contrast, we introduce a data-oblivious approach to identify intrinsic critical
layers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered
Kernel Alignment(CKA). We show that layers with significant shifts in
representation space are also those most affected during fine-tuning--a pattern
that holds consistently across tasks for a given model. Our spectral analysis
further reveals that these shifts are driven by changes in the top principal
components, which encode semantic transitions from rationales to conclusions.
We further apply these findings to two practical scenarios: efficient domain
adaptation, where fine-tuning critical layers leads to greater loss reduction
compared to non-critical layers; and backdoor defense, where freezing them
reduces attack success rates by up to 40%.

</details>


### [150] [Deep-Learning-Driven Prefetching for Far Memory](https://arxiv.org/abs/2506.00384)
*Yutong Huang,Zhiyuan Guo,Yiying Zhang*

Main category: cs.LG

TL;DR: FarSight uses deep learning for data prefetching in Linux-based systems, enhancing performance in far-memory architectures by separating application semantics and runtime memory layouts.


<details>
  <summary>Details</summary>
Motivation: The motivation for this work arises from the increasing runtime performance demands in modern software systems, particularly with new architectures like far memory, where local-memory misses lead to significant latency. While ML has improved offline systems optimization, there is a need to address high-frequency, runtime-level issues where ML applications remain limited.

Method: The method involves using FarSight, a Linux-based far-memory system that utilizes deep learning for accurate data prefetching. It separates application semantics from runtime memory layout and uses offline-trained DL models to predict access patterns, resolved at runtime by lightweight mapping structures. It also incorporates asynchronous inference, lookahead prediction, and utilizes a cache-resident DL model for performance optimization.

Result: Through evaluation on four data-intensive workloads, FarSight outperformed the current state-of-the-art far-memory system by up to 3.6 times, indicating significant performance advancements.

Conclusion: FarSight demonstrates the feasibility and efficiency of employing modern ML techniques, specifically deep learning, in performance-critical runtime software systems to significantly enhance data prefetching and system performance.

Abstract: Modern software systems face increasing runtime performance demands,
particularly in emerging architectures like far memory, where local-memory
misses incur significant latency. While machine learning (ML) has proven
effective in offline systems optimization, its application to high-frequency,
runtime-level problems remains limited due to strict performance,
generalization, and integration constraints. We present FarSight, a Linux-based
far-memory system that leverages deep learning (DL) to efficiently perform
accurate data prefetching. FarSight separates application semantics from
runtime memory layout, allowing offline-trained DL models to predict access
patterns using a compact vocabulary of ordinal possibilities, resolved at
runtime through lightweight mapping structures. By combining asynchronous
inference, lookahead prediction, and a cache-resident DL model, FarSight
achieves high prediction accuracy with low runtime overhead. Our evaluation of
FarSight on four data-intensive workloads shows that it outperforms the
state-of-the-art far-memory system by up to 3.6 times. Overall, this work
demonstrates the feasibility and advantages of applying modern ML techniques to
complex, performance-critical software runtime problems.

</details>


### [151] [CLARIFY: Contrastive Preference Reinforcement Learning for Untangling Ambiguous Queries](https://arxiv.org/abs/2506.00388)
*Ni Mu,Hao Hu,Xiao Hu,Yiqin Yang,Bo Xu,Qing-Shan Jia*

Main category: cs.LG

TL;DR: CLARIFY改善了偏好标签效率，通过学习轨迹嵌入更好地处理模糊反馈，提高查询选择的明确性与效力。


<details>
  <summary>Details</summary>
Motivation: 在人类难以明确标记相似片段的偏好时，标签效率降低，限制了PbRL在现实世界中的应用。

Method: 提出了一种离线生成对比学习的方法，即Contrastive LeArning for ResolvIng Ambiguous Feedback (CLARIFY)，通过学习轨迹嵌入空间来处理偏好信息，将明显区分的片段分隔开来，从而促进更明确的查询选择。

Result: CLARIFY在非理想教师和真实人类反馈中表现优于基线方法。

Conclusion: CLARIFY方法能够更好地处理模糊的反馈，选择更明确的查询，并学习有意义的轨迹嵌入。

Abstract: Preference-based reinforcement learning (PbRL) bypasses explicit reward
engineering by inferring reward functions from human preference comparisons,
enabling better alignment with human intentions. However, humans often struggle
to label a clear preference between similar segments, reducing label efficiency
and limiting PbRL's real-world applicability. To address this, we propose an
offline PbRL method: Contrastive LeArning for ResolvIng Ambiguous Feedback
(CLARIFY), which learns a trajectory embedding space that incorporates
preference information, ensuring clearly distinguished segments are spaced
apart, thus facilitating the selection of more unambiguous queries. Extensive
experiments demonstrate that CLARIFY outperforms baselines in both non-ideal
teachers and real human feedback settings. Our approach not only selects more
distinguished queries but also learns meaningful trajectory embeddings.

</details>


### [152] [Bias as a Virtue: Rethinking Generalization under Distribution Shifts](https://arxiv.org/abs/2506.00407)
*Ruixuan Chen,Wentao Li,Jiahui Xiao,Yuchen Li,Yimin Tang,Xiaonan Wang*

Main category: cs.LG

TL;DR: ADB通过增加训练中的统计多样性，提高模型在不同数据分布上的泛化能力，显著降低OOD错误率，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在训练数据与部署数据分布不一致时通常会性能下降，因此我们挑战传统验证范式，提出一种提高OOD泛化能力的新方法。

Method: 我们引入ADB框架，通过在训练过程中引入控制的统计多样性，发展模型的偏差特征，以实现对不同数据分布的有效泛化。

Result: 我们的ADB框架在多个数据集上显著提升了OOD泛化能力，与传统交叉验证相比，平均错误率减少了最高26.8%，并且一致性地找到高性能的训练策略，其表现排序常超过第74.4百分位。

Conclusion: 我们提出的ADB框架能够有效提高模型在OOD上的泛化能力，并且该方法为重新考虑偏差在机器学习中的作用提供了理论支持。

Abstract: Machine learning models often degrade when deployed on data distributions
different from their training data. Challenging conventional validation
paradigms, we demonstrate that higher in-distribution (ID) bias can lead to
better out-of-distribution (OOD) generalization. Our Adaptive Distribution
Bridge (ADB) framework implements this insight by introducing controlled
statistical diversity during training, enabling models to develop bias profiles
that effectively generalize across distributions. Empirically, we observe a
robust negative correlation where higher ID bias corresponds to lower OOD
error--a finding that contradicts standard practices focused on minimizing
validation error. Evaluation on multiple datasets shows our approach
significantly improves OOD generalization. ADB achieves robust mean error
reductions of up to 26.8% compared to traditional cross-validation, and
consistently identifies high-performing training strategies, evidenced by
percentile ranks often exceeding 74.4%. Our work provides both a practical
method for improving generalization and a theoretical framework for
reconsidering the role of bias in robust machine learning.

</details>


### [153] [JojoSCL: Shrinkage Contrastive Learning for single-cell RNA sequence Clustering](https://arxiv.org/abs/2506.00410)
*Ziwen Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为JojoSCL的新框架，通过自监督对比学习和优化方法提升单细胞RNA测序数据的聚类效果。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序（scRNA-seq）革命性地改变了我们对细胞过程的理解，但其数据的高维性和稀疏性仍然是现有聚类模型的挑战。

Method: 引入JojoSCL，这是一种新颖的自监督对比学习框架，采用基于层次贝叶斯估计的收缩估计器和Stein的无偏风险估计对其进行优化。

Result: 在十个scRNA-seq数据集上的实验表明，JojoSCL始终优于现有的聚类方法，并通过稳健性分析和消融研究进一步验证其实用性。

Conclusion: JojoSCL通过改进实例级和聚类级对比学习，提升了scRNA-seq数据聚类的效果。

Abstract: Single-cell RNA sequencing (scRNA-seq) has revolutionized our understanding
of cellular processes by enabling gene expression analysis at the individual
cell level. Clustering allows for the identification of cell types and the
further discovery of intrinsic patterns in single-cell data. However, the high
dimensionality and sparsity of scRNA-seq data continue to challenge existing
clustering models. In this paper, we introduce JojoSCL, a novel self-supervised
contrastive learning framework for scRNA-seq clustering. By incorporating a
shrinkage estimator based on hierarchical Bayesian estimation, which adjusts
gene expression estimates towards more reliable cluster centroids to reduce
intra-cluster dispersion, and optimized using Stein's Unbiased Risk Estimate
(SURE), JojoSCL refines both instance-level and cluster-level contrastive
learning. Experiments on ten scRNA-seq datasets substantiate that JojoSCL
consistently outperforms prevalent clustering methods, with further validation
of its practicality through robustness analysis and ablation studies. JojoSCL's
code is available at: https://github.com/ziwenwang28/JojoSCL.

</details>


### [154] [Blockchain-Enabled Privacy-Preserving Second-Order Federated Edge Learning in Personalized Healthcare](https://arxiv.org/abs/2506.00416)
*Anum Nawaz,Muhammad Irfan,Xianjia Yu,Zhuo Zou,Tomi Westerlund*

Main category: cs.LG

TL;DR: 提出了一种基于区块链优化的第二阶联邦学习框架BFEL，能够增强个性化医疗系统的稳定性、安全性和隐私。


<details>
  <summary>Details</summary>
Motivation: 解决传统FL方法在处理非独立同分布数据时的个性化训练问题，增强模型的稳定性和一致性，同时保证数据隐私和安全性。

Method: 采用第二阶FL方法，结合Fisher信息矩阵和Ethereum进行模型聚合与加密，使用CNN和MLP在Mnist、Cifar-10和PathMnist数据集上进行实验。

Result: 实验结果表明，BFEL框架在处理Mnist、Cifar-10，以及PathMnist数据集时表现出高度的效率和可扩展性。

Conclusion: BFEL框架通过结合区块链技术和优化的FedCurv实现了个性化医疗系统的高效性和可扩展性，为保护隐私和增强安全提供了可靠的解决方案。

Abstract: Federated learning (FL) has attracted increasing attention to mitigate
security and privacy challenges in traditional cloud-centric machine learning
models specifically in healthcare ecosystems. FL methodologies enable the
training of global models through localized policies, allowing independent
operations at the edge clients' level. Conventional first-order FL approaches
face several challenges in personalized model training due to heterogeneous
non-independent and identically distributed (non-iid) data of each edge client.
Recently, second-order FL approaches maintain the stability and consistency of
non-iid datasets while improving personalized model training. This study
proposes and develops a verifiable and auditable optimized second-order FL
framework BFEL (blockchain-enhanced federated edge learning) based on optimized
FedCurv for personalized healthcare systems. FedCurv incorporates information
about the importance of each parameter to each client's task (through Fisher
Information Matrix) which helps to preserve client-specific knowledge and
reduce model drift during aggregation. Moreover, it minimizes communication
rounds required to achieve a target precision convergence for each edge client
while effectively managing personalized training on non-iid and heterogeneous
data. The incorporation of Ethereum-based model aggregation ensures trust,
verifiability, and auditability while public key encryption enhances privacy
and security. Experimental results of federated CNNs and MLPs utilizing Mnist,
Cifar-10, and PathMnist demonstrate the high efficiency and scalability of the
proposed framework.

</details>


### [155] [A New Spatiotemporal Correlation Anomaly Detection Method that Integrates Contrastive Learning and Few-Shot Learning in Wireless Sensor Networks](https://arxiv.org/abs/2506.00420)
*Miao Ye,Suxiao Wang,Jiaguang Han,Yong Wang,Xiaoli Wang,Jingxuan Wei,Peng Wen,Jing Cui*

Main category: cs.LG

TL;DR: 提出了一种新的WSN异常检测模型MTAD-RD，解决了现有方法的不足，实验中表现出色，F1得分达到90.97%。


<details>
  <summary>Details</summary>
Motivation: 现有的WSN异常检测方法面临时空相关特征提取有限、样本标签缺失、异常样本少以及样本分布不平衡等问题。为了解决这些问题，提出了一种新的时空相关性检测模型。

Method: 本文提出了一种时空相关检测模型（MTAD-RD），结合模型结构设计和两阶段训练策略。模型设计包括保留网络（RetNet）、跨保留模块、多粒度特征融合模块和图注意网络模块。训练采用对比学习代理任务和基于缓存的样本采样器，联合训练双图鉴别器网络。

Result: 在真实的公共数据集上，MTAD-RD方法在F1得分上表现出色，达到了90.97%，超过现有的许多监督检测方法。

Conclusion: MTAD-RD模型在真实公共数据集上实现了90.97%的F1得分，优于现有的监督式WSN异常检测方法。

Abstract: Detecting anomalies in the data collected by WSNs can provide crucial
evidence for assessing the reliability and stability of WSNs. Existing methods
for WSN anomaly detection often face challenges such as the limited extraction
of spatiotemporal correlation features, the absence of sample labels, few
anomaly samples, and an imbalanced sample distribution. To address these
issues, a spatiotemporal correlation detection model (MTAD-RD) considering both
model architecture and a two-stage training strategy perspective is proposed.
In terms of model structure design, the proposed MTAD-RD backbone network
includes a retentive network (RetNet) enhanced by a cross-retention (CR)
module, a multigranular feature fusion module, and a graph attention network
module to extract internode correlation information. This proposed model can
integrate the intermodal correlation features and spatial features of WSN
neighbor nodes while extracting global information from time series data.
Moreover, its serialized inference characteristic can remarkably reduce
inference overhead. For model training, a two-stage training approach was
designed. First, a contrastive learning proxy task was designed for time series
data with graph structure information in WSNs, enabling the backbone network to
learn transferable features from unlabeled data using unsupervised contrastive
learning methods, thereby addressing the issue of missing sample labels in the
dataset. Then, a caching-based sample sampler was designed to divide samples
into few-shot and contrastive learning data. A specific joint loss function was
developed to jointly train the dual-graph discriminator network to address the
problem of sample imbalance effectively. In experiments carried out on real
public datasets, the designed MTAD-RD anomaly detection method achieved an F1
score of 90.97%, outperforming existing supervised WSN anomaly detection
methods.

</details>


### [156] [COGNATE: Acceleration of Sparse Tensor Programs on Emerging Hardware using Transfer Learning](https://arxiv.org/abs/2506.00424)
*Chamika Sudusinghe,Gerasimos Gerogiannis Damitha Lenadora,Charles Block,Josep Torrellas,Charith Mendis*

Main category: cs.LG

TL;DR: COGNATE框架通过少量数据对稀疏张量程序进行优化，有效提升了新兴硬件的性能。


<details>
  <summary>Details</summary>
Motivation: 优化稀疏张量程序的需求日益增加，但针对加速器的早期成本模型需要大量数据，且现有模型在新兴加速器上效果不佳。

Method: COGNATE框架通过利用通用硬件上的廉价数据样本进行初步训练，然后在新兴硬件上进行少量微调，以优化成本模型。

Result: COGNATE在SpMM和SDDMM方面平均加速1.47倍（最高达5.46倍）和1.39倍（最高达4.22倍），超过了现有技术。

Conclusion: COGNATE大幅提高了稀疏张量程序在新兴硬件上的优化效果，以少量数据实现了与加速器特定模型相当的性能。

Abstract: Sparse tensor programs are essential in deep learning and graph analytics,
driving the need for optimized processing. To meet this demand, specialized
hardware accelerators are being developed. Optimizing these programs for
accelerators is challenging for two reasons: program performance is highly
sensitive to variations in sparse inputs, and early-stage accelerators rely on
expensive simulators. Therefore, ML-based cost models used for optimizing such
programs on general-purpose hardware are often ineffective for early-stage
accelerators, as they require large datasets for proper training. To this end,
we introduce COGNATE, a novel framework that leverages inexpensive data samples
from general-purpose hardware (e.g., CPUs) to train cost models, followed by
few-shot fine-tuning on emerging hardware. COGNATE exploits the homogeneity of
input features across hardware platforms while effectively mitigating
heterogeneity, enabling cost model training with just 5% of the data samples
needed by accelerator-specific models to achieve comparable performance. We
conduct extensive experiments to demonstrate that COGNATE outperforms existing
techniques, achieving average speedups of 1.47x (up to 5.46x) for SpMM and
1.39x (up to 4.22x) for SDDMM.

</details>


### [157] [TIDFormer: Exploiting Temporal and Interactive Dynamics Makes A Great Dynamic Graph Transformer](https://arxiv.org/abs/2506.00431)
*Jie Peng,Zhewei Wei,Yuhang Ye*

Main category: cs.LG

TL;DR: 提出一种称为TIDFormer的动态图Transformer模型，通过时间和交互动态捕获，表现优于现有模型并具效率优势。


<details>
  <summary>Details</summary>
Motivation: 动态图神经网络中的Transformer架构有效性和效率参差不齐，亟需一个能够全面编码时间和交互动态而无需额外复杂模块的设计，以提高SAM的定义在动态图上的解释性。

Method: 采用时间和交互动态进行高效捕获，通过简单的分解来联合建模时间和交互特征，利用日历时间分区信息以及单纯采样的一阶邻居来提取双向和非双向图中的互动嵌入。

Result: 实验结果表明TIDFormer在动态图数据集中的表现优于现有最先进模型，并在效率上显示出显著优势。

Conclusion: TIDFormer在动态图神经网络中表现优异，在大多数数据集和实验设置中超过了现有的最先进模型，同时在效率上也显著优于之前的Transformer方法。

Abstract: Due to the proficiency of self-attention mechanisms (SAMs) in capturing
dependencies in sequence modeling, several existing dynamic graph neural
networks (DGNNs) utilize Transformer architectures with various encoding
designs to capture sequential evolutions of dynamic graphs. However, the
effectiveness and efficiency of these Transformer-based DGNNs vary
significantly, highlighting the importance of properly defining the SAM on
dynamic graphs and comprehensively encoding temporal and interactive dynamics
without extra complex modules. In this work, we propose TIDFormer, a dynamic
graph TransFormer that fully exploits Temporal and Interactive Dynamics in an
efficient manner. We clarify and verify the interpretability of our proposed
SAM, addressing the open problem of its uninterpretable definitions on dynamic
graphs in previous works. To model the temporal and interactive dynamics,
respectively, we utilize the calendar-based time partitioning information and
extract informative interaction embeddings for both bipartite and non-bipartite
graphs using merely the sampled first-order neighbors. In addition, we jointly
model temporal and interactive features by capturing potential changes in
historical interaction patterns through a simple decomposition. We conduct
extensive experiments on several dynamic graph datasets to verify the
effectiveness and efficiency of TIDFormer. The experimental results demonstrate
that TIDFormer excels, outperforming state-of-the-art models across most
datasets and experimental settings. Furthermore, TIDFormer exhibits significant
efficiency advantages compared to previous Transformer-based methods.

</details>


### [158] [Channel Normalization for Time Series Channel Identification](https://arxiv.org/abs/2506.00432)
*Seunghan Lee,Taeyoung Park,Kibok Lee*

Main category: cs.LG

TL;DR: This paper proposes Channel Normalization to improve channel identifiability in time series models, introducing adaptive and prototypical variants, leading to significant performance gains.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of channel identifiability in time series modeling, as the absence of it can lead to outputting identical values for identical inputs, ignoring channel-specific properties.

Method: The paper introduces a normalization strategy called Channel Normalization (CN), which assigns distinct affine transformation parameters to each channel. It extends CN into Adaptive CN (ACN), which adjusts parameters based on input time series, and Prototypical CN (PCN), which uses learnable prototypes for better adaptability and application across various datasets.

Result: The application of CN and its variants results in significant performance improvements across various time series models and datasets. The paper also provides an analysis from an information theory perspective demonstrating the success of their approach.

Conclusion: Channel Normalization (CN) and its variants significantly enhance channel identifiability and performance in time series models by providing distinct affine transformations for each channel, leading to performance improvements across different datasets and models.

Abstract: Channel identifiability (CID) refers to the ability to distinguish between
individual channels in time series (TS) modeling. The absence of CID often
results in producing identical outputs for identical inputs, disregarding
channel-specific characteristics. In this paper, we highlight the importance of
CID and propose Channel Normalization (CN), a simple yet effective
normalization strategy that enhances CID by assigning distinct affine
transformation parameters to each channel. We further extend CN in two ways: 1)
Adaptive CN (ACN) dynamically adjusts parameters based on the input TS,
improving adaptability in TS models, and 2) Prototypical CN (PCN) introduces a
set of learnable prototypes instead of per-channel parameters, enabling
applicability to datasets with unknown or varying number of channels and
facilitating use in TS foundation models. We demonstrate the effectiveness of
CN and its variants by applying them to various TS models, achieving
significant performance gains for both non-CID and CID models. In addition, we
analyze the success of our approach from an information theory perspective.
Code is available at https://github.com/seunghan96/CN.

</details>


### [159] [Learning from Double Positive and Unlabeled Data for Potential-Customer Identification](https://arxiv.org/abs/2506.00436)
*Masahiro Kato,Yuki Ikeda abd Kentaro Baba,Takashi Imai,Ryo Inokuchi*

Main category: cs.LG

TL;DR: 提出了一种利用PU学习识别潜在客户的方法，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在目标营销中，虽然公司只能观察到购买产品的客户，但决策者希望根据客户的忠诚度来有效地开展产品营销。

Method: 一个基于正例和未标记数据学习(PU学习)的单阶段优化算法，目标函数隐含了两种损失。

Result: 算法适当地识别了对产品感兴趣但对公司不忠诚的潜在客户，达到了更高效的营销效果。

Conclusion: 通过数值实验验证了所提出算法的有效性，确认其可以适当地解决问题。

Abstract: In this study, we propose a method for identifying potential customers in
targeted marketing by applying learning from positive and unlabeled data (PU
learning). We consider a scenario in which a company sells a product and can
observe only the customers who purchased it. Decision-makers seek to market
products effectively based on whether people have loyalty to the company.
Individuals with loyalty are those who are likely to remain interested in the
company even without additional advertising. Consequently, those loyal
customers would likely purchase from the company if they are interested in the
product. In contrast, people with lower loyalty may overlook the product or buy
similar products from other companies unless they receive marketing attention.
Therefore, by focusing marketing efforts on individuals who are interested in
the product but do not have strong loyalty, we can achieve more efficient
marketing. To achieve this goal, we consider how to learn, from limited data, a
classifier that identifies potential customers who (i) have interest in the
product and (ii) do not have loyalty to the company. Although our algorithm
comprises a single-stage optimization, its objective function implicitly
contains two losses derived from standard PU learning settings. For this
reason, we refer to our approach as double PU learning. We verify the validity
of the proposed algorithm through numerical experiments, confirming that it
functions appropriately for the problem at hand.

</details>


### [160] [Is Your Explanation Reliable: Confidence-Aware Explanation on Graph Neural Networks](https://arxiv.org/abs/2506.00437)
*Jiaxing Zhang,Xiaoou Liu,Dongsheng Luo,Hua Wei*

Main category: cs.LG

TL;DR: 提出了一种框架ConfExplainer，通过置信度评分提高图神经网络解释的可靠性，实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高解释图神经网络（GNNs）的可靠性，特别是在分布外数据集上的表现，提出能够量化解释可靠性的框架。

Method: 提出了一个解释器框架，包含置信度评分模块（ConfExplainer），采用了一种理论基础为广义图信息瓶颈并加置信约束（GIB-CC）的策略。

Result: 实验结果表明，我们的方法优于现有的解释方法，并且置信评分有效提高了解释的可信度和稳健性。

Conclusion: 我们的框架通过加入置信度评分模块，提高了解释的可信度和稳健性。

Abstract: Explaining Graph Neural Networks (GNNs) has garnered significant attention
due to the need for interpretability, enabling users to understand the behavior
of these black-box models better and extract valuable insights from their
predictions. While numerous post-hoc instance-level explanation methods have
been proposed to interpret GNN predictions, the reliability of these
explanations remains uncertain, particularly in the out-of-distribution or
unknown test datasets. In this paper, we address this challenge by introducing
an explainer framework with the confidence scoring module ( ConfExplainer),
grounded in theoretical principle, which is generalized graph information
bottleneck with confidence constraint (GIB-CC), that quantifies the reliability
of generated explanations. Experimental results demonstrate the superiority of
our approach, highlighting the effectiveness of the confidence score in
enhancing the trustworthiness and robustness of GNN explanations.

</details>


### [161] [PointODE: Lightweight Point Cloud Learning with Neural Ordinary Differential Equations on Edge](https://arxiv.org/abs/2506.00438)
*Keisuke Sugiura,Mizuki Yasuda,Hiroki Matsutani*

Main category: cs.LG

TL;DR: Introduces PointODE, a resource-efficient model for point cloud feature extraction with an FPGA accelerator, improving speed and energy efficiency on edge devices without compromising accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the gap in running recent deep learning-based methods for point cloud applications on embedded edge devices with resource constraints.

Method: Developed PointODE, a parameter-efficient architecture utilizing Neural ODE with MLP blocks and residual connections, and introduced PointODE-Elite with 0.58M trainable parameters. Designed a dedicated FPGA accelerator for efficient inference.

Result: PointODE-Elite speeds up feature extraction by 4.9x, inference by 3.7x, and improves energy-efficiency by 3.5x on Xilinx ZCU104 board compared to ARM Cortex-A53 while maintaining competitive accuracy.

Conclusion: PointODE-Elite offers competitive accuracy compared to state-of-the-art models while significantly enhancing the trade-off between accuracy and inference cost on embedded platforms.

Abstract: Embedded edge devices are often used as a computing platform to run
real-world point cloud applications, but recent deep learning-based methods may
not fit on such devices due to limited resources. In this paper, we aim to fill
this gap by introducing PointODE, a parameter-efficient ResNet-like
architecture for point cloud feature extraction based on a stack of MLP blocks
with residual connections. We leverage Neural ODE (Ordinary Differential
Equation), a continuous-depth version of ResNet originally developed for
modeling the dynamics of continuous-time systems, to compress PointODE by
reusing the same parameters across MLP blocks. The point-wise normalization is
proposed for PointODE to handle the non-uniform distribution of feature points.
We introduce PointODE-Elite as a lightweight version with 0.58M trainable
parameters and design its dedicated accelerator for embedded FPGAs. The
accelerator consists of a four-stage pipeline to parallelize the feature
extraction for multiple points and stores the entire parameters on-chip to
eliminate most of the off-chip data transfers. Compared to the ARM Cortex-A53
CPU, the accelerator implemented on a Xilinx ZCU104 board speeds up the feature
extraction by 4.9x, leading to 3.7x faster inference and 3.5x better
energy-efficiency. Despite the simple architecture, PointODE-Elite shows
competitive accuracy to the state-of-the-art models on both synthetic and
real-world classification datasets, greatly improving the trade-off between
accuracy and inference cost.

</details>


### [162] [RLAE: Reinforcement Learning-Assisted Ensemble for LLMs](https://arxiv.org/abs/2506.00439)
*Yuqian Fu,Yuanheng Zhu,Jiajun Chai,Guojun Yin,Wei Lin,Qichao Zhang,Dongbin Zhao*

Main category: cs.LG

TL;DR: RLAE uses reinforcement learning to improve LLM ensembles, achieving higher accuracy, better generalization, and lower latency than traditional methods.


<details>
  <summary>Details</summary>
Motivation: To enhance the performance of LLMs ensembling by overcoming the limitations of fixed weighting strategies in adapting to dynamic and context-dependent characteristics.

Method: Reinforcement Learning-Assisted Ensemble for LLMs (RLAE) using Markov Decision Process with RL agent adjusting weights dynamically.

Result: RLAE shows better performance with up to 3.3% higher accuracy, superior generalization across tasks, and reduced time latency compared to existing ensemble methods.

Conclusion: RLAE demonstrates substantial improvements over conventional ensemble methods with up to 3.3% increase in accuracy, better generalization across tasks, and lower latency.

Abstract: Ensembling large language models (LLMs) can effectively combine diverse
strengths of different models, offering a promising approach to enhance
performance across various tasks. However, existing methods typically rely on
fixed weighting strategies that fail to adapt to the dynamic, context-dependent
characteristics of LLM capabilities. In this work, we propose Reinforcement
Learning-Assisted Ensemble for LLMs (RLAE), a novel framework that reformulates
LLM ensemble through the lens of a Markov Decision Process (MDP). Our approach
introduces a RL agent that dynamically adjusts ensemble weights by considering
both input context and intermediate generation states, with the agent being
trained using rewards that directly correspond to the quality of final outputs.
We implement RLAE using both single-agent and multi-agent reinforcement
learning algorithms ($\text{RLAE}_\text{PPO}$ and $\text{RLAE}_\text{MAPPO}$ ),
demonstrating substantial improvements over conventional ensemble methods.
Extensive evaluations on a diverse set of tasks show that RLAE outperforms
existing approaches by up to $3.3\%$ accuracy points, offering a more effective
framework for LLM ensembling. Furthermore, our method exhibits superior
generalization capabilities across different tasks without the need for
retraining, while simultaneously achieving lower time latency.

</details>


### [163] [PSI-PFL: Population Stability Index for Client Selection in non-IID Personalized Federated Learning](https://arxiv.org/abs/2506.00440)
*Daniel-M. Jimenez-Gutierrez,David Solans,Mohammed Elbamby,Nicolas Kourtellis*

Main category: cs.LG

TL;DR: PSI-PFL框架通过使用PSI选择更均匀的客户端来改善个性化联邦学习的性能，应对non-IID数据导致的挑战。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的非独立同分布（non-IID）数据导致模型更新偏斜和性能下降，因此需要一种方法来缓解这一问题。

Method: PSI-PFL使用人口稳定性指数（PSI）来量化和缓解数据异质性，通过选择更均匀的客户端来减少标签倾斜的影响。

Result: 实验结果表明，PSI-PFL在多种数据模态下显著提高了全球模型的准确性，在non-IID场景下性能超越了最新基线模型达10%。

Conclusion: PSI-PFL提高了联邦学习的性能，特别是在数据隐私和异质性至关重要的应用中表现出实用价值。

Abstract: Federated Learning (FL) enables decentralized machine learning (ML) model
training while preserving data privacy by keeping data localized across
clients. However, non-independent and identically distributed (non-IID) data
across clients poses a significant challenge, leading to skewed model updates
and performance degradation. Addressing this, we propose PSI-PFL, a novel
client selection framework for Personalized Federated Learning (PFL) that
leverages the Population Stability Index (PSI) to quantify and mitigate data
heterogeneity (so-called non-IIDness). Our approach selects more homogeneous
clients based on PSI, reducing the impact of label skew, one of the most
detrimental factors in FL performance. Experimental results over multiple data
modalities (tabular, image, text) demonstrate that PSI-PFL significantly
improves global model accuracy, outperforming state-of-the-art baselines by up
to 10\% under non-IID scenarios while ensuring fairer local performance.
PSI-PFL enhances FL performance and offers practical benefits in applications
where data privacy and heterogeneity are critical.

</details>


### [164] [TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction](https://arxiv.org/abs/2506.00453)
*Hao Li,Hao Wan,Yuzhou Chen,Dongsheng Ye,Yulia Gel,Hao Jiang*

Main category: cs.LG

TL;DR: TMetaNet, based on a new DZP method, improves dynamic graph analysis by considering high-order topological features, showing high performance and resilience to noise.


<details>
  <summary>Details</summary>
Motivation: Most meta-learning approaches neglect intrinsic high-order topological information of dynamic graphs.

Method: Design of Dowker Zigzag Persistence (DZP) and proposal of TMetaNet model based on dynamic topological features.

Result: Experiments demonstrate TMetaNet's state-of-the-art performance and resilience to graph noise on real-world datasets.

Conclusion: TMetaNet shows state-of-the-art performance and resilience to graph noise in dynamic graph analysis.

Abstract: Dynamic graphs evolve continuously, presenting challenges for traditional
graph learning due to their changing structures and temporal dependencies.
Recent advancements have shown potential in addressing these challenges by
developing suitable meta-learning-based dynamic graph neural network models.
However, most meta-learning approaches for dynamic graphs rely on fixed weight
update parameters, neglecting the essential intrinsic complex high-order
topological information of dynamically evolving graphs. We have designed Dowker
Zigzag Persistence (DZP), an efficient and stable dynamic graph persistent
homology representation method based on Dowker complex and zigzag persistence,
to capture the high-order features of dynamic graphs. Armed with the DZP ideas,
we propose TMetaNet, a new meta-learning parameter update model based on
dynamic topological features. By utilizing the distances between high-order
topological features, TMetaNet enables more effective adaptation across
snapshots. Experiments on real-world datasets demonstrate TMetaNet's
state-of-the-art performance and resilience to graph noise, illustrating its
high potential for meta-learning and dynamic graph analysis. Our code is
available at https://github.com/Lihaogx/TMetaNet.

</details>


### [165] [Revisiting LLMs as Zero-Shot Time-Series Forecasters: Small Noise Can Break Large Models](https://arxiv.org/abs/2506.00457)
*Junwoo Park,Hyuck Lee,Dohyun Lee,Daehoon Gwak,Jaegul Choo*

Main category: cs.LG

TL;DR: LLMs struggle in zero-shot time-series forecasting; fine-tuning is recommended to improve performance due to noise sensitivity issues.


<details>
  <summary>Details</summary>
Motivation: Investigating LLMs' potential for time-series forecasting amid conflicting findings on their effectiveness.

Method: Evaluation of LLMs as zero-shot forecasters compared to domain-specific models through experiments.

Result: LLMs underperform in zero-shot settings compared to even simple domain-specific models, due to noise sensitivity.

Conclusion: LLMs struggle with zero-shot forecasting accuracy due to noise sensitivity, and focusing on fine-tuning for numerical sequences is more promising.

Abstract: Large Language Models (LLMs) have shown remarkable performance across diverse
tasks without domain-specific training, fueling interest in their potential for
time-series forecasting. While LLMs have shown potential in zero-shot
forecasting through prompting alone, recent studies suggest that LLMs lack
inherent effectiveness in forecasting. Given these conflicting findings, a
rigorous validation is essential for drawing reliable conclusions. In this
paper, we evaluate the effectiveness of LLMs as zero-shot forecasters compared
to state-of-the-art domain-specific models. Our experiments show that LLM-based
zero-shot forecasters often struggle to achieve high accuracy due to their
sensitivity to noise, underperforming even simple domain-specific models. We
have explored solutions to reduce LLMs' sensitivity to noise in the zero-shot
setting, but improving their robustness remains a significant challenge. Our
findings suggest that rather than emphasizing zero-shot forecasting, a more
promising direction would be to focus on fine-tuning LLMs to better process
numerical sequences. Our experimental code is available at
https://github.com/junwoopark92/revisiting-LLMs-zeroshot-forecaster.

</details>


### [166] [Comparing Traditional and Reinforcement-Learning Methods for Energy Storage Control](https://arxiv.org/abs/2506.00459)
*Elinor Ginzburg,Itay Segev,Yoash Levron,Sarah Keren*

Main category: cs.LG

TL;DR: 探讨传统与强化学习方法在能量存储管理中的性能，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 旨在理解在特定实例中使用生成性强化学习策略替代传统方法寻找最优控制策略时的性能损失。

Method: 采用简化的微电网模型进行性能比较，包括负载组件、光伏源和存储设备。针对三种不同复杂度的应用场景，进行了优化挑战的详细描述。

Result: 分析了传统与强化学习方法的性能，讨论了各自适用的情境，并提出了未来研究方向。

Conclusion: 本文对传统方法和生成性强化学习策略在能量存储管理中的应用进行了比较，强调了使用强化学习方法的优缺点。

Abstract: We aim to better understand the tradeoffs between traditional and
reinforcement learning (RL) approaches for energy storage management. More
specifically, we wish to better understand the performance loss incurred when
using a generative RL policy instead of using a traditional approach to find
optimal control policies for specific instances. Our comparison is based on a
simplified micro-grid model, that includes a load component, a photovoltaic
source, and a storage device. Based on this model, we examine three use cases
of increasing complexity: ideal storage with convex cost functions, lossy
storage devices, and lossy storage devices with convex transmission losses.
With the aim of promoting the principled use RL based methods in this
challenging and important domain, we provide a detailed formulation of each use
case and a detailed description of the optimization challenges. We then compare
the performance of traditional and RL methods, discuss settings in which it is
beneficial to use each method, and suggest avenues for future investigation.

</details>


### [167] [SST: Self-training with Self-adaptive Thresholding for Semi-supervised Learning](https://arxiv.org/abs/2506.00467)
*Shuai Zhao,Heyan Huang,Xinge Li,Xiaokang Chen,Rui Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的半监督学习框架SST，通过自适应阈值机制高效选择高质量伪标签，在多个架构和数据集上实现了最先进的性能，并在ImageNet-1KSSL基准上以较少的标记数据达到较高的准确率。


<details>
  <summary>Details</summary>
Motivation: 由于在真实世界场景中获得高质量标注数据昂贵且费力，因此现在的研究探索半监督学习（SSL）作为解决方案。然而当前的方法在选择高质量伪标签时由于依赖固定阈值仍然面临挑战。本文旨在解决这些挑战，通过引入自适应阈值机制实现更高效的伪标签选择。

Method: 本文提出了一种称为SST（自训练与自适应阈值）的新的SSL框架。SST引入了一种创新的自适应阈值机制（SAT），根据模型的学习进度自适应调整类特异性阈值。SAT确保选择高质量的伪标记数据，缓解不准确的伪标签和确认偏差的风险。

Result: 通过广泛的实验表明，SST框架在各种架构和数据集上实现了最先进的性能，同时具有显著的效率、泛化能力和扩展性。在ImageNet-1K SSL基准上，Semi-SST-ViT-Huge使用1%和10%的标记数据分别实现了80.7%和84.9%的Top-1准确率，比全监督的DeiT-III-ViT-Huge使用100%标记数据的84.8%准确率表现更优。

Conclusion: 本文提出的SST框架在各种架构和数据集上都实现了高效率、广泛的泛化能力和扩展性，取得了最先进的性能。特别是Semi-SST-ViT-Huge在ImageNet-1K SSL基准上实现了最佳结果，使用仅1%/10%标记数据分别达到了80.7%/84.9%的Top-1准确率。与完全监督的DeiT-III-ViT-Huge相比，使用100%标记数据达到了84.8%的Top-1准确率，我们的方法在仅使用10%标记数据的情况下表现更优。

Abstract: Neural networks have demonstrated exceptional performance in supervised
learning, benefiting from abundant high-quality annotated data. However,
obtaining such data in real-world scenarios is costly and labor-intensive.
Semi-supervised learning (SSL) offers a solution to this problem. Recent
studies, such as Semi-ViT and Noisy Student, which employ consistency
regularization or pseudo-labeling, have demonstrated significant achievements.
However, they still face challenges, particularly in accurately selecting
sufficient high-quality pseudo-labels due to their reliance on fixed
thresholds. Recent methods such as FlexMatch and FreeMatch have introduced
flexible or self-adaptive thresholding techniques, greatly advancing SSL
research. Nonetheless, their process of updating thresholds at each iteration
is deemed time-consuming, computationally intensive, and potentially
unnecessary. To address these issues, we propose Self-training with
Self-adaptive Thresholding (SST), a novel, effective, and efficient SSL
framework. SST introduces an innovative Self-Adaptive Thresholding (SAT)
mechanism that adaptively adjusts class-specific thresholds based on the
model's learning progress. SAT ensures the selection of high-quality
pseudo-labeled data, mitigating the risks of inaccurate pseudo-labels and
confirmation bias. Extensive experiments demonstrate that SST achieves
state-of-the-art performance with remarkable efficiency, generalization, and
scalability across various architectures and datasets. Semi-SST-ViT-Huge
achieves the best results on competitive ImageNet-1K SSL benchmarks, with 80.7%
/ 84.9% Top-1 accuracy using only 1% / 10% labeled data. Compared to the
fully-supervised DeiT-III-ViT-Huge, which achieves 84.8% Top-1 accuracy using
100% labeled data, our method demonstrates superior performance using only 10%
labeled data.

</details>


### [168] [Towards Graph-Based Privacy-Preserving Federated Learning: ModelNet -- A ResNet-based Model Classification Dataset](https://arxiv.org/abs/2506.00476)
*Abhisek Ray,Lukas Esterle*

Main category: cs.LG

TL;DR: 引入了ModelNet，一个新的图像分类数据集，针对联邦学习提供跨环境的客户特定数据集，展示有效的隐私保护和评估方法。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中本地数据隐私问题，并应对领域异质性和客户特定划分的评估瓶颈。

Method: 通过将CIFAR100数据集修改为三种客户特定的变体（同质、异质和随机），并在预训练的ResNet50模型上训练这些子集以保存模型参数。

Result: 提出了一个新的假设，定义FL算法可以访问匿名化的模型参数，更有效地保护本地隐私。广泛的实验展示了这些变体在领域转移和聚合策略中的有效性。

Conclusion: 实验结果表明，提出的ModelNet数据集在多域图驱动FL算法中的有效性，使其成为经典和基于图的FL研究的实用基准。

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for training
machine learning models across distributed data sources while preserving data
locality. However, the privacy of local data is always a pivotal concern and
has received a lot of attention in recent research on the FL regime. Moreover,
the lack of domain heterogeneity and client-specific segregation in the
benchmarks remains a critical bottleneck for rigorous evaluation. In this
paper, we introduce ModelNet, a novel image classification dataset constructed
from the embeddings extracted from a pre-trained ResNet50 model. First, we
modify the CIFAR100 dataset into three client-specific variants, considering
three domain heterogeneities (homogeneous, heterogeneous, and random).
Subsequently, we train each client-specific subset of all three variants on the
pre-trained ResNet50 model to save model parameters. In addition to
multi-domain image data, we propose a new hypothesis to define the FL algorithm
that can access the anonymized model parameters to preserve the local privacy
in a more effective manner compared to existing ones. ModelNet is designed to
simulate realistic FL settings by incorporating non-IID data distributions and
client diversity design principles in the mainframe for both conventional and
futuristic graph-driven FL algorithms. The three variants are ModelNet-S,
ModelNet-D, and ModelNet-R, which are based on homogeneous, heterogeneous, and
random data settings, respectively. To the best of our knowledge, we are the
first to propose a cross-environment client-specific FL dataset along with the
graph-based variant. Extensive experiments based on domain shifts and
aggregation strategies show the effectiveness of the above variants, making it
a practical benchmark for classical and graph-based FL research. The dataset
and related code are available online.

</details>


### [169] [Flashbacks to Harmonize Stability and Plasticity in Continual Learning](https://arxiv.org/abs/2506.00477)
*Leila Mahmoodi,Peyman Moghadam,Munawar Hayat,Christian Simon,Mehrtash Harandi*

Main category: cs.LG

TL;DR: 本文提出一种称为Flashback Learning (FL) 的新方法，用于在持续学习中协调模型的稳定性和可塑性。通过双向正则化形式，FL 有效平衡了新旧知识的获取和保留。实验结果表明，FL 在标准图像分类基准上的准确性平均提高了4.91%（Class-Incremental) 和3.51%（Task-Incremental)，并且在更具挑战性的数据集上优于最新方法。


<details>
  <summary>Details</summary>
Motivation: 在持续学习中，模型需要同时保留旧知识及迅速吸收新知识。现有方法多数关注通过对模型更新进行正则化来保留旧信息，但缺乏有效方法来平衡这一过程中的稳定性与可塑性，因此需要一种新方法来协调这种平衡。

Method: 本文提出的Flashback Learning (FL) 是一种通过双向正则化有效协调旧知识保持和新知识学习的过程。FL 采用双阶段训练过程，使用两个不同的知识库：一个增强可塑性，另一个提高稳定性。FL 可以无缝结合到多种CL方法中，包括重放、参数正则化、蒸馏和动态架构技术。

Result: 在标准图像分类基准上，FL在Class-Incremental和Task-Incremental设置中的平均准确率分别提高了4.91%和3.51%。在更具挑战性的数据集（如ImageNet）上，FL 的表现优于最先进的CL方法。

Conclusion: Flashback Learning (FL) 是一种创新方法，通过有效平衡模型的稳定性与可塑性，提高了持续学习中的性能。实验证明，在特定训练预算内，FL 在各类基准和挑战性数据集上的表现均优于其他方法。

Abstract: We introduce Flashback Learning (FL), a novel method designed to harmonize
the stability and plasticity of models in Continual Learning (CL). Unlike prior
approaches that primarily focus on regularizing model updates to preserve old
information while learning new concepts, FL explicitly balances this trade-off
through a bidirectional form of regularization. This approach effectively
guides the model to swiftly incorporate new knowledge while actively retaining
its old knowledge. FL operates through a two-phase training process and can be
seamlessly integrated into various CL methods, including replay, parameter
regularization, distillation, and dynamic architecture techniques. In designing
FL, we use two distinct knowledge bases: one to enhance plasticity and another
to improve stability. FL ensures a more balanced model by utilizing both
knowledge bases to regularize model updates. Theoretically, we analyze how the
FL mechanism enhances the stability-plasticity balance. Empirically, FL
demonstrates tangible improvements over baseline methods within the same
training budget. By integrating FL into at least one representative baseline
from each CL category, we observed an average accuracy improvement of up to
4.91% in Class-Incremental and 3.51% in Task-Incremental settings on standard
image classification benchmarks. Additionally, measurements of the
stability-to-plasticity ratio confirm that FL effectively enhances this
balance. FL also outperforms state-of-the-art CL methods on more challenging
datasets like ImageNet.

</details>


### [170] [Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF](https://arxiv.org/abs/2506.00478)
*Hongjie Zhu,Zezheng Zhang,Zeyu Zhang,Yu Bai,Shimin Wen,Huazhang Wang,Daji Ergu,Ying Cai,Yang Zhao*

Main category: cs.LG

TL;DR: 提出了一种新的交流最优潮流求解器DDA-PIGCN，通过动态域适应与物理信息图卷积网络结合，解决了约束相关的问题，实验结果显示其性能优异。


<details>
  <summary>Details</summary>
Motivation: 当前的交流最优潮流求解器难以有效表示变量分布的复杂关系及其对应的最优解，约束建模的局限性限制了系统发展知识表示的能力。此外，单纯基于空间拓扑来建模电网进一步限制了额外先验知识的整合。

Method: 提出了一种新的方法DDA-PIGCN，通过将动态域适应与物理信息图卷积网络相结合，以解决约束相关的问题并构建一个包含时空特征的图学习框架。

Result: DDA-PIGCN 在多个IEEE标准测试案例中表现强劲，获得了从0.0011到0.0624的均绝对误差和从99.6%到100%的约束满足率。

Conclusion: DDA-PIGCN 是一种可靠而高效的交流最优潮流(AC-OPF)求解器，能够在多个IEEE标准测试案例中实现低均绝对误差和高约束满足率。

Abstract: Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generator
power outputs by utilizing the non-linear relationships between voltage
magnitudes and phase angles in a power system. However, current AC-OPF solvers
struggle to effectively represent the complex relationship between variable
distributions in the constraint space and their corresponding optimal
solutions. This limitation in constraint modeling restricts the system's
ability to develop diverse knowledge representations. Additionally, modeling
the power grid solely based on spatial topology further limits the integration
of additional prior knowledge, such as temporal information. To overcome these
challenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-Driven
Physics-Informed Graph Convolutional Network), a new method designed to address
constraint-related issues and build a graph-based learning framework that
incorporates spatiotemporal features. DDA-PIGCN improves consistency
optimization for features with varying long-range dependencies by applying
multi-layer, hard physics-informed constraints. It also uses a dynamic domain
adaptation learning mechanism that iteratively updates and refines key state
variables under predefined constraints, enabling precise constraint
verification. Moreover, it captures spatiotemporal dependencies between
generators and loads by leveraging the physical structure of the power grid,
allowing for deep integration of topological information across time and space.
Extensive comparative and ablation studies show that DDA-PIGCN delivers strong
performance across several IEEE standard test cases (such as case9, case30, and
case300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 and
constraint satisfaction rates between 99.6% and 100%, establishing it as a
reliable and efficient AC-OPF solver.

</details>


### [171] [BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation](https://arxiv.org/abs/2506.00482)
*Eunsu Kim,Haneul Yoo,Guijin Son,Hitesh Patel,Amit Agarwal,Alice Oh*

Main category: cs.LG

TL;DR: 引入BenchHub，一个动态基准库，用于更有效地评估大型语言模型，支持领域特定的灵活评估。


<details>
  <summary>Details</summary>
Motivation: 由于现有的数据集散乱且难以管理，特别是在需要特定领域或需求的评估时困难重重，因此本文引入了BenchHub，以帮助研究人员和开发人员更有效地评估大型语言模型。

Method: 在论文中，通过多项实验展示了模型在不同领域子集上的性能差异，强调了领域感知基准的重要性。BenchHub自动聚合和分类来自不同领域的基准数据集，并支持持续更新和可扩展的数据管理。

Result: BenchHub集成了38个基准的303K问题，支持灵活可定制的评估方法，适应各种领域或使用案例，是推动大型语言模型评估研究的重要基础设施。

Conclusion: BenchHub是一个动态的基准库，能够更有效地评估大型语言模型，促进更好的数据集重用、更透明的模型比较和更容易识别现有基准中的不足之处。

Abstract: As large language models (LLMs) continue to advance, the need for up-to-date
and well-organized benchmarks becomes increasingly critical. However, many
existing datasets are scattered, difficult to manage, and make it challenging
to perform evaluations tailored to specific needs or domains, despite the
growing importance of domain-specific models in areas such as math or code. In
this paper, we introduce BenchHub, a dynamic benchmark repository that empowers
researchers and developers to evaluate LLMs more effectively. BenchHub
aggregates and automatically classifies benchmark datasets from diverse
domains, integrating 303K questions across 38 benchmarks. It is designed to
support continuous updates and scalable data management, enabling flexible and
customizable evaluation tailored to various domains or use cases. Through
extensive experiments with various LLM families, we demonstrate that model
performance varies significantly across domain-specific subsets, emphasizing
the importance of domain-aware benchmarking. We believe BenchHub can encourage
better dataset reuse, more transparent model comparisons, and easier
identification of underrepresented areas in existing benchmarks, offering a
critical infrastructure for advancing LLM evaluation research.

</details>


### [172] [It Takes a Good Model to Train a Good Model: Generalized Gaussian Priors for Optimized LLMs](https://arxiv.org/abs/2506.00486)
*Jun Wu,Yirong Xiong,Jiangtao Wen,Yuxing Han*

Main category: cs.LG

TL;DR: The paper presents a framework using GG distributions for LLM optimization, improving model size and speed with minimal performance loss by focusing on statistical modeling.


<details>
  <summary>Details</summary>
Motivation: Despite advancements in LLMs, little attention has been given to the statistical distribution of model parameters and their influence on various aspects of the models. The motivation is to enhance the efficiency and scalability of LLMs through principled statistical modeling.

Method: The method involves a GG-based initialization scheme for faster convergence and improved accuracy, a post-training regularization method called DeepShape to match weight distributions to a GG profile, and an RF8 floating-point format for efficient BackSlash training.

Result: Experiments show that the framework generates smaller and faster models with maintained or improved performance compared to standard training methods, with parameter reduction of up to 90% and minimal performance loss.

Conclusion: Our framework consistently yields smaller and faster models that match or outperform standard training baselines by utilizing a GG-based approach that focuses on statistical modeling for efficient and scalable LLM development.

Abstract: Despite rapid advancements in the research and deployment of large language
models (LLMs), the statistical distribution of model parameters, as well as
their influence on initialization, training dynamics, and downstream
efficiency, has received surprisingly little attention. A recent work
introduced BackSlash, a training-time compression algorithm. It first
demonstrated that pre-trained LLM parameters follow generalized Gaussian
distributions (GGDs) better. By optimizing GG priors during training, BackSlash
can reduce parameters by up to 90\% with minimal performance loss. Building on
this foundational insight, we propose a unified, end-to-end framework for LLM
optimization based on the GG model. Our contributions are threefold: (1)
GG-based initialization scheme that aligns with the statistical structure of
trained models, resulting in faster convergence and improved accuracy; (2)
DeepShape, a post-training regularization method that reshapes weight
distributions to match a GG profile, improving compressibility with minimized
degradation in performance; and (3) RF8, a compact and hardware-efficient 8-bit
floating-point format designed for GG-distributed-initialized BackSlash
training, enabling low-cost inference without compromising accuracy.
Experiments across diverse model architectures show that our framework
consistently yields smaller and faster models that match or outperform standard
training baselines. By grounding LLM development in principled statistical
modeling, this work forges a new path toward efficient, scalable, and
hardware-aware AI systems. The code is available on our project page:
https://huggingface.co/spaces/shifeng3711/gg_prior.

</details>


### [173] [FLoE: Fisher-Based Layer Selection for Efficient Sparse Adaptation of Low-Rank Experts](https://arxiv.org/abs/2506.00495)
*Xinyi Wang,Lirong Gao,Haobo Wang,Yiming Zhang,Junbo Zhao*

Main category: cs.LG

TL;DR: FLoE is a PEFT method that enhances fine-tuning efficiency by using Fisher scoring for important layer identification and Bayesian optimization for rank allocation, outperforming traditional methods in efficiency and accuracy, especially in resource-limited settings.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve the efficiency of PEFT methods by addressing the issue of redundant parameter allocation and suboptimal adaptation efficiency in existing methods, which do not consider the varying contributions of different layers and task-specific rank needs.

Method: FLoE introduces a two-fold method: a Fisher information-based scoring mechanism for identifying important layers for sparse adapter deployment, and a Bayesian optimization-driven rank allocator to determine the optimal LoRA ranks without extensive searching.

Result: FLoE achieves better efficiency-accuracy trade-offs across multiple large language models and benchmarks, particularly in environments with resource constraints.

Conclusion: FLoE provides a more efficient approach to fine-tune large language models by using a Fisher information-based method to identify important layers and a Bayesian optimization technique to allocate ranks. This makes it more suited for environments with limited resources.

Abstract: Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a widely
adopted strategy for adapting pre-trained Large Language Models (LLMs) to
downstream tasks, significantly reducing memory and computational costs.
However, most existing PEFT techniques uniformly deploy LoRA adapters across
all layers, disregarding the intrinsic heterogeneity of layer contributions and
task-specific rank requirements. This uniform paradigm leads to redundant
parameter allocation and suboptimal adaptation efficiency. To address these
limitations, we propose FLoE, a novel PEFT framework that introduces two key
innovations: (i) a Fisher information-guided importance scoring mechanism to
dynamically identify task-critical transformer layers for MoE-based low-rank
adaptation, enabling sparse adapter deployment; and (ii) a Bayesian
optimization-driven rank allocator that automatically determines optimal LoRA
ranks on specific datasets without exhaustive grid search. Extensive
experiments across diverse LLMs and benchmarks reveal that FLoE achieves
impressive efficiency-accuracy trade-offs, making FLoE particularly
advantageous in resource-constrained environments that necessitate rapid
adaptation.

</details>


### [174] [Federated learning framework for collaborative remaining useful life prognostics: an aircraft engine case study](https://arxiv.org/abs/2506.00499)
*Diogo Landau,Ingeborg de Pater,Mihaela Mitici,Nishant Saurabh*

Main category: cs.LG

TL;DR: 该研究提出了一个联邦学习框架，通过协作提升航空发动机的剩余寿命预测精度，同时通过新方法提升对噪声数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 航空发动机等复杂系统需要准确的剩余寿命预测，然而由于数据隐私问题，各航空公司不愿共享其数据，导致难以获取足够的故障样本来进行有效的预测。

Method: 开发了一个协作联邦学习框架，提出四种新的参数聚合方法，使用去中心化验证程序进行验证，并通过N-CMAPSS数据集进行训练实验。

Result: 联邦学习框架较独立开发模型能更准确地预测剩余寿命，尤其在六家航空公司中有五家取得显著提升。新提出的方法也增强了框架应对噪声数据的能力。

Conclusion: 联邦学习框架能在不共享数据的情况下实现多航空公司协作，提升了发动机剩余寿命预测的准确性，并通过新颖的参数聚合方法增强了其对噪声数据的鲁棒性。

Abstract: Complex systems such as aircraft engines are continuously monitored by
sensors. In predictive aircraft maintenance, the collected sensor measurements
are used to estimate the health condition and the Remaining Useful Life (RUL)
of such systems. However, a major challenge when developing prognostics is the
limited number of run-to-failure data samples. This challenge could be overcome
if multiple airlines would share their run-to-failure data samples such that
sufficient learning can be achieved. Due to privacy concerns, however, airlines
are reluctant to share their data in a centralized setting. In this paper, a
collaborative federated learning framework is therefore developed instead.
Here, several airlines cooperate to train a collective RUL prognostic machine
learning model, without the need to centrally share their data. For this, a
decentralized validation procedure is proposed to validate the prognostics
model without sharing any data. Moreover, sensor data is often noisy and of low
quality. This paper therefore proposes four novel methods to aggregate the
parameters of the global prognostic model. These methods enhance the robustness
of the FL framework against noisy data. The proposed framework is illustrated
for training a collaborative RUL prognostic model for aircraft engines, using
the N-CMAPSS dataset. Here, six airlines are considered, that collaborate in
the FL framework to train a collective RUL prognostic model for their
aircraft's engines. When comparing the proposed FL framework with the case
where each airline independently develops their own prognostic model, the
results show that FL leads to more accurate RUL prognostics for five out of the
six airlines. Moreover, the novel robust aggregation methods render the FL
framework robust to noisy data samples.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [175] [Behavioral alignment in social networks](https://arxiv.org/abs/2506.00046)
*Yu Xia,Alex McAvoy,Qi Su*

Main category: physics.soc-ph

TL;DR: 本文探讨了鱼群和人群等大型群体的有序行为，研究了个体的自我探索学习对群体行为的影响，发现网络结构尤其是平均路径长度对系统的均衡时间和均衡状态数量有重大影响。


<details>
  <summary>Details</summary>
Motivation: 理解简单规则如何塑造复杂群体动态一直是一个重大的科学挑战，因此本文旨在探讨自我探索和内省学习在群体行为中的作用，以及网络结构对行为模式的影响。

Method: 通过分析网络化的系统，研究个体的协调和反协调行为与网络结构、系统动力学和行为模式的整体效应。

Result: 研究发现，均衡状态的数量可能非常庞大，甚至随着网络结构的小变化而呈指数增长。此外，网络结构显著影响平均均衡时间。研究表明，这些复杂变化可以通过一个简单的网络特征，即平均路径长度来概括。

Conclusion: 研究揭示了网络结构对个体协调和反协调行为影响的重要性，尤其是平均路径长度对均衡时间和均衡状态数量的决定性作用。

Abstract: The orderly behaviors observed in large-scale groups, such as fish schooling
and the organized movement of crowds, are both ubiquitous and essential for the
survival and stability of these systems. Such complex collective behaviors
often emerge from simple local interactions and strategy adjustments among
individuals. Understanding how these basic rules shape complex group dynamics
has long been a significant scientific challenge. Historically, research has
predominantly focused on imitation and social learning, where individuals adopt
the strategies of more successful peers to refine their behavior. However, in
recent years, an alternative learning approach, self-exploration and
introspective learning, has garnered increasing attention. In this paradigm,
individuals assess their own circumstances and select strategies that best
align with their specific conditions. Two primary forms of this learning are
coordination and anti-coordination, where individuals align with and diverge
from the local majority, respectively. In this study, we analyze networked
systems of coordinating and anti-coordinating individuals, exploring the
combined effects of system dynamics, network structure, and behavioral
patterns. We address several practical questions, including the number of
equilibria, their characteristics, the equilibrium time, and the resilience of
systems. We find that the number of equilibrium states can be extremely large,
even increasing exponentially with minor alternations to the network structure.
Moreover, the network structure has a significant impact on the average
equilibrium time. Despite the complexity of these findings, variations can be
captured by a single, simple network characteristic: the average path length.
Our research offers valuable insights into how modifications to the interaction
structure can influence behavioral alignment in social networks.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [176] [Using LLMs to Advance the Cognitive Science of Collectives](https://arxiv.org/abs/2506.00052)
*Ilia Sucholutsky,Katherine M. Collins,Nori Jacoby,Bill D. Thompson,Robert D. Hawkins*

Main category: q-bio.NC

TL;DR: LLMs在集体认知研究中的应用潜力以及相应风险。


<details>
  <summary>Details</summary>
Motivation: LLMs在研究个人认知方面已经取得了显著成果，但在集体认知领域的应用仍待开发。

Method: 文章主要介绍了如何利用LLMs来研究集体认知的复杂性。

Result: 通过介绍LLMs可能解决集体研究中的复杂性，文章指出其应用的潜在风险。

Conclusion: 论文总结了LLMs对集体认知的潜在影响以及亟需发展新的研究方法来应对相关风险。

Abstract: LLMs are already transforming the study of individual cognition, but their
application to studying collective cognition has been underexplored. We lay out
how LLMs may be able to address the complexity that has hindered the study of
collectives and raise possible risks that warrant new methods.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [177] [Improving Multi-Vehicle Perception Fusion with Millimeter-Wave Radar Assistance](https://arxiv.org/abs/2506.00837)
*Zhiqing Luo,Yi Wang,Yingying He,Wei Wang*

Main category: cs.RO

TL;DR: MMatch uses mmWave radar for real-time, accurate perception fusion, achieving decimeter accuracy in 59ms, improving autonomous driving reliability.


<details>
  <summary>Details</summary>
Motivation: Existing methods relying on high-density LiDAR data or fine-grained image features fail to meet the accuracy, real-time, and adaptability requirements for autonomous driving.

Method: The paper presents MMatch, a lightweight system that uses mmWave radar point clouds to enable accurate and real-time perception fusion.

Result: Experiments with over 15,000 radar point cloud pairs show that MMatch achieves decimeter-level accuracy within 59ms.

Conclusion: MMatch significantly improves the reliability of autonomous driving by achieving decimeter-level accuracy within 59ms.

Abstract: Cooperative perception enables vehicles to share sensor readings and has
become a new paradigm to improve driving safety, where the key enabling
technology for realizing this vision is to real-time and accurately align and
fuse the perceptions. Recent advances to align the views rely on high-density
LiDAR data or fine-grained image feature representations, which however fail to
meet the requirements of accuracy, real-time, and adaptability for autonomous
driving. To this end, we present MMatch, a lightweight system that enables
accurate and real-time perception fusion with mmWave radar point clouds. The
key insight is that fine-grained spatial information provided by the radar
present unique associations with all the vehicles even in two separate views.
As a result, by capturing and understanding the unique local and global
position of the targets in this association, we can quickly find out all the
co-visible vehicles for view alignment. We implement MMatch on both the
datasets collected from the CARLA platform and the real-world traffic with over
15,000 radar point cloud pairs. Experimental results show that MMatch achieves
decimeter-level accuracy within 59ms, which significantly improves the
reliability for autonomous driving.

</details>


### [178] [Robust and Safe Multi-Agent Reinforcement Learning Framework with Communication for Autonomous Vehicles](https://arxiv.org/abs/2506.00982)
*Keshawn Smith,Zhili Zhang,H M Sabbir Ahmad,Ehsan Sabouni,Maniak Mondal,Song Han,Wenchao Li,Fei Miao*

Main category: cs.RO

TL;DR: 引入了RSR-RSMARL框架，通过促进行为适应和通信来提升多代理系统在模拟和硬件中的安全性和协调性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度多代理强化学习被证明在多机器人问题模拟中效果显著，而车对车通信技术的发展为进一步提升系统的安全性提供了机会。然而，将模拟器训练的MARL策略零样本转移至硬件动态系统仍具挑战性，并且如何利用通信和共享信息的多代理强化学习在硬件上应用有限。本论文提出新的方法以解决模拟与物理状态的差异、系统状态和模型的不确定性、实际共享信息设计，以及在模拟和硬件中需要的安全保证。

Method: 引入了一种新的鲁棒和安全的MARL框架RSR-RSMARL，该框架支持在多代理系统中通过通信进行Real-Sim-Real（RSR）策略适应，包括模拟和硬件演示。框架结合了状态（包括代理间共享的状态信息）和动作表示，使用鲁棒的MARL算法进行训练，以实现硬件的零样本传输。

Result: 实验结果显示，在具有V2V通信的1/10刻度自动驾驶车辆上，RSR-RSMARL框架能够在多种配置下提升驾驶安全性和协调性。

Conclusion: RSR-RSMARL框架可以增强驾驶安全性和多代理协调能力，强调了设计稳健策略表示和模块化安全架构以实现可扩展、通用的多代理自治RSR传输的重要性。

Abstract: Deep multi-agent reinforcement learning (MARL) has been demonstrated
effectively in simulations for many multi-robot problems. For autonomous
vehicles, the development of vehicle-to-vehicle (V2V) communication
technologies provide opportunities to further enhance safety of the system.
However, zero-shot transfer of simulator-trained MARL policies to hardware
dynamic systems remains challenging, and how to leverage communication and
shared information for MARL has limited demonstrations on hardware. This
problem is challenged by discrepancies between simulated and physical states,
system state and model uncertainties, practical shared information design, and
the need for safety guarantees in both simulation and hardware. This paper
introduces RSR-RSMARL, a novel Robust and Safe MARL framework that supports
Real-Sim-Real (RSR) policy adaptation for multi-agent systems with
communication among agents, with both simulation and hardware demonstrations.
RSR-RSMARL leverages state (includes shared state information among agents) and
action representations considering real system complexities for MARL
formulation. The MARL policy is trained with robust MARL algorithm to enable
zero-shot transfer to hardware considering the sim-to-real gap. A safety shield
module using Control Barrier Functions (CBFs) provides safety guarantee for
each individual agent. Experiment results on F1/10th-scale autonomous vehicles
with V2V communication demonstrate the ability of RSR-RSMARL framework to
enhance driving safety and coordination across multiple configurations. These
findings emphasize the importance of jointly designing robust policy
representations and modular safety architectures to enable scalable,
generalizable RSR transfer in multi-agent autonomy.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [179] [Two-Sided Manipulation Games in Stable Matching Markets](https://arxiv.org/abs/2506.00554)
*Hadi Hosseini,Grzegorz Lisowski,Shraddha Pathak*

Main category: cs.GT

TL;DR: 研究两方匹配市场操控，引入同谋操控游戏，设计算法找纯策略纳什均衡，扩展到其他操控游戏并进行实验评估。


<details>
  <summary>Details</summary>
Motivation: 研究两方匹配市场中的非合作博弈操控，以帮助特定个体获得更好匹配及探索其对应均衡的性质。

Method: 我们提出并研究了同谋操控游戏，通过算法设计提供了一种多项式时间算法来找到该游戏的纯策略纳什均衡。同时将分析技术应用于其他操控游戏。

Result: 提供了一个多项式时间算法来找到纯策略纳什均衡，证明了算法总能产生稳定匹配，虽然不是每个纳什均衡都能对应稳定匹配。

Conclusion: 我们引入了同谋操控游戏，并且为找到纯策略纳什均衡提供了多项式时间算法，尽管并不是每个纳什均衡都对应于稳定匹配。实验评估显示，理论发现可以应用于匹配市场中的其他操控游戏，并考察了均衡的不同属性如代理人的福利。

Abstract: The Deferred Acceptance (DA) algorithm is an elegant procedure for finding a
stable matching in two-sided matching markets. It ensures that no pair of
agents prefers each other to their matched partners. In this work, we initiate
the study of two-sided manipulations in matching markets as non-cooperative
games. We introduce the accomplice manipulation game, where a man misreports to
help a specific woman obtain a better partner, whenever possible. We provide a
polynomial time algorithm for finding a pure strategy Nash equilibrium (NE) and
show that our algorithm always yields a stable matching - although not every
Nash equilibrium corresponds to a stable matching. Additionally, we show how
our analytical techniques for the accomplice manipulation game can be applied
to other manipulation games in matching markets, such as one-for-many and the
standard self-manipulation games. We complement our theoretical findings with
empirical evaluations of different properties of the resulting NE, such as the
welfare of the agents.

</details>


### [180] [Online Competitive Information Gathering for Partially Observable Trajectory Games](https://arxiv.org/abs/2506.01927)
*Mel Krusniak,Hang Xu,Parker Palermo,Forrest Laine*

Main category: cs.GT

TL;DR: 该研究提出一种在部分可观察随机游戏（POSG）中进行在线轨迹规划的方法，通过粒子估计和随机梯度游戏，成功测试于追逐-逃避和仓库场景，展示了优于被动竞争者的信息收集能力。


<details>
  <summary>Details</summary>
Motivation: 博弈论中的智能体必须制定计划以优化其对对手的信息收集。这些问题通过部分可观察随机游戏（POSG）建模，但在没有大量离线计算或对每个玩家的信念顺序做出假设的情况下，在完全连续的POSG中进行规划是不可行的。

Method: 我们提出了一种有限历史/视界细化的POSG，通过一系列近似，呈现了一种在线计算合理轨迹规划的方法，该方法利用基于粒子的联合状态空间估计并执行随机梯度游戏。我们还提供了在个体代理上部署这种方法所需的必要调整。

Result: 该方法在连续追逐-逃避和仓库取物场景（以及扩展到N > 2个玩家和更复杂环境的视觉和物理障碍）中进行了测试，证明了主动信息收集的证据，并且优于被动竞争者。

Conclusion: 通过在连续追逐-逃避和仓库取物场景中的测试，该方法展示了主动信息收集的证据，并且表现优于被动竞争者。

Abstract: Game-theoretic agents must make plans that optimally gather information about
their opponents. These problems are modeled by partially observable stochastic
games (POSGs), but planning in fully continuous POSGs is intractable without
heavy offline computation or assumptions on the order of belief maintained by
each player. We formulate a finite history/horizon refinement of POSGs which
admits competitive information gathering behavior in trajectory space, and
through a series of approximations, we present an online method for computing
rational trajectory plans in these games which leverages particle-based
estimations of the joint state space and performs stochastic gradient play. We
also provide the necessary adjustments required to deploy this method on
individual agents. The method is tested in continuous pursuit-evasion and
warehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more
complex environments with visual and physical obstacles), demonstrating
evidence of active information gathering and outperforming passive competitors.

</details>
