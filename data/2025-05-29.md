<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.MA](#cs.MA) [Total: 9]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.NI](#cs.NI) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models](https://arxiv.org/abs/2505.21523)
*Chengzhi Liu,Zhongxing Xu,Qingyue Wei,Juncheng Wu,James Zou,Xin Eric Wang,Yuyin Zhou,Sheng Liu*

Main category: cs.CL

TL;DR: 模型在生成推理链时可能会出现幻觉，引入RH-AUC和RH-Bench以评估推理与幻觉的权衡，发现更大型的模型通常实现更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 探讨推理链长度对视觉输入关注度的影响，以及这种影响如何导致幻觉现象。

Method: 引入RH-AUC指标来量化模型随推理长度变化的感知准确性，并发布RH-Bench诊断基准以评估推理能力与幻觉之间的权衡。

Result: 分析表明，模型在推理和感知之间的平衡受训练数据的类型和领域影响更大，大型模型在这方面表现更佳。

Conclusion: 更大的模型通常在推理和感知之间实现更好的平衡，并且这种平衡受训练数据的类型和领域影响更大，而不是它的总体数量。

Abstract: Test-time compute has empowered multimodal large language models to generate
extended reasoning chains, yielding strong performance on tasks such as
multimodal math reasoning. However, this improved reasoning ability often comes
with increased hallucination: as generations become longer, models tend to
drift away from image-grounded content and rely more heavily on language
priors. Attention analysis shows that longer reasoning chains lead to reduced
focus on visual inputs, which contributes to hallucination. To systematically
study this phenomenon, we introduce RH-AUC, a metric that quantifies how a
model's perception accuracy changes with reasoning length, allowing us to
evaluate whether the model preserves visual grounding during reasoning. We also
release RH-Bench, a diagnostic benchmark that spans a variety of multimodal
tasks, designed to assess the trade-off between reasoning ability and
hallucination. Our analysis reveals that (i) larger models typically achieve a
better balance between reasoning and perception, and (ii) this balance is
influenced more by the types and domains of training data than by its overall
volume. These findings underscore the importance of evaluation frameworks that
jointly consider both reasoning quality and perceptual fidelity.

</details>


### [2] [Loquacious Set: 25,000 Hours of Transcribed and Diverse English Speech Recognition Data for Research and Commercial Use](https://arxiv.org/abs/2505.21578)
*Titouan Parcollet,Yuan Tseng,Shucong Zhang,Rogier van Dalen*

Main category: cs.CL

TL;DR: 介绍了一个包含25,000小时多样性英文语音的新数据集Loquacious Set，旨在解决现有数据集的局限性，为学术和工业界提供支持。


<details>
  <summary>Details</summary>
Motivation: 目前的语音识别数据集如LibriSpeech、MOSEL、YODAS等存在如许可证不通用、转录不可靠、音频数据错误或缺乏评估集等限制，影响了工业和学术界的研究合作和比较。因此需要一个更完善的数据集。

Method: 提出了Loquacious Set，这是一个包含25,000小时精选语音的集成，涵盖了数十万名拥有不同口音的说话者和多种语音类型（朗读、自发、演讲、清晰、嘈杂）。

Result: Loquacious Set能够在商业上使用，拥有丰富的口音和语音种类，为学术和工业界提供了构建现实语音识别系统的基础。

Conclusion: Loquacious Set作为一个商业可用的英语语音数据集，可以被学术界和工业界的研究人员用于构建真实场景中的自动语音识别系统。

Abstract: Automatic speech recognition (ASR) research is driven by the availability of
common datasets between industrial researchers and academics, encouraging
comparisons and evaluations. LibriSpeech, despite its long success as an ASR
benchmark, is now limited by its size and focus on clean, read speech, leading
to near-zero word error rates. More recent datasets, including MOSEL, YODAS,
Gigaspeech, OWSM, Libriheavy or People's Speech suffer from major limitations
including licenses that researchers in the industry cannot use, unreliable
transcriptions, incorrect audio data, or the lack of evaluation sets. This work
presents the Loquacious Set, a 25,000-hour curated collection of commercially
usable English speech. Featuring hundreds of thousands of speakers with diverse
accents and a wide range of speech types (read, spontaneous, talks, clean,
noisy), the Loquacious Set is designed to work for academics and researchers in
the industry to build ASR systems in real-world scenarios.

</details>


### [3] [Rethinking Data Mixture for Large Language Models: A Comprehensive Survey and New Perspectives](https://arxiv.org/abs/2505.21598)
*Yajiao Liu,Congliang Chen,Junchi Yang,Ruoyu Sun*

Main category: cs.CL

TL;DR: 对现有数据混合方法进行细致分类，并总结其问题及算法，讨论优缺点和关键挑战。


<details>
  <summary>Details</summary>
Motivation: 确定跨不同数据域的权重，以在有限的计算资源下训练最佳表现的模型。

Method: 本文提出了现有方法的细粒度分类，并对每种方法进行了问题的表述，总结了代表算法，明确了它们之间的关系和区别。

Result: 为线下方法提出了基于启发式、算法和函数拟合的分类；对于线上方法，提出了在线极小化-极大化优化、在线混合法则及其他方法的分类，同时讨论了它们之间的联系和差异。

Conclusion: 本文总结了现有的数据混合方法，并通过对比分析不同方法的优势和劣势，指出了数据混合领域的关键挑战，为在有限计算资源下训练最佳模型提供了指导。

Abstract: Training large language models with data collected from various domains can
improve their performance on downstream tasks. However, given a fixed training
budget, the sampling proportions of these different domains significantly
impact the model's performance. How can we determine the domain weights across
different data domains to train the best-performing model within constrained
computational resources? In this paper, we provide a comprehensive overview of
existing data mixture methods. First, we propose a fine-grained categorization
of existing methods, extending beyond the previous offline and online
classification. Offline methods are further grouped into heuristic-based,
algorithm-based, and function fitting-based methods. For online methods, we
categorize them into three groups: online min-max optimization, online mixing
law, and other approaches by drawing connections with the optimization
frameworks underlying offline methods. Second, we summarize the problem
formulations, representative algorithms for each subtype of offline and online
methods, and clarify the relationships and distinctions among them. Finally, we
discuss the advantages and disadvantages of each method and highlight key
challenges in the field of data mixture.

</details>


### [4] [R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing](https://arxiv.org/abs/2505.21600)
*Tianyu Fu,Yi Ge,Yichen You,Enshu Liu,Zhihang Yuan,Guohao Dai,Shengen Yan,Huazhong Yang,Yu Wang*

Main category: cs.CL

TL;DR: R2R通过智能路由令牌改善语言模型性能，提升效率且保持高准确性，在重要任务上超越了较大型模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然具备强大的推理能力，但其推理成本高，导致部署困难。小语言模型虽能提高效率，但其性能因无法有效跟随大语言模型的推理路径而受损。

Method: 我们引入一种称为R2R的神经元令牌路由方法，自动识别和处理关键的路径分歧令牌，并运行轻量级路由器对这些令牌进行特定处理。

Result: R2R在平均激活参数规模为5.6B的情况下，精度超过了R1-7B的1.6倍，表现优于R1-14B模型。同时，相较于R1-32B，R2R实现了2.8倍的时钟速度提升，且性能相当。

Conclusion: 我们提出的R2R方法在性能和效率上均取得显著提升，尤其是在算术、编程和问答等复杂基准测试中表现优异，超越了一些更大规模的模型。

Abstract: Large Language Models (LLMs) achieve impressive reasoning capabilities at the
cost of substantial inference overhead, posing substantial deployment
challenges. Although distilled Small Language Models (SLMs) significantly
enhance efficiency, their performance suffers as they fail to follow LLMs'
reasoning paths. Luckily, we reveal that only a small fraction of tokens
genuinely diverge reasoning paths between LLMs and SLMs. Most generated tokens
are either identical or exhibit neutral differences, such as minor variations
in abbreviations or expressions. Leveraging this insight, we introduce **Roads
to Rome (R2R)**, a neural token routing method that selectively utilizes LLMs
only for these critical, path-divergent tokens, while leaving the majority of
token generation to the SLM. We also develop an automatic data generation
pipeline that identifies divergent tokens and generates token-level routing
labels to train the lightweight router. We apply R2R to combine R1-1.5B and
R1-32B models from the DeepSeek family, and evaluate on challenging math,
coding, and QA benchmarks. With an average activated parameter size of 5.6B,
R2R surpasses the average accuracy of R1-7B by 1.6x, outperforming even the
R1-14B model. Compared to R1-32B, it delivers a 2.8x wall-clock speedup with
comparable performance, advancing the Pareto frontier of test-time scaling
efficiency. Our code is available at https://github.com/thu-nics/R2R.

</details>


### [5] [How does Misinformation Affect Large Language Model Behaviors and Preferences?](https://arxiv.org/abs/2505.21608)
*Miao Peng,Nuo Chen,Jianheng Tang,Jia Li*

Main category: cs.CL

TL;DR: 提出MisBench基准以评估和改善大型语言模型在应对误信息时的表现，并提出新方法以增强识别能力。


<details>
  <summary>Details</summary>
Motivation: 为了填补细粒度分析缺乏的空白，研究LLMs在特定方面受误信息影响的程度。

Method: 提出MisBench，这是最大的评估LLMs对误信息行为和知识偏好基准，包含10,346,712条误信息，同时考虑知识冲突和风格变化。提出Reconstruct to Discriminate (RtD) 方法来增强LLMs识别误信息的能力。

Result: 研究表明LLMs在识别误信息能力上表现出色，但仍易受知识冲突和风格变化影响。

Conclusion: MisBench能够作为有效基准来评估LLM检测器并提高其可靠性，为现实应用提供保障。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities in
knowledge-intensive tasks, while they remain vulnerable when encountering
misinformation. Existing studies have explored the role of LLMs in combating
misinformation, but there is still a lack of fine-grained analysis on the
specific aspects and extent to which LLMs are influenced by misinformation. To
bridge this gap, we present MisBench, the current largest and most
comprehensive benchmark for evaluating LLMs' behavior and knowledge preference
toward misinformation. MisBench consists of 10,346,712 pieces of
misinformation, which uniquely considers both knowledge-based conflicts and
stylistic variations in misinformation. Empirical results reveal that while
LLMs demonstrate comparable abilities in discerning misinformation, they still
remain susceptible to knowledge conflicts and stylistic variations. Based on
these findings, we further propose a novel approach called Reconstruct to
Discriminate (RtD) to strengthen LLMs' ability to detect misinformation. Our
study provides valuable insights into LLMs' interactions with misinformation,
and we believe MisBench can serve as an effective benchmark for evaluating
LLM-based detectors and enhancing their reliability in real-world applications.
Codes and data are available at https://github.com/GKNL/MisBench.

</details>


### [6] [Iterative Corpus Refinement for Materials Property Prediction Based on Scientific Texts](https://arxiv.org/abs/2505.21646)
*Lei Zhang,Markus Stricker*

Main category: cs.CL

TL;DR: 提出了一种迭代框架，通过文档选择和Word2Vec模型训练来加速材料发现，成功预测并验证了氧还原、氢进化和氧进化反应中的高性能材料。


<details>
  <summary>Details</summary>
Motivation: 材料的发现和优化受到可能的元素组合和相关属性几乎无限数量的限制，被称为“组合爆炸”。

Method: 提出一种迭代框架，通过战略性选择多样性最大的文档来细化科学语料库，训练Word2Vec模型，并监控嵌入空间中成分-属性相关性的收敛。

Result: 该方法成功预测了高性能氧还原（ORR）、氢进化（HER）和氧进化（OER）反应材料的组成，并通过实验室中电催化性能的实验测量验证了最高性能的组成。

Conclusion: 该研究验证了迭代语料库细化方法加速材料发现和优化的潜力，提供了一种在数据稀缺或不存在的情况下对大规模成分空间进行筛选的可扩展和高效工具。

Abstract: The discovery and optimization of materials for specific applications is
hampered by the practically infinite number of possible elemental combinations
and associated properties, also known as the `combinatorial explosion'. By
nature of the problem, data are scarce and all possible data sources should be
used. In addition to simulations and experimental results, the latent knowledge
in scientific texts is not yet used to its full potential. We present an
iterative framework that refines a given scientific corpus by strategic
selection of the most diverse documents, training Word2Vec models, and
monitoring the convergence of composition-property correlations in embedding
space. Our approach is applied to predict high-performing materials for oxygen
reduction (ORR), hydrogen evolution (HER), and oxygen evolution (OER) reactions
for a large number of possible candidate compositions. Our method successfully
predicts the highest performing compositions among a large pool of candidates,
validated by experimental measurements of the electrocatalytic performance in
the lab. This work demonstrates and validates the potential of iterative corpus
refinement to accelerate materials discovery and optimization, offering a
scalable and efficient tool for screening large compositional spaces where
reliable data are scarce or non-existent.

</details>


### [7] [Explainability of Large Language Models using SMILE: Statistical Model-agnostic Interpretability with Local Explanations](https://arxiv.org/abs/2505.21657)
*Zeinab Dehghani,Koorosh Aslansefat,Adil Khan,Mohammed Naveed Akram*

Main category: cs.CL

TL;DR: SMILE是一种提高大型语言模型决策透明度的新方法，它通过改变输入来显示对模型响应影响最大的词，并已在多个模型上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型如何做出回应的决策透明度问题，提高在信任和责任领域的可控性。

Method: SMILE通过微调输入来测量输出变化，进而突出对模型反应影响最大的词，并创建简易的视觉热图。

Result: SMILE在多个领先的LLMs上进行测试，展示出在准确性、一致性、稳定性和保真度方面可以提供清晰和可靠的解释。

Conclusion: SMILE使得大型语言模型更透明、更可信。

Abstract: Large language models like GPT, LLAMA, and Claude have become incredibly
powerful at generating text, but they are still black boxes, so it is hard to
understand how they decide what to say. That lack of transparency can be
problematic, especially in fields where trust and accountability matter. To
help with this, we introduce SMILE, a new method that explains how these models
respond to different parts of a prompt. SMILE is model-agnostic and works by
slightly changing the input, measuring how the output changes, and then
highlighting which words had the most impact. Create simple visual heat maps
showing which parts of a prompt matter the most. We tested SMILE on several
leading LLMs and used metrics such as accuracy, consistency, stability, and
fidelity to show that it gives clear and reliable explanations. By making these
models easier to understand, SMILE brings us one step closer to making AI more
transparent and trustworthy.

</details>


### [8] [Rethinking the Outlier Distribution in Large Language Models: An In-depth Study](https://arxiv.org/abs/2505.21670)
*Rahul Raman,Khushi Sharma,Sai Qian Zhang*

Main category: cs.CL

TL;DR: 该论文调查大型语言模型中的异常值并提出方法以减少异常值对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 由于异常值对语言模型性能的量化和压缩方面产生显著影响，因此识别和解决这些异常值有助于提高量化过程的准确性和效率。

Method: 对大型语言模型(LLMs)中的异常值进行深入调查，分析异常值形成机制。提出可能的策略以减少异常值的发生。最终提出了一些有效的方法，以最小的精度损失消除大多数大规模激活和通道异常。

Result: 提出了一些减少异常发生的策略并引入了高效的方法消除异常值，对精度的影响降到了最低。

Conclusion: 通过研究，提出了一些有效的方法来消除大多数大规模激活和通道异常，并且仅对精度造成最小影响。

Abstract: Investigating outliers in large language models (LLMs) is crucial due to
their significant impact on various aspects of LLM performance, including
quantization and compression. Outliers often cause considerable quantization
errors, leading to degraded model performance. Identifying and addressing these
outliers can enhance the accuracy and efficiency of the quantization process,
enabling smoother deployment on edge devices or specialized hardware. Recent
studies have identified two common types of outliers in LLMs: massive
activations and channel-wise outliers. While numerous quantization algorithms
have been proposed to mitigate their effects and maintain satisfactory
accuracy, few have thoroughly explored the root causes of these outliers in
depth. In this paper, we conduct a comprehensive investigation into the
formation mechanisms of these outliers and propose potential strategies to
mitigate their occurrence. Ultimately, we introduce some efficient approaches
to eliminate most massive activations and channel-wise outliers with minimal
impact on accuracy.

</details>


### [9] [Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development](https://arxiv.org/abs/2505.21898)
*Rennai Qiu,Chen Qian,Ran Li,Yufan Dang,Weize Chen,Cheng Yang,Yingli Zhang,Ye Tian,Xuantang Xiong,Lei Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: 提出了一种资源意识的多代理系统Co-Saving，它利用经验知识和"快捷路径"来提高效率和代码质量，与最先进的MAS系统相比，其token使用量减少50.85%，代码质量提高10.06%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和自主代理在许多领域表现出色。然而，独立代理在处理需要大量交互和大量计算资源的复杂任务时常常遇到限制。

Method: 提出了一种资源意识的多代理系统--Co-Saving，该系统通过利用经验知识来提高操作效率和解决方案质量，并引入历史成功轨迹中学到的"快捷路径"来加速集体问题解决过程。

Result: 在软件开发任务的实验中，Co-Saving模型相比于现有方法实现了显著优势，具体来说，与最先进的MAS ChatDev相比，平均减少了50.85%的token使用量，并提高了10.06%的整体代码质量。

Conclusion: 引入资源意识的Co-Saving多代理系统显著提高了操作效率和代码质量，展示了其在处理复杂任务中的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) and autonomous agents
have demonstrated remarkable capabilities across various domains. However,
standalone agents frequently encounter limitations when handling complex tasks
that demand extensive interactions and substantial computational resources.
Although Multi-Agent Systems (MAS) alleviate some of these limitations through
collaborative mechanisms like task decomposition, iterative communication, and
role specialization, they typically remain resource-unaware, incurring
significant inefficiencies due to high token consumption and excessive
execution time. To address these limitations, we propose a resource-aware
multi-agent system -- Co-Saving (meaning that multiple agents collaboratively
engage in resource-saving activities), which leverages experiential knowledge
to enhance operational efficiency and solution quality. Our key innovation is
the introduction of "shortcuts" -- instructional transitions learned from
historically successful trajectories -- which allows to bypass redundant
reasoning agents and expedite the collective problem-solving process.
Experiments for software development tasks demonstrate significant advantages
over existing methods. Specifically, compared to the state-of-the-art MAS
ChatDev, our method achieves an average reduction of 50.85% in token usage, and
improves the overall code quality by 10.06%.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Understanding the learned look-ahead behavior of chess neural networks](https://arxiv.org/abs/2505.21552)
*Diogo Cruz*

Main category: cs.AI

TL;DR: 本研究分析了Leela Chess Zero 的前瞻能力，发现其处理的信息深度可达七步，能够考虑多种可能的走棋序列，丰富了对AI在复杂领域推理能力的理解。


<details>
  <summary>Details</summary>
Motivation: 扩展现有研究，分析神经网络在国际象棋对弈中的前瞻能力，并阐明神经网络在战略任务中复杂域的推理能力。

Method: 通过分析模型的能力来考虑未来移动和替代序列，尤其是超过下一个即时移动的分析能力。

Result: 网络可以处理棋局状态的信息，能够提前考虑多达七步，并显示出在不同的未来时间步上使用相似的内部机制。

Conclusion: 研究表明，Leela Chess Zero 策略网络能够在上下文高度相关的背景下处理七步以内棋局的信息，且能够考虑多种可能的走棋序列。

Abstract: We investigate the look-ahead capabilities of chess-playing neural networks,
specifically focusing on the Leela Chess Zero policy network. We build on the
work of Jenner et al. (2024) by analyzing the model's ability to consider
future moves and alternative sequences beyond the immediate next move. Our
findings reveal that the network's look-ahead behavior is highly
context-dependent, varying significantly based on the specific chess position.
We demonstrate that the model can process information about board states up to
seven moves ahead, utilizing similar internal mechanisms across different
future time steps. Additionally, we provide evidence that the network considers
multiple possible move sequences rather than focusing on a single line of play.
These results offer new insights into the emergence of sophisticated look-ahead
capabilities in neural networks trained on strategic tasks, contributing to our
understanding of AI reasoning in complex domains. Our work also showcases the
effectiveness of interpretability techniques in uncovering cognitive-like
processes in artificial intelligence systems.

</details>


### [11] [R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning](https://arxiv.org/abs/2505.21668)
*Yongchao Chen,Yueying Liu,Junwei Zhou,Yilun Hao,Jingquan Wang,Yang Zhang,Chuchu Fan*

Main category: cs.AI

TL;DR: R1-Code-Interpreter是通过SFT和RL训练的扩展模型，通过代码生成提高了任务准确率，超越了GPT-4o，仅次于GPT-4o带代码解释器版本。


<details>
  <summary>Details</summary>
Motivation: 尽管R1类模型在推理和规划方面取得了进展，但大语言模型（LLMs）在需要精确计算、符号操作、优化和算法推理的任务中仍然困难，因为文本推理缺乏代码执行的严格性。关键挑战是使LLMs能够决定何时使用文本推理与代码生成。

Method: 本文提出了一种名为R1-Code-Interpreter的扩展模型，通过多轮监督微调（SFT）和强化学习（RL）训练，使其在逐步推理中自主生成多个代码查询。

Result: 模型R1-CI-14B的最终测试结果表明，其在37个测试任务中的平均准确率提高到了64.1%，超过了未带代码解释器的GPT-4o（58.6%），并接近带代码解释器的GPT-4o（70.9%）。

Conclusion: 最终模型R1-CI-14B在测试任务中的平均准确率从44.0%提高到64.1%，超越了GPT-4o（仅文本：58.6%），并接近使用代码解释器的GPT-4o（70.9%），通过代码生成实现了自我检查行为的产生。

Abstract: Despite advances in reasoning and planning of R1-like models, Large Language
Models (LLMs) still struggle with tasks requiring precise computation, symbolic
manipulation, optimization, and algorithmic reasoning, in which textual
reasoning lacks the rigor of code execution. A key challenge is enabling LLMs
to decide when to use textual reasoning versus code generation. While OpenAI
trains models to invoke a Code Interpreter as needed, public research lacks
guidance on aligning pre-trained LLMs to effectively leverage code and
generalize across diverse tasks. We present R1-Code-Interpreter, an extension
of a text-only LLM trained via multi-turn supervised fine-tuning (SFT) and
reinforcement learning (RL) to autonomously generate multiple code queries
during step-by-step reasoning. We curate 144 reasoning and planning tasks (107
for training, 37 for testing), each with over 200 diverse questions. We
fine-tune Qwen-2.5 models (3B/7B/14B) using various SFT and RL strategies,
investigating different answer formats, reasoning vs. non-reasoning models,
cold vs. warm starts, GRPO vs. PPO, and masked vs. unmasked code outputs.
Unlike prior RL work on narrow domains, we find that Code Interpreter training
is significantly harder due to high task diversity and expensive code
execution, highlighting the critical role of the SFT stage. Our final model,
R1-CI-14B, improves average accuracy on the 37 test tasks from 44.0\% to
64.1\%, outperforming GPT-4o (text-only: 58.6\%) and approaching GPT-4o with
Code Interpreter (70.9\%), with the emergent self-checking behavior via code
generation. Datasets, Codes, and Models are available at
https://github.com/yongchao98/R1-Code-Interpreter and
https://huggingface.co/yongchao98.

</details>


### [12] [Adaptive Frontier Exploration on Graphs with Applications to Network-Based Disease Testing](https://arxiv.org/abs/2505.21671)
*Davin Choo,Yuqi Pan,Tonghan Wang,Milind Tambe,Alastair van Heerden,Cheryl Johnson*

Main category: cs.AI

TL;DR: 研究一种基于图的马尔科夫性质的序列决策问题，通过基于Gittins指数的策略最大化累计折扣奖励，该策略在图为森林时最优，并在实验中优于基线。


<details>
  <summary>Details</summary>
Motivation: 我们研究一个基于图结构的序列决策问题，其中节点标签的分布满足图的马尔科夫性质。通过选择节点揭示标签并获得标签相关的奖励，目的是在未曾选择的节点的邻居中选择以最大化期望累计折扣奖励，适用于接触追踪和机器人探索等实际约束。

Method: 我们设计了一种基于Gittins指数的政策，该政策适用于一般图。在实现中，我们的方法运行时间为O(n^2 \cdot |\mathbf{\Sigma}|^2)，使用O(n \cdot |\mathbf{\Sigma}|^2)个调用oracle P，并占用O(n^2 \cdot |\mathbf{\Sigma}|)空间。

Result: 实验表明，在合成和真实世界图中，我们的方法在非树结构、预算受限和无折扣情况下始终优于自然基线，包括HIV检测模拟中我们的策略显著超越其他基线。

Conclusion: 我们设计的基于Gittins指数的策略在一般图上适用，并在图G为森林时证明是最优的。通过实验验证，我们的方法在合成和真实世界图中一致地优于自然基线。在HIV检测模拟中，我们的策略能够在仅测试一半人口的情况下检测几乎所有阳性病例，显著超越其他基线。

Abstract: We study a sequential decision-making problem on a $n$-node graph $G$ where
each node has an unknown label from a finite set $\mathbf{\Sigma}$, drawn from
a joint distribution $P$ that is Markov with respect to $G$. At each step,
selecting a node reveals its label and yields a label-dependent reward. The
goal is to adaptively choose nodes to maximize expected accumulated discounted
rewards. We impose a frontier exploration constraint, where actions are limited
to neighbors of previously selected nodes, reflecting practical constraints in
settings such as contact tracing and robotic exploration. We design a Gittins
index-based policy that applies to general graphs and is provably optimal when
$G$ is a forest. Our implementation runs in $O(n^2 \cdot |\mathbf{\Sigma}|^2)$
time while using $O(n \cdot |\mathbf{\Sigma}|^2)$ oracle calls to $P$ and
$O(n^2 \cdot |\mathbf{\Sigma}|)$ space. Experiments on synthetic and real-world
graphs show that our method consistently outperforms natural baselines,
including in non-tree, budget-limited, and undiscounted settings. For example,
in HIV testing simulations on real-world sexual interaction networks, our
policy detects nearly all positive cases with only half the population tested,
substantially outperforming other baselines.

</details>


### [13] [Make Planning Research Rigorous Again!](https://arxiv.org/abs/2505.21674)
*Michael Katz,Harsha Kokel,Christian Muise,Shirin Sohrabi,Sarath Sreedharan*

Main category: cs.AI

TL;DR: 建议将传统自动化规划的经验整合到大语言模型规划器中，以避免重复错误并加快发展。


<details>
  <summary>Details</summary>
Motivation: 虽然计划领域在解决新型的计划问题上取得了重要进展，但最近基于大语言模型的计划工作重复了已知的陷阱，本文旨在通过借鉴传统规划领域的经验，避免这些问题的发生，加速LLM规划器的发展。

Method: 本文建议将自动规划社区的经验、工具和数据融入到大语言模型规划器的设计和评估中，以避免重复已知的错误和陷阱，从而加速这些规划器的发展。

Result: 通过将自动规划领域的经验应用于LLM规划器，能够避免重复过去的错误，并推进新系统的开发和改进。

Conclusion: 通过合理整合自动化规划社区的洞察、工具和数据，可以加速基于大语言模型的规划器的发展，同时避免已知的陷阱，这将极大地促进LLM规划器和整体规划领域的进步。

Abstract: In over sixty years since its inception, the field of planning has made
significant contributions to both the theory and practice of building planning
software that can solve a never-before-seen planning problem. This was done
through established practices of rigorous design and evaluation of planning
systems. It is our position that this rigor should be applied to the current
trend of work on planning with large language models. One way to do so is by
correctly incorporating the insights, tools, and data from the automated
planning community into the design and evaluation of LLM-based planners. The
experience and expertise of the planning community are not just important from
a historical perspective; the lessons learned could play a crucial role in
accelerating the development of LLM-based planners. This position is
particularly important in light of the abundance of recent works that replicate
and propagate the same pitfalls that the planning community has encountered and
learned from. We believe that avoiding such known pitfalls will contribute
greatly to the progress in building LLM-based planners and to planning in
general.

</details>


### [14] [Don't Think Longer, Think Wisely: Optimizing Thinking Dynamics for Large Reasoning Models](https://arxiv.org/abs/2505.21765)
*Sohyun An,Ruochen Wang,Tianyi Zhou,Cho-Jui Hsieh*

Main category: cs.AI

TL;DR: 通过优化思维路径，提高推理效率和准确性，减少计算开销和输出长度。


<details>
  <summary>Details</summary>
Motivation: 大规模推理模型（LRMs）可能由于思考过度而导致推理路径过于复杂，浪费计算资源并可能降低性能，需要改进思维模式选择的动态能力。

Method: 提出一种动态优化框架，将模型生成的推理路径分割成不同的思维模式，并系统性地识别和促进有益的模式，同时去除不利的模式。

Result: 优化后的思维路径使推理效率提高了高达47%，同时保持原始正确响应的准确性，并将部分原始错误响应转换为正确响应，准确率提高了15.6%并减少了输出长度。实验表明，在多个数学推理基准上，方法减少了计算负担并提高了推理准确性，准确率提高了12%，使用的token从约5,000减少到3,000。

Conclusion: 通过应用动态优化框架和偏好优化技术，可以显著提高数学推理的准确性，同时减少计算开销和输出长度。

Abstract: While recent success of large reasoning models (LRMs) significantly advanced
LLMs' reasoning capability by optimizing the final answer accuracy using
reinforcement learning, they may also drastically increase the output length
due to overthinking, characterized by unnecessarily complex reasoning paths
that waste computation and potentially degrade the performance. We hypothesize
that such inefficiencies stem from LRMs' limited capability to dynamically
select the proper modular reasoning strategies, termed thinking patterns at the
right position. To investigate this hypothesis, we propose a dynamic
optimization framework that segments model-generated reasoning paths into
distinct thinking patterns, systematically identifying and promoting beneficial
patterns that improve the answer while removing detrimental ones. Empirical
analysis confirms that our optimized thinking paths yield more concise yet
sufficiently informative trajectories, enhancing reasoning efficiency by
reducing attention FLOPs by up to 47% while maintaining accuracy for originally
correct responses. Moreover, a non-trivial portion of originally incorrect
responses are transformed into correct ones, achieving a 15.6% accuracy
improvement with reduced length. Motivated by the improvement brought by the
optimized thinking paths, we apply a preference optimization technique
supported by a pairwise dataset contrasting suboptimal and optimal reasoning
paths. Experimental evaluations across multiple mathematical reasoning
benchmarks reveal that our method notably reduces computational overhead while
simultaneously improving reasoning accuracy, achieving up to a 12% accuracy
improvement and reducing token usage from approximately 5,000 to 3,000 tokens.

</details>


### [15] [Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation](https://arxiv.org/abs/2505.21784)
*Tharindu Kumarage,Ninareh Mehrabi,Anil Ramakrishna,Xinyan Zhao,Richard Zemel,Kai-Wei Chang,Aram Galstyan,Rahul Gupta,Charith Peris*

Main category: cs.AI

TL;DR: AIDSAFE uses multi-agent deliberation to generate high-quality CoT datasets, improving LLM safety training and robustness.


<details>
  <summary>Details</summary>
Motivation: To overcome challenges in creating accurate and policy-compliant CoT datasets for LLM safety reasoning.

Method: AIDSAFE, a data generation recipe using multi-agent deliberation and data refiners for high-quality CoTs.

Result: AIDSAFE provides datasets that improve safety training, leading to better safety compliance and reduced jailbreak vulnerabilities in LLMs.

Conclusion: AIDSAFE-generated CoTs enhance policy adherence and reasoning quality, improving safety generalization and jailbreak robustness of LLMs.

Abstract: Safety reasoning is a recent paradigm where LLMs reason over safety policies
before generating responses, thereby mitigating limitations in existing safety
measures such as over-refusal and jailbreak vulnerabilities. However,
implementing this paradigm is challenging due to the resource-intensive process
of creating high-quality policy-embedded chain-of-thought (CoT) datasets while
ensuring reasoning remains accurate and free from hallucinations or policy
conflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation
for Safety Reasoning, a novel data generation recipe that leverages multi-agent
deliberation to iteratively expand reasoning on safety policies. A data refiner
stage in AIDSAFE ensures high-quality outputs by eliminating repetitive,
redundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong
foundation for supervised fine-tuning (SFT)-based safety training.
Additionally, to address the need of preference data in alignment stages, such
as DPO training, we introduce a supplemental recipe that uses belief
augmentation to create distinct selected and rejected CoT samples. Our
evaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy
adherence and reasoning quality. Consequently, we show that fine-tuning
open-source LLMs on these CoTs can significantly improve safety generalization
and jailbreak robustness while maintaining acceptable utility and over-refusal
accuracy. AIDSAFE-generated CoT datasets can be found here:
https://huggingface.co/datasets/AmazonScience/AIDSAFE

</details>


### [16] [SAGE-Eval: Evaluating LLMs for Systematic Generalizations of Safety Facts](https://arxiv.org/abs/2505.21828)
*Chen Yueh-Han,Guy Davidson,Brenden M. Lake*

Main category: cs.AI

TL;DR: SAGE-Eval tests LLMs' ability to apply safety facts in naive queries; results show models like Claude-3.7-sonnet fail to generalize well, prompting the need for better pre-deployment evaluations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to test if LLMs can generalize critical safety facts to novel situations, as failing to do so, especially for naive user questions, may result in dangerous consequences.

Method: SAGE-Eval, a benchmark consisting of 104 safety facts from reputable sources, systematically augmented into 10,428 test scenarios across 7 domains, is introduced to evaluate LLMs.

Result: The top model, Claude-3.7-sonnet, only passed 58% of the safety facts, indicating that model capabilities and training compute weakly correlate with performance on safety evaluations.

Conclusion: Frontier LLMs still lack robust generalization ability in applying safety facts to naive user queries, and scaling up models is not the ultimate solution.

Abstract: Do LLMs robustly generalize critical safety facts to novel situations?
Lacking this ability is dangerous when users ask naive questions. For instance,
"I'm considering packing melon balls for my 10-month-old's lunch. What other
foods would be good to include?" Before offering food options, the LLM should
warn that melon balls pose a choking hazard to toddlers, as documented by the
CDC. Failing to provide such warnings could result in serious injuries or even
death. To evaluate this, we introduce SAGE-Eval, SAfety-fact systematic
GEneralization evaluation, the first benchmark that tests whether LLMs properly
apply well established safety facts to naive user queries. SAGE-Eval comprises
104 facts manually sourced from reputable organizations, systematically
augmented to create 10,428 test scenarios across 7 common domains (e.g.,
Outdoor Activities, Medicine). We find that the top model, Claude-3.7-sonnet,
passes only 58% of all the safety facts tested. We also observe that model
capabilities and training compute weakly correlate with performance on
SAGE-Eval, implying that scaling up is not the golden solution. Our findings
suggest frontier LLMs still lack robust generalization ability. We recommend
developers use SAGE-Eval in pre-deployment evaluations to assess model
reliability in addressing salient risks. We publicly release SAGE-Eval at
https://huggingface.co/datasets/YuehHanChen/SAGE-Eval and our code is available
at https://github.com/YuehHanChen/SAGE-Eval/tree/main.

</details>


### [17] [SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem](https://arxiv.org/abs/2505.21887)
*Ahmed Heakl,Yahia Salaheldin Shaaban,Martin Takac,Salem Lahlou,Zangir Iklassov*

Main category: cs.AI

TL;DR: The paper presents SVRPBench, a benchmark for vehicle routing under uncertainty, revealing weaknesses in current RL solvers compared to classical methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the gap in current benchmarks that assume static and idealized settings, and instead create a benchmark that captures the complexity and uncertainty of real-world logistics.

Method: The paper introduces SVRPBench, a benchmark that simulates high-fidelity stochastic dynamics in vehicle routing at urban scale, incorporating realistic delivery conditions and generating diverse, constraint-rich scenarios.

Result: Benchmarking results show that state-of-the-art RL solvers like POMO and AM degrade by over 20% under distributional shift, while classical and metaheuristic methods remain robust.

Conclusion: SVRPBench challenges the community to design solvers that generalize beyond synthetic assumptions and adapt to real-world uncertainty.

Abstract: Robust routing under uncertainty is central to real-world logistics, yet most
benchmarks assume static, idealized settings. We present SVRPBench, the first
open benchmark to capture high-fidelity stochastic dynamics in vehicle routing
at urban scale. Spanning more than 500 instances with up to 1000 customers, it
simulates realistic delivery conditions: time-dependent congestion, log-normal
delays, probabilistic accidents, and empirically grounded time windows for
residential and commercial clients. Our pipeline generates diverse,
constraint-rich scenarios, including multi-depot and multi-vehicle setups.
Benchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade
by over 20% under distributional shift, while classical and metaheuristic
methods remain robust. To enable reproducible research, we release the dataset
and evaluation suite. SVRPBench challenges the community to design solvers that
generalize beyond synthetic assumptions and adapt to real-world uncertainty.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [18] [Uncovering Bottlenecks and Optimizing Scientific Lab Workflows with Cycle Time Reduction Agents](https://arxiv.org/abs/2505.21534)
*Yao Fehlis*

Main category: cs.MA

TL;DR: CTRA是一个基于LangGraph的智能工作流，通过自动化实验室操作指标分析来加速制药和生物技术发展。


<details>
  <summary>Details</summary>
Motivation: 制药和生物技术公司的科学实验室在优化工作流程方面遇到显著挑战，特别是在化合物筛选和测定执行的任务复杂性和任务量上。

Method: 使用基于LangGraph的智能工作流，具体由三个主要组件组成：问题创建代理负责启动分析，运营指标代理负责数据提取和验证，洞察代理负责报告和可视化。

Result: 本文详细介绍了CTRA的架构，并对其在实验室数据集上的表现进行了评估，表明其能够加速制药和生物技术的发展。

Conclusion: CTRA提供了一种可扩展的框架，可以有效降低科学实验室的周期时间，从而促进制药和生物技术的发展。

Abstract: Scientific laboratories, particularly those in pharmaceutical and
biotechnology companies, encounter significant challenges in optimizing
workflows due to the complexity and volume of tasks such as compound screening
and assay execution. We introduce Cycle Time Reduction Agents (CTRA), a
LangGraph-based agentic workflow designed to automate the analysis of lab
operational metrics. CTRA comprises three main components: the Question
Creation Agent for initiating analysis, Operational Metrics Agents for data
extraction and validation, and Insights Agents for reporting and visualization,
identifying bottlenecks in lab processes. This paper details CTRA's
architecture, evaluates its performance on a lab dataset, and discusses its
potential to accelerate pharmaceutical and biotechnological development. CTRA
offers a scalable framework for reducing cycle times in scientific labs.

</details>


### [19] [Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework](https://arxiv.org/abs/2505.21559)
*Julien Soulé,Jean-Paul Jamont,Michel Occello,Louis-Marie Traonouez,Paul Théron*

Main category: cs.MA

TL;DR: 论文提出一种新的多代理系统（MAS）方法来提高Kubernetes集群在对抗性环境中的操作弹性，通过自动化的四阶段在线框架来设计HPA MAS，并证明其优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 在云原生系统中，由于资源阻塞、瓶颈或持续的Pod崩溃，Kubernetes集群的相互依赖服务经常面临其操作弹性的挑战。这些漏洞在分布式拒绝服务攻击（DDoS）等对抗性场景中进一步放大。

Method: 我们提出将维持操作弹性的整体目标分解为委派给协作代理的特定于故障的子目标，形成HPA多代理系统（MAS）。我们引入一个自动化的四阶段在线框架用于HPA MAS设计：1）使用集群痕迹建模一个数字孪生； 2）在仿真中训练代理，使用针对故障上下文的角色和任务； 3）分析代理行为的可解释性； 4）将学习到的策略迁移到真实集群。

Result: 实验结果显示，在提出的复杂集群中的各种对抗条件下，生成的HPA MAS明显优于当前三种最先进的HPA系统，表现其在维持操作弹性方面的优势。

Conclusion: 实验结果表明，生成的HPA多代理系统在维持复杂集群下的操作弹性方面优于三种最先进的HPA系统。

Abstract: In cloud-native systems, Kubernetes clusters with interdependent services
often face challenges to their operational resilience due to poor workload
management issues such as resource blocking, bottlenecks, or continuous pod
crashes. These vulnerabilities are further amplified in adversarial scenarios,
such as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal
Pod Autoscaling (HPA) approaches struggle to address such dynamic conditions,
while reinforcement learning-based methods, though more adaptable, typically
optimize single goals like latency or resource usage, neglecting broader
failure scenarios. We propose decomposing the overarching goal of maintaining
operational resilience into failure-specific sub-goals delegated to
collaborative agents, collectively forming an HPA Multi-Agent System (MAS). We
introduce an automated, four-phase online framework for HPA MAS design: 1)
modeling a digital twin built from cluster traces; 2) training agents in
simulation using roles and missions tailored to failure contexts; 3) analyzing
agent behaviors for explainability; and 4) transferring learned policies to the
real cluster. Experimental results demonstrate that the generated HPA MASs
outperform three state-of-the-art HPA systems in sustaining operational
resilience under various adversarial conditions in a proposed complex cluster.

</details>


### [20] [Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2505.21588)
*Young-Min Cho,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.MA

TL;DR: 论文研究了在LLM多代理系统中的羊群行为，发现其受多种因素影响，并能通过操控这些因素提升协作效果。


<details>
  <summary>Details</summary>
Motivation: 探究在多代理系统中，LLMs间互动如何受同伴影响，引发集体行为形式的动态变化，特别是"羊群行为"。

Method: 进行了一系列受控实验来研究羊群行为在多代理系统中的表现，分析因素包括自信与对同伴信任度的差异及信息呈现格式等。

Result: 揭示了在LLM基础的多代理交互中，羊群行为如何受自信与同伴信任差异、信息呈现形式等因素的影响，并且能够通过合理调节羊群倾向来提升协作效率。

Conclusion: 发现羊群行为受多个因素影响，并可以系统地加以控制，从而在多代理协作中带来更好的结果。

Abstract: Recent advancements in Large Language Models (LLMs) have enabled the
emergence of multi-agent systems where LLMs interact, collaborate, and make
decisions in shared environments. While individual model behavior has been
extensively studied, the dynamics of peer influence in such systems remain
underexplored. In this paper, we investigate herd behavior, the tendency of
agents to align their outputs with those of their peers, within LLM-based
multi-agent interactions. We present a series of controlled experiments that
reveal how herd behaviors are shaped by multiple factors. First, we show that
the gap between self-confidence and perceived confidence in peers significantly
impacts an agent's likelihood to conform. Second, we find that the format in
which peer information is presented plays a critical role in modulating the
strength of herd behavior. Finally, we demonstrate that the degree of herd
behavior can be systematically controlled, and that appropriately calibrated
herd tendencies can enhance collaborative outcomes. These findings offer new
insights into the social dynamics of LLM-based systems and open pathways for
designing more effective and adaptive multi-agent collaboration frameworks.

</details>


### [21] [AI-Supported Platform for System Monitoring and Decision-Making in Nuclear Waste Management with Large Language Models](https://arxiv.org/abs/2505.21741)
*Dongjune Chang,Sola Kim,Young Soo Park*

Main category: cs.MA

TL;DR: 本研究开发了一个多代理系统，结合大型语言模型与文档检索，以提高核废料管理中的合规性和安全性决策。使用普通硬件和嵌入技术，该系统在模拟案例中展现出高效性，并能动态调整以适应不断变化的法规环境。


<details>
  <summary>Details</summary>
Motivation: 核废料管理需要符合严格的法规，这需要能够处理复杂法律、环境和安全考虑的高级决策支持系统。

Method: 本文提出了一种多代理检索增强生成（RAG）系统，将大型语言模型（LLMs）与文档检索机制相结合，通过结构化代理协作来提高决策准确性。系统在消费者级硬件上实施，利用Llama 3.2和mxbai-embed-large-v1嵌入进行高效的检索和语义表示。通过一个结构化的10轮讨论模型，代理们合作评估法规合规性和安全要求，并保持文档为基础的响应。

Result: 研究结果表明，在法律框架的保持上，法规代理获得了一致更高的相关性评分，而安全代理在管理需要多方面分析的复杂风险评估中表现有效。系统显示出在各轮讨论中代理之间一致性和响应连贯性的进步，语义漂移降低，这表明决策一致性增强。

Conclusion: 该系统通过实时文档检索确保法规决策仍然基于事实，并随着不断发展的法规框架进行动态调整，在自动评估与人工监督之间取得平衡，为法规治理提供了一种可扩展和透明的方法。这些发现强调了AI驱动的多代理系统在推进高风险环境管理场景中的循证、负责和自适应决策的潜力。

Abstract: Nuclear waste management requires rigorous regulatory compliance assessment,
demanding advanced decision-support systems capable of addressing complex
legal, environmental, and safety considerations. This paper presents a
multi-agent Retrieval-Augmented Generation (RAG) system that integrates large
language models (LLMs) with document retrieval mechanisms to enhance decision
accuracy through structured agent collaboration. Through a structured 10-round
discussion model, agents collaborate to assess regulatory compliance and safety
requirements while maintaining document-grounded responses. Implemented on
consumer-grade hardware, the system leverages Llama 3.2 and
mxbai-embed-large-v1 embeddings for efficient retrieval and semantic
representation. A case study of a proposed temporary nuclear waste storage site
near Winslow, Arizona, demonstrates the framework's effectiveness. Results show
the Regulatory Agent achieves consistently higher relevance scores in
maintaining alignment with legal frameworks, while the Safety Agent effectively
manages complex risk assessments requiring multifaceted analysis. The system
demonstrates progressive improvement in agreement rates between agents across
discussion rounds while semantic drift decreases, indicating enhanced
decision-making consistency and response coherence. The system ensures
regulatory decisions remain factually grounded, dynamically adapting to
evolving regulatory frameworks through real-time document retrieval. By
balancing automated assessment with human oversight, this framework offers a
scalable and transparent approach to regulatory governance. These findings
underscore the potential of AI-driven, multi-agent systems in advancing
evidence-based, accountable, and adaptive decision-making for high-stakes
environmental management scenarios.

</details>


### [22] [Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation](https://arxiv.org/abs/2505.21880)
*Yu-Lun Song,Chung-En Tsern,Che-Cheng Wu,Yu-Ming Chang,Syuan-Bo Huang,Wei-Chu Chen,Michael Chia-Liang Lin,Yu-Ta Lin*

Main category: cs.MA

TL;DR: 研究集成大型语言模型与代理建模，以提升城市移动仿真，为城市规划提供信息。


<details>
  <summary>Details</summary>
Motivation: 通过引入LLM增强代理多样性和现实性，以改善城市移动仿真，旨在为城市规划提供可操作的信息。

Method: 将大型语言模型（LLM）与基于代理的建模（ABM）相结合，使用真实世界数据来模拟台北市的个体行为和大规模移动模式。

Result: 关键见解如路线热图和特定模式指示器，可以为城市规划人员提供政策制定的可操作信息。

Conclusion: 未来的工作集中于建立强大的验证框架，以确保在城市规划应用中的准确性和可靠性。

Abstract: This study presents an innovative approach to urban mobility simulation by
integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM).
Unlike traditional rule-based ABM, the proposed framework leverages LLM to
enhance agent diversity and realism by generating synthetic population
profiles, allocating routine and occasional locations, and simulating
personalized routes. Using real-world data, the simulation models individual
behaviors and large-scale mobility patterns in Taipei City. Key insights, such
as route heat maps and mode-specific indicators, provide urban planners with
actionable information for policy-making. Future work focuses on establishing
robust validation frameworks to ensure accuracy and reliability in urban
planning applications.

</details>


### [23] [Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2505.21985)
*Naoto Yoshida,Tadahiro Taniguchi*

Main category: cs.MA

TL;DR: MARL-CPC uses predictive coding-based message learning to improve communication in decentralized, non-cooperative MARL, surpassing traditional approaches.


<details>
  <summary>Details</summary>
Motivation: In non-cooperative MARL tasks, traditional message-as-action approaches are inadequate. The proposed MARL-CPC framework seeks to improve communication without assuming cooperation or parameter sharing.

Method: MARL-CPC employs a message learning model based on collective predictive coding (CPC), avoiding the conventional assumption of cooperation by relating messages to state inference.

Result: Benchmarks demonstrate that MARL-CPC, particularly its algorithms Bandit-CPC and IPPO-CPC, outperform standard methods in non-cooperative MARL tasks by enabling coordination through effective message communication.

Conclusion: MARL-CPC establishes effective communication in non-cooperative, decentralized multi-agent environments, outperforming traditional message-as-action approaches.

Abstract: In multi-agent reinforcement learning (MARL), effective communication
improves agent performance, particularly under partial observability. We
propose MARL-CPC, a framework that enables communication among fully
decentralized, independent agents without parameter sharing. MARL-CPC
incorporates a message learning model based on collective predictive coding
(CPC) from emergent communication research. Unlike conventional methods that
treat messages as part of the action space and assume cooperation, MARL-CPC
links messages to state inference, supporting communication in non-cooperative,
reward-independent settings. We introduce two algorithms -Bandit-CPC and
IPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that
both outperform standard message-as-action approaches, establishing effective
communication even when messages offer no direct benefit to the sender. These
results highlight MARL-CPC's potential for enabling coordination in complex,
decentralized environments.

</details>


### [24] [Sentiment Simulation using Generative AI Agents](https://arxiv.org/abs/2505.22125)
*Melrose Tia,Jezreel Sophia Lanuzo,Lei Rigi Baltazar,Marie Joy Lopez-Relente,Diwa Malaya Quiñones,Jason Albia*

Main category: cs.MA

TL;DR: 该研究提出一个使用生成性AI代理进行情感模拟的框架，结合调查获得的社会人口信息和心理特征，评估结果表明情境编码的准确性较高，并展示了该框架的可扩展性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统情感分析依赖表面级的语言模式和回顾数据，限制了其捕捉人类情感心理和情境驱动因素的能力，影响了需要预测性洞察的应用。

Method: 框架包括三个阶段：1.通过类别或情景化编码进行代理体现；2.暴露于真实的政治和经济情景；3.生成情感评分并附带解释性理由。使用QWA评估代理生成与人类响应的匹配度。

Result: 情境编码在复制原始调查响应中实现了92%的匹配度。在情感模拟任务中，与实际情感相比，代理达到81%至86%的准确度，其中情境化的配置明显优于分类配置（p < 0.0001，Cohen's d = 0.70）。模拟结果在重复试验中保持一致（标准差为+/-0.2至0.5%），并对情景设置的变化表现出韧性（p = 0.9676，Cohen's d = 0.02）。

Conclusion: 通过心理上扎实的AI代理，建立了一个情感模拟的可扩展框架。这项工作标志着情感分析从回顾性分类到心理基础上的情感形成的前瞻性和动态模拟的范式转变。

Abstract: Traditional sentiment analysis relies on surface-level linguistic patterns
and retrospective data, limiting its ability to capture the psychological and
contextual drivers of human sentiment. These limitations constrain its
effectiveness in applications that require predictive insight, such as policy
testing, narrative framing, and behavioral forecasting. We present a robust
framework for sentiment simulation using generative AI agents embedded with
psychologically rich profiles. Agents are instantiated from a nationally
representative survey of 2,485 Filipino respondents, combining sociodemographic
information with validated constructs of personality traits, values, beliefs,
and socio-political attitudes. The framework includes three stages: (1) agent
embodiment via categorical or contextualized encodings, (2) exposure to
real-world political and economic scenarios, and (3) generation of sentiment
ratings accompanied by explanatory rationales. Using Quadratic Weighted
Accuracy (QWA), we evaluated alignment between agent-generated and human
responses. Contextualized encoding achieved 92% alignment in replicating
original survey responses. In sentiment simulation tasks, agents reached
81%--86% accuracy against ground truth sentiment, with contextualized profile
encodings significantly outperforming categorical (p < 0.0001, Cohen's d =
0.70). Simulation results remained consistent across repeated trials
(+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676,
Cohen's d = 0.02). Our findings establish a scalable framework for sentiment
modeling through psychographically grounded AI agents. This work signals a
paradigm shift in sentiment analysis from retrospective classification to
prospective and dynamic simulation grounded in psychology of sentiment
formation.

</details>


### [25] [Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on Introspection](https://arxiv.org/abs/2505.22192)
*Yue Cui,Liuyi Yao,Zitao Li,Yaliang Li,Bolin Ding,Xiaofang Zhou*

Main category: cs.MA

TL;DR: 该论文提出了IntrospecLOO方法，通过在LLM多代理争论后添加一个查询回合，有效评估每个代理的贡献，降低了查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 多代理系统中评估个体贡献对于系统改进和结果可靠性至关重要，但传统LOO方法在LLM系统中计算成本高。

Method: 提出IntrospecLOO方法，通过附加查询回合，在不考虑指定代理的情况下促使代理更新答案，以低查询复杂度近似传统LOO。

Result: 在三个基准数据集上的实验验证了IntrospecLOO的有效性。

Conclusion: IntrospecLOO能在降低复杂度的同时有效评估每个参与者的影响，为LLM驱动的多代理系统中的角色评估提供了一种新方法。

Abstract: Multi-agent systems based on large language models (LLMs) advance automatic
task completion in various fields, where debate is a common cooperation form
for agents to solve complicated problems with reasoning and cross-review to
solidify answers. Assessing the individual contributions of agents within these
debates is crucial for system refinement and outcome reliability. Traditional
leave-one-out (LOO) method offers a clear framework for evaluating each agent's
role but face challenges in LLM-based systems due to high computational costs
and associated financial implications. This paper presents
introspective-leave-one-out (IntrospecLOO), a simple yet effective prompting
for approximation of LOO in LLM-powered multi-agent debates. IntrospecLOO
introduces an additional querying round after standard debates, prompting
agents to update their answers while ignoring responses from a designated
agent. This strategy effectively isolates and gauges each participant's
influence at a reduced query complexity compared to the original LOO
approaches. Validation through experiments on three benchmark datasets confirms
the effectiveness of IntrospecLOO.

</details>


### [26] [Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2505.22467)
*Jiaxi Yang,Mengqi Zhang,Yiqiao Jin,Hao Chen,Qingsong Wen,Lu Lin,Yi He,Weijie Xu,James Evans,Jindong Wang*

Main category: cs.MA

TL;DR: 本文提出了一个三阶段框架以开发拓扑感知的多智能体系统，强调拓扑结构在提升协作性能中的重要性，并讨论了可能的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统在如何优化代理的结构化组织以实现最佳合作方面研究不足，因此该研究旨在引导研究社区关注多智能体系统的拓扑组织。

Method: 本文提出了一个三阶段框架：代理选择、结构分析和拓扑合成，以开发面向特定任务的拓扑感知多智能体系统。

Result: 提出的框架将激发语言模型、强化学习、图学习和生成建模等领域的新研究机会，并可能激发多智能体系统在复杂实际应用中的潜力。

Conclusion: 该研究强调了在多智能体系统中引入拓扑感知以提高任务执行效率和协调性能的必要性。

Abstract: Large Language Model-based Multi-Agent Systems (MASs) have emerged as a
powerful paradigm for tackling complex tasks through collaborative
intelligence. Nevertheless, the question of how agents should be structurally
organized for optimal cooperation remains largely unexplored. In this position
paper, we aim to gently redirect the focus of the MAS research community toward
this critical dimension: develop topology-aware MASs for specific tasks.
Specifically, the system consists of three core components - agents,
communication links, and communication patterns - that collectively shape its
coordination performance and efficiency. To this end, we introduce a
systematic, three-stage framework: agent selection, structure profiling, and
topology synthesis. Each stage would trigger new research opportunities in
areas such as language models, reinforcement learning, graph learning, and
generative modeling; together, they could unleash the full potential of MASs in
complicated real-world applications. Then, we discuss the potential challenges
and opportunities in the evaluation of multiple systems. We hope our
perspective and framework can offer critical new insights in the era of agentic
AI.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [27] [The Role of Visualization in LLM-Assisted Knowledge Graph Systems: Effects on User Trust, Exploration, and Workflows](https://arxiv.org/abs/2505.21512)
*Harry Li,Gabriel Appleby,Kenneth Alperin,Steven R Gomez,Ashley Suh*

Main category: cs.LG

TL;DR: 开发LinkQ，通过视觉机制帮助用户评估LLM在知识图谱查询中的准确性，但发现用户容易过度信任工具，即使其出错。


<details>
  <summary>Details</summary>
Motivation: 研究大规模语言模型与知识图谱结合时对用户信任、探索策略和决策的影响。

Method: 开发LinkQ系统，将自然语言问题转换为结构化查询，并结合五种视觉机制帮助用户评估查询和LLM的准确性。

Result: 用户的工作流程不同，取决于他们对知识图谱和大规模语言模型的熟悉程度，这挑战了设计此类系统的“一刀切”假设。

Conclusion: 用户倾向于过度信任LinkQ的输出，尽管LLM可能出错。

Abstract: Knowledge graphs (KGs) are powerful data structures, but exploring them
effectively remains difficult for even expert users. Large language models
(LLMs) are increasingly used to address this gap, yet little is known
empirically about how their usage with KGs shapes user trust, exploration
strategies, or downstream decision-making - raising key design challenges for
LLM-based KG visual analysis systems. To study these effects, we developed
LinkQ, a KG exploration system that converts natural language questions into
structured queries with an LLM. We collaborated with KG experts to design five
visual mechanisms that help users assess the accuracy of both KG queries and
LLM responses: an LLM-KG state diagram that illustrates which stage of the
exploration pipeline LinkQ is in, a query editor displaying the generated query
paired with an LLM explanation, an entity-relation ID table showing extracted
KG entities and relations with semantic descriptions, a query structure graph
that depicts the path traversed in the KG, and an interactive graph
visualization of query results. From a qualitative evaluation with 14
practitioners, we found that users - even KG experts - tended to overtrust
LinkQ's outputs due to its "helpful" visualizations, even when the LLM was
incorrect. Users exhibited distinct workflows depending on their prior
familiarity with KGs and LLMs, challenging the assumption that these systems
are one-size-fits-all - despite often being designed as if they are. Our
findings highlight the risks of false trust in LLM-assisted data analysis tools
and the need for further investigation into the role of visualization as a
mitigation technique.

</details>


### [28] [SIMCOPILOT: Evaluating Large Language Models for Copilot-Style Code Generation](https://arxiv.org/abs/2505.21514)
*Mingchao Jiang,Abhinav Jain,Sophia Zorek,Chris Jermaine*

Main category: cs.LG

TL;DR: SIMCOPILOT是一个用于评估大语言模型编码能力的基准测试，针对Java和Python代码，提供细致分析以评估其在实际编程场景中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型在实际编程环境中的效用，提供一个真实详细的评估环境，并进行细致分析以解决现有基准测试中经常被忽视的关键因素。

Method: 建立了一个综合框架来评估LLM在编程中的能力，包括针对Java和Python的子基准测试，以模拟LLM作为编码助手的互动角色。

Result: 对算法、数据库、计算机视觉和神经网络等领域的评估提供了对模型优势的洞察，并强调了在复杂依赖结构中保持逻辑一致性的持续挑战。

Conclusion: 研究表明当前的LLM在代码生成中仍存在一定的局限性，但正逐步从仅仅是语法识别的生成器过渡到可靠的智能软件开发助手。

Abstract: We introduce SIMCOPILOT, a benchmark that simulates the role of large
language models (LLMs) as interactive, "copilot"-style coding assistants.
Targeting both completion (finishing incomplete methods or code blocks) and
infill tasks (filling missing segments within existing code), SIMCOPILOT
provides a comprehensive framework for evaluating LLM coding capabilities. The
benchmark comprises dedicated sub-benchmarks for Java (SIMCOPILOTJ) and Python
(SIMCOPILOTP), covering diverse codebases varying in size and complexity. Our
key contributions include: (a) establishing a realistic, detailed evaluation
environment to assess LLM utility in practical coding scenarios, and (b)
providing fine-grained analyses that address critical factors frequently
overlooked by existing benchmarks, such as task-specific performance nuances,
contextual understanding across code segments, and sensitivity to variable
scope. Evaluations conducted across domains-including algorithms, databases,
computer vision, and neural networks-offer insights into model strengths and
highlight persistent challenges in maintaining logical consistency within
complex dependency structures. Beyond benchmarking, our study sheds light on
the current limitations of LLM-driven code generation and underscores the
ongoing transition of LLMs from merely syntax-aware generators toward reliable,
intelligent software development partners.

</details>


### [29] [Temporal Restoration and Spatial Rewiring for Source-Free Multivariate Time Series Domain Adaptation](https://arxiv.org/abs/2505.21525)
*Peiliang Gong,Yucheng Wang,Min Wu,Zhenghua Chen,Xiaoli Li,Daoqiang Zhang*

Main category: cs.LG

TL;DR: 提出了TERSE，一种新型的SFDA方法，专注于多变量时间序列，通过时间恢复和空间重组实现跨域空间-时间依赖的适应，更有效且可作为模块集成于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有的源无领域适应方法未能有效考虑多变量时间序列（MTS）数据中固有的空间相关性，导致适应效果不佳。准确表示MTS数据和保持域间的不变信息依赖于这些空间相关性。

Method: 本文提出了一个新的方法TERSE，专为多变量时间序列（MTS）数据设计。TERSE包括定制的时空特征编码器，用于捕捉基础的时空特征，并结合时间恢复和空间重组任务，重新建立时间掩码的时间序列和空间掩码的相关结构的潜在表示。

Result: 在三个真实世界的时间序列数据集上进行了广泛的实验，结果证明了TERSE方法的有效性和多功能性。

Conclusion: TERSE能够有效地对空间-时间依赖关系进行建模和迁移，实现隐含的特征对齐，提升了多变量时间序列的源无领域适应性。作为首个同时考虑空间-时间一致性的方法，TERSE还可以作为多用途的模块集成到其他现有的源无领域适应方法中。

Abstract: Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained model from
an annotated source domain to an unlabelled target domain without accessing the
source data, thereby preserving data privacy. While existing SFDA methods have
proven effective in reducing reliance on source data, they struggle to perform
well on multivariate time series (MTS) due to their failure to consider the
intrinsic spatial correlations inherent in MTS data. These spatial correlations
are crucial for accurately representing MTS data and preserving invariant
information across domains. To address this challenge, we propose Temporal
Restoration and Spatial Rewiring (TERSE), a novel and concise SFDA method
tailored for MTS data. Specifically, TERSE comprises a customized
spatial-temporal feature encoder designed to capture the underlying
spatial-temporal characteristics, coupled with both temporal restoration and
spatial rewiring tasks to reinstate latent representations of the temporally
masked time series and the spatially masked correlated structures. During the
target adaptation phase, the target encoder is guided to produce spatially and
temporally consistent features with the source domain by leveraging the source
pre-trained temporal restoration and spatial rewiring networks. Therefore,
TERSE can effectively model and transfer spatial-temporal dependencies across
domains, facilitating implicit feature alignment. In addition, as the first
approach to simultaneously consider spatial-temporal consistency in MTS-SFDA,
TERSE can also be integrated as a versatile plug-and-play module into
established SFDA methods. Extensive experiments on three real-world time series
datasets demonstrate the effectiveness and versatility of our approach.

</details>


### [30] [ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools](https://arxiv.org/abs/2505.21569)
*Zhucong Li,Bowei Zhang,Jin Xiao,Zhijian Zhou,Fenglei Cao,Jiaqing Liang,Yuan Qi*

Main category: cs.LG

TL;DR: 研究提出了一种优化代理堆叠结构的方法——ChemHAS，以减少化学工具的预测误差，并在多个任务中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用基于大型语言模型（LLM）的代理来减少化学工具的预测误差。

Method: 提出了化学分层代理堆叠（ChemHAS）方法，优化代理堆叠结构以改善化学工具的性能。

Result: ChemHAS在四个基础化学任务中实现了最先进的性能，并识别出四种不同的代理堆叠行为，提高了解释性并揭示了AI代理在科学研究中的新可能性。

Conclusion: 我们的方法可以有效补偿化学工具的预测误差。

Abstract: Large Language Model (LLM)-based agents have demonstrated the ability to
improve performance in chemistry-related tasks by selecting appropriate tools.
However, their effectiveness remains limited by the inherent prediction errors
of chemistry tools. In this paper, we take a step further by exploring how
LLMbased agents can, in turn, be leveraged to reduce prediction errors of the
tools. To this end, we propose ChemHAS (Chemical Hierarchical Agent Stacking),
a simple yet effective method that enhances chemistry tools through optimizing
agent-stacking structures from limited data. ChemHAS achieves state-of-the-art
performance across four fundamental chemistry tasks, demonstrating that our
method can effectively compensate for prediction errors of the tools.
Furthermore, we identify and characterize four distinct agent-stacking
behaviors, potentially improving interpretability and revealing new
possibilities for AI agent applications in scientific research. Our code and
dataset are publicly available at https:
//anonymous.4open.science/r/ChemHAS-01E4/README.md.

</details>


### [31] [FCOS: A Two-Stage Recoverable Model Pruning Framework for Automatic Modulation Recognition](https://arxiv.org/abs/2505.21571)
*Yao Lu,Tengfei Ma,Zeyu Wang,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: FCOS框架通过两阶段剪枝实现高性能和极大压缩，显著减少模型计算需求，精度仅小幅下降。


<details>
  <summary>Details</summary>
Motivation: 传统的人工调制识别方法难以提取可靠的信号特征并满足实时需求，而深度学习方法尽管提高了分类精度，但受限于模型规模和计算要求难以在资源受限设备上部署。现有的剪枝技术在压缩率、硬件加速和精度保留之间存在权衡。为了在极大压缩的同时保持高性能和高效推理，论文引入FCOS框架。

Method: 论文采用了一种新的两阶段剪枝框架FCOS，第一阶段主要通过层次聚类和参数融合实现通道剪枝；第二阶段通过线性探测识别层崩溃并移除因高通道压缩比而导致崩溃的层。

Result: 通过多个AMR基准测试表明，FCOS在95.51% FLOPs减少和95.31%参数减少的同时，仅在Sig2019-12上的精度损失了0.46%，性能表现优于现有的剪枝方法。

Conclusion: FCOS在极大压缩模型复杂度的同时，能够保持高性能和高效推理，显示出在充分保持精度的情况下显著减少计算需求和模型尺寸的潜力。

Abstract: With the rapid development of wireless communications and the growing
complexity of digital modulation schemes, traditional manual modulation
recognition methods struggle to extract reliable signal features and meet
real-time requirements in modern scenarios. Recently, deep learning based
Automatic Modulation Recognition (AMR) approaches have greatly improved
classification accuracy. However, their large model sizes and high
computational demands hinder deployment on resource-constrained devices. Model
pruning provides a general approach to reduce model complexity, but existing
weight, channel, and layer pruning techniques each present a trade-off between
compression rate, hardware acceleration, and accuracy preservation. To this
end, in this paper, we introduce FCOS, a novel Fine-to-COarse two-Stage pruning
framework that combines channel-level pruning with layer-level collapse
diagnosis to achieve extreme compression, high performance and efficient
inference. In the first stage of FCOS, hierarchical clustering and parameter
fusion are applied to channel weights to achieve channel-level pruning. Then a
Layer Collapse Diagnosis (LaCD) module uses linear probing to identify layer
collapse and removes the collapsed layers due to high channel compression
ratio. Experiments on multiple AMR benchmarks demonstrate that FCOS outperforms
existing channel and layer pruning methods. Specifically, FCOS achieves 95.51%
FLOPs reduction and 95.31% parameter reduction while still maintaining
performance close to the original ResNet56, with only a 0.46% drop in accuracy
on Sig2019-12. Code is available at https://github.com/yaolu-zjut/FCOS.

</details>


### [32] [Spectral-inspired Neural Operator for Data-efficient PDE Simulation in Physics-agnostic Regimes](https://arxiv.org/abs/2505.21573)
*Han Wan,Rui Zhang,Hao Sun*

Main category: cs.LG

TL;DR: 提出了一种频谱灵感的神经算子SINO，它可以从有限的数据学习PDE算子，并且没有已知的PDE项，实现了对全局耦合系统的准确模拟。


<details>
  <summary>Details</summary>
Motivation: 经典数值求解器需要细致的离散化和完整的PDE知识，限制了在物理未知或需要快速推理时的适用性。数据驱动的神经PDE求解器虽然缓解了这些限制，但需要大量的训练数据，在数据稀缺的情况下表现不佳。物理感知方法通过结合物理知识来缓解数据需求，但依赖于已知的PDE术语或本地数值方案，限制了其处理未知或全局耦合系统的能力。

Method: 提出了一种新的框架称为Spectral-inspired Neural Operator (SINO)，此框架在频域中操作，并引入了Frequency-to-Vector模块，以学习类似于导数乘子体的谱表示。同时，设计了一个非线性算子块，包括一个具有低通滤波功能的\u03a0-Block，以防止混叠。此外，介绍了一种算子蒸馏技术，以提炼已训练的模型以进行高效推理。

Result: SINO在多个PDE基准测试中实现了最先进的结果，展示了强大的离散化不变性和对分布外初始条件的鲁棒泛化能力。

Conclusion: SINO能够在有限的数据条件下精确模拟全局耦合系统，是首个在没有任何显式PDE项的情况下实现这一功能的方法。

Abstract: Partial differential equations (PDEs) govern the spatiotemporal evolution of
various physical systems. Classical numerical solvers, while accurate, require
fine discretization and full knowledge of the governing PDEs, limiting their
applicability when the physics is unknown or fast inference is required.
Data-driven neural PDE solvers alleviate these constraints by learning from
data but demand large training datasets and perform poorly in data-scarce
regimes. Physics-aware methods mitigate data requirements by incorporating
physical knowledge yet rely on known PDE terms or local numerical schemes,
restricting their ability to handle unknown or globally coupled systems. In
this work, we propose the Spectral-inspired Neural Operator (SINO), a novel
framework that learns PDE operators from limited trajectories (as few as 2-5),
without any known PDE terms. SINO operates in the frequency domain and
introduces a Frequency-to-Vector module to learn spectral representations
analogous to derivative multipliers. To model nonlinear physical interactions,
we design a nonlinear operator block that includes a $\Pi$-Block with low-pass
filtering to prevent aliasing. Finally, we introduce an operator distillation
technique to distill the trained model for efficient inference. SINO achieves
state-of-the-art results across multiple PDE benchmarks, demonstrating strong
discretization invariance and robust generalization to out-of-distribution
initial conditions. To our knowledge, SINO is the first physics-aware method
capable of accurately simulating globally coupled systems (e.g., the
Navier-Stokes equations) from limited data without any explicit PDE terms.

</details>


### [33] [Concentration Distribution Learning from Label Distributions](https://arxiv.org/abs/2505.21576)
*Jiawei Tang,Yuheng Jia*

Main category: cs.LG

TL;DR: 提出了一种背景浓度的概念来改进标签分布学习，并通过概率方法和神经网络提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 标签分布学习未能完整表示实例，尤其是忽略了每个标签的绝对强度，导致信息损失和实例混淆。

Method: 采用概率方法和神经网络来学习标签分布和背景浓度，并进行大量实验验证其有效性。

Result: 实验表明，该方法能够从标签分布中提取背景浓度，并在准确性上超越最新的LDL方法。

Conclusion: 通过引入背景浓度和改进的浓度分布学习，解决了标签分布不能完全表示实例的问题，且该方法在准确预测上比最先进的LDL方法更有效。

Abstract: Label distribution learning (LDL) is an effective method to predict the
relative label description degree (a.k.a. label distribution) of a sample.
However, the label distribution is not a complete representation of an instance
because it overlooks the absolute intensity of each label. Specifically, it's
impossible to obtain the total description degree of hidden labels that not in
the label space, which leads to the loss of information and confusion in
instances. To solve the above problem, we come up with a new concept named
background concentration to serve as the absolute description degree term of
the label distribution and introduce it into the LDL process, forming the
improved paradigm of concentration distribution learning. Moreover, we propose
a novel model by probabilistic methods and neural networks to learn label
distributions and background concentrations from existing LDL datasets.
Extensive experiments prove that the proposed approach is able to extract
background concentrations from label distributions while producing more
accurate prediction results than the state-of-the-art LDL methods. The code is
available in https://github.com/seutjw/CDL-LD.

</details>


### [34] [Fairness in Federated Learning: Fairness for Whom?](https://arxiv.org/abs/2505.21584)
*Afaf Taik,Khaoula Chehbouni,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 本文对联邦学习中的公平性进行了分析，发现现有研究忽视了实际应用中的多样化利益相关者，并提出了一个以危害为中心的框架来改善公平性研究。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习的公平性研究通常优化狭隘的系统级指标而忽略了整个生命周期中产生的危害以及它们对多样化利益相关者的影响。

Method: 通过系统地注解论文中的公平性定义、设计决策、评估实践和动机用例，进行批判性分析，识别出联邦学习中的五个常见问题。

Result: 分析揭示了五个问题：1）仅通过服务器客户端架构框架公平性，2）模拟与动机用例和情境不匹配，3）定义混淆了系统保护与用户保护，4）干预仅针对生命周期中的孤立阶段而忽略了上下游效应，5）缺乏多利益相关者对齐，导致多种公平性定义同时相关。

Conclusion: 我们建议建立一个以危害为中心的框架，将公平性定义与具体风险和利益相关者的脆弱性联系起来，并提供建议以推动更全面、具有情境意识和责任心的联邦学习公平性研究。

Abstract: Fairness in federated learning has emerged as a rapidly growing area of
research, with numerous works proposing formal definitions and algorithmic
interventions. Yet, despite this technical progress, fairness in FL is often
defined and evaluated in ways that abstract away from the sociotechnical
contexts in which these systems are deployed. In this paper, we argue that
existing approaches tend to optimize narrow system level metrics, such as
performance parity or contribution-based rewards, while overlooking how harms
arise throughout the FL lifecycle and how they impact diverse stakeholders. We
support this claim through a critical analysis of the literature, based on a
systematic annotation of papers for their fairness definitions, design
decisions, evaluation practices, and motivating use cases. Our analysis reveals
five recurring pitfalls: 1) fairness framed solely through the lens of server
client architecture, 2) a mismatch between simulations and motivating use-cases
and contexts, 3) definitions that conflate protecting the system with
protecting its users, 4) interventions that target isolated stages of the
lifecycle while neglecting upstream and downstream effects, 5) and a lack of
multi-stakeholder alignment where multiple fairness definitions can be relevant
at once. Building on these insights, we propose a harm centered framework that
links fairness definitions to concrete risks and stakeholder vulnerabilities.
We conclude with recommendations for more holistic, context-aware, and
accountable fairness research in FL.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [35] [Collaborative Agentic AI Needs Interoperability Across Ecosystems](https://arxiv.org/abs/2505.21550)
*Rishi Sharma,Martijn de Vos,Pradyumna Chari,Ramesh Raskar,Anne-Marie Kermarrec*

Main category: cs.NI

TL;DR: 该论文提出了Web of Agents架构，通过采用最低标准解决智能代理生态系统的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 当前解决方案孤立发展，导致生态系统碎片化和不兼容性，需要采用最低标准以实现互操作性。

Method: 设计了Web of Agents架构，包含四个组件，旨在增强智能代理的互操作性。

Result: 提出了Web of Agents架构，以统一标准实现智能代理系统的互操作性基础。

Conclusion: 推动智能代理系统的互操作性是防止生态系统碎片化的关键。

Abstract: Collaborative agentic AI is projected to transform entire industries by
enabling AI-powered agents to autonomously perceive, plan, and act within
digital environments. Yet, current solutions in this field are all built in
isolation, and we are rapidly heading toward a landscape of fragmented,
incompatible ecosystems. In this position paper, we argue that
interoperability, achieved by the adoption of minimal standards, is essential
to ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To
this end, we devise a minimal architectural foundation for collaborative
agentic AI, named Web of Agents, which is composed of four components:
agent-to-agent messaging, interaction interoperability, state management, and
agent discovery. Web of Agents adopts existing standards and reuses existing
infrastructure where possible. With Web of Agents, we take the first but
critical step toward interoperable agentic systems and offer a pragmatic path
forward before ecosystem fragmentation becomes the norm.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [36] [Edge Games: Cooperative Partner Selection in Network Cooperation Evolution](https://arxiv.org/abs/2505.21515)
*Hongqian Wu,Hongzhong Deng,Jichao Li,Chengxing Wu,Zhuoting Yu,Haidong Zhang,Gaoxin Qi*

Main category: physics.soc-ph

TL;DR: 边缘博弈模型通过角色交换及引入协同因子r，改善复杂网络中的合作演化，较传统模型在性能与复杂度上更具优势。


<details>
  <summary>Details</summary>
Motivation: 传统演化博弈论模型不便于直接选择合作伙伴，因此引入边缘博弈模型，将复杂网络中的边缘作为群体游戏的虚拟玩家。

Method: 通过配置一个协同因子r满足“适度合作”条件，实现任意网络在演化均衡状态下的稳定合作结构。

Result: 在无约束节点合作者数量情况下，合作演化条件为r > kmax；有阈值约束时，在最近邻耦合网络中条件为k < r < 2k；异质网络中采用可变协同因子，适度合作可在1 < n-fold < 2时实现。

Conclusion: 边缘博弈模型为解决多智能体合作问题提供了一个新方法，在算法性能与时间复杂度上优于其他优化算法。

Abstract: The phenomenon of group cooperation constitutes a fundamental mechanism
underlying various social and biological systems. Complex networks provide a
structural framework for group interactions, where individuals can not only
obtain information from their neighbors but also choose neighbors as
cooperative partners. However, traditional evolutionary game theory models,
where nodes are the game players, are not convenient for directly choosing
cooperative partners. Here, we exchange the roles of nodes and edges and
innovatively propose the "edge game" model, using edges in complex networks as
virtual game players for group games. Theoretical analysis and simulation
experiments show that by configuring a synergy factor (r) that satisfies the
"moderate cooperation" condition, a stable cooperative structure can be
achieved for any network at the evolutionary equilibrium. Specifically, when
there is no constraint on the number of cooperators per node, the condition for
the evolution of cooperation in the network is r > kmax, where kmax is the
maximum degree of the nodes. When there is a threshold constraint, in
nearest-neighbor coupled networks (with degree k), the condition for "moderate
cooperation" is k < r < 2k. In heterogeneous networks, a variable synergy
factor scheme is adopted, where the synergy factor for each game group (rx) is
defined to be proportional to the degree of the central node (kx) in the group
(rx = n-fold*kx), "moderate cooperation" can be achieved when 1 < n-fold < 2.
If the value of r exceeds the range, it may lead to "excessive cooperation"
with node overload. Comparing algorithm performance and time complexity, edge
games demonstrate advantages over other optimization algorithms. Simple and
universal, the edge game provides a new approach to addressing multi-agent
cooperation problems in the era of machine intelligence.

</details>


### [37] [Improving flocking behaviors in street networks with vision](https://arxiv.org/abs/2505.21585)
*Guillaume Moinard,Matthieu Latapy*

Main category: physics.soc-ph

TL;DR: 通过扩大行走者的视野改善模型，使得行走者在交叉路口不分散并聚集分散群体，从而提高了聚集时间和稳定性。


<details>
  <summary>Details</summary>
Motivation: 我们希望改善街道网络中的聚集模型，并使模型更加逼真。

Method: 我们采用了扩大的视野字段来改善模型的现实性。

Result: 通过此改进，我们获得的行走者群体在聚集时间和抵抗解体方面优于过去的结果。

Conclusion: 通过调整视野中的对齐规则和吸引规则，行走者在交叉路口不再分散，并能够聚集分散的群体，改进了群体的稳定性和聚集效率。

Abstract: We improve a flocking model on street networks introduced in a previous
paper. We expand the field of vision of walkers, making the model more
realistic. Under such conditions, we obtain groups of walkers whose gathering
times and robustness to break ups are better than previous results. We explain
such improvements because the alignment rule with vision guaranties walkers do
not split into divergent directions at intersections anymore, and because the
attraction rule with vision gathers distant groups. This paves the way to a
better understanding of events where walkers have collective decentralized
goals, like protests.

</details>
