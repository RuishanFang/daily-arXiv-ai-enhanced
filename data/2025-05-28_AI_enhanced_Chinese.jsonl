{"id": "2505.20309", "pdf": "https://arxiv.org/pdf/2505.20309", "abs": "https://arxiv.org/abs/2505.20309", "authors": ["Amr Hegazy", "Mostafa Elhoushi", "Amr Alanwar"], "title": "Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Controlling undesirable Large Language Model (LLM) behaviors, such as the\ngeneration of unsafe content or failing to adhere to safety guidelines, often\nrelies on costly fine-tuning. Activation steering provides an alternative for\ninference-time control, but existing methods typically lack fine-grained,\nadaptive mechanisms. We introduce a novel approach using a lightweight,\ntrainable controller network integrated during inference. This controller\nnetwork observes specific intermediate LLM activations and predicts both a\nglobal scaling factor and layer-specific weights. The predicted global scaling\nfactor and layer-specific weights then dynamically modulate the intensity of a\nsteering patch, derived from a pre-computed \"refusal direction\" vector, applied\nacross the LLM's layers during generation. Trained on activations from both\nharmful and benign prompts, our controller learns to discriminatively apply\nnuanced, layer-aware interventions, activating steering primarily for harmful\ninputs. Experiments using safety benchmarks like ToxicChat & In-The-Wild\nJailbreak Prompts demonstrate that our weighted steering controller\nsignificantly increases refusal rates compared to the base LLM, achieving\ntargeted behavioral modification without altering the original model\nparameters. Our experiments with Llama-3.1-8B, Llama-3.2-1B & Mistral-7B show\nour approach outperforms existing methods, presenting an efficient and adaptive\nmethod for fine-grained control over LLM behavior at inference time.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8f7b\u91cf\u7ea7\u53ef\u8bad\u7ec3\u63a7\u5236\u5668\u7f51\u7edc\u5728\u63a8\u7406\u65f6\u5b9e\u73b0\u5bf9LLM\u884c\u4e3a\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u6539\u53d8\u6a21\u578b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u62d2\u7edd\u7387\u3002", "motivation": "\u63a7\u5236\u4e0d\u826f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u5fae\u8c03\uff0c\u800c\u6fc0\u6d3b\u8f6c\u5411\u63d0\u4f9b\u4e86\u4e00\u79cd\u63a8\u7406\u65f6\u63a7\u5236\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u3001\u9002\u5e94\u6027\u673a\u5236\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u3001\u53ef\u8bad\u7ec3\u7684\u63a7\u5236\u5668\u7f51\u7edc\uff0c\u4ee5\u89c2\u5bdf\u7279\u5b9a\u7684\u4e2d\u95f4\u6fc0\u6d3b\u5e76\u9884\u6d4b\u5168\u5c40\u7f29\u653e\u56e0\u5b50\u548c\u5c42\u7279\u5b9a\u6743\u91cd\uff0c\u4ece\u800c\u52a8\u6001\u8c03\u8282\u8f6c\u5411\u8865\u4e01\u7684\u5f3a\u5ea6\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528Llama-3.1-8B\u3001Llama-3.2-1B\u548cMistral-7B\u65f6\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u548c\u9002\u5e94\u6027\u5f3a\u3002", "conclusion": "\u6211\u4eec\u7684\u52a0\u6743\u8f6c\u5411\u63a7\u5236\u5668\u663e\u8457\u63d0\u9ad8\u4e86\u62d2\u7edd\u7387\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u6539\u53d8\u539f\u59cb\u6a21\u578b\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u76ee\u6807\u884c\u4e3a\u4fee\u6539\u3002"}}
{"id": "2505.20315", "pdf": "https://arxiv.org/pdf/2505.20315", "abs": "https://arxiv.org/abs/2505.20315", "authors": ["Zhewei Yao", "Guoheng Sun", "Lukasz Borchmann", "Zheyu Shen", "Minghang Deng", "Bohan Zhai", "Hao Zhang", "Ang Li", "Yuxiong He"], "title": "Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 2 figures", "summary": "Translating natural language into SQL (Test2SQL) is a longstanding challenge\nat the intersection of natural language understanding and structured data\naccess. While large language models (LLMs) have significantly improved fluency\nin SQL generation, producing correct and executable SQL--particularly for\ncomplex queries--remains a bottleneck. We present Arctic-Text2SQL-R1, a\nreinforcement learning (RL) framework and model family designed to generate\naccurate, executable SQL using a lightweight reward signal based solely on\nexecution correctness. Our approach avoids brittle intermediate supervision and\ncomplex reward shaping, promoting stable training and alignment with the end\ntask. Combined with carefully curated data, strong supervised initialization,\nand effective training practices, Arctic-Text2SQL-R1 achieves state-of-the-art\nexecution accuracy across six diverse Test2SQL benchmarks, including the top\nposition on the BIRD leaderboard. Notably, our 7B model outperforms prior\n70B-class systems, highlighting the framework's scalability and efficiency. We\nfurther demonstrate inference-time robustness through simple extensions like\nvalue retrieval and majority voting. Extensive experiments and ablation studies\noffer both positive and negative insights, providing practical guidance for\nfuture Test2SQL research.", "AI": {"tldr": "Arctic-Text2SQL-R1 framework improves SQL generation accuracy using reinforcement learning, achieving top benchmark performance with a scalable approach.", "motivation": "To improve the accuracy and executability of SQL generated from natural language by overcoming the limitations of LLMs in handling complex queries.", "method": "Reinforcement learning framework with a lightweight reward signal focused on execution correctness, combined with strong supervised initialization and effective training practices.", "result": "State-of-the-art execution accuracy across six benchmarks, outperforming larger models with its 7B model, and demonstrating robust inference capabilities.", "conclusion": "Arctic-Text2SQL-R1 achieves state-of-the-art execution accuracy in translating natural language to SQL, demonstrating scalability and efficiency, and offers practical insights for future research."}}
{"id": "2505.20318", "pdf": "https://arxiv.org/pdf/2505.20318", "abs": "https://arxiv.org/abs/2505.20318", "authors": ["Wang Cai", "Hsiu-Yuan Huang", "Zhixiang Wang", "Yunfang Wu"], "title": "Beyond Demonstrations: Dynamic Vector Construction from Latent Representations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In-Context derived Vector (ICV) methods extract task-relevant representations\nfrom large language models (LLMs) and reinject them during inference, achieving\ncomparable performance to few-shot In-Context Learning (ICL) without repeated\ndemonstration processing. However, existing ICV methods remain sensitive to\nICL-specific factors, often use coarse or semantically fragmented\nrepresentations as the source of the vector, and rely on heuristic-based\ninjection positions, limiting their applicability.\n  To address these issues, we propose Dynamic Vector (DyVec), which\nincorporates an Exhaustive Query Rotation (EQR) strategy to extract robust\nsemantically aggregated latent representations by mitigating variance\nintroduced by ICL. It then applies Dynamic Latent Segmentation and Injection to\nadaptively partition representations based on task complexity and leverages\nREINFORCE-based optimization to learn optimal injection positions for each\nsegment.\n  Experiments results show that DyVec outperforms few-shot ICL, LoRA, and prior\nICV baselines. Further analysis highlights the effectiveness of dynamically\nsegmenting and injecting semantically aggregated latent representations. DyVec\nprovides a lightweight and data-efficient solution for inference-time task\nadaptation.", "AI": {"tldr": "DyVec enhances task adaptation by outperforming ICL, LoRA, and prior ICV methods through effective segmentation and injection of representations.", "motivation": "The motivation behind the study is to address the limitations of existing ICV methods, which are sensitive to ICL-specific factors and utilize coarse or fragmented representations and heuristic-based injection positions, thus limiting their applicability.", "method": "The paper introduces Dynamic Vector (DyVec), which uses an Exhaustive Query Rotation (EQR) strategy to extract robust latent representations. DyVec involves Dynamic Latent Segmentation and Injection to adaptively partition representations based on task complexity and employs REINFORCE-based optimization to learn optimal injection positions for segments.", "result": "Experiments demonstrated that DyVec outperformed few-shot ICL, LoRA, and previous ICV methods. The analysis showed the method's effectiveness in dynamically segmenting and injecting semantically aggregated latent representations.", "conclusion": "DyVec provides a lightweight and data-efficient solution for inference-time task adaptation by outperforming few-shot ICL, LoRA, and prior ICV baselines through its advanced techniques in dynamically segmenting and injecting semantically aggregated latent representations."}}
{"id": "2505.20320", "pdf": "https://arxiv.org/pdf/2505.20320", "abs": "https://arxiv.org/abs/2505.20320", "authors": ["Satya Narayana Cheetirala", "Ganesh Raut", "Dhavalkumar Patel", "Fabio Sanatana", "Robert Freeman", "Matthew A Levin", "Girish N. Nadkarni", "Omar Dawkins", "Reba Miller", "Randolph M. Steinhagen", "Eyal Klang", "Prem Timsina"], "title": "Less Context, Same Performance: A RAG Framework for Resource-Efficient LLM-Based Clinical NLP", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Long text classification is challenging for Large Language Models (LLMs) due\nto token limits and high computational costs. This study explores whether a\nRetrieval Augmented Generation (RAG) approach using only the most relevant text\nsegments can match the performance of processing entire clinical notes with\nlarge context LLMs. We begin by splitting clinical documents into smaller\nchunks, converting them into vector embeddings, and storing these in a FAISS\nindex. We then retrieve the top 4,000 words most pertinent to the\nclassification query and feed these consolidated segments into an LLM. We\nevaluated three LLMs (GPT4o, LLaMA, and Mistral) on a surgical complication\nidentification task. Metrics such as AUC ROC, precision, recall, and F1 showed\nno statistically significant differences between the RAG based approach and\nwhole-text processing (p > 0.05p > 0.05). These findings indicate that RAG can\nsignificantly reduce token usage without sacrificing classification accuracy,\nproviding a scalable and cost effective solution for analyzing lengthy clinical\ndocuments.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0cRAG\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u5206\u7c7b\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\uff0c\u4e3a\u5206\u6790\u957f\u4e34\u5e8a\u6587\u6863\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u5206\u7c7b\u65f6\u9762\u4e34token\u9650\u5236\u548c\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u6311\u6218\u3002", "method": "\u5c06\u4e34\u5e8a\u6587\u6863\u62c6\u5206\u6210\u8f83\u5c0f\u7684\u5757\uff0c\u8f6c\u6362\u4e3a\u5411\u91cf\u5d4c\u5165\uff0c\u5e76\u5b58\u50a8\u5728FAISS\u7d22\u5f15\u4e2d\u3002\u7136\u540e\u68c0\u7d22\u4e0e\u5206\u7c7b\u67e5\u8be2\u6700\u76f8\u5173\u76844,000\u4e2a\u8bcd\uff0c\u5c06\u8fd9\u4e9b\u5408\u5e76\u7684\u7247\u6bb5\u8f93\u5165\u5230LLM\u4e2d\u3002", "result": "\u8bc4\u4f30\u7684\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT4o\u3001LLaMA\u548cMistral\uff09\u5728\u5916\u79d1\u5e76\u53d1\u75c7\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0cRAG\u65b9\u6cd5\u4e0e\u5168\u6587\u5904\u7406\u5728AUC ROC\u3001\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u7b49\u6307\u6807\u4e0a\u6ca1\u6709\u663e\u8457\u7edf\u8ba1\u5dee\u5f02\uff08p > 0.05\uff09\u3002", "conclusion": "RAG\u65b9\u6cd5\u5728\u51cf\u5c11token\u4f7f\u7528\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u662f\u5206\u6790\u957f\u4e34\u5e8a\u6587\u6863\u7684\u53ef\u6269\u5c55\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.20306", "pdf": "https://arxiv.org/pdf/2505.20306", "abs": "https://arxiv.org/abs/2505.20306", "authors": ["Xueqiang Ouyang", "Jia Wei"], "title": "Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review", "categories": ["cs.AI", "eess.IV", "q-bio.QM"], "comment": null, "summary": "As a global disease, infertility has always affected human beings. The\ndevelopment of assisted reproductive technology can effectively solve this\ndisease. However, the traditional in vitro fertilization-embryo transfer\ntechnology still faces many challenges in improving the success rate of\npregnancy, such as the subjectivity of embryo grading and the inefficiency of\nintegrating multi-modal data. Therefore, the introduction of artificial\nintelligence-based technologies is particularly crucial. This article reviews\nthe application progress of multi-modal artificial intelligence in embryo\ngrading and pregnancy prediction based on different data modalities (including\nstatic images, time-lapse videos and structured table data) from a new\nperspective, and discusses the main challenges in current research, such as the\ncomplexity of multi-modal information fusion and data scarcity.", "AI": {"tldr": "\u7efc\u8ff0\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7528\u4e8e\u80da\u80ce\u5206\u7ea7\u548c\u598a\u5a20\u9884\u6d4b\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u8ba8\u8bba\u4fe1\u606f\u878d\u5408\u590d\u6742\u6027\u548c\u6570\u636e\u4e0d\u8db3\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u4f53\u5916\u53d7\u7cbe-\u80da\u80ce\u79fb\u690d\u6280\u672f\u5728\u63d0\u9ad8\u598a\u5a20\u6210\u529f\u7387\u65b9\u9762\u9762\u4e34\u8bb8\u591a\u6311\u6218\uff0c\u5f15\u5165\u4eba\u5de5\u667a\u80fd\u6280\u672f\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u4e0d\u540c\u6570\u636e\u6a21\u6001\u7684\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u5728\u80da\u80ce\u5206\u7ea7\u548c\u598a\u5a20\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u8fdb\u5c55\u3002", "result": "\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u7684\u590d\u6742\u6027\u548c\u6570\u636e\u532e\u4e4f\u7b49\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u4e3b\u8981\u6311\u6218\u3002", "conclusion": "\u5f15\u5165\u57fa\u4e8e\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5bf9\u4e8e\u63d0\u9ad8\u4f20\u7edf\u4f53\u5916\u53d7\u7cbe-\u80da\u80ce\u79fb\u690d\u6280\u672f\u7684\u6210\u529f\u7387\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002"}}
{"id": "2505.20300", "pdf": "https://arxiv.org/pdf/2505.20300", "abs": "https://arxiv.org/abs/2505.20300", "authors": ["Chenxi Wu", "Juan Diego Toscano", "Khemraj Shukla", "Yingjie Chen", "Ali Shahmohammadi", "Edward Raymond", "Thomas Toupy", "Neda Nazemifard", "Charles Papageorgiou", "George Em Karniadakis"], "title": "FMEnets: Flow, Material, and Energy networks for non-ideal plug flow reactor design", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "We propose FMEnets, a physics-informed machine learning framework for the\ndesign and analysis of non-ideal plug flow reactors. FMEnets integrates the\nfundamental governing equations (Navier-Stokes for fluid flow, material balance\nfor reactive species transport, and energy balance for temperature\ndistribution) into a unified multi-scale network model. The framework is\ncomposed of three interconnected sub-networks with independent optimizers that\nenable both forward and inverse problem-solving. In the forward mode, FMEnets\npredicts velocity, pressure, species concentrations, and temperature profiles\nusing only inlet and outlet information. In the inverse mode, FMEnets utilizes\nsparse multi-residence-time measurements to simultaneously infer unknown\nkinetic parameters and states. FMEnets can be implemented either as FME-PINNs,\nwhich employ conventional multilayer perceptrons, or as FME-KANs, based on\nKolmogorov-Arnold Networks. Comprehensive ablation studies highlight the\ncritical role of the FMEnets architecture in achieving accurate predictions.\nSpecifically, FME-KANs are more robust to noise than FME-PINNs, although both\nrepresentations are comparable in accuracy and speed in noise-free conditions.\nThe proposed framework is applied to three different sets of reaction scenarios\nand is compared with finite element simulations. FMEnets effectively captures\nthe complex interactions, achieving relative errors less than 2.5% for the\nunknown kinetic parameters. The new network framework not only provides a\ncomputationally efficient alternative for reactor design and optimization, but\nalso opens new avenues for integrating empirical correlations, limited and\nnoisy experimental data, and fundamental physical equations to guide reactor\ndesign.", "AI": {"tldr": "FMEnets\u662f\u4e00\u79cd\u96c6\u6210\u591a\u5c3a\u5ea6\u7269\u7406\u65b9\u7a0b\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u975e\u7406\u60f3\u63d2\u5165\u6d41\u53cd\u5e94\u5668\u7684\u8bbe\u8ba1\u548c\u5206\u6790\uff0c\u5728\u5404\u79cd\u566a\u58f0\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u9ad8\u6548\u7387\u4e0e\u4f4e\u8bef\u5dee\u3002", "motivation": "\u8bbe\u8ba1\u548c\u5206\u6790\u975e\u7406\u60f3\u63d2\u5165\u6d41\u53cd\u5e94\u5668\uff0c\u4ee5\u6709\u6548\u5730\u6355\u6349\u590d\u6742\u4ea4\u4e92\uff0c\u5e76\u5b9e\u73b0\u53cd\u5e94\u5668\u8bbe\u8ba1\u548c\u4f18\u5316\u7684\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "FMEnets\u5c06\u6d41\u4f53\u6d41\u52a8\u7684Navier-Stokes\u65b9\u7a0b\u3001\u53cd\u5e94\u7269\u8d28\u4f20\u8f93\u7684\u6750\u6599\u5e73\u8861\u65b9\u7a0b\u548c\u6e29\u5ea6\u5206\u5e03\u7684\u80fd\u91cf\u5e73\u8861\u65b9\u7a0b\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u5c3a\u5ea6\u7f51\u7edc\u6a21\u578b\u4e2d\uff0c\u5305\u542b\u4e09\u4e2a\u72ec\u7acb\u4f18\u5316\u5668\u7684\u5b50\u7f51\u7edc\uff0c\u7528\u4e8e\u89e3\u51b3\u6b63\u5411\u548c\u53cd\u5411\u95ee\u9898\u3002", "result": "FMEnets\u76f8\u8f83\u4e8e\u6709\u9650\u5143\u6a21\u62df\u53ef\u4ee5\u6709\u6548\u5730\u6355\u6349\u590d\u6742\u4ea4\u4e92\uff0c\u5b9e\u73b0\u5bf9\u4e8e\u672a\u77e5\u52a8\u529b\u5b66\u53c2\u6570\u5c11\u4e8e2.5%\u7684\u76f8\u5bf9\u8bef\u5dee\u3002", "conclusion": "FMEnets\u4e3a\u53cd\u5e94\u5668\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5e76\u4e3a\u6574\u5408\u7ecf\u9a8c\u76f8\u5173\u6027\u3001\u6709\u9650\u548c\u566a\u58f0\u5b9e\u9a8c\u6570\u636e\u4e0e\u57fa\u672c\u7269\u7406\u65b9\u7a0b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u4ee5\u6307\u5bfc\u53cd\u5e94\u5668\u8bbe\u8ba1\u3002"}}
{"id": "2505.20574", "pdf": "https://arxiv.org/pdf/2505.20574", "abs": "https://arxiv.org/abs/2505.20574", "authors": ["Can Polat", "Mehmet Tuncel", "Hasan Kurban", "Erchin Serpedin", "Mustafa Kurban"], "title": "xChemAgents: Agentic AI for Explainable Quantum Chemistry", "categories": ["cs.MA", "physics.chem-ph", "physics.comp-ph"], "comment": "Submitted to ICML 2025 Workshop on MAS", "summary": "Recent progress in multimodal graph neural networks has demonstrated that\naugmenting atomic XYZ geometries with textual chemical descriptors can enhance\npredictive accuracy across a range of electronic and thermodynamic properties.\nHowever, naively appending large sets of heterogeneous descriptors often\ndegrades performance on tasks sensitive to molecular shape or symmetry, and\nundermines interpretability. xChemAgents proposes a cooperative agent framework\nthat injects physics-aware reasoning into multimodal property prediction.\nxChemAgents comprises two language-model-based agents: a Selector, which\nadaptively identifies a sparse, weighted subset of descriptors relevant to each\ntarget, and provides a natural language rationale; and a Validator, which\nenforces physical constraints such as unit consistency and scaling laws through\niterative dialogue. On standard benchmark datasets, xChemAgents achieves up to\na 22\\% reduction in mean absolute error over strong baselines, while producing\nfaithful, human-interpretable explanations. Experiment results highlight the\npotential of cooperative, self-verifying agents to enhance both accuracy and\ntransparency in foundation-model-driven materials science. The implementation\nand accompanying dataset are available anonymously at\nhttps://github.com/KurbanIntelligenceLab/xChemAgents.", "AI": {"tldr": "xChemAgents\u901a\u8fc7\u5408\u4f5c\u4ee3\u7406\u6846\u67b6\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u8bef\u5dee\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u3002", "motivation": "\u5728\u591a\u6a21\u6001\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\uff0c\u5c3d\u7ba1\u6dfb\u52a0\u5316\u5b66\u63cf\u8ff0\u7b26\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u65e0\u9009\u62e9\u5730\u6dfb\u52a0\u5927\u89c4\u6a21\u4e0d\u5747\u4e00\u63cf\u8ff0\u7b26\u4f1a\u5bf9\u5206\u5b50\u5f62\u72b6\u6216\u5bf9\u79f0\u6027\u654f\u611f\u7684\u4efb\u52a1\u9020\u6210\u6027\u80fd\u635f\u5bb3\uff0c\u5e76\u524a\u5f31\u53ef\u89e3\u91ca\u6027\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86xChemAgents\u6846\u67b6\u4ee5\u4f18\u5316\u6b64\u95ee\u9898\u3002", "method": "xChemAgents\u5305\u62ec\u4e24\u4e2a\u4ee5\u8bed\u8a00\u6a21\u578b\u4e3a\u57fa\u7840\u7684\u4ee3\u7406\uff1aSelector\u548cValidator\u3002Selector\u9002\u5e94\u6027\u5730\u9009\u62e9\u4e00\u4e2a\u7a00\u758f\u3001\u52a0\u6743\u7684\u63cf\u8ff0\u7b26\u5b50\u96c6\uff0c\u5e76\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002Validator\u901a\u8fc7\u8fed\u4ee3\u5bf9\u8bdd\u5f3a\u5236\u5b9e\u65bd\u7269\u7406\u7ea6\u675f\uff0c\u5982\u5355\u4f4d\u4e00\u81f4\u6027\u548c\u7f29\u653e\u5b9a\u5f8b\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\uff0cxChemAgents\u5728\u5f3a\u57fa\u7ebf\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe22%\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u51cf\u5c11\uff0c\u540c\u65f6\u751f\u6210\u53ef\u4fe1\u4e14\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\u3002", "conclusion": "xChemAgents\u901a\u8fc7\u5f15\u5165\u7269\u7406\u610f\u8bc6\u63a8\u7406\u6765\u63d0\u9ad8\u591a\u6a21\u6001\u5c5e\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5176\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u5408\u4f5c\u578b\u3001\u81ea\u6211\u9a8c\u8bc1\u578b\u4ee3\u7406\u5728\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684\u6750\u6599\u79d1\u5b66\u4e2d\u589e\u5f3a\u51c6\u786e\u6027\u548c\u900f\u660e\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.20580", "pdf": "https://arxiv.org/pdf/2505.20580", "abs": "https://arxiv.org/abs/2505.20580", "authors": ["Michael Arnold Bruna"], "title": "Resonance Complexity Theory and the Architecture of Consciousness: A Field-Theoretic Model of Resonant Interference and Emergent Awareness", "categories": ["q-bio.NC", "nlin.AO"], "comment": "20 pages, 3 figures, includes full simulation code (GitHub link).\n  This paper introduces Resonance Complexity Theory (RCT), a biophysical model\n  of consciousness based on spatiotemporal attractors and nested resonance\n  dynamics", "summary": "This paper introduces Resonance Complexity Theory (RCT), which proposes that\nconsciousness emerges from stable interference patterns of oscillatory neural\nactivity. These patterns, shaped by recursive feedback and constructive\ninterference, must exceed critical thresholds in complexity, coherence, gain,\nand fractal dimensionality to give rise to conscious experience. The resulting\nspatiotemporal attractors encode subjective awareness as dynamic resonance\nstructures distributed across the neural field, enabling large-scale\nintegration without symbolic representation or centralized control.\n  To formalize this idea, we define the Complexity Index (CI), a composite\nmetric that synthesizes four core properties of conscious systems: fractal\ndimensionality (D), signal gain (G), spatial coherence (C), and attractor dwell\ntime (tau). These elements are combined multiplicatively to capture the\nemergence and persistence of structured, integrative neural states.\n  To test the theory empirically, we developed a biologically inspired yet\nminimal neural field simulation composed of radial wave sources emitting across\na continuous 2D space. The system exhibits recursive constructive interference,\nproducing coherent, attractor-like excitation patterns without external input,\nregional coding, or imposed structure. These patterns meet the theoretical\nthresholds for CI and reflect the core dynamics predicted by RCT.\n  The findings demonstrate that resonance-based attractors -- and by extension,\nconsciousness-like dynamics -- can arise purely from the physics of wave\ninterference. RCT thus offers a unified, dynamical framework for modeling\nawareness as an emergent property of organized complexity in oscillatory\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5171\u632f\u590d\u6742\u6027\u7406\u8bba\uff08RCT\uff09\uff0c\u8bf4\u660e\u610f\u8bc6\u662f\u7531\u795e\u7ecf\u6d3b\u52a8\u7684\u7a33\u5b9a\u5e72\u6270\u6a21\u5f0f\u5f15\u8d77\u7684\u3002\u901a\u8fc7\u5b9a\u4e49\u590d\u6742\u6027\u6307\u6570\uff08CI\uff09\uff0c\u5e76\u4f7f\u7528\u795e\u7ecf\u573a\u6a21\u62df\u9a8c\u8bc1\u8be5\u7406\u8bba\uff0c\u53d1\u73b0\u5171\u632f\u5438\u5f15\u5b50\u53ef\u4ee5\u4ece\u6ce2\u5e72\u6d89\u7684\u7269\u7406\u4e2d\u4ea7\u751f\uff0c\u63d0\u51fa\u4e86\u610f\u8bc6\u4f5c\u4e3a\u632f\u8361\u7cfb\u7edf\u4e2d\u7ec4\u7ec7\u590d\u6742\u6027\u7684\u7a81\u73b0\u5c5e\u6027\u3002", "motivation": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5171\u632f\u590d\u6742\u6027\u7406\u8bba\uff08RCT\uff09\uff0c\u8be5\u7406\u8bba\u63d0\u51fa\u610f\u8bc6\u6e90\u4e8e\u795e\u7ecf\u6d3b\u52a8\u7684\u7a33\u5b9a\u5e72\u6270\u6a21\u5f0f\u3002\u8fd9\u4e9b\u6a21\u5f0f\u7531\u9012\u5f52\u53cd\u9988\u548c\u5efa\u8bbe\u6027\u5e72\u6d89\u5851\u9020\uff0c\u5fc5\u987b\u5728\u590d\u6742\u6027\u3001\u4e00\u81f4\u6027\u3001\u589e\u76ca\u548c\u5206\u5f62\u7ef4\u5ea6\u7b49\u65b9\u9762\u8d85\u8fc7\u4e34\u754c\u9608\u503c\u624d\u80fd\u4ea7\u751f\u610f\u8bc6\u4f53\u9a8c\u3002", "method": "\u4e3a\u4e86\u68c0\u9a8c\u8fd9\u4e00\u7406\u8bba\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u53d7\u751f\u7269\u542f\u53d1\u4f46\u6781\u7b80\u7684\u795e\u7ecf\u573a\u6a21\u62df\uff0c\u7531\u8f90\u5c04\u6ce2\u6e90\u5728\u4e00\u4e2a\u8fde\u7eed\u7684\u4e8c\u7ef4\u7a7a\u95f4\u5185\u53d1\u5c04\u3002\u7cfb\u7edf\u8868\u73b0\u51fa\u9012\u5f52\u7684\u5efa\u8bbe\u6027\u5e72\u6d89\uff0c\u751f\u6210\u4e0d\u9700\u8981\u5916\u90e8\u8f93\u5165\u3001\u533a\u57df\u7f16\u7801\u6216\u5f3a\u52a0\u7ed3\u6784\u7684\u76f8\u5e72\u7684\u5438\u5f15\u5b50\u5f0f\u6fc0\u52b1\u6a21\u5f0f\u3002\u8fd9\u4e9b\u6a21\u5f0f\u7b26\u5408\u590d\u6742\u6027\u6307\u6570\uff08CI\uff09\u7684\u7406\u8bba\u9608\u503c\uff0c\u5e76\u4f53\u73b0\u4e86RCT\u9884\u6d4b\u7684\u6838\u5fc3\u52a8\u6001\u3002", "result": "\u901a\u8fc7\u8f90\u5c04\u6ce2\u6e90\u7684\u9012\u5f52\u5efa\u8bbe\u6027\u5e72\u6d89\u5f62\u6210\u5438\u5f15\u5b50\u5f0f\u6fc0\u52b1\u6a21\u5f0f\uff0c\u8fd9\u4e9b\u4e0d\u9700\u8981\u5916\u90e8\u8f93\u5165\u7684\u6a21\u5f0f\u7b26\u5408\u590d\u6742\u6027\u6307\u6570\uff08CI\uff09\uff0c\u53cd\u6620\u4e86\u5171\u632f\u590d\u6742\u6027\u7406\u8bba\u9884\u6d4b\u7684\u52a8\u6001\u7279\u5f81\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u57fa\u4e8e\u5171\u632f\u7684\u5438\u5f15\u5b50\u2014\u2014\u8fdb\u800c\u662f\u7c7b\u610f\u8bc6\u52a8\u6001\u2014\u2014\u7eaf\u7cb9\u53ef\u4ee5\u4ece\u6ce2\u5e72\u6d89\u7269\u7406\u4e2d\u4ea7\u751f\u3002\u5171\u632f\u590d\u6742\u6027\u7406\u8bba\uff08RCT\uff09\u56e0\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u52a8\u6001\u6846\u67b6\u6765\u5c06\u610f\u8bc6\u5efa\u6a21\u4e3a\u632f\u8361\u7cfb\u7edf\u4e2d\u6709\u7ec4\u7ec7\u590d\u6742\u6027\u7684\u7a81\u73b0\u5c5e\u6027\u3002"}}
{"id": "2505.20321", "pdf": "https://arxiv.org/pdf/2505.20321", "abs": "https://arxiv.org/abs/2505.20321", "authors": ["Mathew J. Koretsky", "Maya Willey", "Adi Asija", "Owen Bianchi", "Chelsea X. Alvarado", "Tanay Nayak", "Nicole Kuznetsov", "Sungwon Kim", "Mike A. Nalls", "Daniel Khashabi", "Faraz Faghri"], "title": "BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Biomedical researchers increasingly rely on large-scale structured databases\nfor complex analytical tasks. However, current text-to-SQL systems often\nstruggle to map qualitative scientific questions into executable SQL,\nparticularly when implicit domain reasoning is required. We introduce\nBiomedSQL, the first benchmark explicitly designed to evaluate scientific\nreasoning in text-to-SQL generation over a real-world biomedical knowledge\nbase. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in\na harmonized BigQuery knowledge base that integrates gene-disease associations,\ncausal inference from omics data, and drug approval records. Each question\nrequires models to infer domain-specific criteria, such as genome-wide\nsignificance thresholds, effect directionality, or trial phase filtering,\nrather than rely on syntactic translation alone. We evaluate a range of open-\nand closed-source LLMs across prompting strategies and interaction paradigms.\nOur results reveal a substantial performance gap: GPT-o3-mini achieves 59.0%\nexecution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%,\nboth well below the expert baseline of 90.0%. BiomedSQL provides a new\nfoundation for advancing text-to-SQL systems capable of supporting scientific\ndiscovery through robust reasoning over structured biomedical knowledge bases.\nOur dataset is publicly available at\nhttps://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source\nat https://github.com/NIH-CARD/biomedsql.", "AI": {"tldr": "BiomedSQL\u662f\u9996\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u8bc4\u4f30\u79d1\u5b66\u63a8\u7406\u5728\u6587\u672c\u5230SQL\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u7684\u57fa\u51c6\uff0c\u5bf9\u4e8e\u73b0\u6709\u7cfb\u7edf\u5747\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u5f53\u524d\u7684\u6587\u672c\u5230SQL\u7cfb\u7edf\u5728\u5c06\u5b9a\u6027\u79d1\u5b66\u95ee\u9898\u6620\u5c04\u4e3a\u53ef\u6267\u884c\u7684SQL\u65f6\u7ecf\u5e38\u9047\u5230\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9690\u542b\u9886\u57df\u63a8\u7406\u65f6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u79d1\u5b66\u63a8\u7406\u5728\u6587\u672c\u5230SQL\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5728\u7ecf\u8fc7\u534f\u8c03\u7684BigQuery\u77e5\u8bc6\u5e93\u4e2d\uff0cBiomedSQL\u5305\u62ec68,000\u4e2a\u95ee\u9898/SQL\u67e5\u8be2/\u7b54\u6848\u4e09\u5143\u7ec4\uff0c\u5e7f\u6cdb\u6574\u5408\u4e86\u57fa\u56e0-\u75be\u75c5\u5173\u8054\u3001\u7ec4\u5b66\u6570\u636e\u56e0\u679c\u63a8\u65ad\u548c\u836f\u7269\u6279\u51c6\u8bb0\u5f55\u3002", "result": "GPT-o3-mini\u7684\u6267\u884c\u51c6\u786e\u7387\u4e3a59.0%\uff0c\u81ea\u5b9a\u4e49\u591a\u6b65\u4ee3\u7406BMSQL\u8fbe\u523062.6%\uff0c\u5747\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u57fa\u51c690.0%\u3002", "conclusion": "BiomedSQL\u4e3a\u63a8\u8fdb\u80fd\u591f\u652f\u6301\u79d1\u5b66\u53d1\u73b0\u7684\u6587\u672c\u5230SQL\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u57fa\u7840\u3002"}}
{"id": "2505.20310", "pdf": "https://arxiv.org/pdf/2505.20310", "abs": "https://arxiv.org/abs/2505.20310", "authors": ["Wanghan Xu", "Wenlong Zhang", "Fenghua Ling", "Ben Fei", "Yusong Hu", "Fangxuan Ren", "Jintai Lin", "Wanli Ouyang", "Lei Bai"], "title": "Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Meta-analysis is a systematic research methodology that synthesizes data from\nmultiple existing studies to derive comprehensive conclusions. This approach\nnot only mitigates limitations inherent in individual studies but also\nfacilitates novel discoveries through integrated data analysis. Traditional\nmeta-analysis involves a complex multi-stage pipeline including literature\nretrieval, paper screening, and data extraction, which demands substantial\nhuman effort and time. However, while LLM-based methods can accelerate certain\nstages, they still face significant challenges, such as hallucinations in paper\nscreening and data extraction. In this paper, we propose a multi-agent system,\nManalyzer, which achieves end-to-end automated meta-analysis through tool\ncalls. The hybrid review, hierarchical extraction, self-proving, and feedback\nchecking strategies implemented in Manalyzer significantly alleviate these two\nhallucinations. To comprehensively evaluate the performance of meta-analysis,\nwe construct a new benchmark comprising 729 papers across 3 domains,\nencompassing text, image, and table modalities, with over 10,000 data points.\nExtensive experiments demonstrate that Manalyzer achieves significant\nperformance improvements over the LLM baseline in multi meta-analysis tasks.\nProject page: https://black-yt.github.io/meta-analysis-page/ .", "AI": {"tldr": "Manalyzer improves automated meta-analysis by addressing hallucinations in LLM methods, showing superior performance on a comprehensive benchmark.", "motivation": "The paper addresses the limitations and challenges of traditional and LLM-based meta-analysis methods, aiming to improve efficiency and accuracy in synthesizing data from multiple studies.", "method": "Manalyzer employs a hybrid review, hierarchical extraction, self-proving, and feedback checking system to facilitate end-to-end automated meta-analysis.", "result": "Experiments show that Manalyzer significantly outperforms the LLM baseline in meta-analysis tasks, evaluated on a benchmark of 729 papers across various domains.", "conclusion": "Manalyzer, a multi-agent system for automated meta-analysis, demonstrates significant improvements over traditional LLM-based methods in synthesizing data and addressing hallucination challenges."}}
{"id": "2505.20330", "pdf": "https://arxiv.org/pdf/2505.20330", "abs": "https://arxiv.org/abs/2505.20330", "authors": ["Yunfu Song", "Zhijian Ou"], "title": "Joint-stochastic-approximation Random Fields with Application to Semi-supervised Learning", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2018 submission. arXiv admin note: text overlap with\n  arXiv:1808.01630, arXiv:2505.18558", "summary": "Our examination of deep generative models (DGMs) developed for\nsemi-supervised learning (SSL), mainly GANs and VAEs, reveals two problems.\nFirst, mode missing and mode covering phenomenons are observed in genertion\nwith GANs and VAEs. Second, there exists an awkward conflict between good\nclassification and good generation in SSL by employing directed generative\nmodels. To address these problems, we formally present\njoint-stochastic-approximation random fields (JRFs) -- a new family of\nalgorithms for building deep undirected generative models, with application to\nSSL. It is found through synthetic experiments that JRFs work well in balancing\nmode covering and mode missing, and match the empirical data distribution well.\nEmpirically, JRFs achieve good classification results comparable to the\nstate-of-art methods on widely adopted datasets -- MNIST, SVHN, and CIFAR-10 in\nSSL, and simultaneously perform good generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u8054\u5408\u968f\u673a\u8fd1\u4f3c\u968f\u673a\u573a\uff08JRFs\uff09\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86GANs\u548cVAEs\u5728\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u6a21\u5f0f\u7f3a\u5931\u548c\u6a21\u5f0f\u8986\u76d6\u95ee\u9898\u3002\u5728MNIST\u3001SVHN\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\uff08\u5982GANs\u548cVAEs\uff09\u5728\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u5b58\u5728\u6a21\u5f0f\u7f3a\u5931\u548c\u6a21\u5f0f\u8986\u76d6\u95ee\u9898\uff0c\u4ee5\u53ca\u5206\u7c7b\u548c\u751f\u6210\u6548\u679c\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u6a21\u578b\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8054\u5408\u968f\u673a\u8fd1\u4f3c\u968f\u673a\u573a\uff08JRFs\uff09\u7b97\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u6df1\u5ea6\u65e0\u5411\u751f\u6210\u6a21\u578b\u6765\u5e73\u8861\u6837\u672c\u751f\u6210\u4e2d\u7684\u6a21\u5f0f\u8986\u76d6\u548c\u6a21\u5f0f\u7f3a\u5931\u95ee\u9898\uff0c\u5e76\u5728\u8bf8\u5982MNIST\u3001SVHN\u548cCIFAR-10\u7b49\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u5408\u6210\u5b9e\u9a8c\u4e2d\u53d1\u73b0\uff0cJRFs\u80fd\u591f\u6709\u6548\u5e73\u8861\u6a21\u5f0f\u8986\u76d6\u548c\u6a21\u5f0f\u7f3a\u5931\uff0c\u5e76\u4e0e\u7ecf\u9a8c\u6570\u636e\u5206\u5e03\u826f\u597d\u5339\u914d\u3002\u5728MNIST\u3001SVHN\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u7ed3\u679c\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u751f\u6210\u6548\u679c\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u5bb6\u65cf\uff0c\u5373\u8054\u5408\u968f\u673a\u8fd1\u4f3c\u968f\u673a\u573a\uff08JRFs\uff09\uff0c\u7528\u4e8e\u6784\u5efa\u6df1\u5ea6\u65e0\u5411\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u5728\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u53d6\u5f97\u826f\u597d\u7684\u5206\u7c7b\u548c\u751f\u6210\u6548\u679c\u3002"}}
