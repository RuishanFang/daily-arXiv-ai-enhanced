<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Guiding Giants: Lightweight Controllers for Weighted Activation Steering in LLMs](https://arxiv.org/abs/2505.20309)
*Amr Hegazy,Mostafa Elhoushi,Amr Alanwar*

Main category: cs.CL

TL;DR: 我们提出了一种通过轻量级可训练控制器网络在推理时实现对LLM行为的细粒度控制的方法，该方法在不改变模型参数的情况下显著提高了拒绝率。


<details>
  <summary>Details</summary>
Motivation: 控制不良的大型语言模型行为通常需要昂贵的微调，而激活转向提供了一种推理时控制的替代方案，但现有方法通常缺乏细粒度、适应性机制。

Method: 我们引入了一种轻量级的、可训练的控制器网络，以观察特定的中间激活并预测全局缩放因子和层特定权重，从而动态调节转向补丁的强度。

Result: 我们的方法在实验中表现优异，尤其是在使用Llama-3.1-8B、Llama-3.2-1B和Mistral-7B时，比现有方法更高效和适应性强。

Conclusion: 我们的加权转向控制器显著提高了拒绝率，实现了在不改变原始模型参数的情况下进行目标行为修改。

Abstract: Controlling undesirable Large Language Model (LLM) behaviors, such as the
generation of unsafe content or failing to adhere to safety guidelines, often
relies on costly fine-tuning. Activation steering provides an alternative for
inference-time control, but existing methods typically lack fine-grained,
adaptive mechanisms. We introduce a novel approach using a lightweight,
trainable controller network integrated during inference. This controller
network observes specific intermediate LLM activations and predicts both a
global scaling factor and layer-specific weights. The predicted global scaling
factor and layer-specific weights then dynamically modulate the intensity of a
steering patch, derived from a pre-computed "refusal direction" vector, applied
across the LLM's layers during generation. Trained on activations from both
harmful and benign prompts, our controller learns to discriminatively apply
nuanced, layer-aware interventions, activating steering primarily for harmful
inputs. Experiments using safety benchmarks like ToxicChat & In-The-Wild
Jailbreak Prompts demonstrate that our weighted steering controller
significantly increases refusal rates compared to the base LLM, achieving
targeted behavioral modification without altering the original model
parameters. Our experiments with Llama-3.1-8B, Llama-3.2-1B & Mistral-7B show
our approach outperforms existing methods, presenting an efficient and adaptive
method for fine-grained control over LLM behavior at inference time.

</details>


### [2] [Arctic-Text2SQL-R1: Simple Rewards, Strong Reasoning in Text-to-SQL](https://arxiv.org/abs/2505.20315)
*Zhewei Yao,Guoheng Sun,Lukasz Borchmann,Zheyu Shen,Minghang Deng,Bohan Zhai,Hao Zhang,Ang Li,Yuxiong He*

Main category: cs.CL

TL;DR: Arctic-Text2SQL-R1 framework improves SQL generation accuracy using reinforcement learning, achieving top benchmark performance with a scalable approach.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy and executability of SQL generated from natural language by overcoming the limitations of LLMs in handling complex queries.

Method: Reinforcement learning framework with a lightweight reward signal focused on execution correctness, combined with strong supervised initialization and effective training practices.

Result: State-of-the-art execution accuracy across six benchmarks, outperforming larger models with its 7B model, and demonstrating robust inference capabilities.

Conclusion: Arctic-Text2SQL-R1 achieves state-of-the-art execution accuracy in translating natural language to SQL, demonstrating scalability and efficiency, and offers practical insights for future research.

Abstract: Translating natural language into SQL (Test2SQL) is a longstanding challenge
at the intersection of natural language understanding and structured data
access. While large language models (LLMs) have significantly improved fluency
in SQL generation, producing correct and executable SQL--particularly for
complex queries--remains a bottleneck. We present Arctic-Text2SQL-R1, a
reinforcement learning (RL) framework and model family designed to generate
accurate, executable SQL using a lightweight reward signal based solely on
execution correctness. Our approach avoids brittle intermediate supervision and
complex reward shaping, promoting stable training and alignment with the end
task. Combined with carefully curated data, strong supervised initialization,
and effective training practices, Arctic-Text2SQL-R1 achieves state-of-the-art
execution accuracy across six diverse Test2SQL benchmarks, including the top
position on the BIRD leaderboard. Notably, our 7B model outperforms prior
70B-class systems, highlighting the framework's scalability and efficiency. We
further demonstrate inference-time robustness through simple extensions like
value retrieval and majority voting. Extensive experiments and ablation studies
offer both positive and negative insights, providing practical guidance for
future Test2SQL research.

</details>


### [3] [Beyond Demonstrations: Dynamic Vector Construction from Latent Representations](https://arxiv.org/abs/2505.20318)
*Wang Cai,Hsiu-Yuan Huang,Zhixiang Wang,Yunfang Wu*

Main category: cs.CL

TL;DR: DyVec enhances task adaptation by outperforming ICL, LoRA, and prior ICV methods through effective segmentation and injection of representations.


<details>
  <summary>Details</summary>
Motivation: The motivation behind the study is to address the limitations of existing ICV methods, which are sensitive to ICL-specific factors and utilize coarse or fragmented representations and heuristic-based injection positions, thus limiting their applicability.

Method: The paper introduces Dynamic Vector (DyVec), which uses an Exhaustive Query Rotation (EQR) strategy to extract robust latent representations. DyVec involves Dynamic Latent Segmentation and Injection to adaptively partition representations based on task complexity and employs REINFORCE-based optimization to learn optimal injection positions for segments.

Result: Experiments demonstrated that DyVec outperformed few-shot ICL, LoRA, and previous ICV methods. The analysis showed the method's effectiveness in dynamically segmenting and injecting semantically aggregated latent representations.

Conclusion: DyVec provides a lightweight and data-efficient solution for inference-time task adaptation by outperforming few-shot ICL, LoRA, and prior ICV baselines through its advanced techniques in dynamically segmenting and injecting semantically aggregated latent representations.

Abstract: In-Context derived Vector (ICV) methods extract task-relevant representations
from large language models (LLMs) and reinject them during inference, achieving
comparable performance to few-shot In-Context Learning (ICL) without repeated
demonstration processing. However, existing ICV methods remain sensitive to
ICL-specific factors, often use coarse or semantically fragmented
representations as the source of the vector, and rely on heuristic-based
injection positions, limiting their applicability.
  To address these issues, we propose Dynamic Vector (DyVec), which
incorporates an Exhaustive Query Rotation (EQR) strategy to extract robust
semantically aggregated latent representations by mitigating variance
introduced by ICL. It then applies Dynamic Latent Segmentation and Injection to
adaptively partition representations based on task complexity and leverages
REINFORCE-based optimization to learn optimal injection positions for each
segment.
  Experiments results show that DyVec outperforms few-shot ICL, LoRA, and prior
ICV baselines. Further analysis highlights the effectiveness of dynamically
segmenting and injecting semantically aggregated latent representations. DyVec
provides a lightweight and data-efficient solution for inference-time task
adaptation.

</details>


### [4] [Less Context, Same Performance: A RAG Framework for Resource-Efficient LLM-Based Clinical NLP](https://arxiv.org/abs/2505.20320)
*Satya Narayana Cheetirala,Ganesh Raut,Dhavalkumar Patel,Fabio Sanatana,Robert Freeman,Matthew A Levin,Girish N. Nadkarni,Omar Dawkins,Reba Miller,Randolph M. Steinhagen,Eyal Klang,Prem Timsina*

Main category: cs.CL

TL;DR: 研究表明，RAG方法可以在不牺牲分类准确性的情况下显著减少token使用量，为分析长临床文档提供了一种可扩展且成本效益高的解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长文本分类时面临token限制和高计算成本的挑战。

Method: 将临床文档拆分成较小的块，转换为向量嵌入，并存储在FAISS索引中。然后检索与分类查询最相关的4,000个词，将这些合并的片段输入到LLM中。

Result: 评估的三个大型语言模型（GPT4o、LLaMA和Mistral）在外科并发症识别任务中，RAG方法与全文处理在AUC ROC、精确度、召回率和F1等指标上没有显著统计差异（p > 0.05）。

Conclusion: RAG方法在减少token使用量的同时保持了分类准确性，是分析长临床文档的可扩展且成本效益高的解决方案。

Abstract: Long text classification is challenging for Large Language Models (LLMs) due
to token limits and high computational costs. This study explores whether a
Retrieval Augmented Generation (RAG) approach using only the most relevant text
segments can match the performance of processing entire clinical notes with
large context LLMs. We begin by splitting clinical documents into smaller
chunks, converting them into vector embeddings, and storing these in a FAISS
index. We then retrieve the top 4,000 words most pertinent to the
classification query and feed these consolidated segments into an LLM. We
evaluated three LLMs (GPT4o, LLaMA, and Mistral) on a surgical complication
identification task. Metrics such as AUC ROC, precision, recall, and F1 showed
no statistically significant differences between the RAG based approach and
whole-text processing (p > 0.05p > 0.05). These findings indicate that RAG can
significantly reduce token usage without sacrificing classification accuracy,
providing a scalable and cost effective solution for analyzing lengthy clinical
documents.

</details>


### [5] [BiomedSQL: Text-to-SQL for Scientific Reasoning on Biomedical Knowledge Bases](https://arxiv.org/abs/2505.20321)
*Mathew J. Koretsky,Maya Willey,Adi Asija,Owen Bianchi,Chelsea X. Alvarado,Tanay Nayak,Nicole Kuznetsov,Sungwon Kim,Mike A. Nalls,Daniel Khashabi,Faraz Faghri*

Main category: cs.CL

TL;DR: BiomedSQL是首个专门设计用于评估科学推理在文本到SQL生成中的作用的基准，对于现有系统均表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到SQL系统在将定性科学问题映射为可执行的SQL时经常遇到困难，特别是在需要隐含领域推理时。因此，需要一个专门设计的基准来评估科学推理在文本到SQL生成中的作用。

Method: 在经过协调的BigQuery知识库中，BiomedSQL包括68,000个问题/SQL查询/答案三元组，广泛整合了基因-疾病关联、组学数据因果推断和药物批准记录。

Result: GPT-o3-mini的执行准确率为59.0%，自定义多步代理BMSQL达到62.6%，均远低于专家基准90.0%。

Conclusion: BiomedSQL为推进能够支持科学发现的文本到SQL系统提供了新基础。

Abstract: Biomedical researchers increasingly rely on large-scale structured databases
for complex analytical tasks. However, current text-to-SQL systems often
struggle to map qualitative scientific questions into executable SQL,
particularly when implicit domain reasoning is required. We introduce
BiomedSQL, the first benchmark explicitly designed to evaluate scientific
reasoning in text-to-SQL generation over a real-world biomedical knowledge
base. BiomedSQL comprises 68,000 question/SQL query/answer triples grounded in
a harmonized BigQuery knowledge base that integrates gene-disease associations,
causal inference from omics data, and drug approval records. Each question
requires models to infer domain-specific criteria, such as genome-wide
significance thresholds, effect directionality, or trial phase filtering,
rather than rely on syntactic translation alone. We evaluate a range of open-
and closed-source LLMs across prompting strategies and interaction paradigms.
Our results reveal a substantial performance gap: GPT-o3-mini achieves 59.0%
execution accuracy, while our custom multi-step agent, BMSQL, reaches 62.6%,
both well below the expert baseline of 90.0%. BiomedSQL provides a new
foundation for advancing text-to-SQL systems capable of supporting scientific
discovery through robust reasoning over structured biomedical knowledge bases.
Our dataset is publicly available at
https://huggingface.co/datasets/NIH-CARD/BiomedSQL, and our code is open-source
at https://github.com/NIH-CARD/biomedsql.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review](https://arxiv.org/abs/2505.20306)
*Xueqiang Ouyang,Jia Wei*

Main category: cs.AI

TL;DR: 综述多模态人工智能用于胚胎分级和妊娠预测的最新进展，讨论信息融合复杂性和数据不足挑战。


<details>
  <summary>Details</summary>
Motivation: 传统体外受精-胚胎移植技术在提高妊娠成功率方面面临许多挑战，引入人工智能技术可以有效解决这些问题。

Method: 该论文综述了基于不同数据模态的多模态人工智能在胚胎分级和妊娠预测中的应用进展。

Result: 探讨了多模态信息融合的复杂性和数据匮乏等当前研究中的主要挑战。

Conclusion: 引入基于多模态人工智能技术对于提高传统体外受精-胚胎移植技术的成功率是至关重要的。

Abstract: As a global disease, infertility has always affected human beings. The
development of assisted reproductive technology can effectively solve this
disease. However, the traditional in vitro fertilization-embryo transfer
technology still faces many challenges in improving the success rate of
pregnancy, such as the subjectivity of embryo grading and the inefficiency of
integrating multi-modal data. Therefore, the introduction of artificial
intelligence-based technologies is particularly crucial. This article reviews
the application progress of multi-modal artificial intelligence in embryo
grading and pregnancy prediction based on different data modalities (including
static images, time-lapse videos and structured table data) from a new
perspective, and discusses the main challenges in current research, such as the
complexity of multi-modal information fusion and data scarcity.

</details>


### [7] [Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System](https://arxiv.org/abs/2505.20310)
*Wanghan Xu,Wenlong Zhang,Fenghua Ling,Ben Fei,Yusong Hu,Fangxuan Ren,Jintai Lin,Wanli Ouyang,Lei Bai*

Main category: cs.AI

TL;DR: Manalyzer improves automated meta-analysis by addressing hallucinations in LLM methods, showing superior performance on a comprehensive benchmark.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the limitations and challenges of traditional and LLM-based meta-analysis methods, aiming to improve efficiency and accuracy in synthesizing data from multiple studies.

Method: Manalyzer employs a hybrid review, hierarchical extraction, self-proving, and feedback checking system to facilitate end-to-end automated meta-analysis.

Result: Experiments show that Manalyzer significantly outperforms the LLM baseline in meta-analysis tasks, evaluated on a benchmark of 729 papers across various domains.

Conclusion: Manalyzer, a multi-agent system for automated meta-analysis, demonstrates significant improvements over traditional LLM-based methods in synthesizing data and addressing hallucination challenges.

Abstract: Meta-analysis is a systematic research methodology that synthesizes data from
multiple existing studies to derive comprehensive conclusions. This approach
not only mitigates limitations inherent in individual studies but also
facilitates novel discoveries through integrated data analysis. Traditional
meta-analysis involves a complex multi-stage pipeline including literature
retrieval, paper screening, and data extraction, which demands substantial
human effort and time. However, while LLM-based methods can accelerate certain
stages, they still face significant challenges, such as hallucinations in paper
screening and data extraction. In this paper, we propose a multi-agent system,
Manalyzer, which achieves end-to-end automated meta-analysis through tool
calls. The hybrid review, hierarchical extraction, self-proving, and feedback
checking strategies implemented in Manalyzer significantly alleviate these two
hallucinations. To comprehensively evaluate the performance of meta-analysis,
we construct a new benchmark comprising 729 papers across 3 domains,
encompassing text, image, and table modalities, with over 10,000 data points.
Extensive experiments demonstrate that Manalyzer achieves significant
performance improvements over the LLM baseline in multi meta-analysis tasks.
Project page: https://black-yt.github.io/meta-analysis-page/ .

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [8] [xChemAgents: Agentic AI for Explainable Quantum Chemistry](https://arxiv.org/abs/2505.20574)
*Can Polat,Mehmet Tuncel,Hasan Kurban,Erchin Serpedin,Mustafa Kurban*

Main category: cs.MA

TL;DR: xChemAgents通过合作代理框架提高了多模态预测的准确性和透明性，并减少了误差，同时提供了可解释的结果。


<details>
  <summary>Details</summary>
Motivation: 在多模态图神经网络中，尽管添加化学描述符能够提高预测准确性，但无选择地添加大规模不均一描述符会对分子形状或对称性敏感的任务造成性能损害，并削弱可解释性，因此提出了xChemAgents框架以优化此问题。

Method: xChemAgents包括两个以语言模型为基础的代理：Selector和Validator。Selector适应性地选择一个稀疏、加权的描述符子集，并提供自然语言解释。Validator通过迭代对话强制实施物理约束，如单位一致性和缩放定律。

Result: 在标准基准数据集中，xChemAgents在强基线上实现了高达22%的平均绝对误差减少，同时生成可信且人类可解释的解释。

Conclusion: xChemAgents通过引入物理意识推理来提高多模态属性预测的准确性和可解释性，其实验结果展示了合作型、自我验证型代理在基础模型驱动的材料科学中增强准确性和透明性的潜力。

Abstract: Recent progress in multimodal graph neural networks has demonstrated that
augmenting atomic XYZ geometries with textual chemical descriptors can enhance
predictive accuracy across a range of electronic and thermodynamic properties.
However, naively appending large sets of heterogeneous descriptors often
degrades performance on tasks sensitive to molecular shape or symmetry, and
undermines interpretability. xChemAgents proposes a cooperative agent framework
that injects physics-aware reasoning into multimodal property prediction.
xChemAgents comprises two language-model-based agents: a Selector, which
adaptively identifies a sparse, weighted subset of descriptors relevant to each
target, and provides a natural language rationale; and a Validator, which
enforces physical constraints such as unit consistency and scaling laws through
iterative dialogue. On standard benchmark datasets, xChemAgents achieves up to
a 22\% reduction in mean absolute error over strong baselines, while producing
faithful, human-interpretable explanations. Experiment results highlight the
potential of cooperative, self-verifying agents to enhance both accuracy and
transparency in foundation-model-driven materials science. The implementation
and accompanying dataset are available anonymously at
https://github.com/KurbanIntelligenceLab/xChemAgents.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [9] [FMEnets: Flow, Material, and Energy networks for non-ideal plug flow reactor design](https://arxiv.org/abs/2505.20300)
*Chenxi Wu,Juan Diego Toscano,Khemraj Shukla,Yingjie Chen,Ali Shahmohammadi,Edward Raymond,Thomas Toupy,Neda Nazemifard,Charles Papageorgiou,George Em Karniadakis*

Main category: cs.LG

TL;DR: FMEnets是一种集成多尺度物理方程的机器学习模型，用于非理想插入流反应器的设计和分析，在各种噪声条件下表现出色，实现高效率与低误差。


<details>
  <summary>Details</summary>
Motivation: 设计和分析非理想插入流反应器，以有效地捕捉复杂交互，并实现反应器设计和优化的高计算效率。

Method: FMEnets将流体流动的Navier-Stokes方程、反应物质传输的材料平衡方程和温度分布的能量平衡方程整合到一个统一的多尺度网络模型中，包含三个独立优化器的子网络，用于解决正向和反向问题。

Result: FMEnets相较于有限元模拟可以有效地捕捉复杂交互，实现对于未知动力学参数少于2.5%的相对误差。

Conclusion: FMEnets为反应器设计和优化提供了一种计算效率高的替代方案，并为整合经验相关性、有限和噪声实验数据与基本物理方程开辟了新途径，以指导反应器设计。

Abstract: We propose FMEnets, a physics-informed machine learning framework for the
design and analysis of non-ideal plug flow reactors. FMEnets integrates the
fundamental governing equations (Navier-Stokes for fluid flow, material balance
for reactive species transport, and energy balance for temperature
distribution) into a unified multi-scale network model. The framework is
composed of three interconnected sub-networks with independent optimizers that
enable both forward and inverse problem-solving. In the forward mode, FMEnets
predicts velocity, pressure, species concentrations, and temperature profiles
using only inlet and outlet information. In the inverse mode, FMEnets utilizes
sparse multi-residence-time measurements to simultaneously infer unknown
kinetic parameters and states. FMEnets can be implemented either as FME-PINNs,
which employ conventional multilayer perceptrons, or as FME-KANs, based on
Kolmogorov-Arnold Networks. Comprehensive ablation studies highlight the
critical role of the FMEnets architecture in achieving accurate predictions.
Specifically, FME-KANs are more robust to noise than FME-PINNs, although both
representations are comparable in accuracy and speed in noise-free conditions.
The proposed framework is applied to three different sets of reaction scenarios
and is compared with finite element simulations. FMEnets effectively captures
the complex interactions, achieving relative errors less than 2.5% for the
unknown kinetic parameters. The new network framework not only provides a
computationally efficient alternative for reactor design and optimization, but
also opens new avenues for integrating empirical correlations, limited and
noisy experimental data, and fundamental physical equations to guide reactor
design.

</details>


### [10] [Joint-stochastic-approximation Random Fields with Application to Semi-supervised Learning](https://arxiv.org/abs/2505.20330)
*Yunfu Song,Zhijian Ou*

Main category: cs.LG

TL;DR: 该论文提出了联合随机近似随机场（JRFs）算法，解决了GANs和VAEs在半监督学习中的模式缺失和模式覆盖问题。在MNIST、SVHN和CIFAR-10数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型（如GANs和VAEs）在半监督学习中存在模式缺失和模式覆盖问题，以及分类和生成效果之间的冲突，因此需要改进模型以解决这些问题。

Method: 使用联合随机近似随机场（JRFs）算法，通过构建深度无向生成模型来平衡样本生成中的模式覆盖和模式缺失问题，并在诸如MNIST、SVHN和CIFAR-10等数据集上进行验证。

Result: 在合成实验中发现，JRFs能够有效平衡模式覆盖和模式缺失，并与经验数据分布良好匹配。在MNIST、SVHN和CIFAR-10数据集上的分类结果与当前最先进的方法相当，同时在生成效果上表现良好。

Conclusion: 提出了一种新的算法家族，即联合随机近似随机场（JRFs），用于构建深度无向生成模型，能够在半监督学习中取得良好的分类和生成效果。

Abstract: Our examination of deep generative models (DGMs) developed for
semi-supervised learning (SSL), mainly GANs and VAEs, reveals two problems.
First, mode missing and mode covering phenomenons are observed in genertion
with GANs and VAEs. Second, there exists an awkward conflict between good
classification and good generation in SSL by employing directed generative
models. To address these problems, we formally present
joint-stochastic-approximation random fields (JRFs) -- a new family of
algorithms for building deep undirected generative models, with application to
SSL. It is found through synthetic experiments that JRFs work well in balancing
mode covering and mode missing, and match the empirical data distribution well.
Empirically, JRFs achieve good classification results comparable to the
state-of-art methods on widely adopted datasets -- MNIST, SVHN, and CIFAR-10 in
SSL, and simultaneously perform good generation.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [11] [Resonance Complexity Theory and the Architecture of Consciousness: A Field-Theoretic Model of Resonant Interference and Emergent Awareness](https://arxiv.org/abs/2505.20580)
*Michael Arnold Bruna*

Main category: q-bio.NC

TL;DR: 本文提出共振复杂性理论（RCT），说明意识是由神经活动的稳定干扰模式引起的。通过定义复杂性指数（CI），并使用神经场模拟验证该理论，发现共振吸引子可以从波干涉的物理中产生，提出了意识作为振荡系统中组织复杂性的突现属性。


<details>
  <summary>Details</summary>
Motivation: 本文介绍了共振复杂性理论（RCT），该理论提出意识源于神经活动的稳定干扰模式。这些模式由递归反馈和建设性干涉塑造，必须在复杂性、一致性、增益和分形维度等方面超过临界阈值才能产生意识体验。

Method: 为了检验这一理论，我们开发了一种受生物启发但极简的神经场模拟，由辐射波源在一个连续的二维空间内发射。系统表现出递归的建设性干涉，生成不需要外部输入、区域编码或强加结构的相干的吸引子式激励模式。这些模式符合复杂性指数（CI）的理论阈值，并体现了RCT预测的核心动态。

Result: 通过辐射波源的递归建设性干涉形成吸引子式激励模式，这些不需要外部输入的模式符合复杂性指数（CI），反映了共振复杂性理论预测的动态特征。

Conclusion: 该研究结果展示了基于共振的吸引子——进而是类意识动态——纯粹可以从波干涉物理中产生。共振复杂性理论（RCT）因此提出了一个统一的动态框架来将意识建模为振荡系统中有组织复杂性的突现属性。

Abstract: This paper introduces Resonance Complexity Theory (RCT), which proposes that
consciousness emerges from stable interference patterns of oscillatory neural
activity. These patterns, shaped by recursive feedback and constructive
interference, must exceed critical thresholds in complexity, coherence, gain,
and fractal dimensionality to give rise to conscious experience. The resulting
spatiotemporal attractors encode subjective awareness as dynamic resonance
structures distributed across the neural field, enabling large-scale
integration without symbolic representation or centralized control.
  To formalize this idea, we define the Complexity Index (CI), a composite
metric that synthesizes four core properties of conscious systems: fractal
dimensionality (D), signal gain (G), spatial coherence (C), and attractor dwell
time (tau). These elements are combined multiplicatively to capture the
emergence and persistence of structured, integrative neural states.
  To test the theory empirically, we developed a biologically inspired yet
minimal neural field simulation composed of radial wave sources emitting across
a continuous 2D space. The system exhibits recursive constructive interference,
producing coherent, attractor-like excitation patterns without external input,
regional coding, or imposed structure. These patterns meet the theoretical
thresholds for CI and reflect the core dynamics predicted by RCT.
  The findings demonstrate that resonance-based attractors -- and by extension,
consciousness-like dynamics -- can arise purely from the physics of wave
interference. RCT thus offers a unified, dynamical framework for modeling
awareness as an emergent property of organized complexity in oscillatory
systems.

</details>
