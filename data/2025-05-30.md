<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 8]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Training Language Models to Generate Quality Code with Program Analysis Feedback](https://arxiv.org/abs/2505.22704)
*Feng Yao,Zilong Wang,Liyuan Liu,Junxia Cui,Li Zhong,Xiaohan Fu,Haohui Mai,Vish Krishnan,Jianfeng Gao,Jingbo Shang*

Main category: cs.CL

TL;DR: REAL是一种新颖的RL框架，通过程序分析引导的反馈提高LLMs生成代码的质量，验证显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前使用大型语言模型进行代码生成时，代码质量尤其在安全性和可维护性方面存在问题。现有的方法依赖于劳动密集型注释或不可靠的启发式，从而限制了可扩展性和有效性。

Method: 提出了REAL，一种使用程序分析引导反馈的强化学习框架，以激励LLMs生成生产质量的代码。REAL集成了两个自动化信号：程序分析用于检测安全性或可维护性缺陷，以及单元测试用于确保功能正确性。

Result: 实验表明REAL在评估功能和代码质量方面优于最先进的方法。

Conclusion: REAL能够缩小快速原型设计与生产就绪代码之间的差距，使LLMs能够同时提供速度和质量。

Abstract: Code generation with large language models (LLMs), often termed vibe coding,
is increasingly adopted in production but fails to ensure code quality,
particularly in security (e.g., SQL injection vulnerabilities) and
maintainability (e.g., missing type annotations). Existing methods, such as
supervised fine-tuning and rule-based post-processing, rely on labor-intensive
annotations or brittle heuristics, limiting their scalability and
effectiveness. We propose REAL, a reinforcement learning framework that
incentivizes LLMs to generate production-quality code using program
analysis-guided feedback. Specifically, REAL integrates two automated signals:
(1) program analysis detecting security or maintainability defects and (2) unit
tests ensuring functional correctness. Unlike prior work, our framework is
prompt-agnostic and reference-free, enabling scalable supervision without
manual intervention. Experiments across multiple datasets and model scales
demonstrate that REAL outperforms state-of-the-art methods in simultaneous
assessments of functionality and code quality. Our work bridges the gap between
rapid prototyping and production-ready code, enabling LLMs to deliver both
speed and quality.

</details>


### [2] [Climate Finance Bench](https://arxiv.org/abs/2505.22752)
*Rafik Mankour,Yassine Chafai,Hamada Saleh,Ghassen Ben Hassine,Thibaud Barreau,Peter Tankov*

Main category: cs.CL

TL;DR: 我们介绍了一个针对企业气候披露的开放基准，提出了RAG方法的比较，强调检索器定位答案段落能力的重要性，并支持AI气候应用中的透明碳报告。


<details>
  <summary>Details</summary>
Motivation: 引入一个开放基准，借助大型语言模型来处理企业气候披露中的问答问题。

Method: 我们提出了RAG（检索增强生成）方法的比较，利用33个最近的可持续性报告和330对专家验证的问题答案对进行实验。

Result: 展示了检索器对于定位实际包含答案的段落能力的决定性作用，并指出技术如权重量化的优势。

Conclusion: 提取器定位实际包含答案的段落的能力是主要性能瓶颈，并主张在AI气候应用中透明的碳报告。

Abstract: Climate Finance Bench introduces an open benchmark that targets
question-answering over corporate climate disclosures using Large Language
Models. We curate 33 recent sustainability reports in English drawn from
companies across all 11 GICS sectors and annotate 330 expert-validated
question-answer pairs that span pure extraction, numerical reasoning, and
logical reasoning. Building on this dataset, we propose a comparison of RAG
(retrieval-augmented generation) approaches. We show that the retriever's
ability to locate passages that actually contain the answer is the chief
performance bottleneck. We further argue for transparent carbon reporting in
AI-for-climate applications, highlighting advantages of techniques such as
Weight Quantization.

</details>


### [3] [Pre-Training Curriculum for Multi-Token Prediction in Language Models](https://arxiv.org/abs/2505.22757)
*Ansar Aynetdinov,Alan Akbik*

Main category: cs.CL

TL;DR: 研究提出了课程学习策略来优化较小语言模型在多标记预测目标上的训练，结果显示正向课程提升了下游性能和生成质量，而反向课程则表现更强但缺乏解码优势。


<details>
  <summary>Details</summary>
Motivation: 尽管多标记预测在大型模型中显示出改善下游性能、推理速度和训练效率的潜力，但较小的语言模型在这一目标上的表现较差。为解决这一问题，提出了课程学习策略以优化较小语言模型的训练。

Method: 提出了一种课程学习策略用于多标记预测训练，探索了两种变体：正向课程，逐步增加预训练目标的复杂性，从单标记预测到多标记预测；反向课程则正好相反。

Result: 正向课程学习使较小的语言模型能够在预训练中更好地利用多标记预测目标，提升下游单标记预测表现和生成输出质量，并保持自我推测解码的优势；而反向课程虽然单标记预测表现和输出质量更强，但没有提供自我推测解码的优势。

Conclusion: 实验结果表明，正向课程学习能够帮助较小的语言模型在预训练中更好地利用多标记预测目标，提升下游的单标记预测表现和生成输出质量，同时保留自我推测解码的优势。然而，反向课程虽然实现了更强的单标记预测表现和输出质量，但却在自我推测解码方面没有任何优势。

Abstract: Multi-token prediction (MTP) is a recently proposed pre-training objective
for language models. Rather than predicting only the next token (NTP), MTP
predicts the next $k$ tokens at each prediction step, using multiple prediction
heads. MTP has shown promise in improving downstream performance, inference
speed, and training efficiency, particularly for large models. However, prior
work has shown that smaller language models (SLMs) struggle with the MTP
objective. To address this, we propose a curriculum learning strategy for MTP
training, exploring two variants: a forward curriculum, which gradually
increases the complexity of the pre-training objective from NTP to MTP, and a
reverse curriculum, which does the opposite. Our experiments show that the
forward curriculum enables SLMs to better leverage the MTP objective during
pre-training, improving downstream NTP performance and generative output
quality, while retaining the benefits of self-speculative decoding. The reverse
curriculum achieves stronger NTP performance and output quality, but fails to
provide any self-speculative decoding benefits.

</details>


### [4] [FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian](https://arxiv.org/abs/2505.22759)
*Sara Papi,Marco Gaido,Luisa Bentivogli,Alessio Brutti,Mauro Cettolo,Roberto Gretter,Marco Matassoni,Mohamed Nabih,Matteo Negri*

Main category: cs.CL

TL;DR: FAMA是首个开源语音基础模型，性能优异且速度快，促进了语音技术的开放科学。


<details>
  <summary>Details</summary>
Motivation: 现有语音基础模型封闭性使得可重复性和公平评估面临挑战，需要开发开源模型来促进开放科学。

Method: 开发了FAMA这个开源语音基础模型，并创建了一个包含16k小时数据的新数据集。

Result: FAMA与现有模型相比表现出色，速度提高至多八倍，并开放了所有研发成果。

Conclusion: FAMA在性能和速度方面具有竞争优势，并实现了开放科学的要求。

Abstract: The development of speech foundation models (SFMs) like Whisper and
SeamlessM4T has significantly advanced the field of speech processing. However,
their closed nature--with inaccessible training data and code--poses major
reproducibility and fair evaluation challenges. While other domains have made
substantial progress toward open science by developing fully transparent models
trained on open-source (OS) code and data, similar efforts in speech remain
limited. To fill this gap, we introduce FAMA, the first family of open science
SFMs for English and Italian, trained on 150k+ hours of OS speech data.
Moreover, we present a new dataset containing 16k hours of cleaned and
pseudo-labeled speech for both languages. Results show that FAMA achieves
competitive performance compared to existing SFMs while being up to 8 times
faster. All artifacts, including code, datasets, and models, are released under
OS-compliant licenses, promoting openness in speech technology research.

</details>


### [5] [StressTest: Can YOUR Speech LM Handle the Stress?](https://arxiv.org/abs/2505.22765)
*Iddo Yosha,Gallil Maimon,Yossi Adi*

Main category: cs.CL

TL;DR: 引入StressTest评估模型处理句子重音能力，发现现有模型表现不佳，提出新的合成数据方法，生成Stress17k训练集，优化后的StresSLM模型在相关任务中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管句子重音在塑造意义和说话者意图中起着至关重要的作用，但在SLMs的评估和开发中仍然被忽视。

Method: 我们提出了一种新的合成数据生成流水线，并创建了Stress17k训练集，通过模拟重音变化引起的意义变化来优化模型。

Result: 优化模型与真实世界录音良好匹配，并能有效微调SLMs。

Conclusion: 我们的微调模型StresSLM在句子重音推理和检测任务上显著优于现有模型。

Abstract: Sentence stress refers to emphasis, placed on specific words within a spoken
utterance to highlight or contrast an idea, or to introduce new information. It
is often used to imply an underlying intention that is not explicitly stated.
Recent advances in speech-aware language models (SLMs) have enabled direct
processing of audio, allowing models to bypass transcription and access the
full richness of the speech signal and perform audio reasoning tasks such as
spoken question answering. Despite the crucial role of sentence stress in
shaping meaning and speaker intent, it remains largely overlooked in evaluation
and development of such models. In this work, we address this gap by
introducing StressTest, a benchmark specifically designed to evaluate a model's
ability to distinguish between interpretations of spoken sentences based on the
stress pattern. We assess the performance of several leading SLMs and find
that, despite their overall capabilities, they perform poorly on such tasks. To
overcome this limitation, we propose a novel synthetic data generation
pipeline, and create Stress17k, a training set that simulates change of meaning
implied by stress variation. Then, we empirically show that optimizing models
with this synthetic dataset aligns well with real-world recordings and enables
effective finetuning of SLMs. Results suggest, that our finetuned model,
StresSLM, significantly outperforms existing models on both sentence stress
reasoning and detection tasks. Code, models, data, and audio samples -
pages.cs.huji.ac.il/adiyoss-lab/stresstest.

</details>


### [6] [Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems](https://arxiv.org/abs/2505.22771)
*Christopher Ormerod*

Main category: cs.CL

TL;DR: Incorporating annotations for spelling, grammar, and argumentative components enhances AES accuracy, demonstrated using LLMs on the PERSUADE corpus.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy of automated essay scoring by incorporating feedback-driven annotations.

Method: The method involves employing two LLMs for generating annotations: a generative language model for spell-correction and an encoder-based token classifier for identifying argumentative elements.

Result: The approach shows improved performance in AES using encoder-based LLMs fine-tuned as classifiers.

Conclusion: Integrating feedback-oriented annotations into the scoring pipeline enhances the accuracy of AES.

Abstract: This study illustrates how incorporating feedback-oriented annotations into
the scoring pipeline can enhance the accuracy of automated essay scoring (AES).
This approach is demonstrated with the Persuasive Essays for Rating, Selecting,
and Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We
integrate two types of feedback-driven annotations: those that identify
spelling and grammatical errors, and those that highlight argumentative
components. To illustrate how this method could be applied in real-world
scenarios, we employ two LLMs to generate annotations -- a generative language
model used for spell-correction and an encoder-based token classifier trained
to identify and mark argumentative elements. By incorporating annotations into
the scoring process, we demonstrate improvements in performance using
encoder-based large language models fine-tuned as classifiers.

</details>


### [7] [Counting trees: A treebank-driven exploration of syntactic variation in speech and writing across languages](https://arxiv.org/abs/2505.22774)
*Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 本文提出了一种新的方法，采用依存解析的树库来比较英语和斯洛文尼亚语中语音和书写的句法结构。结果显示，语音与书写在句法结构上有显著差异，语音更少见、更具互动性。


<details>
  <summary>Details</summary>
Motivation: 研究语音和书写中句法结构的差异，探索何种结构在某一表现形式中更为典型。

Method: 采用了树库驱动的方法，通过依存解析的语料库比较语音和书写中的句法结构，具体从英语和斯洛文尼亚语的UD树库中提取无词汇化的依存子树进行分析。

Result: 在两种语言中，语音语料中的句法结构数量和多样性均少于书写语料，其中特殊的结构类型在两种表现形式中表现出一致的跨语言偏好。语音和书写句法库存的重叠有限，表明存在基于表现形式的句法组织偏好。这种差异通过对语音特定结构的关键性分析得到支持，强调了与互动性、情境基础和表达经济相关的模式。

Conclusion: 该方法提供了一种可扩展的、与语言无关的框架，能够系统地研究语料库中的句法变异，为构建更全面的数据驱动的语法理论奠定基础。

Abstract: This paper presents a novel treebank-driven approach to comparing syntactic
structures in speech and writing using dependency-parsed corpora. Adopting a
fully inductive, bottom-up method, we define syntactic structures as
delexicalized dependency (sub)trees and extract them from spoken and written
Universal Dependencies (UD) treebanks in two syntactically distinct languages,
English and Slovenian. For each corpus, we analyze the size, diversity, and
distribution of syntactic inventories, their overlap across modalities, and the
structures most characteristic of speech. Results show that, across both
languages, spoken corpora contain fewer and less diverse syntactic structures
than their written counterparts, with consistent cross-linguistic preferences
for certain structural types across modalities. Strikingly, the overlap between
spoken and written syntactic inventories is very limited: most structures
attested in speech do not occur in writing, pointing to modality-specific
preferences in syntactic organization that reflect the distinct demands of
real-time interaction and elaborated writing. This contrast is further
supported by a keyness analysis of the most frequent speech-specific
structures, which highlights patterns associated with interactivity,
context-grounding, and economy of expression. We argue that this scalable,
language-independent framework offers a useful general method for
systematically studying syntactic variation across corpora, laying the
groundwork for more comprehensive data-driven theories of grammar in use.

</details>


### [8] [MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators](https://arxiv.org/abs/2505.22777)
*John Mendonça,Alon Lavie,Isabel Trancoso*

Main category: cs.CL

TL;DR: 该论文介绍了用于生成和评估多语言对话的新框架MEDAL，并发现LLMs在评估中识别细微问题方面仍有局限性。


<details>
  <summary>Details</summary>
Motivation: 改善聊天机器人和LLMs的性能评估，解决现有评估数据集中存在的静态、过时和多语言覆盖不足的问题。

Method: 引入MEDAL框架，利用先进的LLMs生成多语言用户-聊天机器人对话，并使用GPT-4.1进行多维度分析以揭示语言间性能差异。

Result: 通过大规模评估，调整并创建新的多语言元评估基准，发现当前LLMs在检测细微问题时有困难，尤其是在同理心和推理方面。

Conclusion: 当前的LLMs在评估开放领域对话时仍有局限性，尤其是在识别细微问题方面。MEDAL框架改善了评估基准的多样性和代表性。

Abstract: As the capabilities of chatbots and their underlying LLMs continue to
dramatically improve, evaluating their performance has increasingly become a
major blocker to their further development. A major challenge is the available
benchmarking datasets, which are largely static, outdated, and lacking in
multilingual coverage, limiting their ability to capture subtle linguistic and
cultural variations. This paper introduces MEDAL, an automated multi-agent
framework for generating, evaluating, and curating more representative and
diverse open-domain dialogue evaluation benchmarks. Our approach leverages
several state-of-the-art LLMs to generate user-chatbot multilingual dialogues,
conditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a
multidimensional analysis of the performance of the chatbots, uncovering
noticeable cross-lingual performance differences. Guided by this large-scale
evaluation, we curate a new meta-evaluation multilingual benchmark and
human-annotate samples with nuanced quality judgments. This benchmark is then
used to assess the ability of several reasoning and non-reasoning LLMs to act
as evaluators of open-domain dialogues. We find that current LLMs struggle to
detect nuanced issues, particularly those involving empathy and reasoning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [9] [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org/abs/2505.22698)
*Luca Fantin,Marco Antonelli,Margherita Cesetti,Daniele Irto,Bruno Zamengo,Francesco Silvestri*

Main category: cs.AI

TL;DR: 本文介绍了一种聊天机器人，旨在简化公共交通服务质量数据的交互流程。它使用代理架构来扩展大型语言模型的功能，并已通过多种测试验证其性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，使用SQL查询分析和可视化大规模公共交通服务数据对大部分用户来说较为复杂。为了解决这一问题，本文提出了一种通过聊天机器人简化用户数据交互和决策支持的解决方案。

Method: 本文使用了一种基于代理架构的聊天机器人，能够与一系列工具交互，以执行SQL查询、数据绘图以及从行程坐标创建地图等任务。

Result: 该聊天机器人经过严格测试，通过一个工作流程来问多个问题，并存储生成的查询、检索的数据和自然语言响应。最终获得的数据集用于评估其性能，特别关注答案的一致性和生成查询的正确性。

Conclusion: 本文提出了一种基于聊天机器人的工具，旨在简化公共交通服务质量数据的交互和决策过程。通过代理架构的使用，扩展了大型语言模型（LLM）的功能，能够执行SQL查询、数据绘图以及地图生成等任务，实现用户友好型的数据交互。

Abstract: Assessing the quality of public transportation services requires the analysis
of large quantities of data on the scheduled and actual trips and documents
listing the quality constraints each service needs to meet. Interrogating such
datasets with SQL queries, organizing and visualizing the data can be quite
complex for most users. This paper presents a chatbot offering a user-friendly
tool to interact with these datasets and support decision making. It is based
on an agent architecture, which expands the capabilities of the core Large
Language Model (LLM) by allowing it to interact with a series of tools that can
execute several tasks, like performing SQL queries, plotting data and creating
maps from the coordinates of a trip and its stops. This paper also tackles one
of the main open problems of such Generative AI projects: collecting data to
measure the system's performance. Our chatbot has been extensively tested with
a workflow that asks several questions and stores the generated query, the
retrieved data and the natural language response for each of them. Such
questions are drawn from a set of base examples which are then completed with
actual data from the database. This procedure yields a dataset for the
evaluation of the chatbot's performance, especially the consistency of its
answers and the correctness of the generated queries.

</details>


### [10] [Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields](https://arxiv.org/abs/2505.22753)
*Arseniy Pertzovsky,Roni Stern,Ariel Felner,Roie Zivan*

Main category: cs.AI

TL;DR: APFs improve LMAPF efficiency, boosting throughput by 7x, but don't help standard MAPF.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency and performance of both MAPF and LMAPF by using Artificial Potential Fields.

Method: The paper proposes methods to integrate APFs into several MAPF algorithms such as Prioritized Planning, MAPF-LNS2, and PIBT.

Result: Incorporating APFs significantly increases overall system throughput by up to seven times for LMAPF, but does not benefit standard MAPF.

Conclusion: APFs are not beneficial for traditional MAPF but significantly enhance throughput in LMAPF.

Abstract: We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent
Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of
agents must move to their goal locations without collisions, whereas in LMAPF,
new goals are generated upon arrival. We propose methods for incorporating APFs
in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and
Priority Inheritance with Backtracking (PIBT). Experimental results show that
using APF is not beneficial for MAPF but yields up to a 7-fold increase in
overall system throughput for LMAPF.

</details>


### [11] [Decomposing Elements of Problem Solving: What "Math" Does RL Teach?](https://arxiv.org/abs/2505.22756)
*Tian Qin,Core Francisco Park,Mujin Kwun,Aaron Walsman,Eran Malach,Nikhil Anand,Hidenori Tanaka,David Alvarez-Melis*

Main category: cs.AI

TL;DR: Research shows RL improves execution skills but fails in planning, posing limitations for solving new tasks in LLMs.


<details>
  <summary>Details</summary>
Motivation: The study aims to address limitations in current accuracy metrics by offering a deeper evaluation method for understanding internalized problem-solving skills in LLMs.

Method: The paper uses a decomposition approach analyzing fundamental capabilities like Plan, Execute, and Verify, along with synthetic task experiments, to explore RL's impact on LLM reasoning.

Result: FFindings show RL primarily enhances execution robustness and struggles with insufficient planning skills for novel problems, termed 'coverage wall'.

Conclusion: RL methods mainly boost the execution capability in LLMs, but they struggle with new problem-solving due to weakness in planning skills.

Abstract: Mathematical reasoning tasks have become prominent benchmarks for assessing
the reasoning capabilities of LLMs, especially with reinforcement learning (RL)
methods such as GRPO showing significant performance gains. However, accuracy
metrics alone do not support fine-grained assessment of capabilities and fail
to reveal which problem-solving skills have been internalized. To better
understand these capabilities, we propose to decompose problem solving into
fundamental capabilities: Plan (mapping questions to sequences of steps),
Execute (correctly performing solution steps), and Verify (identifying the
correctness of a solution). Empirically, we find that GRPO mainly enhances the
execution skill-improving execution robustness on problems the model already
knows how to solve-a phenomenon we call temperature distillation. More
importantly, we show that RL-trained models struggle with fundamentally new
problems, hitting a 'coverage wall' due to insufficient planning skills. To
explore RL's impact more deeply, we construct a minimal, synthetic
solution-tree navigation task as an analogy for mathematical problem-solving.
This controlled setup replicates our empirical findings, confirming RL
primarily boosts execution robustness. Importantly, in this setting, we
identify conditions under which RL can potentially overcome the coverage wall
through improved exploration and generalization to new solution paths. Our
findings provide insights into the role of RL in enhancing LLM reasoning,
expose key limitations, and suggest a path toward overcoming these barriers.
Code is available at https://github.com/cfpark00/RL-Wall.

</details>


### [12] [Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds](https://arxiv.org/abs/2505.22779)
*Mohammad Helal Uddin,Sabur Baidya*

Main category: cs.AI

TL;DR: 该研究利用智能手机传感器数据和Twitter互动分析来评估抑郁水平，通过深度学习和SVM算法实现高精度分类，以此监控抑郁而不侵犯隐私。


<details>
  <summary>Details</summary>
Motivation: 心理障碍如抑郁症、焦虑症及其他神经障碍在全球范围内造成了重大挑战，特别是在具有社交回避倾向的个人中。

Method: 研究采用了CNN深度学习模型和朴素贝叶斯分类来识别人类活动，并通过支持向量机（SVM）算法进行抑郁症状严重程度分类。

Result: 研究结果表明，通过使用六个来自身体活动的特征和三个来自Twitter活动分析的情感特征，活动识别精度达到95%，情感分析精度达到95.6%。SVM算法用于抑郁严重程度分类，准确率达到94%。几项身体活动特征与抑郁症状程度显著相关。

Conclusion: 该研究提出了一种简便而高效的方法，通过智能手机传感器数据和社交媒体互动分析来监控抑郁症状，同时保护个人隐私。这种方法在长期监测中表现出色。

Abstract: Mental disorders including depression, anxiety, and other neurological
disorders pose a significant global challenge, particularly among individuals
exhibiting social avoidance tendencies. This study proposes a hybrid approach
by leveraging smartphone sensor data measuring daily physical activities and
analyzing their social media (Twitter) interactions for evaluating an
individual's depression level. Using CNN-based deep learning models and Naive
Bayes classification, we identify human physical activities accurately and also
classify the user sentiments. A total of 33 participants were recruited for
data acquisition, and nine relevant features were extracted from the physical
activities and analyzed with their weekly depression scores, evaluated using
the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six
are derived from physical activities, achieving an activity recognition
accuracy of 95%, while three features stem from sentiment analysis of Twitter
activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several
physical activity features exhibited significant correlations with the severity
of depression symptoms. For classifying the depression severity, a support
vector machine (SVM)-based algorithm is employed that demonstrated a very high
accuracy of 94%, outperforming alternative models, e.g., the multilayer
perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly
effective in the long run for monitoring depression without breaching personal
privacy.

</details>


### [13] [The WHY in Business Processes: Unification of Causal Process Models](https://arxiv.org/abs/2505.22871)
*Yuval David,Fabiana Fournier,Lior Limonad,Inna Skarbovsky*

Main category: cs.AI

TL;DR: 研究提出了一种新方法统一多种因果过程变体，解决了交替因果条件的问题，并有效评估于多个数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的方法发现因果过程模型，但缺乏在多个变体中捕捉交替因果条件的能力。

Method: 该方法被形式化定义，经过证明，并在三个开放数据集和两个专有数据集上进行评估，同时作为开源实现发布。

Result: 新方法成功地统一了多个因果过程变体为一致的模型，保持原始因果模型的正确性，并明确表示其因果流替换。

Conclusion: 该研究提出了一种新方法，将多个因果过程变体统一为一致的模型，同时保留原始因果模型的正确性，并明确表示其因果流替换。

Abstract: Causal reasoning is essential for business process interventions and
improvement, requiring a clear understanding of causal relationships among
activity execution times in an event log. Recent work introduced a method for
discovering causal process models but lacked the ability to capture alternating
causal conditions across multiple variants. This raises the challenges of
handling missing values and expressing the alternating conditions among log
splits when blending traces with varying activities.
  We propose a novel method to unify multiple causal process variants into a
consistent model that preserves the correctness of the original causal models,
while explicitly representing their causal-flow alternations. The method is
formally defined, proved, evaluated on three open and two proprietary datasets,
and released as an open-source implementation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [14] [A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems](https://arxiv.org/abs/2505.22814)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.MA

TL;DR: 该论文提出了一种大语言模型支持的多代理制造系统控制架构，以应对实时扰动，提高系统弹性和灵活性，并通过仿真验证其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 制造环境日益复杂且难以预测，传统控制方法在动态工业环境中响应能力不足，需要新的控制策略来解决未预见的挑战。

Method: 引入大语言模型支持的控制架构，利用多代理制造系统，通过实施基于仿真的案例研究来展示该架构的优越性。

Result: 案例研究表明，提出的架构提升了系统的弹性和灵活性；与现有方法相比，提高了吞吐量和资源利用效率。

Conclusion: 基于大语言模型的控制架构提高了系统的弹性和灵活性，并且在吞吐量和资源利用效率上优于现有方法。

Abstract: Manufacturing environments are becoming more complex and unpredictable due to
factors such as demand variations and shorter product lifespans. This
complexity requires real-time decision-making and adaptation to disruptions.
Traditional control approaches highlight the need for advanced control
strategies capable of overcoming unforeseen challenges, as they demonstrate
limitations in responsiveness within dynamic industrial settings. Multi-agent
systems address these challenges through decentralization of decision-making,
enabling systems to respond dynamically to operational changes. However,
current multi-agent systems encounter challenges related to real-time
adaptation, context-aware decision-making, and the dynamic exploration of
resource capabilities. Large language models provide the possibility to
overcome these limitations through context-aware decision-making capabilities.
This paper introduces a large language model-enabled control architecture for
multi-agent manufacturing systems to dynamically explore resource capabilities
in response to real-time disruptions. A simulation-based case study
demonstrates that the proposed architecture improves system resilience and
flexibility. The case study findings show improved throughput and efficient
resource utilization compared to existing approaches.

</details>


### [15] [Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2505.23352)
*Xu Shen,Yixin Liu,Yiwei Dai,Yili Wang,Rui Miao,Yue Tan,Shirui Pan,Xin Wang*

Main category: cs.MA

TL;DR: 研究提出了EIB-leanrner，通过融合稀疏和密集图的连接模式优化通信拓扑，实验显示其具备优越的效果、通信成本和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的通信拓扑自动化设计研究往往构建稀疏结构以提高效率，但常常忽视为何以及何时稀疏或密集的拓扑有助或阻碍协作。

Method: 该研究提出了一种新的拓扑设计方法EIB-leanrner，通过融合来自密集和稀疏图的连接模式，平衡错误抑制与有益信息传播。

Result: 广泛的实验显示EIB-leanrner在效果、通信成本和鲁棒性方面具有优越性。

Conclusion: 适度稀疏的拓扑结构通常能达到最佳任务表现，因为它能有效抑制错误传播，同时保留有益的信息扩散。

Abstract: The communication topology in large language model-based multi-agent systems
fundamentally governs inter-agent collaboration patterns, critically shaping
both the efficiency and effectiveness of collective decision-making. While
recent studies for communication topology automated design tend to construct
sparse structures for efficiency, they often overlook why and when sparse and
dense topologies help or hinder collaboration. In this paper, we present a
causal framework to analyze how agent outputs, whether correct or erroneous,
propagate under topologies with varying sparsity. Our empirical studies reveal
that moderately sparse topologies, which effectively suppress error propagation
while preserving beneficial information diffusion, typically achieve optimal
task performance. Guided by this insight, we propose a novel topology design
approach, EIB-leanrner, that balances error suppression and beneficial
information propagation by fusing connectivity patterns from both dense and
sparse graphs. Extensive experiments show the superior effectiveness,
communication cost, and robustness of EIB-leanrner.

</details>


### [16] [Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging](https://arxiv.org/abs/2505.23584)
*Sumbal Malik,Majid Khonji,Khaled Elbassioni,Jorge Dias*

Main category: cs.MA

TL;DR: 研究提出结合使用卡车、无人机和机器人的新方法来优化最后一英里配送，结果表明这种方法在时间和成本上具有显著优势。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速增长和对及时、成本效益强的最后一英里配送需求的增加，促使研究人员关注协作物流，并引入VRP-DR问题。

Method: 通过提出一种新的组合同步多平台车辆路径问题（VRP-DR），并将其构建为一个混合整数线性规划（MILP）模型，以最小化操作成本和完工时间。

Result: 通过数值实验验证了提出的MILP模型和FINDER算法在解决大规模问题时的性能。结果显示，与仅使用卡车的模式相比，结合使用无人机和机器人显著节省时间，并在多次访问的情况下大幅降低成本。

Conclusion: 该研究展示了结合使用卡车、无人机和机器人进行包裹配送在时间和成本上的有效性，特别是在多次访问和在途充电的情况下。

Abstract: The rapid growth of e-commerce and the increasing demand for timely,
cost-effective last-mile delivery have increased interest in collaborative
logistics. This research introduces a novel collaborative synchronized
multi-platform vehicle routing problem with drones and robots (VRP-DR), where a
fleet of $\mathcal{M}$ trucks, $\mathcal{N}$ drones and $\mathcal{K}$ robots,
cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the
launching, retrieving, and en-route charging of drones and robots, thereby
addressing critical limitations such as restricted payload capacities, limited
range, and battery constraints. The VRP-DR incorporates five realistic
features: (1) multi-visit service per trip, (2) multi-trip operations, (3)
flexible docking, allowing returns to the same or different trucks (4) cyclic
and acyclic operations, enabling return to the same or different nodes; and (5)
en-route charging, enabling drones and robots to recharge while being
transported on the truck, maximizing operational efficiency by utilizing idle
transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP)
to minimize both operational costs and makespan. To overcome the computational
challenges of solving large-scale instances, a scalable heuristic algorithm,
FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to
provide efficient, near-optimal solutions. Numerical experiments across various
instance sizes evaluate the performance of the MILP and heuristic approaches in
terms of solution quality and computation time. The results demonstrate
significant time savings of the combined delivery mode over the truck-only mode
and substantial cost reductions from enabling multi-visits. The study also
provides insights into the effects of en-route charging, docking flexibility,
drone count, speed, and payload capacity on system performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [17] [Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs](https://arxiv.org/abs/2505.22686)
*Ange-Clement Akazan,Verlon Roel Mbingui,Gnankan Landry Regis N'guessan,Issa Karambal*

Main category: cs.LG

TL;DR: 研究对比了多种深度学习模型用于热带地区天气预报，发现KAN和自定义的TKAN在温度和降水预测上表现出色，而经典RNN在气压预测中更具竞争力，显示样条函数神经结构在高效天气预报中的潜力。


<details>
  <summary>Details</summary>
Motivation: 目前的天气预报方法在处理热带非洲复杂且非线性的天气模式时表现不佳，因此研究的动机是开发更有效的天气预报模型，以帮助管理风险和经济规划。

Method: 研究对比了深度循环神经网络（如LSTM、GRU、BiLSTM、BiGRU）和Kolmogorov-Arnold（KAN和TKAN）基于样条函数的模型，以预测两个热带城市（科特迪瓦阿比让和卢旺达基加利）的每日温度、降水和气压。研究还引入了两种TKAN的自定义变体，将其原始的SiLU激活函数替换为GeLU和MiSH。通过2010年至2024年的气象数据，对所有模型进行标准回归指标的评估。

Result: KAN模型在温度预测上表现最佳，TKAN变体在低降水环境中的降水预测中将绝对误差最小化。此外，自定义的TKAN模型在两个数据集上的表现均优于标准TKAN。经典的RNN在大气压力预测中保持竞争力，比KAN基于模型在这一任务中表现更好。

Conclusion: 研究结果表明，基于样条函数的神经网络结构在高效且数据高效的天气预报领域具有潜力。

Abstract: Weather forecasting is crucial for managing risks and economic planning,
particularly in tropical Africa, where extreme events severely impact
livelihoods. Yet, existing forecasting methods often struggle with the region's
complex, non-linear weather patterns. This study benchmarks deep recurrent
neural networks such as $\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and
Kolmogorov-Arnold-based models $(\texttt{KAN} and \texttt{TKAN})$ for daily
forecasting of temperature, precipitation, and pressure in two tropical cities:
Abidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce
two customized variants of $ \texttt{TKAN}$ that replace its original
$\texttt{SiLU}$ activation function with $ \texttt{GeLU}$ and \texttt{MiSH},
respectively. Using station-level meteorological data spanning from 2010 to
2024, we evaluate all the models on standard regression metrics. $\texttt{KAN}$
achieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,
$\texttt{MSE} < 0.0014~^\circ C ^2$), while $\texttt{TKAN}$ variants minimize
absolute errors for precipitation forecasting in low-rainfall regimes. The
customized $\texttt{TKAN}$ models demonstrate improvements over the standard
$\texttt{TKAN}$ across both datasets. Classical \texttt{RNNs} remain highly
competitive for atmospheric pressure ($R^2 \approx 0.83{-}0.86$), outperforming
$\texttt{KAN}$-based models in this task. These results highlight the potential
of spline-based neural architectures for efficient and data-efficient
forecasting.

</details>


### [18] [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org/abs/2505.22689)
*Jialong Guo,Xinghao Chen,Yehui Tang,Yunhe Wang*

Main category: cs.LG

TL;DR: 大型语言模型的计算成本限制了其应用，结构化剪枝可解决此问题。本文提出SlimLLM方法，通过整通道和注意头剪枝及线性回归策略实现性能恢复，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因其计算成本高昂，限制了部署和应用。结构化剪枝可有效压缩这些模型的参数，而确定LLMs子模块的重要性及减少性能损失是关键问题。

Method: 整篇论文中使用了一种名为SlimLLM的结构化剪枝方法，其中包括通道和注意头剪枝及用于快速恢复性能的简单线性回归策略，还提出基于层的重要性比率确定剪枝率。

Result: 根据LLaMA基准结果，SlimLLM表现优于其他方法，实现了目前的最佳性能。

Conclusion: 本文提出了一种有效且快速的结构化剪枝方法SlimLLM，用于大型语言模型，实现了性能的恢复和剪枝率的最佳确定。基于LLaMA基准测试，SlimLLM优于其他方法，并达到了目前的最优性能。

Abstract: Large language models(LLMs) have garnered significant attention and
demonstrated impressive capabilities in a wide range of applications. However,
due to their enormous computational costs, the deployment and application of
LLMs are often severely limited. To address this issue, structured pruning is
an effective solution to compress the parameters of LLMs. Determining the
importance of each sub-module in LLMs and minimizing performance loss are
critical issues that need to be carefully addressed in structured pruning. In
this paper, we propose an effective and fast structured pruning method named
SlimLLM for large language models. For channel and attention head pruning, we
evaluate the importance based on the entire channel or head, rather than merely
aggregating the importance of individual elements within a sub-module. This
approach enables a more holistic consideration of the interdependence among
elements within the sub-module. In addition, we design a simple linear
regression strategy for the output matrix to quickly recover performance. We
also propose layer-based importance ratio to determine the pruning ratio for
each layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other
methods and achieves state-of-the-art performance.

</details>


### [19] [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org/abs/2505.22694)
*Dacao Zhang,Kun Zhang,Shimao Chu,Le Wu,Xin Li,Si Wei*

Main category: cs.LG

TL;DR: The paper proposes Mixture of Low-Rank Experts (MoRE) for multi-task PEFT, improving the performance of LLMs in multi-task scenarios without additional inference cost.


<details>
  <summary>Details</summary>
Motivation: Improve the efficiency and effectiveness of Low-Rank Adaptation (LoRA) in multi-task scenarios for LLMs.

Method: Introduce Mixture of Low-Rank Experts (MoRE) method by aligning different ranks of LoRA modules with different tasks and designing an adaptive rank selector for task-specific expert selection.

Result: Experimental results show that MoRE significantly enhances the performance of LLMs in multi-task scenarios compared to traditional LoRA and its variants.

Conclusion: MoRE significantly improves the performance of LLMs in multi-task scenarios without incurring additional inference cost.

Abstract: With the rapid development of Large Language Models (LLMs),
Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant
attention, which aims to achieve efficient fine-tuning of LLMs with fewer
parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)
introduces low-rank matrices to approximate the incremental tuning parameters
and achieves impressive performance over multiple scenarios. After that, plenty
of improvements have been proposed for further improvement. However, these
methods either focus on single-task scenarios or separately train multiple LoRA
modules for multi-task scenarios, limiting the efficiency and effectiveness of
LoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in
this paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for
multi-task PEFT. Specifically, instead of using an individual LoRA for each
task, we align different ranks of LoRA module with different tasks, which we
named low-rank experts. Moreover, we design a novel adaptive rank selector to
select the appropriate expert for each task. By jointly training low-rank
experts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task
scenarios. Finally, we conduct extensive experiments over multiple multi-task
benchmarks along with different LLMs to verify model performance. Experimental
results demonstrate that compared to traditional LoRA and its variants, MoRE
significantly improves the performance of LLMs in multi-task scenarios and
incurs no additional inference cost. We also release the model and code to
facilitate the community.

</details>


### [20] [LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning](https://arxiv.org/abs/2505.22695)
*Tengfei Lyu,Siyuan Feng,Hao Liu,Hai Yang*

Main category: cs.LG

TL;DR: 提出了LLM-ODDR框架，利用LLMs进行网约车订单调度和司机重定位，实验结果显示其在多个方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前传统方法在动态城市环境中的网约车订单调度和司机重定位操作中，往往忽视了司机收入公平性、可解释性和对真实环境动态的适应性。因此，提出利用LLMs来解决这些问题。

Method: LLM-ODDR框架包括三个关键组件：1）多目标引导的订单价值细化；2）考虑司机收入公平性的订单调度；3）空间时间需求感知的司机重定位。此外，开发了一个名为JointDR-GPT的模型，以进行ODDR任务的优化。

Result: 实验证明，LLM-ODDR框架在有效性、适应异常条件的能力和决策的可解释性方面，显著优于传统方法。

Conclusion: 本文提出了一个名为LLM-ODDR的新框架，利用大型语言模型（LLMs）在网约车服务中进行联合订单调度和司机重定位，解决了传统方法中司机收入公平性、可解释性和适应性的问题。实验结果表明，该框架在曼哈顿出租车运营的真实数据集上显著优于传统方法。

Abstract: Ride-hailing platforms face significant challenges in optimizing order
dispatching and driver repositioning operations in dynamic urban environments.
Traditional approaches based on combinatorial optimization, rule-based
heuristics, and reinforcement learning often overlook driver income fairness,
interpretability, and adaptability to real-world dynamics. To address these
gaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models
(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in
ride-hailing services. LLM-ODDR framework comprises three key components: (1)
Multi-objective-guided Order Value Refinement, which evaluates orders by
considering multiple objectives to determine their overall value; (2)
Fairness-aware Order Dispatching, which balances platform revenue with driver
income fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,
which optimizes idle vehicle placement based on historical patterns and
projected supply. We also develop JointDR-GPT, a fine-tuned model optimized for
ODDR tasks with domain knowledge. Extensive experiments on real-world datasets
from Manhattan taxi operations demonstrate that our framework significantly
outperforms traditional methods in terms of effectiveness, adaptability to
anomalous conditions, and decision interpretability. To our knowledge, this is
the first exploration of LLMs as decision-making agents in ride-hailing ODDR
tasks, establishing foundational insights for integrating advanced language
models within intelligent transportation systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [21] [Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models](https://arxiv.org/abs/2505.22804)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 本文提出了一种使用大语言模型的新框架，以提高多机器人制造系统的任务重新分配适应性与成功率。


<details>
  <summary>Details</summary>
Motivation: 应对多机器人系统中由于环境复杂和动态变化带来的意外中断以及适应性挑战。

Method: 中心控制器代理利用大语言模型来解释结构化的机器人配置数据，并在机器人故障时生成有效的任务重新分配。

Result: 实验表明，在处理机器人故障时任务成功率较高，证明了该方法在增强适应性方面的潜力。

Conclusion: 大语言模型为多机器人制造系统任务重新分配提供了一种有效的控制框架，可显著提高适应性和任务成功率。

Abstract: Recent manufacturing systems are increasingly adopting multi-robot
collaboration to handle complex and dynamic environments. While multi-agent
architectures support decentralized coordination among robot agents, they often
face challenges in enabling real-time adaptability for unexpected disruptions
without predefined rules. Recent advances in large language models offer new
opportunities for context-aware decision-making to enable adaptive responses to
unexpected changes. This paper presents an initial exploratory implementation
of a large language model-enabled control framework for dynamic task
reassignment in multi-robot manufacturing systems. A central controller agent
leverages the large language model's ability to interpret structured robot
configuration data and generate valid reassignments in response to robot
failures. Experiments in a real-world setup demonstrate high task success rates
in recovering from failures, highlighting the potential of this approach to
improve adaptability in multi-robot manufacturing systems.

</details>
