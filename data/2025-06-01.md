<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Training Language Models to Generate Quality Code with Program Analysis Feedback](https://arxiv.org/abs/2505.22704)
*Feng Yao,Zilong Wang,Liyuan Liu,Junxia Cui,Li Zhong,Xiaohan Fu,Haohui Mai,Vish Krishnan,Jianfeng Gao,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出了一种名为REAL的强化学习框架，能通过程序分析和测试提高LLM代码生成质量，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在提高生成代码质量上存在可扩展性差和效率低的问题，因此需要一种自动化且高效的方法来提升代码生成质量。

Method: 提出了一种名为REAL的强化学习框架，结合程序分析信号与单元测试信号来指导生成代码的质量。

Result: 实验表明，REAL框架在功能性和代码质量的评估中优于现有的最新方法。

Conclusion: REAL框架有效地提高了代码生成的质量，在机器学习模型中实现了代码功能性与质量的同步提升。

Abstract: Code generation with large language models (LLMs), often termed vibe coding,
is increasingly adopted in production but fails to ensure code quality,
particularly in security (e.g., SQL injection vulnerabilities) and
maintainability (e.g., missing type annotations). Existing methods, such as
supervised fine-tuning and rule-based post-processing, rely on labor-intensive
annotations or brittle heuristics, limiting their scalability and
effectiveness. We propose REAL, a reinforcement learning framework that
incentivizes LLMs to generate production-quality code using program
analysis-guided feedback. Specifically, REAL integrates two automated signals:
(1) program analysis detecting security or maintainability defects and (2) unit
tests ensuring functional correctness. Unlike prior work, our framework is
prompt-agnostic and reference-free, enabling scalable supervision without
manual intervention. Experiments across multiple datasets and model scales
demonstrate that REAL outperforms state-of-the-art methods in simultaneous
assessments of functionality and code quality. Our work bridges the gap between
rapid prototyping and production-ready code, enabling LLMs to deliver both
speed and quality.

</details>


### [2] [Climate Finance Bench](https://arxiv.org/abs/2505.22752)
*Rafik Mankour,Yassine Chafai,Hamada Saleh,Ghassen Ben Hassine,Thibaud Barreau,Peter Tankov*

Main category: cs.CL

TL;DR: 研究了气候财务基准，通过构建数据集比较RAG方法，发现检索器定位段落是性能瓶颈，并倡导碳报告透明性。


<details>
  <summary>Details</summary>
Motivation: 为了解决公司气候披露中的问题回答需求，并提高检索增强生成方法的效果。

Method: 提出了针对公司气候披露进行问答的基准，使用大规模语言模型。

Result: 展示了RAG方法中检索器能力的关键性，并强调透明碳报告的重要性。

Conclusion: 主要瓶颈在于检索器准确定位包含答案的段落的能力。

Abstract: Climate Finance Bench introduces an open benchmark that targets
question-answering over corporate climate disclosures using Large Language
Models. We curate 33 recent sustainability reports in English drawn from
companies across all 11 GICS sectors and annotate 330 expert-validated
question-answer pairs that span pure extraction, numerical reasoning, and
logical reasoning. Building on this dataset, we propose a comparison of RAG
(retrieval-augmented generation) approaches. We show that the retriever's
ability to locate passages that actually contain the answer is the chief
performance bottleneck. We further argue for transparent carbon reporting in
AI-for-climate applications, highlighting advantages of techniques such as
Weight Quantization.

</details>


### [3] [Pre-Training Curriculum for Multi-Token Prediction in Language Models](https://arxiv.org/abs/2505.22757)
*Ansar Aynetdinov,Alan Akbik*

Main category: cs.CL

TL;DR: 通过课程学习策略改善小型语言模型的MTP训练，其中正向课程表现优于逆向课程。


<details>
  <summary>Details</summary>
Motivation: 解决小型语言模型在MTP目标下的困境。

Method: 采用课程学习策略进行MTP训练，包括正向课程和逆向课程两种变体。

Result: 正向课程提高了下游NTP表现和生成质量，同时保留了自我推测解码的优点；逆向课程提高了NTP表现和生成质量，但缺乏自我推测解码优势。

Conclusion: 提出的教学策略能够提高小型语言模型的性能。正向课程在下游任务中表现更好，逆向课程提高了生成质量，但没有自我推测解码优势。

Abstract: Multi-token prediction (MTP) is a recently proposed pre-training objective
for language models. Rather than predicting only the next token (NTP), MTP
predicts the next $k$ tokens at each prediction step, using multiple prediction
heads. MTP has shown promise in improving downstream performance, inference
speed, and training efficiency, particularly for large models. However, prior
work has shown that smaller language models (SLMs) struggle with the MTP
objective. To address this, we propose a curriculum learning strategy for MTP
training, exploring two variants: a forward curriculum, which gradually
increases the complexity of the pre-training objective from NTP to MTP, and a
reverse curriculum, which does the opposite. Our experiments show that the
forward curriculum enables SLMs to better leverage the MTP objective during
pre-training, improving downstream NTP performance and generative output
quality, while retaining the benefits of self-speculative decoding. The reverse
curriculum achieves stronger NTP performance and output quality, but fails to
provide any self-speculative decoding benefits.

</details>


### [4] [FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian](https://arxiv.org/abs/2505.22759)
*Sara Papi,Marco Gaido,Luisa Bentivogli,Alessio Brutti,Mauro Cettolo,Roberto Gretter,Marco Matassoni,Mohamed Nabih,Matteo Negri*

Main category: cs.CL

TL;DR: FAMA是一系列为英语和意大利语开源的语音基础模型，通过开源数据和代码训练，提升了性能和速度，并促进研究的开放性。


<details>
  <summary>Details</summary>
Motivation: 由于现有语音基础模型的封闭性，阻碍了可再现性和公平评估，因此提出了需要开放科学的语音基础模型。

Method: 使用开源代码和数据训练了英文和意大利语的开放科学语音基础模型FAMA。

Result: FAMA在性能上与现有模型具有竞争力，同时速度提升达8倍。

Conclusion: FAMA公开了所有代码、数据集和模型，推动了语音技术研究的开放性。

Abstract: The development of speech foundation models (SFMs) like Whisper and
SeamlessM4T has significantly advanced the field of speech processing. However,
their closed nature--with inaccessible training data and code--poses major
reproducibility and fair evaluation challenges. While other domains have made
substantial progress toward open science by developing fully transparent models
trained on open-source (OS) code and data, similar efforts in speech remain
limited. To fill this gap, we introduce FAMA, the first family of open science
SFMs for English and Italian, trained on 150k+ hours of OS speech data.
Moreover, we present a new dataset containing 16k hours of cleaned and
pseudo-labeled speech for both languages. Results show that FAMA achieves
competitive performance compared to existing SFMs while being up to 8 times
faster. All artifacts, including code, datasets, and models, are released under
OS-compliant licenses, promoting openness in speech technology research.

</details>


### [5] [Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration](https://arxiv.org/abs/2505.23187)
*Yilong Li,Chen Qian,Yu Xia,Ruijie Shi,Yufan Dang,Zihao Xie,Ziming You,Weize Chen,Cheng Yang,Weichuan Liu,Ye Tian,Xuantang Xiong,Lei Han,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: MAEL是一种新框架，通过跨任务学习和经验积累，加强大语言模型驱动的多智能体系统，以实现更高效的任务解决与协作。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将每个任务孤立处理，导致冗余计算和在结构相似任务上的有限泛化能力。为解决这些问题，引入MAEL框架，通过显式跨任务学习和经验积累来增强LLM驱动的智能体。

Method: MAEL框架将任务求解流程建模为图结构的多智能体协作网络，并通过显式连接进行信息传播和协调。在经验学习阶段，量化任务流程中每一步的质量，并将结果奖励及相应输入输出存储到每个智能体的经验池中。在推理阶段，智能体检索高奖励、任务相关的经验作为少样本示例，以增强推理步骤的有效性。

Result: 实验结果表明，MAEL能够有效地从之前的任务经验中学习，实现更快的收敛速度，并在当前任务中提供更高质量的解决方案。

Conclusion: MAEL框架使得多智能体系统能够更快地收敛，并在当前任务上提供更高质量的解决方案。

Abstract: Large Language Model-based multi-agent systems (MAS) have shown remarkable
progress in solving complex tasks through collaborative reasoning and
inter-agent critique. However, existing approaches typically treat each task in
isolation, resulting in redundant computations and limited generalization
across structurally similar tasks. To address this, we introduce multi-agent
cross-task experiential learning (MAEL), a novel framework that endows
LLM-driven agents with explicit cross-task learning and experience
accumulation. We model the task-solving workflow on a graph-structured
multi-agent collaboration network, where agents propagate information and
coordinate via explicit connectivity. During the experiential learning phase,
we quantify the quality for each step in the task-solving workflow and store
the resulting rewards along with the corresponding inputs and outputs into each
agent's individual experience pool. During inference, agents retrieve
high-reward, task-relevant experiences as few-shot examples to enhance the
effectiveness of each reasoning step, thereby enabling more accurate and
efficient multi-agent collaboration. Experimental results on diverse datasets
demonstrate that MAEL empowers agents to learn from prior task experiences
effectively-achieving faster convergence and producing higher-quality solutions
on current tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields](https://arxiv.org/abs/2505.22753)
*Arseniy Pertzovsky,Roni Stern,Ariel Felner,Roie Zivan*

Main category: cs.AI

TL;DR: 探索APF在MAPF和LMAPF中的应用，不利于MAPF，但显著提高LMAPF的系统吞吐量。


<details>
  <summary>Details</summary>
Motivation: 探索人工势场（APF）在解决多智能体路径规划（MAPF）和长期多智能体路径规划（LMAPF）中的应用。

Method: 将人工势场（APF）方法应用于多种MAPF算法中，包括优先级规划、MAPF-LNS2和具有回溯的优先级继承。

Result: 实验结果显示，使用人工势场（APF）方法并不能改善MAPF问题，但在LMAPF中，则能将整体系统吞吐量提高7倍。

Conclusion: 使用人工势场（APF）方法对多智能体路径规划（MAPF）无益，但对于长期多智能体路径规划（LMAPF），则显著提高系统吞吐量。

Abstract: We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent
Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of
agents must move to their goal locations without collisions, whereas in LMAPF,
new goals are generated upon arrival. We propose methods for incorporating APFs
in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and
Priority Inheritance with Backtracking (PIBT). Experimental results show that
using APF is not beneficial for MAPF but yields up to a 7-fold increase in
overall system throughput for LMAPF.

</details>


### [7] [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org/abs/2505.22698)
*Luca Fantin,Marco Antonelli,Margherita Cesetti,Daniele Irto,Bruno Zamengo,Francesco Silvestri*

Main category: cs.AI

TL;DR: 本论文提出一种基于代理架构的聊天机器人，通过与工具的交互来帮助分析和可视化公共交通数据，提高查询与响应的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决使用SQL查询分析公共交通服务质量数据集复杂的问题，并提高用户界面的友好性。

Method: 基于代理架构，使核心大型语言模型（LLM）可以通过一系列工具执行任务，如SQL查询、绘图和地图创建。

Result: 测试表明，该聊天机器人可以通过一系列问题提供一致的答案，并生成正确的查询。

Conclusion: 提出了一种聊天机器人工具，能够与数据库交互，支持公共交通服务质量评估的数据分析和可视化。

Abstract: Assessing the quality of public transportation services requires the analysis
of large quantities of data on the scheduled and actual trips and documents
listing the quality constraints each service needs to meet. Interrogating such
datasets with SQL queries, organizing and visualizing the data can be quite
complex for most users. This paper presents a chatbot offering a user-friendly
tool to interact with these datasets and support decision making. It is based
on an agent architecture, which expands the capabilities of the core Large
Language Model (LLM) by allowing it to interact with a series of tools that can
execute several tasks, like performing SQL queries, plotting data and creating
maps from the coordinates of a trip and its stops. This paper also tackles one
of the main open problems of such Generative AI projects: collecting data to
measure the system's performance. Our chatbot has been extensively tested with
a workflow that asks several questions and stores the generated query, the
retrieved data and the natural language response for each of them. Such
questions are drawn from a set of base examples which are then completed with
actual data from the database. This procedure yields a dataset for the
evaluation of the chatbot's performance, especially the consistency of its
answers and the correctness of the generated queries.

</details>


### [8] [Decomposing Elements of Problem Solving: What "Math" Does RL Teach?](https://arxiv.org/abs/2505.22756)
*Tian Qin,Core Francisco Park,Mujin Kwun,Aaron Walsman,Eran Malach,Nikhil Anand,Hidenori Tanaka,David Alvarez-Melis*

Main category: cs.AI

TL;DR: 研究表明，RL提高了执行能力但在计划能力不足情况下产生'覆盖壁'，通过改进探索能潜在突破这一限制。


<details>
  <summary>Details</summary>
Motivation: 旨在深入理解LLM解决数学推理任务的能力，特别是在RL方法下的表现。

Method: 将问题解决过程分解为计划、执行和验证三个基本能力，并通过构建一个最小的合成解决树导航任务进行验证。

Result: RL主要增强了执行技能，尤其是在模型已知如何解决的问题上表现出更高的执行稳定性。

Conclusion: RL提高了LLM在执行问题解决步骤上的稳定性，但在处理全新的问题时存在'覆盖壁'。通过改进探索和推广，RL有可能克服这一障碍。

Abstract: Mathematical reasoning tasks have become prominent benchmarks for assessing
the reasoning capabilities of LLMs, especially with reinforcement learning (RL)
methods such as GRPO showing significant performance gains. However, accuracy
metrics alone do not support fine-grained assessment of capabilities and fail
to reveal which problem-solving skills have been internalized. To better
understand these capabilities, we propose to decompose problem solving into
fundamental capabilities: Plan (mapping questions to sequences of steps),
Execute (correctly performing solution steps), and Verify (identifying the
correctness of a solution). Empirically, we find that GRPO mainly enhances the
execution skill-improving execution robustness on problems the model already
knows how to solve-a phenomenon we call temperature distillation. More
importantly, we show that RL-trained models struggle with fundamentally new
problems, hitting a 'coverage wall' due to insufficient planning skills. To
explore RL's impact more deeply, we construct a minimal, synthetic
solution-tree navigation task as an analogy for mathematical problem-solving.
This controlled setup replicates our empirical findings, confirming RL
primarily boosts execution robustness. Importantly, in this setting, we
identify conditions under which RL can potentially overcome the coverage wall
through improved exploration and generalization to new solution paths. Our
findings provide insights into the role of RL in enhancing LLM reasoning,
expose key limitations, and suggest a path toward overcoming these barriers.
Code is available at https://github.com/cfpark00/RL-Wall.

</details>


### [9] [Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds](https://arxiv.org/abs/2505.22779)
*Mohammad Helal Uddin,Sabur Baidya*

Main category: cs.AI

TL;DR: 该研究使用智能手机传感器数据和Twitter互动分析来评估抑郁程度，通过混合模型达到了高准确性。参与者身体活动和情感分析的准确率分别为95%和95.6%，且多项身体活动特征与抑郁严重程度高度相关。


<details>
  <summary>Details</summary>
Motivation: 精神障碍如抑郁、焦虑及其他神经系统疾病在全球范围内尤其是有社交回避倾向的人群中构成了重大挑战。研究旨在寻找新的方法来评估和监测这些问题。

Method: 该研究采用了一种混合方法，利用智能手机传感器数据和社交媒体互动来评估个体的抑郁程度。具体方法包括使用CNN深度学习模型和朴素贝叶斯分类器识别人体活动及情感分类，支持向量机（SVM）算法用于分类抑郁程度。

Result: 参与者的身体活动识别达到了95%的准确度，社交媒体活动的情感分析达到了95.6%的准确度。SVM算法用于抑郁严重程度分类，准确率达到了94%，优于其他模型。多个身体活动特征与抑郁症状的严重程度呈现显著相关性。

Conclusion: 研究表明，通过智能手机传感器数据和社交媒体互动来监测抑郁程度是一种有效的方法。这种方法简单但在长期监测抑郁症方面非常有效，不会侵犯个人隐私。

Abstract: Mental disorders including depression, anxiety, and other neurological
disorders pose a significant global challenge, particularly among individuals
exhibiting social avoidance tendencies. This study proposes a hybrid approach
by leveraging smartphone sensor data measuring daily physical activities and
analyzing their social media (Twitter) interactions for evaluating an
individual's depression level. Using CNN-based deep learning models and Naive
Bayes classification, we identify human physical activities accurately and also
classify the user sentiments. A total of 33 participants were recruited for
data acquisition, and nine relevant features were extracted from the physical
activities and analyzed with their weekly depression scores, evaluated using
the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six
are derived from physical activities, achieving an activity recognition
accuracy of 95%, while three features stem from sentiment analysis of Twitter
activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several
physical activity features exhibited significant correlations with the severity
of depression symptoms. For classifying the depression severity, a support
vector machine (SVM)-based algorithm is employed that demonstrated a very high
accuracy of 94%, outperforming alternative models, e.g., the multilayer
perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly
effective in the long run for monitoring depression without breaching personal
privacy.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [10] [A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems](https://arxiv.org/abs/2505.22814)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.MA

TL;DR: 本文提出了一种基于大型语言模型的控制架构，该架构提升了制造系统在实时中断情境下的韧性和灵活性，通过仿真研究验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 制造环境复杂且不可预测，传统控制方法在动态工业环境中响应有限，需要先进的控制策略来应对这些挑战。多代理系统通过决策去中心化来解决这一问题，但在实时适应和上下文感知决策方面存在限制。大型语言模型可提供解决这些限制的可能性。

Method: 本文采用一种仿真案例研究的方法来评估所提出的大型语言模型支持的控制架构在多代理制造系统中应对实时中断的效果。

Result: 研究结果展示了所提出架构在提升系统韧性和灵活性方面的显著优势，仿真案例证明了其能够在提高产量和资源利用效率方面优于现有方法。

Conclusion: 研究结果表明，所提出的大型语言模型支持的控制架构可以显著改善系统的韧性和灵活性。与现有方法相比，仿真案例研究显示，通过提高产量和提高资源利用效率来改善制造系统的性能。

Abstract: Manufacturing environments are becoming more complex and unpredictable due to
factors such as demand variations and shorter product lifespans. This
complexity requires real-time decision-making and adaptation to disruptions.
Traditional control approaches highlight the need for advanced control
strategies capable of overcoming unforeseen challenges, as they demonstrate
limitations in responsiveness within dynamic industrial settings. Multi-agent
systems address these challenges through decentralization of decision-making,
enabling systems to respond dynamically to operational changes. However,
current multi-agent systems encounter challenges related to real-time
adaptation, context-aware decision-making, and the dynamic exploration of
resource capabilities. Large language models provide the possibility to
overcome these limitations through context-aware decision-making capabilities.
This paper introduces a large language model-enabled control architecture for
multi-agent manufacturing systems to dynamically explore resource capabilities
in response to real-time disruptions. A simulation-based case study
demonstrates that the proposed architecture improves system resilience and
flexibility. The case study findings show improved throughput and efficient
resource utilization compared to existing approaches.

</details>


### [11] [Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2505.23352)
*Xu Shen,Yixin Liu,Yiwei Dai,Yili Wang,Rui Miao,Yue Tan,Shirui Pan,Xin Wang*

Main category: cs.MA

TL;DR: 文章提出了一种因果框架分析不同稀疏性拓扑如何影响Agent输出的传播，EIB-learner方法平衡了错误抑制和信息传播，实验显示其具有优越性能。


<details>
  <summary>Details</summary>
Motivation: 自动化通信拓扑设计中的研究通常忽视了稀疏和稠密拓扑在何时有利或不利于协作。

Method: 提出了一种新的拓扑设计方法EIB-learner，通过融合稠密和稀疏图的连接模式来平衡错误抑制和信息传播。

Result: 大量实验表明，EIB-learner在效果、通信成本和鲁棒性方面具有优越性。

Conclusion: 适度稀疏的网络拓扑结构能够在压制错误传播的同时保持有益信息的传播，从而实现最佳任务性能。

Abstract: The communication topology in large language model-based multi-agent systems
fundamentally governs inter-agent collaboration patterns, critically shaping
both the efficiency and effectiveness of collective decision-making. While
recent studies for communication topology automated design tend to construct
sparse structures for efficiency, they often overlook why and when sparse and
dense topologies help or hinder collaboration. In this paper, we present a
causal framework to analyze how agent outputs, whether correct or erroneous,
propagate under topologies with varying sparsity. Our empirical studies reveal
that moderately sparse topologies, which effectively suppress error propagation
while preserving beneficial information diffusion, typically achieve optimal
task performance. Guided by this insight, we propose a novel topology design
approach, EIB-leanrner, that balances error suppression and beneficial
information propagation by fusing connectivity patterns from both dense and
sparse graphs. Extensive experiments show the superior effectiveness,
communication cost, and robustness of EIB-leanrner.

</details>


### [12] [Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging](https://arxiv.org/abs/2505.23584)
*Sumbal Malik,Majid Khonji,Khaled Elbassioni,Jorge Dias*

Main category: cs.MA

TL;DR: 该研究提出了一种新的VRP-DR问题，通过MILP和启发式算法解决，以优化卡车、无人机和机器人协同交付的成本和时效。结果表明联合交付模式节省了时间并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速增长和对及时、成本效益高的“最后一公里”交付的需求增加了对协作物流的兴趣。

Method: 采用了一个可扩展的启发式算法FINDER（灵活集成交付与能量充电），以提供高效、近似最优的解决方案。还进行了数值试验，评估MILP和启发式方法在解决方案质量和计算时间方面的性能。

Result: 数值试验展示了启用多次访问带来的显著成本降低，以及与仅卡车模式相比，联合交付模式提供的显著时间节约。研究还提供了关于在途充电、停靠灵活性、无人机数量、速度和载荷能力对系统性能影响的见解。

Conclusion: 研究结果表明，采用联合交付模式相较于仅卡车模式具有显著的时间节省，且启用多次访问能够显著降低成本。

Abstract: The rapid growth of e-commerce and the increasing demand for timely,
cost-effective last-mile delivery have increased interest in collaborative
logistics. This research introduces a novel collaborative synchronized
multi-platform vehicle routing problem with drones and robots (VRP-DR), where a
fleet of $\mathcal{M}$ trucks, $\mathcal{N}$ drones and $\mathcal{K}$ robots,
cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the
launching, retrieving, and en-route charging of drones and robots, thereby
addressing critical limitations such as restricted payload capacities, limited
range, and battery constraints. The VRP-DR incorporates five realistic
features: (1) multi-visit service per trip, (2) multi-trip operations, (3)
flexible docking, allowing returns to the same or different trucks (4) cyclic
and acyclic operations, enabling return to the same or different nodes; and (5)
en-route charging, enabling drones and robots to recharge while being
transported on the truck, maximizing operational efficiency by utilizing idle
transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP)
to minimize both operational costs and makespan. To overcome the computational
challenges of solving large-scale instances, a scalable heuristic algorithm,
FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to
provide efficient, near-optimal solutions. Numerical experiments across various
instance sizes evaluate the performance of the MILP and heuristic approaches in
terms of solution quality and computation time. The results demonstrate
significant time savings of the combined delivery mode over the truck-only mode
and substantial cost reductions from enabling multi-visits. The study also
provides insights into the effects of en-route charging, docking flexibility,
drone count, speed, and payload capacity on system performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [13] [Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs](https://arxiv.org/abs/2505.22686)
*Ange-Clement Akazan,Verlon Roel Mbingui,Gnankan Landry Regis N'guessan,Issa Karambal*

Main category: cs.LG

TL;DR: 这项研究比较了多种神经网络模型用于热带城市的天气预报，发现KAN和定制TKAN模型在温度和降水预测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于现有天气预报方法难以应对热带地区复杂的非线性天气模式，研究探索更有效的天气预测技术。

Method: 使用深度递归神经网络和Kolmogorov-Arnold模型进行天气预测。

Result: KAN模型在温度预测中表现优异，而定制的TKAN模型在低降水地区的降水预测中最小化了绝对误差。RNN在大气压力预测中表现良好。

Conclusion: 该研究验证了基于深度递归神经网络和Kolmogorov-Arnold模型的天气预测方法在热带地区的有效性，特别是在温度和降水预测方面的优势。

Abstract: Weather forecasting is crucial for managing risks and economic planning,
particularly in tropical Africa, where extreme events severely impact
livelihoods. Yet, existing forecasting methods often struggle with the region's
complex, non-linear weather patterns. This study benchmarks deep recurrent
neural networks such as $\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and
Kolmogorov-Arnold-based models $(\texttt{KAN} and \texttt{TKAN})$ for daily
forecasting of temperature, precipitation, and pressure in two tropical cities:
Abidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce
two customized variants of $ \texttt{TKAN}$ that replace its original
$\texttt{SiLU}$ activation function with $ \texttt{GeLU}$ and \texttt{MiSH},
respectively. Using station-level meteorological data spanning from 2010 to
2024, we evaluate all the models on standard regression metrics. $\texttt{KAN}$
achieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,
$\texttt{MSE} < 0.0014~^\circ C ^2$), while $\texttt{TKAN}$ variants minimize
absolute errors for precipitation forecasting in low-rainfall regimes. The
customized $\texttt{TKAN}$ models demonstrate improvements over the standard
$\texttt{TKAN}$ across both datasets. Classical \texttt{RNNs} remain highly
competitive for atmospheric pressure ($R^2 \approx 0.83{-}0.86$), outperforming
$\texttt{KAN}$-based models in this task. These results highlight the potential
of spline-based neural architectures for efficient and data-efficient
forecasting.

</details>


### [14] [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org/abs/2505.22689)
*Jialong Guo,Xinghao Chen,Yehui Tang,Yunhe Wang*

Main category: cs.LG

TL;DR: 提出了一种名为SlimLLM的快速结构化剪枝方法，通过整体评估通道和头的重要性，并应用线性回归快速恢复性能，在LLaMA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在计算成本上的巨大需求限制了它们的应用和部署，因此需要通过有效的剪枝技术来压缩模型参数。

Method: 提出一种名为SlimLLM的结构化剪枝方法，通过基于整个通道或注意力头评估重要性，并利用简单的线性回归策略快速恢复性能。

Result: 在LLaMA基准测试中，SlimLLM超过了其他方法，达到了最先进的性能水平。

Conclusion: 本研究提出了一种名为SlimLLM的有效且快速的结构化剪枝方法，可以在保证性能的情况下对大型语言模型进行压缩。其结果表明，SlimLLM在LLaMA基准测试中优于其他方法，达到了最先进的性能水平。

Abstract: Large language models(LLMs) have garnered significant attention and
demonstrated impressive capabilities in a wide range of applications. However,
due to their enormous computational costs, the deployment and application of
LLMs are often severely limited. To address this issue, structured pruning is
an effective solution to compress the parameters of LLMs. Determining the
importance of each sub-module in LLMs and minimizing performance loss are
critical issues that need to be carefully addressed in structured pruning. In
this paper, we propose an effective and fast structured pruning method named
SlimLLM for large language models. For channel and attention head pruning, we
evaluate the importance based on the entire channel or head, rather than merely
aggregating the importance of individual elements within a sub-module. This
approach enables a more holistic consideration of the interdependence among
elements within the sub-module. In addition, we design a simple linear
regression strategy for the output matrix to quickly recover performance. We
also propose layer-based importance ratio to determine the pruning ratio for
each layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other
methods and achieves state-of-the-art performance.

</details>


### [15] [MermaidFlow: Redefining Agentic Workflow Generation via Safety-Constrained Evolutionary Programming](https://arxiv.org/abs/2505.22967)
*Chengqi Zheng,Jianda Chen,Yueming Lyu,Wen Zheng Terence Ng,Haopeng Zhang,Yew-Soon Ong,Ivor Tsang,Haiyan Yin*

Main category: cs.LG

TL;DR: MermaidFlow通过安全约束的图演化提高了自主代理工作流的成功率和计划的可执行性。


<details>
  <summary>Details</summary>
Motivation: 现有工作流生成方法易于产生脆弱且不可执行的计划，因此需要重新定义代理的搜索空间，通过安全约束的图演化实现更稳健的工作流生成。

Method: 使用Mermaid语言，将工作流程表示为可验证的中间表示，并通过安全约束的图演化进行高效探索。

Result: MermaidFlow在代理推理基准测试上实现了成功率的一致性提高和更快的可执行计划收敛。

Conclusion: 安全约束的图演化提供了一个可扩展、模块化的基础，用于稳健且可解释的自主代理推理系统。

Abstract: Despite the promise of autonomous agentic reasoning, existing workflow
generation methods frequently produce fragile, unexecutable plans due to
unconstrained LLM-driven construction. We introduce MermaidFlow, a framework
that redefines the agentic search space through safety-constrained graph
evolution. At its core, MermaidFlow represent workflows as a verifiable
intermediate representation using Mermaid, a structured and human-interpretable
graph language. We formulate domain-aware evolutionary operators, i.e.,
crossover, mutation, insertion, and deletion, to preserve semantic correctness
while promoting structural diversity, enabling efficient exploration of a
high-quality, statically verifiable workflow space. Without modifying task
settings or evaluation protocols, MermaidFlow achieves consistent improvements
in success rates and faster convergence to executable plans on the agent
reasoning benchmark. The experimental results demonstrate that
safety-constrained graph evolution offers a scalable, modular foundation for
robust and interpretable agentic reasoning systems.

</details>


### [16] [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org/abs/2505.22694)
*Dacao Zhang,Kun Zhang,Shimao Chu,Le Wu,Xin Li,Si Wei*

Main category: cs.LG

TL;DR: The paper introduces MoRE, a new method for multi-task fine-tuning of LLMs, which improves performance without extra cost, addressing limitations of prior methods like LoRA.


<details>
  <summary>Details</summary>
Motivation: Existing methods for parameter-efficient fine-tuning of LLMs, such as LoRA, are limited in multi-task scenarios as they either focus on single-task scenarios or train multiple LoRA modules separately, limiting efficiency.

Method: The paper proposes a method called Mixture of Low-Rank Experts (MoRE) for multi-task parameter-efficient fine-tuning.

Result: MoRE enhances the adaptability and efficiency of LoRA in multi-task scenarios and achieves significantly better performance compared to traditional LoRA and its variants.

Conclusion: MoRE significantly improves the performance of LLMs in multi-task scenarios without adding extra inference cost and has been released for community use.

Abstract: With the rapid development of Large Language Models (LLMs),
Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant
attention, which aims to achieve efficient fine-tuning of LLMs with fewer
parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)
introduces low-rank matrices to approximate the incremental tuning parameters
and achieves impressive performance over multiple scenarios. After that, plenty
of improvements have been proposed for further improvement. However, these
methods either focus on single-task scenarios or separately train multiple LoRA
modules for multi-task scenarios, limiting the efficiency and effectiveness of
LoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in
this paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for
multi-task PEFT. Specifically, instead of using an individual LoRA for each
task, we align different ranks of LoRA module with different tasks, which we
named low-rank experts. Moreover, we design a novel adaptive rank selector to
select the appropriate expert for each task. By jointly training low-rank
experts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task
scenarios. Finally, we conduct extensive experiments over multiple multi-task
benchmarks along with different LLMs to verify model performance. Experimental
results demonstrate that compared to traditional LoRA and its variants, MoRE
significantly improves the performance of LLMs in multi-task scenarios and
incurs no additional inference cost. We also release the model and code to
facilitate the community.

</details>


### [17] [LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning](https://arxiv.org/abs/2505.22695)
*Tengfei Lyu,Siyuan Feng,Hao Liu,Hai Yang*

Main category: cs.LG

TL;DR: LLM-ODDR利用大型语言模型优化出租车订单派遣和司机重定位，提高效率、公平性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统的出租车订单派遣和司机重定位方案在实现司机收入公平性、解释性和适应性方面存在缺陷，而LLMs的引入有望解决这些不足。

Method: 研究提出LLM-ODDR框架，并结合JointDR-GPT模型进行细化，系统通过三个主要组件：多目标导向的订单价值细化、强调公平性的订单派遣和时空需求感知的司机重定位进行优化。

Result: 实验结果表明，与传统方法相比，该框架在有效性、适应异常情况的能力以及决策解释性方面有显著提高。

Conclusion: 这项研究展示了使用大型语言模型(LLMs)作为决策代理，在出租车订单派遣和司机重定位任务中具有显著优势。新框架LLM-ODDR在多目标导向的订单价值细化、考虑公平性的订单派遣和时空需求感知的司机重定位三方面展现了强大的性能优于传统方法。

Abstract: Ride-hailing platforms face significant challenges in optimizing order
dispatching and driver repositioning operations in dynamic urban environments.
Traditional approaches based on combinatorial optimization, rule-based
heuristics, and reinforcement learning often overlook driver income fairness,
interpretability, and adaptability to real-world dynamics. To address these
gaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models
(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in
ride-hailing services. LLM-ODDR framework comprises three key components: (1)
Multi-objective-guided Order Value Refinement, which evaluates orders by
considering multiple objectives to determine their overall value; (2)
Fairness-aware Order Dispatching, which balances platform revenue with driver
income fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,
which optimizes idle vehicle placement based on historical patterns and
projected supply. We also develop JointDR-GPT, a fine-tuned model optimized for
ODDR tasks with domain knowledge. Extensive experiments on real-world datasets
from Manhattan taxi operations demonstrate that our framework significantly
outperforms traditional methods in terms of effectiveness, adaptability to
anomalous conditions, and decision interpretability. To our knowledge, this is
the first exploration of LLMs as decision-making agents in ride-hailing ODDR
tasks, establishing foundational insights for integrating advanced language
models within intelligent transportation systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [18] [Learning Recommender Mechanisms for Bayesian Stochastic Games](https://arxiv.org/abs/2505.22979)
*Bengisu Guresti,Chongjie Zhang,Yevgeniy Vorobeychik*

Main category: cs.GT

TL;DR: 引入了一种双层强化学习方法来设计贝叶斯随机博弈推荐机制，实验结果显示其在社会福利和激励性能上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在非合作博弈理论中，协同选择一个（近似）均衡是一个重要挑战，尤其是当玩家持有私人信息时，问题变得更加复杂。

Method: 我们提出了一种双层强化学习方法，用于自动设计贝叶斯随机博弈中的推荐机制。

Result: 实验结果表明，我们的方法在两个重复和两个随机游戏中实现的社会福利水平与合作多智能体强化学习基线相竞争，同时显著改善了激励性能。

Conclusion: 我们的双层强化学习方法在贝叶斯随机博弈中设计的推荐机制不仅具有竞争力的社会福利水平，还显著改善了激励性能。

Abstract: An important challenge in non-cooperative game theory is coordinating on a
single (approximate) equilibrium from many possibilities - a challenge that
becomes even more complex when players hold private information. Recommender
mechanisms tackle this problem by recommending strategies to players based on
their reported type profiles. A key consideration in such mechanisms is to
ensure that players are incentivized to participate, report their private
information truthfully, and follow the recommendations. While previous work has
focused on designing recommender mechanisms for one-shot and extensive-form
games, these approaches cannot be effectively applied to stochastic games,
particularly if we constrain recommendations to be Markov stationary policies.
To bridge this gap, we introduce a novel bi-level reinforcement learning
approach for automatically designing recommender mechanisms in Bayesian
stochastic games. Our method produces a mechanism represented by a parametric
function (such as a neural network), and is therefore highly efficient at
execution time. Experimental results on two repeated and two stochastic games
demonstrate that our approach achieves social welfare levels competitive with
cooperative multi-agent reinforcement learning baselines, while also providing
significantly improved incentive properties.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models](https://arxiv.org/abs/2505.22804)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 本文探索了大型语言模型在多机器人制造系统中的应用，通过动态任务重新分配提高系统适应性，实验表明效果显著。


<details>
  <summary>Details</summary>
Motivation: 制造系统正越来越多地采用多机器人协作以应对复杂动态的环境，面临不预定义规则进行实时适应的挑战。

Method: 在制造系统中实施大型语言模型的控制框架，由中央控制代理利用语言模型解释结构化的机器人配置数据并生成有效的任务重新分配。

Result: 实验证明，在从故障中恢复任务方面表现出了很高的成功率。

Conclusion: 本文展示了一种初步的探索性实现，通过使用大型语言模型来提高多机器人制造系统中的适应能力，在发生故障时成功率高。

Abstract: Recent manufacturing systems are increasingly adopting multi-robot
collaboration to handle complex and dynamic environments. While multi-agent
architectures support decentralized coordination among robot agents, they often
face challenges in enabling real-time adaptability for unexpected disruptions
without predefined rules. Recent advances in large language models offer new
opportunities for context-aware decision-making to enable adaptive responses to
unexpected changes. This paper presents an initial exploratory implementation
of a large language model-enabled control framework for dynamic task
reassignment in multi-robot manufacturing systems. A central controller agent
leverages the large language model's ability to interpret structured robot
configuration data and generate valid reassignments in response to robot
failures. Experiments in a real-world setup demonstrate high task success rates
in recovering from failures, highlighting the potential of this approach to
improve adaptability in multi-robot manufacturing systems.

</details>
