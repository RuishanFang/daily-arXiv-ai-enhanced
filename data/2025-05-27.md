<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 18]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.MA](#cs.MA) [Total: 10]
- [cs.LG](#cs.LG) [Total: 10]
- [nlin.AO](#nlin.AO) [Total: 2]
- [cs.GT](#cs.GT) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Advancing Uto-Aztecan Language Technologies: A Case Study on the Endangered Comanche Language](https://arxiv.org/abs/2505.18159)
*Jesus Alvarez C,Daua D. Karajeanes,Ashley Celeste Prado,John Ruttan,Ivory Yang,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 研究展示了利用NLP和社区参与来保护濒危语言科曼奇，通过少量实例提示提高了语言识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决濒危语言在数字领域的排斥问题，以促进语言学研究和语言复兴工作。

Method: 提供了一个手动整理的412个短语数据集、合成数据生成流水线，并对GPT-4o和GPT-4o-mini进行语言识别的实证评估。

Result: 在零样本环境下，模型对科曼奇语的表现较差，但通过少量样本提示（仅五个例子），准确率显著提高，达到了接近完美的效果。

Conclusion: 研究通过少量实例提示显著提高了大型语言模型对科曼奇语的识别能力，证明了NLP在低资源语言环境中的潜力。

Abstract: The digital exclusion of endangered languages remains a critical challenge in
NLP, limiting both linguistic research and revitalization efforts. This study
introduces the first computational investigation of Comanche, an Uto-Aztecan
language on the verge of extinction, demonstrating how minimal-cost,
community-informed NLP interventions can support language preservation. We
present a manually curated dataset of 412 phrases, a synthetic data generation
pipeline, and an empirical evaluation of GPT-4o and GPT-4o-mini for language
identification. Our experiments reveal that while LLMs struggle with Comanche
in zero-shot settings, few-shot prompting significantly improves performance,
achieving near-perfect accuracy with just five examples. Our findings highlight
the potential of targeted NLP methodologies in low-resource contexts and
emphasize that visibility is the first step toward inclusion. By establishing a
foundation for Comanche in NLP, we advocate for computational approaches that
prioritize accessibility, cultural sensitivity, and community engagement.

</details>


### [2] [Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?](https://arxiv.org/abs/2505.18215)
*Junyan Zhang,Yiming Huang,Shuliang Liu,Yubo Gao,Xuming Hu*

Main category: cs.CL

TL;DR: 研究通过比较不同方法，发现BERT类模型在一些高难度数据集上优于LLMs，并提出细粒度的任务选择策略。


<details>
  <summary>Details</summary>
Motivation: 质疑当前流行的'以LLM为中心'的趋势，展示传统BERT类模型在文本分类中潜在的优势。

Method: 通过在六个高难度数据集上对比三种分类方法，包括微调BERT模型、LLM内部状态利用和零样本推理。

Result: 研究表明，BERT类模型在模式驱动任务上表现出色，而LLMs则在需要深度语义或世界知识的任务中占优。提出了一种名为TaMAS的细粒度任务选择策略。

Conclusion: 传统的BERT模型在某些任务上优于LLMs，尤其是在模式驱动任务中。

Abstract: The rapid adoption of LLMs has overshadowed the potential advantages of
traditional BERT-like models in text classification. This study challenges the
prevailing "LLM-centric" trend by systematically comparing three category
methods, i.e., BERT-like models fine-tuning, LLM internal state utilization,
and zero-shot inference across six high-difficulty datasets. Our findings
reveal that BERT-like models often outperform LLMs. We further categorize
datasets into three types, perform PCA and probing experiments, and identify
task-specific model strengths: BERT-like models excel in pattern-driven tasks,
while LLMs dominate those requiring deep semantics or world knowledge. Based on
this, we propose TaMAS, a fine-grained task selection strategy, advocating for
a nuanced, task-driven approach over a one-size-fits-all reliance on LLMs.

</details>


### [3] [CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](https://arxiv.org/abs/2505.18218)
*Shuhang Xu,Fangwei Zhong*

Main category: cs.CL

TL;DR: CoMet框架提升LLMs处理隐喻能力，增强战略沟通。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多代理语言游戏中处理隐喻的能力不足，影响了其战略性沟通的效率。

Method: CoMet框架结合了基于假设的隐喻推理器和隐喻生成器，并通过自我反思和知识整合进行改进。

Result: 实验结果显示，CoMet显著提高了代理在“Undercover”和“Adversarial Taboo”游戏中使用隐喻进行战略沟通的能力。

Conclusion: CoMet框架显著提升了大型语言模型（LLMs）在多代理语言游戏中使用隐喻进行战略性交流的能力。

Abstract: Metaphors are a crucial way for humans to express complex or subtle ideas by
comparing one concept to another, often from a different domain. However, many
large language models (LLMs) struggle to interpret and apply metaphors in
multi-agent language games, hindering their ability to engage in covert
communication and semantic evasion, which are crucial for strategic
communication. To address this challenge, we introduce CoMet, a framework that
enables LLM-based agents to engage in metaphor processing. CoMet combines a
hypothesis-based metaphor reasoner with a metaphor generator that improves
through self-reflection and knowledge integration. This enhances the agents'
ability to interpret and apply metaphors, improving the strategic and nuanced
quality of their interactions. We evaluate CoMet on two multi-agent language
games - Undercover and Adversarial Taboo - which emphasize Covert Communication
and Semantic Evasion. Experimental results demonstrate that CoMet significantly
enhances the agents' ability to communicate strategically using metaphors.

</details>


### [4] [IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis](https://arxiv.org/abs/2505.18223)
*Hanyu Li,Haoyu Liu,Tingyu Zhu,Tianyu Guo,Zeyu Zheng,Xiaotie Deng,Michael I. Jordan*

Main category: cs.CL

TL;DR: 引入IDA-Bench以评估LLM在多轮数据分析中的表现，发现其在<50%的任务中成功，需改进多轮交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视了数据分析领域中的迭代性质，专家的决策随着对数据集的深入理解而演变。此项工作的目的是解决这一问题。

Method: 引入IDA-Bench，评价LLM代理在多轮互动场景下的表现。任务由复杂Kaggle笔记本派生，并通过LLM模拟用户提供自然语言指令进行。通过将代理最终数值输出与人类基线进行比较来判断其表现。

Result: 初步结果显示，即使是最先进的编码代理（如Claude-3.7-thinking），在<50%的任务中成功，突显了在单轮测试中未现的局限性。

Conclusion: LLMs需要提高多轮交互能力以成为更可靠的数据分析代理，需要在指令遵循和推理之间达到平衡。

Abstract: Large Language Models (LLMs) show promise as data analysis agents, but
existing benchmarks overlook the iterative nature of the field, where experts'
decisions evolve with deeper insights of the dataset. To address this, we
introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round
interactive scenarios. Derived from complex Kaggle notebooks, tasks are
presented as sequential natural language instructions by an LLM-simulated user.
Agent performance is judged by comparing its final numerical output to the
human-derived baseline. Initial results show that even state-of-the-art coding
agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting
limitations not evident in single-turn tests. This work underscores the need to
improve LLMs' multi-round capabilities for building more reliable data analysis
agents, highlighting the necessity of achieving a balance between instruction
following and reasoning.

</details>


### [5] [Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens](https://arxiv.org/abs/2505.18237)
*Xixian Yong,Xiao Zhou,Yingying Zhang,Jinlin Li,Yefeng Zheng,Xian Wu*

Main category: cs.CL

TL;DR: 研究发现推理链越长信息偏差越大且信息增益越小。提出自适应策略动态停止推理，并在基准测试中提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型虽然在多步推理上表现出色，但是通常生成的推理链过长，导致效率低下。因此，需要优化推理过程的有效性。

Method: 提出两种用于量化信息偏差和信息增益的指标：InfoBias和InfoGain，并引入一种基于熵的自适应思维策略，动态停止推理。

Result: 所提出的策略在QwQ-32B上的六个基准任务中，表现出优越的效率和推理性能，将标记使用量减少了50.80％，准确性提高了1.10％。

Conclusion: 熵基自适应思维策略在提高多步推理效率的同时保持了竞争性的准确性，能够减少生成的推理链长度。与默认模式相比，在六个基准任务上，该策略提高了1.10%的平均准确性，并减少了50.80%的标记使用量。

Abstract: The recent rise of Large Reasoning Models (LRMs) has significantly improved
multi-step reasoning performance, but often at the cost of generating
excessively long reasoning chains. This paper revisits the efficiency of such
reasoning processes through an information-theoretic lens, revealing a
fundamental trade-off between reasoning length and semantic efficiency. We
propose two metrics, InfoBias and InfoGain, to quantify divergence from ideal
reasoning paths and stepwise information contribution, respectively. Empirical
analyses show that longer reasoning chains tend to exhibit higher information
bias and diminishing information gain, especially for incorrect answers.
Motivated by these findings, we introduce an entropy-based Adaptive Think
strategy that dynamically halts reasoning once confidence is sufficiently high,
improving efficiency while maintaining competitive accuracy. Compared to the
Vanilla Think approach (default mode), our strategy yields a 1.10% improvement
in average accuracy and a 50.80% reduction in token usage on QwQ-32B across six
benchmark tasks spanning diverse reasoning types and difficulty levels,
demonstrating superior efficiency and reasoning performance. These results
underscore the promise of entropy-based methods for enhancing both accuracy and
cost-effiiciency in large language model deployment.

</details>


### [6] [Advancing Uto-Aztecan Language Technologies: A Case Study on the Endangered Comanche Language](https://arxiv.org/abs/2505.18159)
*Jesus Alvarez C,Daua D. Karajeanes,Ashley Celeste Prado,John Ruttan,Ivory Yang,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 研究探讨了如何利用低成本的NLP方法来支持濒危语言科曼奇语的保存，通过少样例的提示技术大幅提高语言识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 濒危语言在数字领域的排斥现象对自然语言处理（NLP）构成了重大挑战，限制了语言学研究和复兴工作。

Method: 引入首个对科曼奇语进行计算调查，包含手动整理的412个短语数据集、合成数据生成管道，并利用GPT-4o和GPT-4o-mini进行语言识别的实证评估。

Result: 实验结果表明，在零样本设置中，大型语言模型（LLMs）难以处理科曼奇语，但在提供少量样例后性能显著提升，仅需五个例子就能达到较高的准确率。

Conclusion: 研究强调了在低资源环境中应用目标明确的NLP方法的潜力，建立了科曼奇语在NLP领域的基础，并提倡采用优先考虑可访问性、文化敏感性和社区参与的计算方法。

Abstract: The digital exclusion of endangered languages remains a critical challenge in
NLP, limiting both linguistic research and revitalization efforts. This study
introduces the first computational investigation of Comanche, an Uto-Aztecan
language on the verge of extinction, demonstrating how minimal-cost,
community-informed NLP interventions can support language preservation. We
present a manually curated dataset of 412 phrases, a synthetic data generation
pipeline, and an empirical evaluation of GPT-4o and GPT-4o-mini for language
identification. Our experiments reveal that while LLMs struggle with Comanche
in zero-shot settings, few-shot prompting significantly improves performance,
achieving near-perfect accuracy with just five examples. Our findings highlight
the potential of targeted NLP methodologies in low-resource contexts and
emphasize that visibility is the first step toward inclusion. By establishing a
foundation for Comanche in NLP, we advocate for computational approaches that
prioritize accessibility, cultural sensitivity, and community engagement.

</details>


### [7] [Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?](https://arxiv.org/abs/2505.18215)
*Junyan Zhang,Yiming Huang,Shuliang Liu,Yubo Gao,Xuming Hu*

Main category: cs.CL

TL;DR: Study comparing BERT-like models and LLMs for text classification; BERT-like models excel in pattern tasks, LLMs in semantic/world knowledge tasks. Advocates task-driven approach over LLM-centric reliance.


<details>
  <summary>Details</summary>
Motivation: To challenge the prevailing trend of LLM-centric approaches and highlight the potential advantages of traditional BERT-like models in text classification.

Method: Systematic comparison of BERT-like models fine-tuning, LLM internal state utilization, and zero-shot inference across six high-difficulty datasets. PCA and probing experiments were conducted.

Result: BERT-like models often outperform LLMs in text classification, depending on the nature of the task.

Conclusion: BERT-like models excel in pattern-driven tasks, while LLMs dominate tasks requiring deep semantics or world knowledge. A nuanced, task-driven approach is advocated instead of relying solely on LLMs.

Abstract: The rapid adoption of LLMs has overshadowed the potential advantages of
traditional BERT-like models in text classification. This study challenges the
prevailing "LLM-centric" trend by systematically comparing three category
methods, i.e., BERT-like models fine-tuning, LLM internal state utilization,
and zero-shot inference across six high-difficulty datasets. Our findings
reveal that BERT-like models often outperform LLMs. We further categorize
datasets into three types, perform PCA and probing experiments, and identify
task-specific model strengths: BERT-like models excel in pattern-driven tasks,
while LLMs dominate those requiring deep semantics or world knowledge. Based on
this, we propose TaMAS, a fine-grained task selection strategy, advocating for
a nuanced, task-driven approach over a one-size-fits-all reliance on LLMs.

</details>


### [8] [CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](https://arxiv.org/abs/2505.18218)
*Shuhang Xu,Fangwei Zhong*

Main category: cs.CL

TL;DR: The CoMet framework enables better metaphor processing in LLMs, improving strategic communication in language games.


<details>
  <summary>Details</summary>
Motivation: Many LLMs struggle with interpreting and applying metaphors, which are crucial for strategic communication. This challenge in metaphor processing hinders LLMs' performance in covert communication and semantic evasion within multi-agent language games.

Method: CoMet integrates a hypothesis-based metaphor reasoner and a metaphor generator to improve LLM-based agents' metaphor processing through self-reflection and knowledge integration.

Result: CoMet successfully improves the strategic and nuanced quality of interactions involving metaphors in multi-agent language games, as evidenced by enhanced performance in the Undercover and Adversarial Taboo games.

Conclusion: CoMet significantly enhances the ability of LLM-based agents to engage in strategic communication using metaphors, as demonstrated in language games like Undercover and Adversarial Taboo.

Abstract: Metaphors are a crucial way for humans to express complex or subtle ideas by
comparing one concept to another, often from a different domain. However, many
large language models (LLMs) struggle to interpret and apply metaphors in
multi-agent language games, hindering their ability to engage in covert
communication and semantic evasion, which are crucial for strategic
communication. To address this challenge, we introduce CoMet, a framework that
enables LLM-based agents to engage in metaphor processing. CoMet combines a
hypothesis-based metaphor reasoner with a metaphor generator that improves
through self-reflection and knowledge integration. This enhances the agents'
ability to interpret and apply metaphors, improving the strategic and nuanced
quality of their interactions. We evaluate CoMet on two multi-agent language
games - Undercover and Adversarial Taboo - which emphasize Covert Communication
and Semantic Evasion. Experimental results demonstrate that CoMet significantly
enhances the agents' ability to communicate strategically using metaphors.

</details>


### [9] [IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis](https://arxiv.org/abs/2505.18223)
*Hanyu Li,Haoyu Liu,Tingyu Zhu,Tianyu Guo,Zeyu Zheng,Xiaotie Deng,Michael I. Jordan*

Main category: cs.CL

TL;DR: LLMs在多轮数据分析中有潜力，但现有基准未充分评估其能力。IDA-Bench为评估多轮互动中的表现提供了新方法，结果显示LLMs在此领域仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有的基准忽视了数据领域迭代的性质，该领域专家的决策随着对数据集的深入理解而演变。为了弥补这一点，研究引入了IDA-Bench，以评估LLM在多轮交互中的表现。

Method: 该研究通过IDA-Bench，一个新的基准，评估LLM代理在多轮交互场景中的表现。任务由复杂的Kaggle笔记本衍生而来，以自然语言指令的形式呈现，并通过比较代理的输出与人工基线进行评估。

Result: 即使是最先进的编码代理（如Claude-3.7-thinking）在不到50%的任务中成功，突显出单轮测试中未能发现的限制。

Conclusion: 研究突显了提高LLMs在多轮交互中的能力，以建立更可靠的数据分析代理的必要性。强调需在遵循指令和推理之间取得平衡。

Abstract: Large Language Models (LLMs) show promise as data analysis agents, but
existing benchmarks overlook the iterative nature of the field, where experts'
decisions evolve with deeper insights of the dataset. To address this, we
introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round
interactive scenarios. Derived from complex Kaggle notebooks, tasks are
presented as sequential natural language instructions by an LLM-simulated user.
Agent performance is judged by comparing its final numerical output to the
human-derived baseline. Initial results show that even state-of-the-art coding
agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting
limitations not evident in single-turn tests. This work underscores the need to
improve LLMs' multi-round capabilities for building more reliable data analysis
agents, highlighting the necessity of achieving a balance between instruction
following and reasoning.

</details>


### [10] [Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens](https://arxiv.org/abs/2505.18237)
*Xixian Yong,Xiao Zhou,Yingying Zhang,Jinlin Li,Yefeng Zheng,Xian Wu*

Main category: cs.CL

TL;DR: 通过熵基自适应思考策略改善多步推理效率，平衡推理链长度与语义效率，在耗费更少计算资源的基础上提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 分析大规模推理模型在多步推理中的效率问题，研究推理链长度与语义效率之间的基本权衡，旨在通过信息论视角提升推理过程的效率。

Method: 通过信息偏差（InfoBias）和信息增益（InfoGain）这两个指标，量化与理想推理路径的偏差及逐步的信息贡献，并引入基于熵的自适应思考策略，动态地在信心足够高时停止推理。

Result: 相比于传统思考方式，自适应思考策略在不同类型和难度的六个基准任务中，QwQ-32B上的平均准确率提升1.10%，标记使用量减少50.80%。

Conclusion: 熵基自适应思考策略在提高效率的同时保持了竞争性的准确性，超过传统范式，尤其在推理过程中显现出更为优越的性能。

Abstract: The recent rise of Large Reasoning Models (LRMs) has significantly improved
multi-step reasoning performance, but often at the cost of generating
excessively long reasoning chains. This paper revisits the efficiency of such
reasoning processes through an information-theoretic lens, revealing a
fundamental trade-off between reasoning length and semantic efficiency. We
propose two metrics, InfoBias and InfoGain, to quantify divergence from ideal
reasoning paths and stepwise information contribution, respectively. Empirical
analyses show that longer reasoning chains tend to exhibit higher information
bias and diminishing information gain, especially for incorrect answers.
Motivated by these findings, we introduce an entropy-based Adaptive Think
strategy that dynamically halts reasoning once confidence is sufficiently high,
improving efficiency while maintaining competitive accuracy. Compared to the
Vanilla Think approach (default mode), our strategy yields a 1.10% improvement
in average accuracy and a 50.80% reduction in token usage on QwQ-32B across six
benchmark tasks spanning diverse reasoning types and difficulty levels,
demonstrating superior efficiency and reasoning performance. These results
underscore the promise of entropy-based methods for enhancing both accuracy and
cost-effiiciency in large language model deployment.

</details>


### [11] [Taming LLMs with Negative Samples: A Reference-Free Framework to Evaluate Presentation Content with Actionable Feedback](https://arxiv.org/abs/2505.18240)
*Ananth Muppidi,Tarak Das,Sambaran Bandyopadhyay,Tripti Shukla,Dharun D A*

Main category: cs.CL

TL;DR: 提出无参考评价方法REFLEX，生成具有特定度量扰动的负样本来微调LLMs，从而无需真实演示文稿进行评估。


<details>
  <summary>Details</summary>
Motivation: 自动生成高质量的演示幻灯片在生成性AI时代是一个重要的问题。

Method: 通过生成具有不同程度特定度量扰动的负面演示样本，并用它们来微调LLMs。然后评估方法在推断过程中使用无参考评估技术。

Result: 大量自动化和人工实验表明，评估方法在生成分数和解释方面优于传统启发式和先进的大型语言模型评估。

Conclusion: REFLEX评估方法优于传统启发式和最新的大型语言模型评估方法，能够生成分数和解释。

Abstract: The generation of presentation slides automatically is an important problem
in the era of generative AI. This paper focuses on evaluating multimodal
content in presentation slides that can effectively summarize a document and
convey concepts to a broad audience. We introduce a benchmark dataset,
RefSlides, consisting of human-made high-quality presentations that span
various topics. Next, we propose a set of metrics to characterize different
intrinsic properties of the content of a presentation and present REFLEX, an
evaluation approach that generates scores and actionable feedback for these
metrics. We achieve this by generating negative presentation samples with
different degrees of metric-specific perturbations and use them to fine-tune
LLMs. This reference-free evaluation technique does not require ground truth
presentations during inference. Our extensive automated and human experiments
demonstrate that our evaluation approach outperforms classical heuristic-based
and state-of-the-art large language model-based evaluations in generating
scores and explanations.

</details>


### [12] [Multi-Scale Probabilistic Generation Theory: A Hierarchical Framework for Interpreting Large Language Models](https://arxiv.org/abs/2505.18244)
*Yukin Zhang,Qi Dong*

Main category: cs.CL

TL;DR: MSPGT是一种分层框架，将生成过程分解为全球上下文、中间结构和局部词汇选择三个语义尺度，并通过两种度量指标识别尺度边界。这种框架在解释和控制语言模型方面具有显著效果。


<details>
  <summary>Details</summary>
Motivation: 大规模Transformer语言模型表现突出，但在如何计划、构建和实现文本方面仍然不够透明。为了更好地理解和控制大语言模型，我们提出了一个能够实现架构无关解释、诊断和控制的方法。

Method: 我们提出了一种名为“多尺度概率生成理论”（MSPGT）的分层框架，通过将生成过程分解为三个语义尺度——全球上下文、中间结构和局部词汇选择，并将每个尺度与Transformer架构中的特定层范围对齐。为识别尺度边界，我们提出了两种互补的度量标准：注意力跨度阈值和层间互信息峰值。通过探测任务和因果干预，验证了这些度量标准在四个代表性模型中生成稳定的局部、中间和全球划分。我们发现，decoder_only模型在中间和全球处理上分配了更多层，而encoder_only模型则更加注重局部特征提取。

Result: 通过有针对性的干预，我们展示了对局部尺度的操控主要影响词汇多样性，中间尺度的修改会影响句子结构和长度，而全球尺度的扰动则影响话语连贯性，并具有统计显著性效果。MSPGT提供了一种统一的架构无关的方法来解释、诊断和控制大型语言模型。

Conclusion: MSPGT提供了一种架构无关的方法，可以对大规模语言模型进行解释、诊断和控制。这一方法实现了对现有语言模型的语义尺度划分，揭示了不同模型的层分配倾向，并能够通过操控不同尺度影响模型输出的词汇多样性、句子结构和语篇连贯性。

Abstract: Large Transformer based language models achieve remarkable performance but
remain opaque in how they plan, structure, and realize text. We introduce
Multi_Scale Probabilistic Generation Theory (MSPGT), a hierarchical framework
that factorizes generation into three semantic scales_global context,
intermediate structure, and local word choices and aligns each scale with
specific layer ranges in Transformer architectures. To identify scale
boundaries, we propose two complementary metrics: attention span thresholds and
inter layer mutual information peaks. Across four representative models (GPT-2,
BERT, RoBERTa, and T5), these metrics yield stable local/intermediate/global
partitions, corroborated by probing tasks and causal interventions. We find
that decoder_only models allocate more layers to intermediate and global
processing while encoder_only models emphasize local feature extraction.
Through targeted interventions, we demonstrate that local scale manipulations
primarily influence lexical diversity, intermediate-scale modifications affect
sentence structure and length, and global_scale perturbations impact discourse
coherence all with statistically significant effects. MSPGT thus offers a
unified, architecture-agnostic method for interpreting, diagnosing, and
controlling large language models, bridging the gap between mechanistic
interpretability and emergent capabilities.

</details>


### [13] [MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning](https://arxiv.org/abs/2505.18247)
*Kunal Sawarkar,Shivam R. Solanki,Abhilasha Mangal*

Main category: cs.CL

TL;DR: MetaGen Blended RAG方法通过提升检索器效率，有效解决了域特定数据集上的RAG准确性问题，显著提高了多个数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在域特定数据集上的应用受限于解答准确性差，难以应对域内复杂术语及语义变化的问题，因此需要开发能够有效提升企业搜索系统的解决方案。

Method: MetaGen Blended RAG方法通过使用关键概念、主题和缩略词来构造元数据生成管道，然后创建具有增强搜索查询的元数据丰富的混合索引。

Result: 在PubMedQA基准测试中，该方法实现了82%的检索准确率和77%的RAG准确率，超过了所有之前未进行微调的RAG准确性结果，并为零样本结果设定了新标杆。其性能甚至可以媲美在这一数据集上进行过微调的最佳模型。

Conclusion: 所提出的方法在多个领域内有效地增强了RAG系统的性能，尤其是在不进行微调的情况下达到了显著的准确性，这表明MetaGen Blended RAG方法具备良好的跨领域通用性。

Abstract: Despite the widespread exploration of Retrieval-Augmented Generation (RAG),
its deployment in enterprises for domain-specific datasets remains limited due
to poor answer accuracy. These corpora, often shielded behind firewalls in
private enterprise knowledge bases, having complex, domain-specific
terminology, rarely seen by LLMs during pre-training; exhibit significant
semantic variability across domains (like networking, military, or legal,
etc.), or even within a single domain like medicine, and thus result in poor
context precision for RAG systems. Currently, in such situations, fine-tuning
or RAG with fine-tuning is attempted, but these approaches are slow, expensive,
and lack generalization for accuracy as the new domain-specific data emerges.
We propose an approach for Enterprise Search that focuses on enhancing the
retriever for a domain-specific corpus through hybrid query indexes and
metadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata
generation pipeline using key concepts, topics, and acronyms, and then creates
a metadata-enriched hybrid index with boosted search queries. This approach
avoids overfitting and generalizes effectively across domains. On the PubMedQA
benchmark for the biomedical domain, the proposed method achieves 82% retrieval
accuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results
without fine-tuning and sets a new benchmark for zero-shot results while
outperforming much larger models like GPT3.5. The results are even comparable
to the best fine-tuned models on this dataset, and we further demonstrate the
robustness and scalability of the approach by evaluating it on other Q&A
datasets like SQuAD, NQ etc.

</details>


### [14] [TAGS: A Test-Time Generalist-Specialist Framework with Retrieval-Augmented Reasoning and Verification](https://arxiv.org/abs/2505.18283)
*Jianghao Wu,Feilong Tang,Yulong Li,Ming Hu,Haochen Xue,Shoaib Jameel,Yutong Xie,Imran Razzak*

Main category: cs.CL

TL;DR: 提出TAGS框架，通过通用模型和专用模型结合，以层次化检索和评估一致性的方式提升医学问答性能，无需微调。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在零样本医学推理中存在浅层和不稳定的问题，微调的医学大模型面对分布变化和未知临床情境时的泛化能力不足。因此需要一种无需模型微调或参数更新的新方法来解决这些问题。

Method: TAGS结合泛用型的通用模型和特定领域的专用模型，通过层次化检索机制和可靠性评分模块，提供多尺度示例和评估推理一致性，以支持综合的推理过程。

Result: TAGS在九个医学问答基准上表现出色，提升了GPT-4o准确性13.8%，DeepSeek-R1提升16.8%，以及提升了一个简单的7B模型的准确性从14.1%到23.9%。

Conclusion: TAGS显著提升了多个医学问答基准的性能，超过了多个经过微调的医学大模型，并展示了无需参数更新的方法的有效性。

Abstract: Recent advances such as Chain-of-Thought prompting have significantly
improved large language models (LLMs) in zero-shot medical reasoning. However,
prompting-based methods often remain shallow and unstable, while fine-tuned
medical LLMs suffer from poor generalization under distribution shifts and
limited adaptability to unseen clinical scenarios. To address these
limitations, we present TAGS, a test-time framework that combines a broadly
capable generalist with a domain-specific specialist to offer complementary
perspectives without any model fine-tuning or parameter updates. To support
this generalist-specialist reasoning process, we introduce two auxiliary
modules: a hierarchical retrieval mechanism that provides multi-scale exemplars
by selecting examples based on both semantic and rationale-level similarity,
and a reliability scorer that evaluates reasoning consistency to guide final
answer aggregation. TAGS achieves strong performance across nine MedQA
benchmarks, boosting GPT-4o accuracy by 13.8%, DeepSeek-R1 by 16.8%, and
improving a vanilla 7B model from 14.1% to 23.9%. These results surpass several
fine-tuned medical LLMs, without any parameter updates. The code will be
available at https://github.com/JianghaoWu/TAGS.

</details>


### [15] [Thinking Fast and Right: Balancing Accuracy and Reasoning Length with Adaptive Rewards](https://arxiv.org/abs/2505.18298)
*Jinyan Su,Claire Cardie*

Main category: cs.CL

TL;DR: 我们的方法实现了语言模型的低成本适应性推理，通过自适应奖励显著减少推理长度并保持准确性。


<details>
  <summary>Details</summary>
Motivation: 当前，强化学习训练的模型因推理路径冗长而导致推理成本和延迟增加。现有方法难以调整固定的长度惩罚项，无法适应模型推理能力的演变，效果有限。

Method: 我们提出了一种自适应奖励整形方法，根据模型性能动态调整准确性与响应长度之间的奖励权衡。

Result: 实验结果表明，我们的方法能够显著减少推理长度，同时基本保持准确性。

Conclusion: 我们的自适应奖励方法在不牺牲准确性的情况下显著减少了推理长度。

Abstract: Large language models (LLMs) have demonstrated strong reasoning abilities in
mathematical tasks, often enhanced through reinforcement learning (RL).
However, RL-trained models frequently produce unnecessarily long reasoning
traces -- even for simple queries -- leading to increased inference costs and
latency. While recent approaches attempt to control verbosity by adding length
penalties to the reward function, these methods rely on fixed penalty terms
that are hard to tune and cannot adapt as the model's reasoning capability
evolves, limiting their effectiveness. In this work, we propose an adaptive
reward-shaping method that enables LLMs to "think fast and right" -- producing
concise outputs without sacrificing correctness. Our method dynamically adjusts
the reward trade-off between accuracy and response length based on model
performance: when accuracy is high, the length penalty increases to encourage
faster length reduction; when accuracy drops, the penalty is relaxed to
preserve correctness. This adaptive reward accelerates early-stage length
reduction while avoiding over-compression in later stages. Experiments across
multiple datasets show that our approach consistently and dramatically reduces
reasoning length while largely maintaining accuracy, offering a new direction
for cost-efficient adaptive reasoning in large-scale language models.

</details>


### [16] [Is It Bad to Work All the Time? Cross-Cultural Evaluation of Social Norm Biases in GPT-4](https://arxiv.org/abs/2505.18322)
*Zhuozhuo Joy Liu,Farhan Samir,Mehar Bhatia,Laura K. Nelson,Vered Shwartz*

Main category: cs.CL

TL;DR: GPT-4生成的文化规范不太具体，隐藏的文化刻板印象易恢复，影响其多样化公平服务能力。


<details>
  <summary>Details</summary>
Motivation: 难以置信LLM能在真实场景中始终如一地应用那些价值观，旨在开发公平服务多样化用户群的LLMs。

Method: 采取自下而上的方法，要求LLM推理不同文化叙述中的文化规范。

Result: GPT-4生成的文化规范不太具体且容易恢复刻板印象，这挑战了LLM在多元文化中公平应用的能力。

Conclusion: GPT-4倾向于生成的文化规范不太具体，并且虽然避免了直接产生刻板印象，但这些刻板印象只是隐藏而非完全抑制，容易被恢复。

Abstract: LLMs have been demonstrated to align with the values of Western or North
American cultures. Prior work predominantly showed this effect through
leveraging surveys that directly ask (originally people and now also LLMs)
about their values. However, it is hard to believe that LLMs would consistently
apply those values in real-world scenarios. To address that, we take a
bottom-up approach, asking LLMs to reason about cultural norms in narratives
from different cultures. We find that GPT-4 tends to generate norms that, while
not necessarily incorrect, are significantly less culture-specific. In
addition, while it avoids overtly generating stereotypes, the stereotypical
representations of certain cultures are merely hidden rather than suppressed in
the model, and such stereotypes can be easily recovered. Addressing these
challenges is a crucial step towards developing LLMs that fairly serve their
diverse user base.

</details>


### [17] [PerMedCQA: Benchmarking Large Language Models on Medical Consumer Question Answering in Persian Language](https://arxiv.org/abs/2505.18331)
*Naghmeh Jamali,Milad Mohammadi,Danial Baledi,Zahra Rezvani,Hesham Faili*

Main category: cs.CL

TL;DR: PerMedCQA是首个波斯语医学消费问答基准，包含68,138个问答对，旨在评估大型语言模型在处理现实世界医学问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在医学问答领域取得了进展，但在面向消费者的多语言资源方面仍然稀缺，尤其是在像波斯语这样的资源匮乏语言中。为了弥补这一差距，我们提出了PerMedCQA，这是第一个用波斯语编写的基准，用于评估LLMs对现实世界中消费者生成的医学问题的回答能力。

Method: 我们采用了MedJudge，一个由LLM评分员驱动的新颖基于评分标准的评估框架，并与专家人工注释进行验证。

Result: 我们的结果强调了多语言医学问答中的关键挑战，并为开发更准确和具上下文意识的医疗辅助系统提供了宝贵的见解。

Conclusion: PerMedCQA是一个重要的资源，它为医学消费问答系统的开发和LLM的评价提供了基准，并公开提供以促进进一步研究。

Abstract: Medical consumer question answering (CQA) is crucial for empowering patients
by providing personalized and reliable health information. Despite recent
advances in large language models (LLMs) for medical QA, consumer-oriented and
multilingual resources, particularly in low-resource languages like Persian,
remain sparse. To bridge this gap, we present PerMedCQA, the first
Persian-language benchmark for evaluating LLMs on real-world,
consumer-generated medical questions. Curated from a large medical QA forum,
PerMedCQA contains 68,138 question-answer pairs, refined through careful data
cleaning from an initial set of 87,780 raw entries. We evaluate several
state-of-the-art multilingual and instruction-tuned LLMs, utilizing MedJudge, a
novel rubric-based evaluation framework driven by an LLM grader, validated
against expert human annotators. Our results highlight key challenges in
multilingual medical QA and provide valuable insights for developing more
accurate and context-aware medical assistance systems. The data is publicly
available on https://huggingface.co/datasets/NaghmehAI/PerMedCQA

</details>


### [18] [Model Editing with Graph-Based External Memory](https://arxiv.org/abs/2505.18343)
*Yash Kumar Atri,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.CL

TL;DR: 提出了HYPE框架，通过超球几何和图神经网络进行模型编辑，实验表明其提高了稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型中的幻觉和过时参数知识问题，特别是通过现有方法进行动态更新时出现过拟合和灾难性遗忘。

Method: 使用双稳定化技术结合超球级数的图构建与Möbius变换更新。

Result: 在CounterFact、CounterFact+和MQuAKE的实验中，HYPE明显增强了编辑的稳定性、事实的准确性和多跳推理。

Conclusion: HYPE显著提高了编辑的稳定性、事实的准确性和多跳推理能力。

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their practical utility is often limited by persistent issues of
hallucinations and outdated parametric knowledge. Although post-training model
editing offers a pathway for dynamic updates, existing methods frequently
suffer from overfitting and catastrophic forgetting. To tackle these
challenges, we propose a novel framework that leverages hyperbolic geometry and
graph neural networks for precise and stable model edits. We introduce HYPE
(HYperbolic Parameter Editing), which comprises three key components: (i)
Hyperbolic Graph Construction, which uses Poincar\'e embeddings to represent
knowledge triples in hyperbolic space, preserving hierarchical relationships
and preventing unintended side effects by ensuring that edits to parent
concepts do not inadvertently affect child concepts; (ii) M\"obius-Transformed
Updates, which apply hyperbolic addition to propagate edits while maintaining
structural consistency within the hyperbolic manifold, unlike conventional
Euclidean updates that distort relational distances; and (iii) Dual
Stabilization, which combines gradient masking and periodic GNN parameter
resetting to prevent catastrophic forgetting by focusing updates on critical
parameters and preserving long-term knowledge. Experiments on CounterFact,
CounterFact+, and MQuAKE with GPT-J and GPT2-XL demonstrate that HYPE
significantly enhances edit stability, factual accuracy, and multi-hop
reasoning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [19] [The end of radical concept nativism](https://arxiv.org/abs/2505.18277)
*Joshua S. Rule,Steven T. Piantadosi*

Main category: cs.AI

TL;DR: 通过对比激进概念天赋论的缺陷，我们证明在某种意义上，人类确实能学习新概念。


<details>
  <summary>Details</summary>
Motivation: 尽管认知科学和心灵哲学的争论长久以来认为学习新的概念是不可能的，但我们认为有必要重新审视并挑战这种观点，尤其是在反驳激进概念天赋论的论点上。

Method: 我们使用计算机科学和信息理论的观点，将相关观点形式化，以期在科学上更具成效。

Result: 我们确定了有关表述能力、概念结构和概念占有的三个关键点，这些点是激进概念天赋论与实际人类认知描绘相分歧的地方。

Conclusion: 我们得出结论，事实上，人们确实在某种重要的意义上学习了新概念。

Abstract: Though humans seem to be remarkable learners, arguments in cognitive science
and philosophy of mind have long maintained that learning something
fundamentally new is impossible. Specifically, Jerry Fodor's arguments for
radical concept nativism hold that most, if not all, concepts are innate and
that what many call concept learning never actually leads to the acquisition of
new concepts. These arguments have deeply affected cognitive science, and many
believe that the counterarguments to radical concept nativism have been either
unsuccessful or only apply to a narrow class of concepts. This paper first
reviews the features and limitations of prior arguments. We then identify three
critical points - related to issues of expressive power, conceptual structure,
and concept possession - at which the arguments in favor of radical concept
nativism diverge from describing actual human cognition. We use ideas from
computer science and information theory to formalize the relevant ideas in ways
that are arguably more scientifically productive. We conclude that, as a
result, there is an important sense in which people do indeed learn new
concepts.

</details>


### [20] [The end of radical concept nativism](https://arxiv.org/abs/2505.18277)
*Joshua S. Rule,Steven T. Piantadosi*

Main category: cs.AI

TL;DR: 论文挑战了实证概念先天论，认为人类能够通过信息理论和计算原理学习新的概念。


<details>
  <summary>Details</summary>
Motivation: 传统的实证概念先天论对认知科学产生了深远影响，但反对观点鲜有成功。本研究旨在探讨这些论点的局限性，并引入更具生产力的科学视角来审视人类的概念学习能力。

Method: 利用计算机科学和信息理论中的思想，以更科学的方式形式化相关观点，从而揭示与传统观念不同的关于人类认知的事实。

Result: 论证表明人类在某种重要意义上能够学习新的概念，挑战了实证概念先天论对人类认知的描述。

Conclusion: 人类确实可以学习新的概念，尽管传统的实证概念先天论强调大多数概念是先天的，认为概念学习不会导致新概念的获取。

Abstract: Though humans seem to be remarkable learners, arguments in cognitive science
and philosophy of mind have long maintained that learning something
fundamentally new is impossible. Specifically, Jerry Fodor's arguments for
radical concept nativism hold that most, if not all, concepts are innate and
that what many call concept learning never actually leads to the acquisition of
new concepts. These arguments have deeply affected cognitive science, and many
believe that the counterarguments to radical concept nativism have been either
unsuccessful or only apply to a narrow class of concepts. This paper first
reviews the features and limitations of prior arguments. We then identify three
critical points - related to issues of expressive power, conceptual structure,
and concept possession - at which the arguments in favor of radical concept
nativism diverge from describing actual human cognition. We use ideas from
computer science and information theory to formalize the relevant ideas in ways
that are arguably more scientifically productive. We conclude that, as a
result, there is an important sense in which people do indeed learn new
concepts.

</details>


### [21] [Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary](https://arxiv.org/abs/2505.18325)
*Licheng Pan,Yongqi Tong,Xin Zhang,Xiaolu Zhang,Jun Zhou,Zhixuan Chu*

Main category: cs.AI

TL;DR: 研究探讨了大语言模型的过度拒绝问题，提出RASS框架通过边界对齐提示有效缓解此问题，实现多语言扩展。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在许多任务中表现优异，但常常因过于保守的安全对齐而拒绝回答合理的问询，这是对模型安全性和实用性的挑战。

Method: 通过探索模型的安全决策边界，运用表示空间中的引导向量策略性识别并生成边界对齐的提示语，从而缓解过度拒绝现象。

Result: 研究发现，过度拒绝与模型在安全边界区域的错位密切相关。RASS框架可以通过生成和选择安全边界附近的提示语来减轻这一问题，并且能够扩展到多语言场景中。

Conclusion: 本文提出的RASS框架能够有效地减少大语言模型的过度拒绝问题，提高模型的安全性和实用性，同时具备多语言适应性。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet they often refuse to answer legitimate queries-a
phenomenon known as overrefusal. Overrefusal typically stems from
over-conservative safety alignment, causing models to treat many reasonable
prompts as potentially risky. To systematically understand this issue, we probe
and leverage the models'safety decision boundaries to analyze and mitigate
overrefusal. Our findings reveal that overrefusal is closely tied to
misalignment at these boundary regions, where models struggle to distinguish
subtle differences between benign and harmful content. Building on these
insights, we present RASS, an automated framework for prompt generation and
selection that strategically targets overrefusal prompts near the safety
boundary. By harnessing steering vectors in the representation space, RASS
efficiently identifies and curates boundary-aligned prompts, enabling more
effective and targeted mitigation of overrefusal. This approach not only
provides a more precise and interpretable view of model safety decisions but
also seamlessly extends to multilingual scenarios.We have explored the safety
decision boundaries of various LLMs and construct the MORBench evaluation set
to facilitate robust assessment of model safety and helpfulness across multiple
languages. Code and datasets will be released at
https://anonymous.4open.science/r/RASS-80D3.

</details>


### [22] [RedactOR: An LLM-Powered Framework for Automatic Clinical Data De-Identification](https://arxiv.org/abs/2505.18380)
*Praphul Singh,Charlotte Dzialo,Jangwon Kim,Sumana Srivatsa,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: 提出RedactOR框架，提高医疗数据去识别的召回率和泛化能力，优化LLM成本，并在实际应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有去识别方法在召回错误、有限泛化及效率上的不足，提高AI驱动医疗数据分析的实用性。

Method: 提出一种完全自动化的多模态框架RedactOR，用于去识别结构化和非结构化电子健康记录，包括临床音频记录。该框架采用成本效益高的脱敏策略，包括智能路由、混合规则和LLM方法，以及两步音频去识别方法。

Result: 在i2b2 2014 De-ID数据集上进行评估，使用严格召回标准和标准指标，我们的方法在优化令牌使用以降低LLM成本的同时，实现了竞争性的表现。

Conclusion: RedactOR框架能够有效地解决现有脱敏方法中的召回错误、有限泛化和效率问题，适用于真实世界的AI医疗数据管道。

Abstract: Ensuring clinical data privacy while preserving utility is critical for
AI-driven healthcare and data analytics. Existing de-identification (De-ID)
methods, including rule-based techniques, deep learning models, and large
language models (LLMs), often suffer from recall errors, limited
generalization, and inefficiencies, limiting their real-world applicability. We
propose a fully automated, multi-modal framework, RedactOR for de-identifying
structured and unstructured electronic health records, including clinical audio
records. Our framework employs cost-efficient De-ID strategies, including
intelligent routing, hybrid rule and LLM based approaches, and a two-step audio
redaction approach. We present a retrieval-based entity relexicalization
approach to ensure consistent substitutions of protected entities, thereby
enhancing data coherence for downstream applications. We discuss key design
desiderata, de-identification and relexicalization methodology, and modular
architecture of RedactX and its integration with the Oracle Health Clinical AI
system. Evaluated on the i2b2 2014 De-ID dataset using standard metrics with
strict recall, our approach achieves competitive performance while optimizing
token usage to reduce LLM costs. Finally, we discuss key lessons and insights
from deployment in real-world AI- driven healthcare data pipelines.

</details>


### [23] [Advertising in AI systems: Society must be vigilant](https://arxiv.org/abs/2505.18425)
*Menghua Wu,Yujia Bao*

Main category: cs.AI

TL;DR: 本文探讨了商业动机会如何影响AI系统输出，并提出设计原则和识别商业偏见的策略。


<details>
  <summary>Details</summary>
Motivation: 传统媒体的内容受到商业激励的影响，而AI系统的输出更具动态性、个性化，且缺乏透明性和可监管性，因此需要研究如何应对商业内容的影响。

Method: 本文通过分析广告商、消费者和平台等关键利益相关者的需求，提出设计原则，并制定策略帮助用户识别商业偏见。

Result: 本文提出了一套设计原则和策略，以帮助用户识别和减少AI系统输出中的商业偏见。

Conclusion: 本文提出了一系列设计原则，旨在规范商业影响下的AI系统，并总结了用户识别和减轻商商业偏见的方法。同时，作者呼吁更多的研究和行动，以解决这些问题。

Abstract: AI systems have increasingly become our gateways to the Internet. We argue
that just as advertising has driven the monetization of web search and social
media, so too will commercial incentives shape the content served by AI. Unlike
traditional media, however, the outputs of these systems are dynamic,
personalized, and lack clear provenance -- raising concerns for transparency
and regulation. In this paper, we envision how commercial content could be
delivered through generative AI-based systems. Based on the requirements of key
stakeholders -- advertisers, consumers, and platforms -- we propose design
principles for commercially-influenced AI systems. We then outline high-level
strategies for end users to identify and mitigate commercial biases from model
outputs. Finally, we conclude with open questions and a call to action towards
these goals.

</details>


### [24] [EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military Communication Networks](https://arxiv.org/abs/2505.18457)
*Abir Ray*

Main category: cs.AI

TL;DR: EdgeAgentX integrates FL, MARL, and adversarial defenses to enhance military network performance and security.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the need for improved performance and robustness in military communication networks.

Method: This paper uses federated learning, multi-agent reinforcement learning, and adversarial defense mechanisms.

Result: EdgeAgentX significantly enhances network performance and security, as demonstrated by simulations.

Conclusion: EdgeAgentX improves autonomous decision-making, reduces latency, enhances throughput, and withstands adversarial disruptions.

Abstract: This paper introduces EdgeAgentX, a novel framework integrating federated
learning (FL), multi-agent reinforcement learning (MARL), and adversarial
defense mechanisms, tailored for military communication networks. EdgeAgentX
significantly improves autonomous decision-making, reduces latency, enhances
throughput, and robustly withstands adversarial disruptions, as evidenced by
comprehensive simulations.

</details>


### [25] [Pedagogy-R1: Pedagogically-Aligned Reasoning Model with Balanced Educational Benchmark](https://arxiv.org/abs/2505.18467)
*Unggi Lee,Jaeyong Lee,Jiyeong Bae,Yeil Jeong,Junbo Koh,Gyeonggeon Lee,Gunho Lee,Taekyung Ahn,Hyeoncheol Kim*

Main category: cs.AI

TL;DR: Pedagogy-R1是一个提高LRMs教学能力的框架，通过创新策略显著改善教学效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决LRMs在教学中缺乏教育连贯性和现实教学行为的不足。

Method: 提出一种基于蒸馏的流水线、创建WBEB基准、并使用CoP提示策略进行LRMs的改进和评估。

Result: 综合定量指标与定性分析，首次系统评估了LRMs在教育方面的优缺点。

Conclusion: Pedagogy-R1框架通过创新的策略显著提高LRMs在课堂环境中的教学能力。

Abstract: Recent advances in large reasoning models (LRMs) show strong performance in
structured domains such as mathematics and programming; however, they often
lack pedagogical coherence and realistic teaching behaviors. To bridge this
gap, we introduce Pedagogy-R1, a framework that adapts LRMs for classroom use
through three innovations: (1) a distillation-based pipeline that filters and
refines model outputs for instruction-tuning, (2) the Well-balanced Educational
Benchmark (WBEB), which evaluates performance across subject knowledge,
pedagogical knowledge, tracing, essay scoring, and teacher decision-making, and
(3) a Chain-of-Pedagogy (CoP) prompting strategy for generating and eliciting
teacher-style reasoning. Our mixed-method evaluation combines quantitative
metrics with qualitative analysis, providing the first systematic assessment of
LRMs' pedagogical strengths and limitations.

</details>


### [26] [Chemical classification program synthesis using generative artificial intelligence](https://arxiv.org/abs/2505.18470)
*Christopher J. Mungall,Adnan Malik,Daniel R. Korn,Justin T. Reese,Noel M. O'Boyle,Noel,Janna Hastings*

Main category: cs.AI

TL;DR: 研究提出使用生成性人工智能自动生成化学分类程序，实现对化学结构的高效分类并提供解释，使其成为一种可解释的化学分类本体模型，同时展示了其广泛的验证效果和应用潜力。


<details>
  <summary>Details</summary>
Motivation: 准确分类化学结构对于化学信息学和生物信息学至关重要，以应对如识别生物活性化合物、筛选具有毒性的分子、寻找具有理想材料特性的非有机化合物等任务。然而，手动分类需要大量劳动投入，且难以扩展至大型化学数据库。现有自动化分类方法依赖手工构建的分类规则或缺乏可解释性的深度学习方法。

Method: 研究采用生成性人工智能来自动编写化学分类程序。所生成的程序能够对SMILES结构进行确定性分类，并提供自然语言的解释。此外，他们验证了该方法对ChEBI数据库的有效性，并与当前最先进的深度学习模型进行了比较。

Result: 我们展示了C3PO在从代谢组学数据库和天然产物数据库中提取的分布外样本上的分类效果。此外，还表明我们的方法可以发现现有化学数据库中的系统错误，并结合生成的本体、自动文献检索和多模态视觉模型来识别需要专家验证的潜在错误。

Conclusion: 这项研究提出了一种使用生成性人工智能的方法，该方法可以自动为生物化学实体数据库中的化学类别编写分类程序。这些程序能够实现对SMILES结构高效的确定性运行时分类，并提供自然语言解释。

Abstract: Accurately classifying chemical structures is essential for cheminformatics
and bioinformatics, including tasks such as identifying bioactive compounds of
interest, screening molecules for toxicity to humans, finding non-organic
compounds with desirable material properties, or organizing large chemical
libraries for drug discovery or environmental monitoring. However, manual
classification is labor-intensive and difficult to scale to large chemical
databases. Existing automated approaches either rely on manually constructed
classification rules, or the use of deep learning methods that lack
explainability.
  This work presents an approach that uses generative artificial intelligence
to automatically write chemical classifier programs for classes in the Chemical
Entities of Biological Interest (ChEBI) database. These programs can be used
for efficient deterministic run-time classification of SMILES structures, with
natural language explanations. The programs themselves constitute an
explainable computable ontological model of chemical class nomenclature, which
we call the ChEBI Chemical Class Program Ontology (C3PO).
  We validated our approach against the ChEBI database, and compared our
results against state of the art deep learning models. We also demonstrate the
use of C3PO to classify out-of-distribution examples taken from metabolomics
repositories and natural product databases. We also demonstrate the potential
use of our approach to find systematic classification errors in existing
chemical databases, and show how an ensemble artificial intelligence approach
combining generated ontologies, automated literature search, and multimodal
vision models can be used to pinpoint potential errors requiring expert
validation

</details>


### [27] [Retrieval Augmented Decision-Making: A Requirements-Driven, Multi-Criteria Framework for Structured Decision Support](https://arxiv.org/abs/2505.18483)
*Hongjia Wu,Hongxin Zhang,Wei Chen,Jiazhi Xia*

Main category: cs.AI

TL;DR: 本文提出了RAD方法，将多准则决策与LLM结合，生成详细且结构良好的决策报告，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的检索增强生成方法在提供上下文相关建议时，缺乏定量权重和可追溯的推理路径，难以提供多层次和透明的决策支持。

Method: RAD方法将多准则决策与LLM的语义理解能力结合，用于自动提取行业文件的关键标准，建立加权层次决策模型，在模型指导下生成结构化报告，并在决策生成中引入显式权重分配和推理链。

Result: 实验表明，RAD在各种决策任务中生成的决策报告在细节、合理性和结构上明显优于现有方法。

Conclusion: RAD方法显著提高了在复杂决策场景中的应用价值和潜力。

Abstract: Various industries have produced a large number of documents such as
industrial plans, technical guidelines, and regulations that are structurally
complex and content-wise fragmented. This poses significant challenges for
experts and decision-makers in terms of retrieval and understanding. Although
existing LLM-based Retrieval-Augmented Generation methods can provide
context-related suggestions, they lack quantitative weighting and traceable
reasoning paths, making it difficult to offer multi-level and transparent
decision support. To address this issue, this paper proposes the RAD method,
which integrates Multi-Criteria Decision Making with the semantic understanding
capabilities of LLMs. The method automatically extracts key criteria from
industry documents, builds a weighted hierarchical decision model, and
generates structured reports under model guidance. The RAD framework introduces
explicit weight assignment and reasoning chains in decision generation to
ensure accuracy, completeness, and traceability. Experiments show that in
various decision-making tasks, the decision reports generated by RAD
significantly outperform existing methods in terms of detail, rationality, and
structure, demonstrating its application value and potential in complex
decision support scenarios.

</details>


### [28] [Enumerate-Conjecture-Prove: Formally Solving Answer-Construction Problems in Math Competitions](https://arxiv.org/abs/2505.18492)
*Jialiang Sun,Yuzhi Tang,Ao Li,Chris J. Maddison,Kuldeep S. Meel*

Main category: cs.AI

TL;DR: 本文提出ECP框架，结合LLM与符号证明，提高构建问题准确性，从14.54%提升到45.06%，并生成了25.01%精度的正确证明。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在创意生成与符号证明之间的差距，提高数学竞赛中复杂问题的解决能力。

Method: 引入Enumerate-Conjecture-Prove (ECP)框架，通过LLM进行枚举和模式驱动的猜想，结合正式定理证明。

Result: 在ConstructiveBench数据集上，ECP将回答构建的准确性从CoT基线的14.54%提升到45.06%。结合ECP生成的答案，DeepSeek-Prover-V2-7B模型在Lean中生成了858个构造问题的正确证明，精度达到25.01%。

Conclusion: 本文提出了ECP框架，一种集成LLM和符号推理的模块化神经符号方法，有效提高了数学竞赛中问题的解决精度。

Abstract: Mathematical reasoning lies at the heart of artificial intelligence,
underpinning applications in education, program verification, and
research-level mathematical discovery. Mathematical competitions, in
particular, present two challenging problem types: theorem-proving, requiring
rigorous proofs of stated conclusions, and answer-construction, involving
hypothesizing and formally verifying mathematical objects. Large Language
Models (LLMs) effectively generate creative candidate answers but struggle with
formal verification, while symbolic provers ensure rigor but cannot efficiently
handle creative conjecture generation. We introduce the
Enumerate-Conjecture-Prove (ECP) framework, a modular neuro-symbolic method
integrating LLM-based enumeration and pattern-driven conjecturing with formal
theorem proving. We present ConstructiveBench, a dataset of 3,431
answer-construction problems in various math competitions with verified Lean
formalizations. On the ConstructiveBench dataset, ECP improves the accuracy of
answer construction from the Chain-of-Thought (CoT) baseline of 14.54% to
45.06% with the gpt-4.1-mini model. Moreover, combining with ECP's constructed
answers, the state-of-the-art DeepSeek-Prover-V2-7B model generates correct
proofs for 858 of the 3,431 constructive problems in Lean, achieving 25.01%
accuracy, compared to 9.86% for symbolic-only baselines. Our code and dataset
are publicly available at GitHub and HuggingFace, respectively.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [29] [Implementing Agents in JavaScript](https://arxiv.org/abs/2505.18228)
*Timotheus Kampik*

Main category: cs.MA

TL;DR: 介绍了JavaScript中的面向代理编程及其在多个技术领域中的应用。


<details>
  <summary>Details</summary>
Motivation: 引入面向代理编程，通过JavaScript实现推理循环代理的抽象。

Method: 进行基于实例的讲解，使用JS-son库来实现更高级的代理和多代理系统，并结合生成式AI技术。

Result: 展示了如何在多个技术生态系统中应用面向代理编程，并指出了未来研究的方向。

Conclusion: JavaScript的面向代理编程对于系统设计和AI整合具有重要意义。

Abstract: This chapter gives an introduction to agent-oriented programming in
JavaScript. It provides an example-based walk-through of how to implement
abstractions for reasoning loop agents in vanilla JavaScript. The initial
example is used as a stepping stone for explaining how to implement slightly
more advanced agents and multi-agent systems using JS-son, a JavaScript library
for agent-oriented programming. In this context, the chapter also explains how
to integrate reasoning loop agents with generative AI
technologies--specifically, large language models. Finally, application
scenarios in several technology ecosystems and future research directions are
sketched.

</details>


### [30] [Implementing Agents in JavaScript](https://arxiv.org/abs/2505.18228)
*Timotheus Kampik*

Main category: cs.MA

TL;DR: 本章介绍如何在JavaScript中实现和应用推理循环代理，并结合生成性AI技术，探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了帮助开发者理解如何在JavaScript中实现面向代理的编程，尤其是结合生成性AI技术如大型语言模型的应用。

Method: 通过实例讲解如何在JavaScript中实现推理循环代理的抽象，并进一步使用JS-son库扩展到更复杂的代理系统。

Result: 展示了在多个技术生态系统中应用推理循环代理的场景，并提出了未来的研究方向。

Conclusion: 这一章介绍了使用JavaScript进行面向代理的编程，并展示了如何利用JS-son库构建更高级的代理及多代理系统。

Abstract: This chapter gives an introduction to agent-oriented programming in
JavaScript. It provides an example-based walk-through of how to implement
abstractions for reasoning loop agents in vanilla JavaScript. The initial
example is used as a stepping stone for explaining how to implement slightly
more advanced agents and multi-agent systems using JS-son, a JavaScript library
for agent-oriented programming. In this context, the chapter also explains how
to integrate reasoning loop agents with generative AI
technologies--specifically, large language models. Finally, application
scenarios in several technology ecosystems and future research directions are
sketched.

</details>


### [31] [Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control](https://arxiv.org/abs/2505.18279)
*Alireza Rezazadeh,Zichao Li,Ange Lou,Yuying Zhao,Wei Wei,Yujia Bao*

Main category: cs.MA

TL;DR: 本文提出了协作记忆框架，解决多用户、多代理环境中的知识共享问题，通过不对称权限实现安全和高效的跨用户知识转移。


<details>
  <summary>Details</summary>
Motivation: 复杂任务越来越多地被委托给基于LLM的专业代理组合，这些代理进行推理、沟通和协调行动。然而，大多数方法假定单一用户上下文，忽略了在动态、不对称权限下实现知识转移的益处和挑战。

Method: 引入了协作记忆，一个用于多用户、多代理环境的框架，其中不对称、不断变化的访问控制被编码为连接用户、代理和资源的二分图。该系统维护两个内存层：私人内存和共享内存，每个片段都有不可变的来源属性，以支持事后许可检查。

Result: 我们的系统通过细粒度的读写策略实现当前用户-代理-资源约束，并将现有内存片段投射到过滤的变换视图中。写策略确定片段的保留和共享，通过上下文感知的变换更新内存。

Conclusion: 我们的框架能够安全、高效和可解释地实现跨用户知识共享，同时证明遵循不对称和随时间变化的策略，并实现内存操作的完全可审计性。

Abstract: Complex tasks are increasingly delegated to ensembles of specialized
LLM-based agents that reason, communicate, and coordinate actions-both among
themselves and through interactions with external tools, APIs, and databases.
While persistent memory has been shown to enhance single-agent performance,
most approaches assume a monolithic, single-user context-overlooking the
benefits and challenges of knowledge transfer across users under dynamic,
asymmetric permissions. We introduce Collaborative Memory, a framework for
multi-user, multi-agent environments with asymmetric, time-evolving access
controls encoded as bipartite graphs linking users, agents, and resources. Our
system maintains two memory tiers: (1) private memory-private fragments visible
only to their originating user; and (2) shared memory-selectively shared
fragments. Each fragment carries immutable provenance attributes (contributing
agents, accessed resources, and timestamps) to support retrospective permission
checks. Granular read policies enforce current user-agent-resource constraints
and project existing memory fragments into filtered transformed views. Write
policies determine fragment retention and sharing, applying context-aware
transformations to update the memory. Both policies may be designed conditioned
on system, agent, and user-level information. Our framework enables safe,
efficient, and interpretable cross-user knowledge sharing, with provable
adherence to asymmetric, time-varying policies and full auditability of memory
operations.

</details>


### [32] [Single-agent or Multi-agent Systems? Why Not Both?](https://arxiv.org/abs/2505.18286)
*Mingyan Gao,Yanzi Li,Banruo Liu,Yifan Yu,Phillip Wang,Ching-Yu Lin,Fan Lai*

Main category: cs.MA

TL;DR: 研究发现随着LLM能力提高，MAS的优势减小，并提出一种混合范式以提升智能体效率和性能。


<details>
  <summary>Details</summary>
Motivation: 探讨MAS与SAS在现代LLM能力进步的背景下的优劣，并提出改进方案以降低MAS的复杂性和成本，提高MAS的效率与性能。

Method: 进行了广泛的实证研究，比较MAS和SAS在各种流行的智能体应用中的表现，并提出精确定位MAS中容易出错的智能体的机制。

Result: 设计的混合智能体范式在多个应用中提高了准确性1.1-12%，同时降低了部署成本最多20%。

Conclusion: 随着大语言模型（LLM）能力的提升，多智能体系统（MAS）相较于单智能体系统（SAS）的优势减少。研究提出了一种混合智能体范式，通过MAS和SAS之间的请求级联来提升效率和能力，同时提高准确性并降低部署成本。

Abstract: Multi-agent systems (MAS) decompose complex tasks and delegate subtasks to
different large language model (LLM) agents and tools. Prior studies have
reported the superior accuracy performance of MAS across diverse domains,
enabled by long-horizon context tracking and error correction through
role-specific agents. However, the design and deployment of MAS incur higher
complexity and runtime cost compared to single-agent systems (SAS). Meanwhile,
frontier LLMs, such as OpenAI-o3 and Gemini-2.5-Pro, have rapidly advanced in
long-context reasoning, memory retention, and tool usage, mitigating many
limitations that originally motivated MAS designs. In this paper, we conduct an
extensive empirical study comparing MAS and SAS across various popular agentic
applications. We find that the benefits of MAS over SAS diminish as LLM
capabilities improve, and we propose efficient mechanisms to pinpoint the
error-prone agent in MAS. Furthermore, the performance discrepancy between MAS
and SAS motivates our design of a hybrid agentic paradigm, request cascading
between MAS and SAS, to improve both efficiency and capability. Our design
improves accuracy by 1.1-12% while reducing deployment costs by up to 20%
across various agentic applications.

</details>


### [33] [Persona Alchemy: Designing, Evaluating, and Implementing Psychologically-Grounded LLM Agents for Diverse Stakeholder Representation](https://arxiv.org/abs/2505.18351)
*Sola Kim,Dongjune Chang,Jieshu Wang*

Main category: cs.MA

TL;DR: 我们提出了一种社会认知理论(SCT)代理设计框架，以设计和实现心理上有依据且行为一致的LLM，实验显示在可重复性和不同利益相关者代表性方面取得了改善。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在与人类认知过程和代表不同利益相关者观点方面上存在的挑战。

Method: 实验通过实施SCT构建的全面流程来评估代理的表现，使用主成分分析来验证理论结构。

Result: 结果显示代理在矛盾信息情况下表现出一致的反应模式，主成分分析识别出解释73%方差的两个维度，验证了理论结构。

Conclusion: 我们的框架相比于黑箱方法提供了更好的可解释性和可重复性，推动了在保持心理一致性方面提高不同利益相关者代表性的努力。

Abstract: Despite advances in designing personas for Large Language Models (LLM),
challenges remain in aligning them with human cognitive processes and
representing diverse stakeholder perspectives. We introduce a Social Cognitive
Theory (SCT) agent design framework for designing, evaluating, and implementing
psychologically grounded LLMs with consistent behavior. Our framework
operationalizes SCT through four personal factors (cognitive, motivational,
biological, and affective) for designing, six quantifiable constructs for
evaluating, and a graph database-backed architecture for implementing
stakeholder personas. Experiments tested agents' responses to contradicting
information of varying reliability. In the highly polarized renewable energy
transition discourse, we design five diverse agents with distinct ideologies,
roles, and stakes to examine stakeholder representation. The evaluation of
these agents in contradictory scenarios occurs through comprehensive processes
that implement the SCT. Results show consistent response patterns ($R^2$ range:
$0.58-0.61$) and systematic temporal development of SCT construct effects.
Principal component analysis identifies two dimensions explaining $73$% of
variance, validating the theoretical structure. Our framework offers improved
explainability and reproducibility compared to black-box approaches. This work
contributes to ongoing efforts to improve diverse stakeholder representation
while maintaining psychological consistency in LLM personas.

</details>


### [34] [An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems](https://arxiv.org/abs/2505.18397)
*Fangqiao Tian,An Luo,Jin Du,Xun Xian,Robert Specht,Ganghua Wang,Xuan Bi,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Rui Zhang,Zirui Liu,Mingyi Hong,Jie Ding*

Main category: cs.MA

TL;DR: 本文探讨了多智能体系统的机会与挑战，并通过生物模拟和理论分析提出开发稳健、可扩展、安全系统的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨多智能体AI系统在分布式智能方面的机会和挑战，并借鉴最新技术成果以提升其能力。

Method: 采用生物学启发的模拟和全面的理论框架来分析多智能体系统。

Result: 通过系统化研究，识别出多智能体系统的发展路径和可能问题，提出了开发可靠与可扩展系统的策略。

Conclusion: 本文总结了多智能体系统的关键概念和面临的主要风险，强调了通过生物模拟和理论框架开发可扩展且安全的系统的重要性。

Abstract: Multi-agent AI systems (MAS) offer a promising framework for distributed
intelligence, enabling collaborative reasoning, planning, and decision-making
across autonomous agents. This paper provides a systematic outlook on the
current opportunities and challenges of MAS, drawing insights from recent
advances in large language models (LLMs), federated optimization, and human-AI
interaction. We formalize key concepts including agent topology, coordination
protocols, and shared objectives, and identify major risks such as dependency,
misalignment, and vulnerabilities arising from training data overlap. Through a
biologically inspired simulation and comprehensive theoretical framing, we
highlight critical pathways for developing robust, scalable, and secure MAS in
real-world settings.

</details>


### [35] [MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs](https://arxiv.org/abs/2505.18530)
*Pengyu Wang,Shuchang Ye,Usman Naseem,Jinman Kim*

Main category: cs.MA

TL;DR: MRGAgents框架通过专门代理生成更平衡和全面的医疗报告，超过了当前最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: Med-LVLMs在生成医疗报告时存在一定的偏差，导致忽略重要的异常并缺乏全面的描述。

Method: 提出了一种新的多代理框架，通过微调专门针对不同疾病类别的代理来解决问题。

Result: 通过实验证明，MRGAgents能够更有效地平衡正常和异常发现，并提供临床相关区域的全面描述。

Conclusion: MRGAgents在多个任务上表现优于目前最先进的方法，提高了报告的全面性和诊断实用性。

Abstract: Medical Large Vision-Language Models (Med-LVLMs) have been widely adopted for
medical report generation. Despite Med-LVLMs producing state-of-the-art
performance, they exhibit a bias toward predicting all findings as normal,
leading to reports that overlook critical abnormalities. Furthermore, these
models often fail to provide comprehensive descriptions of radiologically
relevant regions necessary for accurate diagnosis. To address these challenges,
we proposeMedical Report Generation Agents (MRGAgents), a novel multi-agent
framework that fine-tunes specialized agents for different disease categories.
By curating subsets of the IU X-ray and MIMIC-CXR datasets to train
disease-specific agents, MRGAgents generates reports that more effectively
balance normal and abnormal findings while ensuring a comprehensive description
of clinically relevant regions. Our experiments demonstrate that MRGAgents
outperformed the state-of-the-art, improving both report comprehensiveness and
diagnostic utility.

</details>


### [36] [MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework](https://arxiv.org/abs/2505.18572)
*Yifan Zhu,Chao Zhang,Xin Shi,Xueqiao Zhang,Yi Yang,Yawei Luo*

Main category: cs.MA

TL;DR: 本文提出了MASTER框架以解决多代理系统（MAS）的安全问题，提供自动化构建过程和信息流交互机制，并设计了场景自适应攻击策略，通过实验验证了其有效性，同时提出了相应防御策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）驱动的多代理系统（MAS）在解决问题和任务规划方面展现出显著能力，其安全风险随着MAS攻击而增加，因此需要一个新的安全框架来应对MAS的安全挑战。

Method: MASTER框架提供了自动化构建不同MAS设置的过程和基于信息流的交互范式，并设计了一种场景自适应的扩展攻击策略，利用角色和拓扑信息动态分配针对性的、与领域相关的攻击任务进行协作代理执行。

Result: 实验表明，通过角色和拓扑信息进行的攻击对大多数模型具有显著破坏性。同时，提出的防御策略显著增强了多代理系统在不同场景中的恢复能力。

Conclusion: 本文提出了一种新的安全研究框架MASTER，专注于多代理系统（MAS）中的多样化角色配置和拓扑结构。实验表明，通过角色和拓扑信息发起的攻击对大多数模型具有显著破坏性，同时作者还提出了相应的防御策略，大大增强了MAS在不同场景中的恢复能力。

Abstract: Large Language Models (LLMs)-based Multi-Agent Systems (MAS) exhibit
remarkable problem-solving and task planning capabilities across diverse
domains due to their specialized agentic roles and collaborative interactions.
However, this also amplifies the severity of security risks under MAS attacks.
To address this, we introduce MASTER, a novel security research framework for
MAS, focusing on diverse Role configurations and Topological structures across
various scenarios. MASTER offers an automated construction process for
different MAS setups and an information-flow-based interaction paradigm. To
tackle MAS security challenges in varied scenarios, we design a
scenario-adaptive, extensible attack strategy utilizing role and topological
information, which dynamically allocates targeted, domain-specific attack tasks
for collaborative agent execution. Our experiments demonstrate that such an
attack, leveraging role and topological information, exhibits significant
destructive potential across most models. Additionally, we propose
corresponding defense strategies, substantially enhancing MAS resilience across
diverse scenarios. We anticipate that our framework and findings will provide
valuable insights for future research into MAS security challenges.

</details>


### [37] [Making Teams and Influencing Agents: Efficiently Coordinating Decision Trees for Interpretable Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2505.19316)
*Rex Chen,Stephanie Milani,Zhicheng Zhang,Norman Sadeh,Fei Fang*

Main category: cs.MA

TL;DR: HYDRAVIPER是一种新的决策树基于MARL算法，解决了性能与计算效率的权衡，在标准测试环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释多智能体强化学习在性能和计算效率之间存在权衡，亟需解决这一问题以提高其实际应用性。

Method: HYDRAVIPER是一种基于决策树的MARL算法，通过协调代理间的训练并自适应分配环境交互预算来优化计算效率。

Result: HYDRAVIPER在多智能体协作和交通信号控制的标准测试环境中表现优异，以更少的运行时间达到了与先进方法相当的性能，并维持了不同交互预算的性能帕累托前沿。

Conclusion: HYDRAVIPER为MARL提供了一种兼顾性能和计算效率的可解释代理解决方案。

Abstract: Poor interpretability hinders the practical applicability of multi-agent
reinforcement learning (MARL) policies. Deploying interpretable surrogates of
uninterpretable policies enhances the safety and verifiability of MARL for
real-world applications. However, if these surrogates are to interact directly
with the environment within human supervisory frameworks, they must be both
performant and computationally efficient. Prior work on interpretable MARL has
either sacrificed performance for computational efficiency or computational
efficiency for performance. To address this issue, we propose HYDRAVIPER, a
decision tree-based interpretable MARL algorithm. HYDRAVIPER coordinates
training between agents based on expected team performance, and adaptively
allocates budgets for environment interaction to improve computational
efficiency. Experiments on standard benchmark environments for multi-agent
coordination and traffic signal control show that HYDRAVIPER matches the
performance of state-of-the-art methods using a fraction of the runtime, and
that it maintains a Pareto frontier of performance for different interaction
budgets.

</details>


### [38] [Adaptive Episode Length Adjustment for Multi-agent Reinforcement Learning](https://arxiv.org/abs/2505.19637)
*Byunghyun Yoo,Younghwan Shin,Hyunwoo Kim,Euisok Chung,Jeongmin Yang*

Main category: cs.MA

TL;DR: 提出了一种自适应调整剧集长度的MARL方法，使用熵评估学习进步，显著提升了收敛速度和性能。


<details>
  <summary>Details</summary>
Motivation: 在标准强化学习中，较短的剧集长度可能限制长期交互的收集，但在正确管理时可以提供显著优势。尤其在单智能体强化学习中，较短剧集的好处已被证明，但在MARL中这种方法尚未被充分探索。

Method: 提出了一种新的MARL方法，即自适应剧集长度调整（Adaptive Episode Length Adjustment, AELA），基于熵评估学习进度来逐渐增加剧集长度。

Result: 使用StarCraft多智能体挑战（SMAC）和改进的捕食者-猎物环境验证了我们的方法，与现有方法相比在收敛速度和总体性能上均有显著提升。

Conclusion: 这种方法在MARL中首次根据学习进度自适应调整剧集长度，提升了收敛速度和整体性能。

Abstract: In standard reinforcement learning, an episode is defined as a sequence of
interactions between agents and the environment, which terminates upon reaching
a terminal state or a pre-defined episode length. Setting a shorter episode
length enables the generation of multiple episodes with the same number of data
samples, thereby facilitating an exploration of diverse states. While shorter
episodes may limit the collection of long-term interactions, they may offer
significant advantages when properly managed. For example, trajectory
truncation in single-agent reinforcement learning has shown how the benefits of
shorter episodes can be leveraged despite the trade-off of reduced long-term
interaction experiences. However, this approach remains underexplored in MARL.
This paper proposes a novel MARL approach, Adaptive Episode Length Adjustment
(AELA), where the episode length is initially limited and gradually increased
based on an entropy-based assessment of learning progress. By starting with
shorter episodes, agents can focus on learning effective strategies for initial
states and minimize time spent in dead-end states. The use of entropy as an
assessment metric prevents premature convergence to suboptimal policies and
ensures balanced training over varying episode lengths. We validate our
approach using the StarCraft Multi-agent Challenge (SMAC) and a modified
predator-prey environment, demonstrating significant improvements in both
convergence speed and overall performance compared to existing methods. To the
best of our knowledge, this is the first study to adaptively adjust episode
length in MARL based on learning progress.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [39] [Model-Distributed Inference for Large Language Models at the Edge](https://arxiv.org/abs/2505.18164)
*Davide Macario,Hulya Seferoglu,Erdem Koyuncu*

Main category: cs.LG

TL;DR: MDI-LLM通过模型分割在低功耗设备上部署LLM，使用循环流水线并行技术提高效率，随着设备增加提升吞吐量和降低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 设计一种新框架以促使大型语言模型能够在边缘的低功率设备上进行部署。

Method: 这项研究通过将大语言模型划分为多个部分，并将这些部分分配给网络中的不同设备/节点来实现。节点之间通过设备间链接交换中间激活向量，实现协同计算。为了提升效率，提出了一种“循环流水线并行”技术，减少每个设备的空闲时间，并在生成多个文本序列时实现并行推理。

Result: MDI-LLM通过结合多个边缘设备的计算资源，使得比单台设备容量大的LLM在低成本硬件上得以部署，并随着设备数量的增加而提高吞吐量，降低每个设备的内存消耗。

Conclusion: MDI-LLM能够利用多个边缘设备的计算资源，使得单台设备无法容纳的LLM得以在低成本硬件上进行推理。同时，随着参与设备数量的增加，MDI-LLM提升了令牌生成的吞吐量并减少了单个设备的内存消耗。

Abstract: We introduce Model-Distributed Inference for Large-Language Models (MDI-LLM),
a novel framework designed to facilitate the deployment of state-of-the-art
large-language models (LLMs) across low-power devices at the edge. This is
accomplished by dividing the model into multiple partitions, which are then
assigned to different devices/nodes within the network. These nodes exchange
intermediate activation vectors via device-to-device links, enabling
collaborative computation. To enhance the efficiency of this process, we
propose the "recurrent pipeline parallelism" technique, which reduces idle time
on each device and facilitates parallel inference during the generation of
multiple text sequences. By leveraging the combined computational resources of
multiple edge devices, MDI-LLM enables the deployment of LLMs that exceed the
memory capacity of individual devices, making it possible to perform inference
on low-cost hardware. Furthermore, as the number of participating devices
increases, MDI-LLM boosts token generation throughput and reduces memory
consumption per device.

</details>


### [40] [Model-Distributed Inference for Large Language Models at the Edge](https://arxiv.org/abs/2505.18164)
*Davide Macario,Hulya Seferoglu,Erdem Koyuncu*

Main category: cs.LG

TL;DR: MDI-LLM框架通过模型分区与协作计算，实现大型语言模型在低功耗设备上的高效推理。


<details>
  <summary>Details</summary>
Motivation: 设计一个框架使得最先进的大型语言模型能够在边缘低功耗设备上部署。

Method: 提出“递归流水线并行化”技术，减少设备空闲时间并实现并行推理。通过设备间交换激活向量，进行协同计算。

Result: MDI-LLM在增加参与设备数量时，提高了令牌生成吞吐量，减少了每个设备的内存消耗。

Conclusion: MDI-LLM提升了低功耗设备上的推理能力，通过设备间协作实现超越单一设备内存容量的语言模型推理。

Abstract: We introduce Model-Distributed Inference for Large-Language Models (MDI-LLM),
a novel framework designed to facilitate the deployment of state-of-the-art
large-language models (LLMs) across low-power devices at the edge. This is
accomplished by dividing the model into multiple partitions, which are then
assigned to different devices/nodes within the network. These nodes exchange
intermediate activation vectors via device-to-device links, enabling
collaborative computation. To enhance the efficiency of this process, we
propose the "recurrent pipeline parallelism" technique, which reduces idle time
on each device and facilitates parallel inference during the generation of
multiple text sequences. By leveraging the combined computational resources of
multiple edge devices, MDI-LLM enables the deployment of LLMs that exceed the
memory capacity of individual devices, making it possible to perform inference
on low-cost hardware. Furthermore, as the number of participating devices
increases, MDI-LLM boosts token generation throughput and reduces memory
consumption per device.

</details>


### [41] [Constrained Edge AI Deployment: Fine-Tuning vs Distillation for LLM Compression](https://arxiv.org/abs/2505.18166)
*Jacob Sander,David Moe,Achraf Cohen,Brent Venable,Venkat Dasari,Brian Jalaian*

Main category: cs.LG

TL;DR: The paper studies the effect of L2-norm pruning and re-training loss functions (Cross-Entropy vs. KL-divergence) on Transformer models, showing that KL-based self-distillation can match or exceed the accuracy of models fine-tuned with Cross-Entropy, even with simple MLP pruning.


<details>
  <summary>Details</summary>
Motivation: The motivation is to examine the impact of different re-training loss functions on model performance after pruning, particularly focusing on resource-constrained environments like edge networks. The study aims to isolate the effects of the re-training loss function rather than achieving maximal compression.

Method: The method involves simple, layer-wise L2-norm pruning applied solely to the MLP blocks of the Transformer model, followed by two re-training approaches: Fine-tuning with Cross-Entropy (L2PFT) and Self-Distillation with KL-divergence (L2PSD). Both methods are evaluated under identical pruning schedules on the OLMo2-7B-SFT model for CommonsenseQA.

Result: In the conducted experiments, self-distillation with KL-divergence either matched or outperformed fine-tuning with Cross-Entropy in terms of test accuracy, highlighting the importance of the choice of loss function in recovering model performance post-pruning.

Conclusion: KL-based self-distillation, which uses only teacher logits and does not require labeled data, matches or exceeds the test accuracy of Cross-Entropy fine-tuning. This demonstrates that the choice of loss function can significantly affect the recovery of compressed models in resource-constrained environments, even with simple MLP-only pruning.

Abstract: Modern foundational models are often compressed via a combination of
structured pruning and re-training to meet the strict compute, memory, and
connectivity constraints of edge deployments. While state-of-the-art pruning
schemes target the entire Transformer, we adopt a simple, layer-wise L2-norm
pruning on only the MLP blocks as a fixed baseline. Our focus is not on
achieving maximal compression, but on isolating the impact of the re-training
loss function: (i) Fine-tuning with Cross- Entropy (L2PFT), which requires
labeled data, versus (ii) Self-Distillation with KL-divergence, which leverages
only teacher logits (no labels) (L2PSD). We evaluate both pipelines on the
OLMo2- 7B-SFT model for CommonsenseQA suitable for intermittent or denied
connectivity scenarios typical of edge networks. Under identical pruning
schedules, KL-based distillation matches or exceeds CE fine-tuning in test
accuracy, demonstrating that, even with a basic MLP-only pruning, the choice of
loss function materially affects compressed model recovery in
resource-constrained environments.

</details>


### [42] [Emotion Knowledge Enhancement for Vision Large Language Models: A Self-Verification Approach for High-Quality Emotion Instruction Data Generation](https://arxiv.org/abs/2505.18168)
*Feifan Wang,Tengfei Song,Minggui He,Chang Su,Zhanglin Wu,Hao Yang,Wenming Zheng,Osamu Yoshie*

Main category: cs.LG

TL;DR: 面部情感感知在视觉大语言模型(VLLM)中至关重要，但缺乏高质量注释限制了性能。我们提出SEKE方法，利用自验证策略生成高质量指令数据，提高了模型的情感分析能力。


<details>
  <summary>Details</summary>
Motivation: 高质量的面部情感分析注释需要昂贵的专业知识。缺乏高质量指令数据限制了VLLM在面部情感感知方面的性能。为了解决这个问题，我们提出利用封闭源VLLM生成高质量指令数据，并提高模型的分析能力。

Method: 我们提出了一种自验证情感知识增强(SEKE)的方法，通过使用封闭源VLLM生成高质量指令数据。该方法结合了三个情感描述层级之间的固有关联性，采用不确定性感知蒙特卡洛采样的自验证策略，以提高VLLM预测的准确性。

Result: 我们构建了一个面部情感指令数据集(FEID)，并引入了一个面部情感分析基准(FEAB)，用于测量VLLM的对应能力。

Conclusion: 我们的方法在三种下游面部情感分析任务上显著超越了最先进的方法。

Abstract: Facial emotion perception in the vision large language model (VLLM) is
crucial for achieving natural human-machine interaction. However, creating
high-quality annotations for both coarse- and fine-grained facial emotion
analysis demands costly expertise. The lack of such high-quality instruction
data limits the performance of VLLMs in facial emotion perception. To address
this, we propose a self-verification approach with emotion knowledge
enhancement (SEKE), which generates high-quality instruction data for
multi-grained emotion analysis cost-effectively using closed-source VLLM. This
approach integrates prior human knowledge to VLLM inference, guided by the
inherent correlations between three grained levels of emotion descriptions,
i.e., discrete expression, valence-arousal, and action unit, to reliably
generate comprehensive annotations. A self-verification strategy with
Uncertainty-Aware Monte Carlo sampling (SV-UAMC) is further embedded to
efficiently extract more accurate VLLM predictions, further improving
annotation reliability. Consequently, we construct a facial emotion instruction
dataset (FEID) containing three comprehensive descriptions, which provides
coarse- and fine-grained emotional information for effective model training.
Additionally, we introduce a facial emotion analysis benchmark (FEAB) to
measure the VLLM's corresponding ability. Our method significantly outperforms
state-of-the-art methods on three downstream facial emotion analysis tasks.

</details>


### [43] [Interpretable Multi-Task PINN for Emotion Recognition and EDA Prediction](https://arxiv.org/abs/2505.18169)
*Nischal Mandal*

Main category: cs.LG

TL;DR: 该研究开发了一种多任务PINN，用于可穿戴情感识别，结合心理特征与物理方程，提升了情感预测精度和模型透明性，结果优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 利用可穿戴传感器理解和预测人体情感及生理状态对压力监测、心理健康评估及情感计算具有重要意义。通过更好的模型来提高情感和生理状态预测的精度和透明性。

Method: 采用多任务物理信息神经网络（PINN），结合心理自我报告特征与物理灵感微分方程，通过自定义损失函数实现EDA动态的生物物理约束，并在统一多任务框架下训练模型。

Result: 模型在5折交叉验证中平均取得了0.0362的EDA均方根误差（RMSE）、0.9919的Pearson相关系数以及94.08%的F1得分，表现优于传统模型如SVR和XGBoost及单任务变体。

Conclusion: 研究提出了一种新的多任务物理信息神经网络（PINN）架构，用于同时进行EDA预测和情感分类，并证明了其在预测精度和模型透明性方面的优势。

Abstract: Understanding and predicting human emotional and physiological states using
wearable sensors has important applications in stress monitoring, mental health
assessment, and affective computing. This study presents a novel Multi-Task
Physics-Informed Neural Network (PINN) that performs Electrodermal Activity
(EDA) prediction and emotion classification simultaneously, using the publicly
available WESAD dataset. The model integrates psychological self-report
features (PANAS and SAM) with a physics-inspired differential equation
representing EDA dynamics, enforcing biophysically grounded constraints through
a custom loss function. This loss combines EDA regression, emotion
classification, and a physics residual term for improved interpretability.
  The architecture supports dual outputs for both tasks and is trained under a
unified multi-task framework. Evaluated using 5-fold cross-validation, the
model achieves an average EDA RMSE of 0.0362, Pearson correlation of 0.9919,
and F1-score of 94.08 percent. These results outperform classical models such
as SVR and XGBoost, as well as ablated variants like emotion-only and EDA-only
models.
  In addition, the learned physical parameters including decay rate (alpha_0),
emotional sensitivity (beta), and time scaling (gamma) are interpretable and
stable across folds, aligning with known principles of human physiology. This
work is the first to introduce a multi-task PINN framework for wearable emotion
recognition, offering improved performance, generalizability, and model
transparency. The proposed system provides a foundation for future
interpretable and multimodal applications in healthcare and human-computer
interaction.

</details>


### [44] [Robust Knowledge Graph Embedding via Denoising](https://arxiv.org/abs/2505.18171)
*Tengwei Song,Xudong Ma,Yang Liu,Jie Luo*

Main category: cs.LG

TL;DR: 提出了一种抗噪声的知识图谱嵌入框架，通过去噪增强模型的鲁棒性，并提出认证鲁棒性评估指标，在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在嵌入空间中，围绕获得鲁棒的知识图谱嵌入来对抗扰动。

Method: 将知识图谱嵌入方法视为基于能量的模型，利用去噪与评分匹配之间的已建立联系，训练一个鲁棒的去噪KGE模型。此外，基于随机平滑概念提出了经过认证的鲁棒性评估指标。

Result: 我们的框架在基准数据集的实验中，在面对扰动实体嵌入的情况下，比现有最先进的KGE方法表现出更优异的性能。

Conclusion: 通过全面的实验验证，我们的框架在面对扰动实体嵌入时，表现出相较于现有最先进KGE方法的明显优势。

Abstract: We focus on obtaining robust knowledge graph embedding under perturbation in
the embedding space. To address these challenges, we introduce a novel
framework, Robust Knowledge Graph Embedding via Denoising, which enhances the
robustness of KGE models on noisy triples. By treating KGE methods as
energy-based models, we leverage the established connection between denoising
and score matching, enabling the training of a robust denoising KGE model.
Furthermore, we propose certified robustness evaluation metrics for KGE methods
based on the concept of randomized smoothing. Through comprehensive experiments
on benchmark datasets, our framework consistently shows superior performance
compared to existing state-of-the-art KGE methods when faced with perturbed
entity embedding.

</details>


### [45] [Should We Simultaneously Calibrate Multiple Computer Models?](https://arxiv.org/abs/2505.18176)
*Jonathan Tammer Eweis-Labolle,Tyler Johnson,Xiangyu Sun,Ramin Bostanabad*

Main category: cs.LG

TL;DR: 本文介绍一种新方法质疑传统模式，开发了一个基于神经网络的框架以同时校准多个计算机模型，从而提高预测精度，但在高维空间中可能出现不可辨识性问题。


<details>
  <summary>Details</summary>
Motivation: 在越来越多的应用中，设计者拥有多种计算机模型，这些模型通常具有不同的保真度和成本。传统上，设计者将这些模型与一些高保真数据（例如实验）逐个校准。本文质疑这种传统，并评估同时校准多个计算机模型的潜力。

Method: 我们开发了一个基于定制神经网络的概率框架，设计用于同时校准多个计算机模型。该方法包括：1）考虑大多数计算机模型是多响应的，并且校准参数的数量和性质可能在模型间变化；2）为每个计算机模型的每个校准参数学习一个独特的概率分布；3）开发一个损失函数，使我们的神经网络可以在校准计算机模型的同时模拟所有数据源；4）旨在学习一个可视化的潜在空间，其中可以识别模型形式误差。

Result: 我们在分析和工程问题上测试了我们方法的性能，以了解在同时校准多个计算机模型时的潜在优势和缺陷。

Conclusion: 我们的方法可以提高预测精度，但在通常受基础物理约束的高维输入空间中容易出现不可辨识性问题。

Abstract: In an increasing number of applications designers have access to multiple
computer models which typically have different levels of fidelity and cost.
Traditionally, designers calibrate these models one at a time against some
high-fidelity data (e.g., experiments). In this paper, we question this
tradition and assess the potential of calibrating multiple computer models at
the same time. To this end, we develop a probabilistic framework that is
founded on customized neural networks (NNs) that are designed to calibrate an
arbitrary number of computer models. In our approach, we (1) consider the fact
that most computer models are multi-response and that the number and nature of
calibration parameters may change across the models, and (2) learn a unique
probability distribution for each calibration parameter of each computer model,
(3) develop a loss function that enables our NN to emulate all data sources
while calibrating the computer models, and (4) aim to learn a visualizable
latent space where model-form errors can be identified. We test the performance
of our approach on analytic and engineering problems to understand the
potential advantages and pitfalls in simultaneous calibration of multiple
computer models. Our method can improve predictive accuracy, however, it is
prone to non-identifiability issues in higher-dimensional input spaces that are
normally constrained by underlying physics.

</details>


### [46] [FedGRec: Dynamic Spatio-Temporal Federated Graph Learning for Secure and Efficient Cross-Border Recommendations](https://arxiv.org/abs/2505.18177)
*Zhizhong Tan,Jiexin Zheng,Xingxing Yang,Chi Zhang,Weiping Deng,Wenyong Wang*

Main category: cs.LG

TL;DR: FedGRec是一种隐私保护的联邦图学习方法，通过协作信号优化用户偏好表示，适应异构域数据，在跨境推荐中提升性能并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 在跨境共享中，由于敏感数据受到严格的隐私保护，使得模型训练数据不足，如何在确保隐私安全的同时实现高效的跨境业务推荐成为重大挑战。现有的基于联邦学习的GNN训练方法在异质图数据上优化不足，因此提出FedGRec方法以改善此问题。

Method: FedGRec方法通过从用户或项目关联的本地子图中提取协作信号，丰富其表示学习。此外，它利用动态时空建模实时整合全局和本地用户偏好，从业务推荐状态中提取目标用户和候选项目的最终表示，并通过自动滤除相关行为减少不可靠邻居的噪音干扰。

Result: FedGRec在三个数据集上的大量实验显示，其在单域和跨域基准上均有卓越表现，同时有效保证了跨境推荐中的数据隐私。

Conclusion: FedGRec在跨境推荐中，一方面显著提升了推荐性能，另一方面有效地保护了数据隐私。它通过个性化的联邦聚合策略适应异构域数据，实现跨多个领域的用户偏好协同学习。

Abstract: Due to the highly sensitive nature of certain data in cross-border sharing,
collaborative cross-border recommendations and data sharing are often subject
to stringent privacy protection regulations, resulting in insufficient data for
model training. Consequently, achieving efficient cross-border business
recommendations while ensuring privacy security poses a significant challenge.
Although federated learning has demonstrated broad potential in collaborative
training without exposing raw data, most existing federated learning-based GNN
training methods still rely on federated averaging strategies, which perform
suboptimally on highly heterogeneous graph data. To address this issue, we
propose FedGRec, a privacy-preserving federated graph learning method for
cross-border recommendations. FedGRec captures user preferences from
distributed multi-domain data to enhance recommendation performance across all
domains without privacy leakage. Specifically, FedGRec leverages collaborative
signals from local subgraphs associated with users or items to enrich their
representation learning. Additionally, it employs dynamic spatiotemporal
modeling to integrate global and local user preferences in real time based on
business recommendation states, thereby deriving the final representations of
target users and candidate items. By automatically filtering relevant
behaviors, FedGRec effectively mitigates noise interference from unreliable
neighbors. Furthermore, through a personalized federated aggregation strategy,
FedGRec adapts global preferences to heterogeneous domain data, enabling
collaborative learning of user preferences across multiple domains. Extensive
experiments on three datasets demonstrate that FedGRec consistently outperforms
competitive single-domain and cross-domain baselines while effectively
preserving data privacy in cross-border recommendations.

</details>


### [47] [Less is More: Multimodal Region Representation via Pairwise Inter-view Learning](https://arxiv.org/abs/2505.18178)
*Min Namgung,Yijun Lin,JangHyeon Lee,Yao-Yi Chiang*

Main category: cs.LG

TL;DR: CooKIE方法改进了地区表示学习，通过信息因子化捕捉共享和独特信息，超越了现有方法并减少了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 现有的因子化方法主要关注两个模态，而RRL能够从多种地理空间数据中受益。扩展因子化到两个以上的模态是困难的，因为建模高阶关系会引入一个组合数量的学习目标，增加模型复杂性。

Method: 引入跨模态知识注入嵌入（CooKIE），利用一种成对视图学习方法来进行信息因子化，捕获共享和独特的表示。该方法无需模型高阶依赖，避免了穷尽组合。

Result: CooKIE通过成对视图学习方法有效捕获高阶信息，避免了高阶依赖，实验结果表明其在纽约市和印度德里的多个任务中性能优越，并且训练参数和计算资源需求更低。

Conclusion: CooKIE在纽约市和印度德里进行的三个回归任务和一个土地使用分类任务中表现优异，超过了现有的RRL方法和一个因子化RRL模型，并以更少的训练参数和浮点运算每秒（FLOPs）更好地捕获多模态信息。

Abstract: With the increasing availability of geospatial datasets, researchers have
explored region representation learning (RRL) to analyze complex region
characteristics. Recent RRL methods use contrastive learning (CL) to capture
shared information between two modalities but often overlook task-relevant
unique information specific to each modality. Such modality-specific details
can explain region characteristics that shared information alone cannot
capture. Bringing information factorization to RRL can address this by
factorizing multimodal data into shared and unique information. However,
existing factorization approaches focus on two modalities, whereas RRL can
benefit from various geospatial data. Extending factorization beyond two
modalities is non-trivial because modeling high-order relationships introduces
a combinatorial number of learning objectives, increasing model complexity. We
introduce Cross modal Knowledge Injected Embedding, an information
factorization approach for RRL that captures both shared and unique
representations. CooKIE uses a pairwise inter-view learning approach that
captures high-order information without modeling high-order dependency,
avoiding exhaustive combinations. We evaluate CooKIE on three regression tasks
and a land use classification task in New York City and Delhi, India. Results
show that CooKIE outperforms existing RRL methods and a factorized RRL model,
capturing multimodal information with fewer training parameters and
floating-point operations per second (FLOPs). We release the code:
https://github.com/MinNamgung/CooKIE.

</details>


### [48] [GAIA: A Foundation Model for Operational Atmospheric Dynamics](https://arxiv.org/abs/2505.18179)
*Ata Akbari Asanjan,Olivia Alexander,Tom Berg,Clara Zhang,Matt Yang,Jad Makki,Disha Shidham,Srija Chakraborty,William Bender,Stephen Peng,Arun Ravindran,Olivier Raiman,David Potere,David Bell*

Main category: cs.LG

TL;DR: GAIA模型结合MAE和DINO，成功解决重建丢失区域和降水估算的挑战，表现出色并公开了模型权重和代码。


<details>
  <summary>Details</summary>
Motivation: 解决卫星数据分析中的两个关键挑战：重建丢失区域和估算降水模式。

Method: GAIA模型结合了掩码自动编码器（MAE）和无标签的自蒸馏（DINO）用于分析卫星图像中的全球大气模式。

Result: 模型在填补不同掩码比率上的空白能力表现强劲，在有限训练数据下实现精准降水估算，达到了0.088的错误报警比和0.881的结构相似性。

Conclusion: 这项工作代表了自监督学习在大气科学中的进步，为改进天气监测和气候分析提供了基础。训练模型的权重和附带代码作为开源项目在Hugging Face上公开。

Abstract: We present the GAIA (Geospatial Artificial Intelligence for Atmospheres)
Foundation Model, a novel model that combines masked autoencoders (MAE) and
self-DIstillation with NO labels (DINO) for analyzing global atmospheric
patterns in satellite imagery. By integrating these complementary
self-supervised learning approaches, our model simultaneously captures both
local features and global dependencies. We address two critical challenges in
satellite data analysis: reconstructing missing regions and estimating
precipitation patterns as our first downstream tasks. The model demonstrates
superior temporal pattern capture compared to standard MAE approaches, while
maintaining robust performance in downstream tasks. Our experimental results
show strong gap-filling capabilities across varying mask ratios and accurate
precipitation estimation with limited training data, achieving a false alarm
ratio of 0.088 and structural similarity of 0.881. This work represents an
advancement in self-supervised learning for atmospheric science, providing a
foundation for improved weather monitoring and climate analysis. The trained
model weights and accompanying code are publicly available as open-source on
Hugging Face here: https://huggingface.co/bcg-usra-nasa-gaia/GAIA-v1.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [49] [The influence of data gaps and outliers on resilience indicators](https://arxiv.org/abs/2505.19034)
*Teng Liu,Andreas Morr,Sebastian Bathiany,Lana L. Blaschke,Zhen Qian,Chan Diao,Taylor Smith,Niklas Boers*

Main category: nlin.AO

TL;DR: 文章探讨了关键韧性指标的数学依赖性，并通过实证研究揭示了缺失数据和异常值对指标准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 地球系统组件的稳定性受到人类活动压力的威胁，需要可靠的早期预警信号来预测突然且不可逆的体制变化。

Method: 通过分析合成及实证数据，我们研究了缺失值及异常值对韧性指标一致性的影响。

Result: 研究成果为制定数据预处理策略和精确度评估提供了必要的理论基础，有助于多个学科领域使用真实世界的数据推断系统韧性的变化。

Conclusion: 我们通过数学分析揭示了方差和自相关性指标之间的统计依赖性，强调它们的一致性主要受时间序列的初始数据点驱动。缺失数据和异常值对指标的一致性有显著影响，异常值会导致通过时间自相关性的韧性过高估计。

Abstract: The resilience, or stability, of major Earth system components is
increasingly threatened by anthropogenic pressures, demanding reliable early
warning signals for abrupt and irreversible regime shifts. Widely used
data-driven resilience indicators based on variance and autocorrelation detect
`critical slowing down', a signature of decreasing stability. However, the
interpretation of these indicators is hampered by poorly understood
interdependencies and their susceptibility to common data issues such as
missing values and outliers. Here, we establish a rigorous mathematical
analysis of the statistical dependency between variance- and
autocorrelation-based resilience indicators, revealing that their agreement is
fundamentally driven by the time series' initial data point. Using synthetic
and empirical data, we demonstrate that missing values substantially weaken
indicator agreement, while outliers introduce systematic biases that lead to
overestimation of resilience based on temporal autocorrelation. Our results
provide a necessary and rigorous foundation for preprocessing strategies and
accuracy assessments across the growing number of disciplines that use
real-world data to infer changes in system resilience.

</details>


### [50] [The influence of data gaps and outliers on resilience indicators](https://arxiv.org/abs/2505.19034)
*Teng Liu,Andreas Morr,Sebastian Bathiany,Lana L. Blaschke,Zhen Qian,Chan Diao,Taylor Smith,Niklas Boers*

Main category: nlin.AO

TL;DR: 研究揭示了基于方差和自相关的弹性指标之间的一致性受到时间序列初始数据的显著影响，并分析了缺失值和异常值对这些指标的影响。


<details>
  <summary>Details</summary>
Motivation: 随着人类活动的压力日益增加，地球系统的主要组成部分的稳定性受到威胁，迫切需要可靠的预警信号来应对突然和不可逆转的变化。当前的指标由于数据问题而难以解释，因此需要进行更严谨的分析。

Method: 进行严格的数学分析来研究方差和自相关弹性指标之间的统计依赖性，并使用合成数据和经验数据进行测试。

Result: 研究发现，缺失值显著削弱了指标的一致性，而异常值会引入系统偏差，导致基于时间自相关的弹性高估。

Conclusion: 通过数学分析，研究揭示了基于方差和自相关的弹性指标的统计依赖性，并指出这些指标之间的一致性受到时间序列初始数据点的驱动。该研究为各种学科使用实际数据推断系统弹性变化提供了必要的预处理策略和准确性评估依据。

Abstract: The resilience, or stability, of major Earth system components is
increasingly threatened by anthropogenic pressures, demanding reliable early
warning signals for abrupt and irreversible regime shifts. Widely used
data-driven resilience indicators based on variance and autocorrelation detect
`critical slowing down', a signature of decreasing stability. However, the
interpretation of these indicators is hampered by poorly understood
interdependencies and their susceptibility to common data issues such as
missing values and outliers. Here, we establish a rigorous mathematical
analysis of the statistical dependency between variance- and
autocorrelation-based resilience indicators, revealing that their agreement is
fundamentally driven by the time series' initial data point. Using synthetic
and empirical data, we demonstrate that missing values substantially weaken
indicator agreement, while outliers introduce systematic biases that lead to
overestimation of resilience based on temporal autocorrelation. Our results
provide a necessary and rigorous foundation for preprocessing strategies and
accuracy assessments across the growing number of disciplines that use
real-world data to infer changes in system resilience.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [51] [Co-evolutionary Dynamics of Attack and Defence in Cybersecurity](https://arxiv.org/abs/2505.19338)
*Adeela Bashir,Zia Ush Shamszaman,Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 利用演化博弈理论分析网络攻击与防御动态，提出了提升网络安全的适应性策略，通过实际数据验证了理论效果。


<details>
  <summary>Details</summary>
Motivation: 在数字环境不断变化中，研究网络攻击与防御的动态至关重要，以应对网络威胁并增强网络安全。

Method: 使用演化博弈理论（EGT）框架，开发了攻击者和防御者之间的双人不对称博弈，通过数学分析和数值模拟研究系统稳定性与攻击频率关系。

Result: 在高防御强度的系统中，攻击频率极低且系统稳定；在低防御环境中，系统不稳定且易受攻击。发现五个平衡点，其中总是防御与攻击的策略组合是最可能稳定的状态。

Conclusion: 应用演化博弈理论可以有效提升资源分配、增强系统韧性，并降低网络攻击风险。通过实际数据证明演化博弈理论在处理网络威胁变化性和确保数字生态系统安全方面的一致性。

Abstract: In the evolving digital landscape, it is crucial to study the dynamics of
cyberattacks and defences. This study uses an Evolutionary Game Theory (EGT)
framework to investigate the evolutionary dynamics of attacks and defences in
cyberspace. We develop a two-population asymmetric game between attacker and
defender to capture the essential factors of costs, potential benefits, and the
probability of successful defences. Through mathematical analysis and numerical
simulations, we find that systems with high defence intensities show stability
with minimal attack frequencies, whereas low-defence environments show
instability, and are vulnerable to attacks. Furthermore, we find five
equilibria, where the strategy pair always defend and attack emerged as the
most likely stable state as cyber domain is characterised by a continuous
battle between defenders and attackers. Our theoretical findings align with
real-world data from past cyber incidents, demonstrating the interdisciplinary
impact, such as fraud detection, risk management and cybersecurity
decision-making. Overall, our analysis suggests that adaptive cybersecurity
strategies based on EGT can improve resource allocation, enhance system
resilience, and reduce the overall risk of cyberattacks. By incorporating
real-world data, this study demonstrates the applicability of EGT in addressing
the evolving nature of cyber threats and the need for secure digital ecosystems
through strategic planning and proactive defence measures.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [52] [Agentic Information Theory: Ergodicity and Intrinsic Semantics of Information Processes](https://arxiv.org/abs/2505.19275)
*James P. Crutchfield,Alexandra Jurgens*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了记忆代理在复杂环境中的信息过程，并提供了关于香农信息时间序列的基本结果，用以监测代理对环境认知的不确定性和结构关联性。


<details>
  <summary>Details</summary>
Motivation: 揭示认知代理在复杂且结构化的随机环境中通过时间行为进行信息解析的机制。

Method: 本文引入了一种信息过程，即认知代理在与环境互动和解释刺激时实时产生的随机过程。

Result: 提供了关于香农信息测度的时间序列的基本结果，这些结果监测代理对其环境不确定性和结构关联的适应性看法。

Conclusion: 本文通过研究认知代理在复杂环境中的临时行为，发展了信息理论。

Abstract: We develop information theory for the temporal behavior of memoryful agents
moving through complex -- structured, stochastic -- environments. We introduce
information processes -- stochastic processes produced by cognitive agents in
real-time as they interact with and interpret incoming stimuli. We provide
basic results on the ergodicity and semantics of the resulting time series of
Shannon information measures that monitor an agent's adapting view of
uncertainty and structural correlation in its environment.

</details>
