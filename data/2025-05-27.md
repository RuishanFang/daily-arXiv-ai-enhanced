<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Advancing Uto-Aztecan Language Technologies: A Case Study on the Endangered Comanche Language](https://arxiv.org/abs/2505.18159)
*Jesus Alvarez C,Daua D. Karajeanes,Ashley Celeste Prado,John Ruttan,Ivory Yang,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 研究展示了利用NLP和社区参与来保护濒危语言科曼奇，通过少量实例提示提高了语言识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决濒危语言在数字领域的排斥问题，以促进语言学研究和语言复兴工作。

Method: 提供了一个手动整理的412个短语数据集、合成数据生成流水线，并对GPT-4o和GPT-4o-mini进行语言识别的实证评估。

Result: 在零样本环境下，模型对科曼奇语的表现较差，但通过少量样本提示（仅五个例子），准确率显著提高，达到了接近完美的效果。

Conclusion: 研究通过少量实例提示显著提高了大型语言模型对科曼奇语的识别能力，证明了NLP在低资源语言环境中的潜力。

Abstract: The digital exclusion of endangered languages remains a critical challenge in
NLP, limiting both linguistic research and revitalization efforts. This study
introduces the first computational investigation of Comanche, an Uto-Aztecan
language on the verge of extinction, demonstrating how minimal-cost,
community-informed NLP interventions can support language preservation. We
present a manually curated dataset of 412 phrases, a synthetic data generation
pipeline, and an empirical evaluation of GPT-4o and GPT-4o-mini for language
identification. Our experiments reveal that while LLMs struggle with Comanche
in zero-shot settings, few-shot prompting significantly improves performance,
achieving near-perfect accuracy with just five examples. Our findings highlight
the potential of targeted NLP methodologies in low-resource contexts and
emphasize that visibility is the first step toward inclusion. By establishing a
foundation for Comanche in NLP, we advocate for computational approaches that
prioritize accessibility, cultural sensitivity, and community engagement.

</details>


### [2] [Do BERT-Like Bidirectional Models Still Perform Better on Text Classification in the Era of LLMs?](https://arxiv.org/abs/2505.18215)
*Junyan Zhang,Yiming Huang,Shuliang Liu,Yubo Gao,Xuming Hu*

Main category: cs.CL

TL;DR: 研究通过比较不同方法，发现BERT类模型在一些高难度数据集上优于LLMs，并提出细粒度的任务选择策略。


<details>
  <summary>Details</summary>
Motivation: 质疑当前流行的'以LLM为中心'的趋势，展示传统BERT类模型在文本分类中潜在的优势。

Method: 通过在六个高难度数据集上对比三种分类方法，包括微调BERT模型、LLM内部状态利用和零样本推理。

Result: 研究表明，BERT类模型在模式驱动任务上表现出色，而LLMs则在需要深度语义或世界知识的任务中占优。提出了一种名为TaMAS的细粒度任务选择策略。

Conclusion: 传统的BERT模型在某些任务上优于LLMs，尤其是在模式驱动任务中。

Abstract: The rapid adoption of LLMs has overshadowed the potential advantages of
traditional BERT-like models in text classification. This study challenges the
prevailing "LLM-centric" trend by systematically comparing three category
methods, i.e., BERT-like models fine-tuning, LLM internal state utilization,
and zero-shot inference across six high-difficulty datasets. Our findings
reveal that BERT-like models often outperform LLMs. We further categorize
datasets into three types, perform PCA and probing experiments, and identify
task-specific model strengths: BERT-like models excel in pattern-driven tasks,
while LLMs dominate those requiring deep semantics or world knowledge. Based on
this, we propose TaMAS, a fine-grained task selection strategy, advocating for
a nuanced, task-driven approach over a one-size-fits-all reliance on LLMs.

</details>


### [3] [CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games](https://arxiv.org/abs/2505.18218)
*Shuhang Xu,Fangwei Zhong*

Main category: cs.CL

TL;DR: CoMet框架提升LLMs处理隐喻能力，增强战略沟通。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多代理语言游戏中处理隐喻的能力不足，影响了其战略性沟通的效率。

Method: CoMet框架结合了基于假设的隐喻推理器和隐喻生成器，并通过自我反思和知识整合进行改进。

Result: 实验结果显示，CoMet显著提高了代理在“Undercover”和“Adversarial Taboo”游戏中使用隐喻进行战略沟通的能力。

Conclusion: CoMet框架显著提升了大型语言模型（LLMs）在多代理语言游戏中使用隐喻进行战略性交流的能力。

Abstract: Metaphors are a crucial way for humans to express complex or subtle ideas by
comparing one concept to another, often from a different domain. However, many
large language models (LLMs) struggle to interpret and apply metaphors in
multi-agent language games, hindering their ability to engage in covert
communication and semantic evasion, which are crucial for strategic
communication. To address this challenge, we introduce CoMet, a framework that
enables LLM-based agents to engage in metaphor processing. CoMet combines a
hypothesis-based metaphor reasoner with a metaphor generator that improves
through self-reflection and knowledge integration. This enhances the agents'
ability to interpret and apply metaphors, improving the strategic and nuanced
quality of their interactions. We evaluate CoMet on two multi-agent language
games - Undercover and Adversarial Taboo - which emphasize Covert Communication
and Semantic Evasion. Experimental results demonstrate that CoMet significantly
enhances the agents' ability to communicate strategically using metaphors.

</details>


### [4] [IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis](https://arxiv.org/abs/2505.18223)
*Hanyu Li,Haoyu Liu,Tingyu Zhu,Tianyu Guo,Zeyu Zheng,Xiaotie Deng,Michael I. Jordan*

Main category: cs.CL

TL;DR: 引入IDA-Bench以评估LLM在多轮数据分析中的表现，发现其在<50%的任务中成功，需改进多轮交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视了数据分析领域中的迭代性质，专家的决策随着对数据集的深入理解而演变。此项工作的目的是解决这一问题。

Method: 引入IDA-Bench，评价LLM代理在多轮互动场景下的表现。任务由复杂Kaggle笔记本派生，并通过LLM模拟用户提供自然语言指令进行。通过将代理最终数值输出与人类基线进行比较来判断其表现。

Result: 初步结果显示，即使是最先进的编码代理（如Claude-3.7-thinking），在<50%的任务中成功，突显了在单轮测试中未现的局限性。

Conclusion: LLMs需要提高多轮交互能力以成为更可靠的数据分析代理，需要在指令遵循和推理之间达到平衡。

Abstract: Large Language Models (LLMs) show promise as data analysis agents, but
existing benchmarks overlook the iterative nature of the field, where experts'
decisions evolve with deeper insights of the dataset. To address this, we
introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round
interactive scenarios. Derived from complex Kaggle notebooks, tasks are
presented as sequential natural language instructions by an LLM-simulated user.
Agent performance is judged by comparing its final numerical output to the
human-derived baseline. Initial results show that even state-of-the-art coding
agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting
limitations not evident in single-turn tests. This work underscores the need to
improve LLMs' multi-round capabilities for building more reliable data analysis
agents, highlighting the necessity of achieving a balance between instruction
following and reasoning.

</details>


### [5] [Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens](https://arxiv.org/abs/2505.18237)
*Xixian Yong,Xiao Zhou,Yingying Zhang,Jinlin Li,Yefeng Zheng,Xian Wu*

Main category: cs.CL

TL;DR: 研究发现推理链越长信息偏差越大且信息增益越小。提出自适应策略动态停止推理，并在基准测试中提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型虽然在多步推理上表现出色，但是通常生成的推理链过长，导致效率低下。因此，需要优化推理过程的有效性。

Method: 提出两种用于量化信息偏差和信息增益的指标：InfoBias和InfoGain，并引入一种基于熵的自适应思维策略，动态停止推理。

Result: 所提出的策略在QwQ-32B上的六个基准任务中，表现出优越的效率和推理性能，将标记使用量减少了50.80％，准确性提高了1.10％。

Conclusion: 熵基自适应思维策略在提高多步推理效率的同时保持了竞争性的准确性，能够减少生成的推理链长度。与默认模式相比，在六个基准任务上，该策略提高了1.10%的平均准确性，并减少了50.80%的标记使用量。

Abstract: The recent rise of Large Reasoning Models (LRMs) has significantly improved
multi-step reasoning performance, but often at the cost of generating
excessively long reasoning chains. This paper revisits the efficiency of such
reasoning processes through an information-theoretic lens, revealing a
fundamental trade-off between reasoning length and semantic efficiency. We
propose two metrics, InfoBias and InfoGain, to quantify divergence from ideal
reasoning paths and stepwise information contribution, respectively. Empirical
analyses show that longer reasoning chains tend to exhibit higher information
bias and diminishing information gain, especially for incorrect answers.
Motivated by these findings, we introduce an entropy-based Adaptive Think
strategy that dynamically halts reasoning once confidence is sufficiently high,
improving efficiency while maintaining competitive accuracy. Compared to the
Vanilla Think approach (default mode), our strategy yields a 1.10% improvement
in average accuracy and a 50.80% reduction in token usage on QwQ-32B across six
benchmark tasks spanning diverse reasoning types and difficulty levels,
demonstrating superior efficiency and reasoning performance. These results
underscore the promise of entropy-based methods for enhancing both accuracy and
cost-effiiciency in large language model deployment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [The end of radical concept nativism](https://arxiv.org/abs/2505.18277)
*Joshua S. Rule,Steven T. Piantadosi*

Main category: cs.AI

TL;DR: 通过对比激进概念天赋论的缺陷，我们证明在某种意义上，人类确实能学习新概念。


<details>
  <summary>Details</summary>
Motivation: 尽管认知科学和心灵哲学的争论长久以来认为学习新的概念是不可能的，但我们认为有必要重新审视并挑战这种观点，尤其是在反驳激进概念天赋论的论点上。

Method: 我们使用计算机科学和信息理论的观点，将相关观点形式化，以期在科学上更具成效。

Result: 我们确定了有关表述能力、概念结构和概念占有的三个关键点，这些点是激进概念天赋论与实际人类认知描绘相分歧的地方。

Conclusion: 我们得出结论，事实上，人们确实在某种重要的意义上学习了新概念。

Abstract: Though humans seem to be remarkable learners, arguments in cognitive science
and philosophy of mind have long maintained that learning something
fundamentally new is impossible. Specifically, Jerry Fodor's arguments for
radical concept nativism hold that most, if not all, concepts are innate and
that what many call concept learning never actually leads to the acquisition of
new concepts. These arguments have deeply affected cognitive science, and many
believe that the counterarguments to radical concept nativism have been either
unsuccessful or only apply to a narrow class of concepts. This paper first
reviews the features and limitations of prior arguments. We then identify three
critical points - related to issues of expressive power, conceptual structure,
and concept possession - at which the arguments in favor of radical concept
nativism diverge from describing actual human cognition. We use ideas from
computer science and information theory to formalize the relevant ideas in ways
that are arguably more scientifically productive. We conclude that, as a
result, there is an important sense in which people do indeed learn new
concepts.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [7] [Implementing Agents in JavaScript](https://arxiv.org/abs/2505.18228)
*Timotheus Kampik*

Main category: cs.MA

TL;DR: 介绍了JavaScript中的面向代理编程及其在多个技术领域中的应用。


<details>
  <summary>Details</summary>
Motivation: 引入面向代理编程，通过JavaScript实现推理循环代理的抽象。

Method: 进行基于实例的讲解，使用JS-son库来实现更高级的代理和多代理系统，并结合生成式AI技术。

Result: 展示了如何在多个技术生态系统中应用面向代理编程，并指出了未来研究的方向。

Conclusion: JavaScript的面向代理编程对于系统设计和AI整合具有重要意义。

Abstract: This chapter gives an introduction to agent-oriented programming in
JavaScript. It provides an example-based walk-through of how to implement
abstractions for reasoning loop agents in vanilla JavaScript. The initial
example is used as a stepping stone for explaining how to implement slightly
more advanced agents and multi-agent systems using JS-son, a JavaScript library
for agent-oriented programming. In this context, the chapter also explains how
to integrate reasoning loop agents with generative AI
technologies--specifically, large language models. Finally, application
scenarios in several technology ecosystems and future research directions are
sketched.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [8] [Model-Distributed Inference for Large Language Models at the Edge](https://arxiv.org/abs/2505.18164)
*Davide Macario,Hulya Seferoglu,Erdem Koyuncu*

Main category: cs.LG

TL;DR: MDI-LLM通过模型分割在低功耗设备上部署LLM，使用循环流水线并行技术提高效率，随着设备增加提升吞吐量和降低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 设计一种新框架以促使大型语言模型能够在边缘的低功率设备上进行部署。

Method: 这项研究通过将大语言模型划分为多个部分，并将这些部分分配给网络中的不同设备/节点来实现。节点之间通过设备间链接交换中间激活向量，实现协同计算。为了提升效率，提出了一种“循环流水线并行”技术，减少每个设备的空闲时间，并在生成多个文本序列时实现并行推理。

Result: MDI-LLM通过结合多个边缘设备的计算资源，使得比单台设备容量大的LLM在低成本硬件上得以部署，并随着设备数量的增加而提高吞吐量，降低每个设备的内存消耗。

Conclusion: MDI-LLM能够利用多个边缘设备的计算资源，使得单台设备无法容纳的LLM得以在低成本硬件上进行推理。同时，随着参与设备数量的增加，MDI-LLM提升了令牌生成的吞吐量并减少了单个设备的内存消耗。

Abstract: We introduce Model-Distributed Inference for Large-Language Models (MDI-LLM),
a novel framework designed to facilitate the deployment of state-of-the-art
large-language models (LLMs) across low-power devices at the edge. This is
accomplished by dividing the model into multiple partitions, which are then
assigned to different devices/nodes within the network. These nodes exchange
intermediate activation vectors via device-to-device links, enabling
collaborative computation. To enhance the efficiency of this process, we
propose the "recurrent pipeline parallelism" technique, which reduces idle time
on each device and facilitates parallel inference during the generation of
multiple text sequences. By leveraging the combined computational resources of
multiple edge devices, MDI-LLM enables the deployment of LLMs that exceed the
memory capacity of individual devices, making it possible to perform inference
on low-cost hardware. Furthermore, as the number of participating devices
increases, MDI-LLM boosts token generation throughput and reduces memory
consumption per device.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [9] [The influence of data gaps and outliers on resilience indicators](https://arxiv.org/abs/2505.19034)
*Teng Liu,Andreas Morr,Sebastian Bathiany,Lana L. Blaschke,Zhen Qian,Chan Diao,Taylor Smith,Niklas Boers*

Main category: nlin.AO

TL;DR: 文章探讨了关键韧性指标的数学依赖性，并通过实证研究揭示了缺失数据和异常值对指标准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 地球系统组件的稳定性受到人类活动压力的威胁，需要可靠的早期预警信号来预测突然且不可逆的体制变化。

Method: 通过分析合成及实证数据，我们研究了缺失值及异常值对韧性指标一致性的影响。

Result: 研究成果为制定数据预处理策略和精确度评估提供了必要的理论基础，有助于多个学科领域使用真实世界的数据推断系统韧性的变化。

Conclusion: 我们通过数学分析揭示了方差和自相关性指标之间的统计依赖性，强调它们的一致性主要受时间序列的初始数据点驱动。缺失数据和异常值对指标的一致性有显著影响，异常值会导致通过时间自相关性的韧性过高估计。

Abstract: The resilience, or stability, of major Earth system components is
increasingly threatened by anthropogenic pressures, demanding reliable early
warning signals for abrupt and irreversible regime shifts. Widely used
data-driven resilience indicators based on variance and autocorrelation detect
`critical slowing down', a signature of decreasing stability. However, the
interpretation of these indicators is hampered by poorly understood
interdependencies and their susceptibility to common data issues such as
missing values and outliers. Here, we establish a rigorous mathematical
analysis of the statistical dependency between variance- and
autocorrelation-based resilience indicators, revealing that their agreement is
fundamentally driven by the time series' initial data point. Using synthetic
and empirical data, we demonstrate that missing values substantially weaken
indicator agreement, while outliers introduce systematic biases that lead to
overestimation of resilience based on temporal autocorrelation. Our results
provide a necessary and rigorous foundation for preprocessing strategies and
accuracy assessments across the growing number of disciplines that use
real-world data to infer changes in system resilience.

</details>
