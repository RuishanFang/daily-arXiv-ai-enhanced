{"id": "2506.06168", "pdf": "https://arxiv.org/pdf/2506.06168", "abs": "https://arxiv.org/abs/2506.06168", "authors": ["Marco Cafiso", "Paolo Paradisi"], "title": "Robustness of complexity estimation in event-driven signals against accuracy of event detection method", "categories": ["physics.comp-ph", "nlin.AO"], "comment": null, "summary": "Complexity has gained recent attention in machine learning for its ability to\nextract synthetic information from large datasets. Complex dynamical systems\nare characterized by temporal complexity associated with intermittent\nbirth-death events of self-organizing behavior. These rapid transition events\n(RTEs) can be modelled as a stochastic point process on the time axis, with\ninter-event times (IETs) revealing rich dynamics. In particular, IETs with\npower-law distribution mark a departure from the Poisson statistics and\nindicate the presence of nontrivial complexity that is quantified by the\npower-law exponent $\\mu$ of the IET distribution. However, detection of RTEs in\nnoisy signals remains a challenge, since false positives can obscure the\nstatistical structure of the underlying process. In this paper, we address the\nproblem of quantifying the effect of the event detection tool on the accuracy\nof complexity estimation. This is reached through a systematic evaluation of\nthe Event-Driven Diffusion Scaling (EDDiS) algorithm, a tool exploiting\nevent-driven diffusion to estimate temporal complexity.After introducing the\nevent detection method RTE-Finder (RTEF), we assess the performance of the\nRTEF-EDDiS pipeline using event-driven synthetic signals. The reliability of\nthe RTEF is found to strongly depend on parameters such as the percentile and\nthe number of false positives can be much higher than the number of genuine\ncomplex events. Despite this, we found that the complexity estimation is quite\nrobust with respect to the rate of false positives. For the power-law\ndistributed IETs with $\\mu\\le2.5$, the second moment scaling $H$ appears to\neven improve as the rate of false positives increases, reaching estimation\nerrors of about 4-7%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e8b\u4ef6\u68c0\u6d4b\u5de5\u5177\u5bf9\u590d\u6742\u5ea6\u4f30\u8ba1\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u4f7f\u7528RTEF-EDDiS\u7ba1\u9053\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u5728\u8f83\u9ad8\u5047\u9633\u6027\u7387\u4e0b\uff0c\u590d\u6742\u5ea6\u4f30\u8ba1\u4f9d\u7136\u7a33\u5065\uff0c\u8bef\u5dee\u7ea6\u4e3a4-7%\u3002", "motivation": "\u5728\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u4e2d\uff0c\u5feb\u901f\u8f6c\u6362\u4e8b\u4ef6\u6a21\u578b\u5316\u4e3a\u65f6\u95f4\u8f74\u4e0a\u7684\u968f\u673a\u70b9\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e8b\u4ef6\u95f4\u65f6\u95f4\u7684\u5e42\u5f8b\u5206\u5e03\u63ed\u793a\u590d\u6742\u52a8\u6001\u3002\u566a\u58f0\u4fe1\u53f7\u4e2d\u7684\u5feb\u901f\u8f6c\u6362\u4e8b\u4ef6\u68c0\u6d4b\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u8bef\u62a5\u7387\u8f83\u9ad8\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e8b\u4ef6\u68c0\u6d4b\u5de5\u5177\u5bf9\u590d\u6742\u5ea6\u4f30\u8ba1\u51c6\u786e\u6027\u7684\u5f71\u54cd\u662f\u5fc5\u8981\u7684\u3002", "method": "\u5f15\u5165RTE-Finder (RTEF)\u4e8b\u4ef6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u7684\u5408\u6210\u4fe1\u53f7\u8bc4\u4f30RTEF-EDDiS\u6d41\u6c34\u7ebf\u7684\u6027\u80fd\u3002\u91c7\u7528Event-Driven Diffusion Scaling (EDDiS)\uff0c\u4e00\u79cd\u5229\u7528\u4e8b\u4ef6\u9a71\u52a8\u6269\u6563\u4f30\u8ba1\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\uff0c\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u663e\u793aRTEF\u7684\u53ef\u9760\u6027\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u53c2\u6570\uff0c\u5982\u767e\u5206\u4f4d\u6570\uff0c\u4e14\u5047\u9633\u6027\u4e8b\u4ef6\u8fdc\u591a\u4e8e\u771f\u5b9e\u590d\u6742\u4e8b\u4ef6\u3002\u4f46\u590d\u6742\u5ea6\u4f30\u8ba1\u4ecd\u7136\u76f8\u5bf9\u7a33\u5065\uff0c\u4f30\u7b97\u8bef\u5dee\u57284-7%\u7684\u8303\u56f4\u5185\uff0c\u5c24\u5176\u662f\u5728\u5e42\u5f8b\u5206\u5e03\u7684\u4e8b\u4ef6\u95f4\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u867d\u7136\u5047\u9633\u6027\u7387\u8f83\u9ad8\uff0c\u4f46\u590d\u6742\u5ea6\u4f30\u8ba1\u5bf9\u5047\u9633\u6027\u4ecd\u8868\u73b0\u51fa\u8f83\u597d\u7684\u9c81\u68d2\u6027\u3002\u5bf9\u4e8e\u5e42\u5f8b\u5206\u5e03\u7684\u4e8b\u4ef6\u95f4\u65f6\u95f4\uff0c\u5f53\u6307\u6570\u03bc\u22642.5\u65f6\uff0c\u7b2c\u4e8c\u77e9\u5c3a\u5ea6H\u8868\u73b0\u51fa\u968f\u7740\u5047\u9633\u6027\u7387\u589e\u52a0\u800c\u6539\u8fdb\u7684\u8d8b\u52bf\uff0c\u8bef\u5dee\u7ea6\u4e3a4-7%\u3002"}}
{"id": "2506.05380", "pdf": "https://arxiv.org/pdf/2506.05380", "abs": "https://arxiv.org/abs/2506.05380", "authors": ["Yiliang Zhou", "Abigail M. Newbury", "Gongbo Zhang", "Betina Ross Idnay", "Hao Liu", "Chunhua Weng", "Yifan Peng"], "title": "EvidenceOutcomes: a Dataset of Clinical Trial Publications with Clinically Meaningful Outcomes", "categories": ["cs.CL"], "comment": null, "summary": "The fundamental process of evidence extraction and synthesis in\nevidence-based medicine involves extracting PICO (Population, Intervention,\nComparison, and Outcome) elements from biomedical literature. However,\nOutcomes, being the most complex elements, are often neglected or\noversimplified in existing benchmarks. To address this issue, we present\nEvidenceOutcomes, a novel, large, annotated corpus of clinically meaningful\noutcomes extracted from biomedical literature. We first developed a robust\nannotation guideline for extracting clinically meaningful outcomes from text\nthrough iteration and discussion with clinicians and Natural Language\nProcessing experts. Then, three independent annotators annotated the Results\nand Conclusions sections of a randomly selected sample of 500 PubMed abstracts\nand 140 PubMed abstracts from the existing EBM-NLP corpus. This resulted in\nEvidenceOutcomes with high-quality annotations of an inter-rater agreement of\n0.76. Additionally, our fine-tuned PubMedBERT model, applied to these 500\nPubMed abstracts, achieved an F1-score of 0.69 at the entity level and 0.76 at\nthe token level on the subset of 140 PubMed abstracts from the EBM-NLP corpus.\nEvidenceOutcomes can serve as a shared benchmark to develop and test future\nmachine learning algorithms to extract clinically meaningful outcomes from\nbiomedical abstracts.", "AI": {"tldr": "This paper introduces EvidenceOutcomes, a corpus for clinically meaningful outcome extraction in medicine, showing high annotation quality and effective model performance.", "motivation": "Existing benchmarks often neglect or oversimplify outcomes in evidence-based medicine, necessitating a robust corpus focused on clinically meaningful outcome extraction.", "method": "Development of annotation guidelines through clinician and NLP expert collaboration, annotation of biomedical literature by independent annotators, and fine-tuning of the PubMedBERT model.", "result": "EvidenceOutcomes achieved high inter-rater agreement (0.76) and good performance of the PubMedBERT model (F1-score of 0.69 at the entity level and 0.76 at the token level).", "conclusion": "EvidenceOutcomes provides a high-quality benchmark for extracting clinically meaningful outcomes from biomedical literature and can aid the development of future machine learning models."}}
{"id": "2506.05437", "pdf": "https://arxiv.org/pdf/2506.05437", "abs": "https://arxiv.org/abs/2506.05437", "authors": ["Julien Soul\u00e9", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Th\u00e9ron"], "title": "A MARL-based Approach for Easing MAS Organization Engineering", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Multi-Agent Systems (MAS) have been successfully applied in industry for\ntheir ability to address complex, distributed problems, especially in IoT-based\nsystems. Their efficiency in achieving given objectives and meeting design\nrequirements is strongly dependent on the MAS organization during the\nengineering process of an application-specific MAS. To design a MAS that can\nachieve given goals, available methods rely on the designer's knowledge of the\ndeployment environment. However, high complexity and low readability in some\ndeployment environments make the application of these methods to be costly or\nraise safety concerns. In order to ease the MAS organization design regarding\nthose concerns, we introduce an original Assisted MAS Organization Engineering\nApproach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement\nLearning (MARL) process with an organizational model to suggest relevant\norganizational specifications to help in MAS engineering.", "AI": {"tldr": "AOMEA uses MARL and organizational models to improve MAS design, addressing complexity and safety issues in IoT systems.", "motivation": "Designing effective MAS for complex and distributed environments in IoT systems is challenging due to high complexity and low readability, making traditional methods costly and risking safety.", "method": "A new approach called Assisted MAS Organization Engineering Approach (AOMEA) is proposed, which uses Multi-Agent Reinforcement Learning (MARL) combined with organizational models to suggest organizational specifications.", "result": "AOMEA offers a way to improve MAS organization by providing relevant specifications through the integration of MARL, facilitating the engineering process and addressing complexity and readability issues.", "conclusion": "AOMEA presents a promising approach to enhance MAS organization by integrating MARL with organizational models, potentially leading to more efficient and safer MAS designs."}}
{"id": "2506.05426", "pdf": "https://arxiv.org/pdf/2506.05426", "abs": "https://arxiv.org/abs/2506.05426", "authors": ["Wenhao Wu", "Fuhong Liu", "Haoru Li", "Zican Hu", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "26 pages, 13 figures", "summary": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm\nfor adapting RL agents to downstream tasks through prompt conditioning.\nHowever, two notable challenges remain in fully harnessing in-context learning\nwithin RL domains: the intrinsic multi-modality of the state-action-reward data\nand the diverse, heterogeneous nature of decision tasks. To tackle these\nchallenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise\n\\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that\nintroduces architectural advances of mixture-of-experts (MoE) into\ntransformer-based decision models. T2MIR substitutes the feedforward layer with\ntwo parallel layers: a token-wise MoE that captures distinct semantics of input\ntokens across multiple modalities, and a task-wise MoE that routes diverse\ntasks to specialized experts for managing a broad task distribution with\nalleviated gradient conflicts. To enhance task-wise routing, we introduce a\ncontrastive learning method that maximizes the mutual information between the\ntask and its router representation, enabling more precise capture of\ntask-relevant information. The outputs of two MoE components are concatenated\nand fed into the next layer. Comprehensive experiments show that T2MIR\nsignificantly facilitates in-context learning capacity and outperforms various\ntypes of baselines. We bring the potential and promise of MoE to ICRL, offering\na simple and scalable architectural enhancement to advance ICRL one step closer\ntoward achievements in language and vision communities. Our code is available\nat https://github.com/NJU-RL/T2MIR.", "AI": {"tldr": "T2MIR\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u4e2d\uff0c\u5b58\u5728\u591a\u6a21\u6001\u72b6\u6001-\u52a8\u4f5c-\u5956\u52b1\u6570\u636e\u7684\u5185\u5728\u591a\u6837\u6027\u4ee5\u53ca\u51b3\u7b56\u4efb\u52a1\u7684\u591a\u6837\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u51fa\u4e86T2MIR\u6846\u67b6\u3002", "method": "T2MIR\u6846\u67b6\u5f15\u5165\u4e86\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff08MoE\uff09\u5230\u57fa\u4e8etransformer\u7684\u51b3\u7b56\u6a21\u578b\uff0c\u66ff\u6362\u4e3a\u4e24\u4e2a\u5e76\u884c\u5c42\uff1a\u6355\u6349\u591a\u4e2a\u6a21\u6001\u8f93\u5165\u4ee4\u724c\u8bed\u4e49\u7684token-wise MoE\u5c42\u548c\u4efb\u52a1\u591a\u6837\u6027\u4e13\u7528\u4e13\u5bb6\u7684task-wise MoE\u5c42\u3002\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u589e\u5f3a\u4efb\u52a1\u8def\u7531\uff0c\u8f93\u51fa\u7ecf\u5408\u5e76\u8f93\u5165\u4e0b\u4e00\u5c42\u3002", "result": "\u901a\u8fc7\u5168\u9762\u5b9e\u9a8c\uff0cT2MIR\u663e\u8457\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u57fa\u7ebf\u4e4b\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "T2MIR\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a8\u52a8\u4e86\u6df7\u5408\u4e13\u5bb6\u6a21\u5f0f\u5728\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u6f5c\u529b\u548c\u5e94\u7528\u3002"}}
{"id": "2506.05352", "pdf": "https://arxiv.org/pdf/2506.05352", "abs": "https://arxiv.org/abs/2506.05352", "authors": ["John Beverley", "Regina Hurley"], "title": "A Path to Loving", "categories": ["cs.AI"], "comment": null, "summary": "This work lays the foundations for a rigorous ontological characterization of\nlove, addressing its philosophical complexity and scientific relevance, with\nparticular emphasis on psychology and sociology, as well as highlighting ways\nin which such characterization enhances relevant AI based applications. The\nposition defended here is that love is best understood as a concatenation of\npassive sensations (e.g., emotional arousal) and active evaluative judgments\n(e.g., perceiving the beloved as valuable), in the interest of balancing the\ninvoluntary aspects of love with its rational accountability. To provide a\nstructured foundation, the paper draws on Basic Formal Ontology (BFO) and other\napplied ontological methods to differentiate various senses of love. This work\nengages with objections to the understanding of love as concatenation,\nparticularly concerning the relationship between sensation and judgment. A\ncausal correlation model is defended, ensuring that the affective and cognitive\ncomponents are linked. By offering a precise and scalable ontological account,\nthis work lays the foundation for future interdisciplinary applications, making\nlove a subject of formal inquiry in ontology engineering, artificial\nintelligence, and the sciences.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u672c\u4f53\u8bba\u65b9\u6cd5\uff0c\u5c06\u7231\u60c5\u89e3\u6790\u4e3a\u88ab\u52a8\u611f\u53d7\u548c\u4e3b\u52a8\u8bc4\u5224\u7684\u4e32\u8054\uff0c\u4e3a\u4eba\u5de5\u667a\u80fd\u7b49\u9886\u57df\u7684\u5e94\u7528\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u6790\u7231\u60c5\u7684\u54f2\u5b66\u590d\u6742\u6027\u548c\u79d1\u5b66\u76f8\u5173\u6027\uff0c\u7279\u522b\u662f\u5728\u5fc3\u7406\u5b66\u548c\u793e\u4f1a\u5b66\u9886\u57df\uff0c\u5e76\u63a2\u7d22\u8fd9\u79cd\u8868\u5f81\u5982\u4f55\u589e\u5f3a\u76f8\u5173\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u3002", "method": "\u672c\u7814\u7a76\u4f9d\u8d56\u4e8e\u57fa\u7840\u5f62\u5f0f\u672c\u4f53\uff08BFO\uff09\u548c\u5176\u4ed6\u5e94\u7528\u7684\u672c\u4f53\u8bba\u65b9\u6cd5\uff0c\u4ee5\u533a\u5206\u7231\u60c5\u7684\u4e0d\u540c\u611f\u77e5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56e0\u679c\u5173\u8054\u6a21\u578b\uff0c\u786e\u4fdd\u60c5\u611f\u548c\u8ba4\u77e5\u6210\u5206\u7684\u5173\u8054\u6027\uff0c\u4e3a\u5c06\u6765\u8de8\u5b66\u79d1\u5e94\u7528\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7231\u60c5\u7684\u672c\u4f53\u8bba\u8868\u5f81\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8ba4\u4e3a\u7231\u60c5\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u88ab\u52a8\u611f\u53d7\u548c\u4e3b\u52a8\u8bc4\u5224\u7684\u4e32\u8054\u3002"}}
{"id": "2506.05385", "pdf": "https://arxiv.org/pdf/2506.05385", "abs": "https://arxiv.org/abs/2506.05385", "authors": ["Xinxin Li", "Huiyao Chen", "Chengjun Liu", "Jing Li", "Meishan Zhang", "Jun Yu", "Min Zhang"], "title": "LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models", "categories": ["cs.CL"], "comment": "19 pages, 3 figures, 10 tables", "summary": "Semantic role labeling (SRL) is a crucial task of natural language processing\n(NLP). Although generative decoder-based large language models (LLMs) have\nachieved remarkable success across various NLP tasks, they still lag behind\nstate-of-the-art encoder-decoder (BERT-like) models in SRL. In this work, we\nseek to bridge this gap by equipping LLMs for SRL with two mechanisms: (a)\nretrieval-augmented generation and (b) self-correction. The first mechanism\nenables LLMs to leverage external linguistic knowledge such as predicate and\nargument structure descriptions, while the second allows LLMs to identify and\ncorrect inconsistent SRL outputs. We conduct extensive experiments on three\nwidely-used benchmarks of SRL (CPB1.0, CoNLL-2009, and CoNLL-2012). Results\ndemonstrate that our method achieves state-of-the-art performance in both\nChinese and English, marking the first successful application of LLMs to\nsurpass encoder-decoder approaches in SRL.", "AI": {"tldr": "\u5c06\u68c0\u7d22\u589e\u5f3a\u548c\u81ea\u6211\u7ea0\u6b63\u673a\u5236\u5e94\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u65b0\u6210\u7ee9\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u4efb\u52a1\u4e0a\u4ecd\u4e0d\u5982\u6700\u65b0\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u3002", "method": "\u672c\u6587\u5c06\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u673a\u5236\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff1a\u4e00\u662f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u4e8c\u662f\u81ea\u6211\u7ea0\u6b63\u3002\u524d\u8005\u5229\u7528\u5916\u90e8\u8bed\u8a00\u77e5\u8bc6\uff0c\u540e\u8005\u8bc6\u522b\u5e76\u7ea0\u6b63\u4e0d\u4e00\u81f4\u7684\u8f93\u51fa\u3002", "result": "\u5728\u4e09\u5927\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e2d\u6587\u548c\u82f1\u6587\u4e2d\u5747\u8fbe\u5230\u4e86\u6700\u65b0\u6c34\u5e73\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u9996\u6b21\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u89d2\u8272\u6807\u6ce8\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u3002"}}
{"id": "2506.05527", "pdf": "https://arxiv.org/pdf/2506.05527", "abs": "https://arxiv.org/abs/2506.05527", "authors": ["Caroline Wang", "Di Yang Shi", "Elad Liebman", "Ishan Durugkar", "Arrasy Rahman", "Peter Stone"], "title": "Sequence Modeling for N-Agent Ad Hoc Teamwork", "categories": ["cs.MA"], "comment": null, "summary": "N-agent ad hoc teamwork (NAHT) is a newly introduced challenge in multi-agent\nreinforcement learning, where controlled subteams of varying sizes must\ndynamically collaborate with varying numbers and types of unknown teammates\nwithout pre-coordination. The existing learning algorithm (POAM) considers only\nindependent learning for its flexibility in dealing with a changing number of\nagents. However, independent learning fails to fully capture the inter-agent\ndynamics essential for effective collaboration. Based on our observation that\ntransformers deal effectively with sequences with varying lengths and have been\nshown to be highly effective for a variety of machine learning problems, this\nwork introduces a centralized, transformer-based method for N-agent ad hoc\nteamwork. Our proposed approach incorporates historical observations and\nactions of all controlled agents, enabling optimal responses to diverse and\nunseen teammates in partially observable environments. Empirical evaluation on\na StarCraft II task demonstrates that MAT-NAHT outperforms POAM, achieving\nsuperior sample efficiency and generalization, without auxiliary agent-modeling\nobjectives.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u96c6\u4e2d\u5f0f\u65b9\u6cd5MAT-NAHT\uff0c\u7528\u4e8e\u5e94\u5bf9\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684N-agent ad hoc teamwork\u6311\u6218\uff0c\u4f18\u4e8e\u5df2\u6709\u7b97\u6cd5POAM\u3002", "motivation": "POAM\u7684\u72ec\u7acb\u5b66\u4e60\u672a\u80fd\u5145\u5206\u6355\u6349\u6709\u6548\u534f\u4f5c\u6240\u9700\u7684\u4ee3\u7406\u95f4\u52a8\u6001\u3002\u89c2\u5bdf\u5230Transformer\u5728\u5904\u7406\u53d8\u957f\u5e8f\u5217\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff0c\u7ed3\u5408\u6240\u6709\u63a7\u5236\u4ee3\u7406\u7684\u5386\u53f2\u89c2\u5bdf\u548c\u52a8\u4f5c\u3002", "result": "\u5728\u661f\u9645\u4e89\u9738II\u4efb\u52a1\u4e2d\uff0cMAT-NAHT\u8868\u73b0\u4f18\u4e8ePOAM\uff0c\u5177\u6709\u66f4\u4f18\u7684\u6837\u672c\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MAT-NAHT\u6bd4POAM\u5728\u6837\u672c\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.05427", "pdf": "https://arxiv.org/pdf/2506.05427", "abs": "https://arxiv.org/abs/2506.05427", "authors": ["Zishan Shu", "Yufan Deng", "Hongyu Zhang", "Zhiwei Nie", "Jie Chen"], "title": "MTPNet: Multi-Grained Target Perception for Unified Activity Cliff Prediction", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "Activity cliff prediction is a critical task in drug discovery and material\ndesign. Existing computational methods are limited to handling single binding\ntargets, which restricts the applicability of these prediction models. In this\npaper, we present the Multi-Grained Target Perception network (MTPNet) to\nincorporate the prior knowledge of interactions between the molecules and their\ntarget proteins. Specifically, MTPNet is a unified framework for activity cliff\nprediction, which consists of two components: Macro-level Target Semantic (MTS)\nguidance and Micro-level Pocket Semantic (MPS) guidance. By this way, MTPNet\ndynamically optimizes molecular representations through multi-grained protein\nsemantic conditions. To our knowledge, it is the first time to employ the\nreceptor proteins as guiding information to effectively capture critical\ninteraction details. Extensive experiments on 30 representative activity cliff\ndatasets demonstrate that MTPNet significantly outperforms previous approaches,\nachieving an average RMSE improvement of 18.95% on top of several mainstream\nGNN architectures. Overall, MTPNet internalizes interaction patterns through\nconditional deep learning to achieve unified predictions of activity cliffs,\nhelping to accelerate compound optimization and design. Codes are available at:\nhttps://github.com/ZishanShu/MTPNet.", "AI": {"tldr": "MTPNet\u901a\u8fc7\u7ed3\u5408\u76ee\u6807\u86cb\u767d\u7684\u4fe1\u606f\u4ee5\u6539\u8fdb\u6d3b\u6027\u65ad\u5d16\u9884\u6d4b\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5904\u7406\u5355\u4e00\u7ed3\u5408\u76ee\u6807\uff0c\u9650\u5236\u4e86\u9884\u6d4b\u6a21\u578b\u7684\u9002\u7528\u6027\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u66f4\u597d\u5730\u6355\u6349\u5206\u5b50\u4e0e\u86cb\u767d\u8d28\u76ee\u6807\u4e4b\u95f4\u7684\u4e92\u52a8\u4fe1\u606f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5b8f\u89c2\u548c\u5fae\u89c2\u5c42\u6b21\u4e24\u4e2a\u7ec4\u6210\u90e8\u5206\u7684\u591a\u5c42\u7ea7\u76ee\u6807\u611f\u77e5\u7f51\u7edc(MTPNet)\uff0c\u7528\u4e8e\u52a8\u6001\u4f18\u5316\u5206\u5b50\u8868\u793a\u3002", "result": "MTPNet\u572830\u4e2a\u4ee3\u8868\u6027\u6d3b\u6027\u65ad\u5d16\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\uff0c\u5e73\u5747RMSE\u63d0\u5347\u4e8618.95%\u3002", "conclusion": "MTPNet\u901a\u8fc7\u7ed3\u5408\u5206\u5b50\u4e0e\u76ee\u6807\u86cb\u767d\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u6d3b\u6027\u65ad\u5d16\u9884\u6d4b\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.05370", "pdf": "https://arxiv.org/pdf/2506.05370", "abs": "https://arxiv.org/abs/2506.05370", "authors": ["Kristy Wedel"], "title": "Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems", "categories": ["cs.AI", "cs.ET"], "comment": "32 pages, 9 tables, 1 figure", "summary": "A critical challenge remains unresolved as generative AI systems are quickly\nimplemented in various organizational settings. Despite significant advances in\nmemory components such as RAG, vector stores, and LLM agents, these systems\nstill have substantial memory limitations. Gen AI workflows rarely store or\nreflect on the full context in which decisions are made. This leads to repeated\nerrors and a general lack of clarity. This paper introduces Contextual Memory\nIntelligence (CMI) as a new foundational paradigm for building intelligent\nsystems. It repositions memory as an adaptive infrastructure necessary for\nlongitudinal coherence, explainability, and responsible decision-making rather\nthan passive data. Drawing on cognitive science, organizational theory,\nhuman-computer interaction, and AI governance, CMI formalizes the structured\ncapture, inference, and regeneration of context as a fundamental system\ncapability. The Insight Layer is presented in this paper to operationalize this\nvision. This modular architecture uses human-in-the-loop reflection, drift\ndetection, and rationale preservation to incorporate contextual memory into\nsystems. The paper argues that CMI allows systems to reason with data, history,\njudgment, and changing context, thereby addressing a foundational blind spot in\ncurrent AI architectures and governance efforts. A framework for creating\nintelligent systems that are effective, reflective, auditable, and socially\nresponsible is presented through CMI. This enhances human-AI collaboration,\ngenerative AI design, and the resilience of the institutions.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faCMI\u4f5c\u4e3a\u6784\u5efa\u667a\u80fd\u7cfb\u7edf\u7684\u65b0\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u751f\u6210AI\u5185\u5b58\u5c40\u9650\uff0c\u5e76\u901a\u8fc7Insight Layer\u6574\u5408\u4e0a\u4e0b\u6587\u8bb0\u5fc6\uff0c\u589e\u5f3a\u7cfb\u7edf\u7684\u8fde\u8d2f\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u751f\u6210\u6027AI\u7cfb\u7edf\u5728\u5e94\u7528\u4e8e\u5404\u79cd\u7ec4\u7ec7\u73af\u5883\u65f6\uff0c\u5185\u5b58\u7ec4\u4ef6\u4ecd\u5b58\u5728\u91cd\u5927\u5c40\u9650\uff0c\u5bfc\u81f4\u51b3\u7b56\u65f6\u65e0\u6cd5\u5b58\u50a8\u6216\u53cd\u601d\u5b8c\u6574\u4e0a\u4e0b\u6587\uff0c\u8fdb\u800c\u5bfc\u81f4\u91cd\u590d\u9519\u8bef\u548c\u7f3a\u4e4f\u6e05\u6670\u6027\u3002\u63d0\u51faCMI\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u5f15\u5165Insight Layer\u8fd9\u4e00\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5229\u7528\u4eba\u673a\u534f\u4f5c\u7684\u53cd\u601d\u673a\u5236\u3001\u6f02\u79fb\u68c0\u6d4b\u548c\u7406\u7531\u4fdd\u7559\u529f\u80fd\uff0c\u5c06\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u878d\u5165\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7CMI\u7cfb\u7edf\uff0c\u80fd\u591f\u5229\u7528\u6570\u636e\u3001\u5386\u53f2\u3001\u5224\u65ad\u548c\u53d8\u5316\u7684\u4e0a\u4e0b\u6587\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u4eba\u673a\u534f\u4f5c\u3001\u751f\u6210\u6027AI\u8bbe\u8ba1\u548c\u673a\u6784\u7684\u97e7\u6027\u3002", "conclusion": "CMI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6784\u5efa\u667a\u80fd\u7cfb\u7edf\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5c06\u4e0a\u4e0b\u6587\u5b58\u50a8\u548c\u53cd\u601d\u878d\u5165\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u751f\u6210\u6027AI\u67b6\u6784\u4e2d\u7684\u57fa\u7840\u6027\u76f2\u70b9\u3002"}}
{"id": "2506.05386", "pdf": "https://arxiv.org/pdf/2506.05386", "abs": "https://arxiv.org/abs/2506.05386", "authors": ["Lo Pang-Yun Ting", "Chengshuai Zhao", "Yu-Hua Zeng", "Yuan Jee Lim", "Kun-Ta Chuang"], "title": "Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Clinical note generation aims to automatically produce free-text summaries of\na patient's condition and diagnostic process, with discharge instructions being\na representative long-form example. While recent large language model\n(LLM)-based methods pre-trained on general clinical corpora show promise in\nclinical text generation, they fall short in producing long-form notes from\nlimited patient information. In this paper, we propose R2AG, the first\nreinforced retriever for long-form discharge instruction generation based on\npre-admission data. R2AG is trained with reinforcement learning to retrieve\nreasoning paths from a medical knowledge graph, providing explicit semantic\nguidance to the LLM. To bridge the information gap, we propose Group-Based\nRetriever Optimization (GRO) which improves retrieval quality with\ngroup-relative rewards, encouraging reasoning leaps for deeper inference by the\nLLM. Comprehensive experiments on the MIMIC-IV-Note dataset show that R2AG\noutperforms baselines in both clinical efficacy and natural language generation\nmetrics. Further analysis reveals that R2AG fills semantic gaps in sparse input\nscenarios, and retrieved reasoning paths help LLMs avoid clinical\nmisinterpretation by focusing on key evidence and following coherent reasoning.", "AI": {"tldr": "R2AG\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u6765\u6539\u5584\u957f\u7bc7\u4e34\u5e8a\u7b14\u8bb0\u751f\u6210\uff0c\u88ab\u8bc1\u660e\u5728\u4e34\u5e8a\u6709\u6548\u6027\u548c\u8bed\u8a00\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u751f\u6210\u957f\u7bc7\u4e34\u5e8a\u6587\u672c\u65f6\uff0c\u7531\u4e8e\u60a3\u8005\u4fe1\u606f\u6709\u9650\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u660e\u786e\u8bed\u4e49\u6307\u5bfc\u7684\u7cfb\u7edf\u4ee5\u6539\u8fdb\u751f\u6210\u7ed3\u679c\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u8bad\u7ec3R2AG\u4ee5\u4ece\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u4e2d\u68c0\u7d22\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGroup-Based Retriever Optimization (GRO) \u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u68c0\u7d22\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cR2AG\u5728MIMIC-IV-Note\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\uff0c\u80fd\u591f\u5e2e\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5173\u6ce8\u5173\u952e\u8bc1\u636e\u548c\u9075\u5faa\u8fde\u8d2f\u63a8\u7406\u6765\u907f\u514d\u4e34\u5e8a\u8bef\u89e3\u3002", "conclusion": "R2AG\u901a\u8fc7\u5f15\u5165\u533b\u5b66\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u63a8\u7406\u8def\u5f84\u548c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u586b\u8865\u8f93\u5165\u4fe1\u606f\u7a00\u758f\u7684\u8bed\u4e49\u7a7a\u767d\uff0c\u4ee5\u63d0\u9ad8\u751f\u6210\u957f\u7bc7\u4e34\u5e8a\u7b14\u8bb0\u7684\u6548\u679c\u3002\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u5176\u5728\u4e34\u5e8a\u6709\u6548\u6027\u548c\u81ea\u7136\u8bed\u8a00\u751f\u6210\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2506.05555", "pdf": "https://arxiv.org/pdf/2506.05555", "abs": "https://arxiv.org/abs/2506.05555", "authors": ["Oliver Slumbers", "Joel Z. Leibo", "Marco A. Janssen"], "title": "Using Large Language Models to Simulate Human Behavioural Experiments: Port of Mars", "categories": ["cs.MA", "cs.CY"], "comment": null, "summary": "Collective risk social dilemmas (CRSD) highlight a trade-off between\nindividual preferences and the need for all to contribute toward achieving a\ngroup objective. Problems such as climate change are in this category, and so\nit is critical to understand their social underpinnings. However, rigorous CRSD\nmethodology often demands large-scale human experiments but it is difficult to\nguarantee sufficient power and heterogeneity over socio-demographic factors.\nGenerative AI offers a potential complementary approach to address thisproblem.\nBy replacing human participants with large language models (LLM), it allows for\na scalable empirical framework. This paper focuses on the validity of this\napproach and whether it is feasible to represent a large-scale human-like\nexperiment with sufficient diversity using LLM. In particular, where previous\nliterature has focused on political surveys, virtual towns and classical\ngame-theoretic examples, we focus on a complex CRSD used in the institutional\neconomics and sustainability literature known as Port of Mars", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u4eba\u7c7b\u7814\u7a76\u96c6\u4f53\u98ce\u9669\u793e\u4f1a\u56f0\u5883\uff0c\u4ee5\u63d0\u4f9b\u591a\u6837\u5316\u7684\u5b9e\u9a8c\u73af\u5883\uff0c\u7279\u522b\u805a\u7126\u5728\u673a\u6784\u7ecf\u6d4e\u4e0e\u53ef\u6301\u7eed\u6027\u9886\u57df\u7684\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u7814\u7a76\u96c6\u4f53\u98ce\u9669\u793e\u4f1a\u56f0\u5883\uff08CRSD\uff09\uff0c\u5982\u6c14\u5019\u53d8\u5316\uff0c\u9700\u7406\u89e3\u5176\u793e\u4f1a\u57fa\u7840\uff0c\u4f46\u4f20\u7edfCRSD\u65b9\u6cd5\u9700\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u96be\u4ee5\u4fdd\u8bc1\u4eba\u7fa4\u591a\u6837\u6027\u3002\u751f\u6210\u5f0fAI\u63d0\u4f9b\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u66ff\u4ee3\u4eba\u7c7b\u53c2\u4e0e\u8005\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u7684\u7ecf\u9a8c\u6846\u67b6\u4ee5\u6a21\u62df\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u7684\u4eba\u7c7b\u5b9e\u9a8c\u3002", "result": "\u7814\u7a76\u7740\u91cd\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63a2\u7d22LLM\u80fd\u5426\u771f\u5b9e\u518d\u73b0\u590d\u6742\u7684CRSD\u5b9e\u9a8c\uff0c\u5c24\u5176\u5728\u673a\u6784\u7ecf\u6d4e\u5b66\u548c\u53ef\u6301\u7eed\u6027\u6587\u5b66\u4e2d\u79f0\u4e3a\u706b\u661f\u6e2f\u7684\u6848\u4f8b\u4e2d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u5927\u578b\u4eba\u7c7b\u5b9e\u9a8c\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\uff0c\u4ee5\u7814\u7a76\u96c6\u4f53\u98ce\u9669\u793e\u4f1a\u56f0\u5883\uff0c\u5c24\u5176\u5728\u65e0\u6cd5\u8fbe\u5230\u5b9e\u9a8c\u591a\u6837\u6027\u65f6\u5177\u6709\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2506.05428", "pdf": "https://arxiv.org/pdf/2506.05428", "abs": "https://arxiv.org/abs/2506.05428", "authors": ["Zhihao Tang", "Chaozhuo Li", "Litian Zhang", "Xi Zhang"], "title": "Diffusion with a Linguistic Compass: Steering the Generation of Clinically Plausible Future sMRI Representations for Early MCI Conversion Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Early prediction of Mild Cognitive Impairment (MCI) conversion is hampered by\na trade-off between immediacy--making fast predictions from a single baseline\nsMRI--and accuracy--leveraging longitudinal scans to capture disease\nprogression. We propose MCI-Diff, a diffusion-based framework that synthesizes\nclinically plausible future sMRI representations directly from baseline data,\nachieving both real-time risk assessment and high predictive performance.\nFirst, a multi-task sequence reconstruction strategy trains a shared denoising\nnetwork on interpolation and extrapolation tasks to handle irregular follow-up\nsampling and learn robust latent trajectories. Second, an LLM-driven\n\"linguistic compass\" is introduced for clinical plausibility sampling:\ngenerated feature candidates are quantized, tokenized, and scored by a\nfine-tuned language model conditioned on expected structural biomarkers,\nguiding autoregressive generation toward realistic disease patterns.\nExperiments on ADNI and AIBL cohorts show that MCI-Diff outperforms\nstate-of-the-art baselines, improving early conversion accuracy by 5-12%.", "AI": {"tldr": "MCI-Diff is a framework for predicting MCI conversion that balances immediacy and accuracy by synthesizing future sMRI from baseline, showing a 5-12% performance boost on standard datasets.", "motivation": "The motivation is to address the challenge in early prediction of MCI conversion, balancing between quick predictions from a single baseline sMRI and accuracy through longitudinal scans that depict disease progression.", "method": "The method introduces MCI-Diff, which synthesizes future sMRI representations from baseline data using a diffusion-based framework. It employs a multi-task sequence reconstruction strategy for handling irregular follow-up sampling and learning latent trajectories through a shared denoising network. Additionally, a language model-driven \"linguistic compass\" is used for clinical plausibility sampling to guide realistic disease pattern generation.", "result": "The result demonstrates that MCI-Diff achieves superior performance compared to state-of-the-art methods, with a 5-12% improvement in early conversion accuracy on ADNI and AIBL cohorts.", "conclusion": "MCI-Diff outperforms existing baselines and improves early conversion accuracy by 5-12% in predicting MCI progression."}}
{"id": "2506.05422", "pdf": "https://arxiv.org/pdf/2506.05422", "abs": "https://arxiv.org/abs/2506.05422", "authors": ["Andrei T. Patrascu"], "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "We introduce a novel learning and planning framework that replaces\ntraditional reward-based optimisation with constructive logical inference. In\nour model, actions, transitions, and goals are represented as logical\npropositions, and decision-making proceeds by building constructive proofs\nunder intuitionistic logic. This method ensures that state transitions and\npolicies are accepted only when supported by verifiable preconditions --\neschewing probabilistic trial-and-error in favour of guaranteed logical\nvalidity. We implement a symbolic agent operating in a structured gridworld,\nwhere reaching a goal requires satisfying a chain of intermediate subgoals\n(e.g., collecting keys to open doors), each governed by logical constraints.\nUnlike conventional reinforcement learning agents, which require extensive\nexploration and suffer from unsafe or invalid transitions, our constructive\nagent builds a provably correct plan through goal chaining, condition tracking,\nand knowledge accumulation. Empirical comparison with Q-learning demonstrates\nthat our method achieves perfect safety, interpretable behaviour, and efficient\nconvergence with no invalid actions, highlighting its potential for safe\nplanning, symbolic cognition, and trustworthy AI. This work presents a new\ndirection for reinforcement learning grounded not in numeric optimisation, but\nin constructive logic and proof theory.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66ff\u4ee3\u4f20\u7edf\u5956\u52b1\u4f18\u5316\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u5b9e\u73b0\u5b89\u5168\u89c4\u5212\u548c\u7b26\u53f7\u8ba4\u77e5\u3002\u4e0eQ\u5b66\u4e60\u76f8\u6bd4\uff0c\u5177\u5907\u5b8c\u7f8e\u5b89\u5168\u6027\u548c\u9ad8\u6548\u6536\u655b\u6027\u3002", "motivation": "\u4e3a\u4e86\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u5956\u52b1\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u548c\u89c4\u5212\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u903b\u8f91\u63a8\u7406\u4fdd\u8bc1\u72b6\u6001\u8f6c\u53d8\u548c\u7b56\u7565\u7684\u5408\u7406\u6027\uff0c\u907f\u514d\u6982\u7387\u8bd5\u9519\u3002", "method": "\u6211\u4eec\u7684\u6a21\u578b\u91c7\u53d6\u6784\u9020\u6027\u903b\u8f91\u63a8\u7406\u6765\u8fdb\u884c\u51b3\u7b56\uff0c\u57fa\u4e8e\u76f4\u89c9\u4e3b\u4e49\u903b\u8f91\u8fdb\u884c\u6784\u9020\u6027\u8bc1\u660e\uff0c\u5e76\u5728\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u7f51\u683c\u4e16\u754c\u4e2d\u8fd0\u884c\uff0c\u5176\u4e2d\u8fbe\u5230\u76ee\u6807\u9700\u8981\u6ee1\u8db3\u4e00\u7cfb\u5217\u4e2d\u95f4\u5b50\u76ee\u6807\uff0c\u6bcf\u4e2a\u5b50\u76ee\u6807\u7531\u903b\u8f91\u7ea6\u675f\u7ba1\u7406\u3002", "result": "\u6211\u4eec\u7684\u6784\u9020\u6027\u4ee3\u7406\u901a\u8fc7\u76ee\u6807\u94fe\u3001\u6761\u4ef6\u8ddf\u8e2a\u548c\u77e5\u8bc6\u79ef\u7d2f\uff0c\u6784\u5efa\u4e00\u4e2a\u53ef\u8bc1\u660e\u6b63\u786e\u7684\u8ba1\u5212\u3002\u5728\u4e0eQ\u5b66\u4e60\u7684\u5b9e\u8bc1\u5bf9\u6bd4\u4e2d\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u7684\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u7684\u884c\u4e3a\u548c\u9ad8\u6548\u7684\u6536\u655b\u6027\uff0c\u5e76\u4e14\u6ca1\u6709\u65e0\u6548\u52a8\u4f5c\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u4e0eQ\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u7684\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u6548\u6536\u655b\u6027\uff0c\u4e14\u65e0\u65e0\u6548\u52a8\u4f5c\uff0c\u5c55\u793a\u4e86\u5728\u5b89\u5168\u89c4\u5212\u3001\u7b26\u53f7\u8ba4\u77e5\u548c\u53ef\u4fe1AI\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05387", "pdf": "https://arxiv.org/pdf/2506.05387", "abs": "https://arxiv.org/abs/2506.05387", "authors": ["Jaydip Sen", "Saptarshi Sengupta. Subhasis Dasgupta"], "title": "Advancing Decoding Strategies: Enhancements in Locally Typical Sampling for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "This is the accepted but pre-reviewed version of the chapter that has\n  been accepted for publication in the Springer volume 'Decision-Making in\n  Computational Intelligence-Based Systems,' edited by Witold Pedrycz, Gilberto\n  Rivera, Rose Ma Rodriguez, and Salvador Ibarra Martinez. The chapter is 39\n  pages long, and it contains 2 figures and 6 tables. This is NOT the final\n  camera-ready version", "summary": "This chapter explores advancements in decoding strategies for large language\nmodels (LLMs), focusing on enhancing the Locally Typical Sampling (LTS)\nalgorithm. Traditional decoding methods, such as top-k and nucleus sampling,\noften struggle to balance fluency, diversity, and coherence in text generation.\nTo address these challenges, Adaptive Semantic-Aware Typicality Sampling (ASTS)\nis proposed as an improved version of LTS, incorporating dynamic entropy\nthresholding, multi-objective scoring, and reward-penalty adjustments. ASTS\nensures contextually coherent and diverse text generation while maintaining\ncomputational efficiency. Its performance is evaluated across multiple\nbenchmarks, including story generation and abstractive summarization, using\nmetrics such as perplexity, MAUVE, and diversity scores. Experimental results\ndemonstrate that ASTS outperforms existing sampling techniques by reducing\nrepetition, enhancing semantic alignment, and improving fluency.", "AI": {"tldr": "The chapter proposes ASTS to enhance text generation in LLMs, outperforming existing methods in fluency and coherence while maintaining diversity and efficiency.", "motivation": "Traditional decoding methods face challenges in balancing fluency, diversity, and coherence in text generation. The paper aims to address these challenges by enhancing the LTS algorithm.", "method": "The paper proposes Adaptive Semantic-Aware Typicality Sampling (ASTS) which incorporates dynamic entropy thresholding, multi-objective scoring, and reward-penalty adjustments to enhance LTS.", "result": "ASTS ensures contextually coherent and diverse text generation while maintaining computational efficiency. It demonstrates superior performance in benchmarks like story generation and abstractive summarization, evaluated using metrics such as perplexity, MAUVE, and diversity scores.", "conclusion": "ASTS outperforms existing sampling techniques by reducing repetition, enhancing semantic alignment, and improving fluency."}}
{"id": "2506.06032", "pdf": "https://arxiv.org/pdf/2506.06032", "abs": "https://arxiv.org/abs/2506.06032", "authors": ["Edward Hughes", "Tina O. Zhu", "Martin J. Chadwick", "Raphael Koster", "Antonio Garc\u00eda Casta\u00f1eda", "Charles Beattie", "Thore Graepel", "Matthew M. Botvinick", "Joel Z. Leibo"], "title": "Modeling human reputation-seeking behavior in a spatio-temporally complex public good provision game", "categories": ["cs.MA"], "comment": "45 pages, 29 figures. arXiv admin note: substantial text overlap with\n  arXiv:2103.04982", "summary": "Multi-agent reinforcement learning algorithms are useful for simulating\nsocial behavior in settings that are too complex for other theoretical\napproaches like game theory. However, they have not yet been empirically\nsupported by laboratory experiments with real human participants. In this work\nwe demonstrate how multi-agent reinforcement learning can model group behavior\nin a spatially and temporally complex public good provision game called Clean\nUp. We show that human groups succeed in Clean Up when they can see who is who\nand track reputations over time but fail under conditions of anonymity. A new\nmulti-agent reinforcement learning model of reputation-based cooperation\ndemonstrates the same difference between identifiable and anonymous conditions.\nFurthermore, both human groups and artificial agent groups solve the problem\nvia turn-taking despite other options being available. Our results highlight\nthe benefits of using multi-agent reinforcement learning to model human social\nbehavior in complex environments.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5728\u201c\u6e05\u7406\u201d\u6e38\u620f\u4e2d\u6a21\u62df\u4eba\u7c7b\u793e\u4ea4\u884c\u4e3a\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u8eab\u4efd\u8bc6\u522b\u548c\u58f0\u8a89\u8ddf\u8e2a\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u6a21\u62df\u590d\u6742\u793e\u4ea4\u884c\u4e3a\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9a8c\u5ba4\u6761\u4ef6\u4e0b\u4e0e\u771f\u4eba\u53c2\u4e0e\u8005\u8fdb\u884c\u7684\u5b9e\u9a8c\u5c1a\u7f3a\u4e4f\u5b9e\u8bc1\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u6e05\u7406\u201d\u7684\u516c\u5171\u7269\u54c1\u63d0\u4f9b\u6e38\u620f\uff0c\u4f5c\u4e3a\u65f6\u7a7a\u590d\u6742\u73af\u5883\u4e0b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u7684\u5b9e\u9a8c\u573a\u666f\u3002\u901a\u8fc7\u64cd\u63a7\u53c2\u4e0e\u8005\u80fd\u5426\u8bc6\u522b\u4ed6\u4eba\u5e76\u8ddf\u8e2a\u58f0\u8a89\uff0c\u5206\u6790\u4eba\u7c7b\u7ec4\u4e0e\u4eba\u5de5\u667a\u80fd\u7ec4\u5728\u53ef\u8bc6\u522b\u4e0e\u533f\u540d\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u201c\u6e05\u7406\u201d\u6e38\u620f\u4e2d\uff0c\u5f53\u4eba\u7c7b\u53c2\u4e0e\u8005\u80fd\u591f\u8bc6\u522b\u4ed6\u4eba\u5e76\u8ddf\u8e2a\u58f0\u8a89\u65f6\uff0c\u4ed6\u4eec\u8868\u73b0\u51fa\u6210\u529f\u7684\u5408\u4f5c\uff0c\u800c\u5728\u533f\u540d\u60c5\u51b5\u4e0b\u5219\u5931\u8d25\u3002\u65b0\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u590d\u73b0\u4e86\u8fd9\u4e00\u73b0\u8c61\uff0c\u4e14\u65e0\u8bba\u662f\u4eba\u7c7b\u7ec4\u8fd8\u662f\u4eba\u5de5\u667a\u80fd\u7ec4\uff0c\u90fd\u503e\u5411\u4e8e\u901a\u8fc7\u8f6e\u6362\u5236\u89e3\u51b3\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u5728\u590d\u6742\u73af\u5883\u4e2d\u6210\u529f\u6a21\u62df\u57fa\u4e8e\u58f0\u8a89\u7684\u5408\u4f5c\u884c\u4e3a\uff0c\u4e0e\u4eba\u7c7b\u7684\u793e\u4ea4\u884c\u4e3a\u975e\u5e38\u76f8\u4f3c\uff0c\u7a81\u663e\u51fa\u6b64\u7c7b\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u793e\u4ea4\u884c\u4e3a\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05432", "pdf": "https://arxiv.org/pdf/2506.05432", "abs": "https://arxiv.org/abs/2506.05432", "authors": ["Yuxuan Yue", "Zukang Xu", "Zhihang Yuan", "Dawei Yang", "Jianglong Wu", "Liqiang Nie"], "title": "PCDVQ: Enhancing Vector Quantization for Large Language Models via Polar Coordinate Decoupling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) face significant challenges in edge deployment\ndue to their massive parameter scale. Vector Quantization (VQ), a\nclustering-based quantization method, serves as a prevalent solution to this\nissue for its extremely low-bit (even at 2-bit) and considerable accuracy.\nSince a vector is a quantity in mathematics and physics that has both direction\nand magnitude, existing VQ works typically quantize them in a coupled manner.\nHowever, we find that direction exhibits significantly greater sensitivity to\nquantization compared to the magnitude. For instance, when separately\nclustering the directions and magnitudes of weight vectors in LLaMA-2-7B, the\naccuracy drop of zero-shot tasks are 46.5\\% and 2.3\\%, respectively. This gap\neven increases with the reduction of clustering centers. Further, Euclidean\ndistance, a common metric to access vector similarities in current VQ works,\nplaces greater emphasis on reducing the magnitude error. This property is\ncontrary to the above finding, unavoidably leading to larger quantization\nerrors. To these ends, this paper proposes Polar Coordinate Decoupled Vector\nQuantization (PCDVQ), an effective and efficient VQ framework consisting of two\nkey modules: 1) Polar Coordinate Decoupling (PCD), which transforms vectors\ninto their polar coordinate representations and perform independent\nquantization of the direction and magnitude parameters.2) Distribution Aligned\nCodebook Construction (DACC), which optimizes the direction and magnitude\ncodebooks in accordance with the source distribution. Experimental results show\nthat PCDVQ outperforms baseline methods at 2-bit level by at least 1.5\\%\nzero-shot accuracy, establishing a novel paradigm for accurate and highly\ncompressed LLMs.", "AI": {"tldr": "PCDVQ\u901a\u8fc7\u5bf9\u65b9\u5411\u548c\u5e45\u503c\u7684\u72ec\u7acb\u91cf\u5316\uff0c\u5927\u5e45\u6539\u5584\u4e862-bit\u91cf\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u96f6\u6837\u672c\u4efb\u52a1\u4e0a\u3002", "motivation": "\u73b0\u6709\u7684\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u5c06\u5411\u91cf\u7684\u65b9\u5411\u548c\u5e45\u503c\u4e00\u5e76\u91cf\u5316\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\uff0c\u65b9\u5411\u5bf9\u91cf\u5316\u66f4\u52a0\u654f\u611f\uff0c\u8fd9\u4e0e\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u7684\u6b27\u6c0f\u8ddd\u79bb\u4f5c\u4e3a\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u76f8\u6096\uff0c\u56e0\u4e3a\u6b27\u6c0f\u8ddd\u79bb\u66f4\u6ce8\u91cd\u51cf\u5c11\u5e45\u503c\u8bef\u5dee\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6781\u5750\u6807\u89e3\u8026\u5411\u91cf\u91cf\u5316\uff08PCDVQ\uff09\u6846\u67b6\uff0c\u5176\u5305\u62ec\u4e24\u4e2a\u4e3b\u8981\u6a21\u5757\uff1a1\uff09\u6781\u5750\u6807\u89e3\u8026\uff08PCD\uff09\uff0c\u5c06\u5411\u91cf\u8f6c\u6362\u4e3a\u6781\u5750\u6807\u8868\u793a\uff0c\u5e76\u72ec\u7acb\u91cf\u5316\u65b9\u5411\u548c\u5e45\u503c\u53c2\u6570\uff1b2\uff09\u5206\u5e03\u5bf9\u9f50\u7801\u672c\u6784\u9020\uff08DACC\uff09\uff0c\u4f18\u5316\u65b9\u5411\u548c\u5e45\u503c\u7801\u672c\u4ee5\u7b26\u5408\u6e90\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPCDVQ\u57282-bit\u7ea7\u522b\u4e0a\u81f3\u5c11\u63d0\u9ad8\u4e861.5%\u7684\u96f6\u6837\u672c\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u8fd9\u8bc1\u660e\u4e86\u5176\u5728\u51c6\u786e\u6027\u548c\u9ad8\u538b\u7f29\u7387\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684PCDVQ\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u57282-bit\u91cf\u5316\u7684\u6761\u4ef6\u4e0b\uff0c\u80fd\u591f\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u81f3\u5c111.5%\u7684\u96f6\u6837\u672c\u51c6\u786e\u7387\u3002PCDVQ\u4e3a\u5b9e\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684LLMs\u91cf\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2506.05520", "pdf": "https://arxiv.org/pdf/2506.05520", "abs": "https://arxiv.org/abs/2506.05520", "authors": ["Cecil Pang"], "title": "Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted", "categories": ["cs.AI", "cs.MA"], "comment": "Being peer reviewed by a journal", "summary": "Contemporary businesses operate in dynamic environments requiring rapid\nadaptation to achieve goals and maintain competitiveness. Existing data\nplatforms often fall short by emphasizing tools over alignment with business\nneeds, resulting in inefficiencies and delays. To address this gap, I propose\nthe Business Semantics Centric, AI Agents Assisted Data System (BSDS), a\nholistic system that integrates architecture, workflows, and team organization\nto ensure data systems are tailored to business priorities rather than dictated\nby technical constraints. BSDS redefines data systems as dynamic enablers of\nbusiness success, transforming them from passive tools into active drivers of\norganizational growth. BSDS has a modular architecture that comprises curated\ndata linked to business entities, a knowledge base for context-aware AI agents,\nand efficient data pipelines. AI agents play a pivotal role in assisting with\ndata access and system management, reducing human effort, and improving\nscalability. Complementing this architecture, BSDS incorporates workflows\noptimized for both exploratory data analysis and production requirements,\nbalancing speed of delivery with quality assurance. A key innovation of BSDS is\nits incorporation of the human factor. By aligning data team expertise with\nbusiness semantics, BSDS bridges the gap between technical capabilities and\nbusiness needs. Validated through real-world implementation, BSDS accelerates\ntime-to-market for data-driven initiatives, enhances cross-functional\ncollaboration, and provides a scalable blueprint for businesses of all sizes.\nFuture research can build on BSDS to explore optimization strategies using\ncomplex systems and adaptive network theories, as well as developing autonomous\ndata systems leveraging AI agents.", "AI": {"tldr": "The paper proposes BSDS, a system to align data systems with business needs using AI agents, improving efficiency and scalability.", "motivation": "The motivation is to address the inefficiencies and delays caused by existing data platforms that emphasize tools over alignment with business needs, by proposing a system that integrates architecture, workflows, and team organization to ensure data systems align with business priorities.", "method": "BSDS has a modular architecture with curated data linked to business entities, a knowledge base for context-aware AI agents, efficient data pipelines, optimized workflows, and incorporates human factor alignment with business semantics.", "result": "Validated through real-world implementation, BSDS enables faster time-to-market, enhances cross-functional collaboration, and offers a scalable solution for businesses.", "conclusion": "BSDS accelerates time-to-market for data-driven initiatives, enhances collaboration, and provides a scalable blueprint for businesses."}}
{"id": "2506.05388", "pdf": "https://arxiv.org/pdf/2506.05388", "abs": "https://arxiv.org/abs/2506.05388", "authors": ["Stefanie Urchs", "Veronika Thurner", "Matthias A\u00dfenmacher", "Christian Heumann", "Stephanie Thiemichen"], "title": "taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades", "categories": ["cs.CL"], "comment": "Accepted @ \"63rd Annual Meeting of the Association for Computational\n  Linguistics (ACL 2025)\" as a findings paper. This is the author's version of\n  the work. The definitive version of record will be published in the\n  proceedings", "summary": "Open-access corpora are essential for advancing natural language processing\n(NLP) and computational social science (CSS). However, large-scale resources\nfor German remain limited, restricting research on linguistic trends and\nsocietal issues such as gender bias. We present taz2024full, the largest\npublicly available corpus of German newspaper articles to date, comprising over\n1.8 million texts from taz, spanning 1980 to 2024.\n  As a demonstration of the corpus's utility for bias and discrimination\nresearch, we analyse gender representation across four decades of reporting. We\nfind a consistent overrepresentation of men, but also a gradual shift toward\nmore balanced coverage in recent years. Using a scalable, structured analysis\npipeline, we provide a foundation for studying actor mentions, sentiment, and\nlinguistic framing in German journalistic texts.\n  The corpus supports a wide range of applications, from diachronic language\nanalysis to critical media studies, and is freely available to foster inclusive\nand reproducible research in German-language NLP.", "AI": {"tldr": "taz2024full\u662f\u76ee\u524d\u6700\u5927\u7684\u5fb7\u8bed\u62a5\u7eb8\u6587\u7ae0\u516c\u5f00\u8bed\u6599\u5e93\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u6027\u522b\u4ee3\u8868\u6027\u7b49\u8bed\u8a00\u548c\u793e\u4f1a\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u5fb7\u8bed\u7684\u5927\u89c4\u6a21\u8d44\u6e90\u6709\u9650\uff0c\u9650\u5236\u4e86\u5bf9\u8bed\u8a00\u8d8b\u52bf\u548c\u793e\u4f1a\u95ee\u9898\uff08\u5982\u6027\u522b\u504f\u89c1\uff09\u7684\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u5e9e\u5927\u7684\u5fb7\u8bed\u8bed\u6599\u5e93\u3002", "method": "\u4f7f\u7528\u53ef\u6269\u5c55\u7684\u7ed3\u6784\u5316\u5206\u6790\u7a0b\u5e8f\uff0c\u7814\u7a76\u62a5\u5bfc\u4e2d\u7684\u6f14\u5458\u63d0\u53ca\u3001\u60c5\u611f\u4ee5\u53ca\u8bed\u8a00\u6846\u67b6\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u62a5\u9053\u4e2d\u7537\u6027\u88ab\u8fc7\u5ea6\u4ee3\u8868\uff0c\u4f46\u8fd1\u5e74\u6765\u9010\u6e10\u8d8b\u5411\u4e8e\u66f4\u52a0\u5e73\u8861\u7684\u62a5\u9053\u3002", "conclusion": "taz2024full\u8bed\u6599\u5e93\u4e3a\u7814\u7a76\u5fb7\u8bed\u8bed\u5883\u4e2d\u7684\u504f\u89c1\u548c\u6b67\u89c6\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u652f\u6301\u5404\u79cd\u5e94\u7528\u5e76\u4fc3\u8fdb\u5305\u5bb9\u6027\u548c\u53ef\u91cd\u590d\u6027\u7814\u7a76\u3002"}}
{"id": "2506.05433", "pdf": "https://arxiv.org/pdf/2506.05433", "abs": "https://arxiv.org/abs/2506.05433", "authors": ["Zikang Liu", "Tongtian Yue", "Yepeng Tang", "Longteng Guo", "Junxian Cai", "Qingbin Liu", "Xi Chen", "Jing Liu"], "title": "Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, technical report", "summary": "Group Relative Policy Optimization (GRPO) enhances policy learning by\ncomputing gradients from relative comparisons among candidate outputs that\nshare a common input prefix. Despite its effectiveness, GRPO introduces\nsubstantial computational overhead when processing long shared prefixes, which\nmust be redundantly encoded for each group member. This inefficiency becomes a\nmajor scalability bottleneck in long-context learning scenarios. We propose\nPrefix Grouper, an efficient GRPO training algorithm that eliminates redundant\nprefix computation via a Shared-Prefix Forward strategy. In particular, by\nrestructuring self-attention into two parts, our method enables the shared\nprefix to be encoded only once, while preserving full differentiability and\ncompatibility with end-to-end training. We provide both theoretical and\nempirical evidence that Prefix Grouper is training-equivalent to standard GRPO:\nit yields identical forward outputs and backward gradients, ensuring that the\noptimization dynamics and final policy performance remain unchanged.\nEmpirically, our experiments confirm that Prefix Grouper achieves consistent\nresults while significantly reducing the computational cost of training,\nparticularly in long-prefix scenarios. The proposed method is fully\nplug-and-play: it is compatible with existing GRPO-based architectures and can\nbe seamlessly integrated into current training pipelines as a drop-in\nreplacement, requiring no structural modifications and only minimal changes to\ninput construction and attention computation. Prefix Grouper enables the use of\nlarger group sizes under the same computational budget, thereby improving the\nscalability of GRPO to more complex tasks and larger models. Code is now\navailable at https://github.com/johncaged/PrefixGrouper", "AI": {"tldr": "Prefix Grouper reduces GRPO's computational costs by eliminating redundant prefix encoding, improving scalability without affecting outcomes.", "motivation": "The motivation is to address the computational inefficiency in GRPO when dealing with long shared prefixes, which incurs substantial overhead due to redundant encoding for each group member, hence posing scalability challenges.", "method": "The method, called Prefix Grouper, eliminates redundant computations by restructuring self-attention into two parts. This allows the shared prefix to be encoded only once using a Shared-Prefix Forward strategy, maintaining full differentiability and end-to-end training compatibility.", "result": "Experimental results demonstrate that Prefix Grouper achieves equivalent training outcomes as standard GRPO while drastically reducing the computational expense, confirming its efficacy in long-prefix contexts.", "conclusion": "Prefix Grouper method retains the same forward outputs and backward gradients as standard GRPO while significantly reducing computational costs, especially in scenarios involving long prefixes. It enables larger group sizes under the same computational resources, thus improving the scalability of GRPO."}}
{"id": "2506.05529", "pdf": "https://arxiv.org/pdf/2506.05529", "abs": "https://arxiv.org/abs/2506.05529", "authors": ["Rodney Sanchez", "Ferat Sahin", "Alexander Ororbia", "Jamison Heard"], "title": "Avoiding Death through Fear Intrinsic Conditioning", "categories": ["cs.AI", "cs.LG", "I.2.0; I.2.8"], "comment": null, "summary": "Biological and psychological concepts have inspired reinforcement learning\nalgorithms to create new complex behaviors that expand agents' capacity. These\nbehaviors can be seen in the rise of techniques like goal decomposition,\ncurriculum, and intrinsic rewards, which have paved the way for these complex\nbehaviors. One limitation in evaluating these methods is the requirement for\nengineered extrinsic for realistic environments. A central challenge in\nengineering the necessary reward function(s) comes from these environments\ncontaining states that carry high negative rewards, but provide no feedback to\nthe agent. Death is one such stimuli that fails to provide direct feedback to\nthe agent. In this work, we introduce an intrinsic reward function inspired by\nearly amygdala development and produce this intrinsic reward through a novel\nmemory-augmented neural network (MANN) architecture. We show how this intrinsic\nmotivation serves to deter exploration of terminal states and results in\navoidance behavior similar to fear conditioning observed in animals.\nFurthermore, we demonstrate how modifying a threshold where the fear response\nis active produces a range of behaviors that are described under the paradigm\nof general anxiety disorders (GADs). We demonstrate this behavior in the\nMiniworld Sidewalk environment, which provides a partially observable Markov\ndecision process (POMDP) and a sparse reward with a non-descriptive terminal\ncondition, i.e., death. In effect, this study results in a\nbiologically-inspired neural architecture and framework for fear conditioning\nparadigms; we empirically demonstrate avoidance behavior in a constructed agent\nthat is able to solve environments with non-descriptive terminal conditions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u5f15\u5165\u5185\u5728\u5956\u52b1\uff0c\u6210\u529f\u6a21\u62df\u52a8\u7269\u89c4\u907f\u884c\u4e3a\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u5728\u5177\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\u7684\u73af\u5883\u4e2d\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "\u53d7\u5230\u751f\u7269\u548c\u5fc3\u7406\u5b66\u6982\u5ff5\u7684\u542f\u53d1\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u521b\u9020\u590d\u6742\u884c\u4e3a\u4ee5\u6269\u5c55\u667a\u80fd\u4f53\u7684\u80fd\u529b\uff0c\u4f46\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\u65f6\u9700\u8981\u5de5\u7a0b\u5316\u7684\u5916\u90e8\u5956\u52b1\u4ee5\u5e94\u5bf9\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u6311\u6218\u3002\u5c24\u5176\u662f\u73af\u5883\u4e2d\u5b58\u5728\u72b6\u6001\u5e26\u6765\u9ad8\u8d1f\u9762\u5956\u52b1\u4f46\u672a\u63d0\u4f9b\u53cd\u9988\u7ed9\u667a\u80fd\u4f53\uff0c\u6bd4\u5982\u6b7b\u4ea1\u8fd9\u4e00\u523a\u6fc0\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5bfb\u6c42\u4e00\u79cd\u5185\u5728\u7684\u5956\u52b1\u65b9\u6cd5\u6765\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff08MANN\uff09\u67b6\u6784\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53d7\u65e9\u671f\u674f\u4ec1\u6838\u53d1\u80b2\u542f\u53d1\u7684\u5185\u5728\u5956\u52b1\u529f\u80fd\uff0c\u7528\u4e8e\u6fc0\u52b1\u89c4\u907f\u884c\u4e3a\u3002\u7814\u7a76\u8fd8\u901a\u8fc7\u4fee\u6539\u6050\u60e7\u54cd\u5e94\u7684\u9608\u503c\uff0c\u4ea7\u751f\u7c7b\u4f3c\u4e00\u822c\u6027\u7126\u8651\u969c\u788d\uff08GADs\uff09\u7684\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u5728Miniworld Sidewalk\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u8868\u73b0\u51fa\u89c4\u907f\u884c\u4e3a\uff0c\u5e76\u89e3\u51b3\u5b58\u5728\u975e\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u73af\u5883\u4e2d\u7684\u95ee\u9898\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u751f\u7269\u5b66\u542f\u53d1\u7684\u5185\u5728\u5956\u52b1\u673a\u5236\uff0c\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u4f53\u7cfb\u7ed3\u6784\u5b9e\u73b0\uff0c\u80fd\u591f\u6210\u529f\u5730\u6a21\u62df\u51fa\u7c7b\u4f3c\u52a8\u7269\u7684\u89c4\u907f\u884c\u4e3a\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u65e0\u63cf\u8ff0\u6027\u7ec8\u7aef\u6761\u4ef6\u7684\u73af\u5883\u4e2d\u89e3\u51b3\u95ee\u9898\u3002"}}
{"id": "2506.05390", "pdf": "https://arxiv.org/pdf/2506.05390", "abs": "https://arxiv.org/abs/2506.05390", "authors": ["Markelle Kelly", "Mohammad Tahaei", "Padhraic Smyth", "Lauren Wilcox"], "title": "Understanding Gender Bias in AI-Generated Product Descriptions", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to FAccT 2025", "summary": "While gender bias in large language models (LLMs) has been extensively\nstudied in many domains, uses of LLMs in e-commerce remain largely unexamined\nand may reveal novel forms of algorithmic bias and harm. Our work investigates\nthis space, developing data-driven taxonomic categories of gender bias in the\ncontext of product description generation, which we situate with respect to\nexisting general purpose harms taxonomies. We illustrate how AI-generated\nproduct descriptions can uniquely surface gender biases in ways that require\nspecialized detection and mitigation approaches. Further, we quantitatively\nanalyze issues corresponding to our taxonomic categories in two models used for\nthis task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these\nforms of bias commonly occur in practice. Our results illuminate unique,\nunder-explored dimensions of gender bias, such as assumptions about clothing\nsize, stereotypical bias in which features of a product are advertised, and\ndifferences in the use of persuasive language. These insights contribute to our\nunderstanding of three types of AI harms identified by current frameworks:\nexclusionary norms, stereotyping, and performance disparities, particularly for\nthe context of e-commerce.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u7535\u5b50\u5546\u52a1\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u5f00\u53d1\u4e86\u5206\u7c7b\u6cd5\u5e76\u8fdb\u884c\u4e86\u91cf\u5316\u5206\u6790\uff0c\u63ed\u793a\u4e86\u4ea7\u54c1\u63cf\u8ff0\u4e2d\u7684\u6027\u522b\u504f\u89c1\u3002", "motivation": "\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u6027\u522b\u504f\u89c1\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u7684\u5e94\u7528\u4ecd\u7f3a\u4e4f\u7814\u7a76\u3002\u7535\u5b50\u5546\u52a1\u53ef\u80fd\u63ed\u793a\u65b0\u7684\u7b97\u6cd5\u504f\u89c1\u548c\u5371\u5bb3\u5f62\u5f0f\u3002", "method": "\u5f00\u53d1\u6570\u636e\u9a71\u52a8\u7684\u6027\u522b\u504f\u89c1\u5206\u7c7b\u6cd5\uff0c\u5206\u6790AI\u751f\u6210\u7684\u4ea7\u54c1\u63cf\u8ff0\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u5e76\u5728\u6b64\u8fc7\u7a0b\u4e2d\u5c06\u5176\u4e0e\u73b0\u6709\u7684\u5371\u5bb3\u5206\u7c7b\u6cd5\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u63ed\u793a\u4e86\u6027\u522b\u504f\u89c1\u7684\u4e00\u4e9b\u72ec\u7279\u800c\u672a\u5145\u5206\u63a2\u7d22\u7684\u7ef4\u5ea6\uff0c\u5982\u5bf9\u670d\u88c5\u5c3a\u5bf8\u7684\u5047\u8bbe\u3001\u4ea7\u54c1\u7279\u5f81\u5e7f\u544a\u4e2d\u7684\u523b\u677f\u504f\u89c1\u4ee5\u53ca\u529d\u8bf4\u8bed\u8a00\u4f7f\u7528\u7684\u5dee\u5f02\u3002\u8fd9\u4e9b\u53d1\u73b0\u52a0\u6df1\u4e86\u6211\u4eec\u5bf9\u7535\u5b50\u5546\u52a1\u80cc\u666f\u4e0bAI\u5371\u5bb3\u5982\u6392\u65a5\u6027\u89c4\u8303\u3001\u523b\u677f\u5370\u8c61\u53ca\u6027\u80fd\u5dee\u5f02\u7684\u7406\u89e3\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u8868\u660e\uff0c\u5728\u7535\u5b50\u5546\u52a1\u9886\u57df\u4f7f\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u6027\u522b\u504f\u89c1\u666e\u904d\u5b58\u5728\uff0c\u9700\u7279\u522b\u7684\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\u3002"}}
{"id": "2506.05542", "pdf": "https://arxiv.org/pdf/2506.05542", "abs": "https://arxiv.org/abs/2506.05542", "authors": ["Vlastimil Martinek", "Andrea Gariboldi", "Dimosthenis Tzimotoudis", "Aitor Alberdi Escudero", "Edward Blake", "David Cechak", "Luke Cassar", "Alessandro Balestrucci", "Panagiotis Alexiou"], "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "The adoption of machine learning (ML) and deep learning methods has\nrevolutionized molecular medicine by driving breakthroughs in genomics,\ntranscriptomics, drug discovery, and biological systems modeling. The\nincreasing quantity, multimodality, and heterogeneity of biological datasets\ndemand automated methods that can produce generalizable predictive models.\nRecent developments in large language model-based agents have shown promise for\nautomating end-to-end ML experimentation on structured benchmarks. However,\nwhen applied to heterogeneous computational biology datasets, these methods\nstruggle with generalization and success rates. Here, we introduce\nAgentomics-ML, a fully autonomous agent-based system designed to produce a\nclassification model and the necessary files for reproducible training and\ninference. Our method follows predefined steps of an ML experimentation\nprocess, repeatedly interacting with the file system through Bash to complete\nindividual steps. Once an ML model is produced, training and validation metrics\nprovide scalar feedback to a reflection step to identify issues such as\noverfitting. This step then creates verbal feedback for future iterations,\nsuggesting adjustments to steps such as data representation, model\narchitecture, and hyperparameter choices. We have evaluated Agentomics-ML on\nseveral established genomic and transcriptomic benchmark datasets and show that\nit outperforms existing state-of-the-art agent-based methods in both\ngeneralization and success rates. While state-of-the-art models built by domain\nexperts still lead in absolute performance on the majority of the computational\nbiology datasets used in this work, Agentomics-ML narrows the gap for fully\nautonomous systems and achieves state-of-the-art performance on one of the used\nbenchmark datasets. The code is available at\nhttps://github.com/BioGeMT/Agentomics-ML.", "AI": {"tldr": "Agentomics-ML\u662f\u4e00\u79cd\u81ea\u4e3b\u7cfb\u7edf\uff0c\u5728\u57fa\u56e0\u7ec4\u548c\u8f6c\u5f55\u7ec4\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u7f29\u5c0f\u4e86\u4e0e\u4e13\u5bb6\u8bbe\u8ba1\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u7528\u4e8e\u5f02\u6784\u8ba1\u7b97\u751f\u7269\u6570\u636e\u96c6\u65f6\uff0c\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u548c\u6210\u529f\u7387\u65b9\u9762\u7684\u6311\u6218\uff0c\u9700\u8981\u81ea\u52a8\u65b9\u6cd5\u751f\u6210\u53ef\u63a8\u5e7f\u7684\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgentomics-ML\u7684\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\uff0c\u9075\u5faa\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u6d41\u7a0b\uff0c\u901a\u8fc7Bash\u4e0e\u6587\u4ef6\u7cfb\u7edf\u4ea4\u4e92\u5b8c\u6210\u5404\u6b65\u9aa4\uff0c\u4ee5\u751f\u6210\u5206\u7c7b\u6a21\u578b\u3002\u4f7f\u7528\u8bad\u7ec3\u548c\u9a8c\u8bc1\u6307\u6807\u4e3a\u53cd\u601d\u6b65\u9aa4\u63d0\u4f9b\u53cd\u9988\uff0c\u4ece\u800c\u8c03\u6574\u6570\u636e\u8868\u793a\u3001\u6a21\u578b\u67b6\u6784\u548c\u8d85\u53c2\u6570\u9009\u62e9\u3002", "result": "\u5728\u591a\u4e2a\u5df2\u5efa\u7acb\u7684\u57fa\u56e0\u7ec4\u548c\u8f6c\u5f55\u7ec4\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30Agentomics-ML\uff0c\u663e\u793a\u5176\u5728\u6cdb\u5316\u548c\u6210\u529f\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Agentomics-ML\u7f29\u5c0f\u4e86\u5168\u81ea\u4e3b\u7cfb\u7edf\u5728\u8ba1\u7b97\u751f\u7269\u5b66\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u5728\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u65b0\u6280\u672f\u6c34\u5e73\u3002"}}
{"id": "2506.05434", "pdf": "https://arxiv.org/pdf/2506.05434", "abs": "https://arxiv.org/abs/2506.05434", "authors": ["Thomas Massena", "L\u00e9o and\u00e9ol", "Thibaut Boissin", "Franck Mamalet", "Corentin Friedrich", "Mathieu Serrurier", "S\u00e9bastien Gerchinovitz"], "title": "Efficient Robust Conformal Prediction via Lipschitz-Bounded Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Conformal Prediction (CP) has proven to be an effective post-hoc method for\nimproving the trustworthiness of neural networks by providing prediction sets\nwith finite-sample guarantees. However, under adversarial attacks, classical\nconformal guarantees do not hold anymore: this problem is addressed in the\nfield of Robust Conformal Prediction. Several methods have been proposed to\nprovide robust CP sets with guarantees under adversarial perturbations, but,\nfor large scale problems, these sets are either too large or the methods are\ntoo computationally demanding to be deployed in real life scenarios. In this\nwork, we propose a new method that leverages Lipschitz-bounded networks to\nprecisely and efficiently estimate robust CP sets. When combined with a\n1-Lipschitz robust network, we demonstrate that our lip-rcp method outperforms\nstate-of-the-art results in both the size of the robust CP sets and\ncomputational efficiency in medium and large-scale scenarios such as ImageNet.\nTaking a different angle, we also study vanilla CP under attack, and derive new\nworst-case coverage bounds of vanilla CP sets, which are valid simultaneously\nfor all adversarial attack levels. Our lip-rcp method makes this second\napproach as efficient as vanilla CP while also allowing robustness guarantees.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u5229\u7528Lipschitz\u6709\u754c\u7f51\u7edc\u6765\u4f30\u8ba1\u9c81\u68d2\u4fdd\u5e8f\u9884\u6d4b\u96c6\u5408\uff0c\u63d0\u5347\u4e86\u5728ImageNet\u7b49\u573a\u666f\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65f6\uff0c\u4f20\u7edf\u4fdd\u5e8f\u9884\u6d4b\u7684\u4fdd\u8bc1\u5931\u6548\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\uff0c\u4fdd\u8bc1\u7684\u4fdd\u5e8f\u9884\u6d4b\u96c6\u5408\u8981\u4e48\u8fc7\u5927\uff0c\u8981\u4e48\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\uff0c\u96be\u4ee5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u90e8\u7f72\u3002\u672c\u6587\u7684\u76ee\u7684\u662f\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u51c6\u786e\u7684\u9c81\u68d2\u96c6\u5408\u53c8\u80fd\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u4f7f\u7528Lipschitz\u6709\u754c\u7f51\u7edc\u6765\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u4f30\u8ba1\u9c81\u68d2\u4fdd\u5e8f\u9884\u6d4b\u96c6\u5408\u7684\u65b9\u6cd5\u3002\u7ed3\u54081-Lipschitz\u9c81\u68d2\u7f51\u7edc\uff0c\u6210\u679c\u5728\u4f30\u7b97\u7cbe\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "result": "\u65b0\u7684lip-rcp\u65b9\u6cd5\u5728\u4e2d\u5927\u89c4\u6a21\u95ee\u9898\u4e0a\u8d85\u8fc7\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u66f4\u5c0f\u4e14\u8ba1\u7b97\u4e0a\u66f4\u9ad8\u6548\u7684\u9c81\u68d2CP\u96c6\u5408\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u7ecf\u5178CP\u5728\u653b\u51fb\u4e0b\u7684\u60c5\u51b5\uff0c\u5f97\u51fa\u4e86\u540c\u65f6\u5bf9\u6240\u6709\u653b\u51fb\u7b49\u7ea7\u6709\u6548\u7684\u65b0\u6700\u574f\u60c5\u51b5\u8986\u76d6\u754c\u9650\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528Lipschitz\u6709\u754c\u7f51\u7edc\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u7cbe\u786e\u548c\u9ad8\u6548\u5730\u4f30\u8ba1\u9c81\u68d2\u7684\u4fdd\u5e8f\u9884\u6d4b\uff08CP\uff09\u96c6\u5408\u3002\u7ed3\u54081-Lipschitz\u9c81\u68d2\u7f51\u7edc\uff0c\u6211\u4eec\u7684lip-rcp\u65b9\u6cd5\u5728\u4e2d\u5927\u89c4\u6a21\u573a\u666f\uff08\u5982ImageNet\uff09\u4e2d\uff0c\u5728\u9c81\u68d2CP\u96c6\u5408\u7684\u5927\u5c0f\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.05579", "pdf": "https://arxiv.org/pdf/2506.05579", "abs": "https://arxiv.org/abs/2506.05579", "authors": ["Quan Shi", "Carlos E. Jimenez", "Shunyu Yao", "Nick Haber", "Diyi Yang", "Karthik Narasimhan"], "title": "When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration", "categories": ["cs.AI", "cs.CL", "cs.HC"], "comment": "For code, data, visualizer, visit: https:kite-live.vercel.app", "summary": "Recent advancements in AI reasoning have driven substantial improvements\nacross diverse tasks. A critical open question is whether these improvements\nalso yields better knowledge transfer: the ability of models to communicate\nreasoning in ways humans can understand, apply, and learn from. To investigate\nthis, we introduce Knowledge Integration and Transfer Evaluation (KITE), a\nconceptual and experimental framework for Human-AI knowledge transfer\ncapabilities and conduct the first large-scale human study (N=118) explicitly\ndesigned to measure it. In our two-phase setup, humans first ideate with an AI\non problem-solving strategies, then independently implement solutions,\nisolating model explanations' influence on human understanding. Our findings\nreveal that although model benchmark performance correlates with collaborative\noutcomes, this relationship is notably inconsistent, featuring significant\noutliers, indicating that knowledge transfer requires dedicated optimization.\nOur analysis identifies behavioral and strategic factors mediating successful\nknowledge transfer. We release our code, dataset, and evaluation framework to\nsupport future work on communicatively aligned models.", "AI": {"tldr": "Introduced KITE framework to study human-AI knowledge transfer. Found inconsistent correlation between model performance and knowledge transfer, highlighting the need for optimization.", "motivation": "Investigate whether improvements in AI reasoning also enhance knowledge transfer, i.e., the ability for AI models to communicate reasoning effectively to humans.", "method": "Two-phase setup where humans first ideate with AI on problem-solving strategies, then independently implement solutions to measure the influence of model explanations on human understanding.", "result": "Model benchmark performance correlates inconsistently with collaborative outcomes, featuring significant outliers. Behavioral and strategic factors are identified as mediators of successful knowledge transfer.", "conclusion": "Knowledge transfer requires dedicated optimization as model benchmark performance does not consistently correlate with successful human-AI collaborative outcomes."}}
{"id": "2506.05393", "pdf": "https://arxiv.org/pdf/2506.05393", "abs": "https://arxiv.org/abs/2506.05393", "authors": ["Shenyang Huang", "Ali Parviz", "Emma Kondrup", "Zachary Yang", "Zifeng Ding", "Michael Bronstein", "Reihaneh Rabbany", "Guillaume Rabusseau"], "title": "Are Large Language Models Good Temporal Graph Learners?", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages, 9 tables, 4 figures", "summary": "Large Language Models (LLMs) have recently driven significant advancements in\nNatural Language Processing and various other applications. While a broad range\nof literature has explored the graph-reasoning capabilities of LLMs, including\ntheir use of predictors on graphs, the application of LLMs to dynamic graphs --\nreal world evolving networks -- remains relatively unexplored. Recent work\nstudies synthetic temporal graphs generated by random graph models, but\napplying LLMs to real-world temporal graphs remains an open question. To\naddress this gap, we introduce Temporal Graph Talker (TGTalker), a novel\ntemporal graph learning framework designed for LLMs. TGTalker utilizes the\nrecency bias in temporal graphs to extract relevant structural information,\nconverted to natural language for LLMs, while leveraging temporal neighbors as\nadditional information for prediction. TGTalker demonstrates competitive link\nprediction capabilities compared to existing Temporal Graph Neural Network\n(TGNN) models. Across five real-world networks, TGTalker performs competitively\nwith state-of-the-art temporal graph methods while consistently outperforming\npopular models such as TGN and HTGN. Furthermore, TGTalker generates textual\nexplanations for each prediction, thus opening up exciting new directions in\nexplainability and interpretability for temporal link prediction. The code is\npublicly available at https://github.com/shenyangHuang/TGTalker.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86TGTalker\uff0c\u4e00\u79cd\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u65b0\u578b\u65f6\u95f4\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u94fe\u63a5\u9884\u6d4b\u80fd\u529b\u548c\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u5728\u52a8\u6001\u56fe\u4e0a\u5e94\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u6d89\u53ca\u771f\u5b9e\u4e16\u754c\u7684\u53d8\u5316\u7f51\u7edc\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "TGTalker\u5229\u7528\u65f6\u95f4\u56fe\u4e2d\u7684\u6700\u8fd1\u504f\u7f6e\u6765\u63d0\u53d6\u7ed3\u6784\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u4f9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\uff0c\u540c\u65f6\u5229\u7528\u65f6\u95f4\u90bb\u5c45\u4f5c\u4e3a\u9884\u6d4b\u7684\u9644\u52a0\u4fe1\u606f\u3002", "result": "TGTalker\u5728\u94fe\u63a5\u9884\u6d4b\u80fd\u529b\u4e0a\u4e0e\u73b0\u6709\u7684\u65f6\u95f4\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u4e8e\u6d41\u884c\u6a21\u578b\u5982TGN\u548cHTGN\u3002", "conclusion": "TGTalker\u5728\u4e94\u4e2a\u771f\u5b9e\u4e16\u754c\u7f51\u7edc\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e14\u5728\u89e3\u91ca\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.05577", "pdf": "https://arxiv.org/pdf/2506.05577", "abs": "https://arxiv.org/abs/2506.05577", "authors": ["Saptarshi Nath", "Christos Peridis", "Eseoghene Benjamin", "Xinran Liu", "Soheil Kolouri", "Peter Kinnell", "Zexin Li", "Cong Liu", "Shirin Dora", "Andrea Soltoggio"], "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.6; I.2.11"], "comment": "36 pages, 21 figures, 6 tables. Preprint", "summary": "Agentic AI has gained significant interest as a research paradigm focused on\nautonomy, self-directed learning, and long-term reliability of decision making.\nReal-world agentic systems operate in decentralized settings on a large set of\ntasks or data distributions with constraints such as limited bandwidth,\nasynchronous execution, and the absence of a centralized model or even common\nobjectives. We posit that exploiting previously learned skills, task\nsimilarities, and communication capabilities in a collective of agentic AI are\nchallenging but essential elements to enabling scalability, open-endedness, and\nbeneficial collaborative learning dynamics. In this paper, we introduce Modular\nSharing and Composition in Collective Learning (MOSAIC), an agentic algorithm\nthat allows multiple agents to independently solve different tasks while also\nidentifying, sharing, and reusing useful machine-learned knowledge, without\ncoordination, synchronization, or centralized control. MOSAIC combines three\nmechanisms: (1) modular policy composition via neural network masks, (2) cosine\nsimilarity estimation using Wasserstein embeddings for knowledge selection, and\n(3) asynchronous communication and policy integration. Results on a set of RL\nbenchmarks show that MOSAIC has a greater sample efficiency than isolated\nlearners, i.e., it learns significantly faster, and in some cases, finds\nsolutions to tasks that cannot be solved by isolated learners. The\ncollaborative learning and sharing dynamics are also observed to result in the\nemergence of ideal curricula of tasks, from easy to hard. These findings\nsupport the case for collaborative learning in agentic systems to achieve\nbetter and continuously evolving performance both at the individual and\ncollective levels.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMOSAIC\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u3001\u4f59\u5f26\u76f8\u4f3c\u6027\u4f30\u7b97\u3001\u5f02\u6b65\u901a\u4fe1\u5b9e\u73b0\u591a\u4e2a\u4ee3\u7406\u72ec\u7acb\u89e3\u51b3\u4efb\u52a1\uff0c\u5e76\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u5728\u5206\u6563\u73af\u5883\u4e2d\uff0c\u4ee3\u7406\u7cfb\u7edf\u9762\u4e34\u5e26\u5bbd\u9650\u5236\u3001\u5f02\u6b65\u6267\u884c\u4ee5\u53ca\u7f3a\u4e4f\u96c6\u4e2d\u6a21\u578b\u6216\u5171\u540c\u76ee\u6807\u7684\u6311\u6218\u3002\u5229\u7528\u4ee5\u524d\u5b66\u4e60\u7684\u6280\u80fd\u3001\u4efb\u52a1\u76f8\u4f3c\u6027\u548c\u901a\u4fe1\u80fd\u529b\u662f\u5b9e\u73b0\u6269\u5c55\u6027\u3001\u5f00\u653e\u6027\u548c\u6709\u76ca\u534f\u4f5c\u5b66\u4e60\u52a8\u6001\u7684\u5173\u952e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aMOSAIC\u7684\u4ee3\u7406\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u673a\u5236\u6765\u5b9e\u73b0\uff1a1. \u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u63a9\u7801\u8fdb\u884c\u6a21\u5757\u5316\u7b56\u7565\u7ec4\u5408\uff1b2. \u4f7f\u7528Wasserstein\u5d4c\u5165\u8fdb\u884c\u4f59\u5f26\u76f8\u4f3c\u6027\u4f30\u7b97\u7528\u4e8e\u77e5\u8bc6\u9009\u62e9\uff1b3. \u5f02\u6b65\u901a\u4fe1\u548c\u7b56\u7565\u6574\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMOSAIC\u5728\u4e00\u4e9b\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5177\u6709\u6bd4\u5b64\u7acb\u5b66\u4e60\u8005\u66f4\u5927\u7684\u6837\u672c\u6548\u7387\uff0c\u5373\u5b66\u4e60\u901f\u5ea6\u663e\u8457\u66f4\u5feb\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u89e3\u51b3\u5b64\u7acb\u5b66\u4e60\u8005\u65e0\u6cd5\u89e3\u51b3\u7684\u4efb\u52a1\u3002\u8fd8\u89c2\u5bdf\u5230\u534f\u4f5c\u5b66\u4e60\u548c\u5171\u4eab\u52a8\u6001\u4f1a\u5bfc\u81f4\u4efb\u52a1\u7406\u60f3\u8def\u5f84\u7684\u51fa\u73b0\uff0c\u4ece\u7b80\u5355\u5230\u56f0\u96be\u3002", "conclusion": "\u534f\u4f5c\u5b66\u4e60\u5728\u81ea\u4e3b\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u652f\u6301\u4e86\u66f4\u597d\u7684\u548c\u4e0d\u65ad\u53d1\u5c55\u7684\u6027\u80fd\uff0c\u4ece\u4e2a\u4f53\u548c\u96c6\u5408\u6c34\u5e73\u6765\u770b\u90fd\u80fd\u83b7\u5f97\u63d0\u5347\u3002"}}
{"id": "2506.05435", "pdf": "https://arxiv.org/pdf/2506.05435", "abs": "https://arxiv.org/abs/2506.05435", "authors": ["Manon Renault", "Hamoud Younes", "Hugo Tessier", "Ronan Le Roy", "Bastien Pasdeloup", "Mathieu L\u00e9onardon"], "title": "Event Classification of Accelerometer Data for Industrial Package Monitoring with Embedded Deep Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Package monitoring is an important topic in industrial applications, with\nsignificant implications for operational efficiency and ecological\nsustainability. In this study, we propose an approach that employs an embedded\nsystem, placed on reusable packages, to detect their state (on a Forklift, in a\nTruck, or in an undetermined location). We aim to design a system with a\nlifespan of several years, corresponding to the lifespan of reusable packages.\nOur analysis demonstrates that maximizing device lifespan requires minimizing\nwake time. We propose a pipeline that includes data processing, training, and\nevaluation of the deep learning model designed for imbalanced, multiclass time\nseries data collected from an embedded sensor. The method uses a\none-dimensional Convolutional Neural Network architecture to classify\naccelerometer data from the IoT device. Before training, two data augmentation\ntechniques are tested to solve the imbalance problem of the dataset: the\nSynthetic Minority Oversampling TEchnique and the ADAptive SYNthetic sampling\napproach. After training, compression techniques are implemented to have a\nsmall model size. On the considered twoclass problem, the methodology yields a\nprecision of 94.54% for the first class and 95.83% for the second class, while\ncompression techniques reduce the model size by a factor of four. The trained\nmodel is deployed on the IoT device, where it operates with a power consumption\nof 316 mW during inference.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5d4c\u5165\u5f0f\u7cfb\u7edf\u548c\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u5305\u88f9\u72b6\u6001\u68c0\u6d4b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u538b\u7f29\u6280\u672f\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u8bbe\u8ba1\u4e00\u79cd\u80fd\u5728\u6570\u5e74\u5185\u53ef\u9760\u8fd0\u884c\u5e76\u7cbe\u51c6\u68c0\u6d4b\u53ef\u91cd\u590d\u4f7f\u7528\u5305\u88f9\u72b6\u6001\u7684\u7cfb\u7edf\uff0c\u63d0\u5347\u64cd\u4f5c\u6548\u7387\u5e76\u4fc3\u8fdb\u751f\u6001\u53ef\u6301\u7eed\u6027\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6765\u5bf9\u6765\u81ea\u5d4c\u5165\u5f0f\u4f20\u611f\u5668\u7684\u52a0\u901f\u5ea6\u8ba1\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002\u4e3a\u89e3\u51b3\u6570\u636e\u96c6\u7684\u4e0d\u5e73\u8861\uff0c\u7814\u7a76\u5728\u8bad\u7ec3\u524d\u6d4b\u8bd5\u4e86\u4e24\u79cd\u6570\u636e\u589e\u5f3a\u6280\u672f\uff1a\u5408\u6210\u5c11\u6570\u8fc7\u91c7\u6837\u6280\u672f\uff08SMOTE\uff09\u548c\u81ea\u9002\u5e94\u5408\u6210\u91c7\u6837\u65b9\u6cd5\uff08ADASYN\uff09\u3002\u8bad\u7ec3\u540e\uff0c\u538b\u7f29\u6280\u672f\u88ab\u5e94\u7528\u4ee5\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u3002", "result": "\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u65b9\u6cd5\u5bf9\u7b2c\u4e00\u7c7b\u7684\u7cbe\u5ea6\u4e3a94.54%\uff0c\u5bf9\u7b2c\u4e8c\u7c7b\u7684\u7cbe\u5ea6\u4e3a95.83%\uff0c\u540c\u65f6\u538b\u7f29\u6280\u672f\u5c06\u6a21\u578b\u5927\u5c0f\u7f29\u5c0f\u4e86\u56db\u500d\u3002\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u90e8\u7f72\u5728IoT\u8bbe\u5907\u4e0a\uff0c\u4e8e\u63a8\u7406\u65f6\u529f\u8017\u4e3a316 mW\u3002", "conclusion": "\u672c\u6587\u8bbe\u8ba1\u7684\u7cfb\u7edf\u6210\u529f\u5728IoT\u8bbe\u5907\u4e0a\u90e8\u7f72\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u72b6\u6001\u5206\u7c7b\uff0c\u5177\u5907\u9ad8\u7cbe\u5ea6\u548c\u4f4e\u529f\u8017\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u5305\u88f9\u72b6\u6001\u68c0\u6d4b\u95ee\u9898\u3002"}}
{"id": "2506.05587", "pdf": "https://arxiv.org/pdf/2506.05587", "abs": "https://arxiv.org/abs/2506.05587", "authors": ["Junjie Xing", "Yeye He", "Mengyu Zhou", "Haoyu Dong", "Shi Han", "Lingjiao Chen", "Dongmei Zhang", "Surajit Chaudhuri", "H. V. Jagadish"], "title": "MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark", "categories": ["cs.AI", "cs.CL", "cs.DB", "cs.LG"], "comment": null, "summary": "Tables and table-based use cases play a crucial role in many important\nreal-world applications, such as spreadsheets, databases, and computational\nnotebooks, which traditionally require expert-level users like data engineers,\ndata analysts, and database administrators to operate. Although LLMs have shown\nremarkable progress in working with tables (e.g., in spreadsheet and database\ncopilot scenarios), comprehensive benchmarking of such capabilities remains\nlimited. In contrast to an extensive and growing list of NLP benchmarks,\nevaluations of table-related tasks are scarce, and narrowly focus on tasks like\nNL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks\nthat professional users face. This gap limits our understanding and model\nprogress in this important area.\n  In this work, we introduce MMTU, a large-scale benchmark with over 30K\nquestions across 25 real-world table tasks, designed to comprehensively\nevaluate models ability to understand, reason, and manipulate real tables at\nthe expert-level. These tasks are drawn from decades' worth of computer science\nresearch on tabular data, with a focus on complex table tasks faced by\nprofessional users. We show that MMTU require a combination of skills --\nincluding table understanding, reasoning, and coding -- that remain challenging\nfor today's frontier models, where even frontier reasoning models like OpenAI\no4-mini and DeepSeek R1 score only around 60%, suggesting significant room for\nimprovement. We highlight key findings in our evaluation using MMTU and hope\nthat this benchmark drives further advances in understanding and developing\nfoundation models for structured data processing and analysis. Our code and\ndata are available at https://github.com/MMTU-Benchmark/MMTU and\nhttps://huggingface.co/datasets/MMTU-benchmark/MMTU.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u9879\u9762\u5411\u8868\u683c\u4efb\u52a1\u7684\u57fa\u51c6MMTU\uff0c\u8bc4\u4f30\u73b0\u4ee3\u6a21\u578b\u5728\u8868\u683c\u6570\u636e\u5904\u7406\u4e0a\u7684\u80fd\u529b\uff0c\u5e76\u663e\u793a\u51fa\u5f53\u524d\u6a21\u578b\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u586b\u8865\u5f53\u524dLLMs\u5728\u5904\u7406\u8868\u683c\u4efb\u52a1\u8bc4\u4f30\u4e0a\u7684\u7a7a\u767d\uff0c\u4ee5\u63a8\u52a8\u5bf9\u7ed3\u6784\u5316\u6570\u636e\u5904\u7406\u548c\u5206\u6790\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u9879\u540d\u4e3aMMTU\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u4e13\u5bb6\u7ea7\u522b\u4e0a\u7406\u89e3\u3001\u63a8\u7406\u548c\u64cd\u63a7\u771f\u5b9e\u8868\u683c\u7684\u80fd\u529b\u3002\u4efb\u52a1\u4ece\u51e0\u5341\u5e74\u7684\u5173\u4e8e\u8868\u6570\u636e\u7684\u8ba1\u7b97\u673a\u79d1\u5b66\u7814\u7a76\u4e2d\u6c72\u53d6\u7075\u611f\u3002", "result": "\u5305\u62ecOpenAI o4-mini\u548cDeepSeek R1\u5728\u5185\u7684\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u5728MMTU\u8bc4\u4f30\u4e2d\u4ec5\u5f97\u5206\u7ea660%\uff0c\u8fd9\u8868\u660e\u5b58\u5728\u663e\u8457\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "MMTU\u57fa\u51c6\u901a\u8fc7\u8bc4\u4f3030K\u4e2a\u95ee\u9898\u548c25\u4e2a\u771f\u5b9e\u4e16\u754c\u8868\u4efb\u52a1\uff0c\u663e\u793a\u51fa\u73b0\u4ee3\u6a21\u578b\u5728\u7406\u89e3\u3001\u63a8\u7406\u548c\u64cd\u4f5c\u771f\u5b9e\u8868\u683c\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5f00\u653e\u4e86\u6539\u8fdb\u7684\u7a7a\u95f4\u3002"}}
{"id": "2506.05400", "pdf": "https://arxiv.org/pdf/2506.05400", "abs": "https://arxiv.org/abs/2506.05400", "authors": ["Ayesha Qamar", "Arushi Raghuvanshi", "Conal Sathi", "Youngseo Son"], "title": "Auto Review: Second Stage Error Detection for Highly Accurate Information Extraction from Phone Conversations", "categories": ["cs.CL"], "comment": "Accepted to ACL Industry track 2025", "summary": "Automating benefit verification phone calls saves time in healthcare and\nhelps patients receive treatment faster. It is critical to obtain highly\naccurate information in these phone calls, as it can affect a patient's\nhealthcare journey. Given the noise in phone call transcripts, we have a\ntwo-stage system that involves a post-call review phase for potentially noisy\nfields, where human reviewers manually verify the extracted\ndata$\\unicode{x2013}$a labor-intensive task. To automate this stage, we\nintroduce Auto Review, which significantly reduces manual effort while\nmaintaining a high bar for accuracy. This system, being highly reliant on call\ntranscripts, suffers a performance bottleneck due to automatic speech\nrecognition (ASR) issues. This problem is further exacerbated by the use of\ndomain-specific jargon in the calls. In this work, we propose a second-stage\npostprocessing pipeline for accurate information extraction. We improve\naccuracy by using multiple ASR alternatives and a pseudo-labeling approach that\ndoes not require manually corrected transcripts. Experiments with\ngeneral-purpose large language models and feature-based model pipelines\ndemonstrate substantial improvements in the quality of corrected call\ntranscripts, thereby enhancing the efficiency of Auto Review.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faAuto Review\u7cfb\u7edf\uff0c\u65e8\u5728\u901a\u8fc7\u6539\u5584\u7535\u8bdd\u8bb0\u5f55\u7684\u51c6\u786e\u6027\u6765\u51cf\u5c11\u4eba\u5de5\u5ba1\u6838\u5de5\u4f5c\u91cf\uff0c\u5e76\u6539\u5584\u533b\u7597\u670d\u52a1\u6548\u7387\u3002", "motivation": "\u5728\u7535\u8bdd\u8bb0\u5f55\u4e2d\u566a\u58f0\u8f83\u5927\uff0c\u4e3a\u4e86\u51cf\u5c11\u4eba\u5de5\u5ba1\u6838\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\uff0c\u9700\u8981\u81ea\u52a8\u5316\u540e\u7eed\u5904\u7406\u9636\u6bb5\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u4e8c\u9636\u6bb5\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u5229\u7528\u591a\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u66ff\u4ee3\u65b9\u6848\u548c\u4e00\u79cd\u4e0d\u9700\u8981\u624b\u52a8\u6821\u6b63\u7684\u4f2a\u6807\u7b7e\u65b9\u6cd5\u6765\u8fdb\u884c\u4fe1\u606f\u63d0\u53d6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u5229\u7528\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u4e8e\u7279\u5f81\u7684\u6a21\u578b\u7ba1\u9053\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u8bdd\u8bb0\u5f55\u6821\u6b63\u7684\u8d28\u91cf\uff0c\u63d0\u5347\u4e86Auto Review\u7684\u6548\u7387\u3002", "conclusion": "Auto Review\u7cfb\u7edf\u901a\u8fc7\u4f7f\u7528\u591a\u79cdASR\u66ff\u4ee3\u65b9\u6848\u548c\u4f2a\u6807\u7b7e\u65b9\u6cd5\uff0c\u5728\u65e0\u9700\u4eba\u5de5\u6821\u6b63\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u7535\u8bdd\u8bb0\u5f55\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u6548\u7387\u3002"}}
{"id": "2506.06136", "pdf": "https://arxiv.org/pdf/2506.06136", "abs": "https://arxiv.org/abs/2506.06136", "authors": ["Kaiyuan Chen", "Wanpeng Zhao", "Yongxi Liu", "Yuanqing Xia", "Wannian Liang", "Shuo Wang"], "title": "UAV-UGV Cooperative Trajectory Optimization and Task Allocation for Medical Rescue Tasks in Post-Disaster Environments", "categories": ["cs.RO", "cs.MA"], "comment": null, "summary": "In post-disaster scenarios, rapid and efficient delivery of medical resources\nis critical and challenging due to severe damage to infrastructure. To provide\nan optimized solution, we propose a cooperative trajectory optimization and\ntask allocation framework leveraging unmanned aerial vehicles (UAVs) and\nunmanned ground vehicles (UGVs). This study integrates a Genetic Algorithm (GA)\nfor efficient task allocation among multiple UAVs and UGVs, and employs an\ninformed-RRT* (Rapidly-exploring Random Tree Star) algorithm for collision-free\ntrajectory generation. Further optimization of task sequencing and path\nefficiency is conducted using Covariance Matrix Adaptation Evolution Strategy\n(CMA-ES). Simulation experiments conducted in a realistic post-disaster\nenvironment demonstrate that our proposed approach significantly improves the\noverall efficiency of medical rescue operations compared to traditional\nstrategies, showing substantial reductions in total mission completion time and\ntraveled distance. Additionally, the cooperative utilization of UAVs and UGVs\neffectively balances their complementary advantages, highlighting the system' s\nscalability and practicality for real-world deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u4eba\u673a\u548c\u5730\u9762\u8f66\u8f86\u534f\u4f5c\u7684\u4efb\u52a1\u5206\u914d\u548c\u8f68\u8ff9\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u707e\u540e\u533b\u7597\u8d44\u6e90\u7684\u8fd0\u9001\u6548\u7387\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u8ddd\u79bb\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7b56\u7565\u3002", "motivation": "\u5728\u707e\u540e\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u57fa\u7840\u8bbe\u65bd\u4e25\u91cd\u53d7\u635f\uff0c\u8fc5\u901f\u9ad8\u6548\u5730\u8fd0\u9001\u533b\u7597\u8d44\u6e90\u81f3\u5173\u91cd\u8981\u4e14\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u4ee5\u63d0\u9ad8\u6551\u63f4\u6548\u7387\u3002", "method": "\u7814\u7a76\u7efc\u5408\u5e94\u7528\u9057\u4f20\u7b97\u6cd5(GA)\u8fdb\u884c\u4efb\u52a1\u5206\u914d\uff0c\u5e76\u91c7\u7528\u6539\u8fdb\u7684RRT*\u7b97\u6cd5\u8fdb\u884c\u65e0\u78b0\u649e\u8f68\u8ff9\u751f\u6210\uff0c\u540c\u65f6\u5229\u7528\u534f\u65b9\u5dee\u77e9\u9635\u9002\u5e94\u8fdb\u5316\u7b56\u7565(CMA-ES)\u5bf9\u4efb\u52a1\u987a\u5e8f\u548c\u8def\u5f84\u6548\u7387\u8fdb\u884c\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7b56\u7565\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u884c\u9a76\u8ddd\u79bb\uff0c\u63d0\u9ad8\u4e86\u6551\u63f4\u6548\u7387\u3002\u7cfb\u7edf\u5c55\u793a\u4e86\u5176\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u5408\u4f5c\u5229\u7528\u65e0\u4eba\u673a\u548c\u65e0\u4eba\u5730\u9762\u8f66\u8f86\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u5728\u6a21\u62df\u7684\u771f\u5b9e\u707e\u540e\u73af\u5883\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u533b\u7597\u6551\u63f4\u64cd\u4f5c\u7684\u6574\u4f53\u6548\u7387\uff0c\u4e0e\u4f20\u7edf\u7b56\u7565\u76f8\u6bd4\uff0c\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u548c\u884c\u9a76\u8ddd\u79bb\u5927\u5e45\u51cf\u5c11\uff0c\u8868\u660e\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2506.05438", "pdf": "https://arxiv.org/pdf/2506.05438", "abs": "https://arxiv.org/abs/2506.05438", "authors": ["Tongda Sun", "Chen Yin", "Huailiang Zheng", "Yining Dong"], "title": "An Unsupervised Framework for Dynamic Health Indicator Construction and Its Application in Rolling Bearing Prognostics", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Health indicator (HI) plays a key role in degradation assessment and\nprognostics of rolling bearings. Although various HI construction methods have\nbeen investigated, most of them rely on expert knowledge for feature extraction\nand overlook capturing dynamic information hidden in sequential degradation\nprocesses, which limits the ability of the constructed HI for degradation trend\nrepresentation and prognostics. To address these concerns, a novel dynamic HI\nthat considers HI-level temporal dependence is constructed through an\nunsupervised framework. Specifically, a degradation feature learning module\ncomposed of a skip-connection-based autoencoder first maps raw signals to a\nrepresentative degradation feature space (DFS) to automatically extract\nessential degradation features without the need for expert knowledge.\nSubsequently, in this DFS, a new HI-generating module embedded with an inner\nHI-prediction block is proposed for dynamic HI construction, where the temporal\ndependence between past and current HI states is guaranteed and modeled\nexplicitly. On this basis, the dynamic HI captures the inherent dynamic\ncontents of the degradation process, ensuring its effectiveness for degradation\ntendency modeling and future degradation prognostics. The experiment results on\ntwo bearing lifecycle datasets demonstrate that the proposed HI construction\nmethod outperforms comparison methods, and the constructed dynamic HI is\nsuperior for prognostic tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u76d1\u7763\u6846\u67b6\u6784\u5efa\u52a8\u6001\u5065\u5eb7\u6307\u6807(HI)\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u6355\u6349\u9000\u5316\u8fc7\u7a0b\u7684\u52a8\u6001\u4fe1\u606f\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5065\u5eb7\u6307\u6807(HI)\u6784\u5efa\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u65e0\u6cd5\u6355\u6349\u5e8f\u5217\u9000\u5316\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u4fe1\u606f\uff0c\u4ece\u800c\u9650\u5236\u4e86HI\u5728\u9000\u5316\u8d8b\u52bf\u8868\u793a\u548c\u9884\u6d4b\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e00\u79cd\u65e0\u76d1\u7763\u6846\u67b6\u6784\u5efa\u65b0\u7684\u52a8\u6001\u5065\u5eb7\u6307\u6807(HI)\uff0c\u8be5\u65b9\u6cd5\u8003\u8651\u4e86HI\u7ea7\u522b\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9996\u5148\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u8df3\u8dc3\u8fde\u63a5\u7684\u81ea\u7f16\u7801\u5668\u7ec4\u6210\u7684\u9000\u5316\u7279\u5f81\u5b66\u4e60\u6a21\u5757\uff0c\u5c06\u539f\u59cb\u4fe1\u53f7\u6620\u5c04\u5230\u4ee3\u8868\u6027\u7684\u9000\u5316\u7279\u5f81\u7a7a\u95f4(DFS)\uff0c\u65e0\u9700\u4e13\u5bb6\u77e5\u8bc6\u81ea\u52a8\u63d0\u53d6\u57fa\u672c\u9000\u5316\u7279\u5f81\u3002\u968f\u540e\uff0c\u5728\u8fd9\u4e2aDFS\u4e2d\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684HI\u751f\u6210\u6a21\u5757\uff0c\u5d4c\u5165\u4e86\u4e00\u4e2a\u5185\u90e8HI\u9884\u6d4b\u6a21\u5757\u7528\u4e8e\u52a8\u6001HI\u6784\u5efa\uff0c\u5176\u4e2d\u4fdd\u8bc1\u5e76\u660e\u786e\u5efa\u6a21\u4e86\u8fc7\u53bb\u548c\u5f53\u524dHI\u72b6\u6001\u4e4b\u95f4\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e24\u4e2a\u8f74\u627f\u751f\u547d\u5468\u671f\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u5065\u5eb7\u6307\u6807(HI)\u6784\u5efa\u65b9\u6cd5\u4f18\u4e8e\u6bd4\u8f83\u65b9\u6cd5\uff0c\u6240\u6784\u5efa\u7684\u52a8\u6001HI\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u65e0\u76d1\u7763\u6846\u67b6\u7684\u52a8\u6001\u5065\u5eb7\u6307\u6807(HI)\u6784\u5efa\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u9000\u5316\u8d8b\u52bf\u5efa\u6a21\u548c\u672a\u6765\u9000\u5316\u9884\u6d4b\u4e2d\u8868\u73b0\u5353\u8d8a\u3002"}}
{"id": "2506.05616", "pdf": "https://arxiv.org/pdf/2506.05616", "abs": "https://arxiv.org/abs/2506.05616", "authors": ["Lianhao Zhou", "Hongyi Ling", "Keqiang Yan", "Kaiji Zhao", "Xiaoning Qian", "Raymundo Arr\u00f3yave", "Xiaofeng Qian", "Shuiwang Ji"], "title": "Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists", "categories": ["cs.AI", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "We aim at designing language agents with greater autonomy for crystal\nmaterials discovery. While most of existing studies restrict the agents to\nperform specific tasks within predefined workflows, we aim to automate workflow\nplanning given high-level goals and scientist intuition. To this end, we\npropose Materials Agent unifying Planning, Physics, and Scientists, known as\nMAPPS. MAPPS consists of a Workflow Planner, a Tool Code Generator, and a\nScientific Mediator. The Workflow Planner uses large language models (LLMs) to\ngenerate structured and multi-step workflows. The Tool Code Generator\nsynthesizes executable Python code for various tasks, including invoking a\nforce field foundation model that encodes physics. The Scientific Mediator\ncoordinates communications, facilitates scientist feedback, and ensures\nrobustness through error reflection and recovery. By unifying planning,\nphysics, and scientists, MAPPS enables flexible and reliable materials\ndiscovery with greater autonomy, achieving a five-fold improvement in\nstability, uniqueness, and novelty rates compared with prior generative models\nwhen evaluated on the MP-20 data. We provide extensive experiments across\ndiverse tasks to show that MAPPS is a promising framework for autonomous\nmaterials discovery.", "AI": {"tldr": "MAPPS\u901a\u8fc7\u7edf\u4e00\u89c4\u5212\u3001\u7269\u7406\u548c\u79d1\u5b66\u5bb6\uff0c\u5b9e\u73b0\u4e86\u81ea\u4e3b\u7684\u6750\u6599\u53d1\u73b0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7ed3\u679c\u7684\u7a33\u5b9a\u6027\u548c\u65b0\u9896\u6027\u3002", "motivation": "\u8bbe\u8ba1\u5177\u6709\u66f4\u5927\u81ea\u4e3b\u80fd\u529b\u7684\u8bed\u8a00\u4ee3\u7406\uff0c\u4ee5\u5b9e\u73b0\u81ea\u4e3b\u7684\u6c34\u6676\u6750\u6599\u53d1\u73b0\uff0c\u8d85\u8d8a\u9650\u5b9a\u5728\u7279\u5b9a\u4efb\u52a1\u7684\u65e2\u5b9a\u5de5\u4f5c\u6d41\u7a0b\u5185\u7684\u73b0\u6709\u7814\u7a76\u3002", "method": "MAPPS\u5305\u62ec\u5de5\u4f5c\u6d41\u7a0b\u89c4\u5212\u5668\u3001\u5de5\u5177\u4ee3\u7801\u751f\u6210\u5668\u548c\u79d1\u5b66\u4e2d\u4ecb\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u6784\u5316\u7684\u591a\u6b65\u9aa4\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5408\u6210\u53ef\u6267\u884c\u7684Python\u4ee3\u7801\u4ee5\u5b8c\u6210\u4efb\u52a1\uff0c\u5e76\u534f\u8c03\u6c9f\u901a\u548c\u5904\u7406\u9519\u8bef\u3002", "result": "\u76f8\u8f83\u4e8e\u5148\u524d\u7684\u751f\u6210\u6a21\u578b\uff0cMAPPS\u5728MP-20\u6570\u636e\u96c6\u4e0a\u7684\u7a33\u5b9a\u6027\u3001\u72ec\u7279\u6027\u548c\u65b0\u9896\u6027\u63d0\u9ad8\u4e86\u4e94\u500d\u3002", "conclusion": "MAPPS\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c4\u5212\u3001\u7269\u7406\u548c\u79d1\u5b66\u5bb6\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u7075\u6d3b\u548c\u53ef\u9760\u7684\u6750\u6599\u53d1\u73b0\uff0c\u5e76\u5728\u7a33\u5b9a\u6027\u3001\u72ec\u7279\u6027\u548c\u65b0\u9896\u6027\u65b9\u9762\u76f8\u6bd4\u4e4b\u524d\u7684\u751f\u6210\u6a21\u578b\u63d0\u9ad8\u4e86\u4e94\u500d\u3002"}}
{"id": "2506.05410", "pdf": "https://arxiv.org/pdf/2506.05410", "abs": "https://arxiv.org/abs/2506.05410", "authors": ["Wanyun Cui", "Mingwei Xu"], "title": "Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs", "categories": ["cs.CL", "I.2.7"], "comment": "14 pages,7 figures", "summary": "Recent advances in Large Language Models (LLMs) have highlighted the critical\nimportance of extending context length, yet the quadratic complexity of\nattention mechanisms poses significant challenges for efficient long-context\nmodeling. KV cache compression has emerged as a key approach to address this\nchallenge. Through extensive empirical analysis, we reveal a fundamental yet\npreviously overlooked asymmetry in KV caches: while adjacent keys receive\nsimilar attention weights (local homogeneity), adjacent values demonstrate\ndistinct heterogeneous distributions. This key-value asymmetry reveals a\ncritical limitation in existing compression methods that treat keys and values\nuniformly. To address the limitation, we propose a training-free compression\nframework (AsymKV) that combines homogeneity-based key merging with a\nmathematically proven lossless value compression. Extensive experiments\ndemonstrate that AsymKV consistently outperforms existing long-context methods\nacross various tasks and base models. For example, on LLaMA3.1-8B, AsymKV\nachieves an average score of 43.95 on LongBench, surpassing SOTA methods like\nH$_2$O (38.89) by a large margin.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u8bad\u7ec3\u7684\u538b\u7f29\u6846\u67b6\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u6ce8\u610f\u529b\u673a\u5236\u7684\u6548\u7387\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u6027\u6240\u5e26\u6765\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u8bad\u7ec3\u7684\u538b\u7f29\u6846\u67b6\uff08AsymKV\uff09\uff0c\u7ed3\u5408\u57fa\u4e8e\u540c\u8d28\u6027\u7684\u5173\u952e\u5408\u5e76\u548c\u7ecf\u8fc7\u6570\u5b66\u8bc1\u660e\u7684\u65e0\u635f\u503c\u538b\u7f29\u3002", "result": "AsymKV\u5728LLaMA3.1-8B\u4e0a\u7684\u5e73\u5747\u5f97\u5206\u4e3a43.95\uff0c\u663e\u8457\u8d85\u8fc7\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5982H\u2082O\uff0838.89\uff09\u3002", "conclusion": "AsymKV\u5728\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u57fa\u7840\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.05443", "pdf": "https://arxiv.org/pdf/2506.05443", "abs": "https://arxiv.org/abs/2506.05443", "authors": ["Yiyu Lin", "Yan Wang", "You Zhou", "Xinye Ni", "Jiahui Wu", "Sen Yang"], "title": "UniPTMs: The First Unified Multi-type PTM Site Prediction Model via Master-Slave Architecture-Based Multi-Stage Fusion Strategy and Hierarchical Contrastive Loss", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": null, "summary": "As a core mechanism of epigenetic regulation in eukaryotes, protein\npost-translational modifications (PTMs) require precise prediction to decipher\ndynamic life activity networks. To address the limitations of existing deep\nlearning models in cross-modal feature fusion, domain generalization, and\narchitectural optimization, this study proposes UniPTMs: the first unified\nframework for multi-type PTM prediction. The framework innovatively establishes\na \"Master-Slave\" dual-path collaborative architecture: The master path\ndynamically integrates high-dimensional representations of protein sequences,\nstructures, and evolutionary information through a Bidirectional Gated\nCross-Attention (BGCA) module, while the slave path optimizes feature\ndiscrepancies and recalibration between structural and traditional features\nusing a Low-Dimensional Fusion Network (LDFN). Complemented by a Multi-scale\nAdaptive convolutional Pyramid (MACP) for capturing local feature patterns and\na Bidirectional Hierarchical Gated Fusion Network (BHGFN) enabling multi-level\nfeature integration across paths, the framework employs a Hierarchical Dynamic\nWeighting Fusion (HDWF) mechanism to intelligently aggregate multimodal\nfeatures. Enhanced by a novel Hierarchical Contrastive loss function for\nfeature consistency optimization, UniPTMs demonstrates significant performance\nimprovements (3.2%-11.4% MCC and 4.2%-14.3% AP increases) over state-of-the-art\nmodels across five modification types and transcends the Single-Type Prediction\nParadigm. To strike a balance between model complexity and performance, we have\nalso developed a lightweight variant named UniPTMs-mini.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86 UniPTMs \u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7c7b\u578b\u86cb\u767d\u8d28\u7ffb\u8bd1\u540e\u4fee\u9970\u9884\u6d4b\uff0c\u8868\u73b0\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8de8\u6a21\u6001\u7279\u5f81\u878d\u5408\u3001\u9886\u57df\u6cdb\u5316\u548c\u67b6\u6784\u4f18\u5316\u65b9\u9762\u5b58\u5728\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u201c\u4e3b\u4ece\u201d\u53cc\u8def\u5f84\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u6743\u91cd\u878d\u5408\u673a\u5236\u667a\u80fd\u805a\u5408\u591a\u6a21\u6001\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u5c42\u6b21\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u4f18\u5316\u7279\u5f81\u4e00\u81f4\u6027\u3002", "result": "UniPTMs \u5728\u4e94\u79cd\u4fee\u9970\u7c7b\u578b\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u9ad8\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\u5177\u5907\u66f4\u9ad8\u7684 MCC \u548c AP \u589e\u5e45\u3002", "conclusion": "UniPTMs \u8d85\u8d8a\u4e86\u5355\u4e00\u7c7b\u578b\u9884\u6d4b\u8303\u5f0f\uff0c\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.05619", "pdf": "https://arxiv.org/pdf/2506.05619", "abs": "https://arxiv.org/abs/2506.05619", "authors": ["Kihyun Kim", "Jiawei Zhang", "Asuman Ozdaglar", "Pablo A. Parrilo"], "title": "Population-Proportional Preference Learning from Human Feedback: An Axiomatic Approach", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Conventional preference learning methods often prioritize opinions held more\nwidely when aggregating preferences from multiple evaluators. This may result\nin policies that are biased in favor of some types of opinions or groups. The\nobjective of this paper is to develop a novel preference learning framework\ncapable of aligning aggregate opinions and policies proportionally with the\ntrue population distribution of evaluator preferences. Our approach infers the\nfeasible set of evaluator population distributions directly from pairwise\ncomparison data. Using these estimates, the algorithm constructs a policy that\nsatisfies foundational axioms from social choice theory, namely monotonicity\nand Pareto efficiency, as well as our newly-introduced axioms of\npopulation-proportional representation and population-bounded robustness. We\npropose a soft-max relaxation method that smoothly trade-offs\npopulation-proportional representation with the selection of the Condorcet\nwinner (which beats all other options in pairwise comparisons). Finally, we\nvalidate the effectiveness and scalability of our approach through experiments\non both tabular recommendation tasks and large-scale language model alignment.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u4eba\u53e3\u5206\u5e03\u63a8\u65ad\uff0c\u901a\u8fc7\u8f6f\u6700\u5927\u5316\u65b9\u6cd5\u5e73\u8861\u653f\u7b56\uff0c\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u5728\u4ece\u591a\u4e2a\u8bc4\u4f30\u8005\u805a\u5408\u504f\u597d\u65f6\uff0c\u901a\u5e38\u4f18\u5148\u8003\u8651\u66f4\u5e7f\u6cdb\u6301\u6709\u7684\u89c2\u70b9\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u653f\u7b56\u504f\u5411\u67d0\u4e9b\u7c7b\u578b\u7684\u610f\u89c1\u6216\u7fa4\u4f53\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u6309\u8bc4\u4f30\u8005\u504f\u597d\u7684\u771f\u5b9e\u4eba\u53e3\u5206\u5e03\u6bd4\u4f8b\u5bf9\u9f50\u96c6\u4f53\u610f\u89c1\u548c\u653f\u7b56\u7684\u65b0\u504f\u597d\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u672c\u6587\u91c7\u7528\u8f6f\u6700\u5927\u5316\u677e\u5f1b\u65b9\u6cd5\uff0c\u5e73\u6ed1\u5730\u5b9e\u73b0\u4eba\u53e3\u6bd4\u4f8b\u4ee3\u8868\u4e0e\u9009\u62e9\u5eb7\u591a\u897f\u8d62\u5bb6\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8868\u683c\u63a8\u8350\u4efb\u52a1\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7b49\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u4ece\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\u63a8\u65ad\u8bc4\u4f30\u8005\u4eba\u7fa4\u5206\u5e03\u7684\u53ef\u884c\u96c6\uff0c\u6784\u5efa\u6ee1\u8db3\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u7684\u5355\u8c03\u6027\u548c\u5e15\u7d2f\u6258\u6548\u7387\u7b49\u57fa\u672c\u516c\u7406\u7684\u65b0\u653f\u7b56\u3002\u5e76\u5f15\u5165\u4e86\u6ee1\u8db3\u4eba\u53e3\u6bd4\u4f8b\u4ee3\u8868\u548c\u4eba\u53e3\u6709\u754c\u9c81\u68d2\u6027\u7684\u65b0\u7684\u516c\u7406\u3002"}}
{"id": "2506.05413", "pdf": "https://arxiv.org/pdf/2506.05413", "abs": "https://arxiv.org/abs/2506.05413", "authors": ["Patrik Czak\u00f3", "G\u00e1bor Kert\u00e9sz", "S\u00e1ndor Sz\u00e9n\u00e1si"], "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "6 pages, 3 figures, 5 tables. Submitted to the IEEE SMC 2025\n  conference", "summary": "We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.", "AI": {"tldr": "SmoothRot\u662f\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\uff0c\u901a\u8fc7\u878d\u5408\u901a\u9053\u7ea7\u7f29\u653e\u4e0eHadamard\u53d8\u6362\u6539\u5584\u6fc0\u6d3b\u5f02\u5e38\u95ee\u9898\uff0c\u63d0\u9ad84\u4f4d\u91cf\u5316\u7684\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u53ef\u51cf\u5c1110-30%\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u65e0\u989d\u5916\u63a8\u65ad\u5ef6\u8fdf\u3002", "motivation": "\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d4\u4f4d\u91cf\u5316\u7684\u6548\u7387\u3002", "method": "\u5c06\u5728\u901a\u9053\u7ea7\u7f29\u653e\u4e0eHadamard\u53d8\u6362\u76f8\u878d\u5408\u6765\u89e3\u51b3\u5927\u91cf\u6fc0\u6d3b\u5f02\u5e38\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u91cf\u5316\u53cb\u597d\u7684\u6fc0\u6d3b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6d41\u884c\u7684LLMs\uff08\u5982LLaMA2 7B\u3001LLaMA3.1 8B\u548cMistral 7B\uff09\u4e0a\u8fdb\u884c\u7684\u6d4b\u8bd5\uff0cSmoothRot\u80fd\u591f\u5728\u8bed\u8a00\u751f\u6210\u548c\u96f6\u6b21\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u5c06\u91cf\u5316\u6a21\u578b\u4e0eFP16\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u51cf\u5c11\u7ea610-30%\u3002", "conclusion": "SmoothRot\u80fd\u591f\u6709\u6548\u51cf\u5c11\u91cf\u5316\u6a21\u578b\u4e0eFP16\u6a21\u578b\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u800c\u4e0d\u4f1a\u589e\u52a0\u63a8\u65ad\u5ef6\u8fdf\u3002"}}
{"id": "2506.05445", "pdf": "https://arxiv.org/pdf/2506.05445", "abs": "https://arxiv.org/abs/2506.05445", "authors": ["Thanh Vinh Vo", "Young Lee", "Haozhe Ma", "Chien Lu", "Tze-Yun Leong"], "title": "Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "Hidden confounders that influence both states and actions can bias policy\nlearning in reinforcement learning (RL), leading to suboptimal or\nnon-generalizable behavior. Most RL algorithms ignore this issue, learning\npolicies from observational trajectories based solely on statistical\nassociations rather than causal effects. We propose DoSAC (Do-Calculus Soft\nActor-Critic with Backdoor Adjustment), a principled extension of the SAC\nalgorithm that corrects for hidden confounding via causal intervention\nestimation. DoSAC estimates the interventional policy $\\pi(a | \\mathrm{do}(s))$\nusing the backdoor criterion, without requiring access to true confounders or\ncausal labels. To achieve this, we introduce a learnable Backdoor Reconstructor\nthat infers pseudo-past variables (previous state and action) from the current\nstate to enable backdoor adjustment from observational data. This module is\nintegrated into a soft actor-critic framework to compute both the\ninterventional policy and its entropy. Empirical results on continuous control\nbenchmarks show that DoSAC outperforms baselines under confounded settings,\nwith improved robustness, generalization, and policy reliability.", "AI": {"tldr": "DoSAC addresses hidden confounders in RL using causal intervention estimation, enhancing policy robustness and generalization.", "motivation": "Hidden confounders in RL can bias policy learning, leading to suboptimal behavior. Most RL algorithms neglect causal effects, learning from statistical associations instead.", "method": "DoSAC incorporates a learnable Backdoor Reconstructor to infer pseudo-past variables for backdoor adjustment, integrated into a soft actor-critic framework for computing interventional policy and entropy.", "result": "DoSAC outperforms baseline algorithms in continuous control tasks under confounded conditions, demonstrating improved robustness and generalization capabilities.", "conclusion": "DoSAC improves robustness, generalization, and policy reliability in RL by addressing hidden confounders using causal intervention estimation without the need for true confounders or causal labels."}}
{"id": "2506.05744", "pdf": "https://arxiv.org/pdf/2506.05744", "abs": "https://arxiv.org/abs/2506.05744", "authors": ["Gouki Minegishi", "Hiroki Furuta", "Takeshi Kojima", "Yusuke Iwasawa", "Yutaka Matsuo"], "title": "Topology of Reasoning: Understanding Large Reasoning Models through Reasoning Graph Properties", "categories": ["cs.AI"], "comment": null, "summary": "Recent large-scale reasoning models have achieved state-of-the-art\nperformance on challenging mathematical benchmarks, yet the internal mechanisms\nunderlying their success remain poorly understood. In this work, we introduce\nthe notion of a reasoning graph, extracted by clustering hidden-state\nrepresentations at each reasoning step, and systematically analyze three key\ngraph-theoretic properties: cyclicity, diameter, and small-world index, across\nmultiple tasks (GSM8K, MATH500, AIME 2024). Our findings reveal that distilled\nreasoning models (e.g., DeepSeek-R1-Distill-Qwen-32B) exhibit significantly\nmore recurrent cycles (about 5 per sample), substantially larger graph\ndiameters, and pronounced small-world characteristics (about 6x) compared to\ntheir base counterparts. Notably, these structural advantages grow with task\ndifficulty and model capacity, with cycle detection peaking at the 14B scale\nand exploration diameter maximized in the 32B variant, correlating positively\nwith accuracy. Furthermore, we show that supervised fine-tuning on an improved\ndataset systematically expands reasoning graph diameters in tandem with\nperformance gains, offering concrete guidelines for dataset design aimed at\nboosting reasoning capabilities. By bridging theoretical insights into\nreasoning graph structures with practical recommendations for data\nconstruction, our work advances both the interpretability and the efficacy of\nlarge reasoning models.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u63a8\u7406\u56fe\u6982\u5ff5\uff0c\u901a\u8fc7\u5206\u6790\u5176\u7ed3\u6784\u63ed\u793a\u4e86\u84b8\u998f\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u7ed3\u6784\u4f18\u52bf\uff0c\u5e76\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u8bbe\u8ba1\u7684\u6307\u5bfc\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4ecd\u7136\u4e0d\u4e3a\u4eba\u77e5\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5206\u6790\u63a8\u7406\u56fe\u7ed3\u6784\u6765\u63d0\u9ad8\u5bf9\u6a21\u578b\u6210\u529f\u539f\u56e0\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u4f9b\u6570\u636e\u96c6\u8bbe\u8ba1\u7684\u5177\u4f53\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u63a8\u7406\u6b65\u9aa4\u4e2d\u9690\u85cf\u72b6\u6001\u8868\u793a\u7684\u805a\u7c7b\uff0c\u63d0\u51fa\u63a8\u7406\u56fe\u7684\u6982\u5ff5\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u5206\u6790\u5176\u4e09\u4e2a\u5173\u952e\u56fe\u8bba\u5c5e\u6027\uff1a\u5faa\u73af\u6027\u3001\u76f4\u5f84\u548c\u5c0f\u4e16\u754c\u6307\u6570\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u84b8\u998f\u63a8\u7406\u6a21\u578b\uff08\u5982DeepSeek-R1-Distill-Qwen-32B\uff09\u5c55\u73b0\u51fa\u4e86\u66f4\u663e\u8457\u7684\u5faa\u73af\u6027\u3001\u66f4\u5927\u7684\u56fe\u76f4\u5f84\u548c\u66f4\u660e\u663e\u7684\u5c0f\u4e16\u754c\u7279\u5f81\u3002\u8fd9\u4e9b\u7ed3\u6784\u4f18\u52bf\u968f\u7740\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u5bb9\u91cf\u7684\u589e\u52a0\u800c\u589e\u957f\uff0c\u4e0e\u51c6\u786e\u6027\u5448\u6b63\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u63a8\u7406\u56fe\u7ed3\u6784\uff08\u5982\u5faa\u73af\u3001\u76f4\u5f84\u548c\u5c0f\u4e16\u754c\u6307\u6570\uff09\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u8f83\u5927\u89c4\u6a21\u7684\u84b8\u998f\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u7ed3\u6784\u4f18\u52bf\uff0c\u8fd9\u4e9b\u4f18\u52bf\u968f\u7740\u4efb\u52a1\u96be\u5ea6\u548c\u6a21\u578b\u5bb9\u91cf\u7684\u589e\u52a0\u800c\u589e\u5f3a\uff0c\u5e76\u4e0e\u51c6\u786e\u6027\u5448\u6b63\u76f8\u5173\u3002"}}
{"id": "2506.05415", "pdf": "https://arxiv.org/pdf/2506.05415", "abs": "https://arxiv.org/abs/2506.05415", "authors": ["Ronaldo Luo", "Gary Liang", "Cindy Liu", "Adam Kabbara", "Minahil Bakhtawar", "Kina Kim", "Michael Guerzhoy"], "title": "Automatically Detecting Amusing Games in Wordle", "categories": ["cs.CL"], "comment": "Accepted to the Intenational Conference on Computational Creeativity\n  (ICCC) 2025", "summary": "We explore automatically predicting which Wordle games Reddit users find\namusing.\n  We scrape approximately 80k reactions by Reddit users to Wordle games from\nReddit, classify the reactions as expressing amusement or not using OpenAI's\nGPT-3.5 using few-shot prompting, and verify that GPT-3.5's labels roughly\ncorrespond to human labels.\n  We then extract features from Wordle games that can predict user amusement.\nWe demonstrate that the features indeed provide a (weak) signal that predicts\nuser amusement as predicted by GPT-3.5.\n  Our results indicate that user amusement at Wordle games can be predicted\ncomputationally to some extent. We explore which features of the game\ncontribute to user amusement.\n  We find that user amusement is predictable, indicating a measurable aspect of\ncreativity infused into Wordle games through humor.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u8ba1\u7b97\u65b9\u5f0f\u9884\u6d4bWordle\u6e38\u620f\u5bf9Reddit\u7528\u6237\u7684\u5a31\u4e50\u6548\u679c\uff0c\u4f7f\u7528GPT-3.5\u5bf9\u53cd\u5e94\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u63a2\u8ba8\u6e38\u620f\u7279\u5f81\u5bf9\u5a31\u4e50\u7684\u5f71\u54cd\u3002", "motivation": "\u63a2\u7d22\u80fd\u5426\u81ea\u52a8\u9884\u6d4b\u54ea\u4e9bWordle\u6e38\u620f\u80fd\u8ba9Reddit\u7528\u6237\u611f\u5230\u5a31\u4e50\u3002", "method": "\u6211\u4eec\u4f7f\u7528OpenAI\u7684GPT-3.5\u8fdb\u884c\u5c11\u6837\u672c\u63d0\u793a\uff0c\u4ee5\u5206\u7c7bReddit\u7528\u6237\u5bf9Wordle\u6e38\u620f\u7684\u53cd\u5e94\u662f\u5426\u8868\u8fbe\u4e86\u5a31\u4e50\uff0c\u5e76\u9a8c\u8bc1GPT-3.5\u7684\u6807\u7b7e\u4e0e\u4eba\u5de5\u6807\u7b7e\u5927\u81f4\u5bf9\u5e94\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u5bf9Wordle\u6e38\u620f\u7684\u5a31\u4e50\u6027\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u901a\u8fc7\u8ba1\u7b97\u65b9\u5f0f\u9884\u6d4b\u3002\u6211\u4eec\u63a2\u8ba8\u4e86\u6e38\u620f\u4e2d\u7684\u54ea\u4e9b\u7279\u5f81\u5bf9\u7528\u6237\u5a31\u4e50\u6709\u8d21\u732e\u3002", "conclusion": "\u7528\u6237\u7684\u5a31\u4e50\u6027\u662f\u53ef\u9884\u6d4b\u7684\uff0c\u8fd9\u8868\u660e\u901a\u8fc7\u5e7d\u9ed8\uff0cWordle\u6e38\u620f\u4e2d\u878d\u5165\u4e86\u4e00\u79cd\u53ef\u8861\u91cf\u7684\u521b\u9020\u529b\u3002"}}
{"id": "2506.05447", "pdf": "https://arxiv.org/pdf/2506.05447", "abs": "https://arxiv.org/abs/2506.05447", "authors": ["Andrei Mircea", "Supriyo Chakraborty", "Nima Chitsazan", "Irina Rish", "Ekaterina Lobacheva"], "title": "Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning", "categories": ["cs.LG", "cs.AI", "I.2.7"], "comment": "Published as a conference paper at ACL 2025", "summary": "This work aims to understand how scaling improves language models,\nspecifically in terms of training dynamics. We find that language models\nundergo loss deceleration early in training; an abrupt slowdown in the rate of\nloss improvement, resulting in piecewise linear behaviour of the loss curve in\nlog-log space. Scaling up the model mitigates this transition by (1) decreasing\nthe loss at which deceleration occurs, and (2) improving the log-log rate of\nloss improvement after deceleration. We attribute loss deceleration to a type\nof degenerate training dynamics we term zero-sum learning (ZSL). In ZSL,\nper-example gradients become systematically opposed, leading to destructive\ninterference in per-example changes in loss. As a result, improving loss on one\nsubset of examples degrades it on another, bottlenecking overall progress. Loss\ndeceleration and ZSL provide new insights into the training dynamics underlying\nlanguage model scaling laws, and could potentially be targeted directly to\nimprove language models independent of scale. We make our code and artefacts\navailable at: https://github.com/mirandrom/zsl", "AI": {"tldr": "The paper explores how scaling affects language model training, uncovering loss deceleration and zero-sum learning as key factors influencing training dynamics.", "motivation": "The motivation is to understand the dynamics of scaling in language models and specifically why loss deceleration occurs during training, with the aim of improving training methods and model performance.", "method": "The research involved studying the training dynamics of language models, particularly focusing on how scaling affects loss deceleration. The study attributes the phenomenon to zero-sum learning, where per-example gradients counteract each other.", "result": "Scaling up models is shown to mitigate loss deceleration by decreasing the loss at which it occurs and improving the rate of loss improvement post-deceleration.", "conclusion": "The study provides insights into language model scaling laws by highlighting the phenomenon of loss deceleration and zero-sum learning (ZSL), suggesting they could be targeted to improve language models independent of scale."}}
{"id": "2506.05745", "pdf": "https://arxiv.org/pdf/2506.05745", "abs": "https://arxiv.org/abs/2506.05745", "authors": ["Emil Biju", "Shayan Talaei", "Zhemin Huang", "Mohammadreza Pourreza", "Azalia Mirhoseini", "Amin Saberi"], "title": "SPRINT: Enabling Interleaved Planning and Parallelized Execution in Reasoning Models", "categories": ["cs.AI", "cs.LG"], "comment": "Emil Biju, Shayan Talaei, and Zhemin Huang contributed equally to\n  this work", "summary": "Large reasoning models (LRMs) excel at complex reasoning tasks but typically\ngenerate lengthy sequential chains-of-thought, resulting in long inference\ntimes before arriving at the final answer. To address this challenge, we\nintroduce SPRINT, a novel post-training and inference-time framework designed\nto enable LRMs to dynamically identify and exploit opportunities for\nparallelization during their reasoning process. SPRINT incorporates an\ninnovative data curation pipeline that reorganizes natural language reasoning\ntrajectories into structured rounds of long-horizon planning and parallel\nexecution. By fine-tuning LRMs on a small amount of such curated data, the\nmodels learn to dynamically identify independent subtasks within extended\nreasoning processes and effectively execute them in parallel. Through extensive\nevaluations, we show that the models fine-tuned with the SPRINT framework match\nthe performance of reasoning models on complex domains such as mathematics\nwhile generating up to ~39% fewer sequential tokens on problems requiring more\nthan 8000 output tokens. Finally, we observe consistent results transferred to\ntwo out-of-distribution tasks of GPQA and Countdown with up to 45% and 65%\nreduction in average sequential tokens for longer reasoning trajectories, while\nachieving the performance of the fine-tuned reasoning model.", "AI": {"tldr": "SPRINT\u6846\u67b6\u901a\u8fc7\u5e76\u884c\u5316\u63a8\u7406\u8fc7\u7a0b\uff0c\u51cf\u5c11\u4e86LRMs\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u901a\u5e38\u751f\u6210\u5197\u957f\u7684\u987a\u5e8f\u601d\u8003\u94fe\u6761\uff0c\u5bfc\u81f4\u5728\u5230\u8fbe\u6700\u7ec8\u7b54\u6848\u4e4b\u524d\u63a8\u7406\u65f6\u95f4\u8f83\u957f\u3002", "method": "SPRINT\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u6574\u7406\u7ba1\u9053\u5c06\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u8f68\u8ff9\u91cd\u65b0\u7ec4\u7ec7\u4e3a\u957f\u65f6\u95f4\u89c4\u5212\u548c\u5e76\u884c\u6267\u884c\u7684\u7ed3\u6784\u5316\u56de\u5408\u3002\u901a\u8fc7\u5728\u5c11\u91cf\u6574\u7406\u6570\u636e\u4e0a\u5fae\u8c03LRMs\uff0c\u6a21\u578b\u5b66\u4f1a\u5728\u6269\u5c55\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8bc6\u522b\u72ec\u7acb\u5b50\u4efb\u52a1\u5e76\u6709\u6548\u5e76\u884c\u6267\u884c\u3002", "result": "\u5fae\u8c03\u540e\u7684LRMs\u80fd\u591f\u52a8\u6001\u8bc6\u522b\u6269\u5c55\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u72ec\u7acb\u5b50\u4efb\u52a1\u5e76\u5e76\u884c\u6267\u884c\u5b83\u4eec\uff0c\u51cf\u5c11\u751f\u6210\u7684\u987a\u5e8f\u6807\u8bb0\u6570\u91cf\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u590d\u6742\u57df\u4e2d\u5339\u914d\u4f20\u7edf\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u5e94\u7528SPRINT\u6846\u67b6\u8fdb\u884c\u5fae\u8c03\u7684\u6a21\u578b\u80fd\u591f\u5728\u590d\u6742\u9886\u57df\uff08\u5982\u6570\u5b66\uff09\u7684\u6027\u80fd\u4e0e\u5e38\u89c4\u63a8\u7406\u6a21\u578b\u76f8\u5339\u914d\uff0c\u540c\u65f6\u5728\u9700\u8981\u751f\u6210\u8d85\u8fc78000\u4e2a\u8f93\u51fa\u6807\u8bb0\u7684\u95ee\u9898\u4e0a\u51cf\u5c11\u7ea639%\u7684\u987a\u5e8f\u6807\u8bb0\u3002\u5bf9\u4e8eGPQA\u548cCountdown\u4e24\u9879\u5206\u5e03\u5916\u4efb\u52a1\uff0c\u5e73\u5747\u987a\u5e8f\u6807\u8bb0\u6700\u591a\u51cf\u5c1145%\u548c65%\uff0c\u5e76\u4fdd\u6301\u5fae\u8c03\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05453", "pdf": "https://arxiv.org/pdf/2506.05453", "abs": "https://arxiv.org/abs/2506.05453", "authors": ["Hongbo Zhao", "Fei Zhu", "Rundong Wang", "Gaofeng Meng", "Zhaoxiang Zhang"], "title": "MLLM-CL: Continual Learning for Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Recent Multimodal Large Language Models (MLLMs) excel in vision-language\nunderstanding but face challenges in adapting to dynamic real-world scenarios\nthat require continuous integration of new knowledge and skills. While\ncontinual learning (CL) offers a potential solution, existing benchmarks and\nmethods suffer from critical limitations. In this paper, we introduce MLLM-CL,\na novel benchmark encompassing domain and ability continual learning, where the\nformer focuses on independently and identically distributed (IID) evaluation\nacross evolving mainstream domains, whereas the latter evaluates on non-IID\nscenarios with emerging model ability. Methodologically, we propose preventing\ncatastrophic interference through parameter isolation, along with an MLLM-based\nrouting mechanism. Extensive experiments demonstrate that our approach can\nintegrate domain-specific knowledge and functional abilities with minimal\nforgetting, significantly outperforming existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684MLLM-CL\u57fa\u51c6\u548c\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u9694\u79bb\u548cMLLM\u8def\u7531\u673a\u5236\u89e3\u51b3\u707e\u96be\u6027\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684MMML\u5728\u5904\u7406\u9700\u8981\u6301\u7eed\u6574\u5408\u65b0\u77e5\u8bc6\u548c\u6280\u80fd\u7684\u52a8\u6001\u73b0\u5b9e\u573a\u666f\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u53c2\u6570\u9694\u79bb\u6765\u9632\u6b62\u707e\u96be\u6027\u5e72\u6270\uff0c\u5e76\u5f15\u5165\u4e86\u57fa\u4e8eMLLM\u7684\u8def\u7531\u673a\u5236\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6574\u5408\u9886\u57df\u77e5\u8bc6\u548c\u529f\u80fd\u80fd\u529b\uff0c\u540c\u65f6\u968f\u7740\u6700\u5c0f\u7684\u9057\u5fd8\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u6700\u5c0f\u9057\u5fd8\u7684\u60c5\u51b5\u4e0b\u6574\u5408\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u548c\u529f\u80fd\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.05454", "pdf": "https://arxiv.org/pdf/2506.05454", "abs": "https://arxiv.org/abs/2506.05454", "authors": ["Liang Zhang", "Bingcong Li", "Kiran Koshy Thekumparampil", "Sewoong Oh", "Michael Muehlebach", "Niao He"], "title": "Zeroth-Order Optimization Finds Flat Minima", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "comment": null, "summary": "Zeroth-order methods are extensively used in machine learning applications\nwhere gradients are infeasible or expensive to compute, such as black-box\nattacks, reinforcement learning, and language model fine-tuning. Existing\noptimization theory focuses on convergence to an arbitrary stationary point,\nbut less is known on the implicit regularization that provides a fine-grained\ncharacterization on which particular solutions are finally reached. We show\nthat zeroth-order optimization with the standard two-point estimator favors\nsolutions with small trace of Hessian, which is widely used in previous work to\ndistinguish between sharp and flat minima. We further provide convergence rates\nof zeroth-order optimization to approximate flat minima for convex and\nsufficiently smooth functions, where flat minima are defined as the minimizers\nthat achieve the smallest trace of Hessian among all optimal solutions.\nExperiments on binary classification tasks with convex losses and language\nmodel fine-tuning support our theoretical findings.", "AI": {"tldr": "\u96f6\u9636\u4f18\u5316\u503e\u5411\u9009\u62e9Hessian\u8ff9\u5c0f\u7684\u89e3\uff0c\u52a0\u5f3a\u5bf9\u7a33\u5b9a\u89e3\u7684\u7406\u89e3\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "motivation": "\u63a2\u7d22\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u4e2d\u7684\u9690\u5f0f\u6b63\u5219\u5316\u6548\u5e94\uff0c\u4ee5\u66f4\u7ec6\u81f4\u5730\u7406\u89e3\u8be5\u4f18\u5316\u8fc7\u7a0b\u5982\u4f55\u9009\u62e9\u7279\u5b9a\u89e3\u3002", "method": "\u5728\u96f6\u9636\u4f18\u5316\u4e2d\u91c7\u7528\u6807\u51c6\u7684\u4e24\u70b9\u4f30\u8ba1\u5668\u6765\u5206\u6790Hessian\u8ff9\u5bf9\u6c42\u89e3\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u96f6\u9636\u4f18\u5316\u6536\u655b\u5230\u5e73\u5766\u6781\u5c0f\u503c\u7684\u901f\u5ea6\u3002", "result": "\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u8d8b\u5411\u4e8e\u9009\u62e9Hessian\u8ff9\u8f83\u5c0f\u7684\u89e3\uff0c\u5e76\u5728\u51f8\u51fd\u6570\u53ca\u5145\u5206\u5149\u6ed1\u51fd\u6570\u4e0b\u80fd\u6709\u6548\u6536\u655b\u5230\u8fd1\u4f3c\u7684\u5e73\u5766\u6781\u5c0f\u503c\u3002\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u4ee5\u6536\u655b\u5230\u4efb\u610f\u9a7b\u70b9\uff0c\u8fd8\u5bf9\u6700\u7ec8\u6c42\u5f97\u7684\u89e3\u6709\u9690\u5f0f\u6b63\u5219\u5316\u4f5c\u7528\uff0c\u503e\u5411\u4e8e\u9009\u62e9Hessian\u8ff9\u8f83\u5c0f\u7684\u89e3\u3002"}}
{"id": "2506.05754", "pdf": "https://arxiv.org/pdf/2506.05754", "abs": "https://arxiv.org/abs/2506.05754", "authors": ["Emmanuel Anaya Gonzalez", "Sairam Vaidya", "Kanghee Park", "Ruyi Ji", "Taylor Berg-Kirkpatrick", "Loris D'Antoni"], "title": "Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Constrained decoding enables Language Models (LMs) to produce samples that\nprovably satisfy hard constraints. However, existing constrained-decoding\napproaches often distort the underlying model distribution, a limitation that\nis especially problematic in applications like program fuzzing, where one wants\nto generate diverse and valid program inputs for testing purposes. We propose a\nnew constrained sampling framework based on Markov Chain Monte Carlo (MCMC)\nthat simultaneously satisfies three core desiderata: constraint satisfying\n(every sample satisfies the constraint), monotonically converging (the sampling\nprocess converges to the true conditional distribution), and efficient\n(high-quality samples emerge in few steps). Our method constructs a proposal\ndistribution over valid outputs and applies a Metropolis-Hastings acceptance\ncriterion based on the LM's likelihood, ensuring principled and efficient\nexploration of the constrained space. Empirically, our sampler outperforms\nexisting methods on both synthetic benchmarks and real-world program fuzzing\ntasks.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMCMC\u7684\u7ea6\u675f\u91c7\u6837\u6846\u67b6\uff0c\u80fd\u591f\u5728\u6ee1\u8db3\u7ea6\u675f\u7684\u540c\u65f6\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u7ecf\u5e38\u626d\u66f2\u6a21\u578b\u5206\u5e03\uff0c\u8fd9\u5728\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u7b49\u9700\u8981\u4ea7\u751f\u591a\u6837\u5316\u4e14\u6709\u6548\u8f93\u5165\u7684\u5e94\u7528\u4e2d\u5c24\u4e3a\u6210\u95ee\u9898\u3002\u6211\u4eec\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u3002", "method": "\u6211\u4eec\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\uff08MCMC\uff09\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ea6\u675f\u91c7\u6837\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5173\u4e8e\u6709\u6548\u8f93\u51fa\u7684\u5efa\u8bae\u5206\u5e03\u5e76\u5e94\u7528\u57fa\u4e8eLM\u4f3c\u7136\u7684Metropolis-Hastings\u63a5\u53d7\u51c6\u5219\uff0c\u4ee5\u786e\u4fdd\u5bf9\u7ea6\u675f\u7a7a\u95f4\u7684\u539f\u5219\u6027\u548c\u9ad8\u6548\u63a2\u7d22\u3002", "result": "\u6211\u4eec\u7684\u91c7\u6837\u5668\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u7684\u7a0b\u5e8f\u6a21\u7cca\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u4e0d\u4ec5\u80fd\u591f\u6ee1\u8db3\u5404\u79cd\u7ea6\u675f\u6761\u4ef6\uff0c\u8fd8\u80fd\u901a\u8fc7\u5c11\u91cf\u6b65\u9aa4\u751f\u6210\u9ad8\u8d28\u91cf\u6837\u672c\uff0c\u540c\u65f6\u4fdd\u8bc1\u91c7\u6837\u8fc7\u7a0b\u6536\u655b\u5230\u771f\u5b9e\u7684\u6761\u4ef6\u5206\u5e03\u3002"}}
{"id": "2506.05498", "pdf": "https://arxiv.org/pdf/2506.05498", "abs": "https://arxiv.org/abs/2506.05498", "authors": ["Niruthiha Selvanayagam"], "title": "Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering", "categories": ["cs.CL", "cs.LG", "62H30, 62P10", "I.2.7; J.3"], "comment": "14 pages, 3 figures, 16 tables", "summary": "Specific Language Impairment (SLI) affects approximately 7 percent of\nchildren, presenting as isolated language deficits despite normal cognitive\nabilities, sensory systems, and supportive environments. Traditional diagnostic\napproaches often rely on standardized assessments, which may overlook subtle\ndevelopmental patterns. This study aims to identify natural language\ndevelopment trajectories in children with and without SLI using unsupervised\nmachine learning techniques, providing insights for early identification and\ntargeted interventions. Narrative samples from 1,163 children aged 4-16 years\nacross three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using\nPrincipal Component Analysis (PCA) and clustering. A total of 64 linguistic\nfeatures were evaluated to uncover developmental trajectories and distinguish\nlinguistic profiles. Two primary clusters emerged: (1) high language production\nwith low SLI prevalence, and (2) limited production but higher syntactic\ncomplexity with higher SLI prevalence. Additionally, boundary cases exhibited\nintermediate traits, supporting a continuum model of language abilities.\nFindings suggest SLI manifests primarily through reduced production capacity\nrather than syntactic complexity deficits. The results challenge categorical\ndiagnostic frameworks and highlight the potential of unsupervised learning\ntechniques for refining diagnostic criteria and intervention strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7PCA\u548c\u805a\u7c7b\u5206\u6790\uff0c\u63ed\u793a\u7279\u5b9a\u8bed\u8a00\u969c\u788d\u4e3b\u8981\u8868\u73b0\u4e3a\u4ea7\u51fa\u80fd\u529b\u7684\u51cf\u5c11\uff0c\u63d0\u51fa\u4f7f\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u6539\u8fdb\u8bca\u65ad\u6807\u51c6\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u5fae\u5999\u7684\u53d1\u80b2\u6a21\u5f0f\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8bc6\u522b\u6709\u6216\u6ca1\u6709SLI\u513f\u7ae5\u7684\u81ea\u7136\u8bed\u8a00\u53d1\u5c55\u8f68\u8ff9\uff0c\u4e3a\u65e9\u671f\u8bc6\u522b\u548c\u9488\u5bf9\u6027\u5e72\u9884\u63d0\u4f9b\u6d1e\u5bdf\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u901a\u8fc7PCA\u548c\u805a\u7c7b\u5206\u6790\uff0c\u5206\u6790\u6765\u81ea1,163\u540d\u513f\u7ae5\u7684\u53d9\u8ff0\u6837\u672c\u3002\u8bc4\u4f30\u4e8664\u79cd\u8bed\u8a00\u7279\u5f81\uff0c\u4ee5\u63ed\u793a\u53d1\u5c55\u8f68\u8ff9\u5e76\u533a\u5206\u8bed\u8a00\u7279\u5f81\u3002", "result": "\u5206\u6790\u53d1\u73b0\uff0c\u8bed\u8a00\u80fd\u529b\u4e3b\u8981\u5206\u4e3a\u4e24\u4e2a\u96c6\u7fa4\uff1a\u9ad8\u8bed\u8a00\u4ea7\u51fa\u4e14SLI\u60a3\u75c5\u7387\u4f4e\uff0c\u4ee5\u53ca\u6709\u9650\u4ea7\u51fa\u4f46\u53e5\u6cd5\u590d\u6742\u6027\u9ad8\u4e14SLI\u60a3\u75c5\u7387\u9ad8\u3002\u6b64\u5916\uff0c\u8fb9\u754c\u6848\u4f8b\u8868\u73b0\u51fa\u4e2d\u95f4\u7279\u5f81\uff0c\u652f\u6301\u8bed\u8a00\u80fd\u529b\u8fde\u7eed\u4f53\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u7279\u5b9a\u8bed\u8a00\u969c\u788d\u4e3b\u8981\u8868\u73b0\u4e3a\u4ea7\u51fa\u80fd\u529b\u7684\u51cf\u5c11\uff0c\u800c\u4e0d\u662f\u53e5\u6cd5\u590d\u6742\u6027\u4e0d\u8db3\u3002\u7ed3\u679c\u5bf9\u4f20\u7edf\u8bca\u65ad\u6846\u67b6\u63d0\u51fa\u4e86\u6311\u6218\uff0c\u5e76\u5f3a\u8c03\u4f7f\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u6280\u672f\u5728\u8bca\u65ad\u6807\u51c6\u548c\u5e72\u9884\u7b56\u7565\u4e0a\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05479", "pdf": "https://arxiv.org/pdf/2506.05479", "abs": "https://arxiv.org/abs/2506.05479", "authors": ["Matei Gabriel Co\u015fa", "Marek Eli\u00e1\u0161"], "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors", "categories": ["cs.LG", "cs.DS", "68W40 (Primary), 68T05 (Secondary)"], "comment": "Accepted to ICML 2025", "summary": "We consider the following problem: We are given $\\ell$ heuristics for\nMetrical Task Systems (MTS), where each might be tailored to a different type\nof input instances. While processing an input instance received online, we are\nallowed to query the action of only one of the heuristics at each time step.\nOur goal is to achieve performance comparable to the best of the given\nheuristics. The main difficulty of our setting comes from the fact that the\ncost paid by a heuristic at time $t$ cannot be estimated unless the same\nheuristic was also queried at time $t-1$. This is related to Bandit Learning\nagainst memory bounded adversaries (Arora et al., 2012). We show how to achieve\nregret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the\nconstruction of Dekel et al. (2013).", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u9009\u62e9\u548c\u67e5\u8be2\u542f\u53d1\u5f0f\u4ee5\u5728\u5728\u7ebf\u8f93\u5165\u5904\u7406\u4e2d\u5b9e\u73b0\u6700\u4f73\u8868\u73b0\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u534f\u8c03\u591a\u4e2a\u4e3a\u4e0d\u540c\u7c7b\u578b\u8f93\u5165\u5b9e\u4f8b\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\uff0c\u671f\u671b\u5728\u5728\u7ebf\u5b9e\u4f8b\u5904\u7406\u4e2d\u80fd\u591f\u9009\u62e9\u6700\u4f73\u8868\u73b0\u7684\u542f\u53d1\u5f0f\uff0c\u4ece\u800c\u4f18\u5316\u6027\u80fd\u3002", "method": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u542f\u53d1\u5f0f\u6765\u5904\u7406\u5728\u7ebf\u8f93\u5165\uff0c\u5e76\u901a\u8fc7\u5b9e\u73b0\u4e0d\u540c\u542f\u53d1\u5f0f\u7684\u65f6\u95f4\u6b65\u9aa4\u6765\u6bd4\u8f83\u5176\u7ee9\u6548\u3002", "result": "\u672c\u6587\u5c55\u793a\u4e86\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0$O(\\text{OPT}^{2/3})$\u9057\u61be\u5ea6\u7684\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8eDekel\u7b49\u4eba\uff082013\uff09\u7684\u6784\u5efa\u8bc1\u660e\u4e86\u4e00\u4e2a\u7d27\u7684\u4e0b\u754c\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u5728\u7ebf\u5904\u7406\u8f93\u5165\u5b9e\u4f8b\u65f6\u4e00\u4e2a\u6700\u4f73\u542f\u53d1\u5f0f\u6765\u5b9e\u73b0\u4e0e\u6240\u6709\u7ed9\u5b9a\u542f\u53d1\u5f0f\u4e2d\u8868\u73b0\u6700\u597d\u7684\u542f\u53d1\u5f0f\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05810", "pdf": "https://arxiv.org/pdf/2506.05810", "abs": "https://arxiv.org/abs/2506.05810", "authors": ["Yesheng Zhang", "Wenjian Sun", "Yuheng Chen", "Qingwei Liu", "Qi Lin", "Rui Zhang", "Xu Zhao"], "title": "Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction", "categories": ["cs.AI", "cs.RO"], "comment": "10 pages", "summary": "Complex interactions among agents present a significant challenge for\nautonomous driving in real-world scenarios. Recently, a promising approach has\nemerged, which formulates the interactions of agents as a level-k game\nframework. It effectively decouples agent policies by hierarchical game levels.\nHowever, this framework ignores both the varying driving complexities among\nagents and the dynamic changes in agent states across game levels, instead\ntreating them uniformly. Consequently, redundant and error-prone computations\nare introduced into this framework. To tackle the issue, this paper proposes a\nmetric, termed as Trajectory Entropy, to reveal the game status of agents\nwithin the level-k game framework. The key insight stems from recognizing the\ninherit relationship between agent policy uncertainty and the associated\ndriving complexity. Specifically, Trajectory Entropy extracts statistical\nsignals representing uncertainty from the multimodality trajectory prediction\nresults of agents in the game. Then, the signal-to-noise ratio of this signal\nis utilized to quantify the game status of agents. Based on the proposed\nTrajectory Entropy, we refine the current level-k game framework through a\nsimple gating mechanism, significantly improving overall accuracy while\nreducing computational costs. Our method is evaluated on the Waymo and nuPlan\ndatasets, in terms of trajectory prediction, open-loop and closed-loop planning\ntasks. The results demonstrate the state-of-the-art performance of our method,\nwith precision improved by up to 19.89% for prediction and up to 16.48% for\nplanning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTrajectory Entropy\u5ea6\u91cf\u6307\u6807\uff0c\u4f18\u5316level-k\u6e38\u620f\u6846\u67b6\uff0c\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u4e2d\u4ee3\u7406\u4ea4\u4e92\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u8bc4\u4f30\u663e\u793a\u9884\u6d4b\u7cbe\u5ea6\u63d0\u534719.89%\uff0c\u89c4\u5212\u63d0\u534716.48%\u3002", "motivation": "\u590d\u6742\u7684\u4ee3\u7406\u4ea4\u4e92\u5bf9\u81ea\u52a8\u9a7e\u9a76\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684level-k\u6e38\u620f\u6846\u67b6\u867d\u7136\u901a\u8fc7\u5206\u5c42\u6e38\u620f\u5c42\u6b21\u6709\u6548\u89e3\u8026\u4e86\u4ee3\u7406\u7b56\u7565\uff0c\u4f46\u5ffd\u7565\u4e86\u4ee3\u7406\u95f4\u9a7e\u9a76\u590d\u6742\u6027\u7684\u5dee\u5f02\u548c\u6e38\u620f\u5c42\u6b21\u4e2d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u5197\u4f59\u548c\u6613\u9519\u8bef\u8ba1\u7b97\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684Trajectory Entropy\u6307\u6807\uff0c\u901a\u8fc7\u4ece\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u7ed3\u679c\u4e2d\u63d0\u53d6\u4e0d\u786e\u5b9a\u6027\u7edf\u8ba1\u4fe1\u53f7\uff0c\u7136\u540e\u5229\u7528\u4fe1\u53f7\u7684\u4fe1\u566a\u6bd4\u6765\u91cf\u5316\u4ee3\u7406\u7684\u6e38\u620f\u72b6\u6001\u3002\u540c\u65f6\uff0c\u5728level-k\u6e38\u620f\u6846\u67b6\u4e0a\u52a0\u5165\u7b80\u5355\u7684\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5728Waymo\u548cnuPlan\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8f68\u8ff9\u9884\u6d4b\u3001\u5f00\u73af\u548c\u95ed\u73af\u89c4\u5212\u4efb\u52a1\u7684\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u9884\u6d4b\u7cbe\u5ea6\u63d0\u9ad8\u4e8619.89%\uff0c\u89c4\u5212\u4efb\u52a1\u7cbe\u5ea6\u63d0\u9ad8\u4e8616.48%\u3002", "conclusion": "\u901a\u8fc7Trajectory Entropy\u548c\u6539\u8fdb\u7684level-k\u6e38\u620f\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2506.05560", "pdf": "https://arxiv.org/pdf/2506.05560", "abs": "https://arxiv.org/abs/2506.05560", "authors": ["Petr M\u00e1\u0161a"], "title": "Improving LLMs with a knowledge from databases", "categories": ["cs.CL", "I.2.7; I.2.4"], "comment": null, "summary": "Large language models (LLMs) are achieving significant progress almost every\nmoment now. Many advanced techniques have been introduced and widely accepted,\nlike retrieval-augmentation generation (RAG), agents, and tools. Tools can\nquery the database to answer questions from structured data files or perform\ngroupings or other statistics. This unlocks huge opportunities, such as it can\nanswer any question, but also poses threats, such as safety, because there is\nno control over the commands that are created. We would like to discuss whether\nwe can create a new method that improves answers based on dataset/database via\nsome interpretable ML methods, namely enhanced association rules. The advantage\nwould be if the method can be also used in some safe technique like RAG.\nAssociation rules have a sound history. Since the introduction of CN2 and\naproiri, many enhancements have been made. In parallel, enhanced association\nrules have been introduced and evolved over the last 40 years. The general\nproblem is typically that there are too many rules. There are some techniques\nfor handling it, but when LLM emerged, it turned out to be the best use case\nfor the RAG technique for LLMs. We proposed a method that generates a ruleset\nbased on defined knowledge patterns, then converts rules into text form via a\nrule-to-text converter, and includes the result as an RAG into LLM. We compared\nthis method with ChatGPT (even with using agents) and we have discovered a\nsignificant improvement in answering questions based on the dataset. We have\nalso tried several strategies how much rules to generate. We found this\nimprovement interesting. Moreover, it can also be improved in many ways as\nfuture work, like incorporating other patterns, the use of rule mining as an\nagent, and many others.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u589e\u5f3a\u5173\u8054\u89c4\u5219\u6539\u5584LLMs\u56de\u7b54\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u6570\u636e\u96c6\u7684\u95ee\u7b54\u80fd\u529b\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u6539\u8fdb\u7684\u65b9\u5411\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u56de\u7b54\u95ee\u9898\u65b9\u9762\u7684\u6f5c\u529b\u548c\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u6570\u636e\u96c6\u548c\u6570\u636e\u5e93\u65f6\uff0c\u8fd9\u7bc7\u8bba\u6587\u7684\u52a8\u673a\u662f\u627e\u5230\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u9ad8\u56de\u7b54\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u6a21\u5f0f\u751f\u6210\u89c4\u5219\u96c6\u7684\u65b9\u6cd5\uff0c\u5c06\u89c4\u5219\u901a\u8fc7\u89c4\u5219\u8f6c\u6587\u672c\u8f6c\u6362\u5668\u8f6c\u6362\u4e3a\u6587\u672c\u5f62\u5f0f\uff0c\u5e76\u4f5c\u4e3aRAG\u6280\u672f\u7684\u4e00\u90e8\u5206\u878d\u5165LLM\u4e2d\u3002", "result": "\u4e0eChatGPT\uff08\u5305\u62ec\u4f7f\u7528agents\uff09\u8fdb\u884c\u6bd4\u8f83\u540e\uff0c\u53d1\u73b0\u65b0\u65b9\u6cd5\u5728\u57fa\u4e8e\u6570\u636e\u96c6\u56de\u7b54\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u56de\u7b54\u6539\u8fdb\uff0c\u5e76\u4e14\u672a\u6765\u53ef\u4ee5\u901a\u8fc7\u7ed3\u5408\u5176\u4ed6\u6a21\u5f0f\u548c\u5c06\u89c4\u5219\u6316\u6398\u7528\u4f5c\u4ee3\u7406\u7b49\u591a\u79cd\u65b9\u5f0f\u8fdb\u884c\u6539\u8fdb\u3002"}}
{"id": "2506.05484", "pdf": "https://arxiv.org/pdf/2506.05484", "abs": "https://arxiv.org/abs/2506.05484", "authors": ["Ruihua Chen", "Bangyu Wu", "Meng Li", "Kai Yang"], "title": "Initial Model Incorporation for Deep Learning FWI: Pretraining or Denormalization?", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Subsurface property neural network reparameterized full waveform inversion\n(FWI) has emerged as an effective unsupervised learning framework, which can\ninvert stably with an inaccurate starting model. It updates the trainable\nneural network parameters instead of fine-tuning on the subsurface model\ndirectly. There are primarily two ways to embed the prior knowledge of the\ninitial model into neural networks, that is, pretraining and denormalization.\nPretraining first regulates the neural networks' parameters by fitting the\ninitial velocity model; Denormalization directly adds the outputs of the\nnetwork into the initial models without pretraining. In this letter, we\nsystematically investigate the influence of the two ways of initial model\nincorporation for the neural network reparameterized FWI. We demonstrate that\npretraining requires inverting the model perturbation based on a constant\nvelocity value (mean) with a two-stage implementation. It leads to a complex\nworkflow and inconsistency of objective functions in the two-stage process,\ncausing the network parameters to become inactive and lose plasticity.\nExperimental results demonstrate that denormalization can simplify workflows,\naccelerate convergence, and enhance inversion accuracy compared with\npretraining.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5c06\u521d\u59cb\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\u5d4c\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u4e24\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0\u53bb\u6807\u51c6\u5316\u4f18\u4e8e\u9884\u8bad\u7ec3\uff0c\u53ef\u4ee5\u7b80\u5316\u6d41\u7a0b\u3001\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\u5168\u6ce2\u5f62\u53cd\u6f14\u7684\u7a33\u5b9a\u6027\u548c\u7cbe\u5ea6\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u5982\u4f55\u5c06\u521d\u59cb\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u6709\u6548\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e24\u79cd\u65b9\u6cd5\u5c06\u521d\u59cb\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\u5d4c\u5165\u5230\u795e\u7ecf\u7f51\u7edc\u4e2d\uff1a\u9884\u8bad\u7ec3\u548c\u53bb\u6807\u51c6\u5316\uff0c\u5e76\u7cfb\u7edf\u5730\u5206\u6790\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5bf9\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u91cd\u6784\u7684\u5168\u6ce2\u5f62\u53cd\u6f14\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u9884\u8bad\u7ec3\u76f8\u6bd4\uff0c\u53bb\u6807\u51c6\u5316\u80fd\u591f\u7b80\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u6536\u655b\uff0c\u5e76\u63d0\u9ad8\u53cd\u6f14\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u9884\u8bad\u7ec3\u76f8\u6bd4\uff0c\u53bb\u6807\u51c6\u5316\u53ef\u4ee5\u7b80\u5316\u5de5\u4f5c\u6d41\u7a0b\uff0c\u52a0\u901f\u6536\u655b\uff0c\u63d0\u9ad8\u53cd\u6f14\u7cbe\u5ea6\u3002"}}
{"id": "2506.05887", "pdf": "https://arxiv.org/pdf/2506.05887", "abs": "https://arxiv.org/abs/2506.05887", "authors": ["Marilyn Bello", "Rafael Bello", "Maria-Matilde Garc\u00eda", "Ann Now\u00e9", "Iv\u00e1n Sevillano-Garc\u00eda", "Francisco Herrera"], "title": "Explainability in Context: A Multilevel Framework Aligning AI Explanations with Stakeholder with LLMs", "categories": ["cs.AI"], "comment": "22 pages, 5 figures", "summary": "The growing application of artificial intelligence in sensitive domains has\nintensified the demand for systems that are not only accurate but also\nexplainable and trustworthy. Although explainable AI (XAI) methods have\nproliferated, many do not consider the diverse audiences that interact with AI\nsystems: from developers and domain experts to end-users and society. This\npaper addresses how trust in AI is influenced by the design and delivery of\nexplanations and proposes a multilevel framework that aligns explanations with\nthe epistemic, contextual, and ethical expectations of different stakeholders.\nThe framework consists of three layers: algorithmic and domain-based,\nhuman-centered, and social explainability. We highlight the emerging role of\nLarge Language Models (LLMs) in enhancing the social layer by generating\naccessible, natural language explanations. Through illustrative case studies,\nwe demonstrate how this approach facilitates technical fidelity, user\nengagement, and societal accountability, reframing XAI as a dynamic,\ntrust-building process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u591a\u5c42\u6b21\u6846\u67b6\uff0c\u5c06\u89e3\u91ca\u4e0e\u4e0d\u540c\u89d2\u8272\u7684\u671f\u671b\u5bf9\u9f50\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u52a0\u5f3a\u793e\u4f1a\u5c42\u9762\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u654f\u611f\u9886\u57df\u7684\u5e94\u7528\u589e\u52a0\uff0c\u4eba\u4eec\u5bf9\u4e0d\u4ec5\u51c6\u786e\u800c\u4e14\u53ef\u89e3\u91ca\u548c\u53ef\u4fe1\u7684\u7cfb\u7edf\u7684\u9700\u6c42\u8d8a\u6765\u8d8a\u5f3a\u70c8\u3002\u5c3d\u7ba1\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u5df2\u7ecf\u5927\u91cf\u51fa\u73b0\uff0c\u4f46\u8bb8\u591a\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u4e0eAI\u7cfb\u7edf\u4e92\u52a8\u7684\u591a\u6837\u5316\u7fa4\u4f53\uff1a\u4ece\u5f00\u53d1\u8005\u548c\u9886\u57df\u4e13\u5bb6\u5230\u6700\u7ec8\u7528\u6237\u53ca\u793e\u4f1a\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u5c42\u6b21\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u7b97\u6cd5\u548c\u9886\u57df\u57fa\u7840\u3001\u4eba\u672c\u4e2d\u5fc3\u3001\u4ee5\u53ca\u793e\u4f1a\u53ef\u89e3\u91ca\u6027\u4e09\u4e2a\u5c42\u6b21\u6765\u4f7f\u89e3\u91ca\u4e0e\u4e0d\u540c\u5229\u76ca\u76f8\u5173\u8005\u7684\u77e5\u8bc6\u3001\u80cc\u666f\u548c\u4f26\u7406\u671f\u671b\u76f8\u5bf9\u9f50\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5982\u4f55\u4fc3\u8fdb\u6280\u672f\u7684\u51c6\u786e\u6027\u3001\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u793e\u4f1a\u8d23\u4efb\u611f\uff0c\u5e76\u5c06XAI\u91cd\u65b0\u6784\u5efa\u4e3a\u4e00\u4e2a\u52a8\u6001\u7684\u3001\u4fe1\u4efb\u6784\u5efa\u8fc7\u7a0b\u3002", "conclusion": "\u4fe1\u4efbAI\u53d7\u5230\u89e3\u91ca\u8bbe\u8ba1\u548c\u4ea4\u4ed8\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5448\u73b0\u6848\u4f8b\u7814\u7a76\uff0c\u8bf4\u660e\u8be5\u65b9\u6cd5\u5982\u4f55\u4fc3\u8fdb\u6280\u672f\u53ef\u4fe1\u5ea6\u3001\u7528\u6237\u53c2\u4e0e\u548c\u793e\u4f1a\u8d23\u4efb\uff0c\u5c06XAI\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u52a8\u6001\u7684\u4fe1\u4efb\u6784\u5efa\u8fc7\u7a0b\u3002"}}
{"id": "2506.05582", "pdf": "https://arxiv.org/pdf/2506.05582", "abs": "https://arxiv.org/abs/2506.05582", "authors": ["Azza Abouzied", "Firoj Alam", "Raian Ali", "Paolo Papotti"], "title": "Combating Misinformation in the Arab World: Challenges & Opportunities", "categories": ["cs.CL", "cs.AI", "cs.SI", "68T50", "I.2.7"], "comment": "disinformation, misinformation, factuality, harmfulness, fake news", "summary": "Misinformation and disinformation pose significant risks globally, with the\nArab region facing unique vulnerabilities due to geopolitical instabilities,\nlinguistic diversity, and cultural nuances. We explore these challenges through\nthe key facets of combating misinformation: detection, tracking, mitigation and\ncommunity-engagement. We shed light on how connecting with grass-roots\nfact-checking organizations, understanding cultural norms, promoting social\ncorrection, and creating strong collaborative information networks can create\nopportunities for a more resilient information ecosystem in the Arab world.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u963f\u62c9\u4f2f\u5730\u533a\u5728\u5730\u7f18\u653f\u6cbb\u4e0d\u7a33\u5b9a\u6027\u4e0b\u7684\u9519\u8bef\u4fe1\u606f\u7684\u68c0\u6d4b\u3001\u8ffd\u8e2a\u4e0e\u7f13\u89e3\u7b56\u7565\uff0c\u5f3a\u8c03\u4e0e\u57fa\u5c42\u7ec4\u7ec7\u5408\u4f5c\u53ca\u6587\u5316\u8ba4\u77e5\u3002", "motivation": "\u7531\u4e8e\u5730\u7f18\u653f\u6cbb\u4e0d\u7a33\u5b9a\u6027\u3001\u8bed\u8a00\u591a\u6837\u6027\u548c\u6587\u5316\u5dee\u5f02\uff0c\u963f\u62c9\u4f2f\u5730\u533a\u5728\u5bf9\u6297\u5168\u7403\u9519\u8bef\u8d44\u8baf\u65b9\u9762\u9762\u4e34\u72ec\u7279\u7684\u8106\u5f31\u6027\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u68c0\u6d4b\u3001\u8ffd\u8e2a\u3001\u7f13\u89e3\u548c\u793e\u533a\u53c2\u4e0e\u7b49\u65b9\u9762\u5e94\u5bf9\u9519\u8bef\u8d44\u8baf\u3002", "result": "\u901a\u8fc7\u8fde\u63a5\u57fa\u5c42\u4e8b\u5b9e\u6838\u67e5\u7ec4\u7ec7\u3001\u7406\u89e3\u6587\u5316\u89c4\u8303\u3001\u4fc3\u8fdb\u793e\u4f1a\u66f4\u6b63\uff0c\u53ca\u521b\u5efa\u5f3a\u5927\u7684\u534f\u4f5c\u4fe1\u606f\u7f51\u7edc\uff0c\u53ef\u4ee5\u5728\u963f\u62c9\u4f2f\u4e16\u754c\u6784\u5efa\u4e00\u4e2a\u66f4\u5177\u97e7\u6027\u7684\u8d44\u8baf\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u5728\u963f\u62c9\u4f2f\u5730\u533a\uff0c\u901a\u8fc7\u4e0e\u57fa\u5c42\u4e8b\u5b9e\u6838\u67e5\u7ec4\u7ec7\u8054\u7cfb\u3001\u7406\u89e3\u6587\u5316\u89c4\u8303\u3001\u4fc3\u8fdb\u793e\u4f1a\u66f4\u6b63\u3001\u5efa\u7acb\u5f3a\u6709\u529b\u7684\u4fe1\u606f\u534f\u4f5c\u7f51\u7edc\uff0c\u80fd\u591f\u521b\u9020\u66f4\u5177\u97e7\u6027\u7684\u8d44\u8baf\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2506.05497", "pdf": "https://arxiv.org/pdf/2506.05497", "abs": "https://arxiv.org/abs/2506.05497", "authors": ["Sima Noorani", "Shayan Kiyani", "George Pappas", "Hamed Hassani"], "title": "Conformal Prediction Beyond the Seen: A Missing Mass Perspective for Uncertainty Quantification in Generative Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Uncertainty quantification (UQ) is essential for safe deployment of\ngenerative AI models such as large language models (LLMs), especially in high\nstakes applications. Conformal prediction (CP) offers a principled uncertainty\nquantification framework, but classical methods focus on regression and\nclassification, relying on geometric distances or softmax scores: tools that\npresuppose structured outputs. We depart from this paradigm by studying CP in a\nquery only setting, where prediction sets must be constructed solely from\nfinite queries to a black box generative model, introducing a new trade off\nbetween coverage, test time query budget, and informativeness. We introduce\nConformal Prediction with Query Oracle (CPQ), a framework characterizing the\noptimal interplay between these objectives. Our finite sample algorithm is\nbuilt on two core principles: one governs the optimal query policy, and the\nother defines the optimal mapping from queried samples to prediction sets.\nRemarkably, both are rooted in the classical missing mass problem in\nstatistics. Specifically, the optimal query policy depends on the rate of\ndecay, or the derivative, of the missing mass, for which we develop a novel\nestimator. Meanwhile, the optimal mapping hinges on the missing mass itself,\nwhich we estimate using Good Turing estimators. We then turn our focus to\nimplementing our method for language models, where outputs are vast, variable,\nand often under specified. Fine grained experiments on three real world open\nended tasks and two LLMs, show CPQ applicability to any black box LLM and\nhighlight: (1) individual contribution of each principle to CPQ performance,\nand (2) CPQ ability to yield significantly more informative prediction sets\nthan existing conformal methods for language uncertainty quantification.", "AI": {"tldr": "CPQ offers an innovative way to quantify uncertainty in generative models, particularly LLMs, by using a query-only framework that improves upon existing methods.", "motivation": "The need for effective uncertainty quantification in generative AI models, especially in applications with high stakes, that do not rely on structured outputs.", "method": "CPQ, a new framework for conformal prediction using a query-only approach, grounded in the classical missing mass problem. It involves optimal query policies and mappings for prediction sets.", "result": "CPQ showcases its applicability to black box LLMs and shows significant improvement in providing informative prediction sets across tested models and tasks.", "conclusion": "CPQ provides more informative prediction sets compared to existing conformal methods in the context of language models."}}
{"id": "2506.05904", "pdf": "https://arxiv.org/pdf/2506.05904", "abs": "https://arxiv.org/abs/2506.05904", "authors": ["Yichi Zhang", "Xin Luna Dong", "Zhaojiang Lin", "Andrea Madotto", "Anuj Kumar", "Babak Damavandi", "Joyce Chai", "Seungwhan Moon"], "title": "Proactive Assistant Dialogue Generation from Streaming Egocentric Videos", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "comment": null, "summary": "Recent advances in conversational AI have been substantial, but developing\nreal-time systems for perceptual task guidance remains challenging. These\nsystems must provide interactive, proactive assistance based on streaming\nvisual inputs, yet their development is constrained by the costly and\nlabor-intensive process of data collection and system evaluation. To address\nthese limitations, we present a comprehensive framework with three key\ncontributions. First, we introduce a novel data curation pipeline that\nsynthesizes dialogues from annotated egocentric videos, resulting in \\dataset,\na large-scale synthetic dialogue dataset spanning multiple domains. Second, we\ndevelop a suite of automatic evaluation metrics, validated through extensive\nhuman studies. Third, we propose an end-to-end model that processes streaming\nvideo inputs to generate contextually appropriate responses, incorporating\nnovel techniques for handling data imbalance and long-duration videos. This\nwork lays the foundation for developing real-time, proactive AI assistants\ncapable of guiding users through diverse tasks. Project page:\nhttps://pro-assist.github.io/", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u578b\u6570\u636e\u7ba1\u9053\u3001\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u548c\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u4e3a\u5b9e\u65f6\u4efb\u52a1\u6307\u5bfcAI\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "motivation": "\u5728\u5bf9\u8bdd\u5f0fAI\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\u7684\u80cc\u666f\u4e0b\uff0c\u5b9e\u65f6\u611f\u77e5\u4efb\u52a1\u7684\u6307\u5bfc\u7cfb\u7edf\u7684\u5f00\u53d1\u4ecd\u5177\u6311\u6218\u6027\u3002\u8fd9\u4e9b\u7cfb\u7edf\u9700\u8981\u57fa\u4e8e\u89c6\u9891\u6d41\u8f93\u5165\u63d0\u4f9b\u4e92\u52a8\u548c\u4e3b\u52a8\u7684\u5e2e\u52a9\uff0c\u800c\u6570\u636e\u6536\u96c6\u548c\u7cfb\u7edf\u8bc4\u4f30\u8fc7\u7a0b\u6602\u8d35\u4e14\u8017\u8d39\u5927\u91cf\u4eba\u529b\u3002", "method": "1. \u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u7b56\u5c55\u7ba1\u9053\uff0c\u4ece\u6ce8\u91ca\u7684\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u4e2d\u5408\u6210\u5bf9\u8bdd\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5408\u6210\u5bf9\u8bdd\u6570\u636e\u96c6\u30022. \u5f00\u53d1\u4e86\u4e00\u5957\u81ea\u52a8\u5316\u8bc4\u4f30\u6307\u6807\uff0c\u901a\u8fc7\u5e7f\u6cdb\u7684\u4eba\u4f53\u7814\u7a76\u8fdb\u884c\u4e86\u9a8c\u8bc1\u30023. \u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u89c6\u9891\u6d41\u8f93\u5165\u5e76\u751f\u6210\u4e0a\u4e0b\u6587\u9002\u5f53\u7684\u54cd\u5e94\uff0c\u91c7\u7528\u4e86\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u548c\u957f\u65f6\u95f4\u89c6\u9891\u7684\u65b0\u6280\u672f\u3002", "result": "\u521b\u5efa\u4e86\u8de8\u591a\u4e2a\u9886\u57df\u7684\u5927\u89c4\u6a21\u5408\u6210\u5bf9\u8bdd\u6570\u636e\u96c6\\dataset\uff0c\u5f00\u53d1\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u80fd\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u548c\u957f\u89c6\u9891\u7684\u65b0\u578b\u7aef\u5230\u7aef\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u5b9e\u65f6\u3001\u4e3b\u52a8\u7684AI\u52a9\u624b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8fd9\u4e9b\u52a9\u624b\u80fd\u591f\u5f15\u5bfc\u7528\u6237\u5b8c\u6210\u5404\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.05589", "pdf": "https://arxiv.org/pdf/2506.05589", "abs": "https://arxiv.org/abs/2506.05589", "authors": ["Sara Shields-Menard", "Zach Reimers", "Joshua Gardner", "David Perry", "Anthony Rios"], "title": "UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting", "categories": ["cs.CL"], "comment": "Accepted to BioNLP 2025", "summary": "We describe our system for the ArchEHR-QA Shared Task on answering clinical\nquestions using electronic health records (EHRs). Our approach uses large\nlanguage models in two steps: first, to find sentences in the EHR relevant to a\nclinician's question, and second, to generate a short, citation-supported\nresponse based on those sentences. We use few-shot prompting, self-consistency,\nand thresholding to improve the sentence classification step to decide which\nsentences are essential. We compare several models and find that a smaller 8B\nmodel performs better than a larger 70B model for identifying relevant\ninformation. Our results show that accurate sentence selection is critical for\ngenerating high-quality responses and that self-consistency with thresholding\nhelps make these decisions more reliable.", "AI": {"tldr": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u9009\u62e9\u76f8\u5173\u53e5\u5b50\u5e76\u751f\u6210\u652f\u6301\u5f15\u7528\u7684\u56de\u7b54\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8eEHRs\uff0c\u53d1\u73b08B\u6a21\u578b\u6548\u679c\u4f18\u4e8e70B\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5982\u4f55\u4f7f\u7528\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u56de\u7b54\u4e34\u5e8a\u95ee\u9898\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5206\u4e24\u6b65\u8fdb\u884c\uff1a\u9996\u5148\u5bfb\u627e\u4e0e\u4e34\u5e8a\u95ee\u9898\u76f8\u5173\u7684EHR\u53e5\u5b50\uff0c\u5176\u6b21\u57fa\u4e8e\u8fd9\u4e9b\u53e5\u5b50\u751f\u6210\u7b80\u77ed\u7684\u3001\u5f15\u7528\u652f\u6301\u7684\u54cd\u5e94\u3002\u4f7f\u7528\u5c11\u6837\u672c\u63d0\u793a\u3001\u81ea\u4e00\u81f4\u6027\u548c\u9608\u503c\u5904\u7406\u6765\u6539\u8fdb\u53e5\u5b50\u5206\u7c7b\u6b65\u9aa4\u3002", "result": "\u8f83\u5c0f\u76848B\u6a21\u578b\u5728\u8bc6\u522b\u76f8\u5173\u4fe1\u606f\u65b9\u9762\u4f18\u4e8e\u8f83\u5927\u768470B\u6a21\u578b\u3002", "conclusion": "\u51c6\u786e\u7684\u53e5\u5b50\u9009\u62e9\u5bf9\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u54cd\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u81ea\u4e00\u81f4\u6027\u548c\u9608\u503c\u5904\u7406\u6709\u52a9\u4e8e\u63d0\u9ad8\u8fd9\u4e9b\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.05500", "pdf": "https://arxiv.org/pdf/2506.05500", "abs": "https://arxiv.org/abs/2506.05500", "authors": ["Alex Damian", "Jason D. Lee", "Joan Bruna"], "title": "The Generative Leap: Sharp Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this work we consider generic Gaussian Multi-index models, in which the\nlabels only depend on the (Gaussian) $d$-dimensional inputs through their\nprojection onto a low-dimensional $r = O_d(1)$ subspace, and we study efficient\nagnostic estimation procedures for this hidden subspace. We introduce the\n\\emph{generative leap} exponent $k^\\star$, a natural extension of the\ngenerative exponent from [Damian et al.'24] to the multi-index setting. We\nfirst show that a sample complexity of $n=\\Theta(d^{1 \\vee \\k/2})$ is necessary\nin the class of algorithms captured by the Low-Degree-Polynomial framework. We\nthen establish that this sample complexity is also sufficient, by giving an\nagnostic sequential estimation procedure (that is, requiring no prior knowledge\nof the multi-index model) based on a spectral U-statistic over appropriate\nHermite tensors. We further compute the generative leap exponent for several\nexamples including piecewise linear functions (deep ReLU networks with bias),\nand general deep neural networks (with $r$-dimensional first hidden layer).", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\u4e2d\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u751f\u6210\u8dc3\u8fc1\u6307\u6570\u5e76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u901a\u7528\u9ad8\u65af\u591a\u6307\u6570\u6a21\u578b\uff0c\u5e76\u63a2\u8ba8\u9690\u85cf\u5b50\u7a7a\u95f4\u7684\u6709\u6548\u4f30\u8ba1\u6b65\u9aa4\u3002", "method": "\u5f15\u5165\u751f\u6210\u8dc3\u8fc1\u6307\u6570\uff0c\u901a\u8fc7\u8c31U-\u7edf\u8ba1\u91cf\u4f9d\u636eHermite\u5f20\u91cf\u8fdb\u884c\u4f30\u8ba1\u3002", "result": "\u8bc1\u660e\u4e86\u6240\u9700\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u8ba1\u7b97\u51fa\u591a\u4e2a\u793a\u4f8b\u7684\u751f\u6210\u8dc3\u8fc1\u6307\u6570\u3002", "conclusion": "\u6837\u672c\u590d\u6742\u5ea6\u5728\u4f4e\u9636\u591a\u9879\u5f0f\u6846\u67b6\u4e0b\u662f\u5fc5\u987b\u7684\uff0c\u5e76\u4e14\u901a\u8fc7\u63d0\u51fa\u7684\u4f30\u8ba1\u7a0b\u5e8f\u662f\u8db3\u591f\u7684\u3002"}}
{"id": "2506.05967", "pdf": "https://arxiv.org/pdf/2506.05967", "abs": "https://arxiv.org/abs/2506.05967", "authors": ["Katarzyna Kobalczyk", "Mihaela van der Schaar"], "title": "Preference Learning for AI Alignment: a Causal Perspective", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": null, "summary": "Reward modelling from preference data is a crucial step in aligning large\nlanguage models (LLMs) with human values, requiring robust generalisation to\nnovel prompt-response pairs. In this work, we propose to frame this problem in\na causal paradigm, providing the rich toolbox of causality to identify the\npersistent challenges, such as causal misidentification, preference\nheterogeneity, and confounding due to user-specific factors. Inheriting from\nthe literature of causal inference, we identify key assumptions necessary for\nreliable generalisation and contrast them with common data collection\npractices. We illustrate failure modes of naive reward models and demonstrate\nhow causally-inspired approaches can improve model robustness. Finally, we\noutline desiderata for future research and practices, advocating targeted\ninterventions to address inherent limitations of observational data.", "AI": {"tldr": "\u672c\u6587\u5c06\u5956\u52b1\u5efa\u6a21\u95ee\u9898\u7f6e\u4e8e\u56e0\u679c\u8303\u5f0f\u4e2d\uff0c\u5efa\u8bae\u4f7f\u7528\u56e0\u679c\u63a8\u65ad\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u89e3\u51b3\u6311\u6218\uff0c\u63d0\u5347\u6a21\u578b\u7a33\u5065\u6027\u3002", "motivation": "\u5956\u52b1\u5efa\u6a21\u662f\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u9700\u8981\u5bf9\u65b0\u9896\u7684\u63d0\u793a-\u54cd\u5e94\u5bf9\u8fdb\u884c\u7a33\u5065\u7684\u6cdb\u5316\u3002\u9762\u4e34\u7684\u6311\u6218\u5305\u62ec\u56e0\u679c\u8bef\u8bc6\u522b\u3001\u504f\u597d\u5f02\u8d28\u6027\u548c\u7528\u6237\u7279\u5b9a\u56e0\u7d20\u5bfc\u81f4\u7684\u6df7\u6742\u3002", "method": "\u91c7\u7528\u56e0\u679c\u63a8\u65ad\u7684\u65b9\u6cd5\uff0c\u8bc6\u522b\u53ef\u9760\u6cdb\u5316\u6240\u9700\u7684\u5173\u952e\u5047\u8bbe\uff0c\u5e76\u4e0e\u5e38\u89c4\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u8fdb\u884c\u5bf9\u6bd4\u3002\u901a\u8fc7\u5c55\u793a\u5929\u771f\u5956\u52b1\u6a21\u578b\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u6f14\u793a\u5982\u4f55\u901a\u8fc7\u56e0\u679c\u542f\u53d1\u7684\u65b9\u6cd5\u6539\u8fdb\u6a21\u578b\u7684\u7a33\u5065\u6027\u3002", "result": "\u56e0\u679c\u542f\u53d1\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u7684\u7a33\u5065\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u4e30\u5bcc\u7684\u56e0\u679c\u5de5\u5177\u6765\u8bc6\u522b\u6301\u7eed\u6027\u6311\u6218\u3002\u6b64\u5916\uff0c\u672a\u6765\u7684\u7814\u7a76\u548c\u5b9e\u8df5\u9700\u8981\u5f3a\u8c03\u5bf9\u89c2\u5bdf\u6570\u636e\u5185\u5728\u5c40\u9650\u6027\u7684\u5e72\u9884\u3002", "conclusion": "\u56e0\u679c\u542f\u53d1\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u7684\u7a33\u5065\u6027\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u89c2\u5bdf\u6570\u636e\u7684\u5185\u5728\u5c40\u9650\u6027\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u5e72\u9884\u3002"}}
{"id": "2506.05598", "pdf": "https://arxiv.org/pdf/2506.05598", "abs": "https://arxiv.org/abs/2506.05598", "authors": ["Michael J Ryan", "Omar Shaikh", "Aditri Bhagirath", "Daniel Frees", "William Held", "Diyi Yang"], "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Main Conference", "summary": "Recent calls for pluralistic alignment of Large Language Models (LLMs)\nencourage adapting models to diverse user preferences. However, most prior work\non personalized reward models heavily rely on additional identity information,\nsuch as demographic details or a predefined set of preference categories. To\nthis end, we introduce SynthesizeMe, an approach to inducing synthetic user\npersonas from user interactions for personalized reward modeling. SynthesizeMe\nfirst generates and verifies reasoning to explain user preferences, then\ninduces synthetic user personas from that reasoning, and finally filters to\ninformative prior user interactions in order to build personalized prompts for\na particular user. We show that using SynthesizeMe induced prompts improves\npersonalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining\nSynthesizeMe derived prompts with a reward model achieves top performance on\nPersonalRewardBench: a new curation of user-stratified interactions with\nchatbots collected from 854 users of Chatbot Arena and PRISM.", "AI": {"tldr": "SynthesizeMe\u901a\u8fc7\u7528\u6237\u4ea4\u4e92\u751f\u6210\u5408\u6210\u89d2\u8272\uff0c\u63d0\u9ad8\u4e86\u4e2a\u6027\u5316LLM\u6027\u80fd\uff0c\u4e14\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2a\u4eba\u5316\u65b9\u6cd5\u4f9d\u8d56\u989d\u5916\u7684\u8eab\u4efd\u4fe1\u606f\uff0c\u800cSynthesizeMe\u65e8\u5728\u901a\u8fc7\u7528\u6237\u4ea4\u4e92\u8bf1\u5bfc\u5408\u6210\u7528\u6237\u89d2\u8272\uff0c\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "SynthesizeMe\u901a\u8fc7\u751f\u6210\u548c\u9a8c\u8bc1\u63a8\u7406\u6765\u89e3\u91ca\u7528\u6237\u504f\u597d\uff0c\u8bf1\u5bfc\u5408\u6210\u7528\u6237\u89d2\u8272\uff0c\u5e76\u8fc7\u6ee4\u5177\u6709\u4fe1\u606f\u4ef7\u503c\u7684\u8fc7\u5f80\u7528\u6237\u4ea4\u4e92\uff0c\u4ee5\u6784\u5efa\u4e2a\u6027\u5316\u63d0\u793a\u3002", "result": "SynthesizeMe\u8bf1\u5bfc\u7684\u63d0\u793a\u63d0\u9ad8\u4e86Chatbot Arena\u4e0a\u7684\u4e2a\u6027\u5316LLM\u5224\u65ad\u51c6\u786e\u60274.4%\uff0c\u7ed3\u5408\u5956\u52b1\u6a21\u578b\u5728PersonalRewardBench\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u8868\u73b0\u3002", "conclusion": "SynthesizeMe\u901a\u8fc7\u5408\u6210\u7528\u6237\u89d2\u8272\u548c\u4e2a\u6027\u5316\u63d0\u793a\u63d0\u9ad8\u4e86LLM\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.05513", "pdf": "https://arxiv.org/pdf/2506.05513", "abs": "https://arxiv.org/abs/2506.05513", "authors": ["Yunfei Huang", "David S. Greenberg"], "title": "Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "Neural PDE surrogates can improve the cost-accuracy tradeoff of classical\nsolvers, but often generalize poorly to new initial conditions and accumulate\nerrors over time. Physical and symmetry constraints have shown promise in\nclosing this performance gap, but existing techniques for imposing these\ninductive biases are incompatible with the staggered grids commonly used in\ncomputational fluid dynamics. Here we introduce novel input and output layers\nthat respect physical laws and symmetries on the staggered grids, and for the\nfirst time systematically investigate how these constraints, individually and\nin combination, affect the accuracy of PDE surrogates. We focus on two\nchallenging problems: shallow water equations with closed boundaries and\ndecaying incompressible turbulence. Compared to strong baselines, symmetries\nand physical constraints consistently improve performance across tasks,\narchitectures, autoregressive prediction steps, accuracy measures, and network\nsizes. Symmetries are more effective than physical constraints, but surrogates\nwith both performed best, even compared to baselines with data augmentation or\npushforward training, while themselves benefiting from the pushforward trick.\nDoubly-constrained surrogates also generalize better to initial conditions and\ndurations beyond the range of the training data, and more accurately predict\nreal-world ocean currents.", "AI": {"tldr": "\u4ea4\u9519\u7f51\u683c\u4e0a\u7684\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u663e\u8457\u63d0\u9ad8\u795e\u7ecfPDE\u4ee3\u7406\u7684\u6cdb\u5316\u80fd\u529b\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u63d0\u9ad8\u795e\u7ecfPDE\u4ee3\u7406\u5728\u65b0\u521d\u59cb\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u6027\uff0c\u5e76\u51cf\u5c11\u968f\u65f6\u95f4\u7d2f\u79ef\u7684\u8bef\u5dee\u3002", "method": "\u5f15\u5165\u65b0\u7684\u8f93\u5165\u548c\u8f93\u51fa\u5c42\uff0c\u8fd9\u4e9b\u5c42\u5728\u4ea4\u9519\u7f51\u683c\u4e0a\u5c0a\u91cd\u7269\u7406\u5b9a\u5f8b\u548c\u5bf9\u79f0\u6027\uff0c\u5e76\u7cfb\u7edf\u5730\u7814\u7a76\u8fd9\u4e9b\u7ea6\u675f\u5bf9PDE\u4ee3\u7406\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u5408\u5bf9\u79f0\u6027\u548c\u7269\u7406\u7ea6\u675f\u7684\u4ee3\u7406\u5728\u4efb\u52a1\u8868\u73b0\u3001\u6a21\u578b\u89c4\u6a21\u4ee5\u53ca\u5bf9\u521d\u59cb\u6761\u4ef6\u548c\u6301\u7eed\u65f6\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u4e0a\u5747\u8d85\u8d8a\u57fa\u7ebf\u3002", "conclusion": "\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u548c\u5bf9\u79f0\u7ea6\u675f\u7684PDE\u4ee3\u7406\u5bf9\u6cdb\u5316\u80fd\u529b\u548c\u9884\u6d4b\u51c6\u786e\u6027\u6709\u663e\u8457\u63d0\u9ad8\u3002"}}
{"id": "2506.05981", "pdf": "https://arxiv.org/pdf/2506.05981", "abs": "https://arxiv.org/abs/2506.05981", "authors": ["Qingbin Zeng", "Ruotong Zhao", "Jinzhu Mao", "Haoyang Li", "Fengli Xu", "Yong Li"], "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "Modeling urban crime is an important yet challenging task that requires\nunderstanding the subtle visual, social, and cultural cues embedded in urban\nenvironments. Previous work has predominantly focused on rule-based agent-based\nmodeling (ABM) and deep learning methods. ABMs offer interpretability of\ninternal mechanisms but exhibit limited predictive accuracy.In contrast, deep\nlearning methods are often effective in prediction but are less interpretable\nand require extensive training data. Moreover, both lines of work lack the\ncognitive flexibility to adapt to changing environments. Leveraging the\ncapabilities of large language models (LLMs), we propose CrimeMind, a novel\nLLM-driven ABM framework for simulating urban crime within a multi-modal urban\ncontext.A key innovation of our design is the integration of the Routine\nActivity Theory (RAT) into the agentic workflow of CrimeMind, enabling it to\nprocess rich multi-modal urban features and reason about criminal\nbehavior.However, RAT requires LLM agents to infer subtle cues in evaluating\nenvironmental safety as part of assessing guardianship, which can be\nchallenging for LLMs. To address this, we collect a small-scale human-annotated\ndataset and align CrimeMind's perception with human judgment via a\ntraining-free textual gradient method.Experiments across four major U.S. cities\ndemonstrate that CrimeMind outperforms both traditional ABMs and deep learning\nbaselines in crime hotspot prediction and spatial distribution accuracy,\nachieving up to a 24% improvement over the strongest baseline.Furthermore, we\nconduct counterfactual simulations of external incidents and policy\ninterventions and it successfully captures the expected changes in crime\npatterns, demonstrating its ability to reflect counterfactual\nscenarios.Overall, CrimeMind enables fine-grained modeling of individual\nbehaviors and facilitates evaluation of real-world interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCrimeMind\u7684\u65b0\u7684LLM\u9a71\u52a8\u7684ABM\u6846\u67b6\uff0c\u6bd4\u4f20\u7edf\u6a21\u578b\u5728\u9884\u6d4b\u72af\u7f6a\u70ed\u70b9\u65f6\u66f4\u51c6\u786e\uff0c\u5e76\u80fd\u591f\u6a21\u62df\u653f\u7b56\u5e72\u9884\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7684\u57ce\u5e02\u72af\u7f6a\u5efa\u6a21\u65b9\u6cd5\u5b58\u5728\u89e3\u91ca\u6027\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u540c\u65f6\u7f3a\u4e4f\u9002\u5e94\u53d8\u5316\u73af\u5883\u7684\u7075\u6d3b\u6027\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u521b\u5efa\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u6846\u67b6\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u6a21\u62df\u591a\u6a21\u6001\u57ce\u5e02\u60c5\u5883\u4e0b\u7684\u57ce\u5e02\u72af\u7f6a\u884c\u4e3a\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCrimeMind\u7684\u521b\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4f8b\u884c\u6d3b\u52a8\u7406\u8bba\uff08RAT\uff09\u7684\u4f18\u52bf\uff0c\u80fd\u591f\u5904\u7406\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u57ce\u5e02\u7279\u5f81\uff0c\u5e76\u63a8\u7406\u72af\u7f6a\u884c\u4e3a\u3002\u4e3a\u514b\u670dRAT\u4e2dLLM\u63a8\u65ad\u73af\u5883\u5b89\u5168\u6027\u96be\u4ee5\u8bc4\u4f30\u4fdd\u62a4\u6548\u80fd\u7684\u95ee\u9898\uff0c\u6536\u96c6\u4e86\u5c0f\u89c4\u6a21\u4eba\u5de5\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u65e0\u8bad\u7ec3\u6587\u672c\u68af\u5ea6\u65b9\u6cd5\u5bf9CrimeMind\u7684\u611f\u77e5\u8fdb\u884c\u4e86\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCrimeMind\u5728\u56db\u4e2a\u7f8e\u56fd\u4e3b\u8981\u57ce\u5e02\u7684\u72af\u7f6a\u70ed\u70b9\u9884\u6d4b\u548c\u7a7a\u95f4\u5206\u5e03\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684ABM\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe24%\u7684\u6027\u80fd\u63d0\u5347\u3002\u8be5\u6846\u67b6\u8fd8\u80fd\u591f\u6210\u529f\u6a21\u62df\u5916\u90e8\u4e8b\u4ef6\u548c\u653f\u7b56\u5e72\u9884\u7684\u53cd\u4e8b\u5b9e\u573a\u666f\u53d8\u5316\uff0c\u53cd\u6620\u5176\u5728\u73b0\u5b9e\u5e72\u9884\u8bc4\u4f30\u4e2d\u7684\u6548\u7528\u3002", "conclusion": "CrimeMind\u6846\u67b6\u80fd\u591f\u7ec6\u5316\u4e2a\u4f53\u884c\u4e3a\u5efa\u6a21\uff0c\u5e76\u652f\u6301\u5bf9\u73b0\u5b9e\u4e16\u754c\u5e72\u9884\u63aa\u65bd\u7684\u8bc4\u4f30\uff0c\u5c55\u73b0\u4e86\u5728\u771f\u5b9e\u57ce\u5e02\u72af\u7f6a\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.05606", "pdf": "https://arxiv.org/pdf/2506.05606", "abs": "https://arxiv.org/abs/2506.05606", "authors": ["Ziyi Wang", "Yuxuan Lu", "Wenbo Li", "Amirali Amini", "Bo Sun", "Yakov Bart", "Weimin Lyu", "Jiri Gesi", "Tian Wang", "Jing Huang", "Yu Su", "Upol Ehsan", "Malihe Alikhani", "Toby Jia-Jun Li", "Lydia Chilton", "Dakuo Wang"], "title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "Can large language models (LLMs) accurately simulate the next web action of a\nspecific user? While LLMs have shown promising capabilities in generating\n``believable'' human behaviors, evaluating their ability to mimic real user\nbehaviors remains an open challenge, largely due to the lack of high-quality,\npublicly available datasets that capture both the observable actions and the\ninternal reasoning of an actual human user. To address this gap, we introduce\nOPERA, a novel dataset of Observation, Persona, Rationale, and Action collected\nfrom real human participants during online shopping sessions. OPERA is the\nfirst public dataset that comprehensively captures: user personas, browser\nobservations, fine-grained web actions, and self-reported just-in-time\nrationales. We developed both an online questionnaire and a custom browser\nplugin to gather this dataset with high fidelity. Using OPERA, we establish the\nfirst benchmark to evaluate how well current LLMs can predict a specific user's\nnext action and rationale with a given persona and <observation, action,\nrationale> history. This dataset lays the groundwork for future research into\nLLM agents that aim to act as personalized digital twins for human.", "AI": {"tldr": "\u5f15\u5165OPERA\u6570\u636e\u96c6\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6a21\u62df\u7528\u6237\u884c\u4e3a\u7684\u80fd\u529b\uff0c\u4e3a\u4e2a\u6027\u5316\u6570\u5b57\u52a9\u7406\u7684\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6a21\u62df\u7528\u6237\u4e0b\u4e00\u6b65\u7f51\u7edc\u884c\u52a8\u7684\u80fd\u529b\u548c\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u65e2\u5305\u542b\u53ef\u89c2\u5bdf\u884c\u4e3a\u53c8\u5305\u542b\u7528\u6237\u5185\u5728\u63a8\u7406\u7684\u9ad8\u8d28\u91cf\u516c\u5f00\u6570\u636e\u96c6\u65f6\u3002", "method": "\u4ecb\u7ecdOPERA\u6570\u636e\u96c6\uff0c\u5305\u542b\u4ece\u771f\u4eba\u5728\u7ebf\u8d2d\u7269\u4f1a\u8bdd\u4e2d\u6536\u96c6\u7684\u89c2\u5bdf\u3001\u4eba\u683c\u3001\u63a8\u7406\u548c\u884c\u52a8\u3002\u5229\u7528\u5728\u7ebf\u95ee\u5377\u548c\u5b9a\u5236\u6d4f\u89c8\u5668\u63d2\u4ef6\u9ad8\u4fdd\u771f\u6536\u96c6\u6570\u636e\u3002\u4ee5\u6b64\u6570\u636e\u96c6\u5efa\u7acb\u4e86\u8bc4\u4f30\u5f53\u524dLLMs\u9884\u6d4b\u7279\u5b9a\u7528\u6237\u4e0b\u4e00\u6b65\u884c\u52a8\u53ca\u63a8\u7406\u7684\u57fa\u51c6\u3002", "result": "\u5f00\u53d1\u4e86OPERA\u6570\u636e\u96c6\uff0c\u80fd\u591f\u6355\u83b7\u7528\u6237\u89d2\u8272\u3001\u6d4f\u89c8\u89c2\u5bdf\u3001\u7ec6\u7c92\u5ea6\u7f51\u7edc\u884c\u52a8\u548c\u5373\u65f6\u81ea\u8ff0\u63a8\u7406\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u4e2a\u6027\u5316\u6570\u5b57\u5b6a\u751f\u4f53\u4e3a\u76ee\u6807\u7684LLM\u4ee3\u7406\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "OPERA\u6570\u636e\u96c6\u7684\u5f15\u5165\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbLLMs\u5728\u6a21\u62df\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\uff0c\u63a8\u52a8\u4e2a\u6027\u5316\u6570\u5b57\u52a9\u7406\u7684\u7814\u7a76\u3002"}}
{"id": "2506.05515", "pdf": "https://arxiv.org/pdf/2506.05515", "abs": "https://arxiv.org/abs/2506.05515", "authors": ["Adrien Cort\u00e9s", "R\u00e9mi Rehm", "Victor Letzelter"], "title": "Winner-takes-all for Multivariate Probabilistic Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "ICML 2025", "summary": "We introduce TimeMCL, a method leveraging the Multiple Choice Learning (MCL)\nparadigm to forecast multiple plausible time series futures. Our approach\nemploys a neural network with multiple heads and utilizes the Winner-Takes-All\n(WTA) loss to promote diversity among predictions. MCL has recently gained\nattention due to its simplicity and ability to address ill-posed and ambiguous\ntasks. We propose an adaptation of this framework for time-series forecasting,\npresenting it as an efficient method to predict diverse futures, which we\nrelate to its implicit quantization objective. We provide insights into our\napproach using synthetic data and evaluate it on real-world time series,\ndemonstrating its promising performance at a light computational cost.", "AI": {"tldr": "TimeMCL\u662f\u4e00\u79cd\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u591a\u9009\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u548c\u80dc\u8005\u4e3a\u738b\u635f\u5931\u5b9e\u73b0\u591a\u6837\u5316\u9884\u6d4b\uff0c\u5728\u591a\u6837\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "motivation": "\u7531\u4e8eMCL\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u548c\u6a21\u7cca\u4efb\u52a1\u4e0a\u7684\u7b80\u5355\u548c\u6709\u6548\u6027\uff0c\u5f15\u8d77\u4e86\u6781\u5927\u7684\u5173\u6ce8\u3002\u4e3a\u6b64\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u6539\u7f16\u6846\u67b6\u4ee5\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "method": "TimeMCL\u65b9\u6cd5\u91c7\u7528\u4e86\u591a\u5934\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5229\u7528WTA\u635f\u5931\u6765\u4fc3\u8fdb\u9884\u6d4b\u7ed3\u679c\u7684\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTimeMCL\u5728\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u8868\u73b0\u51fa\u4ee4\u4eba\u9f13\u821e\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u3002", "conclusion": "TimeMCL\u65b9\u6cd5\u88ab\u63d0\u51fa\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u591a\u6837\u5316\u672a\u6765\u9884\u6d4b\u5de5\u5177\uff0c\u80fd\u591f\u5728\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u591a\u6837\u5316\u9884\u6d4b\u3002"}}
{"id": "2506.06052", "pdf": "https://arxiv.org/pdf/2506.06052", "abs": "https://arxiv.org/abs/2506.06052", "authors": ["Kostis Michailidis", "Dimos Tsouros", "Tias Guns"], "title": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "categories": ["cs.AI"], "comment": null, "summary": "Combinatorial problems are present in a wide range of industries. Constraint\nProgramming (CP) is a well-suited problem-solving paradigm, but its core\nprocess, namely constraint modelling, is a bottleneck for wider adoption.\nAiming to alleviate this bottleneck, recent studies have explored using Large\nLanguage Models (LLMs) as modelling assistants, transforming combinatorial\nproblem descriptions to executable constraint models, similar to coding\nassistants. However, the existing evaluation datasets for constraint modelling\nare often limited to small, homogeneous, or domain-specific instances, which do\nnot capture the diversity of real-world scenarios. This work addresses this gap\nby introducing CP-Bench, a novel benchmark dataset that includes a diverse set\nof well-known combinatorial problem classes sourced from the CP community,\nstructured explicitly for evaluating LLM-driven CP modelling. With this\ndataset, and given the variety of constraint modelling frameworks, we compare\nand evaluate the modelling capabilities of LLMs for three distinct constraint\nmodelling systems, which vary in abstraction level and underlying syntax: the\nhigh-level MiniZinc language and Python-based CPMpy library, and the\nlower-level Python interface of the OR-Tools CP-SAT solver. In order to enhance\nthe ability of LLMs to produce valid constraint models, we systematically\nevaluate the use of prompt-based and inference-time compute methods adapted\nfrom existing LLM-based code generation research. Our results underscore the\nmodelling convenience provided by Python-based frameworks, as well as the\neffectiveness of documentation-rich system prompts, which, augmented with\nrepeated sampling and self-verification, achieve further improvements, reaching\nup to 70\\% accuracy on this new, highly challenging benchmark.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86CP-Bench\u6570\u636e\u96c6\u8bc4\u4f30LLM\u5728\u4e09\u79cd\u7ea6\u675f\u6a21\u578b\u7cfb\u7edf\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u901a\u8fc7Python\u6846\u67b6\u548c\u7cfb\u7edf\u63d0\u793a\u589e\u5f3a\uff0c\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u523070%\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u6a21\u578b\u8bc4\u4f30\u6570\u636e\u96c6\u5728\u89c4\u6a21\u3001\u540c\u8d28\u6027\u6216\u9886\u57df\u7279\u5b9a\u5b9e\u4f8b\u4e0a\u8fc7\u4e8e\u6709\u9650\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u7684\u591a\u6837\u6027\u3002\u56e0\u6b64\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u91c7\u7528\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u751f\u6210\u6280\u672f\uff0c\u8fdb\u884c\u63d0\u793a\u548c\u63a8\u7406\u65f6\u8ba1\u7b97\u7684\u65b9\u6cd5\u8bc4\u4f30\uff0c\u4ee5\u63d0\u9ad8\u751f\u6210\u6709\u6548\u7ea6\u675f\u6a21\u578b\u7684\u80fd\u529b\u3002", "result": "\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6570\u636e\u96c6CP-Bench\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u7ea6\u675f\u6a21\u578b\u7cfb\u7edf\u4e2dLLM\u7684\u80fd\u529b\uff0c\u5e76\u53d1\u73b0Python\u6846\u67b6\u7684\u4fbf\u5229\u6027\u548c\u6587\u6863\u4e30\u5bcc\u7684\u7cfb\u7edf\u63d0\u793a\u6709\u6548\u6027\uff0c\u51c6\u786e\u7387\u8fbe\u523070%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e Python \u5e93\u5728\u7ea6\u675f\u6a21\u578b\u751f\u6210\u65b9\u9762\u5177\u6709\u4fbf\u5229\u6027\uff0c\u5e76\u4e14\u914d\u5408\u6587\u6863\u4e30\u5bcc\u7684\u7cfb\u7edf\u63d0\u793a\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u8fbe\u523070% \u7684\u6b63\u786e\u7387\u3002"}}
{"id": "2506.05610", "pdf": "https://arxiv.org/pdf/2506.05610", "abs": "https://arxiv.org/abs/2506.05610", "authors": ["Zhecheng Sheng", "Xiruo Ding", "Brian Hur", "Changye Li", "Trevor Cohen", "Serguei Pakhomov"], "title": "Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking", "categories": ["cs.CL"], "comment": "16 pages, 20 figures. Accepted to ACL 2025 Main Conference", "summary": "Deep transformer models have been used to detect linguistic anomalies in\npatient transcripts for early Alzheimer's disease (AD) screening. While\npre-trained neural language models (LMs) fine-tuned on AD transcripts perform\nwell, little research has explored the effects of the gender of the speakers\nrepresented by these transcripts. This work addresses gender confounding in\ndementia detection and proposes two methods: the $\\textit{Extended Confounding\nFilter}$ and the $\\textit{Dual Filter}$, which isolate and ablate weights\nassociated with gender. We evaluate these methods on dementia datasets with\nfirst-person narratives from patients with cognitive impairment and healthy\ncontrols. Our results show transformer models tend to overfit to training data\ndistributions. Disrupting gender-related weights results in a deconfounded\ndementia classifier, with the trade-off of slightly reduced dementia detection\nperformance.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u6df1\u5ea6\u53d8\u538b\u5668\u6a21\u578b\u8fdb\u884c\u963f\u5c14\u8328\u6d77\u9ed8\u75c7\u65e9\u671f\u68c0\u6d4b\uff0c\u63d0\u51fa\u65b9\u6cd5\u89e3\u51b3\u6027\u522b\u6df7\u6dc6\u95ee\u9898\uff0c\u7ed3\u679c\u8868\u660e\u53bb\u6027\u522b\u6743\u91cd\u53ef\u964d\u4f4e\u8fc7\u62df\u5408\u4f46\u6027\u80fd\u7565\u51cf\u3002", "motivation": "\u63a2\u7d22\u8bf4\u8bdd\u8005\u6027\u522b\u5bf9\u57fa\u4e8e\u6df1\u5ea6\u53d8\u538b\u5668\u6a21\u578b\u7684\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c7\u68c0\u6d4b\u4e2d\u7684\u5f71\u54cd\uff0c\u4ee5\u89e3\u51b3\u75f4\u5446\u68c0\u6d4b\u4e2d\u7684\u6027\u522b\u6df7\u6dc6\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u6269\u5c55\u6df7\u6dc6\u8fc7\u6ee4\u5668\u548c\u53cc\u91cd\u8fc7\u6ee4\u5668\uff0c\u7528\u4e8e\u9694\u79bb\u548c\u6d88\u9664\u4e0e\u6027\u522b\u76f8\u5173\u7684\u6743\u91cd\u3002\u4f7f\u7528\u6765\u81ea\u8ba4\u77e5\u969c\u788d\u60a3\u8005\u548c\u5065\u5eb7\u5bf9\u7167\u8005\u7684\u7b2c\u4e00\u4eba\u79f0\u53d9\u8ff0\u7684\u75f4\u5446\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d8\u538b\u5668\u6a21\u578b\u5728\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e2d\u5f80\u5f80\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u901a\u8fc7\u5e72\u6270\u4e0e\u6027\u522b\u76f8\u5173\u7684\u6743\u91cd\uff0c\u53ef\u4ee5\u5f97\u5230\u53bb\u6df7\u6dc6\u7684\u75f4\u5446\u5206\u7c7b\u5668\uff0c\u4f46\u8fd9\u4f1a\u7a0d\u5fae\u964d\u4f4e\u75f4\u5446\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5e72\u6270\u4e0e\u6027\u522b\u76f8\u5173\u7684\u6743\u91cd\u53ef\u4ee5\u4f7f\u75f4\u5446\u5206\u7c7b\u5668\u53bb\u6df7\u6dc6\uff0c\u4f46\u540c\u65f6\u4f1a\u7a0d\u5fae\u964d\u4f4e\u75f4\u5446\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.05526", "pdf": "https://arxiv.org/pdf/2506.05526", "abs": "https://arxiv.org/abs/2506.05526", "authors": ["Michal Klein", "Alireza Mousavi-Hosseini", "Stephen Zhang", "Marco Cuturi"], "title": "On Fitting Flow Models with Large Sinkhorn Couplings", "categories": ["cs.LG", "stat.ML"], "comment": "20 pages, 14 figures", "summary": "Flow models transform data gradually from one modality (e.g. noise) onto\nanother (e.g. images). Such models are parameterized by a time-dependent\nvelocity field, trained to fit segments connecting pairs of source and target\npoints. When the pairing between source and target points is given, training\nflow models boils down to a supervised regression problem. When no such pairing\nexists, as is the case when generating data from noise, training flows is much\nharder. A popular approach lies in picking source and target points\nindependently. This can, however, lead to velocity fields that are slow to\ntrain, but also costly to integrate at inference time. In theory, one would\ngreatly benefit from training flow models by sampling pairs from an optimal\ntransport (OT) measure coupling source and target, since this would lead to a\nhighly efficient flow solving the Benamou and Brenier dynamical OT problem. In\npractice, recent works have proposed to sample mini-batches of $n$ source and\n$n$ target points and reorder them using an OT solver to form better pairs.\nThese works have advocated using batches of size $n\\approx 256$, and considered\nOT solvers that return couplings that are either sharp (using e.g. the\nHungarian algorithm) or blurred (using e.g. entropic regularization, a.k.a.\nSinkhorn). We follow in the footsteps of these works by exploring the benefits\nof increasing $n$ by three to four orders of magnitude, and look more carefully\non the effect of the entropic regularization $\\varepsilon$ used in the Sinkhorn\nalgorithm. Our analysis is facilitated by new scale invariant quantities to\nreport the sharpness of a coupling, while our sharded computations across\nmultiple GPU or GPU nodes allow scaling up $n$. We show that in both synthetic\nand image generation tasks, flow models greatly benefit when fitted with large\nSinkhorn couplings, with a low entropic regularization $\\varepsilon$.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u589e\u52a0Sinkhorn\u8026\u5408\u7684\u89c4\u6a21\u53ca\u964d\u4f4e\u71b5\u6b63\u5219\u5316\u6765\u63d0\u9ad8\u6d41\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u4f18\u5316\u6d41\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4ece\u6e90\u70b9\u548c\u76ee\u6807\u70b9\u4e2d\u91c7\u6837\u5bf9\uff0c\u4ee5\u9002\u5e94\u52a8\u6001OT\u95ee\u9898\uff0c\u964d\u4f4e\u5728\u751f\u6210\u6570\u636e\u65f6\u7684\u8bad\u7ec3\u96be\u5ea6\u548c\u63a8\u7406\u65f6\u7684\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5b9e\u9a8c\u5206\u6790\u5305\u62ec\u5408\u6210\u4efb\u52a1\u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\uff0c\u91c7\u7528Sinkhorn\u7b97\u6cd5\uff0c\u901a\u8fc7\u65b0\u7684\u5c3a\u5ea6\u4e0d\u53d8\u91cf\u62a5\u544a\u8026\u5408\u7684\u9510\u5ea6\uff0c\u5e76\u901a\u8fc7\u5206\u7247\u8ba1\u7b97\u5728\u591a\u4e2aGPU\u8282\u70b9\u4e0a\u6269\u5927$n$\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5408\u6210\u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u5f53\u6d41\u6a21\u578b\u4f7f\u7528\u5927\u578bSinkhorn\u8026\u5408\u548c\u4f4e\u71b5\u6b63\u5219\u5316\u8fdb\u884c\u62df\u5408\u65f6\uff0c\u6027\u80fd\u589e\u5f3a\u663e\u8457\u3002", "conclusion": "\u5927\u578bSinkhorn\u8026\u5408\u5668\u548c\u4f4e\u71b5\u6b63\u5219\u5316\u80fd\u591f\u5728\u6d41\u6a21\u578b\u7684\u62df\u5408\u8fc7\u7a0b\u4e2d\u63d0\u4f9b\u663e\u8457\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.06121", "pdf": "https://arxiv.org/pdf/2506.06121", "abs": "https://arxiv.org/abs/2506.06121", "authors": ["Ziyu Zhang", "Peilan Xu", "Yuetong Sun", "Yuhui Shi", "Wenjian Luo"], "title": "Decomposability-Guaranteed Cooperative Coevolution for Large-Scale Itinerary Planning", "categories": ["cs.AI"], "comment": null, "summary": "Large-scale itinerary planning is a variant of the traveling salesman\nproblem, aiming to determine an optimal path that maximizes the collected\npoints of interest (POIs) scores while minimizing travel time and cost, subject\nto travel duration constraints. This paper analyzes the decomposability of\nlarge-scale itinerary planning, proving that strict decomposability is\ndifficult to satisfy, and introduces a weak decomposability definition based on\na necessary condition, deriving the corresponding graph structures that fulfill\nthis property. With decomposability guaranteed, we propose a novel\nmulti-objective cooperative coevolutionary algorithm for large-scale itinerary\nplanning, addressing the challenges of component imbalance and interactions.\nSpecifically, we design a dynamic decomposition strategy based on the\nnormalized fitness within each component, define optimization potential\nconsidering component scale and contribution, and develop a computational\nresource allocation strategy. Finally, we evaluate the proposed algorithm on a\nset of real-world datasets. Comparative experiments with state-of-the-art\nmulti-objective itinerary planning algorithms demonstrate the superiority of\nour approach, with performance advantages increasing as the problem scale\ngrows.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u76ee\u6807\u534f\u540c\u8fdb\u5316\u7b97\u6cd5\u7528\u4e8e\u5927\u89c4\u6a21\u884c\u7a0b\u89c4\u5212\uff0c\u8bc1\u660e\u4e86\u5f31\u53ef\u5206\u89e3\u6027\u7684\u6709\u6548\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u4e14\u968f\u7740\u95ee\u9898\u89c4\u6a21\u7684\u589e\u52a0\uff0c\u5176\u4f18\u52bf\u66f4\u4e3a\u660e\u663e\u3002", "motivation": "\u9488\u5bf9\u65c5\u884c\u5546\u95ee\u9898\u7684\u53d8\u4f53\u2014\u2014\u5927\u89c4\u6a21\u884c\u7a0b\u89c4\u5212\uff0c\u8fd9\u9879\u7814\u7a76\u65e8\u5728\u786e\u5b9a\u4e00\u6761\u6700\u4f18\u8def\u5f84\uff0c\u4f7f\u5f97\u5728\u65c5\u884c\u65f6\u9650\u7ea6\u675f\u4e0b\uff0c\u6700\u5927\u5316\u6536\u96c6\u7684\u5174\u8da3\u70b9\u5206\u6570\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u65c5\u884c\u65f6\u95f4\u548c\u6210\u672c\u3002\u672c\u6587\u5206\u6790\u4e86\u5927\u89c4\u6a21\u884c\u7a0b\u89c4\u5212\u7684\u53ef\u5206\u89e3\u6027\uff0c\u5e76\u6307\u51fa\u4e25\u683c\u7684\u53ef\u5206\u89e3\u6027\u96be\u4ee5\u6ee1\u8db3\uff0c\u56e0\u800c\u5f15\u5165\u4e86\u57fa\u4e8e\u5fc5\u8981\u6761\u4ef6\u7684\u5f31\u53ef\u5206\u89e3\u6027\u5b9a\u4e49\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6807\u51c6\u5316\u9002\u5e94\u5ea6\u7684\u52a8\u6001\u5206\u89e3\u7b56\u7565\uff0c\u5b9a\u4e49\u4e86\u8003\u8651\u7ec4\u5206\u89c4\u6a21\u548c\u8d21\u732e\u7684\u4f18\u5316\u6f5c\u529b\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u7b56\u7565\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u76ee\u6807\u534f\u540c\u8fdb\u5316\u7b97\u6cd5\uff0c\u5e76\u5728\u4e00\u7ec4\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u5bf9\u8be5\u7b97\u6cd5\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u7684\u8bc4\u4f30\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u591a\u76ee\u6807\u884c\u7a0b\u89c4\u5212\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u5176\u4f18\u8d8a\u6027\u968f\u7740\u95ee\u9898\u89c4\u6a21\u7684\u589e\u52a0\u800c\u63d0\u5347\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u884c\u7a0b\u89c4\u5212\u95ee\u9898\u4e0a\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u662f\u5728\u95ee\u9898\u89c4\u6a21\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u591a\u76ee\u6807\u884c\u7a0b\u89c4\u5212\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6027\u80fd\u4f18\u52bf\u66f4\u4e3a\u663e\u8457\u3002"}}
{"id": "2506.05629", "pdf": "https://arxiv.org/pdf/2506.05629", "abs": "https://arxiv.org/abs/2506.05629", "authors": ["Ananth Muppidi", "Abhilash Nandy", "Sambaran Bandyopadhyay"], "title": "Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs", "categories": ["cs.CL"], "comment": "Accepted in ACL 2025 (Main) Conference", "summary": "The performance of large language models in domain-specific tasks\nnecessitates fine-tuning, which is computationally expensive and technically\nchallenging. This paper focuses on parameter-efficient fine-tuning using soft\nprompting, a promising approach that adapts pre-trained models to downstream\ntasks by learning a small set of parameters. We propose a novel Input Dependent\nSoft Prompting technique with a self-Attention Mechanism (ID-SPAM) that\ngenerates soft prompts based on the input tokens and attends different tokens\nwith varying importance. Our method is simple and efficient, keeping the number\nof trainable parameters small. We show the merits of the proposed approach\ncompared to state-of-the-art techniques on various tasks and show the improved\nzero shot domain transfer capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684ID-SPAM\u8f6f\u63d0\u793a\u5fae\u8c03\u6280\u672f\uff0c\u901a\u8fc7\u51cf\u5c11\u8bad\u7ec3\u53c2\u6570\u91cf\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9886\u57df\u8fc1\u79fb\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u9700\u8981\u8fdb\u884c\u5fae\u8c03\uff0c\u8fd9\u79cd\u5fae\u8c03\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u5e76\u4e14\u6280\u672f\u4e0a\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u5bfb\u627e\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\u663e\u5f97\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u8f93\u5165\u4f9d\u8d56\u7684\u8f6f\u63d0\u793a\u6280\u672f\u4e0e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u76f8\u7ed3\u5408\uff0c\u5f00\u53d1\u51faID-SPAM\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8c03\u6574\u5c11\u91cf\u53c2\u6570\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u4e0e\u6700\u5148\u8fdb\u7684\u6280\u672f\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u63d0\u5347\u4e86\u96f6\u6837\u672c\u9886\u57df\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aID-SPAM\u7684\u8f93\u5165\u4f9d\u8d56\u8f6f\u63d0\u793a\u6280\u672f\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u57fa\u4e8e\u8f93\u5165\u7684\u8f6f\u63d0\u793a\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u5c11\u91cf\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u9886\u57df\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2506.05530", "pdf": "https://arxiv.org/pdf/2506.05530", "abs": "https://arxiv.org/abs/2506.05530", "authors": ["Snir Hordan", "Maya Bechler-Speicher", "Gur Lifshitz", "Nadav Dym"], "title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "categories": ["cs.LG"], "comment": "9 pages main text", "summary": "Spectral features are widely incorporated within Graph Neural Networks (GNNs)\nto improve their expressive power, or their ability to distinguish among\nnon-isomorphic graphs. One popular example is the usage of graph Laplacian\neigenvectors for positional encoding in MPNNs and Graph Transformers. The\nexpressive power of such Spectrally-enhanced GNNs (SGNNs) is usually evaluated\nvia the k-WL graph isomorphism test hierarchy and homomorphism counting. Yet,\nthese frameworks align poorly with the graph spectra, yielding limited insight\ninto SGNNs' expressive power. We leverage a well-studied paradigm of\nclassifying graphs by their largest eigenvalue multiplicity to introduce an\nexpressivity hierarchy for SGNNs. We then prove that many SGNNs are incomplete\neven on graphs with distinct eigenvalues. To mitigate this deficiency, we adapt\nrotation equivariant neural networks to the graph spectra setting to propose a\nmethod to provably improve SGNNs' expressivity on simple spectrum graphs. We\nempirically verify our theoretical claims via an image classification\nexperiment on the MNIST Superpixel dataset and eigenvector canonicalization on\ngraphs from ZINC.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u6700\u5927\u7279\u5f81\u503c\u591a\u91cd\u6027\u7684\u8868\u8fbe\u5c42\u6b21\u7ed3\u6784\u548c\u9002\u5e94\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u6765\u63d0\u9ad8SGNNs\u7684\u56fe\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u76ee\u524d\u7528\u4e8e\u8bc4\u4ef7SGNNs\u8868\u73b0\u80fd\u529b\u7684\u6846\u67b6\u4e0e\u56fe\u8c31\u5bf9\u9f50\u4e0d\u4f73\uff0c\u56e0\u6b64\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u8868\u8fbe\u5c42\u6b21\u7ed3\u6784\u6765\u6539\u5584\u8fd9\u79cd\u4e0d\u8db3\u3002", "method": "\u5c06\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u9002\u5e94\u4e8e\u56fe\u8c31\u8bbe\u7f6e\uff0c\u5e76\u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u548c\u7279\u5f81\u5411\u91cf\u89c4\u8303\u5316\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7MNIST Superpixel\u6570\u636e\u96c6\u7684\u56fe\u50cf\u5206\u7c7b\u5b9e\u9a8c\u548cZINC\u6570\u636e\u96c6\u4e0a\u7684\u7279\u5f81\u5411\u91cf\u89c4\u8303\u5316\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u4e3b\u5f20\u3002", "conclusion": "\u901a\u8fc7\u9002\u5e94\u65cb\u8f6c\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u5230\u56fe\u8c31\u8bbe\u7f6e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u9ad8SGNNs\u5728\u7b80\u5355\u9891\u8c31\u56fe\u4e0a\u7684\u8868\u8fbe\u80fd\u529b\u3002"}}
{"id": "2506.06216", "pdf": "https://arxiv.org/pdf/2506.06216", "abs": "https://arxiv.org/abs/2506.06216", "authors": ["Jialu Zhang", "Chu-Min Li", "Sami Cherif", "Shuolin Li", "Zhifei Zheng"], "title": "Integer Linear Programming Preprocessing for Maximum Satisfiability", "categories": ["cs.AI"], "comment": null, "summary": "The Maximum Satisfiability problem (MaxSAT) is a major optimization challenge\nwith numerous practical applications. In recent MaxSAT evaluations, most MaxSAT\nsolvers have adopted an ILP solver as part of their portfolios. This paper\ninvestigates the impact of Integer Linear Programming (ILP) preprocessing\ntechniques on MaxSAT solving. Experimental results show that ILP preprocessing\ntechniques help WMaxCDCL-OpenWbo1200, the winner of the MaxSAT evaluation 2024\nin the unweighted track, solve 15 additional instances. Moreover, current\nstate-of-the-art MaxSAT solvers heavily use an ILP solver in their portfolios,\nwhile our proposed approach reduces the need to call an ILP solver in a\nportfolio including WMaxCDCL or MaxCDCL.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86ILP\u9884\u5904\u7406\u6280\u672f\u5bf9MaxSAT\u6c42\u89e3\u7684\u6548\u679c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6280\u672f\u53ef\u663e\u8457\u63d0\u5347\u6c42\u89e3\u5668\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11ILP\u6c42\u89e3\u5668\u7684\u4f7f\u7528\u3002", "motivation": "\u63a2\u8ba8ILP\u9884\u5904\u7406\u6280\u672f\u5bf9\u4e8eMaxSAT\u6c42\u89e3\u5668\u6027\u80fd\u7684\u63d0\u5347\u4f5c\u7528\uff0c\u4ee5\u4f18\u5316\u6c42\u89e3\u5668\u7684\u4f7f\u7528\u7b56\u7565\u3002", "method": "\u91c7\u7528ILP\u9884\u5904\u7406\u6280\u672f\u5bf9MaxSAT\u95ee\u9898\u8fdb\u884c\u6c42\u89e3\uff0c\u7ed3\u5408\u73b0\u6709\u7684MaxSAT\u6c42\u89e3\u5668\u7ec4\u5408\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cILP\u9884\u5904\u7406\u6280\u672f\u4f7f\u5f97WMaxCDCL-OpenWbo1200\u5728\u672a\u52a0\u6743\u8d5b\u9053\u4e2d\u591a\u89e3\u51b3\u4e8615\u4e2a\u5b9e\u4f8b\uff0c\u5e76\u964d\u4f4e\u4e86ILP\u6c42\u89e3\u5668\u5728\u7ec4\u5408\u4e2d\u7684\u8c03\u7528\u6b21\u6570\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684ILP\u9884\u5904\u7406\u6280\u672f\u80fd\u591f\u663e\u8457\u589e\u52a0MaxSAT\u6c42\u89e3\u5668\u89e3\u51b3\u95ee\u9898\u7684\u5b9e\u4f8b\u6570\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u5bf9ILP\u6c42\u89e3\u5668\u7684\u8c03\u7528\u9700\u6c42\u3002"}}
{"id": "2506.05635", "pdf": "https://arxiv.org/pdf/2506.05635", "abs": "https://arxiv.org/abs/2506.05635", "authors": ["Christine de Kock", "Arij Riabi", "Zeerak Talat", "Michael Sejr Schlichtkrull", "Pranava Madhyastha", "Ed Hovy"], "title": "IYKYK: Using language models to decode extremist cryptolects", "categories": ["cs.CL"], "comment": null, "summary": "Extremist groups develop complex in-group language, also referred to as\ncryptolects, to exclude or mislead outsiders. We investigate the ability of\ncurrent language technologies to detect and interpret the cryptolects of two\nonline extremist platforms. Evaluating eight models across six tasks, our\nresults indicate that general purpose LLMs cannot consistently detect or decode\nextremist language. However, performance can be significantly improved by\ndomain adaptation and specialised prompting techniques. These results provide\nimportant insights to inform the development and deployment of automated\nmoderation technologies. We further develop and release novel labelled and\nunlabelled datasets, including 19.4M posts from extremist platforms and\nlexicons validated by human experts.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u7528\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u68c0\u6d4b\u6781\u7aef\u4e3b\u4e49\u8bed\u8a00\uff0c\u9886\u57df\u9002\u914d\u548c\u4e13\u95e8\u63d0\u793a\u6280\u672f\u53ef\u63d0\u9ad8\u6027\u80fd\uff0c\u63d0\u4f9b\u91cd\u8981\u6d1e\u5bdf\u4ee5\u5f00\u53d1\u81ea\u52a8\u5316\u5ba1\u6838\u6280\u672f\u3002", "motivation": "\u63a2\u8ba8\u5f53\u524d\u8bed\u8a00\u6280\u672f\u662f\u5426\u80fd\u68c0\u6d4b\u548c\u89e3\u91ca\u6781\u7aef\u4e3b\u4e49\u5e73\u53f0\u7684\u52a0\u5bc6\u8bed\u8a00\u3002", "method": "\u8bc4\u4f30\u516b\u79cd\u6a21\u578b\u5728\u516d\u9879\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5f00\u53d1\u65b0\u7684\u6807\u6ce8\u548c\u672a\u6807\u6ce8\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc7\u9886\u57df\u9002\u914d\u548c\u4e13\u95e8\u63d0\u793a\u6280\u672f\uff0c\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u6d4b\u548c\u89e3\u7801\u6027\u80fd\u5f97\u5230\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u901a\u7528\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u4e00\u81f4\u5730\u68c0\u6d4b\u6216\u89e3\u7801\u6781\u7aef\u4e3b\u4e49\u8bed\u8a00\u3002\u901a\u8fc7\u9886\u57df\u9002\u914d\u548c\u4e13\u95e8\u63d0\u793a\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2506.05538", "pdf": "https://arxiv.org/pdf/2506.05538", "abs": "https://arxiv.org/abs/2506.05538", "authors": ["Arnesh Batra", "Anushk Kumar", "Jashn Khemani", "Arush Gumber", "Arhan Jain", "Somil Gupta"], "title": "SocialDF: Benchmark Dataset and Detection Model for Mitigating Harmful Deepfake Content on Social Media Platforms", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "The rapid advancement of deep generative models has significantly improved\nthe realism of synthetic media, presenting both opportunities and security\nchallenges. While deepfake technology has valuable applications in\nentertainment and accessibility, it has emerged as a potent vector for\nmisinformation campaigns, particularly on social media. Existing detection\nframeworks struggle to distinguish between benign and adversarially generated\ndeepfakes engineered to manipulate public perception. To address this\nchallenge, we introduce SocialDF, a curated dataset reflecting real-world\ndeepfake challenges on social media platforms. This dataset encompasses\nhigh-fidelity deepfakes sourced from various online ecosystems, ensuring broad\ncoverage of manipulative techniques. We propose a novel LLM-based multi-factor\ndetection approach that combines facial recognition, automated speech\ntranscription, and a multi-agent LLM pipeline to cross-verify audio-visual\ncues. Our methodology emphasizes robust, multi-modal verification techniques\nthat incorporate linguistic, behavioral, and contextual analysis to effectively\ndiscern synthetic media from authentic content.", "AI": {"tldr": "\u63d0\u51fa\u4e86SocialDF\u6570\u636e\u96c6\u548c\u4e00\u79cd\u65b0\u9896\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\u6765\u5e94\u5bf9\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6df1\u5ea6\u4f2a\u9020\u6311\u6218\u3002\u8fd9\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u9a8c\u8bc1\u6280\u672f\uff0c\u5305\u62ec\u9762\u90e8\u8bc6\u522b\u3001\u8bed\u97f3\u8f6c\u5f55\u548c\u591a\u4ee3\u7406LLM\u7ba1\u9053\u7b49\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u6d4b\u6846\u67b6\u96be\u4ee5\u533a\u5206\u5584\u610f\u548c\u5bf9\u6297\u6027\u751f\u6210\u7684\u6df1\u5ea6\u4f2a\u9020\uff0c\u800c\u540e\u8005\u662f\u64cd\u7eb5\u516c\u4f17\u8ba4\u77e5\u7684\u5de5\u5177\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u7814\u7a76\u56e2\u961f\u5f15\u5165\u4e86SocialDF\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u56e0\u7d20\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u9762\u90e8\u8bc6\u522b\u3001\u81ea\u52a8\u8bed\u97f3\u8f6c\u5f55\u548c\u591a\u4ee3\u7406LLM\u7ba1\u9053\u4ee5\u4ea4\u53c9\u9a8c\u8bc1\u89c6\u542c\u7ebf\u7d22\u3002", "result": "\u4f7f\u7528\u4e86\u4e00\u79cd\u5f3a\u8c03\u5f3a\u5927\u3001\u591a\u6a21\u5f0f\u9a8c\u8bc1\u6280\u672f\u7684\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e86\u8bed\u8a00\u3001\u884c\u4e3a\u548c\u60c5\u5883\u5206\u6790\uff0c\u4ee5\u6709\u6548\u5730\u8fa8\u522b\u5408\u6210\u5a92\u4f53\u4e0e\u771f\u5b9e\u5185\u5bb9\u3002", "conclusion": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aSocialDF\u7684\u7ecf\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\uff0c\u53cd\u6620\u4e86\u5728\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u5b9e\u9645\u5b58\u5728\u7684\u6df1\u5ea6\u4f2a\u9020\u6311\u6218\u3002\u8fd9\u4e00\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u4ece\u5404\u79cd\u5728\u7ebf\u751f\u6001\u7cfb\u7edf\u4e2d\u83b7\u53d6\u7684\u9ad8\u4fdd\u771f\u6df1\u5ea6\u4f2a\u9020\uff0c\u786e\u4fdd\u4e86\u5bf9\u64cd\u7eb5\u6280\u672f\u7684\u5e7f\u6cdb\u8986\u76d6\u3002"}}
{"id": "2506.06254", "pdf": "https://arxiv.org/pdf/2506.06254", "abs": "https://arxiv.org/abs/2506.06254", "authors": ["Weizhi Zhang", "Xinyang Zhang", "Chenwei Zhang", "Liangwei Yang", "Jingbo Shang", "Zhepei Wei", "Henry Peng Zou", "Zijie Huang", "Zhengyang Wang", "Yifan Gao", "Xiaoman Pan", "Lian Xiong", "Jingguo Liu", "Philip S. Yu", "Xian Li"], "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM) empowered agents have recently emerged as advanced\nparadigms that exhibit impressive capabilities in a wide range of domains and\ntasks. Despite their potential, current LLM agents often adopt a\none-size-fits-all approach, lacking the flexibility to respond to users'\nvarying needs and preferences. This limitation motivates us to develop\nPersonaAgent, the first personalized LLM agent framework designed to address\nversatile personalization tasks. Specifically, PersonaAgent integrates two\ncomplementary components - a personalized memory module that includes episodic\nand semantic memory mechanisms; a personalized action module that enables the\nagent to perform tool actions tailored to the user. At the core, the persona\n(defined as unique system prompt for each user) functions as an intermediary:\nit leverages insights from personalized memory to control agent actions, while\nthe outcomes of these actions in turn refine the memory. Based on the\nframework, we propose a test-time user-preference alignment strategy that\nsimulate the latest n interactions to optimize the persona prompt, ensuring\nreal-time user preference alignment through textual loss feedback between\nsimulated and ground-truth responses. Experimental evaluations demonstrate that\nPersonaAgent significantly outperforms other baseline methods by not only\npersonalizing the action space effectively but also scaling during test-time\nreal-world applications. These results underscore the feasibility and potential\nof our approach in delivering tailored, dynamic user experiences.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PersonaAgent\uff0c\u4e2a\u6027\u5316\u7684LLM\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u8bb0\u5fc6\u548c\u52a8\u4f5c\u6a21\u5757\u5b9e\u73b0\u52a8\u6001\u7528\u6237\u4f53\u9a8c\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5f80\u5f80\u91c7\u7528\u4e00\u5200\u5207\u7684\u65b9\u6cd5\uff0c\u96be\u4ee5\u9002\u5e94\u7528\u6237\u591a\u6837\u5316\u7684\u9700\u6c42\u548c\u504f\u597d\uff0c\u56e0\u6b64\u63a8\u52a8\u5f00\u53d1\u66f4\u7075\u6d3b\u7684\u4e2a\u6027\u5316\u4ee3\u7406\u6846\u67b6\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86PersonaAgent\u6846\u67b6\uff0c\u901a\u8fc7\u4e2a\u6027\u5316\u8bb0\u5fc6\u6a21\u5757\u548c\u4e2a\u6027\u5316\u52a8\u4f5c\u6a21\u5757\u6765\u5b9e\u73b0\u4e2a\u6027\u5316\u529f\u80fd\uff0c\u4ee5\u53ca\u63d0\u51fa\u4e86\u4e00\u79cd\u6d4b\u8bd5\u65f6\u7528\u6237\u504f\u597d\u5bf9\u9f50\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cPersonaAgent\u5728\u4e2a\u6027\u5316\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u6d4b\u8bd5\u65f6\u7684\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\u80fd\u3002", "conclusion": "PersonaAgent\u901a\u8fc7\u6574\u5408\u4e2a\u6027\u5316\u8bb0\u5fc6\u6a21\u5757\u548c\u4e2a\u6027\u5316\u52a8\u4f5c\u6a21\u5757\uff0c\u5b9e\u73b0\u4e86\u5728\u5404\u79cd\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u7684\u663e\u8457\u8868\u73b0\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2506.05639", "pdf": "https://arxiv.org/pdf/2506.05639", "abs": "https://arxiv.org/abs/2506.05639", "authors": ["John Kirchenbauer", "Janny Mongkolsupawan", "Yuxin Wen", "Tom Goldstein", "Daphne Ippolito"], "title": "A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages and 8 figures in the main body", "summary": "When language models are trained on textual data, they acquire both knowledge\nabout the structure of language as well as knowledge of facts about the world.\nAt inference time, their knowledge of facts can be leveraged to solve\ninteresting problems and perform useful knowledge work for users. It is well\nknown that language models can verbatim memorize long sequences from their\ntraining data. However, it is much less well understood how language models\nmemorize facts seen during training. In this work, we propose a new dataset to\nspecifically empower researchers to study the dual processes of fact\nmemorization and verbatim sequence memorization. The dataset consists of\nsynthetically-generated, webtext-like documents about fictional events, as well\nas question-answer pairs about the events. We conduct training experiments\nshowing how synthetic data about fictional events can be effective in teasing\napart different forms of memorization. We also document the challenges in\neffectively building realistic, fictional synthetic data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u6570\u636e\u96c6\u7528\u4e8e\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u8fc7\u7a0b\uff0c\u5305\u62ec\u4e8b\u5b9e\u8bb0\u5fc6\u548c\u9010\u5b57\u5e8f\u5217\u8bb0\u5fc6\uff0c\u5e76\u5c55\u793a\u5408\u6210\u6570\u636e\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5728\u8bad\u7ec3\u4e2d\u8bb0\u4f4f\u4e8b\u5b9e\u548c\u9010\u5b57\u5e8f\u5217\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\uff0c\u5305\u62ec\u5408\u6210\u751f\u6210\u7684\u5173\u4e8e\u865a\u6784\u4e8b\u4ef6\u7684\u7c7b\u7f51\u7edc\u6587\u672c\u6587\u6863\u4ee5\u53ca\u5173\u4e8e\u4e8b\u4ef6\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u5e76\u8fdb\u884c\u8bad\u7ec3\u5b9e\u9a8c\u3002", "result": "\u5c55\u793a\u5408\u6210\u6570\u636e\u53ef\u4ee5\u6709\u6548\u5730\u533a\u5206\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u4e8b\u5b9e\u548c\u8bb0\u5fc6\u9010\u5b57\u5e8f\u5217\u7684\u5f62\u5f0f\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5408\u6210\u6570\u636e\u6709\u6548\u5730\u533a\u5206\u4e8b\u5b9e\u8bb0\u5fc6\u548c\u9010\u5b57\u5e8f\u5217\u8bb0\u5fc6\u7684\u4e0d\u540c\u5f62\u5f0f\uff0c\u540c\u65f6\u9762\u4e34\u6784\u5efa\u73b0\u5b9e\u7684\u865a\u6784\u5408\u6210\u6570\u636e\u7684\u6311\u6218\u3002"}}
{"id": "2506.06261", "pdf": "https://arxiv.org/pdf/2506.06261", "abs": "https://arxiv.org/abs/2506.06261", "authors": ["Jihwan Jeong", "Xiaoyu Wang", "Jingmin Wang", "Scott Sanner", "Pascal Poupart"], "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) is crucial when online exploration is\ncostly or unsafe but often struggles with high epistemic uncertainty due to\nlimited data. Existing methods rely on fixed conservative policies, restricting\nadaptivity and generalization. To address this, we propose Reflect-then-Plan\n(RefPlan), a novel doubly Bayesian offline model-based (MB) planning approach.\nRefPlan unifies uncertainty modeling and MB planning by recasting planning as\nBayesian posterior estimation. At deployment, it updates a belief over\nenvironment dynamics using real-time observations, incorporating uncertainty\ninto MB planning via marginalization. Empirical results on standard benchmarks\nshow that RefPlan significantly improves the performance of conservative\noffline RL policies. In particular, RefPlan maintains robust performance under\nhigh epistemic uncertainty and limited data, while demonstrating resilience to\nchanging environment dynamics, improving the flexibility, generalizability, and\nrobustness of offline-learned policies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5 RefPlan\uff0c\u4ee5\u5e94\u5bf9\u9ad8\u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u663e\u8457\u6539\u5584\u4e86\u7b56\u7565\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u5728\u7ebf\u63a2\u7d22\u6602\u8d35\u6216\u4e0d\u5b89\u5168\u65f6\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u6709\u9650\uff0c\u5e38\u5e38\u4f1a\u9762\u4e34\u9ad8 epistemic \u4e0d\u786e\u5b9a\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u4fdd\u5b88\u7b56\u7565\uff0c\u9650\u5236\u4e86\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\u63d0\u51fa RefPlan \u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a Reflect-then-Plan (RefPlan) \u7684\u65b0\u578b\u53cc\u8d1d\u53f6\u65af\u79bb\u7ebf\u6a21\u578b\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u89c4\u5212\u91cd\u65b0\u89e3\u91ca\u4e3a\u8d1d\u53f6\u65af\u540e\u9a8c\u4f30\u8ba1\u6765\u7edf\u4e00\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u548c\u6a21\u578b\u89c4\u5212\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cRefPlan \u663e\u8457\u63d0\u9ad8\u4e86\u4fdd\u5b88\u79bb\u7ebf RL \u7b56\u7565\u7684\u6027\u80fd\uff0c\u4fdd\u6301\u4e86\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u548c\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u8868\u73b0\u51fa\u5bf9\u73af\u5883\u52a8\u6001\u53d8\u5316\u7684\u9002\u5e94\u529b\u3002", "conclusion": "RefPlan \u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5728\u9ad8 epistemic \u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u7a33\u5b9a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u73af\u5883\u52a8\u6001\u53d8\u5316\u65f6\u8868\u73b0\u51fa\u97e7\u6027\u3002"}}
{"id": "2506.05670", "pdf": "https://arxiv.org/pdf/2506.05670", "abs": "https://arxiv.org/abs/2506.05670", "authors": ["Priyanka Dey", "Yugal Khanter", "Aayush Bothra", "Jieyu Zhao", "Emilio Ferrara"], "title": "Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment", "categories": ["cs.CL"], "comment": null, "summary": "As LLMs become central to interactive applications, ranging from tutoring to\nmental health, the ability to express personality in culturally appropriate\nways is increasingly important. While recent works have explored personality\nevaluation of LLMs, they largely overlook the interplay between culture and\npersonality. To address this, we introduce CulturalPersonas, the first\nlarge-scale benchmark with human validation for evaluating LLMs' personality\nexpression in culturally grounded, behaviorally rich contexts. Our dataset\nspans 3,000 scenario-based questions across six diverse countries, designed to\nelicit personality through everyday scenarios rooted in local values. We\nevaluate three LLMs, using both multiple-choice and open-ended response\nformats. Our results show that CulturalPersonas improves alignment with\ncountry-specific human personality distributions (over a 20% reduction in\nWasserstein distance across models and countries) and elicits more expressive,\nculturally coherent outputs compared to existing benchmarks. CulturalPersonas\nsurfaces meaningful modulated trait outputs in response to culturally grounded\nprompts, offering new directions for aligning LLMs to global norms of behavior.\nBy bridging personality expression and cultural nuance, we envision that\nCulturalPersonas will pave the way for more socially intelligent and globally\nadaptive LLMs.", "AI": {"tldr": "CulturalPersonas benchmark evaluates LLMs' personality in culturally rich contexts, improving alignment with human personality through expressive outputs.", "motivation": "The growing importance of LLMs in interactive applications such as tutoring and mental health necessitates the ability to express culturally appropriate personalities.", "method": "Introducing CulturalPersonas, a large-scale benchmark validated by humans, for evaluating LLMs' personality expression in culturally grounded contexts with a dataset of 3,000 scenarios across six countries.", "result": "The CulturalPersonas benchmark improves alignment with country-specific human personality distributions, showing a significant reduction in Wasserstein distance and eliciting expressive, culturally coherent outputs.", "conclusion": "CulturalPersonas paves the way for creating LLMs that are both socially intelligent and globally adaptive, by bridging personality expression with cultural nuances."}}
{"id": "2506.05568", "pdf": "https://arxiv.org/pdf/2506.05568", "abs": "https://arxiv.org/abs/2506.05568", "authors": ["Arian Raje", "Baris Askin", "Divyansh Jhunjhunwala", "Gauri Joshi"], "title": "Ravan: Multi-Head Low-Rank Adaptation for Federated Fine-Tuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have not yet effectively leveraged the vast\namounts of edge-device data, and federated learning (FL) offers a promising\nparadigm to collaboratively fine-tune LLMs without transferring private edge\ndata to the cloud. To operate within the computation and communication\nconstraints of edge devices, recent literature on federated fine-tuning of LLMs\nproposes the use of low-rank adaptation (LoRA) and similar parameter-efficient\nmethods. However, LoRA-based methods suffer from accuracy degradation in FL\nsettings, primarily because of data and computational heterogeneity across\nclients. We propose \\textsc{Ravan}, an adaptive multi-head LoRA method that\nbalances parameter efficiency and model expressivity by reparameterizing the\nweight updates as the sum of multiple LoRA heads\n$s_i\\textbf{B}_i\\textbf{H}_i\\textbf{A}_i$ in which only the core matrices\n$\\textbf{H}_i$ and their lightweight scaling factors $s_i$ are trained. These\ntrainable scaling factors let the optimization focus on the most useful heads,\nrecovering a higher-rank approximation of the full update without increasing\nthe number of communicated parameters since clients upload $s_i\\textbf{H}_i$\ndirectly. Experiments on vision and language benchmarks show that\n\\textsc{Ravan} improves test accuracy by 2-8\\% over prior parameter-efficient\nbaselines, making it a robust and scalable solution for federated fine-tuning\nof LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\\textsc{Ravan}\u7684\u81ea\u9002\u5e94\u591a\u5934LoRA\u65b9\u6cd5\uff0c\u53ef\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u51c6\u786e\u6027\uff0c\u5e76\u89e3\u51b3LoRA\u65b9\u6cd5\u5728\u8054\u90a6\u8bbe\u7f6e\u4e2d\u7684\u51c6\u786e\u6027\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c1a\u672a\u6709\u6548\u5229\u7528\u5927\u91cf\u7684\u8fb9\u7f18\u8bbe\u5907\u6570\u636e\uff0c\u8054\u90a6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u53ef\u4ee5\u5728\u4e0d\u8f6c\u79fb\u8fb9\u7f18\u79c1\u6709\u6570\u636e\u5230\u4e91\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u591a\u5934LoRA\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u65b0\u53c2\u6570\u5316\u6743\u91cd\u66f4\u65b0\u6765\u5b9e\u73b0\uff0c\u5728\u591a\u4e2aLoRA\u5934\u7684\u603b\u548c\u4e2d\uff0c\u53ea\u6709\u6838\u5fc3\u77e9\u9635\u548c\u8f7b\u91cf\u7ea7\u7f29\u653e\u56e0\u5b50\u88ab\u8bad\u7ec3\u3002", "result": "\\textsc{Ravan} \u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6d4b\u8bd5\u51c6\u786e\u6027\u6bd4\u4e4b\u524d\u7684\u53c2\u6570\u9ad8\u6548\u57fa\u7ebf\u63d0\u9ad8\u4e862-8%\u3002", "conclusion": "\\textsc{Ravan} \u662f\u4e00\u4e2a\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8054\u90a6\u5fae\u8c03\uff0c\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u51c6\u786e\u6027\u3002"}}
{"id": "2303.14005", "pdf": "https://arxiv.org/pdf/2303.14005", "abs": "https://arxiv.org/abs/2303.14005", "authors": ["Chi Xie", "Fangao Zeng", "Yue Hu", "Shuang Liang", "Yichen Wei"], "title": "Category Query Learning for Human-Object Interaction Classification", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR 2023", "summary": "Unlike most previous HOI methods that focus on learning better human-object\nfeatures, we propose a novel and complementary approach called category query\nlearning. Such queries are explicitly associated to interaction categories,\nconverted to image specific category representation via a transformer decoder,\nand learnt via an auxiliary image-level classification task. This idea is\nmotivated by an earlier multi-label image classification method, but is for the\nfirst time applied for the challenging human-object interaction classification\ntask. Our method is simple, general and effective. It is validated on three\nrepresentative HOI baselines and achieves new state-of-the-art results on two\nbenchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7c7b\u522b\u67e5\u8be2\u5b66\u4e60\u65b9\u6cd5\u7528\u4e8eHOI\u5206\u7c7b\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u79c0\u6210\u7ee9\u3002", "motivation": "\u8be5\u65b9\u6cd5\u7684\u7075\u611f\u6765\u6e90\u4e8e\u65e9\u671f\u7684\u591a\u6807\u7b7e\u56fe\u50cf\u5206\u7c7b\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5148\u524d\u5927\u591a\u6570HOI\u65b9\u6cd5\u4ec5\u5173\u6ce8\u4e8e\u5b66\u4e60\u66f4\u597d\u7684\u4eba\u4e0e\u7269\u4f53\u7279\u5f81\u7684\u95ee\u9898\u3002", "method": "\u65b9\u6cd5\u4f7f\u7528\u4e86\u4e00\u79cd\u79f0\u4e3a\u7c7b\u522b\u67e5\u8be2\u5b66\u4e60\u7684\u521b\u65b0\u6280\u672f\uff0c\u901a\u8fc7transformer\u89e3\u7801\u5668\u5c06\u67e5\u8be2\u8f6c\u6362\u4e3a\u7279\u5b9a\u56fe\u50cf\u7684\u7c7b\u522b\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u8f85\u52a9\u56fe\u50cf\u7ea7\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u5b66\u4e60\u3002", "result": "\u65b9\u6cd5\u5728\u4e09\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684HOI\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u5728\u4e24\u4e2a\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u9886\u5148\u7ed3\u679c\u3002", "conclusion": "\u6211\u4eec\u7684\u7b80\u5355\u3001\u901a\u7528\u800c\u6709\u6548\u7684\u65b9\u6cd5\u9996\u6b21\u5728\u5177\u6709\u6311\u6218\u6027\u7684HOI\u5206\u7c7b\u4efb\u52a1\u4e2d\u5e94\u7528\u5e76\u5728\u4e24\u4e2a\u6807\u51c6\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002"}}
{"id": "2506.05675", "pdf": "https://arxiv.org/pdf/2506.05675", "abs": "https://arxiv.org/abs/2506.05675", "authors": ["Zefan Zeng", "Xingchen Hu", "Qing Cheng", "Weiping Ding", "Wentao Li", "Zhong Liu"], "title": "Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Event Causality Identification (ECI) aims to detect causal relationships\nbetween events in textual contexts. Existing ECI models predominantly rely on\nsupervised methodologies, suffering from dependence on large-scale annotated\ndata. Although Large Language Models (LLMs) enable zero-shot ECI, they are\nprone to causal hallucination-erroneously establishing spurious causal links.\nTo address these challenges, we propose MEFA, a novel zero-shot framework based\non Multi-source Evidence Fuzzy Aggregation. First, we decompose causality\nreasoning into three main tasks (temporality determination, necessity analysis,\nand sufficiency verification) complemented by three auxiliary tasks. Second,\nleveraging meticulously designed prompts, we guide LLMs to generate uncertain\nresponses and deterministic outputs. Finally, we quantify LLM's responses of\nsub-tasks and employ fuzzy aggregation to integrate these evidence for\ncausality scoring and causality determination. Extensive experiments on three\nbenchmarks demonstrate that MEFA outperforms second-best unsupervised baselines\nby 6.2% in F1-score and 9.3% in precision, while significantly reducing\nhallucination-induced errors. In-depth analysis verify the effectiveness of\ntask decomposition and the superiority of fuzzy aggregation.", "AI": {"tldr": "MEFA is a novel zero-shot framework for Event Causality Identification that improves performance and reduces errors compared to unsupervised baselines.", "motivation": "To address the dependence of ECI models on large-scale annotated data and the causal hallucination issues in zero-shot ECI by LLMs.", "method": "MEFA uses Multi-source Evidence Fuzzy Aggregation by decomposing causality reasoning into primary and auxiliary tasks, guiding LLMs through prompts, and using fuzzy aggregation for causality scoring.", "result": "MEFA improves performance by 6.2% in F1-score and 9.3% in precision on three benchmarks compared to other unsupervised baselines.", "conclusion": "MEFA significantly reduces hallucination-induced errors and outperforms second-best unsupervised baselines."}}
{"id": "2506.05574", "pdf": "https://arxiv.org/pdf/2506.05574", "abs": "https://arxiv.org/abs/2506.05574", "authors": ["Chase Goddard", "Lindsay M. Smith", "Vudtiwat Ngampruetikorn", "David J. Schwab"], "title": "When can in-context learning generalize out of task distribution?", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC", "stat.ML"], "comment": null, "summary": "In-context learning (ICL) is a remarkable capability of pretrained\ntransformers that allows models to generalize to unseen tasks after seeing only\na few examples. We investigate empirically the conditions necessary on the\npretraining distribution for ICL to emerge and generalize\n\\emph{out-of-distribution}. Previous work has focused on the number of distinct\ntasks necessary in the pretraining dataset. Here, we use a different notion of\ntask diversity to study the emergence of ICL in transformers trained on linear\nfunctions. We find that as task diversity increases, transformers undergo a\ntransition from a specialized solution, which exhibits ICL only within the\npretraining task distribution, to a solution which generalizes out of\ndistribution to the entire task space. We also investigate the nature of the\nsolutions learned by the transformer on both sides of the transition, and\nobserve similar transitions in nonlinear regression problems. We construct a\nphase diagram to characterize how our concept of task diversity interacts with\nthe number of pretraining tasks. In addition, we explore how factors such as\nthe depth of the model and the dimensionality of the regression problem\ninfluence the transition.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4efb\u52a1\u591a\u6837\u6027\u5bf9transformers\u4e2dICL\u51fa\u73b0\u548c\u6cdb\u5316\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u589e\u52a0\u4efb\u52a1\u591a\u6837\u6027\u6709\u52a9\u4e8eICL\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "motivation": "\u63a2\u8ba8ICL\u51fa\u73b0\u5728transformers\u4e2d\u7684\u6761\u4ef6\uff0c\u5e76\u4e86\u89e3\u5982\u4f55\u8ba9ICL\u7684\u80fd\u529b\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u7a7a\u95f4\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u51fd\u6570\u7814\u7a76transformers\u4e0a\u7684\u4efb\u52a1\u591a\u6837\u6027\u4e0eICL\u51fa\u73b0\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6784\u5efa\u76f8\u56fe\u63a2\u8ba8\u4efb\u52a1\u591a\u6837\u6027\u4e0e\u9884\u8bad\u7ec3\u4efb\u52a1\u6570\u91cf\u4e4b\u95f4\u7684\u4ea4\u4e92\u3002", "result": "\u53d1\u73b0\u4efb\u52a1\u591a\u6837\u6027\u589e\u52a0\u53ef\u5bfc\u81f4transformers\u4ece\u4e13\u95e8\u5316\u89e3\u51b3\u65b9\u6848\u8fc7\u6e21\u5230\u6cdb\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e00\u73b0\u8c61\u5728\u975e\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u4e2d\u4e5f\u5b58\u5728\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u968f\u7740\u4efb\u52a1\u591a\u6837\u6027\u7684\u589e\u52a0\uff0ctransformers\u4f1a\u4ece\u4ec5\u5728\u9884\u8bad\u7ec3\u4efb\u52a1\u5206\u5e03\u5185\u5c55\u793aICL\u7684\u4e13\u95e8\u5316\u89e3\u51b3\u65b9\u6848\u8f6c\u53d8\u4e3a\u5bf9\u6574\u4e2a\u4efb\u52a1\u7a7a\u95f4\u7684\u6cdb\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.05171", "pdf": "https://arxiv.org/pdf/2506.05171", "abs": "https://arxiv.org/abs/2506.05171", "authors": ["Linxuan He", "Qing-Shan Jia", "Ang Li", "Hongyan Sang", "Ling Wang", "Jiwen Lu", "Tao Zhang", "Jie Zhou", "Yi Zhang", "Yisen Wang", "Peng Wei", "Zhongyuan Wang", "Henry X. Liu", "Shuo Feng"], "title": "Towards provable probabilistic safety for scalable embodied AI systems", "categories": ["eess.SY", "cs.AI", "cs.SY"], "comment": null, "summary": "Embodied AI systems, comprising AI models and physical plants, are\nincreasingly prevalent across various applications. Due to the rarity of system\nfailures, ensuring their safety in complex operating environments remains a\nmajor challenge, which severely hinders their large-scale deployment in\nsafety-critical domains, such as autonomous vehicles, medical devices, and\nrobotics. While achieving provable deterministic safety--verifying system\nsafety across all possible scenarios--remains theoretically ideal, the rarity\nand complexity of corner cases make this approach impractical for scalable\nembodied AI systems. To address this challenge, we introduce provable\nprobabilistic safety, which aims to ensure that the residual risk of\nlarge-scale deployment remains below a predefined threshold. Instead of\nattempting exhaustive safety proof across all corner cases, this paradigm\nestablishes a probabilistic safety boundary on overall system performance,\nleveraging statistical methods to enhance feasibility and scalability. A\nwell-defined probabilistic safety boundary enables embodied AI systems to be\ndeployed at scale while allowing for continuous refinement of safety\nguarantees. Our work focuses on three core questions: what is provable\nprobabilistic safety, how to prove the probabilistic safety, and how to achieve\nthe provable probabilistic safety. By bridging the gap between theoretical\nsafety assurance and practical deployment, our work offers a pathway toward\nsafer, large-scale adoption of embodied AI systems in safety-critical\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53ef\u8bc1\u660e\u7684\u6982\u7387\u5b89\u5168\u6027\uff0c\u4ee5\u5e94\u5bf9\u5d4c\u5165\u5f0fAI\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u6311\u6218\uff0c\u4ece\u800c\u652f\u6301\u5176\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "motivation": "\u5d4c\u5165\u5f0fAI\u7cfb\u7edf\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u3001\u533b\u7597\u8bbe\u5907\u548c\u673a\u5668\u4eba\uff09\u7684\u5927\u89c4\u6a21\u90e8\u7f72\u53d7\u5230\u5b89\u5168\u6027\u96be\u4ee5\u4fdd\u8bc1\u7684\u5236\u7ea6\uff0c\u7279\u522b\u662f\u7531\u4e8e\u7cfb\u7edf\u6545\u969c\u7684\u7f55\u89c1\u6027\uff0c\u9a8c\u8bc1\u6240\u6709\u53ef\u80fd\u573a\u666f\u4e0b\u7684\u7cfb\u7edf\u5b89\u5168\u6027\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u53ef\u8bc1\u660e\u7684\u6982\u7387\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u7edf\u8ba1\u65b9\u6cd5\u5efa\u7acb\u7cfb\u7edf\u6027\u80fd\u7684\u6982\u7387\u5b89\u5168\u8fb9\u754c\uff0c\u800c\u975e\u7a77\u5c3d\u9a8c\u8bc1\u6240\u6709\u53ef\u80fd\u60c5\u51b5\u4e0b\u7684\u5b89\u5168\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u589e\u5f3a\u4e86\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u7684\u53ef\u884c\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u53ef\u8bc1\u660e\u7684\u6982\u7387\u5b89\u5168\u6027\uff0c\u672c\u6587\u4e3a\u5d4c\u5165\u5f0fAI\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u5728\u65e2\u5b9a\u98ce\u9669\u9608\u503c\u4e0b\u5b9e\u73b0\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e94\u7528\u5e76\u5141\u8bb8\u6301\u7eed\u7684\u5b89\u5168\u6027\u4fdd\u969c\u4f18\u5316\u3002", "conclusion": "\u4e3a\u4e86\u89e3\u51b3\u5728\u590d\u6742\u64cd\u4f5c\u73af\u5883\u4e2d\u4fdd\u6301\u5d4c\u5165\u5f0fAI\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u53ef\u8bc1\u660e\u7684\u6982\u7387\u5b89\u5168\u6027\u3002\u901a\u8fc7\u5efa\u7acb\u6982\u7387\u5b89\u5168\u8fb9\u754c\uff0c\u672c\u6587\u4e3a\u5927\u89c4\u6a21\u90e8\u7f72\u5d4c\u5165\u5f0fAI\u63d0\u4f9b\u4e86\u4e00\u6761\u4ece\u7406\u8bba\u4e0a\u7684\u5b89\u5168\u4fdd\u8bc1\u5230\u5b9e\u9645\u5e94\u7528\u7684\u8def\u5f84\u3002"}}
{"id": "2506.05686", "pdf": "https://arxiv.org/pdf/2506.05686", "abs": "https://arxiv.org/abs/2506.05686", "authors": ["Ratna Kandala", "Prakash Mondal"], "title": "A Unified Representation for Continuity and Discontinuity: Syntactic and Computational Motivations", "categories": ["cs.CL"], "comment": null, "summary": "This paper advances a unified representation of linguistic structure for\nthree grammar formalisms, namely, Phrase Structure Grammar (PSG), Dependency\nGrammar (DG) and Categorial Grammar (CG) from the perspective of syntactic and\ncomputational complexity considerations. The correspondence principle is\nproposed to enable a unified representation of the representational principles\nfrom PSG, DG, and CG. To that end, the paper first illustrates a series of\nsteps in achieving a unified representation for a discontinuous subordinate\nclause from Turkish as an illustrative case. This affords a new way of\napproaching discontinuity in natural language from a theoretical point of view\nthat unites and integrates the basic tenets of PSG, DG, and CG, with\nsignificant consequences for syntactic analysis. Then this paper demonstrates\nthat a unified representation can simplify computational complexity with\nregards to the neurocognitive representation and processing of both continuous\nand discontinuous sentences vis-\\`a-vis the basic principles of PSG, DG, and\nCG.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86PSG\u3001DG\u548cCG\u7684\u7edf\u4e00\u8868\u793a\uff0c\u4ee5\u7b80\u5316\u53e5\u6cd5\u5206\u6790\u548c\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e0d\u8fde\u7eed\u53e5\u5b50\u65f6\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u5728\u4e8e\u4ece\u53e5\u6cd5\u548c\u8ba1\u7b97\u590d\u6742\u6027\u8003\u8651\u51fa\u53d1\uff0c\u63d0\u51fa\u4e00\u79cd\u5bf9\u8bed\u8a00\u7ed3\u6784\u7edf\u4e00\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u5904\u7406PSG\u3001DG\u548cCG\u4e2d\u7684\u4e0d\u8fde\u7eed\u6027\u95ee\u9898\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u5bf9\u5e94\u539f\u5219\uff0c\u5b9e\u73b0\u5bf9PSG\u3001DG\u548cCG\u7684\u7edf\u4e00\u8868\u793a\uff0c\u5177\u4f53\u901a\u8fc7\u5c55\u793a\u4e00\u7cfb\u5217\u6b65\u9aa4\u6765\u8bf4\u660e\u5982\u4f55\u5728\u571f\u8033\u5176\u8bed\u4e2d\u5b9e\u73b0\u4e0d\u8fde\u7eed\u4ece\u53e5\u7684\u7edf\u4e00\u8868\u793a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7edf\u4e00\u8868\u793a\u80fd\u591f\u7b80\u5316\u5173\u4e8ePSG\u3001DG\u548cCG\u57fa\u672c\u539f\u5219\u7684\u8fde\u7eed\u548c\u4e0d\u8fde\u7eed\u53e5\u5b50\u7684\u795e\u7ecf\u8ba4\u77e5\u8868\u793a\u548c\u5904\u7406\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "conclusion": "\u672c\u6587\u5f97\u51fa\u7ed3\u8bba\uff0c\u901a\u8fc7\u5bf9PSG\u3001DG\u548cCG\u7684\u7edf\u4e00\u8868\u793a\uff0c\u4e0d\u4ec5\u53ef\u4ee5\u4ece\u7406\u8bba\u4e0a\u5904\u7406\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u4e0d\u8fde\u7eed\u6027\uff0c\u8fd8\u53ef\u4ee5\u7b80\u5316\u8fde\u7eed\u548c\u4e0d\u8fde\u7eed\u53e5\u5b50\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002"}}
{"id": "2506.05351", "pdf": "https://arxiv.org/pdf/2506.05351", "abs": "https://arxiv.org/abs/2506.05351", "authors": ["Rukmal Weerawarana", "Maxwell Braun"], "title": "Infinite Time Turing Machines and their Applications", "categories": ["cs.CC", "cs.AI", "cs.FL", "cs.LG"], "comment": "Published by Ren XYZ Inc", "summary": "This work establishes a rigorous theoretical foundation for analyzing deep\nlearning systems by leveraging Infinite Time Turing Machines (ITTMs), which\nextend classical computation into transfinite ordinal steps. Using ITTMs, we\nreinterpret modern architectures like Transformers, revealing fundamental\nlimitations in scalability, efficiency, and interpretability. Building on these\ninsights, we propose the Universal State Machine (USM), a novel computational\nparadigm designed from first principles. The USM employs a dynamic, queryable\ncomputation graph that evolves in real time, enabling modular, interpretable,\nand resource-efficient computation. This framework not only overcomes the\ninefficiencies and rigidity of current models but also lays the groundwork for\nscalable, generalizable artificial intelligence systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5229\u7528\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u5206\u6790\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\u4f5c\u4e3a\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u4ee5\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002", "motivation": "\u901a\u8fc7\u5229\u7528\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u62d3\u5c55\u7ecf\u5178\u8ba1\u7b97\u7406\u8bba\u81f3\u8d85\u9650\u5e8f\u6570\u6b65\uff0c\u5efa\u7acb\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5206\u6790\u7684\u4e25\u683c\u7406\u8bba\u57fa\u7840\u3002", "method": "\u5229\u7528\u65e0\u9650\u65f6\u95f4\u56fe\u7075\u673a\uff08ITTMs\uff09\u91cd\u65b0\u89e3\u91ca\u73b0\u4ee3\u67b6\u6784\uff08\u5982Transformers\uff09\uff0c\u63ed\u793a\u5176\u5728\u53ef\u6269\u5c55\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6839\u672c\u9650\u5236\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u52a8\u6001\u3001\u53ef\u67e5\u8be2\u7684\u8ba1\u7b97\u56fe\u6765\u8fdb\u884c\u5b9e\u65f6\u6f14\u53d8\u3002", "result": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5373\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\uff0c\u652f\u6301\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u8ba1\u7b97\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5373\u901a\u7528\u72b6\u6001\u673a\uff08USM\uff09\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u6a21\u578b\u7684\u6548\u7387\u4f4e\u4e0b\u548c\u50f5\u5316\u95ee\u9898\uff0c\u5e76\u4e3a\u53ef\u6269\u5c55\u3001\u53ef\u6cdb\u5316\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2506.05690", "pdf": "https://arxiv.org/pdf/2506.05690", "abs": "https://arxiv.org/abs/2506.05690", "authors": ["Zhishang Xiang", "Chuanjie Wu", "Qinggang Zhang", "Shengyuan Chen", "Zijin Hong", "Xiao Huang", "Jinsong Su"], "title": "When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful\nparadigm for enhancing large language models (LLMs) with external knowledge. It\nleverages graphs to model the hierarchical structure between specific concepts,\nenabling more coherent and effective knowledge retrieval for accurate\nreasoning.Despite its conceptual promise, recent studies report that GraphRAG\nfrequently underperforms vanilla RAG on many real-world tasks. This raises a\ncritical question: Is GraphRAG really effective, and in which scenarios do\ngraph structures provide measurable benefits for RAG systems? To address this,\nwe propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate\nGraphRAG models onboth hierarchical knowledge retrieval and deep contextual\nreasoning. GraphRAG-Bench features a comprehensive dataset with tasks of\nincreasing difficulty, coveringfact retrieval, complex reasoning, contextual\nsummarization, and creative generation, and a systematic evaluation across the\nentire pipeline, from graph constructionand knowledge retrieval to final\ngeneration. Leveraging this novel benchmark, we systematically investigate the\nconditions when GraphRAG surpasses traditional RAG and the underlying reasons\nfor its success, offering guidelines for its practical application. All related\nresources and analyses are collected for the community at\nhttps://github.com/GraphRAG-Bench/GraphRAG-Benchmark.", "AI": {"tldr": "GraphRAG-Bench is a benchmark for evaluating the effectiveness of GraphRAG in comparison to traditional RAG, identifying scenarios where GraphRAG excels.", "motivation": "The motivation is to determine the effectiveness of GraphRAG compared to traditional RAG systems, identifying scenarios where graph structures enhance knowledge retrieval and generation.", "method": "GraphRAG-Bench is developed with a comprehensive dataset for hierarchical knowledge retrieval and deep contextual reasoning, including tasks of fact retrieval, complex reasoning, contextual summarization, and creative generation, to systematically evaluate GraphRAG models.", "result": "The benchmark uncovers specific conditions under which GraphRAG outperforms traditional RAG models and elucidates the underlying reasons, providing a resource and guidelines for the application of GraphRAG systems.", "conclusion": "GraphRAG-Bench provides a systematic benchmark for evaluating the scenarios in which GraphRAG models surpass traditional RAG systems, offering insights and guidelines for practical applications."}}
{"id": "2506.05583", "pdf": "https://arxiv.org/pdf/2506.05583", "abs": "https://arxiv.org/abs/2506.05583", "authors": ["Nien-Shao Wang", "Duygu Nur Yaldiz", "Yavuz Faruk Bakman", "Sai Praneeth Karimireddy"], "title": "Conformal Prediction Adaptive to Unknown Subpopulation Shifts", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "20 pages, 6 figures, 5 tables, submitted to NeurIPS 2025", "summary": "Conformal prediction is widely used to equip black-box machine learning\nmodels with uncertainty quantification enjoying formal coverage guarantees.\nHowever, these guarantees typically break down in the presence of distribution\nshifts, where the data distribution at test time differs from the training (or\ncalibration-time) distribution. In this work, we address subpopulation shifts,\nwhere the test environment exhibits an unknown and differing mixture of\nsubpopulations compared to the calibration data. We propose new methods that\nprovably adapt conformal prediction to such shifts, ensuring valid coverage\nwithout requiring explicit knowledge of subpopulation structure. Our algorithms\nscale to high-dimensional settings and perform effectively in realistic machine\nlearning tasks. Extensive experiments on vision (with vision transformers) and\nlanguage (with large language models) benchmarks demonstrate that our methods\nreliably maintain coverage and controls risk in scenarios where standard\nconformal prediction fails.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5728\u5b50\u7fa4\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u9002\u5e94\u5730\u8c03\u6574\u4fdd\u5f62\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u786e\u4fdd\u5728\u4e0d\u660e\u786e\u4e86\u89e3\u5b50\u7fa4\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u8bc1\u6709\u6548\u8986\u76d6\u3002", "motivation": "\u6807\u51c6\u7684\u4fdd\u5f62\u9884\u6d4b\u5728\u5206\u5e03\u53d8\u5316\u7279\u522b\u662f\u5b50\u7fa4\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u65e0\u6cd5\u63d0\u4f9b\u4fdd\u8bc1\u3002\u4e3a\u4e86\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\u4fdd\u6301\u6709\u6548\u7684\u8986\u76d6\u7387\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u9488\u5bf9\u672a\u77e5\u548c\u4e0d\u540c\u7684\u5b50\u7fa4\u6df7\u5408\u5206\u5e03\u7684\u60c5\u51b5\uff0c\u81ea\u9002\u5e94\u5730\u8c03\u6574\u4fdd\u5f62\u9884\u6d4b\u3002\u8fd9\u4e9b\u7b97\u6cd5\u53ef\u4ee5\u6269\u5c55\u5230\u9ad8\u7ef4\u8bbe\u7f6e\uff0c\u5e76\u5728\u73b0\u5b9e\u7684\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u6709\u6548\u5de5\u4f5c\u3002", "result": "\u5728\u89c6\u89c9\uff08\u4f7f\u7528\u89c6\u89c9\u53d8\u6362\u5668\uff09\u548c\u8bed\u8a00\uff08\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u57fa\u51c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u6807\u51c6\u4fdd\u5f62\u9884\u6d4b\u5931\u6548\u7684\u573a\u666f\u4e2d\uff0c\u80fd\u53ef\u9760\u5730\u7ef4\u62a4\u8986\u76d6\u7387\u5e76\u63a7\u5236\u98ce\u9669\u3002", "conclusion": "\u5728\u5206\u5e03\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u6807\u51c6\u7684\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u4f1a\u5931\u6548\u3002\u672c\u6587\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u9700\u8981\u660e\u786e\u4e86\u89e3\u5b50\u7fa4\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u9002\u5e94\u5730\u5904\u7406\u8fd9\u79cd\u53d8\u5316\uff0c\u4ece\u800c\u4fdd\u8bc1\u6709\u6548\u7684\u8986\u76d6\u7387\u3002"}}
{"id": "2506.05358", "pdf": "https://arxiv.org/pdf/2506.05358", "abs": "https://arxiv.org/abs/2506.05358", "authors": ["Souradip Nath"], "title": "Can ChatGPT Perform Image Splicing Detection? A Preliminary Study", "categories": ["cs.CV", "cs.AI", "cs.CR"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) like GPT-4V are capable of reasoning\nacross text and image modalities, showing promise in a variety of complex\nvision-language tasks. In this preliminary study, we investigate the\nout-of-the-box capabilities of GPT-4V in the domain of image forensics,\nspecifically, in detecting image splicing manipulations. Without any\ntask-specific fine-tuning, we evaluate GPT-4V using three prompting strategies:\nZero-Shot (ZS), Few-Shot (FS), and Chain-of-Thought (CoT), applied over a\ncurated subset of the CASIA v2.0 splicing dataset.\n  Our results show that GPT-4V achieves competitive detection performance in\nzero-shot settings (more than 85% accuracy), with CoT prompting yielding the\nmost balanced trade-off across authentic and spliced images. Qualitative\nanalysis further reveals that the model not only detects low-level visual\nartifacts but also draws upon real-world contextual knowledge such as object\nscale, semantic consistency, and architectural facts, to identify implausible\ncomposites. While GPT-4V lags behind specialized state-of-the-art splicing\ndetection models, its generalizability, interpretability, and encyclopedic\nreasoning highlight its potential as a flexible tool in image forensics.", "AI": {"tldr": "GPT-4V, tested on CASIA v2.0 for image splicing detection, shows over 85% accuracy in zero-shot scenarios. Chain-of-Thought prompting helps it achieve a balanced detection, highlighting its potential in forensic applications despite some limitations compared to specialized models.", "motivation": "To explore and understand the capabilities of GPT-4V in image forensics, particularly in detecting image splicing manipulations, by leveraging its multimodal reasoning abilities.", "method": "The study evaluates the out-of-the-box capabilities of GPT-4V using three prompting strategies - Zero-Shot (ZS), Few-Shot (FS), and Chain-of-Thought (CoT) - on the CASIA v2.0 splicing dataset.", "result": "GPT-4V achieves over 85% accuracy in zero-shot settings, with the CoT prompting offering a balanced detection across different types of images. It uses both low-level visual artifacts and high-level contextual reasoning.", "conclusion": "GPT-4V, without task-specific fine-tuning, shows competitive performance in detecting image splicing, especially with CoT prompting. Despite lagging behind specialized models, it demonstrates good generalization and reasoning capabilities."}}
{"id": "2506.05695", "pdf": "https://arxiv.org/pdf/2506.05695", "abs": "https://arxiv.org/abs/2506.05695", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "AI": {"tldr": "Introduces a novel curriculum learning framework, POCL, that improves KD by progressively introducing ranked training samples, enhancing stability and performance.", "motivation": "Existing KD methods often cause distribution shifts in student models, leading to issues like catastrophic forgetting and mode collapse. The motivation is to address these challenges with a new learning framework.", "method": "The novel plug-in curriculum learning framework inspired by progressive overload, incorporating two components: difficulty measurer and training scheduler, integrating into existing KD methods with minimal overhead.", "result": "POCL consistently enhances the performance of student models in various KD methods as shown in extensive experiments in instruction-following settings.", "conclusion": "POCL effectively improves the performance and stability of distilled student models by structuring training data and introducing them progressively based on difficulty."}}
{"id": "2506.05584", "pdf": "https://arxiv.org/pdf/2506.05584", "abs": "https://arxiv.org/abs/2506.05584", "authors": ["Yuchen Zeng", "Tuan Dinh", "Wonjun Kang", "Andreas C Mueller"], "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention", "categories": ["cs.LG"], "comment": "30 pages, ICML 2025", "summary": "Leveraging the in-context learning (ICL) capability of Large Language Models\n(LLMs) for tabular classification has gained significant attention for its\ntraining-free adaptability across diverse datasets. Recent advancements, like\nTabPFN, excel in small-scale tabular datasets but struggle to scale for large\nand complex datasets. Our work enhances the efficiency and scalability of\nTabPFN for larger datasets by incorporating linear attention mechanisms as a\nscalable alternative to complexity-quadratic self-attention. Our model,\nTabFlex, efficiently handles tabular datasets with thousands of features and\nhundreds of classes, scaling seamlessly to millions of samples. For instance,\nTabFlex processes the poker-hand dataset with over a million samples in just 5\nseconds. Our extensive evaluations demonstrate that TabFlex can achieve over a\n2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, outperforming 25\ntested baselines in terms of efficiency across a diverse range of datasets.\nFurthermore, TabFlex remains highly effective on large-scale datasets,\ndelivering strong performance with significantly reduced computational costs,\nespecially when combined with data-efficient techniques such as dimensionality\nreduction and data sampling.", "AI": {"tldr": "The paper introduces TabFlex, which improves upon TabPFN by using linear attention mechanisms to handle large tabular datasets efficiently, achieving significant speedups and computational savings while maintaining strong performance.", "motivation": "To overcome the scalability and efficiency limitations of recent tabular classification models such as TabPFN when applied to large and complex datasets.", "method": "Incorporating linear attention mechanisms as a scalable alternative to complexity-quadratic self-attention, and employing data-efficient techniques like dimensionality reduction and data sampling.", "result": "TabFlex achieves over a 2x speedup compared to TabPFN and a 1.5x speedup over XGBoost, demonstrating its superior efficiency across diverse datasets.", "conclusion": "TabFlex significantly enhances the efficiency and scalability of tabular data classification, outperforming existing methods in terms of speed and computational cost, while maintaining strong performance across large-scale datasets."}}
{"id": "2506.05368", "pdf": "https://arxiv.org/pdf/2506.05368", "abs": "https://arxiv.org/abs/2506.05368", "authors": ["Valentine Bernasconi", "Gustavo Marfia"], "title": "Speaking images. A novel framework for the automated self-description of artworks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent breakthroughs in generative AI have opened the door to new research\nperspectives in the domain of art and cultural heritage, where a large number\nof artifacts have been digitized. There is a need for innovation to ease the\naccess and highlight the content of digital collections. Such innovations\ndevelop into creative explorations of the digital image in relation to its\nmalleability and contemporary interpretation, in confrontation to the original\nhistorical object. Based on the concept of the autonomous image, we propose a\nnew framework towards the production of self-explaining cultural artifacts\nusing open-source large-language, face detection, text-to-speech and\naudio-to-animation models. The goal is to start from a digitized artwork and to\nautomatically assemble a short video of the latter where the main character\nanimates to explain its content. The whole process questions cultural biases\nencapsulated in large-language models, the potential of digital images and\ndeepfakes of artworks for educational purposes, along with concerns of the\nfield of art history regarding such creative diversions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u751f\u6210\u6027\u4eba\u5de5\u667a\u80fd\u521b\u5efa\u81ea\u6211\u89e3\u91ca\u7684\u6570\u5b57\u5316\u6587\u5316\u827a\u672f\u54c1\u7684\u65b0\u6846\u67b6\u3002", "motivation": "\u751f\u6210\u6027\u4eba\u5de5\u667a\u80fd\u7684\u7a81\u7834\u4e3a\u827a\u672f\u548c\u6587\u5316\u9057\u4ea7\u9886\u57df\u7684\u7814\u7a76\u5e26\u6765\u65b0\u7684\u89c6\u89d2\uff0c\u9700\u8981\u521b\u65b0\u4ee5\u4fbf\u66f4\u5bb9\u6613\u8bbf\u95ee\u548c\u7a81\u51fa\u6570\u5b57\u6536\u85cf\u7684\u5185\u5bb9\u3002", "method": "\u672c\u6587\u65b9\u6cd5\u6d89\u53ca\u4f7f\u7528\u5f00\u6e90\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u9762\u90e8\u68c0\u6d4b\u3001\u6587\u672c\u5230\u8bed\u97f3\u548c\u97f3\u9891\u5230\u52a8\u753b\u6a21\u578b\uff0c\u81ea\u52a8\u7ec4\u88c5\u77ed\u89c6\u9891\uff0c\u4f7f\u6570\u5b57\u5316\u827a\u672f\u54c1\u4e2d\u7684\u4e3b\u8981\u89d2\u8272\u6d3b\u8dc3\u8d77\u6765\u5e76\u89e3\u91ca\u5176\u5185\u5bb9\u3002", "result": "\u4ece\u6570\u5b57\u5316\u827a\u672f\u4f5c\u54c1\u5f00\u59cb\uff0c\u81ea\u52a8\u751f\u6210\u77ed\u89c6\u9891\uff0c\u5176\u4e2d\u4e3b\u8981\u89d2\u8272\u52a8\u753b\u5316\u5e76\u89e3\u91ca\u5176\u5185\u5bb9\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u5f00\u6e90\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u9762\u90e8\u68c0\u6d4b\u3001\u6587\u672c\u5230\u8bed\u97f3\u548c\u97f3\u9891\u5230\u52a8\u753b\u6a21\u578b\uff0c\u521b\u9020\u81ea\u6211\u89e3\u91ca\u7684\u6587\u5316\u827a\u672f\u54c1\u3002"}}
{"id": "2506.05700", "pdf": "https://arxiv.org/pdf/2506.05700", "abs": "https://arxiv.org/abs/2506.05700", "authors": ["Yan Wang", "Yueru He", "Ruoyu Xiang", "Jeff Zhao"], "title": "RKEFino1: A Regulation Knowledge-Enhanced Large Language Model", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) hold great promise for\nfinancial applications but introduce critical accuracy and compliance\nchallenges in Digital Regulatory Reporting (DRR). To address these issues, we\npropose RKEFino1, a regulation knowledge-enhanced financial reasoning model\nbuilt upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We\nformulate two QA tasks-knowledge-based and mathematical reasoning-and introduce\na novel Numerical NER task covering financial entities in both sentences and\ntables. Experimental results demonstrate the effectiveness and generalization\ncapacity of RKEFino1 in compliance-critical financial tasks. We have released\nour model on Hugging Face.", "AI": {"tldr": "RKEFino1\u901a\u8fc7\u589e\u5f3a\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5728\u91d1\u878d\u5408\u89c4\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6548\u679c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u6709\u5f88\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u6570\u5b57\u76d1\u7ba1\u62a5\u544a\u4e2d\u5f15\u53d1\u4e86\u51c6\u786e\u6027\u548c\u5408\u89c4\u6027\u65b9\u9762\u7684\u6311\u6218\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u52a0\u5f3a\u578b\u91d1\u878d\u63a8\u7406\u6a21\u578bRKEFino1\u3002", "method": "\u901a\u8fc7\u5fae\u8c03Fino1\u5e76\u7ed3\u5408\u6765\u81eaXBRL\u3001CDM\u548cMOF\u7684\u9886\u57df\u77e5\u8bc6\u6765\u6784\u5efa\u589e\u5f3a\u578b\u91d1\u878d\u63a8\u7406\u6a21\u578bRKEFino1\uff0c\u5e76\u8bbe\u8ba1\u4e24\u4e2aQA\u4efb\u52a1\uff1a\u77e5\u8bc6\u578b\u63a8\u7406\u548c\u6570\u5b66\u63a8\u7406\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u8986\u76d6\u53e5\u5b50\u548c\u8868\u683c\u7684\u91d1\u878d\u5b9e\u4f53\u7684\u65b0\u589eEEP\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eRKEFino1\u5728\u5408\u89c4\u6027\u5173\u952e\u7684\u91d1\u878d\u4efb\u52a1\u4e2d\u5177\u5907\u6709\u6548\u6027\uff0c\u5e76\u5df2\u5728Hugging Face\u5e73\u53f0\u53d1\u5e03\u3002", "conclusion": "RKEFino1\u5728\u5408\u89c4\u6027\u5173\u952e\u7684\u91d1\u878d\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.05586", "pdf": "https://arxiv.org/pdf/2506.05586", "abs": "https://arxiv.org/abs/2506.05586", "authors": ["Isha Puri", "Amit Dhurandhar", "Tejaswini Pedapati", "Kartikeyan Shanmugam", "Dennis Wei", "Kush R. Varshney"], "title": "CoFrNets: Interpretable Neural Architecture Inspired by Continued Fractions", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In recent years there has been a considerable amount of research on local\npost hoc explanations for neural networks. However, work on building\ninterpretable neural architectures has been relatively sparse. In this paper,\nwe present a novel neural architecture, CoFrNet, inspired by the form of\ncontinued fractions which are known to have many attractive properties in\nnumber theory, such as fast convergence of approximations to real numbers. We\nshow that CoFrNets can be efficiently trained as well as interpreted leveraging\ntheir particular functional form. Moreover, we prove that such architectures\nare universal approximators based on a proof strategy that is different than\nthe typical strategy used to prove universal approximation results for neural\nnetworks based on infinite width (or depth), which is likely to be of\nindependent interest. We experiment on nonlinear synthetic functions and are\nable to accurately model as well as estimate feature attributions and even\nhigher order terms in some cases, which is a testament to the representational\npower as well as interpretability of such architectures. To further showcase\nthe power of CoFrNets, we experiment on seven real datasets spanning tabular,\ntext and image modalities, and show that they are either comparable or\nsignificantly better than other interpretable models and multilayer\nperceptrons, sometimes approaching the accuracies of state-of-the-art models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784CoFrNet\uff0c\u5177\u6709\u5f3a\u5927\u7684\u8868\u73b0\u529b\u548c\u89e3\u91ca\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u795e\u7ecf\u7f51\u7edc\u4e2d\u7814\u7a76\u89e3\u91ca\u6027\u67b6\u6784\u8f83\u4e3a\u7a00\u5c11\uff0c\u6b64\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u5177\u6709\u4f18\u826f\u7684\u903c\u8fd1\u5b9e\u6570\u7684\u6027\u8d28\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u67b6\u6784CoFrNet\uff0c\u8be5\u67b6\u6784\u53d7\u5230\u8fde\u5206\u6570\u7684\u542f\u53d1\uff0c\u5177\u6709\u5feb\u901f\u903c\u8fd1\u5b9e\u6570\u7684\u53ef\u53d6\u6027\u8d28\u3002\u901a\u8fc7\u72ec\u7279\u7684\u65b9\u6cd5\u8bc1\u660e\u8fd9\u4e9b\u67b6\u6784\u662f\u901a\u7528\u903c\u8fd1\u5668\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eCoFrNets\u4e0d\u4ec5\u53ef\u4ee5\u6709\u6548\u5730\u5efa\u6a21\u975e\u7ebf\u6027\u5408\u6210\u51fd\u6570\uff0c\u8fd8\u80fd\u4f30\u8ba1\u7279\u5f81\u8d21\u732e\u548c\u8f83\u9ad8\u9636\u9879\u3002\u5728\u4e03\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\uff0cCoFrNets\u7684\u6027\u80fd\u8981\u4e48\u4e0e\u5176\u5b83\u53ef\u89e3\u91ca\u6a21\u578b\u548c\u591a\u5c42\u611f\u77e5\u673a\u76f8\u5f53\uff0c\u8981\u4e48\u663e\u8457\u4f18\u4e8e\u5b83\u4eec\uff0c\u63a5\u8fd1\u6216\u8fbe\u5230\u6700\u5148\u8fdb\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "conclusion": "CoFrNets\u662f\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5177\u6709\u826f\u597d\u7684\u8868\u73b0\u529b\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u63a5\u8fd1\u751a\u81f3\u8d85\u8d8a\u4e86\u4e00\u4e9b\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002"}}
{"id": "2506.05376", "pdf": "https://arxiv.org/pdf/2506.05376", "abs": "https://arxiv.org/abs/2506.05376", "authors": ["Zifan Wang", "Christina Q. Knight", "Jeremy Kritz", "Willow E. Primack", "Julian Michael"], "title": "A Red Teaming Roadmap Towards System-Level Safety", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) safeguards, which implement request refusals, have\nbecome a widely adopted mitigation strategy against misuse. At the intersection\nof adversarial machine learning and AI safety, safeguard red teaming has\neffectively identified critical vulnerabilities in state-of-the-art\nrefusal-trained LLMs. However, in our view the many conference submissions on\nLLM red teaming do not, in aggregate, prioritize the right research problems.\nFirst, testing against clear product safety specifications should take a higher\npriority than abstract social biases or ethical principles. Second, red teaming\nshould prioritize realistic threat models that represent the expanding risk\nlandscape and what real attackers might do. Finally, we contend that\nsystem-level safety is a necessary step to move red teaming research forward,\nas AI models present new threats as well as affordances for threat mitigation\n(e.g., detection and banning of malicious users) once placed in a deployment\ncontext. Adopting these priorities will be necessary in order for red teaming\nresearch to adequately address the slate of new threats that rapid AI advances\npresent today and will present in the very near future.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3a\u5f53\u524d\u7684\u7ea2\u961f\u7814\u7a76\u6ca1\u6709\u4f18\u5148\u89e3\u51b3\u6b63\u786e\u7684\u95ee\u9898\uff0c\u5efa\u8bae\u5c06\u91cd\u70b9\u653e\u5728\u4ea7\u54c1\u5b89\u5168\u89c4\u683c\u3001\u73b0\u5b9e\u5a01\u80c1\u6a21\u578b\u4ee5\u53ca\u7cfb\u7edf\u7ea7\u5b89\u5168\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u7684AI\u5a01\u80c1\u3002", "motivation": "\u5f53\u524d\u7684\u7ea2\u961f\u7814\u7a76\u672a\u80fd\u4f18\u5148\u89e3\u51b3\u6b63\u786e\u7684\u95ee\u9898\uff0c\u5e94\u5c06\u91cd\u70b9\u653e\u5728\u4ea7\u54c1\u5b89\u5168\u89c4\u683c\u7684\u6d4b\u8bd5\u4ee5\u53ca\u73b0\u5b9e\u5a01\u80c1\u6a21\u578b\uff0c\u800c\u975e\u62bd\u8c61\u7684\u793e\u4f1a\u504f\u89c1\u6216\u4f26\u7406\u539f\u5219\u4e0a\u3002", "method": "\u91c7\u53d6\u57fa\u4e8e\u73b0\u5b9e\u5a01\u80c1\u6a21\u578b\u7684\u7ea2\u961f\u6d4b\u8bd5\uff0c\u5e76\u5bf9\u4ea7\u54c1\u5b89\u5168\u89c4\u683c\u8fdb\u884c\u660e\u786e\u6d4b\u8bd5\uff0c\u540c\u65f6\u5173\u6ce8\u7cfb\u7edf\u7ea7\u5b89\u5168\u4ee5\u63a8\u52a8\u7ea2\u961f\u7814\u7a76\u7684\u8fdb\u6b65\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5173\u4e8e\u5982\u4f55\u63d0\u9ad8\u7ea2\u961f\u7814\u7a76\u6548\u7387\u7684\u4f18\u5148\u4e8b\u9879\uff0c\u5305\u62ec\u5173\u6ce8\u4ea7\u54c1\u5b89\u5168\u89c4\u683c\u3001\u73b0\u5b9e\u5a01\u80c1\u6a21\u578b\u4ee5\u53ca\u7cfb\u7edf\u7ea7\u5b89\u5168\u3002", "conclusion": "\u4e3a\u5b9e\u73b0\u7ea2\u961f\u7814\u7a76\u7684\u8fdb\u6b65\uff0c\u7cfb\u7edf\u7ea7\u5b89\u5168\u662f\u5fc5\u8981\u7684\u4e00\u6b65\uff0c\u56e0\u4e3a\u4e00\u65e6\u5728\u90e8\u7f72\u73af\u5883\u4e2d\u4f7f\u7528\uff0c\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u4e0d\u4ec5\u4f1a\u5e26\u6765\u65b0\u7684\u5a01\u80c1\uff0c\u8fd8\u80fd\u591f\u901a\u8fc7\u68c0\u6d4b\u548c\u5c01\u7981\u6076\u610f\u7528\u6237\u7b49\u65b9\u6cd5\u63d0\u4f9b\u5a01\u80c1\u7f13\u89e3\u80fd\u529b\u3002"}}
{"id": "2506.05725", "pdf": "https://arxiv.org/pdf/2506.05725", "abs": "https://arxiv.org/abs/2506.05725", "authors": ["Fang Wu", "Vijay Prakash Dwivedi", "Jure Leskovec"], "title": "Large Language Models are Good Relational Learners", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, yet their application to relational deep learning (RDL)\nremains underexplored. Existing approaches adapt LLMs by traversing relational\nlinks between entities in a database and converting the structured data into\nflat text documents. Still, this text-based serialization disregards critical\nrelational structures, introduces redundancy, and often exceeds standard LLM\ncontext lengths. We introduce Rel-LLM, a novel architecture that utilizes a\ngraph neural network (GNN)- based encoder to generate structured relational\nprompts for LLMs within a retrieval-augmented generation (RAG) framework.\nUnlike traditional text-based serialization approaches, our method preserves\nthe inherent relational structure of databases while enabling LLMs to\neffectively process and reason over complex entity relationships. Specifically,\nthe GNN encoder extracts a local subgraph around an entity to build feature\nrepresentations that contain relevant entity relationships and temporal\ndependencies. These representations are transformed into structured prompts\nusing a denormalization process, effectively allowing the LLM to reason over\nrelational structures. Through extensive experiments, we demonstrate that\nRel-LLM outperforms existing methods on key RDL tasks, offering a scalable and\nefficient approach to integrating LLMs with structured data sources. Code is\navailable at https://github.com/smiles724/Rel-LLM.", "AI": {"tldr": "Rel-LLM uses a GNN-based encoder to preserve relational structures in databases, outperforming current methods in processing structured data with LLMs.", "motivation": "The motivation is to address the limitations of existing approaches that disregard critical relational structures in databases and introduce redundancy, while often exceeding standard LLM context lengths.", "method": "The method utilizes a graph neural network (GNN)-based encoder within a retrieval-augmented generation (RAG) framework to preserve relational database structures and generate structured relational prompts for LLMs.", "result": "Extensive experiments demonstrate that Rel-LLM surpasses existing methods in relational deep learning tasks.", "conclusion": "Rel-LLM outperforms existing methods on key relational deep learning tasks, presenting a scalable and efficient solution for integrating large language models with structured data sources."}}
{"id": "2506.05596", "pdf": "https://arxiv.org/pdf/2506.05596", "abs": "https://arxiv.org/abs/2506.05596", "authors": ["Jes Frellsen", "Maher M. Kassem", "Tone Bengtsen", "Lars Olsen", "Kresten Lindorff-Larsen", "Jesper Ferkinghoff-Borg", "Wouter Boomsma"], "title": "Zero-shot protein stability prediction by inverse folding models: a free energy interpretation", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "stat.ML"], "comment": null, "summary": "Inverse folding models have proven to be highly effective zero-shot\npredictors of protein stability. Despite this success, the link between the\namino acid preferences of an inverse folding model and the free-energy\nconsiderations underlying thermodynamic stability remains incompletely\nunderstood. A better understanding would be of interest not only from a\ntheoretical perspective, but also potentially provide the basis for stronger\nzero-shot stability prediction. In this paper, we take steps to clarify the\nfree-energy foundations of inverse folding models. Our derivation reveals the\nstandard practice of likelihood ratios as a simplistic approximation and\nsuggests several paths towards better estimates of the relative stability. We\nempirically assess these approaches and demonstrate that considerable gains in\nzero-shot performance can be achieved with fairly simple means.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u63a8\u5bfc\u548c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u51e0\u79cd\u6539\u8fdb\u9006\u6298\u53e0\u6a21\u578b\u7a33\u5b9a\u6027\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6027\u80fd\u7684\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u9006\u6298\u53e0\u6a21\u578b\u5728\u86cb\u767d\u8d28\u7a33\u5b9a\u6027\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u6c28\u57fa\u9178\u9009\u62e9\u504f\u597d\u4e0e\u70ed\u529b\u5b66\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u5173\u8054\u5c1a\u672a\u5b8c\u5168\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u79cd\u5173\u8054\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u6709\u610f\u4e49\uff0c\u8fd8\u53ef\u80fd\u4e3a\u66f4\u5f3a\u7684\u96f6\u6837\u672c\u7a33\u5b9a\u6027\u9884\u6d4b\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u672c\u8bba\u6587\u901a\u8fc7\u63a8\u5bfc\u63ed\u793a\u4e86\u9006\u6298\u53e0\u6a21\u578b\u4e2d\u6807\u51c6\u4f3c\u7136\u6bd4\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u79cd\u6539\u8fdb\u8def\u5f84\u7528\u4e8e\u66f4\u597d\u5730\u4f30\u8ba1\u76f8\u5bf9\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u63d0\u51fa\u7684\u6539\u8fdb\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u6027\u80fd\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u8bba\u6587\u63ed\u793a\u4e86\u57fa\u4e8e\u9006\u6298\u53e0\u6a21\u578b\u7684\u6807\u51c6\u4f3c\u7136\u6bd4\u65b9\u6cd5\u662f\u4e00\u79cd\u7b80\u5316\u7684\u8fd1\u4f3c\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u79cd\u6539\u8fdb\u76f8\u5bf9\u7a33\u5b9a\u6027\u4f30\u8ba1\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u96f6\u6837\u672c\u6027\u80fd\u3002"}}
{"id": "2506.05379", "pdf": "https://arxiv.org/pdf/2506.05379", "abs": "https://arxiv.org/abs/2506.05379", "authors": ["Seyed Moein Ayyoubzadeh", "Kourosh Shahnazari", "Mohammmadali Keshtparvar", "MohammadAmin Fazli"], "title": "Designing DSIC Mechanisms for Data Sharing in the Era of Large Language Models", "categories": ["cs.GT", "cs.AI", "cs.CY"], "comment": null, "summary": "Training large language models (LLMs) requires vast amounts of high-quality\ndata from institutions that face legal, privacy, and strategic constraints.\nExisting data procurement methods often rely on unverifiable trust or ignore\nheterogeneous provider costs. We introduce a mechanism-design framework for\ntruthful, trust-minimized data sharing that ensures dominant-strategy incentive\ncompatibility (DSIC), individual rationality, and weak budget balance, while\nrewarding data based on both quality and learning utility. We formalize a model\nwhere providers privately know their data cost and quality, and value arises\nsolely from the data's contribution to model performance. Based on this, we\npropose the Quality-Weighted Marginal-Incentive Auction (Q-MIA), which ranks\nproviders using a virtual cost metric and uses Myerson-style payments to ensure\nDSIC and budget feasibility. To support settings with limited liquidity or\nlong-term incentives, we introduce the Marginal Utility Token (MUT), which\nallocates future rights based on marginal contributions. We unify these in\nMixed-MIA, a hybrid mechanism balancing upfront payments and deferred rewards.\nAll mechanisms support verifiable, privacy-preserving implementation.\nTheoretically and empirically, they outperform volume-based and trust-based\nbaselines, eliciting higher-quality data under budget constraints while\nremaining robust to misreporting and collusion. This establishes a principled\nfoundation for sustainable and fair data markets for future LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u673a\u5236\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7 Q-MIA \u548c Mixed-MIA \u673a\u5236\uff0c\u5728\u516c\u5e73\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u5171\u4eab\u548c\u6fc0\u52b1\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u83b7\u53d6\u65b9\u6cd5\u4f9d\u8d56\u65e0\u6cd5\u9a8c\u8bc1\u7684\u4fe1\u4efb\uff0c\u6216\u5ffd\u7565\u4e0d\u540c\u63d0\u4f9b\u8005\u7684\u6210\u672c\u5dee\u5f02\u3002\u9700\u8981\u4e00\u79cd\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u548c\u5b66\u4e60\u6548\u7528\uff0c\u4e14\u517c\u987e\u5404\u79cd\u7ea6\u675f\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u673a\u5236\u8bbe\u8ba1\u6846\u67b6\uff0c\u540d\u4e3a Q-MIA \u548c Mixed-MIA\uff0c\u7ed3\u5408\u8d28\u91cf\u52a0\u6743\u8fb9\u9645\u6fc0\u52b1\u62cd\u5356\u548c\u8fb9\u9645\u6548\u76ca\u4ee3\u5e01\uff0c\u5b9e\u73b0\u4e86 DSIC \u548c\u9884\u7b97\u53ef\u884c\u6027\u3002", "result": "\u63d0\u51fa\u7684\u673a\u5236\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u6570\u636e\u91cf\u548c\u4fe1\u4efb\u7684\u57fa\u51c6\uff0c\u80fd\u591f\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u5f15\u51fa\u66f4\u9ad8\u8d28\u91cf\u7684\u6570\u636e\uff0c\u5e76\u4e14\u5bf9\u9519\u8bef\u62a5\u544a\u548c\u5408\u8c0b\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165 Q-MIA \u548c MUT \u673a\u5236\uff0c\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u57fa\u7840\uff0c\u7528\u4e8e\u672a\u6765 LLMs \u7684\u53ef\u6301\u7eed\u548c\u516c\u5e73\u7684\u6570\u636e\u5e02\u573a\u3002"}}
{"id": "2506.05735", "pdf": "https://arxiv.org/pdf/2506.05735", "abs": "https://arxiv.org/abs/2506.05735", "authors": ["Rongzhe Wei", "Peizhi Niu", "Hans Hao-Hsun Hsu", "Ruihan Wu", "Haoteng Yin", "Mohsen Ghassemi", "Yifan Li", "Vamsi K. Potluru", "Eli Chien", "Kamalika Chaudhuri", "Olgica Milenkovic", "Pan Li"], "title": "Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Machine unlearning techniques aim to mitigate unintended memorization in\nlarge language models (LLMs). However, existing approaches predominantly focus\non the explicit removal of isolated facts, often overlooking latent inferential\ndependencies and the non-deterministic nature of knowledge within LLMs.\nConsequently, facts presumed forgotten may persist implicitly through\ncorrelated information. To address these challenges, we propose a knowledge\nunlearning evaluation framework that more accurately captures the implicit\nstructure of real-world knowledge by representing relevant factual contexts as\nknowledge graphs with associated confidence scores. We further develop an\ninference-based evaluation protocol leveraging powerful LLMs as judges; these\njudges reason over the extracted knowledge subgraph to determine unlearning\nsuccess. Our LLM judges utilize carefully designed prompts and are calibrated\nagainst human evaluations to ensure their trustworthiness and stability.\nExtensive experiments on our newly constructed benchmark demonstrate that our\nframework provides a more realistic and rigorous assessment of unlearning\nperformance. Moreover, our findings reveal that current evaluation strategies\ntend to overestimate unlearning effectiveness. Our code is publicly available\nat https://github.com/Graph-COM/Knowledge_Unlearning.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u77e5\u8bc6\u9057\u5fd8\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u548c\u63a8\u7406\u534f\u8bae\u6765\u66f4\u771f\u5b9e\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9057\u5fd8\u6548\u679c\uff0c\u53d1\u73b0\u73b0\u6709\u7b56\u7565\u5bf9\u9057\u5fd8\u6548\u679c\u7684\u8bc4\u4f30\u5f80\u5f80\u8fc7\u9ad8\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u9057\u5fd8\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u4e8e\u5b64\u7acb\u4e8b\u5b9e\u7684\u663e\u5f0f\u5220\u9664\uff0c\u5ffd\u7565\u4e86\u63a8\u7406\u4f9d\u8d56\u5173\u7cfb\u53ca\u77e5\u8bc6\u7684\u975e\u786e\u5b9a\u6027\u3002\u8fd9\u5bfc\u81f4\u88ab\u8ba4\u4e3a\u5df2\u9057\u5fd8\u7684\u4e8b\u5b9e\u53ef\u80fd\u4ecd\u901a\u8fc7\u5173\u8054\u4fe1\u606f\u9690\u6027\u5b58\u5728\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u63a8\u7406\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u6a21\u578b\u751f\u6210\u76f8\u5173\u4e8b\u5b9e\u73af\u5883\uff0c\u540c\u65f6\u901a\u8fc7\u63a8\u7406\u534f\u8bae\u6765\u8bc4\u4f30\u9057\u5fd8\u6548\u679c\u3002\u8bc4\u4f30\u534f\u8bae\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4f30\u8005\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u5e76\u8fdb\u884c\u6821\u51c6\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u5bf9\u6bd4\u4ee5\u786e\u4fdd\u8bc4\u4f30\u8005\u7684\u53ef\u9760\u6027\u548c\u7a33\u5b9a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u66f4\u771f\u5b9e\u3001\u4e25\u683c\u5730\u8bc4\u4f30\u9057\u5fd8\u6548\u679c\u3002\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u7684\u8bc4\u4f30\u7b56\u7565\u5f80\u5f80\u9ad8\u4f30\u4e86\u9057\u5fd8\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u9057\u5fd8\u6548\u679c\u7684\u8bc4\u4f30\u4e0d\u591f\u771f\u5b9e\uff0c\u5f80\u5f80\u9ad8\u4f30\u4e86\u9057\u5fd8\u6548\u679c\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u9057\u5fd8\u6548\u679c\u3002"}}
{"id": "2506.05597", "pdf": "https://arxiv.org/pdf/2506.05597", "abs": "https://arxiv.org/abs/2506.05597", "authors": ["Yash Vijay", "Harini Subramanyan"], "title": "FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "While Transformers excel in language and vision-where inputs are semantically\nrich and exhibit univariate dependency structures-their architectural\ncomplexity leads to diminishing returns in time series forecasting. Time series\ndata is characterized by low per-timestep information density and complex\ndependencies across channels and covariates, requiring conditioning on\nstructured variable interactions. To address this mismatch and\noverparameterization, we propose FaCTR, a lightweight spatiotemporal\nTransformer with an explicitly structural design. FaCTR injects dynamic,\nsymmetric cross-channel interactions-modeled via a low-rank Factorization\nMachine into temporally contextualized patch embeddings through a learnable\ngating mechanism. It further encodes static and dynamic covariates for\nmultivariate conditioning. Despite its compact design, FaCTR achieves\nstate-of-the-art performance on eleven public forecasting benchmarks spanning\nboth short-term and long-term horizons, with its largest variant using close to\nonly 400K parameters-on average 50x smaller than competitive spatiotemporal\ntransformer baselines. In addition, its structured design enables\ninterpretability through cross-channel influence scores-an essential\nrequirement for real-world decision-making. Finally, FaCTR supports\nself-supervised pretraining, positioning it as a compact yet versatile\nfoundation for downstream time series tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86FaCTR\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65f6\u7a7aTransformer\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bbe\u8ba1\u89e3\u51b3Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7531\u4e8e\u67b6\u6784\u590d\u6742\u6027\u5bfc\u81f4\u7684\u6548\u679c\u9012\u51cf\u95ee\u9898\uff0c\u5e76\u9488\u5bf9\u7ed3\u6784\u5316\u53d8\u91cf\u4ea4\u4e92\u8fdb\u884c\u6761\u4ef6\u5316\u4ee5\u5e94\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u4f4e\u4fe1\u606f\u5bc6\u5ea6\u548c\u590d\u6742\u8de8\u901a\u9053\u4f9d\u8d56\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u95e8\u63a7\u673a\u5236\u5c06\u52a8\u6001\u5bf9\u79f0\u7684\u8de8\u901a\u9053\u4ea4\u4e92\uff08\u901a\u8fc7\u4f4e\u79e9\u56e0\u5b50\u5206\u89e3\u673a\u5efa\u6a21\uff09\u6ce8\u5165\u5230\u65f6\u5e8f\u80cc\u666f\u5316\u7684\u8865\u4e01\u5d4c\u5165\u4e2d\u3002\u8fd8\u7f16\u7801\u4e86\u9759\u6001\u548c\u52a8\u6001\u534f\u53d8\u91cf\u4ee5\u8fdb\u884c\u591a\u53d8\u91cf\u6761\u4ef6\u5316\u3002\u652f\u6301\u81ea\u6211\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u4ee5\u4f5c\u4e3a\u540e\u7eed\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u7684\u57fa\u7840\u3002", "result": "FaCTR\u4ee5\u8fd1400K\u4e2a\u53c2\u6570\u7684\u6700\u5927\u53d8\u4f53\u5728\u77ed\u671f\u548c\u957f\u671f\u9884\u6d4b\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e73\u5747\u6bd4\u7ade\u4e89\u5bf9\u624b\u5c0f50\u500d\u3002", "conclusion": "FaCTR\u5728\u4fdd\u6301\u6a21\u578b\u7d27\u51d1\u8bbe\u8ba1\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4e1a\u754c\u9886\u5148\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u89e3\u91ca\u6027\u5f3a\u7684\u8de8\u901a\u9053\u5f71\u54cd\u8bc4\u5206\u3002"}}
{"id": "2506.05382", "pdf": "https://arxiv.org/pdf/2506.05382", "abs": "https://arxiv.org/abs/2506.05382", "authors": ["Francesco Panebianco", "Mario D'Onghia", "Stefano Zanero aand Michele Carminati"], "title": "How stealthy is stealthy? Studying the Efficacy of Black-Box Adversarial Attacks in the Real World", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Deep learning systems, critical in domains like autonomous vehicles, are\nvulnerable to adversarial examples (crafted inputs designed to mislead\nclassifiers). This study investigates black-box adversarial attacks in computer\nvision. This is a realistic scenario, where attackers have query-only access to\nthe target model. Three properties are introduced to evaluate attack\nfeasibility: robustness to compression, stealthiness to automatic detection,\nand stealthiness to human inspection. State-of-the-Art methods tend to\nprioritize one criterion at the expense of others. We propose ECLIPSE, a novel\nattack method employing Gaussian blurring on sampled gradients and a local\nsurrogate model. Comprehensive experiments on a public dataset highlight\nECLIPSE's advantages, demonstrating its contribution to the trade-off between\nthe three properties.", "AI": {"tldr": "The paper presents ECLIPSE, a novel method for black-box adversarial attacks in computer vision, improving the balance between robustness, stealthiness to detection, and inspection.", "motivation": "The motivation is to address adversarial vulnerabilities in deep learning systems, especially in black-box scenarios like computer vision, by balancing multiple attack feasibility criteria.", "method": "The method proposed is called ECLIPSE, which uses Gaussian blurring on sampled gradients and a local surrogate model to conduct adversarial attacks.", "result": "ECLIPSE shows advantages in experiments by providing a better trade-off between robustness to compression, stealthiness to automatic detection, and human inspection compared to State-of-the-Art methods.", "conclusion": "ECLIPSE method enhances the trade-off balance among robustness to compression, stealthiness to automatic detection, and stealthiness to human inspection in black-box adversarial attacks."}}
{"id": "2506.05746", "pdf": "https://arxiv.org/pdf/2506.05746", "abs": "https://arxiv.org/abs/2506.05746", "authors": ["Atharv Kulkarni", "Kushagra Dixit", "Vivek Srikumar", "Dan Roth", "Vivek Gupta"], "title": "LLM-Symbolic Integration for Robust Temporal Tabular Reasoning", "categories": ["cs.CL"], "comment": "Accepted to ACL Findings 2025", "summary": "Temporal tabular question answering presents a significant challenge for\nLarge Language Models (LLMs), requiring robust reasoning over structured data,\nwhich is a task where traditional prompting methods often fall short. These\nmethods face challenges such as memorization, sensitivity to table size, and\nreduced performance on complex queries. To overcome these limitations, we\nintroduce TempTabQA-C, a synthetic dataset designed for systematic and\ncontrolled evaluations, alongside a symbolic intermediate representation that\ntransforms tables into database schemas. This structured approach allows LLMs\nto generate and execute SQL queries, enhancing generalization and mitigating\nbiases. By incorporating adaptive few-shot prompting with contextually tailored\nexamples, our method achieves superior robustness, scalability, and\nperformance. Experimental results consistently highlight improvements across\nkey challenges, setting a new benchmark for robust temporal reasoning with\nLLMs.", "AI": {"tldr": "The paper introduces a method that transforms tables into database schemas for SQL query generation and utilizes adaptive few-shot prompting, leading to enhanced performance in temporal tabular question answering.", "motivation": "Traditional prompting methods in Temporal Tabular Question Answering are often inadequate, suffering from issues like memorization, sensitivity to table size, and poor performance on complex queries. There is a need for a robust approach to overcome these limitations.", "method": "We introduce a symbolic intermediate representation that transforms tables into database schemas for SQL query generation. Furthermore, adaptive few-shot prompting with contextually tailored examples is applied to improve model performance.", "result": "The proposed method consistently shows improvements across key challenges in the field, offering superior robustness, scalability, and performance in temporal reasoning with LLMs.", "conclusion": "Our method enhances generalization and reduces biases in Temporal Tabular Question Answering by transforming tables into database schemas for SQL query generation and execution, incorporating adaptive few-shot prompting, ultimately setting a new benchmark in this field."}}
{"id": "2506.05615", "pdf": "https://arxiv.org/pdf/2506.05615", "abs": "https://arxiv.org/abs/2506.05615", "authors": ["Ruipeng Zhang", "Ya-Chien Chang", "Sicun Gao"], "title": "When Maximum Entropy Misleads Policy Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Maximum Entropy Reinforcement Learning (MaxEnt RL) framework is a leading\napproach for achieving efficient learning and robust performance across many RL\ntasks. However, MaxEnt methods have also been shown to struggle with\nperformance-critical control problems in practice, where non-MaxEnt algorithms\ncan successfully learn. In this work, we analyze how the trade-off between\nrobustness and optimality affects the performance of MaxEnt algorithms in\ncomplex control tasks: while entropy maximization enhances exploration and\nrobustness, it can also mislead policy optimization, leading to failure in\ntasks that require precise, low-entropy policies. Through experiments on a\nvariety of control problems, we concretely demonstrate this misleading effect.\nOur analysis leads to better understanding of how to balance reward design and\nentropy maximization in challenging control problems.", "AI": {"tldr": "MaxEnt RL\u867d\u7136\u63d0\u9ad8\u4e86\u4efb\u52a1\u7684\u63a2\u7d22\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u63a7\u5236\u7684\u4efb\u52a1\u4e2d\u53ef\u80fd\u5bfc\u81f4\u7b56\u7565\u4f18\u5316\u5931\u8bef\u3002", "motivation": "\u5206\u6790MaxEnt\u7b97\u6cd5\u5728\u6027\u80fd\u5173\u952e\u7684\u63a7\u5236\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u590d\u6742\u7684\u63a7\u5236\u4efb\u52a1\u4e2d\u5e73\u8861\u5956\u52b1\u8bbe\u8ba1\u4e0e\u71b5\u6700\u5927\u5316\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790MaxEnt\u7b97\u6cd5\u5728\u5404\u79cd\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u7814\u7a76\u9c81\u68d2\u6027\u4e0e\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5982\u4f55\u5f71\u54cd\u5176\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u71b5\u6700\u5927\u5316\u867d\u7136\u63d0\u9ad8\u4e86\u63a2\u7d22\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u9700\u8981\u4f4e\u71b5\u7b56\u7565\u7684\u4efb\u52a1\u4e2d\u53ef\u80fd\u4f1a\u5bfc\u81f4\u7b56\u7565\u4f18\u5316\u5931\u8bef\u3002", "conclusion": "\u5728\u590d\u6742\u63a7\u5236\u4efb\u52a1\u4e2d\uff0cMaxEnt\u7b97\u6cd5\u7684\u6027\u80fd\u53d7\u5230\u9c81\u68d2\u6027\u548c\u6700\u4f18\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5f71\u54cd\u3002\u867d\u7136\u71b5\u6700\u5927\u5316\u589e\u5f3a\u4e86\u63a2\u7d22\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u3001\u4f4e\u71b5\u7b56\u7565\u7684\u4efb\u52a1\u4e2d\uff0c\u5b83\u53ef\u80fd\u4f1a\u8bef\u5bfc\u7b56\u7565\u4f18\u5316\u3002\u901a\u8fc7\u5bf9\u591a\u79cd\u63a7\u5236\u95ee\u9898\u7684\u5b9e\u9a8c\uff0c\u4f5c\u8005\u5177\u4f53\u5c55\u793a\u4e86\u8fd9\u79cd\u8bef\u5bfc\u6548\u5e94\u3002"}}
{"id": "2506.05384", "pdf": "https://arxiv.org/pdf/2506.05384", "abs": "https://arxiv.org/abs/2506.05384", "authors": ["Zhuoxuan Cai", "Jian Zhang", "Xinbin Yuan", "Pengtao Jiang", "Wenxiang Chen", "Bowen Tang", "Lujian Yao", "Qiyuan Wang", "Jinwen Chen", "Bo Li"], "title": "Q-Ponder: A Unified Training Pipeline for Reasoning-based Visual Quality Assessment", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": null, "summary": "Recent studies demonstrate that multimodal large language models (MLLMs) can\nproficiently evaluate visual quality through interpretable assessments.\nHowever, existing approaches typically treat quality scoring and reasoning\ndescriptions as separate tasks with disjoint optimization objectives, leading\nto a trade-off: models adept at quality reasoning descriptions struggle with\nprecise score regression, while score-focused models lack interpretability.\nThis limitation hinders the full potential of MLLMs in visual quality\nassessment, where accuracy and interpretability should be mutually reinforcing.\nTo address this, we propose a unified two-stage training framework comprising a\ncold-start stage and a reinforcement learning-based fine-tuning stage.\nSpecifically, in the first stage, we distill high-quality data from a teacher\nmodel through expert-designed prompts, initializing reasoning capabilities via\ncross-entropy loss supervision. In the second stage, we introduce a novel\nreward with Group Relative Policy Optimization (GRPO) to jointly optimize\nscoring accuracy and reasoning consistency. We designate the models derived\nfrom these two stages as Q-Ponder-CI and Q-Ponder. Extensive experiments show\nthat Q-Ponder achieves state-of-the-art (SOTA) performance on quality score\nregression benchmarks, delivering up to 6.5% higher SRCC on cross-domain\ndatasets. Furthermore, Q-Ponder significantly outperforms description-based\nSOTA models, including its teacher model Qwen-2.5-VL-72B, particularly in\ndescription accuracy and reasonableness, demonstrating the generalization\npotential over diverse tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u5347\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u7cbe\u5ea6\u548c\u89e3\u91ca\u6027\uff0c\u6a21\u578bQ-Ponder\u8868\u73b0\u4f18\u4e8e\u73b0\u6709SOTA\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u8d28\u91cf\u8bc4\u4f30\u4e2d\uff0c\u5c06\u8d28\u91cf\u8bc4\u5206\u4e0e\u63a8\u7406\u63cf\u8ff0\u89c6\u4f5c\u72ec\u7acb\u4efb\u52a1\u8fdb\u884c\u5904\u7406\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u8d28\u91cf\u63a8\u7406\u63cf\u8ff0\u548c\u7cbe\u786e\u8bc4\u4f30\u4e4b\u95f4\u96be\u4ee5\u517c\u987e\u3002\u8fd9\u4e00\u9650\u5236\u4f7f\u5f97\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u5176\u5728\u89c6\u89c9\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u5728\u9ad8\u7cbe\u5ea6\u8bc4\u5206\u548c\u89e3\u91ca\u6027\u4e4b\u95f4\u5b9e\u73b0\u4f18\u52bf\u4e92\u8865\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u4e24\u4e2a\u9636\u6bb5\u7ec4\u6210\u7684\u7edf\u4e00\u8bad\u7ec3\u6846\u67b6\uff1a\u51b7\u542f\u52a8\u9636\u6bb5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5fae\u8c03\u9636\u6bb5\u3002\u5728\u7b2c\u4e00\u4e2a\u9636\u6bb5\uff0c\u901a\u8fc7\u6559\u5e08\u6a21\u578b\u548c\u4e13\u5bb6\u8bbe\u8ba1\u7684\u63d0\u793a\u84b8\u998f\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u901a\u8fc7\u4ea4\u53c9\u71b5\u635f\u5931\u76d1\u7763\u521d\u59cb\u5316\u63a8\u7406\u80fd\u529b\u3002\u5728\u7b2c\u4e8c\u4e2a\u9636\u6bb5\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u5956\u52b1\u673a\u5236\u2014\u2014\u7ec4\u76f8\u5bf9\u653f\u7b56\u4f18\u5316\uff08Group Relative Policy Optimization, GRPO\uff09\uff0c\u4ee5\u5171\u540c\u4f18\u5316\u8bc4\u5206\u51c6\u786e\u6027\u548c\u63a8\u7406\u4e00\u81f4\u6027\u3002", "result": "Q-Ponder\u5728\u8d28\u91cf\u5f97\u5206\u56de\u5f52\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u5f53\u524d\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u4e0e\u8de8\u9886\u57df\u6570\u636e\u96c6\u4e0a\u7684SOTA\u76f8\u6bd4\uff0cSRCC\u63d0\u5347\u8fbe6.5%\u3002\u6b64\u5916\uff0c\u5728\u63cf\u8ff0\u578b\u4efb\u52a1\u4e2d\uff0cQ-Ponder\u5728\u63cf\u8ff0\u7684\u51c6\u786e\u6027\u548c\u5408\u7406\u6027\u4e0a\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u7684SOTA\u6a21\u578b\u3002", "conclusion": "\u6a21\u578bQ-Ponder\u5728\u89c6\u89c9\u8d28\u91cf\u8bc4\u4f30\u4e2d\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8de8\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u9ad8\u7cbe\u5ea6\u7684\u5f97\u5206\u56de\u5f52\u80fd\u529b\uff0c\u540c\u65f6\u8be5\u6a21\u578b\u5728\u63cf\u8ff0\u7cbe\u5ea6\u548c\u5408\u7406\u6027\u65b9\u9762\u4e5f\u4f18\u4e8e\u73b0\u6709\u7684SOTA\u6a21\u578b\uff0c\u4f53\u73b0\u4e86\u5176\u5728\u591a\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u6f5c\u529b\u3002"}}
{"id": "2506.05760", "pdf": "https://arxiv.org/pdf/2506.05760", "abs": "https://arxiv.org/abs/2506.05760", "authors": ["Xuanyu Lei", "Chenliang Li", "Yuning Wu", "Kaiming Liu", "Weizhou Shen", "Peng Li", "Ming Yan", "Ji Zhang", "Fei Huang", "Yang Liu"], "title": "Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning", "categories": ["cs.CL"], "comment": "Work in progress", "summary": "Recent advances in Large Language Models (LLMs) have enabled strong\nperformance in long-form writing, yet existing supervised fine-tuning (SFT)\napproaches suffer from limitations such as data saturation and restricted\nlearning capacity bounded by teacher signals. In this work, we present\nWriting-RL: an Adaptive Curriculum Reinforcement Learning framework to advance\nlong-form writing capabilities beyond SFT. The framework consists of three key\ncomponents: Margin-aware Data Selection strategy that prioritizes samples with\nhigh learning potential, Pairwise Comparison Reward mechanism that provides\ndiscriminative learning signals in the absence of verifiable rewards, and\nDynamic Reference Scheduling approach, which plays a particularly critical role\nby adaptively adjusting task difficulty based on evolving model performance.\nExperiments on 7B-scale writer models show that our RL framework largely\nimproves long-form writing performance over strong SFT baselines. Furthermore,\nwe observe that models trained with long-output RL generalize surprisingly well\nto long-input reasoning tasks, potentially offering a promising perspective for\nrethinking long-context training.", "AI": {"tldr": "\u63d0\u51faWriting-RL\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u5927\u6a21\u578b\u957f\u6587\u5199\u4f5c\u80fd\u529b\uff0c\u4e14\u5bf9\u957f\u8f93\u5165\u63a8\u7406\u4efb\u52a1\u6709\u826f\u597d\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u6570\u636e\u9971\u548c\u548c\u6559\u5e08\u4fe1\u53f7\u7684\u9650\u5236\u4e0b\uff0c\u5b66\u4e60\u80fd\u529b\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u957f\u6587\u5199\u4f5c\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u2014\u2014Writing-RL\uff0c\u5305\u62ec\u8fb9\u9645\u611f\u77e5\u7684\u6570\u636e\u9009\u62e9\u7b56\u7565\u3001\u6210\u5bf9\u6bd4\u8f83\u5956\u52b1\u673a\u5236\u4ee5\u53ca\u52a8\u6001\u53c2\u8003\u8c03\u5ea6\u65b9\u6cd5\u3002", "result": "\u57287B\u89c4\u6a21\u7684\u5199\u4f5c\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0cWriting-RL\u6846\u67b6\u5927\u5927\u63d0\u5347\u4e86\u957f\u6587\u5199\u4f5c\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u957f\u8f93\u51faRL\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u957f\u8f93\u5165\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528Writing-RL\u6846\u67b6\uff0c\u53ef\u4ee5\u5927\u5e45\u63d0\u5347\u5927\u89c4\u6a21\u6a21\u578b\u5728\u957f\u6587\u5199\u4f5c\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u8fd9\u4e9b\u7ecf\u8fc7\u957f\u8f93\u51faRL\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u957f\u8f93\u5165\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u73b0\u51fa\u5bf9\u91cd\u65b0\u601d\u8003\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05617", "pdf": "https://arxiv.org/pdf/2506.05617", "abs": "https://arxiv.org/abs/2506.05617", "authors": ["Antonia van Betteray", "Matthias Rottmann", "Karsten Kahl"], "title": "LFA applied to CNNs: Efficient Singular Value Decomposition of Convolutional Mappings by Local Fourier Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The singular values of convolutional mappings encode interesting spectral\nproperties, which can be used, e.g., to improve generalization and robustness\nof convolutional neural networks as well as to facilitate model compression.\nHowever, the computation of singular values is typically very\nresource-intensive. The naive approach involves unrolling the convolutional\nmapping along the input and channel dimensions into a large and sparse\ntwo-dimensional matrix, making the exact calculation of all singular values\ninfeasible due to hardware limitations. In particular, this is true for\nmatrices that represent convolutional mappings with large inputs and a high\nnumber of channels. Existing efficient methods leverage the Fast Fourier\ntransformation (FFT) to transform convolutional mappings into the frequency\ndomain, enabling the computation of singular values for matrices representing\nconvolutions with larger input and channel dimensions. For a constant number of\nchannels in a given convolution, an FFT can compute N singular values in O(N\nlog N) complexity. In this work, we propose an approach of complexity O(N)\nbased on local Fourier analysis, which additionally exploits the shift\ninvariance of convolutional operators. We provide a theoretical analysis of our\nalgorithm's runtime and validate its efficiency through numerical experiments.\nOur results demonstrate that our proposed method is scalable and offers a\npractical solution to calculate the entire set of singular values - along with\nthe corresponding singular vectors if needed - for high-dimensional\nconvolutional mappings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u7684\u65b0\u65b9\u6cd5\uff0c\u590d\u6742\u5ea6\u4e3a O(N)\uff0c\u7528\u4e8e\u9ad8\u6548\u8ba1\u7b97\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\uff0c\u5e76\u5df2\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u8ba1\u7b97\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u6cdb\u5316\u80fd\u529b\u3001\u9c81\u68d2\u6027\u4ee5\u53ca\u6a21\u578b\u538b\u7f29\u3002\u800c\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u5947\u5f02\u503c\u8d44\u6e90\u6d88\u8017\u5f88\u5927\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5c40\u90e8\u5085\u91cc\u53f6\u5206\u6790\u548c\u5377\u79ef\u64cd\u4f5c\u7684\u5e73\u79fb\u4e0d\u53d8\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u6742\u5ea6\u4e3a O(N) \u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6548\u7387\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u8ba1\u7b97\u4e0a\u5177\u6709\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u5377\u79ef\u6620\u5c04\u7684\u5947\u5f02\u503c\u8ba1\u7b97\u65b9\u9762\u975e\u5e38\u9ad8\u6548\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.05766", "pdf": "https://arxiv.org/pdf/2506.05766", "abs": "https://arxiv.org/abs/2506.05766", "authors": ["Saptarshi Sengupta", "Shuhua Yang", "Paul Kwong Yu", "Fali Wang", "Suhang Wang"], "title": "BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval augmented generation (RAG) has shown great power in improving Large\nLanguage Models (LLMs). However, most existing RAG-based LLMs are dedicated to\nretrieving single modality information, mainly text; while for many real-world\nproblems, such as healthcare, information relevant to queries can manifest in\nvarious modalities such as knowledge graph, text (clinical notes), and complex\nmolecular structure. Thus, being able to retrieve relevant multi-modality\ndomain-specific information, and reason and synthesize diverse knowledge to\ngenerate an accurate response is important. To address the gap, we present\nBioMol-MQA, a new question-answering (QA) dataset on polypharmacy, which is\ncomposed of two parts (i) a multimodal knowledge graph (KG) with text and\nmolecular structure for information retrieval; and (ii) challenging questions\nthat designed to test LLM capabilities in retrieving and reasoning over\nmultimodal KG to answer questions. Our benchmarks indicate that existing LLMs\nstruggle to answer these questions and do well only when given the necessary\nbackground data, signaling the necessity for strong RAG frameworks.", "AI": {"tldr": "\u63d0\u51fa\u4e86BioMol-MQA\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6d4b\u8bd5LLM\u5728\u591a\u6a21\u6001\u4e0b\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793aLLM\u9700\u8981\u66f4\u5f3a\u7684RAG\u652f\u6301\u4ee5\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eRAG\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u8fdb\u884c\u5355\u4e00\u6a21\u6001\u7684\u4fe1\u606f\u68c0\u7d22\uff0c\u800c\u73b0\u5b9e\u4e16\u754c\u4e2d\u5982\u533b\u7597\u9886\u57df\u7684\u95ee\u9898\u6d89\u53ca\u591a\u79cd\u6a21\u6001\u7684\u4fe1\u606f\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u591f\u68c0\u7d22\u591a\u6a21\u6001\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u5e76\u8fdb\u884c\u63a8\u7406\u548c\u5408\u6210\u4ee5\u751f\u6210\u7cbe\u786e\u7b54\u6848\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u95ee\u9898\u56de\u7b54\u6570\u636e\u96c6BioMol-MQA\uff0c\u5305\u542b\u4e00\u4e2a\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u548c\u7528\u4e8e\u68c0\u9a8cLLM\u80fd\u529b\u7684\u6311\u6218\u6027\u95ee\u9898\u3002", "result": "\u6211\u4eec\u7684\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u76ee\u524d\u7684LLM\u5728\u56de\u7b54\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u95ee\u9898\u65f6\u4ec5\u5728\u63d0\u4f9b\u5fc5\u8981\u80cc\u666f\u6570\u636e\u65f6\u8868\u73b0\u826f\u597d\uff0c\u663e\u793a\u51fa\u5bf9\u5f3a\u5927RAG\u67b6\u6784\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56de\u7b54\u591a\u6a21\u6001\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u9700\u8981\u66f4\u5f3a\u5927\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u6765\u652f\u6301\u3002"}}
{"id": "2506.05626", "pdf": "https://arxiv.org/pdf/2506.05626", "abs": "https://arxiv.org/abs/2506.05626", "authors": ["Xiaohua Lu", "Liubov Tupikina", "Mehwish Alam"], "title": "Two-dimensional Taxonomy for N-ary Knowledge Representation Learning Methods", "categories": ["cs.LG"], "comment": null, "summary": "Real-world knowledge can take various forms, including structured,\nsemi-structured, and unstructured data. Among these, knowledge graphs are a\nform of structured human knowledge that integrate heterogeneous data sources\ninto structured representations but typically reduce complex n-ary relations to\nsimple triples, thereby losing higher-order relational details. In contrast,\nhypergraphs naturally represent n-ary relations with hyperedges, which directly\nconnect multiple entities together. Yet hypergraph representation learning\noften overlooks entity roles in hyperedges, limiting the fine-grained semantic\nmodelling. To address these issues, knowledge hypergraphs and hyper-relational\nknowledge graphs combine the advantages of knowledge graphs and hypergraphs to\nbetter capture the complex structures and role-specific semantics of real-world\nknowledge. This survey provides a comprehensive review of methods handling\nn-ary relational data, covering both knowledge hypergraphs and hyper-relational\nknowledge graphs literatures. We propose a two-dimensional taxonomy: the first\ndimension categorises models based on their methodology, i.e.,\ntranslation-based models, tensor factorisation-based models, deep neural\nnetwork-based models, logic rules-based models, and hyperedge expansion-based\nmodels. The second dimension classifies models according to their awareness of\nentity roles and positions in n-ary relations, dividing them into aware-less,\nposition-aware, and role-aware approaches. Finally, we discuss existing\ndatasets, negative sampling strategies, and outline open challenges to inspire\nfuture research.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5206\u7c7b\u6cd5\u4ee5\u5e2e\u52a9\u7406\u89e3\u4e0d\u540c\u6a21\u578b\uff0c\u6307\u660e\u4e86\u4e00\u4e9b\u6fc0\u52b1\u672a\u6765\u7814\u7a76\u7684\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u5e38\u5c06\u590d\u6742\u7684n\u5143\u5173\u7cfb\u7b80\u5316\u4e3a\u7b80\u5355\u7684\u4e09\u5143\u7ec4\uff0c\u5bfc\u81f4\u66f4\u9ad8\u9636\u5173\u7cfb\u7ec6\u8282\u7684\u4e22\u5931\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u597d\u5730\u6355\u83b7\u590d\u6742\u7ed3\u6784\u548c\u89d2\u8272\u7279\u5b9a\u8bed\u4e49\u7684\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5206\u7c7b\u6cd5\u6765\u5206\u7c7b\u4e0d\u540c\u7684\u6a21\u578b\uff1a\u7b2c\u4e00\u7ef4\u5ea6\u6839\u636e\u65b9\u6cd5\u8bba\u8fdb\u884c\u5206\u7c7b\uff0c\u5305\u62ec\u57fa\u4e8e\u7ffb\u8bd1\u3001\u57fa\u4e8e\u5f20\u91cf\u5206\u89e3\u3001\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3001\u57fa\u4e8e\u903b\u8f91\u89c4\u5219\u548c\u57fa\u4e8e\u8d85\u8fb9\u6269\u5c55\u7684\u6a21\u578b\uff1b\u7b2c\u4e8c\u7ef4\u5ea6\u6839\u636e\u6a21\u578b\u5bf9\u5b9e\u4f53\u89d2\u8272\u548c\u4f4d\u7f6e\u7684\u611f\u77e5\u8fdb\u884c\u5206\u7c7b\uff0c\u5206\u4e3a\u65e0\u611f\u77e5\u3001\u4f4d\u7f6e\u611f\u77e5\u548c\u89d2\u8272\u611f\u77e5\u3002", "result": "\u5206\u7c7b\u4e86\u73b0\u6709\u6a21\u578b\u5e76\u8ba8\u8bba\u4e86\u73b0\u6709\u6570\u636e\u96c6\u548c\u8d1f\u91c7\u6837\u7b56\u7565\uff0c\u6307\u51fa\u4e86\u4e00\u4e9b\u5f00\u653e\u6311\u6218\u4ee5\u6fc0\u52b1\u672a\u6765\u7814\u7a76\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u5904\u7406n\u5143\u5173\u7cfb\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u77e5\u8bc6\u8d85\u56fe\u548c\u8d85\u5173\u7cfb\u77e5\u8bc6\u56fe\u8c31\u7684\u7814\u7a76\u6587\u732e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5206\u7c7b\u6cd5\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u4e0d\u540c\u65b9\u9762\u3002"}}
{"id": "2506.05767", "pdf": "https://arxiv.org/pdf/2506.05767", "abs": "https://arxiv.org/abs/2506.05767", "authors": ["Bi Huo", "Bin Tu", "Cheng Qin", "Da Zheng", "Debing Zhang", "Dongjie Zhang", "En Li", "Fu Guo", "Jian Yao", "Jie Lou", "Junfeng Tian", "Li Hu", "Ran Zhu", "Shengdong Chen", "Shuo Liu", "Su Guang", "Te Wo", "Weijun Zhang", "Xiaoming Shi", "Xinxin Peng", "Xing Wu", "Yawen Liu", "Yuqiu Ji", "Ze Wen", "Zhenhai Liu", "Zichao Li", "Zilong Liao"], "title": "dots.llm1 Technical Report", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Mixture of Experts (MoE) models have emerged as a promising paradigm for\nscaling language models efficiently by activating only a subset of parameters\nfor each input token. In this report, we present dots.llm1, a large-scale MoE\nmodel that activates 14B parameters out of a total of 142B parameters,\ndelivering performance on par with state-of-the-art models while reducing\ntraining and inference costs. Leveraging our meticulously crafted and efficient\ndata processing pipeline, dots.llm1 achieves performance comparable to\nQwen2.5-72B after pretraining on 11.2T high-quality tokens and post-training to\nfully unlock its capabilities. Notably, no synthetic data is used during\npretraining. To foster further research, we open-source intermediate training\ncheckpoints at every one trillion tokens, providing valuable insights into the\nlearning dynamics of large language models.", "AI": {"tldr": "dots.llm1 \u662f\u4e00\u4e2a\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff0c\u901a\u8fc7\u6fc0\u6d3b\u5c11\u91cf\u53c2\u6570\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u5f00\u653e\u8bad\u7ec3\u68c0\u67e5\u70b9\u3002", "motivation": "\u4e3a\u4e86\u9ad8\u6548\u6269\u5c55\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6fc0\u6d3b\u53c2\u6570\u5b50\u96c6\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u5f00\u9500\u3002", "method": "\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u6a21\u578b\u901a\u8fc7\u4ec5\u6fc0\u6d3b\u90e8\u5206\u53c2\u6570\u8fdb\u884c\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u3002\u4f7f\u7528\u9ad8\u8d28\u91cf\u7684\u6d77\u91cf\u6570\u636e\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5e76\u5f00\u653e\u4e2d\u95f4\u8bad\u7ec3\u68c0\u67e5\u70b9\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002", "result": "\u6fc0\u6d3b1420\u4ebf\u53c2\u6570\u4e2d\u7684140\u4ebf\u53c2\u6570\uff0c\u5b9e\u73b0\u4e0eQwen2.5-72B\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u8bad\u7ec3\u68c0\u67e5\u70b9\u3002", "conclusion": "dots.llm1 \u6a21\u578b\u80fd\u591f\u5728\u4e0d\u4f7f\u7528\u5408\u6210\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u3002"}}
{"id": "2506.05628", "pdf": "https://arxiv.org/pdf/2506.05628", "abs": "https://arxiv.org/abs/2506.05628", "authors": ["Jiri Navratil", "Jarret Ross", "Payel Das", "Youssef Mroueh", "Samuel C Hoffman", "Vijil Chenthamarakshan", "Brian Belgodere"], "title": "GP-MoLFormer-Sim: Test Time Molecular Optimization through Contextual Similarity Guidance", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages main article, 21 pages total", "summary": "The ability to design molecules while preserving similarity to a target\nmolecule and/or property is crucial for various applications in drug discovery,\nchemical design, and biology. We introduce in this paper an efficient\ntraining-free method for navigating and sampling from the molecular space with\na generative Chemical Language Model (CLM), while using the molecular\nsimilarity to the target as a guide. Our method leverages the contextual\nrepresentations learned from the CLM itself to estimate the molecular\nsimilarity, which is then used to adjust the autoregressive sampling strategy\nof the CLM. At each step of the decoding process, the method tracks the\ndistance of the current generations from the target and updates the logits to\nencourage the preservation of similarity in generations. We implement the\nmethod using a recently proposed $\\sim$47M parameter SMILES-based CLM,\nGP-MoLFormer, and therefore refer to the method as GP-MoLFormer-Sim, which\nenables a test-time update of the deep generative policy to reflect the\ncontextual similarity to a set of guide molecules. The method is further\nintegrated into a genetic algorithm (GA) and tested on a set of standard\nmolecular optimization benchmarks involving property optimization, molecular\nrediscovery, and structure-based drug design. Results show that,\nGP-MoLFormer-Sim, combined with GA (GP-MoLFormer-Sim+GA) outperforms existing\ntraining-free baseline methods, when the oracle remains black-box. The findings\nin this work are a step forward in understanding and guiding the generative\nmechanisms of CLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86GP-MoLFormer-Sim\u65b9\u6cd5\uff0c\u53ef\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5bfc\u822a\u5206\u5b50\u7a7a\u95f4\uff0c\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u5728\u5206\u5b50\u4f18\u5316\u4efb\u52a1\u4e2d\u6548\u679c\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u4e13\u6ce8\u4e8e\u8bbe\u8ba1\u5728\u5206\u5b50\u4e4b\u95f4\u4fdd\u6301\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\uff0c\u8fd9\u5bf9\u4e8e\u836f\u7269\u53d1\u73b0\u3001\u5316\u5b66\u8bbe\u8ba1\u548c\u751f\u7269\u5b66\u4e2d\u7684\u5404\u79cd\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5316\u5b66\u8bed\u8a00\u6a21\u578b\uff08CLM\uff09\uff0c\u5229\u7528\u5206\u5b50\u76f8\u4f3c\u6027\u4e3a\u5bfc\u5411\u8fdb\u884c\u5bfc\u822a\u548c\u91c7\u6837\u3002\u8be5\u65b9\u6cd5\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u8ffd\u8e2a\u5f53\u524d\u751f\u6210\u4e0e\u76ee\u6807\u7684\u8ddd\u79bb\uff0c\u5e76\u66f4\u65b0logits\u4ee5\u9f13\u52b1\u751f\u6210\u4fdd\u7559\u76f8\u4f3c\u6027\u3002", "result": "GP-MoLFormer-Sim\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u5728\u6807\u51c6\u5206\u5b50\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u9ed1\u76d2\u60c5\u51b5\u4e0b\u7684\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "GP-MoLFormer-Sim\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u7684\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u8bad\u7ec3\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.05397", "pdf": "https://arxiv.org/pdf/2506.05397", "abs": "https://arxiv.org/abs/2506.05397", "authors": ["Jerrin Bright", "Zhibo Wang", "Yuhao Chen", "Sirisha Rambhatla", "John Zelek", "David Clausi"], "title": "Gen4D: Synthesizing Humans and Scenes in the Wild", "categories": ["cs.GR", "cs.AI"], "comment": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) Workshops", "summary": "Lack of input data for in-the-wild activities often results in low\nperformance across various computer vision tasks. This challenge is\nparticularly pronounced in uncommon human-centric domains like sports, where\nreal-world data collection is complex and impractical. While synthetic datasets\noffer a promising alternative, existing approaches typically suffer from\nlimited diversity in human appearance, motion, and scene composition due to\ntheir reliance on rigid asset libraries and hand-crafted rendering pipelines.\nTo address this, we introduce Gen4D, a fully automated pipeline for generating\ndiverse and photorealistic 4D human animations. Gen4D integrates expert-driven\nmotion encoding, prompt-guided avatar generation using diffusion-based Gaussian\nsplatting, and human-aware background synthesis to produce highly varied and\nlifelike human sequences. Based on Gen4D, we present SportPAL, a large-scale\nsynthetic dataset spanning three sports: baseball, icehockey, and soccer.\nTogether, Gen4D and SportPAL provide a scalable foundation for constructing\nsynthetic datasets tailored to in-the-wild human-centric vision tasks, with no\nneed for manual 3D modeling or scene design.", "AI": {"tldr": "\u63d0\u51fa\u4e86Gen4D\u81ea\u52a8\u751f\u62104D\u4eba\u7c7b\u52a8\u753b\u7684\u7ba1\u9053\uff0c\u4ee5\u53ca\u57fa\u4e8e\u6b64\u7684SportPAL\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u89e3\u51b3\u91ce\u5916\u4eba\u7c7b\u89c6\u89c9\u4efb\u52a1\u4e2d\u6570\u636e\u96c6\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u6536\u96c6\u590d\u6742\u4e14\u4e0d\u5207\u5b9e\u9645\uff0c\u5c24\u5176\u662f\u5728\u4f53\u80b2\u8fd9\u79cd\u4e0d\u5e38\u89c1\u7684\u4eba\u7c7b\u4e2d\u5fc3\u9886\u57df\uff0c\u56e0\u6b64\u7f3a\u4e4f\u91ce\u5916\u6d3b\u52a8\u8f93\u5165\u6570\u636e\u5bfc\u81f4\u5404\u79cd\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u7684\u4f4e\u6027\u80fd\u8868\u73b0\u3002", "method": "\u5f15\u5165Gen4D\uff0c\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u591a\u6837\u5316\u548c\u903c\u771f4D\u4eba\u7c7b\u52a8\u753b\u7684\u5168\u81ea\u52a8\u7ba1\u9053\uff0c\u5e76\u6574\u5408\u4e86\u4e13\u5bb6\u9a71\u52a8\u7684\u8fd0\u52a8\u7f16\u7801\u3001\u57fa\u4e8e\u6269\u6563\u7684\u9ad8\u65af\u70b9\u5f15\u5bfc\u7684\u5934\u50cf\u751f\u6210\uff0c\u4ee5\u53ca\u5177\u6709\u4eba\u7684\u80cc\u666f\u5408\u6210\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u751f\u6210\u9ad8\u591a\u6837\u6027\u548c\u903c\u771f\u5ea6\u7684\u4eba\u7c7b\u52a8\u753b\u5e8f\u5217\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5408\u6210\u6570\u636e\u96c6SportPAL\uff0c\u6db5\u76d6\u4e86\u4e09\u79cd\u4f53\u80b2\u9879\u76ee\u3002", "conclusion": "Gen4D\u548cSportPAL\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u7684\u9ad8\u903c\u771f\u5ea64D\u4eba\u7c7b\u52a8\u753b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u624b\u52a83D\u5efa\u6a21\u6216\u573a\u666f\u8bbe\u8ba1\u7684\u53ef\u6269\u5c55\u57fa\u7840\uff0c\u7528\u4e8e\u6784\u5efa\u9002\u5408\u91ce\u5916\u4eba\u7c7b\u4e2d\u5fc3\u89c6\u89c9\u4efb\u52a1\u7684\u5408\u6210\u6570\u636e\u96c6\u3002"}}
