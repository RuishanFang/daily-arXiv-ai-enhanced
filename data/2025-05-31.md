<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Training Language Models to Generate Quality Code with Program Analysis Feedback](https://arxiv.org/abs/2505.22704)
*Feng Yao,Zilong Wang,Liyuan Liu,Junxia Cui,Li Zhong,Xiaohan Fu,Haohui Mai,Vish Krishnan,Jianfeng Gao,Jingbo Shang*

Main category: cs.CL

TL;DR: REAL 框架利用程序分析和单元测试作为反馈信号，通过强化学习提升大语言模型的代码生成质量，实现生产质量的快速高效代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有的代码生成方法存在安全性和可维护性的问题，而现有解决方案依赖人工注释或脆弱的启发式方法，难以扩展。需要一个能自动有效激励语言模型生成高质量代码的方法。

Method: 提出了 REAL 框架，结合程序分析检测安全性或可维护性缺陷，以及单元测试确保功能正确性，以此作为激励信号，采用强化学习来提高代码生成质量。

Result: 通过实验验证，REAL 框架在多个数据集和模型规模上均展现出优于现有方法的性能，能够同时保证代码的功能正确性和质量。

Conclusion: REAL 框架通过程序分析引导反馈，成功激励大型语言模型生成生产质量的代码。实验表明，REAL 在功能性和代码质量的同步评估上优于当前最先进的方法。

Abstract: Code generation with large language models (LLMs), often termed vibe coding,
is increasingly adopted in production but fails to ensure code quality,
particularly in security (e.g., SQL injection vulnerabilities) and
maintainability (e.g., missing type annotations). Existing methods, such as
supervised fine-tuning and rule-based post-processing, rely on labor-intensive
annotations or brittle heuristics, limiting their scalability and
effectiveness. We propose REAL, a reinforcement learning framework that
incentivizes LLMs to generate production-quality code using program
analysis-guided feedback. Specifically, REAL integrates two automated signals:
(1) program analysis detecting security or maintainability defects and (2) unit
tests ensuring functional correctness. Unlike prior work, our framework is
prompt-agnostic and reference-free, enabling scalable supervision without
manual intervention. Experiments across multiple datasets and model scales
demonstrate that REAL outperforms state-of-the-art methods in simultaneous
assessments of functionality and code quality. Our work bridges the gap between
rapid prototyping and production-ready code, enabling LLMs to deliver both
speed and quality.

</details>


### [2] [Climate Finance Bench](https://arxiv.org/abs/2505.22752)
*Rafik Mankour,Yassine Chafai,Hamada Saleh,Ghassen Ben Hassine,Thibaud Barreau,Peter Tankov*

Main category: cs.CL

TL;DR: 这项研究通过构建数据集，比较了RAG方法在企业气候披露问答任务中的表现，发现检索器的有效性是关键瓶颈，并建议透明的碳报告技术。


<details>
  <summary>Details</summary>
Motivation: 提供一个关于企业气候披露的问答基准，以评估大型语言模型的表现。

Method: 构建了一个包含33份可持续发展报告和330个专家验证的问答对的数据集，并在此基础上提出了RAG方法的比较。

Result: 证明了RAG方法在响应问答任务时受限于检索器定位正确答案段落的能力，并倡导AI气候应用中透明的碳报告。

Conclusion: 揭示了RAG方法中的检索器在定位包含答案的段落的能力是其主要性能瓶颈。

Abstract: Climate Finance Bench introduces an open benchmark that targets
question-answering over corporate climate disclosures using Large Language
Models. We curate 33 recent sustainability reports in English drawn from
companies across all 11 GICS sectors and annotate 330 expert-validated
question-answer pairs that span pure extraction, numerical reasoning, and
logical reasoning. Building on this dataset, we propose a comparison of RAG
(retrieval-augmented generation) approaches. We show that the retriever's
ability to locate passages that actually contain the answer is the chief
performance bottleneck. We further argue for transparent carbon reporting in
AI-for-climate applications, highlighting advantages of techniques such as
Weight Quantization.

</details>


### [3] [Pre-Training Curriculum for Multi-Token Prediction in Language Models](https://arxiv.org/abs/2505.22757)
*Ansar Aynetdinov,Alan Akbik*

Main category: cs.CL

TL;DR: The paper proposes curriculum learning strategies for MTP in SLMs, showing forward curriculum benefits in enhancing NTP and output quality while retaining decoding advantages, unlike the reverse approach.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the capability of smaller language models (SLMs) to effectively utilize the multi-token prediction (MTP) objective, which has been challenging for them.

Method: The paper introduces a curriculum learning strategy for MTP training, exploring two variants: forward curriculum and reverse curriculum.

Result: The forward curriculum allows SLMs to leverage MTP better during pre-training, enhancing downstream NTP performance and generative output quality. The reverse curriculum improves NTP performance and output quality but doesn't aid self-speculative decoding.

Conclusion: SLMs can better leverage the MTP objective through a forward curriculum, improving NTP performance while retaining self-speculative decoding benefits. The reverse curriculum improves NTP performance and output quality but lacks self-speculative decoding enhancements.

Abstract: Multi-token prediction (MTP) is a recently proposed pre-training objective
for language models. Rather than predicting only the next token (NTP), MTP
predicts the next $k$ tokens at each prediction step, using multiple prediction
heads. MTP has shown promise in improving downstream performance, inference
speed, and training efficiency, particularly for large models. However, prior
work has shown that smaller language models (SLMs) struggle with the MTP
objective. To address this, we propose a curriculum learning strategy for MTP
training, exploring two variants: a forward curriculum, which gradually
increases the complexity of the pre-training objective from NTP to MTP, and a
reverse curriculum, which does the opposite. Our experiments show that the
forward curriculum enables SLMs to better leverage the MTP objective during
pre-training, improving downstream NTP performance and generative output
quality, while retaining the benefits of self-speculative decoding. The reverse
curriculum achieves stronger NTP performance and output quality, but fails to
provide any self-speculative decoding benefits.

</details>


### [4] [FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian](https://arxiv.org/abs/2505.22759)
*Sara Papi,Marco Gaido,Luisa Bentivogli,Alessio Brutti,Mauro Cettolo,Roberto Gretter,Marco Matassoni,Mohamed Nabih,Matteo Negri*

Main category: cs.CL

TL;DR: FAMA introduces open science speech models for English and Italian, achieving efficient performance and promoting transparency in research by releasing all resources as open source.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address reproducibility and fair evaluation challenges posed by the closed nature of current speech foundation models.

Method: The paper develops a family of open science SFMs for English and Italian using 150k+ hours of open-source speech data, and introduces a new dataset with 16k hours of cleaned and pseudo-labeled speech.

Result: FAMA achieves competitive performance and is up to 8 times faster than existing SFMs.

Conclusion: FAMA achieves competitive performance compared to existing SFMs, and promotes openness in speech technology research by releasing all artifacts under open-source licenses.

Abstract: The development of speech foundation models (SFMs) like Whisper and
SeamlessM4T has significantly advanced the field of speech processing. However,
their closed nature--with inaccessible training data and code--poses major
reproducibility and fair evaluation challenges. While other domains have made
substantial progress toward open science by developing fully transparent models
trained on open-source (OS) code and data, similar efforts in speech remain
limited. To fill this gap, we introduce FAMA, the first family of open science
SFMs for English and Italian, trained on 150k+ hours of OS speech data.
Moreover, we present a new dataset containing 16k hours of cleaned and
pseudo-labeled speech for both languages. Results show that FAMA achieves
competitive performance compared to existing SFMs while being up to 8 times
faster. All artifacts, including code, datasets, and models, are released under
OS-compliant licenses, promoting openness in speech technology research.

</details>


### [5] [StressTest: Can YOUR Speech LM Handle the Stress?](https://arxiv.org/abs/2505.22765)
*Iddo Yosha,Gallil Maimon,Yossi Adi*

Main category: cs.CL

TL;DR: 研究提出StressTest基准和Stress17k数据集，用以提升语音语言模型在句子重音任务上的表现，并成功优化出性能优异的StresSLM模型。


<details>
  <summary>Details</summary>
Motivation: 句子重音在语音的意义和说话者意图中起着重要作用，但在现有语音语言模型的评估和开发中尚未得到充分重视。

Method: 提出了一种新的合成数据生成管道，并创建Stress17k数据集，以模拟重音变化带来的意义变化，并用其优化模型。

Result: 优化后的模型StresSLM在句子重音推理和检测任务上显著优于现有模型。

Conclusion: 优化后的模型StresSLM在句子重音推理和检测任务上显著优于现有模型。

Abstract: Sentence stress refers to emphasis, placed on specific words within a spoken
utterance to highlight or contrast an idea, or to introduce new information. It
is often used to imply an underlying intention that is not explicitly stated.
Recent advances in speech-aware language models (SLMs) have enabled direct
processing of audio, allowing models to bypass transcription and access the
full richness of the speech signal and perform audio reasoning tasks such as
spoken question answering. Despite the crucial role of sentence stress in
shaping meaning and speaker intent, it remains largely overlooked in evaluation
and development of such models. In this work, we address this gap by
introducing StressTest, a benchmark specifically designed to evaluate a model's
ability to distinguish between interpretations of spoken sentences based on the
stress pattern. We assess the performance of several leading SLMs and find
that, despite their overall capabilities, they perform poorly on such tasks. To
overcome this limitation, we propose a novel synthetic data generation
pipeline, and create Stress17k, a training set that simulates change of meaning
implied by stress variation. Then, we empirically show that optimizing models
with this synthetic dataset aligns well with real-world recordings and enables
effective finetuning of SLMs. Results suggest, that our finetuned model,
StresSLM, significantly outperforms existing models on both sentence stress
reasoning and detection tasks. Code, models, data, and audio samples -
pages.cs.huji.ac.il/adiyoss-lab/stresstest.

</details>


### [6] [Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems](https://arxiv.org/abs/2505.22771)
*Christopher Ormerod*

Main category: cs.CL

TL;DR: 研究提出通过集成反馈导向标注提高自动作文评分的准确性。


<details>
  <summary>Details</summary>
Motivation: 提升自动作文评分的准确性，通过整合反馈导向的标注来改善评分性能。

Method: 使用两种大型语言模型生成标注，其中生成型语言模型用于拼写纠正，而编码器型语言模型用于识别和标记论证元素。将标注整合到评分过程中，采用微调的编码器作为分类器来提升性能。

Result: 通过使用微调的编码器型大语言模型作为分类器进行评分，性能得到了提高。

Conclusion: 结合反馈导向的标注可以提高自动作文评分的准确性，尤其是在识别拼写和语法错误以及论证组件方面，使用微调的编码器型大型语言模型作为分类器时可以提升性能。

Abstract: This study illustrates how incorporating feedback-oriented annotations into
the scoring pipeline can enhance the accuracy of automated essay scoring (AES).
This approach is demonstrated with the Persuasive Essays for Rating, Selecting,
and Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We
integrate two types of feedback-driven annotations: those that identify
spelling and grammatical errors, and those that highlight argumentative
components. To illustrate how this method could be applied in real-world
scenarios, we employ two LLMs to generate annotations -- a generative language
model used for spell-correction and an encoder-based token classifier trained
to identify and mark argumentative elements. By incorporating annotations into
the scoring process, we demonstrate improvements in performance using
encoder-based large language models fine-tuned as classifiers.

</details>


### [7] [Counting trees: A treebank-driven exploration of syntactic variation in speech and writing across languages](https://arxiv.org/abs/2505.22774)
*Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 研究发现语音和书面语的句法结构有显著差异，语音中存在的许多结构在书面语中并未出现。


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展、与语言无关的框架，以便系统地研究不同语料库中的句法变化。

Method: 采用完全归纳、自底向上的方法，将句法结构定义为去词化的依存（子）树，并从英语和斯洛文尼亚语的UD树库中提取这些结构。

Result: 通过分析，发现语音语料库包含的句法结构数量较少，且多样性低于书面语料库，并且语音和书面语的句法结构重叠非常有限。

Conclusion: 这项研究提出了一种基于树库的方法，比较语音和书面语中的句法结构。结果显示，语音和书面语的句法结构存在很大差异，语音中的句法结构较少且多样性较低，大多数在语音中出现的结构未在书面语中出现。

Abstract: This paper presents a novel treebank-driven approach to comparing syntactic
structures in speech and writing using dependency-parsed corpora. Adopting a
fully inductive, bottom-up method, we define syntactic structures as
delexicalized dependency (sub)trees and extract them from spoken and written
Universal Dependencies (UD) treebanks in two syntactically distinct languages,
English and Slovenian. For each corpus, we analyze the size, diversity, and
distribution of syntactic inventories, their overlap across modalities, and the
structures most characteristic of speech. Results show that, across both
languages, spoken corpora contain fewer and less diverse syntactic structures
than their written counterparts, with consistent cross-linguistic preferences
for certain structural types across modalities. Strikingly, the overlap between
spoken and written syntactic inventories is very limited: most structures
attested in speech do not occur in writing, pointing to modality-specific
preferences in syntactic organization that reflect the distinct demands of
real-time interaction and elaborated writing. This contrast is further
supported by a keyness analysis of the most frequent speech-specific
structures, which highlights patterns associated with interactivity,
context-grounding, and economy of expression. We argue that this scalable,
language-independent framework offers a useful general method for
systematically studying syntactic variation across corpora, laying the
groundwork for more comprehensive data-driven theories of grammar in use.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Design and testing of an agent chatbot supporting decision making with public transport data](https://arxiv.org/abs/2505.22698)
*Luca Fantin,Marco Antonelli,Margherita Cesetti,Daniele Irto,Bruno Zamengo,Francesco Silvestri*

Main category: cs.AI

TL;DR: 该论文提出了一种基于大型语言模型的聊天机器人，它通过集成多种工具简化了公共交通服务数据的查询与可视化，并通过一系列标准化问题测试其性能，验证生成查询的正确性和回答的一致性。


<details>
  <summary>Details</summary>
Motivation: 由于分析公共交通服务质量需要处理大量复杂的数据，许多用户难以使用SQL查询等工具。因此，提供一个简单友好的方式来与这些数据交互是非常必要的。

Method: 该聊天机器人综合使用大型语言模型(LLM)和一系列工具，通过代理架构实现，如执行SQL查询、数据可视化和创建地图。它还通过设定问题的工作流程来测试其性能，并存储生成的查询和响应数据。

Result: 聊天机器人经过全面测试，其数据集评估结果表明，它能够生成一致、正确的自然语言回答和SQL查询。

Conclusion: 实验结果表明，所开发的聊天机器人能够有效地与用户交互并支持决策制定，尤其是在验证回答的一致性和生成查询的正确性方面。

Abstract: Assessing the quality of public transportation services requires the analysis
of large quantities of data on the scheduled and actual trips and documents
listing the quality constraints each service needs to meet. Interrogating such
datasets with SQL queries, organizing and visualizing the data can be quite
complex for most users. This paper presents a chatbot offering a user-friendly
tool to interact with these datasets and support decision making. It is based
on an agent architecture, which expands the capabilities of the core Large
Language Model (LLM) by allowing it to interact with a series of tools that can
execute several tasks, like performing SQL queries, plotting data and creating
maps from the coordinates of a trip and its stops. This paper also tackles one
of the main open problems of such Generative AI projects: collecting data to
measure the system's performance. Our chatbot has been extensively tested with
a workflow that asks several questions and stores the generated query, the
retrieved data and the natural language response for each of them. Such
questions are drawn from a set of base examples which are then completed with
actual data from the database. This procedure yields a dataset for the
evaluation of the chatbot's performance, especially the consistency of its
answers and the correctness of the generated queries.

</details>


### [9] [Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields](https://arxiv.org/abs/2505.22753)
*Arseniy Pertzovsky,Roni Stern,Ariel Felner,Roie Zivan*

Main category: cs.AI

TL;DR: 研究人工势场(APFs)在MAPF和LMAPF中的应用，发现其对MAPF无益，但在LMAPF中大幅提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 研究如何将人工势场(APFs)应用于解决多代理路径规划(MAPF)和长期多代理路径规划(LMAPF)问题，以提高系统性能。

Method: 研究在不同的MAPF算法中引入人工势场(APFs)的方法，包括优先级规划、MAPF-LNS2和具有回溯的优先级继承(PIBT)。

Result: 实验结果显示，APFs虽然对MAPF没有实质性好处，但在LMAPF上显著提高了系统吞吐量。

Conclusion: 使用人工势场(APFs)对于传统多代理路径规划(MAPF)没有优势，但对于长期多代理路径规划(LMAPF)，APFs可以提高多达7倍的系统吞吐量。

Abstract: We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent
Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of
agents must move to their goal locations without collisions, whereas in LMAPF,
new goals are generated upon arrival. We propose methods for incorporating APFs
in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and
Priority Inheritance with Backtracking (PIBT). Experimental results show that
using APF is not beneficial for MAPF but yields up to a 7-fold increase in
overall system throughput for LMAPF.

</details>


### [10] [Decomposing Elements of Problem Solving: What "Math" Does RL Teach?](https://arxiv.org/abs/2505.22756)
*Tian Qin,Core Francisco Park,Mujin Kwun,Aaron Walsman,Eran Malach,Nikhil Anand,Hidenori Tanaka,David Alvarez-Melis*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型在数学推理任务中的能力，发现强化学习主要增强了执行稳健性，但在全新问题上受制于计划技能的不足。我们提供了一种模拟任务来验证并提出方法以潜在克服这些限制。


<details>
  <summary>Details</summary>
Motivation: 现有的数学推理任务已成为评估大语言模型推理能力的重要基准，但单靠精度指标难以细致地评估这些能力，无法揭示模型内化了哪些问题解决技能。为了更好地理解这些能力，我们提出将问题解决过程分解为基本能力：规划、执行和验证。

Method: 我们构建了一个简单的、合成的解题树导航任务，以模拟数学问题解决，验证强化学习主要提升了解题过程中的执行稳健性。

Result: 我们的实验证实，GRPO主要增强了解题中的执行技能——提高了模型在已知如何解决的问题上的执行稳健性。然而，RL训练的模型在面对全新问题时面临'覆盖墙'，因为其计划技能不足。在我们的合成任务中，我们确定了一些条件，使RL能够通过改善探索和对新解路径的泛化来潜在地克服覆盖墙。

Conclusion: 我们的研究揭示了强化学习在提升大语言模型推理能力中的作用，暴露了关键的局限性，并建议了一条克服这些障碍的路径。

Abstract: Mathematical reasoning tasks have become prominent benchmarks for assessing
the reasoning capabilities of LLMs, especially with reinforcement learning (RL)
methods such as GRPO showing significant performance gains. However, accuracy
metrics alone do not support fine-grained assessment of capabilities and fail
to reveal which problem-solving skills have been internalized. To better
understand these capabilities, we propose to decompose problem solving into
fundamental capabilities: Plan (mapping questions to sequences of steps),
Execute (correctly performing solution steps), and Verify (identifying the
correctness of a solution). Empirically, we find that GRPO mainly enhances the
execution skill-improving execution robustness on problems the model already
knows how to solve-a phenomenon we call temperature distillation. More
importantly, we show that RL-trained models struggle with fundamentally new
problems, hitting a 'coverage wall' due to insufficient planning skills. To
explore RL's impact more deeply, we construct a minimal, synthetic
solution-tree navigation task as an analogy for mathematical problem-solving.
This controlled setup replicates our empirical findings, confirming RL
primarily boosts execution robustness. Importantly, in this setting, we
identify conditions under which RL can potentially overcome the coverage wall
through improved exploration and generalization to new solution paths. Our
findings provide insights into the role of RL in enhancing LLM reasoning,
expose key limitations, and suggest a path toward overcoming these barriers.
Code is available at https://github.com/cfpark00/RL-Wall.

</details>


### [11] [Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds](https://arxiv.org/abs/2505.22779)
*Mohammad Helal Uddin,Sabur Baidya*

Main category: cs.AI

TL;DR: 该研究通过智能手机传感器数据和社交媒体情感分析评估抑郁水平，使用SVM算法分类，结果显示高准确率和显著相关性。


<details>
  <summary>Details</summary>
Motivation: 精神障碍，包括抑郁、焦虑及其他神经系统失调，特别在有社交回避倾向的个体中，构成了全球的重大挑战。

Method: 使用CNN深度学习模型和朴素贝叶斯分类器识别人类的日常身体活动，并对用户情感进行分类。通过支持向量机（SVM）算法对抑郁严重程度进行分类，取得了较高的准确率。

Result: 通过身体活动识别和情感分析取得95%和95.6%的准确率，最终使用SVM算法对抑郁严重程度进行分类，达到94%的高准确率。多个身体活动特征与抑郁症状的严重程度显著相关。

Conclusion: 该研究提出了一种基于智能手机传感器数据和社交媒体互动分析的混合方法，用于评估个体的抑郁水平。

Abstract: Mental disorders including depression, anxiety, and other neurological
disorders pose a significant global challenge, particularly among individuals
exhibiting social avoidance tendencies. This study proposes a hybrid approach
by leveraging smartphone sensor data measuring daily physical activities and
analyzing their social media (Twitter) interactions for evaluating an
individual's depression level. Using CNN-based deep learning models and Naive
Bayes classification, we identify human physical activities accurately and also
classify the user sentiments. A total of 33 participants were recruited for
data acquisition, and nine relevant features were extracted from the physical
activities and analyzed with their weekly depression scores, evaluated using
the Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six
are derived from physical activities, achieving an activity recognition
accuracy of 95%, while three features stem from sentiment analysis of Twitter
activities, yielding a sentiment analysis accuracy of 95.6%. Notably, several
physical activity features exhibited significant correlations with the severity
of depression symptoms. For classifying the depression severity, a support
vector machine (SVM)-based algorithm is employed that demonstrated a very high
accuracy of 94%, outperforming alternative models, e.g., the multilayer
perceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly
effective in the long run for monitoring depression without breaching personal
privacy.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [12] [A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems](https://arxiv.org/abs/2505.22814)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.MA

TL;DR: 本文提出了一种由大型语言模型启用的控制架构，以改善多代理制造系统在实时中断时的资源能力探索，与现有方法相比提高了系统的弹性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 制造环境复杂且不可预测，传统控制方法在动态工业环境中反应不足，因此需要先进的控制策略来处理不可预见的挑战，多代理系统可以通过决策的去中心化应对这些挑战，但当前的多代理系统在实时适应和上下文感知决策中面临挑战，提出本文的架构是为了解决这些局限。

Method: 本文通过模拟案例研究验证了所提出的启用大型语言模型的控制架构，以评估其在制造环境中的有效性。

Result: 模拟案例研究表明，所提出的架构提高了系统的弹性、灵活性、吞吐量和资源利用效率，与现有方法相比具有优势。

Conclusion: 本文提出了一种启用大型语言模型的多代理系统控制架构，可应对制造环境中的实时中断，并动态探索资源能力。通过模拟案例研究，发现与现有方法相比，该架构提高了系统的弹性和灵活性，改进了吞吐量和资源利用效率。

Abstract: Manufacturing environments are becoming more complex and unpredictable due to
factors such as demand variations and shorter product lifespans. This
complexity requires real-time decision-making and adaptation to disruptions.
Traditional control approaches highlight the need for advanced control
strategies capable of overcoming unforeseen challenges, as they demonstrate
limitations in responsiveness within dynamic industrial settings. Multi-agent
systems address these challenges through decentralization of decision-making,
enabling systems to respond dynamically to operational changes. However,
current multi-agent systems encounter challenges related to real-time
adaptation, context-aware decision-making, and the dynamic exploration of
resource capabilities. Large language models provide the possibility to
overcome these limitations through context-aware decision-making capabilities.
This paper introduces a large language model-enabled control architecture for
multi-agent manufacturing systems to dynamically explore resource capabilities
in response to real-time disruptions. A simulation-based case study
demonstrates that the proposed architecture improves system resilience and
flexibility. The case study findings show improved throughput and efficient
resource utilization compared to existing approaches.

</details>


### [13] [Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2505.23352)
*Xu Shen,Yixin Liu,Yiwei Dai,Yili Wang,Rui Miao,Yue Tan,Shirui Pan,Xin Wang*

Main category: cs.MA

TL;DR: 提出了一种名为EIB-leanrner的新型通信拓扑设计方法，通过平衡连接密度来优化多智能体协作，提高系统性能并降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 在语言模型驱动的多智能体系统中，通信拓扑结构决定了智能体之间的协作模式，影响集体决策的效率和有效性。现有研究往往过于专注于稀疏结构的构建，而忽视了稀疏和密集拓扑在协作中的影响。本研究旨在理解不同稀疏度的拓扑对智能体输出传播方式的影响。

Method: 提出了一种称为EIB-leanrner的新型拓扑设计方法，通过融合稠密和稀疏图的连接模式，平衡错误抑制和有益信息传播。

Result: 实验表明，EIB-leanrner在有效性、通信成本和鲁棒性方面具有明显优势。

Conclusion: 适度稀疏的拓扑结构可以在抑制错误传播的同时保持有益的信息扩散，通常达到最佳任务性能。EIB-leanrner通过融合稠密和稀疏图的连接模式，实现了错误抑制和有益信息传播的平衡。

Abstract: The communication topology in large language model-based multi-agent systems
fundamentally governs inter-agent collaboration patterns, critically shaping
both the efficiency and effectiveness of collective decision-making. While
recent studies for communication topology automated design tend to construct
sparse structures for efficiency, they often overlook why and when sparse and
dense topologies help or hinder collaboration. In this paper, we present a
causal framework to analyze how agent outputs, whether correct or erroneous,
propagate under topologies with varying sparsity. Our empirical studies reveal
that moderately sparse topologies, which effectively suppress error propagation
while preserving beneficial information diffusion, typically achieve optimal
task performance. Guided by this insight, we propose a novel topology design
approach, EIB-leanrner, that balances error suppression and beneficial
information propagation by fusing connectivity patterns from both dense and
sparse graphs. Extensive experiments show the superior effectiveness,
communication cost, and robustness of EIB-leanrner.

</details>


### [14] [Collaborative Last-Mile Delivery: A Multi-Platform Vehicle Routing Problem With En-route Charging](https://arxiv.org/abs/2505.23584)
*Sumbal Malik,Majid Khonji,Khaled Elbassioni,Jorge Dias*

Main category: cs.MA

TL;DR: 该研究提出了一种新的协同同步多平台无人机和机器人车辆路径问题（VRP-DR），并开发了启发式算法以提供高效的近似最优解。结果显示，多平台递送模式大幅节省了时间并降低了成本，同时揭示了多项因素对系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速增长和对及时、经济高效的最后一公里交付的需求增加了对协同物流的兴趣。这项研究旨在解决现有递送方式中存在的有效载荷限制、范围限制和电池约束等关键缺陷。

Method: 本研究将多平台无人机和机器人车辆路径问题（VRP-DR）构建为混合整数线性规划（MILP），以最小化运营成本和完工时间。同时，开发了一种可扩展的启发式算法FINDER（灵活集成交付与能源充电），用于提供有效的近似最优解。

Result: 通过多实例规模的数值实验评估MILP和启发式方法在解质量和计算时间方面的性能。结果表明，与仅使用卡车模式相比，联合递送模式显著节省了时间，并使成本大幅度降低。

Conclusion: 研究表明，采用多平台协同递送模式相比于仅使用卡车模式可以显著节省时间，并通过启用多次访问显著降低成本。还提供了关于在途充电、停靠灵活性、无人机数量、速度和有效载荷能力对系统性能影响的见解。

Abstract: The rapid growth of e-commerce and the increasing demand for timely,
cost-effective last-mile delivery have increased interest in collaborative
logistics. This research introduces a novel collaborative synchronized
multi-platform vehicle routing problem with drones and robots (VRP-DR), where a
fleet of $\mathcal{M}$ trucks, $\mathcal{N}$ drones and $\mathcal{K}$ robots,
cooperatively delivers parcels. Trucks serve as mobile platforms, enabling the
launching, retrieving, and en-route charging of drones and robots, thereby
addressing critical limitations such as restricted payload capacities, limited
range, and battery constraints. The VRP-DR incorporates five realistic
features: (1) multi-visit service per trip, (2) multi-trip operations, (3)
flexible docking, allowing returns to the same or different trucks (4) cyclic
and acyclic operations, enabling return to the same or different nodes; and (5)
en-route charging, enabling drones and robots to recharge while being
transported on the truck, maximizing operational efficiency by utilizing idle
transit time. The VRP-DR is formulated as a mixed-integer linear program (MILP)
to minimize both operational costs and makespan. To overcome the computational
challenges of solving large-scale instances, a scalable heuristic algorithm,
FINDER (Flexible INtegrated Delivery with Energy Recharge), is developed, to
provide efficient, near-optimal solutions. Numerical experiments across various
instance sizes evaluate the performance of the MILP and heuristic approaches in
terms of solution quality and computation time. The results demonstrate
significant time savings of the combined delivery mode over the truck-only mode
and substantial cost reductions from enabling multi-visits. The study also
provides insights into the effects of en-route charging, docking flexibility,
drone count, speed, and payload capacity on system performance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [15] [Localized Weather Prediction Using Kolmogorov-Arnold Network-Based Models and Deep RNNs](https://arxiv.org/abs/2505.22686)
*Ange-Clement Akazan,Verlon Roel Mbingui,Gnankan Landry Regis N'guessan,Issa Karambal*

Main category: cs.LG

TL;DR: 本研究评估了一些深度递归神经网络和基于Kolmogorov-Arnold的模型用于热带城市的天气预报，发现KAN模型在温度预测中表现优异，而TKAN变体在降水预报中表现突出，并且在气压预测方面传统RNN仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 天气预报对于风险管理和经济规划至关重要，尤其是在极端天气严重影响生计的热带非洲地区。然而，现有方法常常难以应对该地区复杂的非线性天气模式，因此有必要寻找更有效的数据高效方法。

Method: 本文通过对深度递归神经网络（如LSTM, GRU, BiLSTM, BiGRU）以及基于Kolmogorov-Arnold模型（KAN和TKAN）的性能进行基准测试，采用了自定义的TKAN变体，替换了TKAN的激活函数，以评估其在温度、降水和气压预测方面的表现。

Result: KAN模型在温度预测中表现突出，R2分别达到了0.9986（阿比让）和0.9998（基加利），MSE小于0.0014摄氏度平方。在降水预测中，TKAN变体在低降雨状态下的绝对误差最小。经典RNN在气压预测中仍表现强劲，R2约为0.83至0.86，超过了KAN模型在该任务中的表现。

Conclusion: 本研究表明，基于样条的神经架构在有效和数据高效的天气预报中具有潜力。KAN和TKAN模型在温度和降水预测中具有明显优势，传统RNN在气压预测中仍有竞争力。

Abstract: Weather forecasting is crucial for managing risks and economic planning,
particularly in tropical Africa, where extreme events severely impact
livelihoods. Yet, existing forecasting methods often struggle with the region's
complex, non-linear weather patterns. This study benchmarks deep recurrent
neural networks such as $\texttt{LSTM, GRU, BiLSTM, BiGRU}$, and
Kolmogorov-Arnold-based models $(\texttt{KAN} and \texttt{TKAN})$ for daily
forecasting of temperature, precipitation, and pressure in two tropical cities:
Abidjan, Cote d'Ivoire (Ivory Coast) and Kigali (Rwanda). We further introduce
two customized variants of $ \texttt{TKAN}$ that replace its original
$\texttt{SiLU}$ activation function with $ \texttt{GeLU}$ and \texttt{MiSH},
respectively. Using station-level meteorological data spanning from 2010 to
2024, we evaluate all the models on standard regression metrics. $\texttt{KAN}$
achieves temperature prediction ($R^2=0.9986$ in Abidjan, $0.9998$ in Kigali,
$\texttt{MSE} < 0.0014~^\circ C ^2$), while $\texttt{TKAN}$ variants minimize
absolute errors for precipitation forecasting in low-rainfall regimes. The
customized $\texttt{TKAN}$ models demonstrate improvements over the standard
$\texttt{TKAN}$ across both datasets. Classical \texttt{RNNs} remain highly
competitive for atmospheric pressure ($R^2 \approx 0.83{-}0.86$), outperforming
$\texttt{KAN}$-based models in this task. These results highlight the potential
of spline-based neural architectures for efficient and data-efficient
forecasting.

</details>


### [16] [SlimLLM: Accurate Structured Pruning for Large Language Models](https://arxiv.org/abs/2505.22689)
*Jialong Guo,Xinghao Chen,Yehui Tang,Yunhe Wang*

Main category: cs.LG

TL;DR: SlimLLM提供了一种快速有效的结构化剪枝方法，通过整体评估通道和注意力头的重要性并结合线性回归策略，能在保证性能的情况下压缩大语言模型的参数，在LLaMA基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型巨大的计算成本，其部署和应用受到严重限制。结构化剪枝是一种有效的解决方案，用于压缩大语言模型的参数并最小化性能损失。

Method: 我们的方法包括对通道和注意力头的整体重要性评估，而不是简单地汇总子模块中各个元素的重要性，并使用线性回归策略快速恢复性能。此外，我们还引入了基于层的重要性比率来决定每层的剪枝比率。

Result: 我们的SlimLLM方法在LLaMA基准测试中优于其他方法，并达到了最先进的性能。

Conclusion: 我们提出了一种名为SlimLLM的结构化剪枝方法，可以有效地压缩大语言模型的参数并保持性能。

Abstract: Large language models(LLMs) have garnered significant attention and
demonstrated impressive capabilities in a wide range of applications. However,
due to their enormous computational costs, the deployment and application of
LLMs are often severely limited. To address this issue, structured pruning is
an effective solution to compress the parameters of LLMs. Determining the
importance of each sub-module in LLMs and minimizing performance loss are
critical issues that need to be carefully addressed in structured pruning. In
this paper, we propose an effective and fast structured pruning method named
SlimLLM for large language models. For channel and attention head pruning, we
evaluate the importance based on the entire channel or head, rather than merely
aggregating the importance of individual elements within a sub-module. This
approach enables a more holistic consideration of the interdependence among
elements within the sub-module. In addition, we design a simple linear
regression strategy for the output matrix to quickly recover performance. We
also propose layer-based importance ratio to determine the pruning ratio for
each layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other
methods and achieves state-of-the-art performance.

</details>


### [17] [MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning](https://arxiv.org/abs/2505.22694)
*Dacao Zhang,Kun Zhang,Shimao Chu,Le Wu,Xin Li,Si Wei*

Main category: cs.LG

TL;DR: MoRE improves multi-task LLM performance by aligning LoRA ranks with tasks, outperforming other methods without extra inference costs.


<details>
  <summary>Details</summary>
Motivation: Overcome the limitations of existing LoRA methods in multi-task scenarios by aligning different ranks of LoRA modules with specific tasks to enhance efficiency and effectiveness.

Method: Proposing MoRE, a Mixture of Low-Rank Experts, which includes an adaptive rank selector to align different LoRA ranks with specific tasks.

Result: MoRE enhances the adaptability and efficiency of LoRA in multi-task scenarios, outperforming traditional LoRA and its variants over multiple benchmarks with different LLMs.

Conclusion: MoRE significantly improves the performance of LLMs in multi-task scenarios without adding extra inference costs.

Abstract: With the rapid development of Large Language Models (LLMs),
Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant
attention, which aims to achieve efficient fine-tuning of LLMs with fewer
parameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)
introduces low-rank matrices to approximate the incremental tuning parameters
and achieves impressive performance over multiple scenarios. After that, plenty
of improvements have been proposed for further improvement. However, these
methods either focus on single-task scenarios or separately train multiple LoRA
modules for multi-task scenarios, limiting the efficiency and effectiveness of
LoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in
this paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for
multi-task PEFT. Specifically, instead of using an individual LoRA for each
task, we align different ranks of LoRA module with different tasks, which we
named low-rank experts. Moreover, we design a novel adaptive rank selector to
select the appropriate expert for each task. By jointly training low-rank
experts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task
scenarios. Finally, we conduct extensive experiments over multiple multi-task
benchmarks along with different LLMs to verify model performance. Experimental
results demonstrate that compared to traditional LoRA and its variants, MoRE
significantly improves the performance of LLMs in multi-task scenarios and
incurs no additional inference cost. We also release the model and code to
facilitate the community.

</details>


### [18] [LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning](https://arxiv.org/abs/2505.22695)
*Tengfei Lyu,Siyuan Feng,Hao Liu,Hai Yang*

Main category: cs.LG

TL;DR: 提出了使用LLMs的新框架LLM-ODDR，以优化叫车服务中的订单派送和司机重新定位，取得了比传统方法更优的效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽视了司机收入公平性、可解释性和适应真实动态的能力，需要新的方法来解决这些问题。

Method: 我们提出了使用大型语言模型（LLMs）的新框架LLM-ODDR来进行订单派送和司机重新定位。框架包括三个关键组件：多目标指导的订单价值优化、公平感知的订单派送和时空需求感知的司机重新定位。

Result: 通过曼哈顿出租车运营的真实数据集进行的广泛实验表明，LLM-ODDR框架在有效性、适应性和可解释性方面优于传统方法。

Conclusion: 我们的框架显著优于传统方法，在有效性、适应异常条件和决策可解释性方面表现突出。

Abstract: Ride-hailing platforms face significant challenges in optimizing order
dispatching and driver repositioning operations in dynamic urban environments.
Traditional approaches based on combinatorial optimization, rule-based
heuristics, and reinforcement learning often overlook driver income fairness,
interpretability, and adaptability to real-world dynamics. To address these
gaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models
(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in
ride-hailing services. LLM-ODDR framework comprises three key components: (1)
Multi-objective-guided Order Value Refinement, which evaluates orders by
considering multiple objectives to determine their overall value; (2)
Fairness-aware Order Dispatching, which balances platform revenue with driver
income fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,
which optimizes idle vehicle placement based on historical patterns and
projected supply. We also develop JointDR-GPT, a fine-tuned model optimized for
ODDR tasks with domain knowledge. Extensive experiments on real-world datasets
from Manhattan taxi operations demonstrate that our framework significantly
outperforms traditional methods in terms of effectiveness, adaptability to
anomalous conditions, and decision interpretability. To our knowledge, this is
the first exploration of LLMs as decision-making agents in ride-hailing ODDR
tasks, establishing foundational insights for integrating advanced language
models within intelligent transportation systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [19] [Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models](https://arxiv.org/abs/2505.22804)
*Jonghan Lim,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 该论文探讨了利用大型语言模型提高多机器人制造系统的任务重新分配能力，实验中证明了其在故障恢复中的高效性。


<details>
  <summary>Details</summary>
Motivation: 多机器人协作在处理复杂和动态环境方面受到越来越多的关注，但其去中心化协调系统在实时适应意外中断方面存在挑战。大型语言模型的进步为上下文感知决策提供了新的机会。

Method: 引入了一个基于大型语言模型的控制框架，用于动态任务重新分配，中央控制器代理利用语言模型解释机器人配置数据，并在故障发生时生成有效的重新分配方案。

Result: 在真实世界的实验设置中展示了高任务成功率，表明该方法在从故障中恢复的方面表现优异。

Conclusion: 实验结果表明，该框架能够有效应对机器人的故障，具有很高的任务成功率，强调了其在提高多机器人制造系统适应性方面的潜力。

Abstract: Recent manufacturing systems are increasingly adopting multi-robot
collaboration to handle complex and dynamic environments. While multi-agent
architectures support decentralized coordination among robot agents, they often
face challenges in enabling real-time adaptability for unexpected disruptions
without predefined rules. Recent advances in large language models offer new
opportunities for context-aware decision-making to enable adaptive responses to
unexpected changes. This paper presents an initial exploratory implementation
of a large language model-enabled control framework for dynamic task
reassignment in multi-robot manufacturing systems. A central controller agent
leverages the large language model's ability to interpret structured robot
configuration data and generate valid reassignments in response to robot
failures. Experiments in a real-world setup demonstrate high task success rates
in recovering from failures, highlighting the potential of this approach to
improve adaptability in multi-robot manufacturing systems.

</details>
