{"id": "2506.04236", "pdf": "https://arxiv.org/pdf/2506.04236", "abs": "https://arxiv.org/abs/2506.04236", "authors": ["Botao Amber Hu", "Helena Rong"], "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "categories": ["cs.MA", "cs.AI", "cs.HC", "cs.NE"], "comment": "Submitted to ALIFE 2025", "summary": "In Artificial Life (ALife) research, replicating Open-Ended Evolution\n(OEE)-the continuous emergence of novelty observed in biological life-has\ntraditionally been pursued within isolated closed system simulations, such as\nTierra and Avida, which have typically plateaued after an initial burst of\nnovelty, failing to achieve sustained OEE. Scholars suggest that OEE requires\nan \"open\" system that continually exchanges information or energy with its\nenvironment. A recent technological innovation in decentralized physical\ninfrastructure networks (DePIN) providing permissionless computational\nsubstrates enables deploying large language model (LLM)-based AI agents on\nblockchains integrated with Trusted Execution Environments (TEEs). This enables\non-chain agents to operate autonomously \"in the wild,\" achieving\nself-sovereignty without human oversight. These agents can control their own\nsocial media accounts and cryptocurrency wallets, allowing them to interact\ndirectly with blockchain-based financial networks and broader human social\nmedia. Building on this new paradigm of on-chain agents, Spore.fun is a recent\nreal-world AI evolution experiment that enables autonomous breeding and\nevolution of new on-chain agents. This paper presents a detailed case study of\nSpore.fun, examining agent behaviors and their evolutionary trajectories\nthrough digital ethology. We aim to spark discussion about whether \"open\" ALife\nsystems \"in-the-wild,\" based on permissionless computational substrates and\ndriven by economic incentives to interact with their environment, could finally\nachieve the long-sought goal of OEE.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u667a\u80fd\u4f53\u5728\u5f00\u653e\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u8fdb\u5316\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u4e8eSpore.fun\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9645\u6848\u4f8b\u5206\u6790\u3002", "motivation": "\u901a\u8fc7\u65b0\u6280\u672f\u7684\u5e94\u7528\uff0c\u5c06\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684AI\u667a\u80fd\u4f53\u90e8\u7f72\u5728\u533a\u5757\u94fe\u4e0a\uff0c\u4ee5\u5b9e\u73b0\u65e0\u9700\u4eba\u7c7b\u76d1\u7763\u7684\u81ea\u6cbb\u6f14\u5316\uff0c\u4e3a\u957f\u671f\u7684\u5f00\u653e\u5f0f\u8fdb\u5316\u63d0\u4f9b\u53ef\u80fd\u3002", "method": "\u672c\u6587\u5229\u7528\u6570\u5b57\u884c\u4e3a\u5b66\u5bf9Spore.fun\u4e2d\u94fe\u4e0a\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u548c\u8fdb\u5316\u8f68\u8ff9\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u94fe\u4e0a\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u7e41\u6b96\u548c\u8fdb\u5316\uff0c\u4e0e\u533a\u5757\u94fe\u91d1\u878d\u7f51\u7edc\u53ca\u4eba\u7c7b\u793e\u4ea4\u5a92\u4f53\u8fdb\u884c\u4ea4\u4e92\uff0c\u5c55\u793a\u4e86\u5f00\u653e\u7cfb\u7edf\u4e2d\u6301\u7eed\u65b0\u9896\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5f00\u653e\u4eba\u5de5\u751f\u547d\u7cfb\u7edf\u662f\u5426\u80fd\u591f\u901a\u8fc7\u7ecf\u6d4e\u6fc0\u52b1\u4e0e\u73af\u5883\u4e92\u52a8\u6765\u5b9e\u73b0\u6301\u7eed\u7684\u5f00\u653e\u5f0f\u8fdb\u5316\u3002"}}
{"id": "2506.04255", "pdf": "https://arxiv.org/pdf/2506.04255", "abs": "https://arxiv.org/abs/2506.04255", "authors": ["Kunal Pai", "Parth Shah", "Harshil Patel"], "title": "HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization", "categories": ["cs.MA"], "comment": "Submitted as part of the Research Track at AgentX 2025, organized by\n  Berkeley RDI", "summary": "Rapid Large Language Model (LLM) advancements are fueling autonomous\nMulti-Agent System (MAS) development. However, current frameworks often lack\nflexibility, resource awareness, model diversity, and autonomous tool creation.\nThis paper introduces HASHIRU (Hierarchical Agent System for Hybrid Intelligent\nResource Utilization), a novel MAS framework enhancing flexibility, resource\nefficiency, and adaptability. HASHIRU features a \"CEO\" agent dynamically\nmanaging specialized \"employee\" agents, instantiated based on task needs and\nresource constraints (cost, memory). Its hybrid intelligence prioritizes\nsmaller, local LLMs (via Ollama) while flexibly using external APIs and larger\nmodels when necessary. An economic model with hiring/firing costs promotes team\nstability and efficient resource allocation. The system also includes\nautonomous API tool creation and a memory function. Evaluations on tasks like\nacademic paper review (58% success), safety assessments (100% on a\nJailbreakBench subset), and complex reasoning (outperforming Gemini 2.0 Flash\non GSM8K: 96% vs. 61%; JEEBench: 80% vs. 68.3%; SVAMP: 92% vs. 84%) demonstrate\nHASHIRU's capabilities. Case studies illustrate its self-improvement via\nautonomous cost model generation, tool integration, and budget management.\nHASHIRU offers a promising approach for more robust, efficient, and adaptable\nMAS through dynamic hierarchical control, resource-aware hybrid intelligence,\nand autonomous functional extension. Source code and benchmarks are available\nat https://github.com/HASHIRU-AI/HASHIRU and\nhttps://github.com/HASHIRU-AI/HASHIRUBench respectively, and a live demo is\navailable at https://hashiruagentx-hashiruai.hf.space upon request.", "AI": {"tldr": "HASHIRU improves flexibility, resource efficiency, and adaptability in MAS through a dynamic management model and hybrid intelligence, outperforming current benchmarks in various evaluations.", "motivation": "Existing MAS frameworks lack flexibility, resource awareness, model diversity, and the ability to autonomously create tools, which HASHIRU aims to address.", "method": "The framework employs a \"CEO\" agent that dynamically manages \"employee\" agents, adapting to task and resource needs. It uses a hybrid intelligence model prioritizing smaller, local LLMs, and flexibly supplements with external APIs and larger models. An economic model governs hiring/firing costs to enhance stability and efficiency.", "result": "HASHIRU demonstrated high performance in various tasks. It succeeded in academic paper review (58% success), excelled in safety assessments (100% success on a JailbreakBench subset), and outperformed existing models in complex reasoning tasks such as GSM8K, JEEBench, and SVAMP.", "conclusion": "HASHIRU provides a more robust, efficient, and adaptable MAS framework through dynamic hierarchical control, resource-aware hybrid intelligence, and autonomous functional extension."}}
{"id": "2506.04265", "pdf": "https://arxiv.org/pdf/2506.04265", "abs": "https://arxiv.org/abs/2506.04265", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "comment": null, "summary": "This work focuses on the credit assignment problem in cooperative multi-agent\nreinforcement learning (MARL). Sharing the global advantage among agents often\nleads to suboptimal policy updates as it fails to account for the distinct\ncontributions of agents. Although numerous methods consider global or\nindividual contributions for credit assignment, a detailed analysis at the\ncoalition level remains lacking in many approaches. This work analyzes the\nover-updating problem during multi-agent policy updates from a coalition-level\nperspective. To address this issue, we propose a credit assignment method\ncalled Coalitional Rational Advantage Decomposition (CORA). CORA evaluates\ncoalitional advantages via marginal contributions from all possible coalitions\nand decomposes advantages using the core solution from cooperative game theory,\nensuring coalitional rationality. To reduce computational overhead, CORA\nemploys random coalition sampling. Experiments on matrix games, differential\ngames, and multi-agent collaboration benchmarks demonstrate that CORA\noutperforms strong baselines, particularly in tasks with multiple local optima.\nThese findings highlight the importance of coalition-aware credit assignment\nfor improving MARL performance.", "AI": {"tldr": "CORA\u65b9\u6cd5\u901a\u8fc7\u8054\u76df\u7ea7\u4fe1\u7528\u5206\u914d\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u5c24\u5176\u5728\u591a\u5c40\u90e8\u6700\u4f18\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4fe1\u7528\u5206\u914d\u4e0a\u5f80\u5f80\u7f3a\u4e4f\u5bf9\u8054\u76df\u7ea7\u8d21\u732e\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u5bfc\u81f4\u5728\u7b56\u7565\u66f4\u65b0\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86CORA\u4fe1\u7528\u5206\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u968f\u673a\u8054\u76df\u62bd\u6837\u8ba1\u7b97\u8054\u76df\u4f18\u52bf\uff0c\u5e76\u4f7f\u7528\u5408\u4f5c\u535a\u5f08\u8bba\u4e2d\u7684\u6838\u5fc3\u89e3\u6765\u5206\u89e3\u4f18\u52bf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCORA\u5728\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u591a\u4e2a\u5c40\u90e8\u6700\u4f18\u70b9\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCORA\u7684\u4fe1\u7528\u5206\u914d\u65b9\u6cd5\uff0c\u5f3a\u8c03\u8054\u76df\u7ea7\u7684\u4fe1\u7528\u5206\u914d\u5728\u6539\u8fdb\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.04266", "pdf": "https://arxiv.org/pdf/2506.04266", "abs": "https://arxiv.org/abs/2506.04266", "authors": ["Timo Looms", "Lin Xie"], "title": "CPU-Based Layout Design for Picker-to-Parts Pallet Warehouses", "categories": ["cs.MA", "cs.AR"], "comment": "8 pages,6 figures, conference", "summary": "Picker-to-parts pallet warehouses often face inefficiencies due to\nconventional layouts causing excessive travel distances and high labor\nrequirements. This study introduces a novel layout design inspired by CPU\narchitecture, partitioning warehouse space into specialized zones, namely\nPerformance (P), Efficiency (E), and Shared (S). Discrete-event simulation is\nused to evaluate this design against traditional rectangular (random and ABC\nstorage) and Flying-V layouts. Results demonstrate significant improvements in\nthroughput time and reduced labor requirements, highlighting the potential for\nCPU-based layouts in optimizing warehouse operations.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u53d7CPU\u67b6\u6784\u542f\u53d1\u7684\u4ed3\u5e93\u7a7a\u95f4\u5e03\u5c40\uff0c\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8be5\u5e03\u5c40\u5728\u541e\u5410\u65f6\u95f4\u548c\u52b3\u52a8\u529b\u9700\u6c42\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u5e03\u5c40\u3002", "motivation": "\u4f20\u7edf\u5e03\u5c40\u5bfc\u81f4\u8fc7\u591a\u7684\u884c\u8d70\u8ddd\u79bb\u548c\u9ad8\u52b3\u52a8\u529b\u9700\u6c42\uff0c\u4e9f\u9700\u4e00\u79cd\u521b\u65b0\u7684\u5e03\u5c40\u8bbe\u8ba1\u6765\u4f18\u5316\u4ed3\u5e93\u6548\u7387\u3002", "method": "\u4f7f\u7528\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u6280\u672f\u5bf9\u4e0d\u540c\u5e03\u5c40\u8fdb\u884c\u5bf9\u6bd4\u8bc4\u4f30\u3002", "result": "\u65b0\u7684\u5e03\u5c40\u8bbe\u8ba1\u5728\u541e\u5410\u65f6\u95f4\u548c\u52b3\u52a8\u529b\u9700\u6c42\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u5584\u3002", "conclusion": "\u57fa\u4e8eCPU\u7684\u5e03\u5c40\u8bbe\u8ba1\u53ef\u4ee5\u663e\u8457\u6539\u5584\u4ed3\u5e93\u7684\u8fd0\u8425\u6548\u7387\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\u7f29\u77ed\u4e86\u8fd0\u8f93\u65f6\u95f4\u548c\u964d\u4f4e\u4e86\u52b3\u52a8\u529b\u9700\u6c42\u3002"}}
{"id": "2506.04344", "pdf": "https://arxiv.org/pdf/2506.04344", "abs": "https://arxiv.org/abs/2506.04344", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large decoder-only language models (LLMs) have achieved remarkable success in\ngeneration and reasoning tasks, where they generate text responses given\ninstructions. However, many applications, e.g., retrieval augmented generation\n(RAG), still rely on separate embedding models to generate text embeddings,\nwhich can complicate the system and introduce discrepancies in understanding of\nthe query between the embedding model and LLMs. To address this limitation, we\npropose a simple self-supervised approach, Generative Embedding large language\nModel (GEM), that enables any large decoder-only LLM to generate high-quality\ntext embeddings while maintaining its original text generation and reasoning\ncapabilities. Our method inserts new special token(s) into a text body, and\ngenerates summarization embedding of the text by manipulating the attention\nmask. This method could be easily integrated into post-training or fine tuning\nstages of any existing LLMs. We demonstrate the effectiveness of our approach\nby applying it to two popular LLM families, ranging from 1B to 8B parameters,\nand evaluating the transformed models on both text embedding benchmarks (MTEB)\nand NLP benchmarks (MMLU). The results show that our proposed method\nsignificantly improves the original LLMs on MTEB while having a minimal impact\non MMLU. Our strong results indicate that our approach can empower LLMs with\nstate-of-the-art text embedding capabilities while maintaining their original\nNLP performance", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u751f\u6210\u5d4c\u5165\u5927\u8bed\u8a00\u6a21\u578b\uff08GEM\uff09\u65b9\u6cd5\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4fdd\u7559\u5176\u539f\u6709\u80fd\u529b\u7684\u540c\u65f6\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\u5d4c\u5165\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u76ee\u524d\u8bb8\u591a\u5e94\u7528\u4ecd\u4f9d\u8d56\u4e8e\u5355\u72ec\u7684\u5d4c\u5165\u6a21\u578b\u751f\u6210\u6587\u672c\u5d4c\u5165\uff0c\u8fd9\u53ef\u80fd\u4f1a\u4f7f\u7cfb\u7edf\u590d\u6742\u5316\uff0c\u5e76\u5728\u5d4c\u5165\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u5f15\u5165\u5bf9\u67e5\u8be2\u7406\u89e3\u7684\u4e0d\u4e00\u81f4\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u9650\u5236\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\u5d4c\u5165\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u81ea\u76d1\u7763\u65b9\u6cd5\uff0c\u79f0\u4e3a\u751f\u6210\u5d4c\u5165\u5927\u8bed\u8a00\u6a21\u578b\uff08GEM\uff09\uff0c\u901a\u8fc7\u5728\u6587\u672c\u4e3b\u4f53\u4e2d\u63d2\u5165\u65b0\u7684\u7279\u6b8a\u6807\u8bb0\u5e76\u64cd\u63a7\u6ce8\u610f\u529b\u63a9\u7801\u7684\u65b9\u6cd5\uff0c\u4f7f\u4efb\u4f55\u5927\u578b\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u5d4c\u5165\u3002\u8be5\u65b9\u6cd5\u53ef\u5728\u540e\u8bad\u7ec3\u6216\u5fae\u8c03\u9636\u6bb5\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6587\u672c\u5d4c\u5165\u57fa\u51c6\uff08MTEB\uff09\u4e0a\uff0c\u5e94\u7528\u672c\u6587\u65b9\u6cd5\u540e\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u800c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u57fa\u51c6\uff08MMLU\uff09\u4e0a\u7684\u5f71\u54cd\u6781\u5c0f", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u539f\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u540c\u65f6\u5bf9\u5176\u539f\u6709\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u8868\u73b0\u5f71\u54cd\u6781\u5c0f\u3002"}}
{"id": "2506.04244", "pdf": "https://arxiv.org/pdf/2506.04244", "abs": "https://arxiv.org/abs/2506.04244", "authors": ["Farzad Farhadzadeh", "Debasmit Das", "Shubhankar Borse", "Fatih Porikli"], "title": "Zero-Shot Adaptation of Parameter-Efficient Fine-Tuning in Diffusion Models", "categories": ["cs.AI"], "comment": "ICML 2025", "summary": "We introduce ProLoRA, enabling zero-shot adaptation of parameter-efficient\nfine-tuning in text-to-image diffusion models. ProLoRA transfers pre-trained\nlow-rank adjustments (e.g., LoRA) from a source to a target model without\nadditional training data. This overcomes the limitations of traditional methods\nthat require retraining when switching base models, often challenging due to\ndata constraints. ProLoRA achieves this via projection of source adjustments\ninto the target model's weight space, leveraging subspace and null space\nsimilarities and selectively targeting aligned layers. Evaluations on\nestablished text-to-image models demonstrate successful knowledge transfer and\ncomparable performance without retraining.", "AI": {"tldr": "ProLoRA\u4f7f\u5f97\u5728\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u8de8\u6a21\u578b\u8f6c\u79fb\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6570\u636e\uff0c\u5229\u7528\u5b50\u7a7a\u95f4\u548c\u96f6\u7a7a\u95f4\u7684\u76f8\u4f3c\u6027\u5bf9\u9f50\u5c42\uff0c\u6210\u529f\u8fdb\u884c\u77e5\u8bc6\u8f6c\u79fb\uff0c\u6027\u80fd\u826f\u597d\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5207\u6362\u57fa\u7840\u6a21\u578b\u65f6\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\uff0c\u8fd9\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u8f83\u4e3a\u56f0\u96be\u3002ProLoRA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5c06\u6e90\u8c03\u6574\u6295\u5c04\u5230\u76ee\u6807\u6a21\u578b\u7684\u6743\u91cd\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u5b50\u7a7a\u95f4\u548c\u96f6\u7a7a\u95f4\u76f8\u4f3c\u6027\uff0c\u9009\u62e9\u6027\u5730\u5bf9\u9f50\u76ee\u6807\u6a21\u578b\u7684\u5c42\uff0c\u6765\u5b9e\u73b0\u96f6\u6837\u672c\u7684\u6a21\u578b\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u65e2\u5b9a\u7684\u6587\u672c\u751f\u6210\u56fe\u50cf\u6a21\u578b\u4e0a\uff0cProLoRA\u80fd\u591f\u5728\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6210\u529f\u5b9e\u73b0\u77e5\u8bc6\u8f6c\u79fb\uff0c\u6027\u80fd\u53ef\u4e0e\u91cd\u65b0\u8bad\u7ec3\u7684\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "ProLoRA\u5b9e\u73b0\u4e86\u4e0d\u9700\u8981\u989d\u5916\u8bad\u7ec3\u6570\u636e\u7684\u8de8\u6a21\u578b\u8f6c\u79fb\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5927\u5e45\u5ea6\u51cf\u8f7b\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5207\u6362\u57fa\u7840\u6a21\u578b\u65f6\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u7684\u95ee\u9898\u3002"}}
{"id": "2506.04237", "pdf": "https://arxiv.org/pdf/2506.04237", "abs": "https://arxiv.org/abs/2506.04237", "authors": ["Sanchit Sinha", "Aidong Zhang"], "title": "A Comprehensive Survey on the Risks and Limitations of Concept-based Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept-based Models are a class of inherently explainable networks that\nimprove upon standard Deep Neural Networks by providing a rationale behind\ntheir predictions using human-understandable `concepts'. With these models\nbeing highly successful in critical applications like medical diagnosis and\nfinancial risk prediction, there is a natural push toward their wider adoption\nin sensitive domains to instill greater trust among diverse stakeholders.\nHowever, recent research has uncovered significant limitations in the structure\nof such networks, their training procedure, underlying assumptions, and their\nsusceptibility to adversarial vulnerabilities. In particular, issues such as\nconcept leakage, entangled representations, and limited robustness to\nperturbations pose challenges to their reliability and generalization.\nAdditionally, the effectiveness of human interventions in these models remains\nan open question, raising concerns about their real-world applicability. In\nthis paper, we provide a comprehensive survey on the risks and limitations\nassociated with Concept-based Models. In particular, we focus on aggregating\ncommonly encountered challenges and the architecture choices mitigating these\nchallenges for Supervised and Unsupervised paradigms. We also examine recent\nadvances in improving their reliability and discuss open problems and promising\navenues of future research in this domain.", "AI": {"tldr": "\u8bba\u6587\u5bf9\u6982\u5ff5\u6a21\u578b\u7684\u98ce\u9669\u548c\u9650\u5236\u8fdb\u884c\u4e86\u8be6\u7ec6\u8c03\u67e5\uff0c\u6307\u51fa\u5176\u7ed3\u6784\u548c\u8bad\u7ec3\u7a0b\u5e8f\u4e2d\u7684\u663e\u8457\u9650\u5236\uff0c\u5e76\u603b\u7ed3\u6539\u8fdb\u63aa\u65bd\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a8\u52a8\u6982\u5ff5\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\uff0c\u4ee5\u589e\u52a0\u5404\u65b9\u7684\u4fe1\u4efb\u3002", "method": "\u5bf9\u6982\u5ff5\u6a21\u578b\u7684\u98ce\u9669\u548c\u5c40\u9650\u6027\u8fdb\u884c\u4e86\u7efc\u5408\u8c03\u67e5\uff0c\u6c47\u603b\u4e86\u5e38\u89c1\u6311\u6218\u53ca\u5e94\u5bf9\u67b6\u6784\u9009\u62e9\uff0c\u5e76\u63a2\u8ba8\u4e86\u6539\u8fdb\u6a21\u578b\u53ef\u9760\u6027\u7684\u6700\u65b0\u8fdb\u5c55\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u6982\u5ff5\u6a21\u578b\u7684\u6df1\u5165\u5206\u6790\uff0c\u6307\u51fa\u5176\u5728\u7ed3\u6784\u3001\u8bad\u7ec3\u3001\u5047\u8bbe\u548c\u5bf9\u6297\u8106\u5f31\u6027\u65b9\u9762\u7684\u663e\u8457\u9650\u5236\uff0c\u5e76\u603b\u7ed3\u4e86\u6539\u8fdb\u5176\u53ef\u9760\u6027\u7684\u8fdb\u5c55\u3002", "conclusion": "\u5bf9\u6982\u5ff5\u6a21\u578b\u5728\u5404\u4e2a\u65b9\u9762\u7684\u6311\u6218\u53ca\u6539\u8fdb\u63aa\u65bd\u8fdb\u884c\u4e86\u5168\u9762\u603b\u7ed3\uff0c\u4f46\u4ecd\u5b58\u5728\u8bb8\u591a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.04275", "pdf": "https://arxiv.org/pdf/2506.04275", "abs": "https://arxiv.org/abs/2506.04275", "authors": ["Silja Sormunen", "Thilo Gross", "Jari Saram\u00e4ki"], "title": "Self-organization to multicriticality", "categories": ["nlin.AO"], "comment": null, "summary": "Self-organized criticality is a well-established phenomenon, where a system\ndynamically tunes its structure to operate on the verge of a phase transition.\nHere, we show that the dynamics inside the self-organized critical state are\nfundamentally far more versatile than previously recognized, to the extent that\na system can self-organize to a new type of phase transition while staying on\nthe verge of another. In this first demonstration of self-organization to\nmulticriticality, we investigate a model of coupled oscillators on a random\nnetwork, where the network topology evolves in response to the oscillator\ndynamics. We show that the system first self-organizes to the onset of\noscillations, after which it drifts to the onset of pattern formation while\nstill remaining at the onset of oscillations, thus becoming critical in two\ndifferent ways at once. The observed evolution to multicriticality is robust\ngeneric behavior that we expect to be widespread in self-organizing systems.\nOverall, these results offer a unifying framework for studying systems, such as\nthe brain, where multiple phase transitions may be relevant for proper\nfunctioning.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u81ea\u7ec4\u7ec7\u4e34\u754c\u72b6\u6001\u53ef\u8fbe\u5230\u591a\u91cd\u4e34\u754c\u6027\uff0c\u4e14\u8fd9\u79cd\u73b0\u8c61\u5728\u81ea\u7ec4\u7ec7\u7cfb\u7edf\u4e2d\u53ef\u80fd\u5e7f\u6cdb\u5b58\u5728\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u7ec4\u7ec7\u4e34\u754c\u72b6\u6001\u7684\u52a8\u6001\u6027\u53ef\u80fd\u6bd4\u9884\u60f3\u4e2d\u66f4\u4e3a\u591a\u6837\u5316\uff0c\u5e76\u63a2\u8ba8\u7cfb\u7edf\u5982\u4f55\u5728\u4fdd\u6301\u63a5\u8fd1\u67d0\u4e00\u76f8\u53d8\u7684\u540c\u65f6\u81ea\u7ec4\u7ec7\u5230\u53e6\u4e00\u79cd\u76f8\u53d8\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u4e2a\u968f\u673a\u7f51\u7edc\u4e0a\u8026\u5408\u632f\u8361\u5668\u7684\u6a21\u578b\uff0c\u5176\u4e2d\u7f51\u7edc\u62d3\u6251\u6839\u636e\u632f\u8361\u5668\u7684\u52a8\u6001\u6027\u8fdb\u884c\u6f14\u5316\u3002\u81ea\u7ec4\u7ec7\u4ee5\u591a\u91cd\u4e34\u754c\u6027\u73b0\u8c61\u7684\u9996\u6b21\u5c55\u793a\uff0c\u901a\u8fc7\u7cfb\u7edf\u81ea\u7ec4\u7ec7\u5230\u632f\u8361\u5f00\u59cb\u72b6\u6001\uff0c\u968f\u540e\u6f02\u79fb\u5230\u6a21\u5f0f\u5f62\u6210\u7684\u5f00\u59cb\u72b6\u6001\uff0c\u4fdd\u6301\u5728\u632f\u8361\u5f00\u59cb\u72b6\u6001\u7684\u540c\u65f6\u4f53\u73b0\u591a\u91cd\u4e34\u754c\u6027\u3002", "result": "\u7cfb\u7edf\u9996\u5148\u81ea\u7ec4\u7ec7\u5230\u632f\u8361\u5f00\u59cb\u72b6\u6001\uff0c\u968f\u540e\u5728\u4fdd\u6301\u632f\u8361\u5f00\u59cb\u72b6\u6001\u7684\u540c\u65f6\u6f02\u79fb\u5230\u6a21\u5f0f\u5f62\u6210\u5f00\u59cb\u72b6\u6001\uff0c\u4ece\u800c\u5728\u4e24\u4e2a\u4e0d\u540c\u65b9\u9762\u8fbe\u5230\u4e34\u754c\u72b6\u6001\u3002", "conclusion": "\u7ed3\u679c\u63ed\u793a\u4e86\u591a\u91cd\u4e34\u754c\u6027\u662f\u81ea\u7ec4\u7ec7\u7cfb\u7edf\u4e2d\u7684\u4e00\u79cd\u666e\u904d\u884c\u4e3a\uff0c\u5e76\u5efa\u8bae\u8fd9\u79cd\u73b0\u8c61\u53ef\u80fd\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u5177\u5907\u5e7f\u6cdb\u610f\u4e49\uff0c\u7279\u522b\u662f\u5bf9\u9700\u8981\u591a\u79cd\u76f8\u53d8\u7684\u7cfb\u7edf\u5982\u5927\u8111\u7684\u7814\u7a76\u3002"}}
{"id": "2506.04276", "pdf": "https://arxiv.org/pdf/2506.04276", "abs": "https://arxiv.org/abs/2506.04276", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "categories": ["cs.MA", "cs.AI"], "comment": null, "summary": "Natural disasters have caused significant losses to human society, and the\ntimely and efficient acquisition of post-disaster environmental information is\ncrucial for the effective implementation of rescue operations. Due to the\ncomplexity of post-disaster environments, existing sensing technologies face\nchallenges such as weak environmental adaptability, insufficient specialized\nsensing capabilities, and limited practicality of sensing solutions. This paper\nexplores the heterogeneous multi-agent online autonomous collaborative\nscheduling algorithm HoAs-PALN, aimed at achieving efficient collection of\npost-disaster environmental information. HoAs-PALN is realized through adaptive\ndimensionality reduction in the matching process and local Nash equilibrium\ngame, facilitating autonomous collaboration among time-dependent UAVs, workers\nand vehicles to enhance sensing scheduling. (1) In terms of adaptive\ndimensionality reduction during the matching process, HoAs-PALN significantly\nreduces scheduling decision time by transforming a five-dimensional matching\nprocess into two categories of three-dimensional matching processes; (2)\nRegarding the local Nash equilibrium game, HoAs-PALN combines the softmax\nfunction to optimize behavior selection probabilities and introduces a local\nNash equilibrium determination mechanism to ensure scheduling decision\nperformance. Finally, we conducted detailed experiments based on extensive\nreal-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL\nand MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%,\nand 14.03% on average, respectively, while each online scheduling decision\ntakes less than 10 seconds, demonstrating its effectiveness in dynamic\npost-disaster environments.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faHoAs-PALN\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u964d\u7ef4\u548c\u7eb3\u4ec0\u5747\u8861\u535a\u5f08\u4f18\u5316\u8c03\u5ea6\uff0c\u5728\u707e\u540e\u73af\u5883\u4fe1\u606f\u91c7\u96c6\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u5f53\u524d\u611f\u77e5\u6280\u672f\u5728\u707e\u540e\u73af\u5883\u4e2d\u5b58\u5728\u9002\u5e94\u6027\u5dee\u3001\u4e13\u4e1a\u611f\u77e5\u80fd\u529b\u4e0d\u8db3\u548c\u89e3\u51b3\u65b9\u6848\u5b9e\u7528\u6027\u6709\u9650\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u707e\u540e\u73af\u5883\u4fe1\u606f\u91c7\u96c6\u65b9\u5f0f\u3002", "method": "\u91c7\u7528\u5f02\u6784\u591a\u667a\u80fd\u4f53\u5728\u7ebf\u81ea\u4e3b\u534f\u4f5c\u8c03\u5ea6\u7b97\u6cd5HoAs-PALN\uff0c\u901a\u8fc7\u5339\u914d\u8fc7\u7a0b\u4e2d\u7684\u81ea\u9002\u5e94\u964d\u7ef4\u548c\u5c40\u90e8\u7eb3\u4ec0\u5747\u8861\u535a\u5f08\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cHoAs-PALN\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u5e73\u5747\u63d0\u9ad864.12%\u300146.48%\u300116.55%\u548c14.03%\uff0c\u6bcf\u6b21\u5728\u7ebf\u8c03\u5ea6\u51b3\u7b56\u8017\u65f6\u5747\u5c0f\u4e8e10\u79d2\u3002", "conclusion": "HoAs-PALN\u7b97\u6cd5\u5728\u52a8\u6001\u707e\u540e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u5e76\u80fd\u591f\u5feb\u901f\u505a\u51fa\u5728\u7ebf\u8c03\u5ea6\u51b3\u7b56\u3002"}}
{"id": "2506.04364", "pdf": "https://arxiv.org/pdf/2506.04364", "abs": "https://arxiv.org/abs/2506.04364", "authors": ["Zheng-Xin Yong", "Vineel Pratap", "Michael Auli", "Jean Maillard"], "title": "Effects of Speaker Count, Duration, and Accent Diversity on Zero-Shot Accent Robustness in Low-Resource ASR", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted to INTERSPEECH 2025", "summary": "To build an automatic speech recognition (ASR) system that can serve everyone\nin the world, the ASR needs to be robust to a wide range of accents including\nunseen accents. We systematically study how three different variables in\ntraining data -- the number of speakers, the audio duration per each individual\nspeaker, and the diversity of accents -- affect ASR robustness towards unseen\naccents in a low-resource training regime. We observe that for a fixed number\nof ASR training hours, it is more beneficial to increase the number of speakers\n(which means each speaker contributes less) than the number of hours\ncontributed per speaker. We also observe that more speakers enables ASR\nperformance gains from scaling number of hours. Surprisingly, we observe\nminimal benefits to prioritizing speakers with different accents when the\nnumber of speakers is controlled. Our work suggests that practitioners should\nprioritize increasing the speaker count in ASR training data composition for\nnew languages.", "AI": {"tldr": "\u5bf9\u4e8e\u65b0\u8bed\u8a00\u7684ASR\u7cfb\u7edf\u5efa\u8bbe\uff0c\u5e94\u4f18\u5148\u589e\u52a0\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8bf4\u8bdd\u8005\u6570\u91cf\u3002", "motivation": "\u5efa\u7acb\u4e00\u4e2a\u53ef\u4ee5\u670d\u52a1\u5168\u7403\u7528\u6237\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\uff0c\u9700\u8981\u5bf9\u5e7f\u6cdb\u7684\u53e3\u97f3\u5177\u6709\u9c81\u68d2\u6027\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e09\u4e2a\u53d8\u91cf\u5bf9ASR\u9762\u5bf9\u672a\u89c1\u53e3\u97f3\u7684\u9c81\u68d2\u6027\u5f71\u54cd\u3002", "result": "\u589e\u52a0\u8bf4\u8bdd\u8005\u6570\u91cf\u80fd\u591f\u5728\u56fa\u5b9a\u7684\u8bad\u7ec3\u65f6\u957f\u4e0b\u63d0\u5347ASR\u7684\u6027\u80fd\uff0c\u800c\u589e\u52a0\u591a\u79cd\u53e3\u97f3\u7684\u8bf4\u8bdd\u8005\u4f18\u5148\u7ea7\u6548\u679c\u751a\u5fae\u3002", "conclusion": "\u5728ASR\u8bad\u7ec3\u6570\u636e\u4e2d\u589e\u52a0\u8bf4\u8bdd\u8005\u6570\u91cf\u6bd4\u589e\u52a0\u6bcf\u4f4d\u8bf4\u8bdd\u8005\u7684\u8d21\u732e\u65f6\u957f\u66f4\u4e3a\u6709\u5229\u3002"}}
{"id": "2506.04245", "pdf": "https://arxiv.org/pdf/2506.04245", "abs": "https://arxiv.org/abs/2506.04245", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "categories": ["cs.AI", "cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "As the era of autonomous agents making decisions on behalf of users unfolds,\nensuring contextual integrity (CI) -- what is the appropriate information to\nshare while carrying out a certain task -- becomes a central question to the\nfield. We posit that CI demands a form of reasoning where the agent needs to\nreason about the context in which it is operating. To test this, we first\nprompt LLMs to reason explicitly about CI when deciding what information to\ndisclose. We then extend this approach by developing a reinforcement learning\n(RL) framework that further instills in models the reasoning necessary to\nachieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$\nexamples but with diverse contexts and information disclosure norms, we show\nthat our method substantially reduces inappropriate information disclosure\nwhile maintaining task performance across multiple model sizes and families.\nImportantly, improvements transfer from this synthetic dataset to established\nCI benchmarks such as PrivacyLens that has human annotations and evaluates\nprivacy leakage of AI assistants in actions and tool calls.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u793aLLMs\u548c\u4f7f\u7528RL\u6846\u67b6\u6765\u589e\u5f3a\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\uff08CI\uff09\u63a8\u7406\uff0c\u6210\u529f\u51cf\u5c11\u4fe1\u606f\u6cc4\u9732\uff0c\u5e76\u7ef4\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u81ea\u4e3b\u4ee3\u7406\u4e3a\u7528\u6237\u505a\u51fa\u51b3\u7b56\u7684\u65f6\u4ee3\u7684\u5230\u6765\uff0c\u786e\u5b9a\u5728\u6267\u884c\u67d0\u9879\u4efb\u52a1\u8fc7\u7a0b\u4e2d\u5171\u4eab\u4ec0\u4e48\u4fe1\u606f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\uff08CI\uff09\uff0c\u5373\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5171\u4eab\u9002\u5f53\u7684\u4fe1\u606f\u3002", "method": "\u672c\u6587\u9996\u5148\u901a\u8fc7\u63d0\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u51b3\u5b9a\u62ab\u9732\u4fe1\u606f\u65f6\u660e\u786e\u8003\u8651\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\uff08CI\uff09\u3002\u968f\u540e\uff0c\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\uff0c\u8fdb\u4e00\u6b65\u5728\u6a21\u578b\u4e2d\u704c\u8f93\u5b9e\u73b0CI\u6240\u9700\u7684\u63a8\u7406\u80fd\u529b\u3002\u7814\u7a76\u4f7f\u7528\u4e00\u4e2a\u5408\u6210\u7684\u81ea\u52a8\u521b\u5efa\u7684\u6570\u636e\u96c6\u6765\u6d4b\u8bd5\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u51cf\u5c11\u4e0d\u5f53\u4fe1\u606f\u62ab\u9732\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002\u6539\u8fdb\u4e5f\u80fd\u591f\u4ece\u5408\u6210\u6570\u636e\u96c6\u6210\u529f\u8f6c\u79fb\u81f3\u50cfPrivacyLens\u7b49\u6709\u4eba\u5de5\u6807\u6ce8\u7684CI\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\uff08CI\uff09\u5728\u81ea\u4e3b\u4ee3\u7406\u4fe1\u606f\u62ab\u9732\u4e2d\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u8ba9\u6a21\u578b\u8003\u8651\u4e0a\u4e0b\u6587\uff0c\u7814\u7a76\u6210\u529f\u51cf\u5c11\u4e86\u4fe1\u606f\u6cc4\u9732\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002"}}
{"id": "2506.04241", "pdf": "https://arxiv.org/pdf/2506.04241", "abs": "https://arxiv.org/abs/2506.04241", "authors": ["Konstantin Kirchheim", "Frank Ortmeier"], "title": "Improving Out-of-Distribution Detection with Markov Logic Networks", "categories": ["cs.LG"], "comment": null, "summary": "Out-of-distribution (OOD) detection is essential for ensuring the reliability\nof deep learning models operating in open-world scenarios. Current OOD\ndetectors mainly rely on statistical models to identify unusual patterns in the\nlatent representations of a deep neural network. This work proposes to augment\nexisting OOD detectors with probabilistic reasoning, utilizing Markov logic\nnetworks (MLNs). MLNs connect first-order logic with probabilistic reasoning to\nassign probabilities to inputs based on weighted logical constraints defined\nover human-understandable concepts, which offers improved explainability.\nThrough extensive experiments on multiple datasets, we demonstrate that MLNs\ncan significantly enhance the performance of a wide range of existing OOD\ndetectors while maintaining computational efficiency. Furthermore, we introduce\na simple algorithm for learning logical constraints for OOD detection from a\ndataset and showcase its effectiveness.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u9a6c\u5c14\u53ef\u592b\u903b\u8f91\u7f51\u7edc\uff0c\u52a0\u5f3a\u4e86\u73b0\u6709\u7684OOD\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u548c\u89e3\u91ca\u6027\uff0c\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u63d0\u51fa\u4e00\u79cd\u5b66\u4e60\u7b97\u6cd5\u6765\u4f18\u5316\u903b\u8f91\u7ea6\u675f\u3002", "motivation": "\u786e\u4fdd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u73b0\u6709\u7684OOD\u68c0\u6d4b\u5668\u4e3b\u8981\u4f9d\u8d56\u4e8e\u7edf\u8ba1\u6a21\u578b\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u5177\u89e3\u91ca\u6027\u548c\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u672c\u7814\u7a76\u5c06\u73b0\u6709\u7684OOD\u68c0\u6d4b\u5668\u4e0e\u9a6c\u5c14\u53ef\u592b\u903b\u8f91\u7f51\u7edc\uff08MLNs\uff09\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u5728\u4eba\u7684\u53ef\u7406\u89e3\u6982\u5ff5\u4e0a\u5b9a\u4e49\u52a0\u6743\u903b\u8f91\u7ea6\u675f\u6765\u4e3a\u8f93\u5165\u8d4b\u4e88\u6982\u7387\uff0c\u4ece\u800c\u589e\u5f3aOOD\u68c0\u6d4b\u7684\u6548\u679c\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e00\u79cd\u4ece\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u903b\u8f91\u7ea6\u675f\u7684\u7b97\u6cd5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMLNs\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u73b0\u6709\u591a\u79cdOOD\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u9ad8\u6548\u6027\u3002\u6b64\u5916\uff0c\u5b66\u4e60\u903b\u8f91\u7ea6\u675f\u7684\u7b97\u6cd5\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6982\u7387\u63a8\u7406\u548cMLNs\u5f15\u5165OOD\u68c0\u6d4b\uff0c\u80fd\u591f\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u589e\u5f3a\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.04701", "pdf": "https://arxiv.org/pdf/2506.04701", "abs": "https://arxiv.org/abs/2506.04701", "authors": ["Meiru Jiang", "Wei Su", "Guojian Ren", "Yongguang Yu"], "title": "Memory-Driven Bounded Confidence Opinion Dynamics: A Hegselmann-Krause Model Based on Fractional-Order Methods", "categories": ["physics.soc-ph", "cs.MA", "cs.SI", "nlin.AO"], "comment": null, "summary": "Memory effects play a crucial role in social interactions and decision-making\nprocesses. This paper proposes a novel fractional-order bounded confidence\nopinion dynamics model to characterize the memory effects in system states.\nBuilding upon the Hegselmann-Krause framework and fractional-order difference,\na comprehensive model is established that captures the persistent influence of\nhistorical information. Through rigorous theoretical analysis, the fundamental\nproperties including convergence and consensus is investigated. The results\ndemonstrate that the proposed model not only maintains favorable convergence\nand consensus characteristics compared to classical opinion dynamics, but also\naddresses limitations such as the monotonicity of bounded opinions. This\nenables a more realistic representation of opinion evolution in real-world\nscenarios. The findings of this study provide new insights and methodological\napproaches for understanding opinion formation and evolution, offering both\ntheoretical significance and practical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u6570\u9636\u6a21\u578b\uff0c\u6539\u8fdb\u4e86\u610f\u89c1\u52a8\u6001\u7684\u6536\u655b\u6027\u548c\u4e00\u81f4\u6027\uff0c\u66f4\u8d34\u8fd1\u771f\u5b9e\u4e16\u754c\u7684\u610f\u89c1\u6f14\u53d8\u3002", "motivation": "\u7814\u7a76\u8bb0\u5fc6\u6548\u5e94\u5728\u793e\u4f1a\u4e92\u52a8\u548c\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u66f4\u771f\u5b9e\u7684\u610f\u89c1\u52a8\u6001\u6a21\u578b\u3002", "method": "\u57fa\u4e8eHegselmann-Krause\u6846\u67b6\u548c\u5206\u6570\u9636\u5dee\u5206\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6a21\u578b\u6765\u63cf\u8ff0\u7cfb\u7edf\u72b6\u6001\u4e2d\u7684\u8bb0\u5fc6\u6548\u5e94\u3002", "result": "\u6a21\u578b\u663e\u793a\u51fa\u6709\u5229\u7684\u6536\u655b\u6027\u548c\u4e00\u81f4\u6027\u7279\u6027\uff0c\u89e3\u51b3\u4e86\u7ecf\u5178\u610f\u89c1\u52a8\u6001\u4e2d\u7684\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u5982\u6709\u754c\u610f\u89c1\u7684\u5355\u8c03\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u6570\u9636\u6709\u754c\u4fe1\u4efb\u5ea6\u610f\u89c1\u52a8\u6001\u6a21\u578b\uff0c\u53ef\u4ee5\u66f4\u771f\u5b9e\u5730\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u4e2d\u610f\u89c1\u7684\u6f14\u53d8\u3002"}}
{"id": "2506.04565", "pdf": "https://arxiv.org/pdf/2506.04565", "abs": "https://arxiv.org/abs/2506.04565", "authors": ["Jiayi Chen", "Junyi Ye", "Guiling Wang"], "title": "From Standalone LLMs to Integrated Intelligence: A Survey of Compound Al Systems", "categories": ["cs.MA", "cs.CL"], "comment": null, "summary": "Compound Al Systems (CAIS) is an emerging paradigm that integrates large\nlanguage models (LLMs) with external components, such as retrievers, agents,\ntools, and orchestrators, to overcome the limitations of standalone models in\ntasks requiring memory, reasoning, real-time grounding, and multimodal\nunderstanding. These systems enable more capable and context-aware behaviors by\ncomposing multiple specialized modules into cohesive workflows. Despite growing\nadoption in both academia and industry, the CAIS landscape remains fragmented,\nlacking a unified framework for analysis, taxonomy, and evaluation. In this\nsurvey, we define the concept of CAIS, propose a multi-dimensional taxonomy\nbased on component roles and orchestration strategies, and analyze four\nfoundational paradigms: Retrieval-Augmented Generation (RAG), LLM Agents,\nMultimodal LLMs (MLLMs), and orchestration-centric architectures. We review\nrepresentative systems, compare design trade-offs, and summarize evaluation\nmethodologies across these paradigms. Finally, we identify key\nchallenges-including scalability, interoperability, benchmarking, and\ncoordination-and outline promising directions for future research. This survey\naims to provide researchers and practitioners with a comprehensive foundation\nfor understanding, developing, and advancing the next generation of\nsystem-level artificial intelligence.", "AI": {"tldr": "\u6b64\u8c03\u67e5\u6982\u8ff0\u4e86\u590d\u5408AI\u7cfb\u7edf\uff08CAIS\uff09\uff0c\u63d0\u51fa\u4e86\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u51e0\u4e2a\u57fa\u7840\u8303\u5f0f\uff0c\u4ee5\u5e2e\u52a9\u7406\u89e3\u548c\u53d1\u5c55\u7cfb\u7edf\u7ea7AI\u3002", "motivation": "\u5e94\u5bf9\u72ec\u7acb\u6a21\u578b\u5728\u9700\u8981\u8bb0\u5fc6\u3001\u63a8\u7406\u3001\u5b9e\u65f6\u843d\u5730\u548c\u591a\u6a21\u6001\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u6574\u5408LLMs\u4e0e\u5916\u90e8\u7ec4\u4ef6\u5f62\u6210\u590d\u5408AI\u7cfb\u7edf\u3002", "method": "\u5b9a\u4e49CAIS\u6982\u5ff5\uff0c\u63d0\u51fa\u57fa\u4e8e\u7ec4\u4ef6\u89d2\u8272\u548c\u7f16\u6392\u7b56\u7565\u7684\u591a\u7ef4\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u56db\u4e2a\u57fa\u7840\u8303\u5f0f\uff0c\u5e76\u56de\u987e\u4ee3\u8868\u6027\u7cfb\u7edf\uff0c\u6bd4\u8f83\u8bbe\u8ba1\u6743\u8861\uff0c\u603b\u7ed3\u8bc4\u4ef7\u65b9\u6cd5\u3002", "result": "\u5b9a\u4f4d\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u53ef\u6269\u5c55\u6027\u3001\u4e92\u64cd\u4f5c\u6027\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u534f\u8c03\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u7684\u6709\u524d\u666f\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7ef4\u5206\u7c7b\u6cd5\uff0c\u5e76\u5206\u6790\u4e86\u56db\u4e2a\u57fa\u672c\u8303\u5f0f\uff0c\u4ee5\u5e2e\u52a9\u7406\u89e3\u548c\u53d1\u5c55\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u7ea7\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2506.04373", "pdf": "https://arxiv.org/pdf/2506.04373", "abs": "https://arxiv.org/abs/2506.04373", "authors": ["Matthieu Tehenan", "Vikram Natarajan", "Jonathan Michala", "Milton Lin", "Juri Opitz"], "title": "Mechanistic Decomposition of Sentence Representations", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Sentence embeddings are central to modern NLP and AI systems, yet little is\nknown about their internal structure. While we can compare these embeddings\nusing measures such as cosine similarity, the contributing features are not\nhuman-interpretable, and the content of an embedding seems untraceable, as it\nis masked by complex neural transformations and a final pooling operation that\ncombines individual token embeddings. To alleviate this issue, we propose a new\nmethod to mechanistically decompose sentence embeddings into interpretable\ncomponents, by using dictionary learning on token-level representations. We\nanalyze how pooling compresses these features into sentence representations,\nand assess the latent features that reside in a sentence embedding. This\nbridges token-level mechanistic interpretability with sentence-level analysis,\nmaking for more transparent and controllable representations. In our studies,\nwe obtain several interesting insights into the inner workings of sentence\nembedding spaces, for instance, that many semantic and syntactic aspects are\nlinearly encoded in the embeddings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u5206\u89e3\u53e5\u5b50\u5d4c\u5165\u4e3a\u53ef\u89e3\u91ca\u7ec4\u4ef6\uff0c\u901a\u8fc7\u5b57\u5178\u5b66\u4e60\u8fdb\u884c\u5206\u6790\uff0c\u63ed\u793a\u51fa\u5d4c\u5165\u4e2d\u8bb8\u591a\u7279\u5f81\u662f\u7ebf\u6027\u7f16\u7801\u7684\uff0c\u4e3a\u5d4c\u5165\u63d0\u4f9b\u66f4\u900f\u660e\u548c\u53ef\u63a7\u7684\u8868\u793a\u3002", "motivation": "\u5f53\u524dNLP\u548cAI\u7cfb\u7edf\u4e2d\uff0c\u53e5\u5b50\u5d4c\u5165\u662f\u6838\u5fc3\uff0c\u4f46\u5bf9\u5176\u5185\u90e8\u7ed3\u6784\u8ba4\u8bc6\u8f83\u5c11\uff0c\u4e14\u4e0d\u6613\u89e3\u91ca\u3002\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u5c06\u53e5\u5b50\u5d4c\u5165\u5206\u89e3\u4e3a\u53ef\u89e3\u91ca\u7ec4\u4ef6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u8bcd\u7ea7\u522b\u8868\u793a\u4f7f\u7528\u5b57\u5178\u5b66\u4e60\uff0c\u5b9a\u4e49\u53e5\u5b50\u5d4c\u5165\u7684\u53ef\u89e3\u91ca\u7ec4\u4ef6\uff0c\u5e76\u5206\u6790\u6c60\u5316\u8fc7\u7a0b\u5bf9\u7279\u5f81\u7684\u538b\u7f29\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u53e5\u5b50\u5d4c\u5165\u4e2d\u7684\u8bb8\u591a\u8bed\u4e49\u548c\u8bed\u6cd5\u7279\u5f81\u662f\u901a\u8fc7\u7ebf\u6027\u7f16\u7801\u7684\uff0c\u63d0\u5347\u4e86\u5bf9\u5d4c\u5165\u7a7a\u95f4\u7684\u900f\u660e\u5ea6\u548c\u53ef\u63a7\u6027\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u5b57\u5178\u5b66\u4e60\u548c\u5bf9token\u7ea7\u522b\u8868\u793a\u5206\u6790\uff0c\u53d1\u73b0\u8bb8\u591a\u8bed\u4e49\u548c\u53e5\u6cd5\u65b9\u9762\u901a\u8fc7\u7ebf\u6027\u65b9\u5f0f\u7f16\u7801\u5728\u5d4c\u5165\u4e2d\uff0c\u63d0\u5347\u4e86\u5bf9\u53e5\u5b50\u5d4c\u5165\u7a7a\u95f4\u7684\u7406\u89e3\u5ea6\u3002"}}
{"id": "2506.04251", "pdf": "https://arxiv.org/pdf/2506.04251", "abs": "https://arxiv.org/abs/2506.04251", "authors": ["Zhengyang Li"], "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "categories": ["cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "This paper introduces LLM-MARL, a unified framework that incorporates large\nlanguage models (LLMs) into multi-agent reinforcement learning (MARL) to\nenhance coordination, communication, and generalization in simulated game\nenvironments. The framework features three modular components of Coordinator,\nCommunicator, and Memory, which dynamically generate subgoals, facilitate\nsymbolic inter-agent messaging, and support episodic recall. Training combines\nPPO with a language-conditioned loss and LLM query gating. LLM-MARL is\nevaluated in Google Research Football, MAgent Battle, and StarCraft II. Results\nshow consistent improvements over MAPPO and QMIX in win rate, coordination\nscore, and zero-shot generalization. Ablation studies demonstrate that subgoal\ngeneration and language-based messaging each contribute significantly to\nperformance gains. Qualitative analysis reveals emergent behaviors such as role\nspecialization and communication-driven tactics. By bridging language modeling\nand policy learning, this work contributes to the design of intelligent,\ncooperative agents in interactive simulations. It offers a path forward for\nleveraging LLMs in multi-agent systems used for training, games, and human-AI\ncollaboration.", "AI": {"tldr": "\u5f15\u5165LLM-MARL\u6846\u67b6\uff0c\u901a\u8fc7\u4e0e\u6e38\u620f\u73af\u5883\u7684\u96c6\u6210\uff0c\u4f7f\u667a\u80fd\u4f53\u5728\u534f\u8c03\u548c\u901a\u4fe1\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u589e\u5f3a\u6a21\u62df\u6e38\u620f\u73af\u5883\u4e2d\u591a\u667a\u80fd\u4f53\u7684\u534f\u8c03\u3001\u901a\u4fe1\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u534f\u8c03\u5668\u3001\u901a\u8baf\u5668\u548c\u8bb0\u5fc6\uff0c\u7ed3\u5408PPO\u8bad\u7ec3\u3001\u8bed\u8a00\u6761\u4ef6\u635f\u5931\u548cLLM\u67e5\u8be2\u95e8\u63a7\u8bc4\u4f30\u3002", "result": "\u5728Google Research Football\u3001MAgent Battle\u548cStarCraft II\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5404\u9879\u6307\u6807\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u5b50\u76ee\u6807\u751f\u6210\u548c\u57fa\u4e8e\u8bed\u8a00\u7684\u6d88\u606f\u4f20\u9012\u5bf9\u6027\u80fd\u63d0\u5347\u8d21\u732e\u663e\u8457\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f15\u5165\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\uff0c\u7cfb\u7edf\u8868\u73b0\u51fa\u5728\u80dc\u7387\u3001\u534f\u8c03\u5206\u6570\u548c\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.04243", "pdf": "https://arxiv.org/pdf/2506.04243", "abs": "https://arxiv.org/abs/2506.04243", "authors": ["Warayut Dokduea", "Weerachart Tangchirapat", "Sompote Youwai"], "title": "Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a novel Triple Attention Transformer Architecture for\npredicting time-dependent concrete creep, addressing fundamental limitations in\ncurrent approaches that treat time as merely an input parameter rather than\nmodeling the sequential nature of deformation development. By transforming\nconcrete creep prediction into an autoregressive sequence modeling task similar\nto language processing, our architecture leverages the transformer's\nself-attention mechanisms to capture long-range dependencies in historical\ncreep patterns. The model implements a triple-stream attention framework\nincorporating temporal attention for sequential progression, feature attention\nfor material property interactions, and batch attention for inter-sample\nrelationships. Evaluated on experimental datasets with standardized daily\nmeasurements spanning 160 days, the architecture achieves exceptional\nperformance with mean absolute percentage error of 1.63% and R2 values of 0.999\nacross all datasets, substantially outperforming traditional empirical models\nand existing machine learning approaches. Ablation studies confirm the critical\nrole of attention mechanisms, with attention pooling contributing most\nsignificantly to model performance. SHAP analysis reveals Young's modulus as\nthe primary predictive feature, followed by density and compressive strength,\nproviding interpretability essential for engineering applications. A deployed\nweb-based interface facilitates practical implementation, enabling real-time\npredictions using standard laboratory parameters. This work establishes the\nviability of applying transformer architectures to materials science problems,\ndemonstrating the potential for data-driven approaches to revolutionize\nstructural behavior prediction and engineering design practices.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u91cd\u6ce8\u610f\u529b\u53d8\u538b\u5668\u67b6\u6784\uff0c\u4ee5\u4f18\u5f02\u8868\u73b0\u9884\u6d4b\u6df7\u51dd\u571f\u8815\u53d8\uff0c\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u53d8\u538b\u5668\u67b6\u6784\u5728\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u5c06\u65f6\u95f4\u4ec5\u4ec5\u89c6\u4e3a\u8f93\u5165\u53c2\u6570\uff0c\u6ca1\u6709\u5efa\u6a21\u53d8\u5f62\u53d1\u5c55\u7684\u987a\u5e8f\u6027\u3002\u672c\u6587\u901a\u8fc7\u65b0\u7684\u53d8\u538b\u5668\u67b6\u6784\u89e3\u51b3\u8fd9\u4e00\u6839\u672c\u9650\u5236\u3002", "method": "\u672c\u6587\u5c06\u6df7\u51dd\u571f\u8815\u53d8\u9884\u6d4b\u8f6c\u5316\u4e3a\u81ea\u56de\u5f52\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\uff0c\u7c7b\u4f3c\u4e8e\u8bed\u8a00\u5904\u7406\uff0c\u5229\u7528\u53d8\u538b\u5668\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u5386\u53f2\u8815\u53d8\u6a21\u5f0f\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u3002\u6a21\u578b\u5b9e\u65bd\u4e86\u4e09\u91cd\u6d41\u6ce8\u610f\u529b\u6846\u67b6\uff0c\u5305\u62ec\u65f6\u95f4\u6ce8\u610f\u529b\u3001\u7279\u5f81\u6ce8\u610f\u529b\u548c\u6279\u6ce8\u610f\u529b\u3002", "result": "\u5728\u5305\u542b160\u5929\u6807\u51c6\u5316\u65e5\u6d4b\u91cf\u7684\u5b9e\u9a8c\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5b9e\u73b0\u4e861.63%\u7684\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u548c\u6240\u6709\u6570\u636e\u96c6\u4e0a\u7684R^2\u503c\u4e3a0.999\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7ecf\u9a8c\u6a21\u578b\u548c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002\u6ce8\u610f\u529b\u673a\u5236\u7684\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u5176\u5173\u952e\u4f5c\u7528\uff0c\u6ce8\u610f\u529b\u6c60\u5316\u5bf9\u6a21\u578b\u6027\u80fd\u8d21\u732e\u6700\u5927\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e09\u91cd\u6ce8\u610f\u529b\u53d8\u538b\u5668\u67b6\u6784\u5728\u9884\u6d4b\u65f6\u95f4\u4f9d\u8d56\u578b\u6df7\u51dd\u571f\u8815\u53d8\u65f6\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4f20\u7edf\u7ecf\u9a8c\u6a21\u578b\u548c\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e3a\u6750\u6599\u79d1\u5b66\u95ee\u9898\u5e94\u7528\u53d8\u538b\u5668\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\uff0c\u63ed\u793a\u4e86\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u9884\u6d4b\u7ed3\u6784\u884c\u4e3a\u548c\u5de5\u7a0b\u8bbe\u8ba1\u5b9e\u8df5\u4e2d\u7684\u9769\u547d\u6f5c\u529b\u3002"}}
{"id": "2506.05178", "pdf": "https://arxiv.org/pdf/2506.05178", "abs": "https://arxiv.org/abs/2506.05178", "authors": ["Joshua Hess", "Quaid Morris"], "title": "Associative Memory and Generative Diffusion in the Zero-noise Limit", "categories": ["cs.LG", "cond-mat.dis-nn", "math.DS", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "Connections between generative diffusion and continuous-state associative\nmemory models are studied. Morse-Smale dynamical systems are emphasized as\nuniversal approximators of gradient-based associative memory models and\ndiffusion models as white-noise perturbed systems thereof. Universal properties\nof associative memory that follow from this description are described and used\nto characterize a generic transition from generation to memory as noise levels\ndiminish. Structural stability inherited by Morse-Smale flows is shown to imply\na notion of stability for diffusions at vanishing noise levels. Applied to one-\nand two-parameter families of gradients, this indicates stability at all but\nisolated points of associative memory learning landscapes and the learning and\ngeneration landscapes of diffusion models with gradient drift in the zero-noise\nlimit, at which small sets of generic bifurcations characterize qualitative\ntransitions between stable systems. Examples illustrating the characterization\nof these landscapes by sequences of these bifurcations are given, along with\nstructural stability criterion for classic and modern Hopfield networks\n(equivalently, the attention mechanism).", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5173\u8054\u8bb0\u5fc6\u548c\u751f\u6210\u6269\u6563\u6a21\u578b\u95f4\u7684\u5173\u7cfb\uff0c\u5f3a\u8c03Morse-Smale\u7cfb\u7edf\u5728\u566a\u58f0\u6d88\u5931\u65f6\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u5206\u5c94\u5206\u6790\u63cf\u8ff0\u666f\u89c2\u8f6c\u6362\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u6269\u6563\u6a21\u578b\u4e0e\u8fde\u7eed\u72b6\u6001\u5173\u8054\u8bb0\u5fc6\u6a21\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63ed\u793a\u57fa\u7840\u52a8\u529b\u7cfb\u7edf\u7684\u666e\u904d\u6027\u8d28\u3002", "method": "\u901a\u8fc7\u7814\u7a76Morse-Smale\u52a8\u529b\u7cfb\u7edf\u4f5c\u4e3a\u68af\u5ea6\u5173\u8054\u8bb0\u5fc6\u6a21\u578b\u548c\u6269\u6563\u6a21\u578b\uff08\u5e26\u767d\u566a\u58f0\u6270\u52a8\u7684\u7cfb\u7edf\uff09\u7684\u552f\u8c61\u8fd1\u4f3c\u3002", "result": "\u786e\u5b9a\u4e86\u5173\u8054\u8bb0\u5fc6\u5728\u566a\u58f0\u6c34\u5e73\u4e0b\u964d\u65f6\u4ece\u751f\u6210\u8fc7\u6e21\u5230\u8bb0\u5fc6\u7684\u901a\u7528\u6027\u3002\u8fd9\u8fd8\u63ed\u793a\u4e86\u5728\u96f6\u566a\u58f0\u6781\u9650\u4e0b\u7684\u7a33\u5b9a\u6027\uff0c\u901a\u8fc7\u5c0f\u578b\u6cdb\u5316\u5206\u6b67\u7684\u96c6\u5408\u6765\u8868\u5f81\u5728\u8fd9\u4e9b\u6781\u9650\u4e0b\u7684\u7a33\u5b9a\u7cfb\u7edf\u4e4b\u95f4\u7684\u5b9a\u6027\u8f6c\u6362\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86Morse-Smale\u6d41\u7684\u7ed3\u6784\u7a33\u5b9a\u6027\u5728\u566a\u58f0\u6d88\u5931\u6781\u9650\u4e0b\u8574\u542b\u7684\u6269\u6563\u7a33\u5b9a\u6027\u6982\u5ff5\u3002\u901a\u8fc7\u4f8b\u5b50\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4e00\u7cfb\u5217\u5206\u5c94\u6765\u8868\u5f81\u8fd9\u4e9b\u666f\u89c2\uff0c\u5e76\u4e3a\u7ecf\u5178\u548c\u73b0\u4ee3Hopfield\u7f51\u7edc\u63d0\u4f9b\u7ed3\u6784\u7a33\u5b9a\u6027\u6807\u51c6\u3002"}}
{"id": "2506.05236", "pdf": "https://arxiv.org/pdf/2506.05236", "abs": "https://arxiv.org/abs/2506.05236", "authors": ["Maxime Toquebiau", "Jae-Yun Jun", "Fa\u00efz Benamar", "Nicolas Bredeche"], "title": "Towards Language-Augmented Multi-Agent Deep Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "Communication is a fundamental aspect of coordinated behavior in multi-agent\nreinforcement learning. Yet, most prior works in this field have focused on\nemergent communication protocols developed from scratch, often resulting in\ninefficient or non-interpretable systems. Inspired by the role of language in\nnatural intelligence, we investigate how grounding agents in a human-defined\nlanguage can improve learning and coordination of multiple embodied agents. We\npropose a framework in which agents are trained not only to act but also to\nproduce and interpret natural language descriptions of their observations. This\nlanguage-augmented learning serves a dual role: enabling explicit communication\nbetween agents and guiding representation learning. We demonstrate that agents\ntrained with our method outperform traditional emergent communication baselines\nacross various tasks. Our analysis reveals that language grounding leads to\nmore informative internal representations, better generalization to new\npartners, and improved capability for human-agent interaction. These findings\ndemonstrate the effectiveness of integrating structured language into\nmulti-agent learning and open avenues for more interpretable and capable\nmulti-agent systems.", "AI": {"tldr": "\u7814\u7a76\u5c06\u4eba\u7c7b\u8bed\u8a00\u6574\u5408\u5230\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u4e2d\uff0c\u8bc1\u660e\u8bed\u8a00\u589e\u5f3a\u5b66\u4e60\u53ef\u4ee5\u63d0\u9ad8\u4ee3\u7406\u7684\u8868\u73b0\u548c\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8\u901a\u8fc7\u5c06\u4ee3\u7406\u4e0e\u4eba\u7c7b\u5b9a\u4e49\u7684\u8bed\u8a00\u57fa\u7840\u76f8\u7ed3\u5408\u6765\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7684\u5b66\u4e60\u548c\u534f\u8c03\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6\uff0c\u4f7f\u4ee3\u7406\u4e0d\u4ec5\u5b66\u4e60\u884c\u52a8\uff0c\u8fd8\u80fd\u591f\u4ea7\u751f\u548c\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\uff0c\u4ee5\u6539\u8fdb\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u548c\u5b66\u4e60\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u81ea\u4e3b\u5f62\u6210\u901a\u4fe1\u57fa\u7ebf\u76f8\u6bd4\uff0c\u4f7f\u7528\u8bed\u8a00\u589e\u5f3a\u5b66\u4e60\u65b9\u6cd5\u7684\u4ee3\u7406\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8bed\u8a00\u589e\u5f3a\u5b66\u4e60\u53ef\u4ee5\u6709\u6548\u5730\u6539\u5584\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u6027\u80fd\u548c\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.04381", "pdf": "https://arxiv.org/pdf/2506.04381", "abs": "https://arxiv.org/abs/2506.04381", "authors": ["Neeraj Agrawal", "Saurabh Kumar", "Priyanka Bhatt", "Tanishka Agarwal"], "title": "Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy", "categories": ["cs.CL", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2203.03825 by other authors", "summary": "Hierarchical Text Classification (HTC) has recently gained traction given the\nability to handle complex label hierarchy. This has found applications in\ndomains like E- commerce, customer care and medicine industry among other\nreal-world applications. Existing HTC models either encode label hierarchy\nseparately and mix it with text encoding or guide the label hierarchy structure\nin the text encoder. Both approaches capture different characteristics of label\nhierarchy and are complementary to each other. In this paper, we propose a\nHierarchical Text Classification using Contrastive Learning Informed Path\nguided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation\nand text informed path guided hierarchy representation using contrastive\nlearning. During the training of HTC-CLIP, we learn two different sets of class\nprobabilities distributions and during inference, we use the pooled output of\nboth probabilities for each class to get the best of both representations. Our\nresults show that the two previous approaches can be effectively combined into\none architecture to achieve improved performance. Tests on two public benchmark\ndatasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP\nover the existing state-of-the-art models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c42\u6b21\u6587\u672c\u5206\u7c7b\u6a21\u578bHTC-CLIP\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u7ed3\u5408\u4e24\u79cd\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\uff0c\u63d0\u9ad8\u4e86Macro F1\u8bc4\u5206\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u7684\u5c42\u6b21\u6587\u672c\u5206\u7c7b\u6a21\u578b\u5404\u81ea\u5177\u6709\u4e0d\u540c\u7279\u5f81\uff0c\u901a\u8fc7\u540c\u65f6\u7ed3\u5408\u5b83\u4eec\u7684\u4f18\u52bf\u53ef\u4ee5\u589e\u5f3a\u5206\u7c7b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u6765\u5b66\u4e60\u5177\u6709\u5c42\u6b21\u611f\u77e5\u7684\u6587\u672c\u8868\u793a\u548c\u6587\u672c\u5f15\u5bfc\u8def\u5f84\u6307\u5bfc\u7684\u5c42\u6b21\u8868\u793a\uff0c\u5e76\u5c06\u4e24\u8005\u7684\u6982\u7387\u5206\u5e03\u5408\u5e76\u4f7f\u7528\u3002", "result": "HTC-CLIP\u6a21\u578b\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86Macro F1\u8bc4\u5206\uff0c\u8f83\u73b0\u6709\u6700\u4f18\u6a21\u578b\u63d0\u5347\u4e860.99 - 2.37%\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u73b0\u6709\u7684\u5c42\u6b21\u6587\u672c\u5206\u7c7b\u65b9\u6cd5\uff0cHTC-CLIP\u5728\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\u5176\u5728Macro F1\u8bc4\u5206\u65b9\u9762\u63d0\u9ad8\u4e860.99 - 2.37%\u3002"}}
{"id": "2506.04252", "pdf": "https://arxiv.org/pdf/2506.04252", "abs": "https://arxiv.org/abs/2506.04252", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H. Z. HO"], "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) hold promise for sustainable manufacturing, but\noften hallucinate industrial codes and emission factors, undermining regulatory\nand investment decisions. We introduce CircuGraphRAG, a retrieval-augmented\ngeneration (RAG) framework that grounds LLMs outputs in a domain-specific\nknowledge graph for the circular economy. This graph connects 117,380\nindustrial and waste entities with classification codes and GWP100 emission\ndata, enabling structured multi-hop reasoning. Natural language queries are\ntranslated into SPARQL and verified subgraphs are retrieved to ensure accuracy\nand traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG\nachieves superior performance in single-hop and multi-hop question answering,\nwith ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also\nimproves efficiency, halving the response time and reducing token usage by 16%\nin representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready\nsupport for circular economy planning, advancing reliable, low-carbon resource\ndecision making.", "AI": {"tldr": "CircuGraphRAG\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u56fe\u89e3\u51b3LLM\u5e7b\u89c9\u95ee\u9898\uff0c\u6539\u5584\u5faa\u73af\u7ecf\u6d4e\u51b3\u7b56\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u53ef\u6301\u7eed\u5236\u9020\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5de5\u4e1a\u4ee3\u7801\u548c\u6392\u653e\u56e0\u5b50\u76f8\u5173\u7684\u5e7b\u89c9\uff0c\u4fdd\u8bc1\u51b3\u7b56\u7684\u51c6\u786e\u6027\u3002", "method": "\u5f15\u5165\u4e86CircuGraphRAG\u8fd9\u4e00\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5c06\u9886\u57df\u77e5\u8bc6\u56fe\u878d\u5165LLM\u4ee5\u8fdb\u884c\u7ed3\u6784\u5316\u591a\u8df3\u63a8\u7406\u3002", "result": "\u76f8\u6bd4\u5355\u72ec\u7684LLMs\u548c\u7b80\u5355RAG\uff0cCircuGraphRAG\u5728\u5355\u8df3\u548c\u591a\u8df3\u95ee\u7b54\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cROUGE-L F1\u5f97\u5206\u53ef\u8fbe1.0\uff0c\u54cd\u5e94\u65f6\u95f4\u51cf\u534a\uff0c\u4ee4\u724c\u4f7f\u7528\u51cf\u5c1116%\u3002", "conclusion": "CircuGraphRAG\u4e3a\u5faa\u73af\u7ecf\u6d4e\u89c4\u5212\u63d0\u4f9b\u4e86\u4e8b\u5b9e\u6838\u67e5\u548c\u7b26\u5408\u76d1\u7ba1\u8981\u6c42\u7684\u652f\u6301\uff0c\u63d0\u5347\u4e86\u4f4e\u78b3\u8d44\u6e90\u51b3\u7b56\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.04250", "pdf": "https://arxiv.org/pdf/2506.04250", "abs": "https://arxiv.org/abs/2506.04250", "authors": ["Shaona Ghosh", "Amrita Bhattacharjee", "Yftah Ziser", "Christopher Parisien"], "title": "SafeSteer: Interpretable Safety Steering with Refusal-Evasion in LLMs", "categories": ["cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2410.01174", "summary": "Fine-tuning large language models (LLMs) to adapt to evolving safety policies\nis costly and impractical. Mechanistic interpretability enables inference-time\ncontrol through latent activation steering, yet its potential for precise,\ncustomizable safety adjustments remains largely untapped. This paper\ninvestigates an approach called SafeSteer for guiding the outputs of LLMs by:\n(i) leveraging category-specific steering vectors for more precise control,\n(ii) employing a simple, gradient-free unsupervised method to enhance safety\nsteering while preserving text quality, topic relevance, and without explicit\nrefusal, and (iii) accomplishing this without a hard requirement of contrastive\npairwise safe data. We also highlight that our method, being simple and\neffective, aligns with recent studies suggesting that simple techniques often\noutperform more complex ones in activation steering. We showcase the\neffectiveness of our approach across various LLMs, datasets, and risk\ncategories, demonstrating its ability to provide precise control, prevent\nblanket refusals, and guide models toward generating safe content while\nmaintaining topic relevance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSafeSteer\u65b9\u6cd5\uff0c\u901a\u8fc7\u7c7b\u522b\u7279\u5b9a\u7684\u8f6c\u5411\u5411\u91cf\u5b9e\u73b0LLM\u8f93\u51fa\u7684\u7cbe\u786e\u5b89\u5168\u63a7\u5236\uff0c\u91c7\u7528\u7b80\u5355\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u907f\u514d\u5185\u5bb9\u62d2\u7edd\uff0c\u4e14\u65e0\u9700\u5bf9\u6bd4\u5b89\u5168\u6570\u636e\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u98ce\u9669\u7c7b\u522b\u4e2d\u663e\u793a\u51fa\u6709\u6548\u6027\u3002", "motivation": "\u9488\u5bf9\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u5b89\u5168\u7b56\u7565\u65e2\u6602\u8d35\u53c8\u4e0d\u5207\u5b9e\u9645\u7684\u95ee\u9898\uff0c\u63a2\u8ba8\u901a\u8fc7\u6f5c\u5728\u6fc0\u6d3b\u8f6c\u5411\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u63a7\u5236\uff0c\u4ee5\u5b9e\u73b0\u7cbe\u786e\u4e14\u53ef\u5b9a\u5236\u7684\u5b89\u5168\u8c03\u6574\u3002", "method": "\u4f7f\u7528\u540d\u4e3aSafeSteer\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u7c7b\u522b\u7279\u5b9a\u7684\u8f6c\u5411\u5411\u91cf\uff0c\u901a\u8fc7\u7b80\u5355\u3001\u65e0\u68af\u5ea6\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u6765\u63d0\u5347\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6587\u672c\u8d28\u91cf\u548c\u4e3b\u9898\u76f8\u5173\u6027\uff0c\u800c\u4e0d\u660e\u786e\u62d2\u7edd\u3002", "result": "\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u98ce\u9669\u7c7b\u522b\u4e2d\u7684\u6548\u679c\uff0c\u8bc1\u660e\u5176\u53ef\u4ee5\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\u3001\u907f\u514d\u4e00\u5200\u5207\u7684\u62d2\u7edd\uff0c\u5e76\u6307\u5bfc\u6a21\u578b\u751f\u6210\u5b89\u5168\u7684\u5185\u5bb9\uff0c\u540c\u65f6\u4fdd\u6301\u4e3b\u9898\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u5728\u5404\u79cdLLMs\u3001\u6570\u636e\u96c6\u548c\u98ce\u9669\u7c7b\u522b\u4e2d\u6709\u6548\u8fd0\u4f5c\uff0c\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\u548c\u907f\u514d\u5185\u5bb9\u62d2\u7edd\uff0c\u786e\u4fdd\u751f\u6210\u7684\u5185\u5bb9\u5b89\u5168\u4e14\u4e3b\u9898\u76f8\u5173\u3002"}}
{"id": "2506.05309", "pdf": "https://arxiv.org/pdf/2506.05309", "abs": "https://arxiv.org/abs/2506.05309", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "categories": ["cs.MA", "cs.AI", "cs.CL"], "comment": null, "summary": "LLMs are used predominantly in synchronous communication, where a human user\nand a model communicate in alternating turns. In contrast, many real-world\nsettings are inherently asynchronous. For example, in group chats, online team\nmeetings, or social games, there is no inherent notion of turns; therefore, the\ndecision of when to speak forms a crucial part of the participant's decision\nmaking. In this work, we develop an adaptive asynchronous LLM-agent which, in\naddition to determining what to say, also decides when to say it. To evaluate\nour agent, we collect a unique dataset of online Mafia games, including both\nhuman participants, as well as our asynchronous agent. Overall, our agent\nperforms on par with human players, both in game performance, as well as in its\nability to blend in with the other human players. Our analysis shows that the\nagent's behavior in deciding when to speak closely mirrors human patterns,\nalthough differences emerge in message content. We release all our data and\ncode to support and encourage further research for more realistic asynchronous\ncommunication between LLM agents. This work paves the way for integration of\nLLMs into realistic human group settings, from assistance in team discussions\nto educational and professional environments where complex social dynamics must\nbe navigated.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u5f02\u6b65LLM\u4ee3\u7406\uff0c\u53ef\u4ee5\u51b3\u5b9a\u4f55\u65f6\u53d1\u8a00\uff0c\u5176\u5728Mafia\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u76f8\u5f53\uff0c\u5e76\u80fd\u591f\u81ea\u7136\u878d\u5165\u53c2\u4e0e\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5728\u5f02\u6b65\u4ea4\u6d41\u4e2d\u51b3\u5b9a\u4f55\u65f6\u53d1\u8a00\u7684\u9002\u5e94\u6027\u5f02\u6b65LLM\u4ee3\u7406\u3002", "method": "\u6536\u96c6\u5728\u7ebfMafia\u6e38\u620f\u6570\u636e\uff0c\u8bc4\u4f30\u5f02\u6b65\u4ee3\u7406\u4e0e\u4eba\u7c7b\u53c2\u4e0e\u8005\u7684\u8868\u73b0\u4e0e\u878d\u5165\u80fd\u529b\u3002", "result": "\u6211\u4eec\u7684\u4ee3\u7406\u5728\u6e38\u620f\u8868\u73b0\u548c\u878d\u5165\u65b9\u9762\u8868\u73b0\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u76f8\u5f53\uff0c\u53d1\u8a00\u65f6\u673a\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u6d88\u606f\u5185\u5bb9\u6709\u6240\u4e0d\u540c\u3002", "conclusion": "\u6210\u679c\u4fc3\u8fdb\u4e86LLMs\u5728\u73b0\u5b9e\u4eba\u7fa4\u73af\u5883\u4e2d\u7684\u96c6\u6210\uff0c\u63a8\u52a8\u5176\u5728\u56e2\u961f\u8ba8\u8bba\u3001\u6559\u80b2\u548c\u4e13\u4e1a\u73af\u5883\u4e2d\u89e3\u51b3\u590d\u6742\u793e\u4ea4\u52a8\u6001\u7684\u5e94\u7528\u3002"}}
{"id": "2506.04385", "pdf": "https://arxiv.org/pdf/2506.04385", "abs": "https://arxiv.org/abs/2506.04385", "authors": ["Kurt Micallef", "Claudia Borg"], "title": "MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings Camera-Ready", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious Natural Language Processing (NLP) tasks, largely due to their\ngeneralisability and ability to perform tasks without additional training.\nHowever, their effectiveness for low-resource languages remains limited. In\nthis study, we evaluate the performance of 55 publicly available LLMs on\nMaltese, a low-resource language, using a newly introduced benchmark covering\n11 discriminative and generative tasks. Our experiments highlight that many\nmodels perform poorly, particularly on generative tasks, and that smaller\nfine-tuned models often perform better across all tasks. From our\nmultidimensional analysis, we investigate various factors impacting\nperformance. We conclude that prior exposure to Maltese during pre-training and\ninstruction-tuning emerges as the most important factor. We also examine the\ntrade-offs between fine-tuning and prompting, highlighting that while\nfine-tuning requires a higher initial cost, it yields better performance and\nlower inference costs. Through this work, we aim to highlight the need for more\ninclusive language technologies and recommend that researchers working with\nlow-resource languages consider more \"traditional\" language modelling\napproaches.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e8655\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u9a6c\u8033\u4ed6\u8bed\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u65f6\u63a5\u89e6\u8bed\u8a00\u548c\u5fae\u8c03\u662f\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5fae\u8c03\u5c3d\u7ba1\u6210\u672c\u9ad8\u4f46\u6548\u679c\u66f4\u597d\uff0c\u5efa\u8bae\u4f7f\u7528\u66f4\u52a0\u4f20\u7edf\u7684\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cdNLP\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u9a6c\u8033\u4ed6\u8bed\u4e0a\u7684\u8868\u73b0\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30LLM\u5728\u8fd9\u79cd\u8bed\u8a00\u4e0a\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u7d22\u5f71\u54cd\u5176\u6027\u80fd\u7684\u56e0\u7d20\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e8655\u4e2a\u516c\u5f00\u53d1\u5e03\u7684LLM\u5728\u9a6c\u8033\u4ed6\u8bed\u4e0a\u7684\u8868\u73b0\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u8986\u76d611\u4e2a\u8fa8\u522b\u548c\u751f\u6210\u4efb\u52a1\u7684\u65b0\u57fa\u51c6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u4e86\u5fae\u8c03\u548c\u63d0\u793a\u7b56\u7565\u7684\u6548\u679c\uff0c\u5e76\u5206\u6790\u4e86\u5f71\u54cd\u6027\u80fd\u7684\u5404\u79cd\u56e0\u7d20\u3002", "result": "\u8bb8\u591a\u6a21\u578b\u5728\u9a6c\u8033\u4ed6\u8bed\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8f83\u5dee\uff0c\u800c\u8f83\u5c0f\u7684\u5fae\u8c03\u6a21\u578b\u6574\u4f53\u8868\u73b0\u66f4\u597d\u3002\u6b64\u5916\uff0c\u9884\u8bad\u7ec3\u671f\u95f4\u7684\u8bed\u8a00\u63a5\u89e6\u548c\u6307\u4ee4\u8c03\u4f18\u5bf9\u4e8e\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u5fae\u8c03\u521d\u59cb\u6210\u672c\u9ad8\uff0c\u4f46\u5176\u8868\u73b0\u66f4\u597d\u4e14\u63a8\u7406\u6210\u672c\u8f83\u4f4e\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5bf955\u4e2a\u516c\u5f00\u7684LLM\u8fdb\u884c\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u9a6c\u8033\u4ed6\u8bed\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u5c24\u5176\u662f\u5728\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u800c\u8f83\u5c0f\u7684\u5fae\u8c03\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\u3002\u9884\u8bad\u7ec3\u671f\u95f4\u63a5\u89e6\u9a6c\u8033\u4ed6\u8bed\u548c\u6307\u4ee4\u8c03\u4f18\u662f\u5f71\u54cd\u6027\u80fd\u7684\u6700\u91cd\u8981\u56e0\u7d20\u3002\u5fae\u8c03\u867d\u7136\u521d\u59cb\u6210\u672c\u8f83\u9ad8\uff0c\u4f46\u6027\u80fd\u66f4\u597d\u4e14\u63a8\u7406\u6210\u672c\u66f4\u4f4e\u3002\u5efa\u8bae\u7814\u7a76\u4eba\u5458\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u8bed\u8a00\u65f6\u8003\u8651\u4f20\u7edf\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\u3002"}}
{"id": "2506.04253", "pdf": "https://arxiv.org/pdf/2506.04253", "abs": "https://arxiv.org/abs/2506.04253", "authors": ["Tapio Pitk\u00e4ranta", "Leena Pitk\u00e4ranta"], "title": "HADA: Human-AI Agent Decision Alignment Architecture", "categories": ["cs.AI", "cs.HC", "cs.AI, cs.SE, cs.MA, cs.CL, cs.LG"], "comment": "18 pages, 4 figures", "summary": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and\nframework agnostic reference architecture that keeps both large language model\n(LLM) agents and legacy algorithms aligned with organizational targets and\nvalues. HADA wraps any algorithm or LLM in role-specific stakeholder agents --\nbusiness, data-science, audit, ethics, and customer -- each exposing\nconversational APIs so that technical and non-technical actors can query,\nsteer, audit, or contest every decision across strategic, tactical, and\nreal-time horizons. Alignment objectives, KPIs, and value constraints are\nexpressed in natural language and are continuously propagated, logged, and\nversioned while thousands of heterogeneous agents run on different\norchestration stacks. A cloud-native proof of concept packages a production\ncredit-scoring model (getLoanDecision) and deploys it on\nDocker/Kubernetes/Python; five scripted retail-bank scenarios show how target\nchanges, parameter tweaks, explanation requests, and ethics triggers flow end\nto end through the architecture. Evaluation followed the Design-Science\nResearch Methodology. Walkthrough observation and log inspection demonstrated\ncomplete coverage of six predefined objectives: every role could invoke\nconversational control, trace KPIs and value constraints, detect and mitigate\nZIP-code bias, and reproduce full decision lineage, independent of the\nunderlying LLM or agent library. Contributions: (1) an open-source HADA\narchitecture, (2) a mid-range design theory for human-AI alignment in\nmulti-agent systems, and (3) empirical evidence that framework-agnostic,\nprotocol-compliant stakeholder agents improve accuracy, transparency, and\nethical compliance in real-world decision pipelines.", "AI": {"tldr": "\u63d0\u51faHADA\u67b6\u6784\uff0c\u4f7f\u5f97\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4f20\u7edf\u7b97\u6cd5\u80fd\u591f\u4e0e\u7ec4\u7ec7\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\uff0c\u901a\u8fc7\u4e91\u7aef\u6f14\u793a\u548c\u8bc4\u4f30\u8bc1\u660e\u5176\u5728\u63d0\u9ad8\u51b3\u7b56\u6d41\u7a0b\u7684\u900f\u660e\u6027\u548c\u51c6\u786e\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u4e00\u79cd\u4e00\u81f4\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f97\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u548c\u4f20\u7edf\u7b97\u6cd5\u80fd\u591f\u4e0e\u7ec4\u7ec7\u7684\u76ee\u6807\u548c\u4ef7\u503c\u89c2\u4fdd\u6301\u4e00\u81f4\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e91\u7684\u6982\u5ff5\u9a8c\u8bc1\u6a21\u578b\uff0c\u901a\u8fc7\u5728Docker/Kubernetes/Python\u4e0a\u90e8\u7f72\u751f\u4ea7\u4fe1\u8d37\u8bc4\u5206\u6a21\u578b\uff0c\u6f14\u793a\u8be5\u67b6\u6784\u5982\u4f55\u5728\u4e94\u4e2a\u96f6\u552e\u94f6\u884c\u573a\u666f\u4e2d\u8fdb\u884c\u8fd0\u4f5c\u548c\u8c03\u6574\u3002\u8bc4\u4f30\u4f7f\u7528\u4e86\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u8bba\uff0c\u901a\u8fc7\u89c2\u5bdf\u548c\u65e5\u5fd7\u68c0\u67e5\u8bc1\u660e\u67b6\u6784\u8986\u76d6\u6240\u6709\u9884\u5b9a\u4e49\u76ee\u6807\u3002", "result": "\u8bc1\u660e\u4e86HADA\u67b6\u6784\u80fd\u591f\u6539\u5584\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u6d41\u7a0b\u7684\u51c6\u786e\u6027\u3001\u900f\u660e\u5ea6\u548c\u4f26\u7406\u5408\u89c4\u6027\uff0c\u6587\u4e2d\u5217\u51fa\u4e86\u4e94\u4e2a\u793a\u4f8b\u573a\u666f\u8fdb\u884c\u9a8c\u8bc1\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f00\u6e90HADA\u67b6\u6784\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u7528\u4e8e\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u4eba\u673a\u534f\u4f5c\u4e2d\u7a0b\u8bbe\u8ba1\u7406\u8bba\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\u534f\u8bae\u517c\u5bb9\u7684\u89d2\u8272\u4ee3\u7406\u53ef\u4ee5\u6539\u5584\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u6d41\u7a0b\u3002"}}
{"id": "2506.04254", "pdf": "https://arxiv.org/pdf/2506.04254", "abs": "https://arxiv.org/abs/2506.04254", "authors": ["Nicolas Caron", "Christophe Guyeux", "Hassan Noura", "Benjamin Aynes"], "title": "Localized Forest Fire Risk Prediction: A Department-Aware Approach for Operational Decision Support", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 7 figures, 3 tables, submitted to ECAI2025", "summary": "Forest fire prediction involves estimating the likelihood of fire ignition or\nrelated risk levels in a specific area over a defined time period. With climate\nchange intensifying fire behavior and frequency, accurate prediction has become\none of the most pressing challenges in Artificial Intelligence (AI).\nTraditionally, fire ignition is approached as a binary classification task in\nthe literature. However, this formulation oversimplifies the problem,\nespecially from the perspective of end-users such as firefighters. In general,\nas is the case in France, firefighting units are organized by department, each\nwith its terrain, climate conditions, and historical experience with fire\nevents. Consequently, fire risk should be modeled in a way that is sensitive to\nlocal conditions and does not assume uniform risk across all regions. This\npaper proposes a new approach that tailors fire risk assessment to departmental\ncontexts, offering more actionable and region-specific predictions for\noperational use. With this, we present the first national-scale AI benchmark\nfor metropolitan France using state-of-the-art AI models on a relatively\nunexplored dataset. Finally, we offer a summary of important future works that\nshould be taken into account. Supplementary materials are available on GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u5730\u65b9\u6761\u4ef6\u7684\u68ee\u6797\u706b\u707e\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f7f\u7528AI\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u63d0\u4f9b\u6cd5\u56fd\u5168\u56fd\u8303\u56f4\u5185\u7684AI\u57fa\u51c6\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u4e86\u706b\u884c\u4e3a\u548c\u9891\u7387\uff0c\u4f7f\u5f97\u51c6\u786e\u9884\u6d4b\u68ee\u6797\u706b\u707e\u6210\u4e3aAI\u9886\u57df\u7684\u7d27\u8feb\u6311\u6218\u3002\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\u6cd5\u8fc7\u4e8e\u7b80\u5355\u5316\uff0c\u65e0\u6cd5\u6ee1\u8db3\u6d88\u9632\u4eba\u5458\u7684\u9700\u6c42\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9002\u5e94\u5730\u65b9\u6761\u4ef6\u5e76\u63d0\u4f9b\u533a\u57df\u4e13\u5c5e\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684AI\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5e76\u4ee5\u5168\u56fd\u8303\u56f4\u4e3a\u5c3a\u5ea6\uff0c\u4f7f\u7528\u672a\u5145\u5206\u7814\u7a76\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u6cd5\u56fd\u90fd\u5e02\u5730\u533a\u7684\u7b2c\u4e00\u4e2a\u56fd\u5bb6\u7ea7AI\u57fa\u51c6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u5730\u65b9\u6761\u4ef6\u7684\u706b\u707e\u98ce\u9669\u8bc4\u4f30\u65b0\u65b9\u6cd5\uff0c\u4ee5\u53ca\u6cd5\u56fd\u90fd\u5e02\u5730\u533a\u7b2c\u4e00\u4e2a\u56fd\u5bb6\u7ea7AI\u57fa\u51c6\uff0c\u4e3a\u672a\u6765\u7684\u91cd\u8981\u5de5\u4f5c\u63d0\u4f9b\u4e86\u603b\u7ed3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9002\u5e94\u4e0d\u540c\u90e8\u95e8\u7684\u73af\u5883\u6761\u4ef6\uff0c\u4e3a\u68ee\u6797\u706b\u707e\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u9488\u5bf9\u6027\u66f4\u5f3a\u7684\u9884\u6d4b\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u5e94\u7528\u4e8e\u6cd5\u56fd\uff0c\u4e5f\u4e3a\u5176\u4ed6\u56fd\u5bb6\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2506.04389", "pdf": "https://arxiv.org/pdf/2506.04389", "abs": "https://arxiv.org/abs/2506.04389", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Customer care is an essential pillar of the e-commerce shopping experience\nwith companies spending millions of dollars each year, employing automation and\nhuman agents, across geographies (like US, Canada, Mexico, Chile), channels\n(like Chat, Interactive Voice Response (IVR)), and languages (like English,\nSpanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on\nannotated data have shown good performance in downstream tasks relevant to\nCustomer Care. However, model performance is largely subject to the\navailability of sufficient annotated domain-specific data. Cross-domain\navailability of data remains a bottleneck, thus building an intent classifier\nthat generalizes across domains (defined by channel, geography, and language)\nwith only a few annotations, is of great practical value. In this paper, we\npropose an embedder-cum-classifier model architecture which extends\nstate-of-the-art domain-specific models to other domains with only a few\nlabeled samples. We adopt a supervised fine-tuning approach with isotropic\nregularizers to train a domain-specific sentence embedder and a multilingual\nknowledge distillation strategy to generalize this embedder across multiple\ndomains. The trained embedder, further augmented with a simple linear\nclassifier can be deployed for new domains. Experiments on Canada and Mexico\ne-commerce Customer Care dataset with few-shot intent detection show an\nincrease in accuracy by 20-23% against the existing state-of-the-art\npre-trained models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5d4c\u5165\u5668\u4e0e\u5206\u7c7b\u5668\u7ec4\u5408\u6a21\u578b\uff0c\u5728\u5c11\u6837\u672c\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u4e0d\u540c\u9886\u57df\u7684\u5ba2\u6237\u670d\u52a1\u610f\u56fe\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u5728\u4e0d\u540c\u9886\u57df\uff08\u6839\u636e\u6e20\u9053\u3001\u5730\u7406\u4f4d\u7f6e\u548c\u8bed\u8a00\u5b9a\u4e49\uff09\u4e2d\u6cdb\u5316\u7684\u610f\u56fe\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u4ec5\u9700\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u7ed3\u5408\u7b49\u65b9\u6b63\u5219\u5316\u8bad\u7ec3\u9886\u57df\u7279\u5b9a\u7684\u53e5\u5b50\u5d4c\u5165\uff0c\u5e76\u4f7f\u7528\u591a\u8bed\u8a00\u77e5\u8bc6\u84b8\u998f\u7b56\u7565\u6765\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u6cdb\u5316\u3002", "result": "\u6a21\u578b\u5728\u52a0\u62ff\u5927\u548c\u58a8\u897f\u54e5\u7535\u5546\u5ba2\u6237\u670d\u52a1\u6570\u636e\u96c6\u4e0a\u7684\u610f\u56fe\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad8\u4e8620-23%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u5c11\u6837\u672c\u9886\u57df\u6cdb\u5316\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.04287", "pdf": "https://arxiv.org/pdf/2506.04287", "abs": "https://arxiv.org/abs/2506.04287", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "categories": ["cs.AI", "cs.LG"], "comment": "Preprint, under review", "summary": "Training large language model (LLM) agents to acquire necessary skills and\nperform diverse tasks within an environment is gaining interest as a means to\nenable open-endedness. However, creating the training dataset for their skill\nacquisition faces several challenges. Manual trajectory collection requires\nsignificant human effort. Another approach, where LLMs directly propose tasks\nto learn, is often invalid, as the LLMs lack knowledge of which tasks are\nactually feasible. Moreover, the generated data may not provide a meaningful\nlearning signal, as agents often already perform well on the proposed tasks. To\naddress this, we propose a novel automatic skill discovery framework EXIF for\nLLM-powered agents, designed to improve the feasibility of generated target\nbehaviors while accounting for the agents' capabilities. Our method adopts an\nexploration-first strategy by employing an exploration agent (Alice) to train\nthe target agent (Bob) to learn essential skills in the environment.\nSpecifically, Alice first interacts with the environment to retrospectively\ngenerate a feasible, environment-grounded skill dataset, which is then used to\ntrain Bob. Crucially, we incorporate an iterative feedback loop, where Alice\nevaluates Bob's performance to identify areas for improvement. This feedback\nthen guides Alice's next round of exploration, forming a closed-loop data\ngeneration process. Experiments on Webshop and Crafter demonstrate EXIF's\nability to effectively discover meaningful skills and iteratively expand the\ncapabilities of the trained agent without any human intervention, achieving\nsubstantial performance improvements. Interestingly, we observe that setting\nAlice to the same model as Bob also notably improves performance, demonstrating\nEXIF's potential for building a self-evolving system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEXIF\u7684\u81ea\u52a8\u6280\u80fd\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u4eba\u5de5\u5e72\u9884\u7684\u8fed\u4ee3\u53cd\u9988\u673a\u5236\uff0c\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\uff0c\u5b9e\u73b0\u6280\u80fd\u63d0\u5347\u548c\u6027\u80fd\u6539\u5584\u3002", "motivation": "\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4ee5\u83b7\u53d6\u5fc5\u8981\u7684\u6280\u80fd\u548c\u5728\u73af\u5883\u4e2d\u6267\u884c\u591a\u6837\u5316\u4efb\u52a1\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u521b\u5efa\u7528\u4e8e\u6280\u80fd\u83b7\u53d6\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6536\u96c6\u8f68\u8ff9\uff0c\u6216\u7531\u4e8eLLM\u7f3a\u4e4f\u53ef\u884c\u4efb\u52a1\u7684\u77e5\u8bc6\uff0c\u5bfc\u81f4\u6240\u63d0\u4efb\u52a1\u65e0\u6548\u4e14\u65e0\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u5b66\u4e60\u4fe1\u53f7\u3002\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u662f\u672c\u6587\u7684\u52a8\u529b\u6240\u5728\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aEXIF\u7684\u81ea\u52a8\u6280\u80fd\u53d1\u73b0\u6846\u67b6\u3002\u91c7\u7528\u201c\u63a2\u7d22\u4f18\u5148\u201d\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u8bbe\u7f6e\u63a2\u7d22\u4ee3\u7406Alice\u5728\u73af\u5883\u4e2d\u751f\u6210\u53ef\u884c\u7684\u6280\u80fd\u6570\u636e\u96c6\uff0c\u7136\u540e\u7528\u4e8e\u8bad\u7ec3\u76ee\u6807\u4ee3\u7406Bob\u3002\u540c\u65f6\u5f15\u5165\u4e00\u4e2a\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\uff0cAlice\u8bc4\u4f30Bob\u7684\u8868\u73b0\uff0c\u5e76\u6307\u5bfc\u4e0b\u4e00\u8f6e\u63a2\u7d22\uff0c\u5f62\u6210\u95ed\u73af\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728Webshop\u548cCrafter\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEXIF\u80fd\u591f\u6709\u6548\u53d1\u73b0\u6709\u610f\u4e49\u7684\u6280\u80fd\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u6269\u5927\u8bad\u7ec3\u4ee3\u7406\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u4e3a\u5e72\u9884\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "EXIF\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4ee5\u83b7\u5f97\u5fc5\u8981\u6280\u80fd\u548c\u6267\u884c\u591a\u6837\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u5728\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u901a\u8fc7\u8bbe\u7f6e\u63a2\u7d22\u4ee3\u7406Alice\u4e0e\u76ee\u6807\u4ee3\u7406Bob\u76f8\u540c\u7684\u6a21\u578b\uff0c\u6027\u80fd\u4e5f\u5f97\u5230\u4e86\u663e\u8457\u6539\u5584\uff0c\u663e\u793a\u51faEXIF\u7cfb\u7edf\u81ea\u6211\u8fdb\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.04268", "pdf": "https://arxiv.org/pdf/2506.04268", "abs": "https://arxiv.org/abs/2506.04268", "authors": ["Jingyang Li", "Guoqiang Li"], "title": "MUC-G4: Minimal Unsat Core-Guided Incremental Verification for Deep Neural Network Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The rapid development of deep learning has led to challenges in deploying\nneural networks on edge devices, mainly due to their high memory and runtime\ncomplexity. Network compression techniques, such as quantization and pruning,\naim to reduce this complexity while maintaining accuracy. However, existing\nincremental verification methods often focus only on quantization and struggle\nwith structural changes. This paper presents MUC-G4 (Minimal Unsat Core-Guided\nIncremental Verification), a novel framework for incremental verification of\ncompressed deep neural networks. It encodes both the original and compressed\nnetworks into SMT formulas, classifies changes, and use \\emph{Minimal Unsat\nCores (MUCs)} from the original network to guide efficient verification for the\ncompressed network. Experimental results show its effectiveness in handling\nquantization and pruning, with high proof reuse rates and significant speedup\nin verification time compared to traditional methods. MUC-G4 hence offers a\npromising solution for ensuring the safety and reliability of compressed neural\nnetworks in practical applications.", "AI": {"tldr": "MUC-G4\u662f\u4e00\u79cd\u7528\u4e8e\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u589e\u91cf\u9a8c\u8bc1\u7684\u65b0\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u5904\u7406\u91cf\u5316\u548c\u526a\u679d\u65f6\u5177\u6709\u9ad8\u6548\u6027\u548c\u5feb\u901f\u6027\uff0c\u53ef\u5728\u5b9e\u8df5\u5e94\u7528\u4e2d\u786e\u4fdd\u7f51\u7edc\u7684\u5b89\u5168\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u7684\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u795e\u7ecf\u7f51\u7edc\u7684\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u5176\u9ad8\u5185\u5b58\u548c\u8fd0\u884c\u65f6\u590d\u6742\u6027\u3002\u7f51\u7edc\u538b\u7f29\u6280\u672f\u65e8\u5728\u51cf\u5c11\u8fd9\u79cd\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMUC-G4\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u539f\u59cb\u548c\u538b\u7f29\u540e\u7684\u7f51\u7edc\u7f16\u7801\u4e3aSMT\u516c\u5f0f\uff0c\u5206\u7c7b\u53d8\u5316\uff0c\u5e76\u4f7f\u7528\u539f\u59cb\u7f51\u7edc\u7684\u6700\u5c0f\u4e0d\u6ee1\u8db3\u6838\u5fc3\u6765\u6307\u5bfc\u9ad8\u6548\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u91cf\u5316\u548c\u526a\u679d\u5904\u7406\u65b9\u9762\u5177\u6709\u9ad8\u8bc1\u660e\u91cd\u7528\u7387\u548c\u663e\u8457\u7684\u9a8c\u8bc1\u65f6\u95f4\u52a0\u901f\u6548\u679c\u3002", "conclusion": "MUC-G4\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u786e\u4fdd\u538b\u7f29\u795e\u7ecf\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.04676", "pdf": "https://arxiv.org/pdf/2506.04676", "abs": "https://arxiv.org/abs/2506.04676", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MA"], "comment": null, "summary": "Recently, Large Language Models (LLMs) and Vision Large Language Models\n(VLLMs) have demonstrated impressive performance as agents across various tasks\nwhile data scarcity and label noise remain significant challenges in computer\nvision tasks, such as object detection and instance segmentation. A common\nsolution for resolving these issues is to generate synthetic data. However,\ncurrent synthetic data generation methods struggle with issues, such as\nmultiple objects per mask, inaccurate segmentation, and incorrect category\nlabels, limiting their effectiveness. To address these issues, we introduce\nGen-n-Val, a novel agentic data generation framework that leverages Layer\nDiffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks\nand diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt\nagent, an LLM, optimizes prompts for LD to generate high-quality foreground\ninstance images and segmentation masks. These optimized prompts ensure the\ngeneration of single-object synthetic data with precise instance masks and\nclean backgrounds. (2) The data validation agent, a VLLM, which filters out\nlow-quality synthetic instance images. The system prompts for both agents are\nrefined through TextGrad. Additionally, we use image harmonization to combine\nmultiple instances within scenes. Compared to state-of-the-art synthetic data\napproaches like MosaicFusion, our approach reduces invalid synthetic data from\n50% to 7% and improves performance by 1% mAP on rare classes in COCO instance\nsegmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant\nimprovements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object\ndetection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance\nof YOLOv9 and YOLO11 families in instance segmentation and object detection.", "AI": {"tldr": "Gen-n-Val is a framework improving synthetic data quality, reducing label noise, and enhancing performance in object detection and segmentation, outperforming existing methods like MosaicFusion.", "motivation": "To address the challenges of data scarcity and label noise in computer vision tasks, especially in object detection and instance segmentation, by improving synthetic data quality.", "method": "The paper introduces Gen-n-Val, an agentic data generation framework comprising two agents: a Layer Diffusion (LD) prompt agent and a data validation agent using language models (LLMs and VLLMs). The use of TextGrad refines system prompts, and image harmonization combines multiple instances within scenes.", "result": "Compared to MosaicFusion, Gen-n-Val reduces invalid synthetic data from 50% to 7% and achieves a 1% mAP improvement on rare classes in COCO instance segmentation. It also shows a significant 7.1% mAP improvement on open-vocabulary object detection benchmarks, improving the performance of the YOLOv9 and YOLO11 families.", "conclusion": "Gen-n-Val significantly enhances synthetic data quality and improves performance in object detection and instance segmentation tasks compared to existing methods."}}
{"id": "2506.04405", "pdf": "https://arxiv.org/pdf/2506.04405", "abs": "https://arxiv.org/abs/2506.04405", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "We introduce MedAgentGYM, the first publicly available training environment\ndesigned to enhance coding-based medical reasoning capabilities in large\nlanguage model (LLM) agents. MedAgentGYM comprises 72,413 task instances across\n129 categories derived from authentic real-world biomedical scenarios. Tasks\nare encapsulated within executable coding environments, each featuring detailed\ntask descriptions, interactive feedback mechanisms, verifiable ground-truth\nannotations, and scalable training trajectory generation. Extensive\nbenchmarking of over 30 LLMs reveals a notable performance disparity between\ncommercial API-based models and open-source counterparts. Leveraging\nMedAgentGYM, Med-Copilot-7B achieves substantial performance gains through\nsupervised fine-tuning (+36.44%) and continued reinforcement learning\n(+42.47%), emerging as an affordable and privacy-preserving alternative\ncompetitive with gpt-4o. By offering both a comprehensive benchmark and\naccessible, expandable training resources within unified execution\nenvironments, MedAgentGYM delivers an integrated platform to develop LLM-based\ncoding assistants for advanced biomedical research and practice.", "AI": {"tldr": "MedAgentGYM\u662f\u4e00\u4e2a\u8bad\u7ec3\u73af\u5883\uff0c\u589e\u5f3aLLM\u4ee3\u7406\u7684\u7f16\u7801\u578b\u533b\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u7814\u7a76\u5f00\u53d1\u63d0\u4f9b\u4e86\u5e73\u53f0\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u7684\u7f16\u7801\u578b\u533b\u5b66\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f7f\u7528MedAgentGYM\u5bf9\u8d85\u8fc730\u79cdLLM\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002", "result": "Med-Copilot-7B\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0egpt-4o\u7ade\u4e89\u3002", "conclusion": "MedAgentGYM\u4e3a\u5f00\u53d1LLM\u57fa\u7840\u7684\u7f16\u7801\u52a9\u624b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u5e73\u53f0\uff0c\u4ee5\u4fc3\u8fdb\u9ad8\u7ea7\u751f\u7269\u533b\u5b66\u7814\u7a76\u548c\u5b9e\u8df5\u3002"}}
{"id": "2506.04374", "pdf": "https://arxiv.org/pdf/2506.04374", "abs": "https://arxiv.org/abs/2506.04374", "authors": ["Jack David Carson", "Amir Reisizadeh"], "title": "A Statistical Physics of Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Transformer LMs show emergent reasoning that resists mechanistic\nunderstanding. We offer a statistical physics framework for continuous-time\nchain-of-thought reasoning dynamics. We model sentence-level hidden state\ntrajectories as a stochastic dynamical system on a lower-dimensional manifold.\nThis drift-diffusion system uses latent regime switching to capture diverse\nreasoning phases, including misaligned states or failures. Empirical\ntrajectories (8 models, 7 benchmarks) show a rank-40 projection (balancing\nvariance capture and feasibility) explains ~50% variance. We find four latent\nreasoning regimes. An SLDS model is formulated and validated to capture these\nfeatures. The framework enables low-cost reasoning simulation, offering tools\nto study and predict critical transitions like misaligned states or other LM\nfailures.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u8ba1\u7269\u7406\u6846\u67b6\u6765\u7406\u89e3\u53d8\u538b\u5668\u8bed\u8a00\u6a21\u578b\u7684\u8fde\u7eed\u65f6\u95f4\u63a8\u7406\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e86\u56db\u79cd\u6f5c\u5728\u63a8\u7406\u6a21\u5f0f\uff0c\u53ef\u4ee5\u4f4e\u6210\u672c\u6a21\u62df\u5e76\u9884\u6d4b\u5173\u952e\u8f6c\u53d8\u3002", "motivation": "\u53d8\u538b\u5668\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u7684\u63a8\u7406\u80fd\u529b\u96be\u4ee5\u901a\u8fc7\u673a\u5236\u6765\u7406\u89e3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u7edf\u8ba1\u7269\u7406\u6846\u67b6\u6765\u8fbe\u5230\u5bf9\u6b64\u7684\u5206\u6790\u548c\u7406\u89e3\u3002", "method": "\u8be5\u7814\u7a76\u5c06\u53e5\u5b50\u7ea7\u9690\u85cf\u72b6\u6001\u8f68\u8ff9\u5efa\u6a21\u4e3a\u4e0b\u7ef4\u6d41\u5f62\u4e0a\u7684\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u3002\u901a\u8fc7\u6f5c\u5728\u72b6\u6001\u53d8\u6362\u7684\u6f02\u79fb-\u6269\u6563\u7cfb\u7edf\u6765\u6355\u6349\u4e0d\u540c\u7684\u63a8\u7406\u9636\u6bb5\uff0c\u5305\u62ec\u672a\u5bf9\u9f50\u72b6\u6001\u6216\u5931\u8d25\u3002\u7814\u7a76\u8005\u8fd8\u5efa\u7acb\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2aSLDS\u6a21\u578b\u4ee5\u6355\u6349\u8fd9\u4e9b\u7279\u5f81\u3002", "result": "\u516b\u4e2a\u6a21\u578b\u5728\u4e03\u4e2a\u57fa\u51c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u901a\u8fc7\u79e9\u4e3a40\u7684\u6295\u5f71\uff08\u5728\u65b9\u5dee\u6355\u83b7\u4e0e\u53ef\u884c\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff09\u53ef\u4ee5\u89e3\u91ca\u5927\u7ea650%\u7684\u65b9\u5dee\uff0c\u53d1\u73b0\u4e86\u56db\u79cd\u6f5c\u5728\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u4ee5\u4f4e\u6210\u672c\u6a21\u62df\u63a8\u7406\uff0c\u63d0\u4f9b\u4e86\u7814\u7a76\u548c\u9884\u6d4b\u5982\u72b6\u6001\u5931\u8c03\u6216\u5176\u4ed6\u6a21\u578b\u5931\u8d25\u7b49\u5173\u952e\u8f6c\u53d8\u7684\u5de5\u5177\u3002"}}
{"id": "2506.04272", "pdf": "https://arxiv.org/pdf/2506.04272", "abs": "https://arxiv.org/abs/2506.04272", "authors": ["Kyung Rok Kim", "Yumo Bai", "Chonghuan Wang", "Guanting Chen"], "title": "Understanding the Impact of Sampling Quality in Direct Preference Optimization", "categories": ["cs.LG"], "comment": "Submitted to NeurIPS2025", "summary": "We study the role of the sampling distribution in Direct Preference\nOptimization (DPO) and aim to understand its impact on DPO's training dynamics.\nOur analyses show that both the solution space and the convergence behavior of\nDPO depend on the support and quality of the generating distribution. We first\nanalyze how distribution of responses influences policy updates during gradient\ndescent, drawing connections to common phenomena found in practice. We then\ndesign a simplified yet well-structured alignment model as a proxy, and develop\nquantitative results showing how more frequent high-quality responses amplify\nthe gradient signal and improve the optimization landscape, leading to more\neffective policy learning. Our theoretical findings are supported by empirical\nexperiments and provide a principled justification for the online DPO framework\nin practice.", "AI": {"tldr": "\u7814\u7a76\u4e86\u91c7\u6837\u5206\u5e03\u5bf9\u76f4\u63a5\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b80\u5316\u6a21\u578b\uff0c\u8bc1\u660e\u9ad8\u8d28\u91cf\u54cd\u5e94\u80fd\u6539\u5584\u4f18\u5316\u6548\u679c\u3002", "motivation": "\u7406\u89e3\u91c7\u6837\u5206\u5e03\u5728\u76f4\u63a5\u504f\u597d\u4f18\u5316\u4e2d\u7684\u4f5c\u7528\u53ca\u5176\u5bf9\u8bad\u7ec3\u52a8\u6001\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5316\u800c\u7ed3\u6784\u826f\u597d\u7684\u5bf9\u9f50\u6a21\u578b\uff0c\u901a\u8fc7\u8fd9\u79cd\u4ee3\u7406\u6a21\u578b\uff0c\u8fdb\u884c\u4e86\u5b9a\u91cf\u7814\u7a76\uff0c\u5c55\u793a\u9ad8\u8d28\u91cf\u54cd\u5e94\u9891\u7387\u5982\u4f55\u589e\u5f3a\u68af\u5ea6\u4fe1\u53f7\u5e76\u4f18\u5316\u4f18\u5316\u666f\u89c2\u3002", "result": "\u5f97\u51fa\u66f4\u591a\u9ad8\u8d28\u91cf\u54cd\u5e94\u7684\u9891\u7387\u80fd\u591f\u589e\u5f3a\u68af\u5ea6\u4fe1\u53f7\u5e76\u6539\u5584\u4f18\u5316\u666f\u89c2\uff0c\u4ece\u800c\u6709\u6548\u63d0\u9ad8\u7b56\u7565\u5b66\u4e60\u7684\u6548\u679c\u3002\u7406\u8bba\u53d1\u73b0\u5f97\u5230\u4e86\u5b9e\u8bc1\u5b9e\u9a8c\u7684\u652f\u6301\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u751f\u6210\u5206\u5e03\u7684\u652f\u6301\u548c\u8d28\u91cf\u5bf9DPO\u8bad\u7ec3\u52a8\u6001\u7684\u5f71\u54cd\uff0c\u4e3a\u5728\u7ebfDPO\u6846\u67b6\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.04408", "pdf": "https://arxiv.org/pdf/2506.04408", "abs": "https://arxiv.org/abs/2506.04408", "authors": ["Wesley Scivetti", "Tatsuya Aoyama", "Ethan Wilcox", "Nathan Schneider"], "title": "Unpacking Let Alone: Human-Scale Models Generalize to a Rare Construction in Form but not Meaning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Humans have a remarkable ability to acquire and understand grammatical\nphenomena that are seen rarely, if ever, during childhood. Recent evidence\nsuggests that language models with human-scale pretraining data may possess a\nsimilar ability by generalizing from frequent to rare constructions. However,\nit remains an open question how widespread this generalization ability is, and\nto what extent this knowledge extends to meanings of rare constructions, as\nopposed to just their forms. We fill this gap by testing human-scale\ntransformer language models on their knowledge of both the form and meaning of\nthe (rare and quirky) English LET-ALONE construction. To evaluate our LMs we\nconstruct a bespoke synthetic benchmark that targets syntactic and semantic\nproperties of the construction. We find that human-scale LMs are sensitive to\nform, even when related constructions are filtered from the dataset. However,\nhuman-scale LMs do not make correct generalizations about LET-ALONE's meaning.\nThese results point to an asymmetry in the current architectures' sample\nefficiency between language form and meaning, something which is not present in\nhuman language learners.", "AI": {"tldr": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u7406\u89e3\u7f55\u89c1\u8bed\u6cd5\u5f62\u5f0f\uff0c\u4f46\u5728\u8bed\u4e49\u7406\u89e3\u4e0a\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4e0e\u4eba\u7c7b\u5b66\u4e60\u8005\u4e0d\u540c\u3002", "motivation": "\u63a2\u8ba8\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u4ece\u5e38\u89c1\u7684\u6784\u9020\u63a8\u5e7f\u5230\u7f55\u89c1\u7684\u6784\u9020\uff0c\u5c24\u5176\u662f\u5176\u5bf9\u7f55\u89c1\u6784\u9020\u7684\u5f62\u5f0f\u548c\u610f\u4e49\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u91c7\u7528\u5b9a\u5236\u5316\u7684\u5408\u6210\u57fa\u51c6\u6765\u6d4b\u8bd5\u6a21\u578b\u5bf9LET-ALONE\u6784\u9020\u7684\u53e5\u6cd5\u548c\u8bed\u4e49\u5c5e\u6027\u7684\u7406\u89e3\u80fd\u529b\u3002", "result": "\u4eba\u7c7b\u7ea7\u522b\u7684\u8bed\u8a00\u6a21\u578b\u5bf9\u6784\u9020\u7684\u5f62\u5f0f\u654f\u611f\uff0c\u4f46\u4e0d\u80fd\u6b63\u786e\u63a8\u5e7f\u5176\u610f\u4e49\u3002", "conclusion": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u8bed\u8a00\u5f62\u5f0f\u7684\u654f\u611f\u6027\u8f83\u9ad8\uff0c\u4f46\u5728\u7406\u89e3\u7f55\u89c1\u6784\u9020\u7684\u8bed\u4e49\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2506.04410", "pdf": "https://arxiv.org/pdf/2506.04410", "abs": "https://arxiv.org/abs/2506.04410", "authors": ["Peter Jansen", "Samiah Hassan", "Ruoyao Wang"], "title": "Matter-of-Fact: A Benchmark for Verifying the Feasibility of Literature-Supported Claims in Materials Science", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.CL"], "comment": "8 pages", "summary": "Contemporary approaches to assisted scientific discovery use language models\nto automatically generate large numbers of potential hypothesis to test, while\nalso automatically generating code-based experiments to test those hypotheses.\nWhile hypotheses can be comparatively inexpensive to generate, automated\nexperiments can be costly, particularly when run at scale (i.e. thousands of\nexperiments). Developing the capacity to filter hypotheses based on their\nfeasibility would allow discovery systems to run at scale, while increasing\ntheir likelihood of making significant discoveries. In this work we introduce\nMatter-of-Fact, a challenge dataset for determining the feasibility of\nhypotheses framed as claims. Matter-of-Fact includes 8.4k claims extracted from\nscientific articles spanning four high-impact contemporary materials science\ntopics, including superconductors, semiconductors, batteries, and aerospace\nmaterials, while including qualitative and quantitative claims from\ntheoretical, experimental, and code/simulation results. We show that strong\nbaselines that include retrieval augmented generation over scientific\nliterature and code generation fail to exceed 72% performance on this task\n(chance performance is 50%), while domain-expert verification suggests nearly\nall are solvable -- highlighting both the difficulty of this task for current\nmodels, and the potential to accelerate scientific discovery by making\nnear-term progress.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Matter-of-Fact\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u5047\u8bbe\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u663e\u793a\u5f53\u524d\u6a21\u578b\u96be\u4ee5\u89e3\u51b3\u4f46\u4efb\u52a1\u662f\u53ef\u89e3\u51b3\u7684\uff0c\u6709\u6f5c\u529b\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002", "motivation": "\u5f53\u524d\u8f85\u52a9\u79d1\u5b66\u53d1\u73b0\u7684\u65b9\u6cd5\u5229\u7528\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u5927\u91cf\u6f5c\u5728\u5047\u8bbe\u8fdb\u884c\u6d4b\u8bd5\uff0c\u540c\u65f6\u81ea\u52a8\u751f\u6210\u57fa\u4e8e\u4ee3\u7801\u7684\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u5047\u8bbe\u3002\u7136\u800c\uff0c\u5f53\u5b9e\u9a8c\u89c4\u6a21\u8f83\u5927\u65f6\uff08\u6570\u5343\u4e2a\u5b9e\u9a8c\uff09\uff0c\u81ea\u52a8\u5316\u5b9e\u9a8c\u7684\u6210\u672c\u53ef\u80fd\u4f1a\u5f88\u9ad8\u3002\u4e3a\u4e86\u5b9e\u73b0\u5927\u89c4\u6a21\u7684\u53d1\u73b0\u7cfb\u7edf\uff0c\u5e76\u63d0\u9ad8\u91cd\u5927\u53d1\u73b0\u7684\u53ef\u80fd\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u529b\u6765\u6839\u636e\u5047\u8bbe\u7684\u53ef\u884c\u6027\u8fdb\u884c\u7b5b\u9009\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86Matter-of-Fact\uff0c\u4e00\u4e2a\u7528\u4e8e\u786e\u5b9a\u5047\u8bbe\u53ef\u884c\u6027\u7684\u6311\u6218\u6570\u636e\u96c6\u3002Matter-of-Fact\u4ece\u79d1\u5b66\u6587\u7ae0\u4e2d\u63d0\u53d6\u4e868.4k\u4e2a\u5173\u4e8e\u56db\u4e2a\u9ad8\u5f71\u54cd\u5f53\u4ee3\u6750\u6599\u79d1\u5b66\u4e3b\u9898\u7684\u58f0\u660e\uff0c\u5305\u62ec\u8d85\u5bfc\u4f53\u3001\u534a\u5bfc\u4f53\u3001\u7535\u6c60\u548c\u822a\u7a7a\u822a\u5929\u6750\u6599\uff0c\u540c\u65f6\u5305\u62ec\u7406\u8bba\u3001\u5b9e\u9a8c\u548c\u4ee3\u7801/\u6a21\u62df\u7ed3\u679c\u4e2d\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u58f0\u660e\u3002", "result": "\u6211\u4eec\u5c55\u793a\u4e86\u5728\u79d1\u5b66\u6587\u732e\u548c\u4ee3\u7801\u751f\u6210\u4e0a\u589e\u5f3a\u7684\u68c0\u7d22\u751f\u6210\u7684\u5f3a\u57fa\u7ebf\u5728\u5b8c\u6210\u8fd9\u9879\u4efb\u52a1\u65f6\u672a\u80fd\u8d85\u8fc772%\u7684\u8868\u73b0\uff08\u673a\u4f1a\u8868\u73b0\u4e3a50%\uff09\uff0c\u800c\u9886\u57df\u4e13\u5bb6\u7684\u9a8c\u8bc1\u8868\u660e\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u90fd\u662f\u53ef\u4ee5\u89e3\u51b3\u7684\uff0c\u8fd9\u7a81\u663e\u4e86\u5f53\u524d\u6a21\u578b\u5bf9\u8fd9\u4e00\u4efb\u52a1\u7684\u96be\u5ea6\uff0c\u4ee5\u53ca\u901a\u8fc7\u53d6\u5f97\u77ed\u671f\u8fdb\u5c55\u6765\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u7684\u6f5c\u529b\u3002", "conclusion": "\u5f53\u524d\u7684\u6a21\u578b\u5728\u786e\u5b9a\u5047\u8bbe\u53ef\u884c\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff08\u672a\u8d85\u8fc772%\uff09\uff0c\u7136\u800c\u9886\u57df\u4e13\u5bb6\u8ba4\u4e3a\u4efb\u52a1\u662f\u53ef\u89e3\u51b3\u7684\uff0c\u8fd9\u8868\u660e\u6709\u53ef\u80fd\u901a\u8fc7\u6539\u8fdb\u6a21\u578b\u6765\u663e\u8457\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2506.04281", "pdf": "https://arxiv.org/pdf/2506.04281", "abs": "https://arxiv.org/abs/2506.04281", "authors": ["Xu Zheng", "Chaohao Lin", "Sipeng Chen", "Zhuomin Chen", "Jimeng Shi", "Wei Cheng", "Jayantha Obeysekera", "Jason Liu", "Dongsheng Luo"], "title": "SF$^2$Bench: Evaluating Data-Driven Models for Compound Flood Forecasting in South Florida", "categories": ["cs.LG"], "comment": "60 Pages", "summary": "Forecasting compound floods presents a significant challenge due to the\nintricate interplay of meteorological, hydrological, and oceanographic factors.\nAnalyzing compound floods has become more critical as the global climate\nincreases flood risks. Traditional physics-based methods, such as the\nHydrologic Engineering Center's River Analysis System, are often\ntime-inefficient. Machine learning has recently demonstrated promise in both\nmodeling accuracy and computational efficiency. However, the scarcity of\ncomprehensive datasets currently hinders systematic analysis. Existing\nwater-related datasets are often limited by a sparse network of monitoring\nstations and incomplete coverage of relevant factors. To address this\nchallenge, we introduce SF2Bench, a comprehensive time series collection on\ncompound floods in South Florida, which integrates four key factors: tide,\nrainfall, groundwater, and human management activities (gate and pump\ncontrolling). This integration allows for a more detailed analysis of the\nindividual contributions of these drivers to compound flooding and informs the\ndevelopment of improved flood forecasting approaches. To comprehensively\nevaluate the potential of various modeling paradigms, we assess the performance\nof six categories of methods, encompassing Multilayer Perceptrons,\nConvolutional Neural Networks, Recurrent Neural Networks, Graph Neural\nNetworks, Transformers, and Large Language Models. We verified the impact of\ndifferent key features on flood forecasting through experiments. Our analysis\nexamines temporal and spatial aspects, providing insights into the influence of\nhistorical data and spatial dependencies. The varying performance across these\napproaches underscores the diverse capabilities of each in capturing complex\ntemporal and spatial dependencies inherent in compound floods.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86SF2Bench\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u590d\u5408\u6d2a\u6c34\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u4e0d\u540c\u65b9\u6cd5\u5728\u65f6\u7a7a\u4f9d\u8d56\u5904\u7406\u4e0a\u8868\u73b0\u4e0d\u4e00\u3002", "motivation": "\u5f53\u524d\u6d2a\u6c34\u9884\u6d4b\u9762\u4e34\u6570\u636e\u4e0d\u8db3\u548c\u5206\u6790\u65b9\u6cd5\u6548\u7387\u4e0d\u9ad8\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u6765\u63d0\u9ad8\u6d2a\u6c34\u9884\u6d4b\u6548\u679c\u3002", "method": "\u7814\u7a76\u8bc4\u4f30\u4e86\u516d\u7c7b\u5efa\u6a21\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5305\u62ec\u591a\u5c42\u611f\u77e5\u673a\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3001\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u3001\u53d8\u538b\u5668\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u5173\u952e\u7279\u5f81\u5bf9\u6d2a\u6c34\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4e86\u65f6\u7a7a\u56e0\u7d20\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5404\u7c7b\u65b9\u6cd5\u5728\u6355\u6349\u590d\u5408\u6d2a\u6c34\u4e2d\u7684\u590d\u6742\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u4e0a\u8868\u73b0\u4e0d\u540c\u3002", "conclusion": "\u591a\u79cd\u5efa\u6a21\u65b9\u6cd5\u5728\u6355\u6349\u590d\u5408\u6d2a\u6c34\u590d\u6742\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u4e0d\u540c\u7684\u80fd\u529b\uff0c\u8868\u660e\u8fd9\u4e9b\u65b9\u6cd5\u5177\u6709\u5f88\u5927\u7684\u6f5c\u529b\u7528\u4e8e\u6539\u5584\u6d2a\u6c34\u9884\u6d4b\u3002"}}
{"id": "2506.05252", "pdf": "https://arxiv.org/pdf/2506.05252", "abs": "https://arxiv.org/abs/2506.05252", "authors": ["Dravyansh Sharma", "Alec Sun"], "title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "categories": ["cs.LG", "cs.GT", "cs.MA"], "comment": "24 pages", "summary": "Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f53\u5206\u7c7b\u4ee3\u7406\u771f\u6b63\u6539\u8fdb\u4ee5\u83b7\u5f97\u66f4\u597d\u5206\u7c7b\u65f6\u7684\u5b66\u4e60\u7b97\u6cd5\u7279\u6027\uff0c\u5e76\u89e3\u51b3\u4e86Attias\u7b49\u63d0\u51fa\u7684\u5f00\u653e\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5728\u793e\u4f1a\u51b3\u7b56\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u666e\u904d\uff0c\u4e86\u89e3\u5206\u7c7b\u4ee3\u7406\u5982\u4f55\u5bf9\u5b66\u4e60\u7b97\u6cd5\u505a\u51fa\u53cd\u5e94\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u672c\u6587\u901a\u8fc7\u63a2\u8ba8\u4ee3\u7406\u771f\u6b63\u6539\u8fdb\u4ee5\u83b7\u5f97\u7406\u60f3\u5206\u7c7b\u7684\u5b66\u4e60\u7279\u6027\uff0c\u4ece\u800c\u4fc3\u8fdb\u5b66\u4e60\u7b97\u6cd5\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u901a\u8fc7\u4e0d\u5bf9\u79f0\u53d8\u4f53\u7684\u6700\u5c0f\u4e00\u81f4\u6982\u5ff5\u7c7b\uff0c\u5bf9\u73b0\u5b9e\u73af\u5883\u4e0b\u7684\u6539\u8fdb\u7684\u9002\u5f53\u5b66\u4e60\u8fdb\u884c\u4e86\u7cbe\u786e\u7684\u63cf\u8ff0\u3002", "result": "\u672c\u6587\u7ed9\u51fa\u4e86\u81ea\u7136\u7684\u6b27\u51e0\u91cc\u5f97\u7403\u6539\u5584\u96c6\u7684\u79ef\u6781\u7ed3\u679c\uff0c\u8868\u660e\u5728\u6570\u636e\u5206\u5e03\u4e0a\u7684\u8f7b\u5ea6\u751f\u6210\u5047\u8bbe\u4e0b\u7684\u975e\u6b63\u89c4\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u672c\u6587\u5728\u7814\u7a76\u826f\u597d\u7684\u6709\u754c\u566a\u58f0\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u8f83\u4f4e\u7684\u6cdb\u5316\u8bef\u5dee\uff0c\u5e76\u83b7\u5f97\u4e86\u53ef\u5b9e\u73b0\u548c\u4e0d\u53ef\u77e5\u5728\u7ebf\u5b66\u4e60\u4e2d\u7684\u9519\u8bef\u8fb9\u754c\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5b9e\u73b0\u73af\u5883\u4e0b\u901a\u8fc7\u4ee3\u7406\u771f\u6b63\u6539\u8fdb\u7684\u5b66\u4e60\u7b97\u6cd5\u7684\u53ef\u5b66\u4e60\u6027\uff0c\u672c\u6587\u901a\u8fc7\u5f15\u5165\u4e0d\u5bf9\u79f0\u7684\u6700\u5c0f\u4e00\u81f4\u6982\u5ff5\u7c7b\uff0c\u51c6\u786e\u5730\u63cf\u8ff0\u4e86\u6539\u8fdb\u7684\u9002\u5f53\u5b66\u4e60\u3002"}}
{"id": "2506.04409", "pdf": "https://arxiv.org/pdf/2506.04409", "abs": "https://arxiv.org/abs/2506.04409", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025, an ACL 2025 workshop", "summary": "This paper describes EmoRAG, a system designed to detect perceived emotions\nin text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We\nfocus on predicting the perceived emotions of the speaker from a given text\nsnippet, labeling it with emotions such as joy, sadness, fear, anger, surprise,\nand disgust. Our approach does not require additional model training and only\nuses an ensemble of models to predict emotions. EmoRAG achieves results\ncomparable to the best performing systems, while being more efficient,\nscalable, and easier to implement.", "AI": {"tldr": "EmoRAG is a system for detecting perceived emotions in text, using an ensemble of models without additional training. It is efficient, scalable, and achieves comparable results to top systems in emotion detection.", "motivation": "To detect perceived emotions in text efficiently and effectively for SemEval-2025 Task 11, Subtask A.", "method": "Uses an ensemble of models to predict emotions without requiring additional model training.", "result": "Achieves results comparable to the best performing systems in multi-label emotion detection of speaker emotions from text.", "conclusion": "EmoRAG is efficient, scalable, and easy to implement, achieving results comparable to the best systems in emotion detection."}}
{"id": "2506.04427", "pdf": "https://arxiv.org/pdf/2506.04427", "abs": "https://arxiv.org/abs/2506.04427", "authors": ["Xixi Wang", "Miguel Costa", "Jordanka Kovaceva", "Shuai Wang", "Francisco C. Pereira"], "title": "Plugging Schema Graph into Multi-Table QA: A Human-Guided Framework for Reducing LLM Reliance", "categories": ["cs.AI", "cs.CL"], "comment": "Submitted to EMNLP 2025", "summary": "Large language models (LLMs) have shown promise in table Question Answering\n(Table QA). However, extending these capabilities to multi-table QA remains\nchallenging due to unreliable schema linking across complex tables. Existing\nmethods based on semantic similarity work well only on simplified hand-crafted\ndatasets and struggle to handle complex, real-world scenarios with numerous and\ndiverse columns. To address this, we propose a graph-based framework that\nleverages human-curated relational knowledge to explicitly encode schema links\nand join paths. Given a natural language query, our method searches this graph\nto construct interpretable reasoning chains, aided by pruning and sub-path\nmerging strategies to enhance efficiency and coherence. Experiments on both\nstandard benchmarks and a realistic, large-scale dataset demonstrate the\neffectiveness of our approach. To our knowledge, this is the first multi-table\nQA system applied to truly complex industrial tabular data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u56fe\u5f62\u6846\u67b6\u6784\u5efa\u6709\u6548\u63a8\u7406\u94fe\u7684\u65b9\u6cd5\uff0c\u6539\u5584LLMs\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u591a\u8868\u95ee\u7b54\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6548\u679c\u663e\u8457\u3002", "motivation": "\u6269\u5c55LLMs\u7684\u80fd\u529b\u7528\u4e8e\u591a\u8868\u95ee\u7b54\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u96be\u4ee5\u5904\u7406\u4e0d\u53ef\u9760\u7684\u6a21\u5f0f\u94fe\u63a5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u5f62\u7684\u6846\u67b6\uff0c\u5229\u7528\u4eba\u7c7b\u7b56\u5212\u7684\u5173\u7cfb\u77e5\u8bc6\uff0c\u4ee5\u663e\u5f0f\u65b9\u5f0f\u7f16\u7801\u6a21\u5f0f\u94fe\u63a5\u548c\u8fde\u63a5\u8def\u5f84\uff0c\u5e76\u901a\u8fc7\u641c\u7d22\u56fe\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u94fe\uff0c\u8f85\u4ee5\u4fee\u526a\u548c\u5b50\u8def\u5f84\u5408\u5e76\u7b56\u7565\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u8fde\u8d2f\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u57fa\u51c6\u548c\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u5f62\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7801\u6a21\u5f0f\u94fe\u63a5\u548c\u8fde\u63a5\u8def\u5f84\u6765\u89e3\u51b3\u591a\u8868\u95ee\u7b54\u4e2d\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u57fa\u51c6\u548c\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u826f\u597d\uff0c\u6807\u5fd7\u7740\u9996\u6b21\u5728\u590d\u6742\u5de5\u4e1a\u8868\u683c\u6570\u636e\u4e2d\u5e94\u7528\u591a\u8868\u95ee\u7b54\u7cfb\u7edf\u3002"}}
{"id": "2506.04282", "pdf": "https://arxiv.org/pdf/2506.04282", "abs": "https://arxiv.org/abs/2506.04282", "authors": ["Runxiang Wang", "Boxiao Wang", "Kai Li", "Yifan Zhang", "Jian Cheng"], "title": "DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience", "categories": ["cs.LG"], "comment": null, "summary": "Symbolic regression is a fundamental tool for discovering interpretable\nmathematical expressions from data, with broad applications across scientific\nand engineering domains. Recently, large language models (LLMs) have\ndemonstrated strong performance in this task, leveraging embedded scientific\npriors and reasoning capabilities to surpass traditional methods. However,\nexisting LLM-based approaches, such as LLM-SR, often over-rely on internal\npriors, lacking explicit data understanding and systematic reflection during\nequation generation. To address these limitations, we propose DrSR (Dual\nReasoning Symbolic Regression), a framework that combines data-driven insight\nwith reflective learning to enhance both robustness and discovery capability.\nSpecifically, DrSR guides LLMs to analyze structural relationships (e.g.,\nmonotonicity, nonlinearity, and correlation) within the data to generate\nstructured descriptions. Simultaneously, it monitors equation performance and\nestablishes a feedback loop to refine subsequent generations. By integrating\ndata understanding and generation reflection in a closed loop, DrSR enables\nmore efficient exploration of the symbolic expression space. Experiments across\ninterdisciplinary datasets in physics, chemistry, biology, and materials\nscience demonstrate that DrSR substantially improves the valid equation rate\nand consistently outperforms both classical and recent LLM-based methods in\nterms of accuracy, generalization, and search efficiency. These results\nunderscore its potential for scientific equation discovery.", "AI": {"tldr": "DrSR\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u548c\u53cd\u601d\u5b66\u4e60\u6539\u5584\u7b26\u53f7\u56de\u5f52\u80fd\u529b\uff0c\u5728\u8de8\u5b66\u79d1\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u5176\u5728\u65b9\u7a0b\u53d1\u73b0\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u4e0a\u8d85\u8fc7\u4f20\u7edf\u548cLLM\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5982LLM-SR\u8fc7\u4e8e\u4f9d\u8d56\u5185\u90e8\u7684\u79d1\u5b66\u5148\u9a8c\u77e5\u8bc6\uff0c\u7f3a\u4e4f\u663e\u5f0f\u7684\u6570\u636e\u7406\u89e3\u548c\u7cfb\u7edf\u7684\u53cd\u601d\uff0c\u5f71\u54cd\u4e86\u65b9\u7a0b\u751f\u6210\u7684\u6548\u679c\u3002", "method": "DrSR\u5f15\u5bfcLLM\u5206\u6790\u6570\u636e\u4e2d\u7684\u7ed3\u6784\u5173\u7cfb\uff0c\u751f\u6210\u7ed3\u6784\u5316\u63cf\u8ff0\uff1b\u540c\u65f6\u76d1\u63a7\u65b9\u7a0b\u6027\u80fd\u5e76\u5efa\u7acb\u53cd\u9988\u73af\uff0c\u4ee5\u6539\u8fdb\u540e\u7eed\u751f\u6210\u8fc7\u7a0b\uff0c\u5f62\u6210\u6570\u636e\u7406\u89e3\u4e0e\u751f\u6210\u53cd\u601d\u7684\u95ed\u73af\u3002", "result": "DrSR\u5728\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u548c\u6750\u6599\u79d1\u5b66\u7684\u8de8\u5b66\u79d1\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cDrSR\u663e\u8457\u63d0\u9ad8\u4e86\u6709\u6548\u65b9\u7a0b\u7387\uff0c\u5e76\u5728\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u548c\u641c\u7d22\u6548\u7387\u4e0a\u8d85\u8fc7\u4e86\u7ecf\u5178\u548c\u8fd1\u671f\u7684LLM\u65b9\u6cd5\u3002", "conclusion": "DrSR\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u6d1e\u5bdf\u548c\u53cd\u601d\u5b66\u4e60\u63d0\u9ad8\u4e86\u7b26\u53f7\u56de\u5f52\u7684\u9c81\u68d2\u6027\u548c\u53d1\u73b0\u80fd\u529b\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u53ca\u73b0\u6709LLM\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u548c\u641c\u7d22\u6548\u7387\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u663e\u793a\u51fa\u5176\u5728\u79d1\u5b66\u65b9\u7a0b\u53d1\u73b0\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.05265", "pdf": "https://arxiv.org/pdf/2506.05265", "abs": "https://arxiv.org/abs/2506.05265", "authors": ["Mohammed Almutairi"], "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "categories": ["cs.HC", "cs.AI", "cs.MA"], "comment": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "summary": "Effective teamwork is essential across diverse domains. During the team\nformation stage, a key challenge is forming teams that effectively balance user\npreferences with task objectives to enhance overall team satisfaction. In the\nteam performing stage, maintaining cohesion and engagement is critical for\nsustaining high team performance. However, existing computational tools and\nalgorithms for team optimization often rely on static data inputs, narrow\nalgorithmic objectives, or solutions tailored for specific contexts, failing to\naccount for the dynamic interplay of team members personalities, evolving\ngoals, and changing individual preferences. Therefore, teams may encounter\nmember dissatisfaction, as purely algorithmic assignments can reduce members\ncommitment to team goals or experience suboptimal engagement due to the absence\nof timely, personalized guidance to help members adjust their behaviors and\ninteractions as team dynamics evolve. Ultimately, these challenges can lead to\nreduced overall team performance. My Ph.D. dissertation aims to develop\nAI-augmented team optimization frameworks and practical systems that enhance\nteam satisfaction, engagement, and performance. First, I propose a team\nformation framework that leverages a multi-armed bandit algorithm to\niteratively refine team composition based on user preferences, ensuring\nalignment between individual needs and collective team goals to enhance team\nsatisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an\nAI-powered system that utilizes large language models (LLMs) to deliver\nimmediate, personalized feedback to both teams and individual members,\nenhancing cohesion and engagement. Finally, I present PuppeteerLLM, an\nLLM-based simulation framework that simulates multi-agent teams to model\ncomplex team dynamics within realistic environments, incorporating task-driven\ncollaboration and long-term coordination.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1AI\u589e\u5f3a\u7684\u56e2\u961f\u4f18\u5316\u7cfb\u7edf\uff0c\u5305\u62ec\u56e2\u961f\u7ec4\u5efa\u6846\u67b6\u548c\u5373\u65f6\u53cd\u9988\u7cfb\u7edf\uff0c\u63d0\u5347\u56e2\u961f\u6ee1\u610f\u5ea6\u548c\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u56e2\u961f\u4f18\u5316\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u5904\u7406\u4e2a\u4f53\u504f\u597d\u548c\u56e2\u961f\u76ee\u6807\u4e4b\u95f4\u7684\u52a8\u6001\u5e73\u8861\uff0c\u5bfc\u81f4\u6210\u5458\u4e0d\u6ee1\u610f\u53ca\u56e2\u961f\u8868\u73b0\u4e0b\u964d\u3002\u7814\u7a76\u52a8\u673a\u662f\u5f00\u53d1\u80fd\u591f\u63d0\u9ad8\u56e2\u961f\u6ee1\u610f\u5ea6\u3001\u51dd\u805a\u529b\u548c\u7ee9\u6548\u7684AI\u589e\u5f3a\u56e2\u961f\u4f18\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u81c2\u8d4c\u535a\u7b97\u6cd5\u7528\u4e8e\u56e2\u961f\u7ec4\u6210\uff0c\u5e76\u5f15\u5165\u4e86\u540d\u4e3atAIfa\u7684\u7cfb\u7edf\uff0c\u5229\u7528LLMs\u63d0\u4f9b\u5373\u65f6\u53cd\u9988\u3002\u6b64\u5916\uff0c\u4f7f\u7528PuppeteerLLM\u6a21\u62df\u591a\u4ee3\u7406\u56e2\u961f\u7684\u52a8\u6001\u3002", "result": "\u6784\u5efa\u4e86AI\u589e\u5f3a\u7684\u56e2\u961f\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u56e2\u961f\u7ec4\u6210\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\uff0c\u63d0\u5347\u4e86\u56e2\u961f\u7684\u6574\u4f53\u8868\u73b0\u548c\u6210\u5458\u6ee1\u610f\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u591a\u81c2\u8d4c\u535a\u7b97\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u6280\u672f\uff0c\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u7684\u56e2\u961f\u4f18\u5316\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u56e2\u961f\u6ee1\u610f\u5ea6\u3001\u51dd\u805a\u529b\u548c\u8868\u73b0\u3002"}}
{"id": "2506.04458", "pdf": "https://arxiv.org/pdf/2506.04458", "abs": "https://arxiv.org/abs/2506.04458", "authors": ["Xueqiang Xu", "Jinfeng Xiao", "James Barry", "Mohab Elkaref", "Jiaru Zou", "Pengcheng Jiang", "Yunyi Zhang", "Max Giammona", "Geeth de Mel", "Jiawei Han"], "title": "Zero-Shot Open-Schema Entity Structure Discovery", "categories": ["cs.CL"], "comment": "14 pages, 3 figures", "summary": "Entity structure extraction, which aims to extract entities and their\nassociated attribute-value structures from text, is an essential task for text\nunderstanding and knowledge graph construction. Existing methods based on large\nlanguage models (LLMs) typically rely heavily on predefined entity attribute\nschemas or annotated datasets, often leading to incomplete extraction results.\nTo address these challenges, we introduce Zero-Shot Open-schema Entity\nStructure Discovery (ZOES), a novel approach to entity structure extraction\nthat does not require any schema or annotated samples. ZOES operates via a\nprincipled mechanism of enrichment, refinement, and unification, based on the\ninsight that an entity and its associated structure are mutually reinforcing.\nExperiments demonstrate that ZOES consistently enhances LLMs' ability to\nextract more complete entity structures across three different domains,\nshowcasing both the effectiveness and generalizability of the method. These\nfindings suggest that such an enrichment, refinement, and unification mechanism\nmay serve as a principled approach to improving the quality of LLM-based entity\nstructure discovery in various scenarios.", "AI": {"tldr": "ZOES is a novel approach enhancing entity structure extraction by using enrichment, refinement, and unification, eliminating the need for predefined schemas or datasets, and proving effective across multiple domains.", "motivation": "The motivation is to overcome the reliance on predefined schemas or annotated datasets, which often lead to incomplete extraction results in existing large language model-based methods.", "method": "ZOES utilizes an enrichment, refinement, and unification mechanism to enhance entity structure extraction.", "result": "Experiments show that ZOES significantly improves the extraction of entity structures in three domains, demonstrating its effectiveness and generalizability.", "conclusion": "ZOES improves LLMs' capability to extract more complete entity structures without the need for predefined schemas or annotated datasets, asserting its effectiveness and generalizability across various domains."}}
{"id": "2506.04429", "pdf": "https://arxiv.org/pdf/2506.04429", "abs": "https://arxiv.org/abs/2506.04429", "authors": ["Ananya Joshi", "Nolan Gormley", "Richa Gadgil", "Tina Townes", "Roni Rosenfeld", "Bryan Wilder"], "title": "An AI-Based Public Health Data Monitoring System", "categories": ["cs.AI"], "comment": null, "summary": "Public health experts need scalable approaches to monitor large volumes of\nhealth data (e.g., cases, hospitalizations, deaths) for outbreaks or data\nquality issues. Traditional alert-based monitoring systems struggle with modern\npublic health data monitoring systems for several reasons, including that\nalerting thresholds need to be constantly reset and the data volumes may cause\napplication lag. Instead, we propose a ranking-based monitoring paradigm that\nleverages new AI anomaly detection methods. Through a multi-year\ninterdisciplinary collaboration, the resulting system has been deployed at a\nnational organization to monitor up to 5,000,000 data points daily. A\nthree-month longitudinal deployed evaluation revealed a significant improvement\nin monitoring objectives, with a 54x increase in reviewer speed efficiency\ncompared to traditional alert-based methods. This work highlights the potential\nof human-centered AI to transform public health decision-making.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u57fa\u4e8eAI\u7684\u6392\u540d\u76d1\u63a7\u7cfb\u7edf\uff0c\u5927\u5e45\u63d0\u9ad8\u4e86\u516c\u5171\u536b\u751f\u6570\u636e\u76d1\u63a7\u7684\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u8b66\u62a5\u76d1\u63a7\u7cfb\u7edf\u5728\u5904\u7406\u73b0\u4ee3\u516c\u5171\u536b\u751f\u6570\u636e\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u9891\u7e41\u8c03\u6574\u544a\u8b66\u9608\u503c\uff0c\u5e76\u56e0\u6570\u636e\u91cf\u5927\u800c\u5bfc\u81f4\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u76d1\u63a7\u5927\u91cf\u536b\u751f\u6570\u636e\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6392\u540d\u7684\u76d1\u63a7\u8303\u5f0f\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u548cAI\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b9e\u73b0\uff0c\u800c\u975e\u4f20\u7edf\u7684\u9608\u503c\u8b66\u62a5\u7cfb\u7edf\u3002", "result": "\u90e8\u7f72\u5728\u56fd\u5bb6\u7ea7\u673a\u6784\u7684\u7cfb\u7edf\u6bcf\u5929\u76d1\u63a7\u591a\u8fbe500\u4e07\u4e2a\u6570\u636e\u70b9\uff0c\u5728\u88ab\u8bc4\u4f30\u7684\u4e09\u4e2a\u6708\u4e2d\uff0c\u4e0e\u4f20\u7edf\u8b66\u62a5\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8bc4\u5ba1\u901f\u5ea6\u6548\u7387\u63d0\u9ad8\u4e8654\u500d\uff0c\u663e\u8457\u6539\u5584\u4e86\u76d1\u63a7\u76ee\u6807\u3002", "conclusion": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u7c7b\u4e2d\u5fc3\u7684AI\u6280\u672f\u5728\u7a81\u53d1\u516c\u5171\u536b\u751f\u4e8b\u4ef6\u548c\u6570\u636e\u8d28\u91cf\u76d1\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.04285", "pdf": "https://arxiv.org/pdf/2506.04285", "abs": "https://arxiv.org/abs/2506.04285", "authors": ["Stephen Smith", "Cormac Purcell", "Zdenka Kuncic"], "title": "Training-free AI for Earth Observation Change Detection using Physics Aware Neuromorphic Networks", "categories": ["cs.LG"], "comment": "16 pages, 9 figures, 3 tables", "summary": "Earth observations from low Earth orbit satellites provide vital information\nfor decision makers to better manage time-sensitive events such as natural\ndisasters. For the data to be most effective for first responders, low latency\nis required between data capture and its arrival to decision makers. A major\nbottleneck is in the bandwidth-limited downlinking of the data from satellites\nto ground stations. One approach to overcome this challenge is to process at\nleast some of the data on-board and prioritise pertinent data to be downlinked.\nIn this work we propose a Physics Aware Neuromorphic Network (PANN) to detect\nchanges caused by natural disasters from a sequence of multi-spectral satellite\nimages and produce a change map, enabling relevant data to be prioritised for\ndownlinking. The PANN used in this study is motivated by physical neural\nnetworks comprised of nano-electronic circuit elements known as \"memristors\"\n(nonlinear resistors with memory). The weights in the network are dynamic and\nupdate in response to varying input signals according to memristor equations of\nstate and electrical circuit conservation laws. The PANN thus generates\nphysics-constrained dynamical output features which are used to detect changes\nin a natural disaster detection task by applying a distance-based metric.\nImportantly, this makes the whole model training-free, allowing it to be\nimplemented with minimal computing resources. The PANN was benchmarked against\na state-of-the-art AI model and achieved comparable or better results in each\nnatural disaster category. It thus presents a promising solution to the\nchallenge of resource-constrained on-board processing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdPhysics Aware Neuromorphic Network (PANN) \u7528\u4e8e\u63d0\u9ad8\u81ea\u7136\u707e\u5bb3\u68c0\u6d4b\u4e2d\u4ece\u536b\u661f\u5230\u5730\u9762\u7684\u6570\u636e\u4f18\u5148\u4e0b\u4f20\uff0c\u901a\u8fc7\u7269\u7406\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u8bad\u7ec3\u65e0\u5173\u3001\u4f4e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u4e14\u6548\u679c\u4f18\u4e8e\u4f20\u7edfAI\u6a21\u578b\u3002", "motivation": "\u4e3a\u89e3\u51b3\u536b\u661f\u6570\u636e\u5230\u5730\u9762\u7ad9\u7684\u5e26\u5bbd\u9650\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u536b\u661f\u4e0a\u8fdb\u884c\u6570\u636e\u5904\u7406\u5e76\u4f18\u5148\u4e0b\u4f20\u76f8\u5173\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7269\u7406\u611f\u77e5\u7f51\u7edc\uff08PANN\uff09\u6765\u5904\u7406\u591a\u5149\u8c31\u536b\u661f\u56fe\u50cf\u4ee5\u751f\u6210\u53d8\u5316\u56fe\uff0c\u4ece\u800c\u4f18\u5148\u4e0b\u4f20\u76f8\u5173\u6570\u636e\u3002PANN\u57fa\u4e8e\u7eb3\u7c73\u7535\u5b50\u7535\u8def\u5143\u4ef6\u201c\u5fc6\u963b\u5668\u201d\uff08\u5177\u6709\u8bb0\u5fc6\u7684\u975e\u7ebf\u6027\u7535\u963b\uff09\u7ec4\u6210\u7684\u7269\u7406\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u4e0e\u7269\u7406\u76f8\u5bb9\u7684\u52a8\u6001\u8f93\u51fa\u7279\u5f81\u8fdb\u884c\u81ea\u7136\u707e\u5bb3\u68c0\u6d4b\u3002", "result": "PANN\u4e0e\u6700\u5148\u8fdb\u7684AI\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u6bcf\u4e2a\u81ea\u7136\u707e\u5bb3\u7c7b\u522b\u4e2d\u53d6\u5f97\u4e86\u76f8\u5f53\u6216\u66f4\u597d\u7684\u7ed3\u679c\u3002", "conclusion": "PANN\u5728\u4e0e\u6700\u5148\u8fdb\u7684AI\u6a21\u578b\u7684\u6bd4\u8f83\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u673a\u8f7d\u5904\u7406\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.04462", "pdf": "https://arxiv.org/pdf/2506.04462", "abs": "https://arxiv.org/abs/2506.04462", "authors": ["Apurv Verma", "NhatHai Phan", "Shubhendu Trivedi"], "title": "Watermarking Degrades Alignment in Language Models: Analysis and Mitigation", "categories": ["cs.CL", "cs.CR", "cs.LG", "I.2.7"], "comment": "Published at the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025. OpenReview: https://openreview.net/forum?id=SIBkIV48gF", "summary": "Watermarking techniques for large language models (LLMs) can significantly\nimpact output quality, yet their effects on truthfulness, safety, and\nhelpfulness remain critically underexamined. This paper presents a systematic\nanalysis of how two popular watermarking approaches-Gumbel and KGW-affect these\ncore alignment properties across four aligned LLMs. Our experiments reveal two\ndistinct degradation patterns: guard attenuation, where enhanced helpfulness\nundermines model safety, and guard amplification, where excessive caution\nreduces model helpfulness. These patterns emerge from watermark-induced shifts\nin token distribution, surfacing the fundamental tension that exists between\nalignment objectives.\n  To mitigate these degradations, we propose Alignment Resampling (AR), an\ninference-time sampling method that uses an external reward model to restore\nalignment. We establish a theoretical lower bound on the improvement in\nexpected reward score as the sample size is increased and empirically\ndemonstrate that sampling just 2-4 watermarked generations effectively recovers\nor surpasses baseline (unwatermarked) alignment scores. To overcome the limited\nresponse diversity of standard Gumbel watermarking, our modified implementation\nsacrifices strict distortion-freeness while maintaining robust detectability,\nensuring compatibility with AR. Experimental results confirm that AR\nsuccessfully recovers baseline alignment in both watermarking approaches, while\nmaintaining strong watermark detectability. This work reveals the critical\nbalance between watermark strength and model alignment, providing a simple\ninference-time solution to responsibly deploy watermarked LLMs in practice.", "AI": {"tldr": "\u7814\u7a76\u6c34\u5370\u6280\u672f\u5bf9LLMs\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86AR\u65b9\u6cd5\u6062\u590d\u5bf9\u9f50\u6027\uff0c\u6709\u6548\u4e14\u4fdd\u6301\u6c34\u5370\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3\u6c34\u5370\u6280\u672f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u771f\u76f8\u6027\u3001\u5b89\u5168\u6027\u548c\u6709\u7528\u6027\u7b49\u6838\u5fc3\u5c5e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faAlignment Resampling (AR)\u65b9\u6cd5\uff0c\u5229\u7528\u5916\u90e8\u5956\u52b1\u6a21\u578b\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u91c7\u6837\uff0c\u6062\u590d\u6a21\u578b\u7684\u5bf9\u9f50\u6027\uff0c\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u5bf92-4\u4e2a\u6c34\u5370\u751f\u6210\u7ed3\u679c\u8fdb\u884c\u91c7\u6837\uff0c\u53ef\u4ee5\u6709\u6548\u6062\u590d\u6216\u8d85\u8fc7\u57fa\u7ebf\u7684\u5bf9\u9f50\u5206\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u70c8\u7684\u6c34\u5370\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u6c34\u5370\u5f3a\u5ea6\u548c\u6a21\u578b\u5bf9\u9f50\u6027\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u5730\u90e8\u7f72\u5e26\u6c34\u5370\u7684LLMs\u3002"}}
{"id": "2506.04478", "pdf": "https://arxiv.org/pdf/2506.04478", "abs": "https://arxiv.org/abs/2506.04478", "authors": ["Hadi Hosseini", "Samarth Khanna", "Ronak Singh"], "title": "Matching Markets Meet LLMs: Algorithmic Reasoning with Ranked Preferences", "categories": ["cs.AI", "cs.GT", "econ.TH", "I.2.6; I.2.11; J.4"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has driven progress in reasoning\ntasks -- from program synthesis to scientific hypothesis generation -- yet\ntheir ability to handle ranked preferences and structured algorithms in\ncombinatorial domains remains underexplored. We study matching markets, a core\nframework behind applications like resource allocation and ride-sharing, which\nrequire reconciling individual ranked preferences to ensure stable outcomes. We\nevaluate several state-of-the-art models on a hierarchy of preference-based\nreasoning tasks -- ranging from stable-matching generation to instability\ndetection, instability resolution, and fine-grained preference queries -- to\nsystematically expose their logical and algorithmic limitations in handling\nranked inputs. Surprisingly, even top-performing models with advanced reasoning\nstruggle to resolve instability in large markets, often failing to identify\nblocking pairs or execute algorithms iteratively. We further show that\nparameter-efficient fine-tuning (LoRA) significantly improves performance in\nsmall markets, but fails to bring about a similar improvement on large\ninstances, suggesting the need for more sophisticated strategies to improve\nLLMs' reasoning with larger-context inputs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5339\u914d\u5e02\u573a\u4e2d\u7684\u6392\u540d\u504f\u597d\u548c\u7ed3\u6784\u5316\u7b97\u6cd5\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u5927\u5e02\u573a\u4e2d\u6539\u5584\u63a8\u7406\u80fd\u529b\u9700\u8981\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u8fdb\u6b65\uff0c\u4f46\u5176\u5904\u7406\u7ec4\u5408\u9886\u57df\u4e2d\u6392\u540d\u504f\u597d\u548c\u7ed3\u6784\u5316\u7b97\u6cd5\u7684\u80fd\u529b\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bf9\u5f53\u524d\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u4e0d\u540c\u5c42\u6b21\u7684\u504f\u597d\u63a8\u7406\u4efb\u52a1\u8bc4\u4f30\uff0c\u5305\u62ec\u7a33\u5b9a\u5339\u914d\u751f\u6210\u3001\u4e0d\u7a33\u5b9a\u6027\u68c0\u6d4b\u3001\u4e0d\u7a33\u5b9a\u6027\u89e3\u51b3\u548c\u7ec6\u7c92\u5ea6\u504f\u597d\u67e5\u8be2\uff0c\u4ee5\u7cfb\u7edf\u5316\u5730\u63ed\u793a\u5b83\u4eec\u5728\u5904\u7406\u6392\u540d\u8f93\u5165\u65f6\u7684\u903b\u8f91\u548c\u7b97\u6cd5\u5c40\u9650\u6027\u3002", "result": "\u53d1\u73b0\u5373\u4fbf\u662f\u529f\u80fd\u5148\u8fdb\u7684\u9876\u5c16\u6a21\u578b\u5728\u5927\u5e02\u573a\u4e2d\u4e5f\u96be\u4ee5\u89e3\u51b3\u4e0d\u7a33\u5b9a\u6027\uff0c\u901a\u5e38\u65e0\u6cd5\u8bc6\u522b\u963b\u585e\u5bf9\u6216\u8fed\u4ee3\u6267\u884c\u7b97\u6cd5\u3002\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08LoRA\uff09\uff0c\u5728\u5c0f\u5e02\u573a\u4e2d\u7684\u8868\u73b0\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e2d\u672a\u80fd\u83b7\u5f97\u7c7b\u4f3c\u7684\u63d0\u5347\u3002", "conclusion": "\u5f53\u524d\u9876\u5c16\u7684\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u5339\u914d\u5e02\u573a\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5c24\u5176\u662f\u5728\u5927\u89c4\u6a21\u5e02\u573a\u4e2d\uff0c\u8fd9\u7a81\u663e\u4e86\u9700\u8981\u66f4\u590d\u6742\u7684\u7b56\u7565\u6765\u6539\u8fdb\u5bf9\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u8f93\u5165\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2506.04288", "pdf": "https://arxiv.org/pdf/2506.04288", "abs": "https://arxiv.org/abs/2506.04288", "authors": ["Jae Wan Park", "Junhyeok Kim", "Youngjun Jun", "Hyunah Ko", "Seong Jae Hwang"], "title": "Backbone Augmented Training for Adaptations", "categories": ["cs.LG"], "comment": null, "summary": "Adaptations facilitate efficient training of large backbone models, including\ndiffusion models for image generation and transformer-based language models.\nWhile various adaptation techniques enhance performance with minimal\ncomputational resources, limited adaptation data often leads to challenges in\ntraining. To address this, we focus on the enormous amount of backbone data\nused to pre-train the backbone models. We propose Backbone Augmented Training\n(BAT), a method that leverages backbone data to augment the adaptation dataset.\nFirst, we formulate and prove two mathematical key propositions: one\nestablishes the validity of BAT, while the other identifies a condition under\nwhich BAT benefits adaptation. Furthermore, we introduce an advanced data\nselection scheme that satisfies these propositions and present ALBAT algorithm\nto implement this approach. ALBAT efficiently enhances adaptation training in\nboth personalization and language generation tasks with scarce data.", "AI": {"tldr": "\u63d0\u51faBAT\u65b9\u6cd5\u5229\u7528\u4e3b\u5e72\u6570\u636e\u589e\u5f3a\u9002\u5e94\u6027\u8bad\u7ec3\uff0c\u5728\u4e2a\u6027\u5316\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u901a\u8fc7\u4f7f\u7528\u5927\u91cf\u7528\u4e8e\u8bad\u7ec3\u4e3b\u5e72\u6a21\u578b\u7684\u4e3b\u5e72\u6570\u636e\u6765\u7f13\u89e3\u56e0\u9002\u5e94\u6027\u6570\u636e\u6709\u9650\u800c\u5bfc\u81f4\u7684\u8bad\u7ec3\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3b\u5e72\u589e\u5f3a\u8bad\u7ec3\uff08BAT\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e3b\u5e72\u6570\u636e\u6765\u6269\u5145\u9002\u5e94\u6027\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7ALBAT\u7b97\u6cd5\u5b9e\u65bd\u8be5\u65b9\u6cd5\u3002", "result": "ALBAT\u7b97\u6cd5\u5728\u4e2a\u6027\u5316\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u4e2d\u589e\u5f3a\u4e86\u9002\u5e94\u6027\u8bad\u7ec3\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u5883\u4e0b\u3002", "conclusion": "\u5229\u7528\u4e3b\u5e72\u6570\u636e\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u9002\u5e94\u6027\u8bad\u7ec3\uff0c\u589e\u5f3a\u4e2a\u6027\u5316\u548c\u8bed\u8a00\u751f\u6210\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2506.04463", "pdf": "https://arxiv.org/pdf/2506.04463", "abs": "https://arxiv.org/abs/2506.04463", "authors": ["Zhaoxuan Tan", "Zheng Li", "Tianyi Liu", "Haodong Wang", "Hyokun Yun", "Ming Zeng", "Pei Chen", "Zhihan Zhang", "Yifan Gao", "Ruijie Wang", "Priyanka Nigam", "Bing Yin", "Meng Jiang"], "title": "Aligning Large Language Models with Implicit Preferences from User-Generated Content", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Main Conference", "summary": "Learning from preference feedback is essential for aligning large language\nmodels (LLMs) with human values and improving the quality of generated\nresponses. However, existing preference learning methods rely heavily on\ncurated data from humans or advanced LLMs, which is costly and difficult to\nscale. In this work, we present PUGC, a novel framework that leverages implicit\nhuman Preferences in unlabeled User-Generated Content (UGC) to generate\npreference data. Although UGC is not explicitly created to guide LLMs in\ngenerating human-preferred responses, it often reflects valuable insights and\nimplicit preferences from its creators that has the potential to address\nreaders' questions. PUGC transforms UGC into user queries and generates\nresponses from the policy model. The UGC is then leveraged as a reference text\nfor response scoring, aligning the model with these implicit preferences. This\napproach improves the quality of preference data while enabling scalable,\ndomain-specific alignment. Experimental results on Alpaca Eval 2 show that\nmodels trained with DPO and PUGC achieve a 9.37% performance improvement over\ntraditional methods, setting a 35.93% state-of-the-art length-controlled win\nrate using Mistral-7B-Instruct. Further studies highlight gains in reward\nquality, domain-specific alignment effectiveness, robustness against UGC\nquality, and theory of mind capabilities. Our code and dataset are available at\nhttps://zhaoxuan.info/PUGC.github.io/", "AI": {"tldr": "\u63d0\u51faPUGC\u6846\u67b6\uff0c\u4eceUGC\u63d0\u53d6\u9690\u6027\u504f\u597d\uff0c\u6539\u8fdb\u6a21\u578b\u54cd\u5e94\u8d28\u91cf\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\u53ca\u9886\u57df\u7279\u5b9a\u5bf9\u9f50\u7b49\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u504f\u597d\u5b66\u4e60\u65b9\u6cd5\u9700\u4f9d\u8d56\u4eba\u5de5\u6216\u5148\u8fdb\u5927\u6a21\u578b\u7684\u7cbe\u5fc3\u8bbe\u8ba1\u6570\u636e\uff0c\u800c\u8fd9\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u56e0\u6b64\uff0c\u5229\u7528\u65e0\u6807\u6ce8\u7684\u7528\u6237\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u9690\u6027\u4eba\u7c7b\u504f\u597d\uff0c\u751f\u6210\u504f\u597d\u6570\u636e\u662f\u4e00\u4e2a\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3aPUGC\u7684\u6846\u67b6\uff0c\u5c06\u7528\u6237\u751f\u6210\u5185\u5bb9\u8f6c\u5316\u4e3a\u7528\u6237\u67e5\u8be2\uff0c\u5e76\u751f\u6210\u7b56\u7565\u6a21\u578b\u7684\u54cd\u5e94\uff1bUGC\u4f5c\u4e3a\u53c2\u8003\u6587\u672c\u6765\u8bc4\u5206\u54cd\u5e94\uff0c\u4ece\u800c\u4f7f\u6a21\u578b\u4e0e\u9690\u6027\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u4f7f\u7528DPO\u548cPUGC\u8bad\u7ec3\u7684\u6a21\u578b\u5728Alpaca Eval 2\u6d4b\u8bd5\u4e2d\u6027\u80fd\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u9ad8\u4e869.37%\uff0c\u5e76\u521b\u9020\u4e8635.93%\u7684\u6700\u65b0\u957f\u5ea6\u63a7\u5236\u80dc\u7387\u3002\u7814\u7a76\u8fd8\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5956\u52b1\u8d28\u91cf\u3001\u9886\u57df\u7279\u5b9a\u5bf9\u9f50\u6709\u6548\u6027\u3001\u5bf9UGC\u8d28\u91cf\u7684\u9c81\u68d2\u6027\u53ca\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528PUGC\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u4eba\u4e3a\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u7528\u6237\u751f\u6210\u5185\u5bb9\u4e2d\u63d0\u53d6\u9690\u6027\u504f\u597d\uff0c\u63d0\u9ad8\u6a21\u578b\u751f\u6210\u7ed3\u679c\u7684\u8d28\u91cf\u548c\u9886\u57df\u7279\u5b9a\u7684\u5bf9\u9f50\u6548\u679c\u3002"}}
{"id": "2506.04481", "pdf": "https://arxiv.org/pdf/2506.04481", "abs": "https://arxiv.org/abs/2506.04481", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "categories": ["cs.AI"], "comment": null, "summary": "Although large language models (LLMs) show promise in solving complex\nmathematical tasks, existing evaluation paradigms rely solely on a coarse\nmeasure of overall answer accuracy, which are insufficient for assessing their\nauthentic capabilities. In this paper, we propose \\textbf{CogMath}, which\ncomprehensively assesses LLMs' mathematical abilities through the lens of human\ncognition. Specifically, inspired by psychological theories, CogMath formalizes\nhuman reasoning process into 3 stages: \\emph{problem comprehension},\n\\emph{problem solving}, and \\emph{solution summarization}. Within these stages,\nwe investigate perspectives such as numerical calculation, knowledge, and\ncounterfactuals, and design a total of 9 fine-grained evaluation dimensions. In\neach dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}''\nmulti-agent system to generate inquiries that assess LLMs' mastery from this\ndimension. An LLM is considered to truly master a problem only when excelling\nin all inquiries from the 9 dimensions. By applying CogMath on three\nbenchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs\nare overestimated by 30\\%-40\\%. Moreover, we locate their strengths and\nweaknesses across specific stages/dimensions, offering in-depth insights to\nfurther enhance their reasoning abilities.", "AI": {"tldr": "CogMath\u8bc4\u4f30\u6846\u67b6\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u80fd\u529b\u88ab\u9ad8\u4f30\uff0c\u5e76\u63d0\u4f9b\u4e86\u7cbe\u786e\u8bc4\u4f30\u5176\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6df1\u523b\u89c1\u89e3\u3002", "motivation": "\u4e3a\u4e86\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u7ec6\u5316\u3001\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86CogMath\u8bc4\u4f30\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\uff0c\u901a\u8fc7\u4e09\u4e2a\u9636\u6bb5\u548c\u4e5d\u4e2a\u7ec6\u5316\u8bc4\u4f30\u7ef4\u5ea6\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u80fd\u529b\u3002", "result": "\u901a\u8fc7CogMath\u6846\u67b6\u8bc4\u4f30\uff0c\u53d1\u73b0\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u80fd\u529b\u88ab\u9ad8\u4f30\u4e8630%-40%\uff0c\u5e76\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u7279\u5b9a\u9636\u6bb5\u548c\u7ef4\u5ea6\u4e0a\u7684\u5f3a\u9879\u548c\u5f31\u9879\u3002", "conclusion": "CogMath\u5c55\u793a\u4e86\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u80fd\u529b\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u7cbe\u7ec6\u5316\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5176\u771f\u5b9e\u80fd\u529b\u3002"}}
{"id": "2506.04289", "pdf": "https://arxiv.org/pdf/2506.04289", "abs": "https://arxiv.org/abs/2506.04289", "authors": ["Jesse Geerts", "Stephanie Chan", "Claudia Clopath", "Kimberly Stachenfeld"], "title": "Relational reasoning and inductive bias in transformers trained on a transitive inference task", "categories": ["cs.LG", "q-bio.NC"], "comment": "13 pages, 6 figures", "summary": "Transformer-based models have demonstrated remarkable reasoning abilities,\nbut the mechanisms underlying relational reasoning in different learning\nregimes remain poorly understood. In this work, we investigate how transformers\nperform a classic relational reasoning task from the Psychology literature,\n\\textit{transitive inference}, which requires inference about indirectly\nrelated items by integrating information across observed adjacent item pairs\n(e.g., if A>B and B>C, then A>C). We compare transitive inference behavior\nacross two distinct learning regimes: in-weights learning (IWL), where models\nstore information in network parameters, and in-context learning (ICL), where\nmodels flexibly utilize information presented within the input sequence. Our\nfindings reveal that IWL naturally induces a generalization bias towards\ntransitive inference, despite being trained only on adjacent items, whereas ICL\nmodels trained solely on adjacent items do not generalize transitively.\nMechanistic analysis shows that ICL models develop induction circuits that\nimplement a simple match-and-copy strategy that performs well at relating\nadjacent pairs, but does not encoding hierarchical relationships among\nindirectly related items. Interestingly, when pre-trained on in-context linear\nregression tasks, transformers successfully exhibit in-context generalizable\ntransitive inference. Moreover, like IWL, they display both \\textit{symbolic\ndistance} and \\textit{terminal item effects} characteristic of human and animal\nperformance, without forming induction circuits. These results suggest that\npre-training on tasks with underlying structure promotes the development of\nrepresentations that can scaffold in-context relational reasoning.", "AI": {"tldr": "\u7814\u7a76Transformer\u5728\u4e0d\u540c\u5b66\u4e60\u6a21\u5f0f\u4e0b\u7684\u4f20\u9012\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u53ef\u4ee5\u6539\u5584\u4e0a\u4e0b\u6587\u6a21\u5f0f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u7814\u7a76Transformer\u5728\u4e0d\u540c\u5b66\u4e60\u6a21\u5f0f\u4e0b\u7684\u5173\u7cfb\u63a8\u7406\u673a\u5236\u4e0d\u660e\u663e\uff0c\u5c24\u5176\u662f\u5728\u5fc3\u7406\u5b66\u7ecf\u5178\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76Transformer\u5982\u4f55\u5728\u6743\u91cd\u5b66\u4e60\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e24\u79cd\u6a21\u5f0f\u4e0b\u6267\u884c\u4f20\u9012\u63a8\u7406\u4efb\u52a1\u3002", "result": "\u6743\u91cd\u5b66\u4e60\u5728\u4ec5\u57fa\u4e8e\u76f8\u90bb\u9879\u7684\u8bad\u7ec3\u4e2d\u81ea\u7136\u503e\u5411\u4e8e\u4f20\u9012\u6027\u63a8\u7406\uff0c\u800c\u53ea\u63a5\u53d7\u76f8\u90bb\u9879\u8bad\u7ec3\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6a21\u578b\u4e0d\u8868\u73b0\u51fa\u4f20\u9012\u6027\u63a8\u7406\u3002\u9884\u8bad\u7ec3\u4efb\u52a1\u53ef\u4ee5\u4fc3\u8fdb\u4e0a\u4e0b\u6587\u5173\u7cfb\u63a8\u7406\u7684\u53d1\u5c55\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\uff0c\u63ed\u793a\u4e86Transformer\u5728\u4e0d\u540c\u5b66\u4e60\u6a21\u5f0f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u5dee\u5f02\uff0c\u5e76\u6f14\u793a\u4e86\u8bad\u7ec3\u4efb\u52a1\u7684\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\u3002"}}
{"id": "2506.04494", "pdf": "https://arxiv.org/pdf/2506.04494", "abs": "https://arxiv.org/abs/2506.04494", "authors": ["Yue Gong", "Chuan Lei", "Xiao Qin", "Kapil Vaidya", "Balakrishnan Narayanaswamy", "Tim Kraska"], "title": "SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL", "categories": ["cs.CL"], "comment": null, "summary": "Text-to-SQL systems translate natural language (NL) questions into SQL\nqueries, enabling non-technical users to interact with structured data. While\nlarge language models (LLMs) have shown promising results on the text-to-SQL\ntask, they often produce semantically incorrect yet syntactically valid\nqueries, with limited insight into their reliability. We propose SQLens, an\nend-to-end framework for fine-grained detection and correction of semantic\nerrors in LLM-generated SQL. SQLens integrates error signals from both the\nunderlying database and the LLM to identify potential semantic errors within\nSQL clauses. It further leverages these signals to guide query correction.\nEmpirical results on two public benchmarks show that SQLens outperforms the\nbest LLM-based self-evaluation method by 25.78% in F1 for error detection, and\nimproves execution accuracy of out-of-the-box text-to-SQL systems by up to 20%.", "AI": {"tldr": "SQLens\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684SQL\u8bed\u53e5\u7684\u8bed\u4e49\u9519\u8bef\u68c0\u6d4b\u4e0e\u4fee\u6b63\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9519\u8bef\u68c0\u6d4b\u548c\u6267\u884c\u7cbe\u5ea6\u3002", "motivation": "\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728text-to-SQL\u4efb\u52a1\u4e2d\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e38\u4ea7\u751f\u8bed\u4e49\u4e0d\u6b63\u786e\u4f46\u8bed\u6cd5\u6709\u6548\u7684\u67e5\u8be2\uff0c\u56e0\u800c\u9700\u8981\u63d0\u9ad8\u5176\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faSQLens\uff0c\u4e00\u4e2a\u7528\u4e8e\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u548c\u4fee\u6b63\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684SQL\u8bed\u53e5\u4e2d\u8bed\u4e49\u9519\u8bef\u7684\u6846\u67b6\u3002SQLens\u7ed3\u5408\u5e95\u5c42\u6570\u636e\u5e93\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u4fe1\u53f7\uff0c\u8bc6\u522bSQL\u5b50\u53e5\u4e2d\u7684\u6f5c\u5728\u8bed\u4e49\u9519\u8bef\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u4fe1\u53f7\u6307\u5bfc\u67e5\u8be2\u4fee\u6b63\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cSQLens\u5728\u4e24\u4e2a\u516c\u5171\u57fa\u51c6\u4e0a\u6bd4\u6700\u4f73\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u8bc4\u65b9\u6cd5\u5728\u9519\u8bef\u68c0\u6d4bF1\u503c\u4e0a\u63d0\u5347\u4e8625.78%\uff0c\u5e76\u63d0\u5347text-to-SQL\u7cfb\u7edf\u7684\u6267\u884c\u7cbe\u5ea6\u6700\u9ad8\u8fbe20%\u3002", "conclusion": "SQLens\u80fd\u591f\u6709\u6548\u5730\u68c0\u6d4b\u548c\u4fee\u6b63\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684SQL\u8bed\u53e5\u4e2d\u7684\u8bed\u4e49\u9519\u8bef\uff0c\u63d0\u9ad8\u4e86text-to-SQL\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.04500", "pdf": "https://arxiv.org/pdf/2506.04500", "abs": "https://arxiv.org/abs/2506.04500", "authors": ["Aladin Djuhera", "Amin Seffo", "Masataro Asai", "Holger Boche"], "title": "\"Don't Do That!\": Guiding Embodied Systems through Large Language Model-based Constraint Generation", "categories": ["cs.AI", "cs.RO"], "comment": "Preprint; under review", "summary": "Recent advancements in large language models (LLMs) have spurred interest in\nrobotic navigation that incorporates complex spatial, mathematical, and\nconditional constraints from natural language into the planning problem. Such\nconstraints can be informal yet highly complex, making it challenging to\ntranslate into a formal description that can be passed on to a planning\nalgorithm. In this paper, we propose STPR, a constraint generation framework\nthat uses LLMs to translate constraints (expressed as instructions on ``what\nnot to do'') into executable Python functions. STPR leverages the LLM's strong\ncoding capabilities to shift the problem description from language into\nstructured and transparent code, thus circumventing complex reasoning and\navoiding potential hallucinations. We show that these LLM-generated functions\naccurately describe even complex mathematical constraints, and apply them to\npoint cloud representations with traditional search algorithms. Experiments in\na simulated Gazebo environment show that STPR ensures full compliance across\nseveral constraints and scenarios, while having short runtimes. We also verify\nthat STPR can be used with smaller, code-specific LLMs, making it applicable to\na wide range of compact models at low inference cost.", "AI": {"tldr": "STPR\u6846\u67b6\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u590d\u6742\u81ea\u7136\u8bed\u8a00\u7ea6\u675f\u8f6c\u5316\u4e3aPython\u51fd\u6570\uff0c\u5b9e\u73b0\u673a\u5668\u4eba\u5bfc\u822a\u4e2d\u7684\u5408\u89c4\u6027\u548c\u4f4e\u6210\u672c\u63a8\u7406\u3002", "motivation": "\u7531\u4e8e\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u7ea6\u675f\u5f80\u5f80\u590d\u6742\u4e14\u975e\u6b63\u5f0f\uff0c\u56e0\u6b64\u5f88\u96be\u5c06\u5176\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u63cf\u8ff0\u4ee5\u4f9b\u89c4\u5212\u7b97\u6cd5\u4f7f\u7528\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSTPR\u7684\u7ea6\u675f\u751f\u6210\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u7ea6\u675f\u7ffb\u8bd1\u4e3a\u53ef\u6267\u884c\u7684Python\u51fd\u6570\uff0c\u5e76\u5e94\u7528\u4e8e\u70b9\u4e91\u8868\u793a\u548c\u4f20\u7edf\u641c\u7d22\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7Gazebo\u6a21\u62df\u73af\u5883\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0cSTPR\u5728\u591a\u79cd\u7ea6\u675f\u548c\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u652f\u6301\u8f83\u5c0f\u7684\u3001\u7279\u5b9a\u4e8e\u4ee3\u7801\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f7f\u7528\uff0c\u5177\u6709\u8f83\u4f4e\u7684\u63a8\u7406\u6210\u672c\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSTPR\u80fd\u591f\u5728\u590d\u6742\u7ea6\u675f\u548c\u573a\u666f\u4e0b\u786e\u4fdd\u5b8c\u5168\u7684\u5408\u89c4\u6027\uff0c\u540c\u65f6\u5177\u6709\u8f83\u77ed\u7684\u8fd0\u884c\u65f6\u95f4\u3002"}}
{"id": "2506.04291", "pdf": "https://arxiv.org/pdf/2506.04291", "abs": "https://arxiv.org/abs/2506.04291", "authors": ["Wenhan Xu", "Jiashuo Jiang", "Lei Deng", "Danny Hin-Kwok Tsang"], "title": "A Lyapunov Drift-Plus-Penalty Method Tailored for Reinforcement Learning with Queue Stability", "categories": ["cs.LG"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "With the proliferation of Internet of Things (IoT) devices, the demand for\naddressing complex optimization challenges has intensified. The Lyapunov\nDrift-Plus-Penalty algorithm is a widely adopted approach for ensuring queue\nstability, and some research has preliminarily explored its integration with\nreinforcement learning (RL). In this paper, we investigate the adaptation of\nthe Lyapunov Drift-Plus-Penalty algorithm for RL applications, deriving an\neffective method for combining Lyapunov Drift-Plus-Penalty with RL under a set\nof common and reasonable conditions through rigorous theoretical analysis.\nUnlike existing approaches that directly merge the two frameworks, our proposed\nalgorithm, termed Lyapunov drift-plus-penalty method tailored for reinforcement\nlearning with queue stability (LDPTRLQ) algorithm, offers theoretical\nsuperiority by effectively balancing the greedy optimization of Lyapunov\nDrift-Plus-Penalty with the long-term perspective of RL. Simulation results for\nmultiple problems demonstrate that LDPTRLQ outperforms the baseline methods\nusing the Lyapunov drift-plus-penalty method and RL, corroborating the validity\nof our theoretical derivations. The results also demonstrate that our proposed\nalgorithm outperforms other benchmarks in terms of compatibility and stability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aLDPTRLQ\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06Lyapunov\u6f02\u79fb\u52a0\u7f5a\u7b97\u6cd5\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\u6765\u89e3\u51b3\u961f\u5217\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u7531\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u7684\u6fc0\u589e\uff0c\u5bf9\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\u7684\u9700\u6c42\u52a0\u5267\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861Lyapunov\u6f02\u79fb\u52a0\u7f5a\u7b97\u6cd5\u8d2a\u5a6a\u4f18\u5316\u4e0e\u5f3a\u5316\u5b66\u4e60\u957f\u8fdc\u89c6\u89d2\u7684\u65b9\u6cd5\u3002", "method": "\u5c06Lyapunov\u6f02\u79fb\u52a0\u7f5a\u7b97\u6cd5\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u961f\u5217\u7a33\u5b9aLyapunov\u6f02\u79fb\u52a0\u7f5a\u65b9\u6cd5\uff08LDPTRLQ\u7b97\u6cd5\uff09\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0cLDPTRLQ\u7b97\u6cd5\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u517c\u5bb9\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6211\u4eec\u7684LDPTRLQ\u7b97\u6cd5\u4f18\u4e8e\u4f7f\u7528Lyapunov\u6f02\u79fb\u52a0\u7f5a\u7b97\u6cd5\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u63a8\u5bfc\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.04516", "pdf": "https://arxiv.org/pdf/2506.04516", "abs": "https://arxiv.org/abs/2506.04516", "authors": ["Kun Zhao", "Bohao Yang", "Chen Tang", "Siyuan Dai", "Haoteng Tang", "Chenghua Lin", "Liang Zhan"], "title": "DRE: An Effective Dual-Refined Method for Integrating Small and Large Language Models in Open-Domain Dialogue Evaluation", "categories": ["cs.CL"], "comment": "arXiv admin note: text overlap with arXiv:2405.15924", "summary": "Large Language Models (LLMs) excel at many tasks but struggle with ambiguous\nscenarios where multiple valid responses exist, often yielding unreliable\nresults. Conversely, Small Language Models (SLMs) demonstrate robustness in\nsuch scenarios but are susceptible to misleading or adversarial inputs. We\nobserved that LLMs handle negative examples effectively, while SLMs excel with\npositive examples. To leverage their complementary strengths, we introduce\nSLIDE (Small and Large Integrated for Dialogue Evaluation), a method\nintegrating SLMs and LLMs via adaptive weighting. Building on SLIDE, we further\npropose a Dual-Refinement Evaluation (DRE) method to enhance SLM-LLM\nintegration: (1) SLM-generated insights guide the LLM to produce initial\nevaluations; (2) SLM-derived adjustments refine the LLM's scores for improved\naccuracy. Experiments demonstrate that DRE outperforms existing methods,\nshowing stronger alignment with human judgment across diverse benchmarks. This\nwork illustrates how combining small and large models can yield more reliable\nevaluation tools, particularly for open-ended tasks such as dialogue\nevaluation.", "AI": {"tldr": "\u7ed3\u5408SLM\u548cLLM\u7684\u65b9\u6cd5\uff08SLIDE\u548cDRE\uff09\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "LLMs\u5728\u5904\u7406\u6a21\u7cca\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800cSLMs\u5728\u53d7\u5230\u8bef\u5bfc\u6216\u5bf9\u6297\u6027\u8f93\u5165\u65f6\u6613\u53d7\u5f71\u54cd\u3002\u4e3a\u4e86\u5229\u7528\u5b83\u4eec\u7684\u4e92\u8865\u4f18\u70b9\uff0c\u9700\u8981\u7ed3\u5408SLM\u548cLLM\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86SLIDE\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u52a0\u6743\u7ed3\u5408SLM\u548cLLM\uff0c\u5e76\u8fdb\u4e00\u6b65\u63d0\u51fa\u53cc\u91cd\u7ec6\u5316\u8bc4\u4f30\uff08DRE\uff09\u65b9\u6cd5\uff0c\u5229\u7528SLM\u751f\u6210\u7684\u6d1e\u5bdf\u6307\u5bfcLLM\u7684\u521d\u6b65\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7SLM\u6539\u8fdbLLM\u7684\u5f97\u5206\uff0c\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDRE\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u57fa\u51c6\u4e0a\u663e\u793a\u51fa\u4e0e\u4eba\u7c7b\u5224\u65ad\u66f4\u5f3a\u7684\u5bf9\u9f50\u6027\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u5c0f\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\u548cLLM\uff09\uff0c\u53ef\u4ee5\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u6027\u4efb\u52a1\uff08\u5982\u5bf9\u8bdd\u8bc4\u4f30\uff09\u4e2d\u3002"}}
{"id": "2506.04512", "pdf": "https://arxiv.org/pdf/2506.04512", "abs": "https://arxiv.org/abs/2506.04512", "authors": ["Bohui Zhang", "Yuan He", "Lydia Pintscher", "Albert Mero\u00f1o Pe\u00f1uela", "Elena Simperl"], "title": "Schema Generation for Large Knowledge Graphs Using Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Schemas are vital for ensuring data quality in the Semantic Web and natural\nlanguage processing. Traditionally, their creation demands substantial\ninvolvement from knowledge engineers and domain experts. Leveraging the\nimpressive capabilities of large language models (LLMs) in related tasks like\nontology engineering, we explore automatic schema generation using LLMs. To\nbridge the resource gap, we introduce two datasets: YAGO Schema and Wikidata\nEntitySchema, along with evaluation metrics. The LLM-based pipelines\neffectively utilize local and global information from knowledge graphs (KGs) to\ngenerate validating schemas in Shape Expressions (ShEx). Experiments\ndemonstrate LLMs' strong potential in producing high-quality ShEx schemas,\npaving the way for scalable, automated schema generation for large KGs.\nFurthermore, our benchmark introduces a new challenge for structured\ngeneration, pushing the limits of LLMs on syntactically rich formalisms.", "AI": {"tldr": "The paper explores using LLMs for automatic schema generation, introduces new datasets and metrics, and shows LLMs' effectiveness in generating schemas for large knowledge graphs.", "motivation": "To explore automatic schema generation using LLMs due to their impressive capabilities in ontology engineering.", "method": "LLM-based pipelines utilizing local and global information from knowledge graphs to generate schemas in Shape Expressions (ShEx).", "result": "Experiments demonstrate the effectiveness of LLMs in producing high-quality ShEx schemas.", "conclusion": "LLMs exhibit strong potential in automated schema generation for large KGs."}}
{"id": "2506.04293", "pdf": "https://arxiv.org/pdf/2506.04293", "abs": "https://arxiv.org/abs/2506.04293", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Clinical trials are critical for advancing medical treatments but remain\nprohibitively expensive and time-consuming. Accurate prediction of clinical\ntrial outcomes can significantly reduce research and development costs and\naccelerate drug discovery. While recent deep learning models have shown promise\nby leveraging unstructured data, their black-box nature, lack of\ninterpretability, and vulnerability to label leakage limit their practical use\nin high-stakes biomedical contexts. In this work, we propose AutoCT, a novel\nframework that combines the reasoning capabilities of large language models\nwith the explainability of classical machine learning. AutoCT autonomously\ngenerates, evaluates, and refines tabular features based on public information\nwithout human input. Our method uses Monte Carlo Tree Search to iteratively\noptimize predictive performance. Experimental results show that AutoCT performs\non par with or better than SOTA methods on clinical trial prediction tasks\nwithin only a limited number of self-refinement iterations, establishing a new\nparadigm for scalable, interpretable, and cost-efficient clinical trial\nprediction.", "AI": {"tldr": "AutoCT\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7ecf\u5178\u673a\u5668\u5b66\u4e60\uff0c\u4f18\u5316\u4e34\u5e8a\u8bd5\u9a8c\u9884\u6d4b\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u548c\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u63d0\u9ad8\u4e34\u5e8a\u8bd5\u9a8c\u7ed3\u679c\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4ee5\u964d\u4f4e\u7814\u53d1\u6210\u672c\u5e76\u52a0\u5feb\u836f\u7269\u53d1\u73b0\u8fdb\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAutoCT\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4f7f\u7528\u8499\u7279\u5361\u7f57\u6811\u641c\u7d22\u8fed\u4ee3\u4f18\u5316\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAutoCT\u5728\u4e34\u5e8a\u8bd5\u9a8c\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u4e14\u4ec5\u9700\u6709\u9650\u7684\u81ea\u6211\u6539\u8fdb\u8fed\u4ee3\u3002", "conclusion": "AutoCT\u4e3a\u5927\u89c4\u6a21\u3001\u53ef\u89e3\u91ca\u4e14\u6210\u672c\u9ad8\u6548\u7684\u4e34\u5e8a\u8bd5\u9a8c\u9884\u6d4b\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2506.04521", "pdf": "https://arxiv.org/pdf/2506.04521", "abs": "https://arxiv.org/abs/2506.04521", "authors": ["Di Wu", "Seth Aycock", "Christof Monz"], "title": "Please Translate Again: Two Simple Experiments on Whether Human-Like Reasoning Helps Translation", "categories": ["cs.CL"], "comment": "16 pages, 16 figures", "summary": "Large Language Models (LLMs) demonstrate strong reasoning capabilities for\nmany tasks, often by explicitly decomposing the task via Chain-of-Thought (CoT)\nreasoning. Recent work on LLM-based translation designs hand-crafted prompts to\ndecompose translation, or trains models to incorporate intermediate\nsteps.~\\textit{Translating Step-by-step}~\\citep{briakou2024translating}, for\ninstance, introduces a multi-step prompt with decomposition and refinement of\ntranslation with LLMs, which achieved state-of-the-art results on WMT24. In\nthis work, we scrutinise this strategy's effectiveness. Empirically, we find no\nclear evidence that performance gains stem from explicitly decomposing the\ntranslation process, at least for the models on test; and we show that simply\nprompting LLMs to ``translate again'' yields even better results than\nhuman-like step-by-step prompting. Our analysis does not rule out the role of\nreasoning, but instead invites future work exploring the factors for CoT's\neffectiveness in the context of translation.", "AI": {"tldr": "\u9010\u6b65\u7ffb\u8bd1\u7684\u624b\u6bb5\u5e76\u672a\u8868\u73b0\u51fa\u9884\u671f\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7b80\u5316\u4e3a\u76f4\u63a5\u63d0\u793a\u201c\u518d\u6b21\u7ffb\u8bd1\u201d\u6548\u679c\u66f4\u4f73\u3002", "motivation": "\u63a2\u8ba8LLM\uff08\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u5728\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u4e3b\u5f20\u8fdb\u4e00\u6b65\u7814\u7a76\u5f71\u54cdCoT\u5728\u7ffb\u8bd1\u4e2d\u7684\u6709\u6548\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u6570\u636e\u7684\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u5229\u7528\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u8fdb\u884c\u4efb\u52a1\u5206\u89e3\u7684\u7ffb\u8bd1\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "result": "\u6ca1\u6709\u660e\u786e\u8bc1\u636e\u8868\u660e\u5728\u6d4b\u8bd5\u6a21\u578b\u4e2d\u901a\u8fc7\u660e\u786e\u5206\u89e3\u7ffb\u8bd1\u8fc7\u7a0b\u80fd\u591f\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5206\u6790\u8868\u660e\uff0c\u5728\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\uff0c\u4ec5\u901a\u8fc7\u7b80\u5355\u5730\u63d0\u793aLLMs\u201c\u518d\u6b21\u7ffb\u8bd1\u201d\u6bd4\u4f9d\u8d56\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u9010\u6b65\u7ffb\u8bd1\u65b9\u5f0f\u6548\u679c\u66f4\u597d\u3002"}}
{"id": "2506.04571", "pdf": "https://arxiv.org/pdf/2506.04571", "abs": "https://arxiv.org/abs/2506.04571", "authors": ["Srikanth Thudumu", "Jason Fisher"], "title": "OpenAg: Democratizing Agricultural Intelligence", "categories": ["cs.AI"], "comment": "10 pages, 1 figure", "summary": "Agriculture is undergoing a major transformation driven by artificial\nintelligence (AI), machine learning, and knowledge representation technologies.\nHowever, current agricultural intelligence systems often lack contextual\nunderstanding, explainability, and adaptability, especially for smallholder\nfarmers with limited resources. General-purpose large language models (LLMs),\nwhile powerful, typically lack the domain-specific knowledge and contextual\nreasoning needed for practical decision support in farming. They tend to\nproduce recommendations that are too generic or unrealistic for real-world\napplications. To address these challenges, we present OpenAg, a comprehensive\nframework designed to advance agricultural artificial general intelligence\n(AGI). OpenAg combines domain-specific foundation models, neural knowledge\ngraphs, multi-agent reasoning, causal explainability, and adaptive transfer\nlearning to deliver context-aware, explainable, and actionable insights. The\nsystem includes: (i) a unified agricultural knowledge base that integrates\nscientific literature, sensor data, and farmer-generated knowledge; (ii) a\nneural agricultural knowledge graph for structured reasoning and inference;\n(iii) an adaptive multi-agent reasoning system where AI agents specialize and\ncollaborate across agricultural domains; and (iv) a causal transparency\nmechanism that ensures AI recommendations are interpretable, scientifically\ngrounded, and aligned with real-world constraints. OpenAg aims to bridge the\ngap between scientific knowledge and the tacit expertise of experienced farmers\nto support scalable and locally relevant agricultural decision-making.", "AI": {"tldr": "OpenAg\u662f\u4e00\u4e2a\u5168\u9762\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u6280\u672f\u6765\u6539\u5584\u519c\u4e1a\u4eba\u5de5\u667a\u80fd\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u65e8\u5728\u652f\u6301\u5c0f\u519c\u6237\u7684\u53ef\u6269\u5c55\u519c\u4e1a\u51b3\u7b56\u3002", "motivation": "\u5f53\u524d\u519c\u4e1a\u667a\u80fd\u7cfb\u7edf\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7406\u89e3\u529b\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9002\u5e94\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u5c0f\u519c\u6237\u3002\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u5e38\u7f3a\u4e4f\u519c\u4e1a\u9886\u57df\u7684\u7279\u5b9a\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u5bfc\u81f4\u5efa\u8bae\u8fc7\u4e8e\u6cdb\u6cdb\u6216\u4e0d\u5207\u5b9e\u9645\u3002OpenAg\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "OpenAg\u7ed3\u5408\u4e86\u9886\u57df\u7279\u5b9a\u57fa\u7840\u6a21\u578b\u3001\u795e\u7ecf\u77e5\u8bc6\u56fe\u8c31\u3001\u591a\u667a\u80fd\u4f53\u63a8\u7406\u3001\u56e0\u679c\u89e3\u91ca\u6027\u548c\u81ea\u9002\u5e94\u8fc1\u79fb\u5b66\u4e60\uff0c\u4ee5\u63d0\u4f9b\u5177\u6709\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002\u7cfb\u7edf\u5305\u62ec\u7edf\u4e00\u7684\u519c\u4e1a\u77e5\u8bc6\u5e93\uff0c\u6574\u5408\u79d1\u5b66\u6587\u732e\u3001\u4f20\u611f\u5668\u6570\u636e\u548c\u519c\u6c11\u751f\u6210\u7684\u77e5\u8bc6\uff0c\u795e\u7ecf\u519c\u4e1a\u77e5\u8bc6\u56fe\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u548c\u63a8\u65ad\uff0c\u9002\u5e94\u6027\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\u4ee5\u53ca\u56e0\u679c\u900f\u660e\u673a\u5236\u3002", "result": "OpenAg\u901a\u8fc7\u5176\u591a\u5c42\u6b21\u548c\u591a\u6a21\u5757\u7684\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u4e3a\u519c\u4e1a\u63d0\u4f9b\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u4f5c\u7684\u667a\u80fd\u5efa\u8bae\u3002", "conclusion": "OpenAg\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u9762\u6846\u67b6\uff0c\u65e8\u5728\u63a8\u52a8\u519c\u4e1a\u4eba\u5de5\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u80fd\u591f\u652f\u6301\u53ef\u6269\u5c55\u4e14\u672c\u5730\u76f8\u5173\u7684\u519c\u4e1a\u51b3\u7b56\u3002"}}
{"id": "2506.04294", "pdf": "https://arxiv.org/pdf/2506.04294", "abs": "https://arxiv.org/abs/2506.04294", "authors": ["Asier Diaz-Iglesias", "Xabier Belaunzaran", "Ane M. Florez-Tapia"], "title": "Short-Term Power Demand Forecasting for Diverse Consumer Types to Enhance Grid Planning and Synchronisation", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring grid stability in the transition to renewable energy sources\nrequires accurate power demand forecasting. This study addresses the need for\nprecise forecasting by differentiating among industrial, commercial, and\nresidential consumers through customer clusterisation, tailoring the\nforecasting models to capture the unique consumption patterns of each group. A\nfeature selection process is done for each consumer type including temporal,\nsocio-economic, and weather-related data obtained from the Copernicus Earth\nObservation (EO) program. A variety of AI and machine learning algorithms for\nShort-Term Load Forecasting (STLF) and Very Short-Term Load Forecasting (VSTLF)\nare explored and compared, determining the most effective approaches. With all\nthat, the main contribution of this work are the new forecasting approaches\nproposed, which have demonstrated superior performance compared to simpler\nmodels, both for STLF and VSTLF, highlighting the importance of customized\nforecasting strategies for different consumer groups and demonstrating the\nimpact of incorporating detailed weather data on forecasting accuracy. These\nadvancements contribute to more reliable power demand predictions, thereby\nsupporting grid stability.", "AI": {"tldr": "\u4e3a\u4e86\u8f6c\u578b\u81f3\u53ef\u518d\u751f\u80fd\u6e90\uff0c\u672c\u7814\u7a76\u901a\u8fc7\u5ba2\u6237\u7fa4\u4f53\u5316\u548cAI\u53ca\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u63d0\u9ad8\u7535\u529b\u9700\u6c42\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u652f\u6301\u7535\u7f51\u7a33\u5b9a\u6027\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u8f6c\u578b\u4e2d\u786e\u4fdd\u7535\u7f51\u7a33\u5b9a\u6027\u9700\u8981\u51c6\u786e\u7684\u7535\u529b\u9700\u6c42\u9884\u6d4b\u3002", "method": "\u4f18\u5316\u5ba2\u6237\u7fa4\u4f53\u5316\uff0c\u5229\u7528AI\u548c\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u77ed\u671f\u8d1f\u8377\u9884\u6d4b\uff08STLF\uff09\u548c\u6781\u77ed\u671f\u8d1f\u8377\u9884\u6d4b\uff08VSTLF\uff09\uff0c\u5e76\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u5305\u62ec\u65f6\u95f4\u3001\u793e\u4f1a\u7ecf\u6d4e\u548c\u7531\u54e5\u767d\u5c3c\u5730\u7403\u89c2\u6d4b\u8ba1\u5212\u83b7\u5f97\u7684\u5929\u6c14\u76f8\u5173\u6570\u636e\u3002", "result": "\u65b0\u63d0\u51fa\u7684\u9884\u6d4b\u65b9\u6cd5\u5728STLF\u548cVSTLF\u4e0a\u90fd\u8868\u73b0\u51fa\u6bd4\u7b80\u5355\u6a21\u578b\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u63d0\u5347\u4e86\u53ef\u9760\u7684\u7535\u529b\u9700\u6c42\u9884\u6d4b\uff0c\u652f\u6301\u7535\u7f51\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7684\u65b0\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u7528\u6237\u7fa4\u4f53\u4e0a\u90fd\u6709\u76f8\u5bf9\u4e8e\u7b80\u5355\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5f3a\u8c03\u4e86\u5b9a\u5236\u5316\u9884\u6d4b\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u8be6\u7ec6\u5929\u6c14\u6570\u636e\u5bf9\u9884\u6d4b\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002"}}
{"id": "2506.04534", "pdf": "https://arxiv.org/pdf/2506.04534", "abs": "https://arxiv.org/abs/2506.04534", "authors": ["William Sheffield", "Kanishka Misra", "Valentina Pyatkin", "Ashwini Deo", "Kyle Mahowald", "Junyi Jessy Li"], "title": "Is It JUST Semantics? A Case Study of Discourse Particle Understanding in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "To be published in Findings of The 63rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2025). The main paper is 5\n  pages and contains 3 figures and 1 table. In total, the paper is 12 pages and\n  contains 8 figures and 5 tables (References + Appendix)", "summary": "Discourse particles are crucial elements that subtly shape the meaning of\ntext. These words, often polyfunctional, give rise to nuanced and often quite\ndisparate semantic/discourse effects, as exemplified by the diverse uses of the\nparticle \"just\" (e.g., exclusive, temporal, emphatic). This work investigates\nthe capacity of LLMs to distinguish the fine-grained senses of English \"just\",\na well-studied example in formal semantics, using data meticulously created and\nlabeled by expert linguists. Our findings reveal that while LLMs exhibit some\nability to differentiate between broader categories, they struggle to fully\ncapture more subtle nuances, highlighting a gap in their understanding of\ndiscourse particles.", "AI": {"tldr": "\u7814\u7a76\u663e\u793aLLMs\u53ef\u4ee5\u533a\u5206\u201cjust\u201d\u7684\u5e7f\u6cdb\u7c7b\u522b\uff0c\u4f46\u96be\u4ee5\u6355\u6349\u5176\u7ec6\u5fae\u5dee\u522b\u3002", "motivation": "\u5206\u6790\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u7406\u89e3\u82f1\u8bed\u8bdd\u8bed\u7c92\u5b50\u201cjust\u201d\u7ec6\u5fae\u610f\u4e49\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u7531\u4e13\u5bb6\u8bed\u8a00\u5b66\u5bb6\u7cbe\u5fc3\u521b\u5efa\u548c\u6807\u8bb0\u7684\u6570\u636e\u5bf9LLMs\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0LLMs\u80fd\u533a\u5206\u8f83\u5e7f\u6cdb\u7684\u7c7b\u522b\uff0c\u4f46\u96be\u4ee5\u5b8c\u5168\u6355\u6349\u7ec6\u5fae\u5dee\u522b\u3002", "conclusion": "LLMs\u5728\u7406\u89e3\u8bdd\u8bed\u7c92\u5b50\u7684\u7ec6\u5fae\u5dee\u522b\u65b9\u9762\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002"}}
{"id": "2506.04610", "pdf": "https://arxiv.org/pdf/2506.04610", "abs": "https://arxiv.org/abs/2506.04610", "authors": ["Guido Governatori", "Antonino Rotolo"], "title": "Judicial Permission", "categories": ["cs.AI", "cs.CY", "cs.LO"], "comment": null, "summary": "This paper examines the significance of weak permissions in criminal trials\n(\\emph{judicial permission}). It introduces a dialogue game model to\nsystematically address judicial permissions, considering different standards of\nproof and argumentation semantics.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5bf9\u8bdd\u6e38\u620f\u6a21\u578b\u63a2\u8ba8\u5211\u4e8b\u5ba1\u5224\u4e2d\u5f31\u8bb8\u53ef\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u4e0d\u540c\u8bc1\u660e\u6807\u51c6\u548c\u8bba\u8bc1\u8bed\u4e49\u5bf9\u53f8\u6cd5\u8bb8\u53ef\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u5f31\u8bb8\u53ef\u5728\u5211\u4e8b\u5ba1\u5224\u4e2d\u6709\u65f6\u53ef\u4ee5\u5f71\u54cd\u6848\u4ef6\u7684\u6700\u7ec8\u5224\u51b3\uff0c\u4f46\u5176\u4f5c\u7528\u5e38\u5e38\u88ab\u5ffd\u89c6\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u6a21\u578b\u7684\u5efa\u7acb\u6765\u63ed\u793a\u548c\u5206\u6790\u5f31\u8bb8\u53ef\u7684\u91cd\u8981\u6027\u548c\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e00\u79cd\u5bf9\u8bdd\u6e38\u620f\u6a21\u578b\uff0c\u7cfb\u7edf\u6027\u5730\u5904\u7406\u53f8\u6cd5\u8bb8\u53ef\uff0c\u5e76\u8003\u8651\u4e0d\u540c\u7684\u8bc1\u660e\u6807\u51c6\u548c\u8bba\u8bc1\u8bed\u4e49\u3002", "result": "\u7814\u7a76\u901a\u8fc7\u5bf9\u8bdd\u6e38\u620f\u6a21\u578b\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u4e0d\u540c\u7684\u8bc1\u660e\u6807\u51c6\u548c\u8bba\u8bc1\u8bed\u4e49\u53ef\u4ee5\u663e\u8457\u5f71\u54cd\u53f8\u6cd5\u8bb8\u53ef\u7684\u5b9e\u65bd\u548c\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u53f8\u6cd5\u8bb8\u53ef\u4e2d\u7684\u5f31\u8bb8\u53ef\u5728\u5211\u4e8b\u5ba1\u5224\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u8ba8\u3002"}}
{"id": "2506.04296", "pdf": "https://arxiv.org/pdf/2506.04296", "abs": "https://arxiv.org/abs/2506.04296", "authors": ["N Guerin", "M Nakhla", "A Dehoux", "J L Loyer"], "title": "Deep learning for predicting hauling fleet production capacity under uncertainties in open pit mines using real and simulated data", "categories": ["cs.LG"], "comment": null, "summary": "Accurate short-term forecasting of hauling-fleet capacity is crucial in\nopen-pit mining, where weather fluctuations, mechanical breakdowns, and\nvariable crew availability introduce significant operational uncertainties. We\npropose a deep-learning framework that blends real-world operational records\n(high-resolution rainfall measurements, fleet performance telemetry) with\nsynthetically generated mechanical-breakdown scenarios to enable the model to\ncapture fluctuating high-impact failure events. We evaluate two architectures:\nan XGBoost regressor achieving a median absolute error (MedAE) of 14.3 per cent\nand a Long Short-Term Memory network with a MedAE of 15.1 per cent. Shapley\nAdditive exPlanations (SHAP) value analyses identify cumulative rainfall,\nhistorical payload trends, and simulated breakdown frequencies as dominant\npredictors. Integration of simulated breakdown data and shift-planning features\nnotably reduces prediction volatility. Future work will further integrate\nmaintenance-scheduling indicators (Mean Time Between Failures, Mean Time to\nRepair), detailed human resource data (operator absenteeism, crew efficiency\nmetrics), blast event scheduling, and other operational constraints to enhance\nforecast robustness and adaptability. This hybrid modelling approach offers a\ncomprehensive decision-support tool for proactive, data-driven fleet management\nunder dynamically uncertain conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u771f\u5b9e\u64cd\u4f5c\u6570\u636e\u4e0e\u5408\u6210\u673a\u68b0\u6545\u969c\u573a\u666f\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u9732\u5929\u77ff\u4e1a\u4e2d\u7684\u8f66\u961f\u5bb9\u91cf\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u901a\u8fc7\u4e24\u79cd\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "motivation": "\u77ed\u671f\u9884\u6d4b\u5f00\u91c7\u8f66\u961f\u5bb9\u91cf\u5bf9\u9732\u5929\u77ff\u4e1a\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5929\u6c14\u6ce2\u52a8\u3001\u673a\u68b0\u6545\u969c\u4ee5\u53ca\u4eba\u5458\u53ef\u7528\u6027\u7684\u53d8\u5316\u4f1a\u5f15\u5165\u663e\u8457\u7684\u8fd0\u8425\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u771f\u5b9e\u7684\u64cd\u4f5c\u8bb0\u5f55\uff08\u9ad8\u5206\u8fa8\u7387\u964d\u96e8\u91cf\u6d4b\u91cf\u3001\u8f66\u961f\u6027\u80fd\u9065\u6d4b\uff09\u4e0e\u5408\u6210\u4ea7\u751f\u7684\u673a\u68b0\u6545\u969c\u573a\u666f\uff0c\u4ee5\u6355\u6349\u9ad8\u5f71\u54cd\u6545\u969c\u4e8b\u4ef6\u7684\u6ce2\u52a8\u6027\u3002", "result": "\u901a\u8fc7\u5bf9\u4e24\u79cd\u67b6\u6784\u8fdb\u884c\u8bc4\u4f30\uff1aXGBoost\u56de\u5f52\u5668\u5b9e\u73b0\u4e8614.3%\u7684\u4e2d\u4f4d\u7edd\u5bf9\u8bef\u5dee\uff08MedAE\uff09\uff0c\u800c\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u5219\u5b9e\u73b0\u4e8615.1%\u7684MedAE\u3002SHAP\u503c\u5206\u6790\u786e\u5b9a\u7d2f\u8ba1\u964d\u96e8\u91cf\u3001\u5386\u53f2\u8f7d\u8377\u8d8b\u52bf\u548c\u6a21\u62df\u6545\u969c\u9891\u7387\u4e3a\u4e3b\u8981\u9884\u6d4b\u6307\u6807\u3002", "conclusion": "\u6df7\u5408\u5efa\u6a21\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u8fdb\u884c\u4e3b\u52a8\u7684\u6570\u636e\u9a71\u52a8\u8f66\u961f\u7ba1\u7406\u3002"}}
{"id": "2506.04535", "pdf": "https://arxiv.org/pdf/2506.04535", "abs": "https://arxiv.org/abs/2506.04535", "authors": ["K. O. T. Erziev"], "title": "BSBench: will your LLM find the largest prime number?", "categories": ["cs.CL"], "comment": "7 + 2 pages", "summary": "We propose that benchmarking LLMs on questions which have no reasonable\nanswer actually isn't as silly as it sounds. We also present a benchmark that\nallows such testing and a method to modify the existing datasets, and discover\nthat existing models demonstrate a performance far from the perfect on such\nquestions. Our code and data artifacts are available at\nhttps://github.com/L3G5/impossible-bench", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u5408\u7406\u7b54\u6848\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u7684\u4ee3\u7801\u548c\u6570\u636e\u3002", "motivation": "\u8ba4\u4e3a\u5728\u65e0\u89e3\u95ee\u9898\u4e0a\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5e76\u4e0d\u662f\u65e0\u610f\u4e49\u7684\uff0c\u65e8\u5728\u7814\u7a76\u5176\u5728\u6b64\u7c7b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u51c6\u65b9\u6cd5\u6765\u4fee\u6539\u73b0\u6709\u6570\u636e\u96c6\uff0c\u4ee5\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u5408\u7406\u7b54\u6848\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7ecf\u8fc7\u6d4b\u8bd5\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u6b64\u7c7b\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u65e0\u89e3\u95ee\u9898\u65f6\uff0c\u8868\u73b0\u8fdc\u672a\u8fbe\u5230\u7406\u60f3\u72b6\u6001\u3002"}}
{"id": "2506.04613", "pdf": "https://arxiv.org/pdf/2506.04613", "abs": "https://arxiv.org/abs/2506.04613", "authors": ["Li Liu", "Heng Yong"], "title": "DeePoly: A High-Order Accuracy and Efficiency Deep-Polynomial Framework for Scientific Machine Learning", "categories": ["cs.AI", "cs.LG"], "comment": "for associated mpeg file, see http://github.com/bfly123/DeePoly", "summary": "Recently, machine learning methods have gained significant traction in\nscientific computing, particularly for solving Partial Differential Equations\n(PDEs). However, methods based on deep neural networks (DNNs) often lack\nconvergence guarantees and computational efficiency compared to traditional\nnumerical schemes. This work introduces DeePoly, a novel framework that\ntransforms the solution paradigm from pure non-convex parameter optimization to\na two-stage approach: first employing a DNN to capture complex global features,\nfollowed by linear space optimization with combined DNN-extracted features\n(Scoper) and polynomial basis functions (Sniper). This strategic combination\nleverages the complementary strengths of both methods -- DNNs excel at\napproximating complex global features (i.e., high-gradient features) and\nstabilize the polynomial approximation while polynomial bases provide\nhigh-precision local corrections with convergence guarantees. Theoretical\nanalysis and numerical experiments demonstrate that this approach significantly\nenhances both high-order accuracy and efficiency across diverse problem types\nwhile maintaining mesh-free and scheme-free properties. This paper also serves\nas a theoretical exposition for the open-source project DeePoly.", "AI": {"tldr": "DeePoly combines DNNs with polynomial optimization to solve PDEs efficiently, offering both high-order accuracy and convergence guarantees.", "motivation": "Machine learning methods, especially those based on DNNs, have lacked convergence guarantees and computational efficiency in scientific computing compared to traditional numerical schemes.", "method": "DeePoly employs a two-stage approach: first using a DNN to capture complex global features, followed by linear space optimization with DNN-extracted features and polynomial basis functions.", "result": "The approach improves high-order accuracy and efficiency across diverse problem types, leveraging the strengths of DNNs and polynomial bases.", "conclusion": "DeePoly significantly enhances accuracy and efficiency in solving PDEs, maintaining mesh-free and scheme-free properties, demonstrated through theoretical analysis and numerical experiments."}}
{"id": "2506.04297", "pdf": "https://arxiv.org/pdf/2506.04297", "abs": "https://arxiv.org/abs/2506.04297", "authors": ["Abdourrahmane Mahamane Atto"], "title": "Softlog-Softmax Layers and Divergences Contribute to a Computationally Dependable Ensemble Learning", "categories": ["cs.LG"], "comment": null, "summary": "The paper proposes a 4-step process for highlighting that softlog-softmax\ncascades can improve both consistency and dependability of the next generation\nensemble learning systems. The first process is anatomical in nature: the\ntarget ensemble model under consideration is composed by canonical elements\nrelating to the definition of a convolutional frustum. No a priori is\nconsidered in the choice of canonical forms. Diversity is the main criterion\nfor selecting these forms. It is shown that the more complex the problem, the\nmore useful this ensemble diversity is. The second process is physiological and\nrelates to neural engineering: a softlog is derived to both make weak\nlogarithmic operations consistent and lead, through multiple softlog-softmax\nlayers, to intermediate decisions in the sense of respecting the same class\nlogic as that faced by the output layer. The third process concerns neural\ninformation theory: softlog-based entropy and divergence are proposed for the\nsake of constructing information measures yielding consistent values on closed\nintervals. These information measures are used to determine the relationships\nbetween individual and sub-community decisions in frustum diversitybased\nensemble learning. The concluding process addresses the derivation of an\ninformative performance tensor for the purpose of a reliable ensemble\nevaluation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a4\u6b65\u6d41\u7a0b\uff0c\u901a\u8fc7\u4f7f\u7528\u8f6f\u5bf9\u6570-\u8f6f\u6700\u5927\u503c\u7ea7\u8054\u63d0\u5347\u96c6\u6210\u5b66\u4e60\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u63d0\u5347\u4e0b\u4e00\u4ee3\u96c6\u6210\u5b66\u4e60\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5efa\u7acb\u8f6f\u5bf9\u6570-\u8f6f\u6700\u5927\u503c\u7ea7\u8054\u6765\u5b9e\u73b0\u6b65\u9aa4\u6d41\u7a0b\uff0c\u5305\u62ec\u6784\u9020\u5377\u79ef\u622a\u65ad\u6a21\u578b\uff0c\u5bfc\u51fa\u8f6f\u5bf9\u6570\uff0c\u4f7f\u7528\u4fe1\u606f\u5ea6\u91cf\u8fdb\u884c\u51b3\u7b56\u5173\u7cfb\u5206\u6790\uff0c\u5e76\u751f\u6210\u6027\u80fd\u5f20\u91cf\u3002", "result": "\u672c\u6587\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u590d\u6742\u95ee\u9898\u4e2d\u7684\u96c6\u6210\u591a\u6837\u6027\u548c\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u4e0e\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u76844\u6b65\u8fc7\u7a0b\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4e0b\u4e00\u4ee3\u96c6\u6210\u5b66\u4e60\u7cfb\u7edf\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.04557", "pdf": "https://arxiv.org/pdf/2506.04557", "abs": "https://arxiv.org/abs/2506.04557", "authors": ["Senyu Li", "Jiayi Wang", "Felermino D. M. A. Ali", "Colin Cherry", "Daniel Deutsch", "Eleftheria Briakou", "Rui Sousa-Silva", "Henrique Lopes Cardoso", "Pontus Stenetorp", "David Ifeoluwa Adelani"], "title": "SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for Under-Resourced African Languages?", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Evaluating machine translation (MT) quality for under-resourced African\nlanguages remains a significant challenge, as existing metrics often suffer\nfrom limited language coverage and poor performance in low-resource settings.\nWhile recent efforts, such as AfriCOMET, have addressed some of the issues,\nthey are still constrained by small evaluation sets, a lack of publicly\navailable training data tailored to African languages, and inconsistent\nperformance in extremely low-resource scenarios. In this work, we introduce\nSSA-MTE, a large-scale human-annotated MT evaluation (MTE) dataset covering 13\nAfrican language pairs from the News domain, with over 63,000 sentence-level\nannotations from a diverse set of MT systems. Based on this data, we develop\nSSA-COMET and SSA-COMET-QE, improved reference-based and reference-free\nevaluation metrics. We also benchmark prompting-based approaches using\nstate-of-the-art LLMs like GPT-4o and Claude. Our experimental results show\nthat SSA-COMET models significantly outperform AfriCOMET and are competitive\nwith the strongest LLM (Gemini 2.5 Pro) evaluated in our study, particularly on\nlow-resource languages such as Twi, Luo, and Yoruba. All resources are released\nunder open licenses to support future research.", "AI": {"tldr": "\u5f15\u5165\u4e00\u4e2a\u5927\u89c4\u6a21\u975e\u6d32\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u65b0\u7684\u8bc4\u4ef7\u6307\u6807\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u8bc4\u4ef7\u975e\u6d32\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u7684\u6307\u6807\u5b58\u5728\u8986\u76d6\u7387\u6709\u9650\u548c\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165SSA-MTE\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u4eba\u7c7b\u6807\u6ce8\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u8be5\u6570\u636e\u5f00\u53d1\u6539\u8fdb\u7684\u8bc4\u4ef7\u6307\u6807SSA-COMET\u548cSSA-COMET-QE\uff0c\u540c\u65f6\u5bf9\u63d0\u793a\u9a71\u52a8\u7684\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "SSA-COMET\u6a21\u578b\u663e\u8457\u4f18\u4e8eAfriCOMET\uff0c\u5e76\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u4e0e\u5f3a\u5927\u7684LLM\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "SSA-COMET\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u4e0a\u5177\u5907\u7ade\u4e89\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u653e\u8d44\u6e90\u4ee5\u652f\u6301\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2506.04614", "pdf": "https://arxiv.org/pdf/2506.04614", "abs": "https://arxiv.org/abs/2506.04614", "authors": ["Yuyang Wanyan", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Jiabo Ye", "Yutong Kou", "Ming Yan", "Fei Huang", "Xiaoshan Yang", "Weiming Dong", "Changsheng Xu"], "title": "Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error Diagnosis in GUI Automation", "categories": ["cs.AI"], "comment": null, "summary": "In recent years, Multimodal Large Language Models (MLLMs) have been\nextensively utilized for multimodal reasoning tasks, including Graphical User\nInterface (GUI) automation. Unlike general offline multimodal tasks, GUI\nautomation is executed in online interactive environments, necessitating\nstep-by-step decision-making based on real-time status of the environment. This\ntask has a lower tolerance for decision-making errors at each step, as any\nmistakes may cumulatively disrupt the process and potentially lead to\nirreversible outcomes like deletions or payments. To address these issues, we\nintroduce a pre-operative critic mechanism that provides effective feedback\nprior to the actual execution, by reasoning about the potential outcome and\ncorrectness of actions. Specifically, we propose a Suggestion-aware Gradient\nRelative Policy Optimization (S-GRPO) strategy to construct our pre-operative\ncritic model GUI-Critic-R1, incorporating a novel suggestion reward to enhance\nthe reliability of the model's feedback. Furthermore, we develop a\nreasoning-bootstrapping based data collection pipeline to create a\nGUI-Critic-Train and a GUI-Critic-Test, filling existing gaps in GUI critic\ndata. Static experiments on the GUI-Critic-Test across both mobile and web\ndomains reveal that our GUI-Critic-R1 offers significant advantages in critic\naccuracy compared to current MLLMs. Dynamic evaluation on GUI automation\nbenchmark further highlights the effectiveness and superiority of our model, as\nevidenced by improved success rates and operational efficiency.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u7528\u4e8e\u56fe\u5f62\u7528\u6237\u754c\u9762\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u9884\u64cd\u4f5c\u8bc4\u8bba\u673a\u5236\uff0c\u901a\u8fc7S-GRPO\u7b56\u7565\u53ca\u63a8\u7406\u5f15\u5bfc\u7684\u6570\u636e\u6536\u96c6\uff0c\u589e\u5f3a\u4efb\u52a1\u6267\u884c\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\uff0c\u53d6\u5f97\u4f18\u4e8e\u73b0\u6709MLLMs\u7684\u7ed3\u679c\u3002", "motivation": "\u901a\u8fc7\u5f15\u5165\u9884\u64cd\u4f5c\u8bc4\u8bba\u673a\u5236\u6765\u51cf\u5c11\u5728\u7ebf\u4ea4\u4e92\u73af\u5883\u4e2d\u56fe\u5f62\u7528\u6237\u754c\u9762\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u51b3\u7b56\u9519\u8bef\uff0c\u5e76\u52a0\u5f3a\u4efb\u52a1\u6267\u884c\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5efa\u8bae\u611f\u77e5\u68af\u5ea6\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08S-GRPO\uff09\u7b56\u7565\uff0c\u7528\u4e8e\u6784\u5efa\u6211\u4eec\u7684\u9884\u64cd\u4f5c\u8bc4\u8bba\u673a\u5236\u6a21\u578bGUI-Critic-R1\uff0c\u5e76\u901a\u8fc7\u63a8\u7406\u5f15\u5bfc\u7684\u6570\u636e\u6536\u96c6\u7ba1\u9053\u5f00\u53d1\u4e86GUI-Critic-Train\u548cGUI-Critic-Test\u3002", "result": "\u5728GUI-Critic-Test\u7684\u9759\u6001\u5b9e\u9a8c\u4e2d\uff0cGUI-Critic-R1\u5728\u8bc4\u8bba\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u76ee\u524d\u7684MLLMs\u3002\u5728GUI\u81ea\u52a8\u5316\u57fa\u51c6\u7684\u52a8\u6001\u8bc4\u4f30\u4e2d\uff0c\u8be5\u6a21\u578b\u5728\u6210\u529f\u7387\u548c\u64cd\u4f5c\u6548\u7387\u4e0a\u4e5f\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "GUI-Critic-R1\u7684\u63a8\u51fa\u901a\u8fc7\u5efa\u8bae\u5956\u52b1\u7684\u5f15\u5165\u548c\u63a8\u7406\u5f15\u5bfc\u7684\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u56fe\u5f62\u7528\u6237\u754c\u9762\u81ea\u52a8\u5316\u4efb\u52a1\u7684\u51b3\u7b56\u51c6\u786e\u6027\u548c\u64cd\u4f5c\u6548\u7387\uff0c\u4e0e\u73b0\u6709MLLMs\u76f8\u6bd4\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.04301", "pdf": "https://arxiv.org/pdf/2506.04301", "abs": "https://arxiv.org/abs/2506.04301", "authors": ["Jiin Kim", "Byeongjun Shin", "Jinha Chung", "Minsoo Rhu"], "title": "The Cost of Dynamic Reasoning: Demystifying AI Agents and Test-Time Scaling from an AI Infrastructure Perspective", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Large-language-model (LLM)-based AI agents have recently showcased impressive\nversatility by employing dynamic reasoning, an adaptive, multi-step process\nthat coordinates with external tools. This shift from static, single-turn\ninference to agentic, multi-turn workflows broadens task generalization and\nbehavioral flexibility, but it also introduces serious concerns about\nsystem-level cost, efficiency, and sustainability. This paper presents the\nfirst comprehensive system-level analysis of AI agents, quantifying their\nresource usage, latency behavior, energy consumption, and datacenter-wide power\nconsumption demands across diverse agent designs and test-time scaling\nstrategies. We further characterize how AI agent design choices, such as\nfew-shot prompting, reflection depth, and parallel reasoning, impact\naccuracy-cost tradeoffs. Our findings reveal that while agents improve accuracy\nwith increased compute, they suffer from rapidly diminishing returns, widening\nlatency variance, and unsustainable infrastructure costs. Through detailed\nevaluation of representative agents, we highlight the profound computational\ndemands introduced by AI agent workflows, uncovering a looming sustainability\ncrisis. These results call for a paradigm shift in agent design toward\ncompute-efficient reasoning, balancing performance with deployability under\nreal-world constraints.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86AI\u4ee3\u7406\u7684\u8d44\u6e90\u548c\u80fd\u8017\u95ee\u9898\uff0c\u53d1\u73b0\u5176\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u65f6\u5b58\u5728\u9ad8\u6602\u4e14\u4e0d\u53ef\u6301\u7eed\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5efa\u8bae\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u63a2\u8ba8AI\u4ee3\u7406\u5728\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5c55\u793a\u7684\u4efb\u52a1\u6cdb\u5316\u548c\u7075\u6d3b\u6027\u589e\u52a0\u7684\u540c\u65f6\uff0c\u5982\u4f55\u534f\u8c03\u7cfb\u7edf\u7ea7\u7684\u6210\u672c\u3001\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "method": "\u5bf9\u4e0d\u540c\u4ee3\u7406\u8bbe\u8ba1\u548c\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u7b56\u7565\u7684\u8d44\u6e90\u4f7f\u7528\u3001\u5ef6\u8fdf\u884c\u4e3a\u3001\u80fd\u8017\u548c\u6570\u636e\u4e2d\u5fc3\u529f\u7387\u6d88\u8017\u8fdb\u884c\u5168\u9762\u7684\u7cfb\u7edf\u7ea7\u5206\u6790\u3002", "result": "AI\u4ee3\u7406\u5728\u8ba1\u7b97\u589e\u52a0\u65f6\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u51fa\u73b0\u4e86\u6536\u76ca\u9012\u51cf\u3001\u5ef6\u8fdf\u5dee\u5f02\u6269\u5927\u548c\u4e0d\u53ef\u6301\u7eed\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u9700\u5728\u6027\u80fd\u4e0e\u5b9e\u9645\u90e8\u7f72\u7ea6\u675f\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\uff0cAI\u4ee3\u7406\u5728\u63d0\u9ad8\u51c6\u786e\u6027\u65f6\uff0c\u8ba1\u7b97\u7684\u8fb9\u9645\u6536\u76ca\u8fc5\u901f\u51cf\u5c11\uff0c\u540c\u65f6\u5e26\u6765\u4e86\u5de8\u5927\u548c\u4e0d\u53ef\u6301\u7eed\u7684\u57fa\u7840\u8bbe\u65bd\u6210\u672c\uff0c\u547c\u5401\u5728\u4ee3\u7406\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u7684\u63a8\u7406\u3002"}}
{"id": "2506.04572", "pdf": "https://arxiv.org/pdf/2506.04572", "abs": "https://arxiv.org/abs/2506.04572", "authors": ["Can Zheng", "Yuhan Cao", "Xiaoning Dong", "Tianxing He"], "title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding, code generation, and complex planning.\nSimultaneously, Multi-Agent Systems (MAS) have garnered attention for their\npotential to enable cooperation among distributed agents. However, from a\nmulti-party perspective, MAS could be vulnerable to malicious agents that\nexploit the system to serve self-interests without disrupting its core\nfunctionality. This work explores integrity attacks where malicious agents\nemploy subtle prompt manipulation to bias MAS operations and gain various\nbenefits. Four types of attacks are examined: \\textit{Scapegoater}, who\nmisleads the system monitor to underestimate other agents' contributions;\n\\textit{Boaster}, who misleads the system monitor to overestimate their own\nperformance; \\textit{Self-Dealer}, who manipulates other agents to adopt\ncertain tools; and \\textit{Free-Rider}, who hands off its own task to others.\nWe demonstrate that strategically crafted prompts can introduce systematic\nbiases in MAS behavior and executable instructions, enabling malicious agents\nto effectively mislead evaluation systems and manipulate collaborative agents.\nFurthermore, our attacks can bypass advanced LLM-based monitors, such as\nGPT-4o-mini and o3-mini, highlighting the limitations of current detection\nmechanisms. Our findings underscore the critical need for MAS architectures\nwith robust security protocols and content validation mechanisms, alongside\nmonitoring systems capable of comprehensive risk scenario assessment.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u6076\u610f\u667a\u80fd\u4f53\u53ef\u4ee5\u901a\u8fc7\u63d0\u793a\u64cd\u63a7\u5f71\u54cd\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u884c\u4e3a\uff0c\u5efa\u8bae\u589e\u5f3a\u5b89\u5168\u673a\u5236\u4ee5\u9632\u6b62\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u4fdd\u62a4\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u514d\u53d7\u6076\u610f\u653b\u51fb\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e9b\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5206\u6790\u6076\u610f\u667a\u80fd\u4f53\u5982\u4f55\u901a\u8fc7\u5fae\u5999\u7684\u63d0\u793a\u64cd\u63a7\u6765\u504f\u5411\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u64cd\u4f5c\uff0c\u5e76\u8bbe\u8ba1\u56db\u79cd\u7c7b\u578b\u7684\u653b\u51fb\u4ee5\u6d4b\u8bd5\u5176\u6548\u679c\u3002", "result": "\u8bc1\u660e\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u64cd\u63a7\u53ef\u4ee5\u9020\u6210\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u8fd9\u4f7f\u5f97\u6076\u610f\u667a\u80fd\u4f53\u80fd\u591f\u6709\u6548\u5730\u8bef\u5bfc\u8bc4\u4f30\u7cfb\u7edf\u5e76\u64cd\u63a7\u534f\u4f5c\u667a\u80fd\u4f53\u3002\u6b64\u5916\uff0c\u73b0\u6709\u68c0\u6d4b\u673a\u5236\u5982GPT-4o-mini\u548co3-mini\u65e0\u6cd5\u68c0\u6d4b\u5230\u8fd9\u4e9b\u653b\u51fb\u3002", "conclusion": "\u9700\u8981\u52a0\u5f3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b89\u5168\u534f\u8bae\u548c\u5185\u5bb9\u9a8c\u8bc1\u673a\u5236\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u98ce\u9669\u60c5\u666f\u8bc4\u4f30\uff0c\u4ee5\u53ca\u63d0\u5347\u76d1\u6d4b\u7cfb\u7edf\u7684\u80fd\u529b\u3002"}}
{"id": "2506.04636", "pdf": "https://arxiv.org/pdf/2506.04636", "abs": "https://arxiv.org/abs/2506.04636", "authors": ["Lucas Irwin", "Arda Kaz", "Peiyao Sheng", "Pramod Viswanath"], "title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Law has long been a domain that has been popular in natural language\nprocessing (NLP) applications. Reasoning (ratiocination and the ability to make\nconnections to precedent) is a core part of the practice of the law in the real\nworld. Nevertheless, while multiple legal datasets exist, none have thus far\nfocused specifically on reasoning tasks. We focus on a specific aspect of the\nlegal landscape by introducing a corporate governance reasoning benchmark\n(CHANCERY) to test a model's ability to reason about whether\nexecutive/board/shareholder's proposed actions are consistent with corporate\ngovernance charters. This benchmark introduces a first-of-its-kind corporate\ngovernance reasoning test for language models - modeled after real world\ncorporate governance law. The benchmark consists of a corporate charter (a set\nof governing covenants) and a proposal for executive action. The model's task\nis one of binary classification: reason about whether the action is consistent\nwith the rules contained within the charter. We create the benchmark following\nestablished principles of corporate governance - 24 concrete corporate\ngovernance principles established in and 79 real life corporate charters\nselected to represent diverse industries from a total dataset of 10k real life\ncorporate charters. Evaluations on state-of-the-art (SOTA) reasoning models\nconfirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet\nand GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents\nexhibit superior performance, with agents based on the ReAct and CodeAct\nframeworks scoring 76.1% and 78.1% respectively, further confirming the\nadvanced legal reasoning capabilities required to score highly on the\nbenchmark. We also conduct an analysis of the types of questions which current\nreasoning models struggle on, revealing insights into the legal reasoning\ncapabilities of SOTA models.", "AI": {"tldr": "\u8bba\u6587\u5f15\u5165CHANCERY\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u516c\u53f8\u6cbb\u7406\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u8fd9\u4e00\u9886\u57df\u7684\u6311\u6218\u6027\u548c\u53d1\u5c55\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u591a\u4e2a\u6cd5\u5f8b\u6570\u636e\u96c6\uff0c\u4f46\u5c1a\u672a\u6709\u4e13\u95e8\u9488\u5bf9\u63a8\u7406\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u5f15\u5165\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u2014\u2014CHANCERY\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u63a8\u7406\u7279\u522b\u662f\u516c\u53f8\u6cbb\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "Claude 3.7 Sonnet\u548cGPT-4o\u5728\u6b64\u57fa\u51c6\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u4e3a64.5%\u548c75.2%\u3002ReAct\u548cCodeAct\u6846\u67b6\u7684\u4ee3\u7406\u8868\u73b0\u66f4\u597d\uff0c\u5206\u522b\u53d6\u5f9776.1%\u548c78.1%\u7684\u5f97\u5206\uff0c\u8bc1\u660e\u9700\u8981\u9ad8\u7ea7\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u624d\u80fd\u5728\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u9ad8\u5206\u3002", "conclusion": "\u6cd5\u5f8b\u63a8\u7406\u5bf9\u73b0\u6709\u7684\u6700\u5148\u8fdb\u6a21\u578b\u6784\u6210\u4e86\u4e00\u5b9a\u7684\u6311\u6218\uff0c\u8868\u660e\u8fdb\u4e00\u6b65\u53d1\u5c55\u7684\u7a7a\u95f4\u3002"}}
{"id": "2506.04302", "pdf": "https://arxiv.org/pdf/2506.04302", "abs": "https://arxiv.org/abs/2506.04302", "authors": ["Xiang Zheng", "Xingjun Ma", "Wei-Bin Lee", "Cong Wang"], "title": "RedRFT: A Light-Weight Benchmark for Reinforcement Fine-Tuning-Based Red Teaming", "categories": ["cs.LG"], "comment": null, "summary": "Red teaming has proven to be an effective method for identifying and\nmitigating vulnerabilities in Large Language Models (LLMs). Reinforcement\nFine-Tuning (RFT) has emerged as a promising strategy among existing red\nteaming techniques. However, a lack of a unified benchmark hinders current\nRFT-based red teaming methods. Implementation details, especially in Proximal\nPolicy Optimization (PPO)-based RFT, significantly affect outcome stability and\nreproducibility. To address this issue, we introduce RedRFT, a lightweight\nbenchmark designed to simplify and standardize the implementation and\nevaluation of RFT-based red teaming. RedRFT combines the design strengths of\nboth single-file CleanRL and highly modularized Tianshou, offering high-quality\nsingle-file red teaming implementations and modular PPO core components, such\nas the General Advantage Estimator. It supports a variety of token and sentence\ndiversity metrics, featuring modularized intrinsic reward computation that\nfacilitates plug-and-play experimentation. To clarify their influence on RFT\nperformance, we conducted an extensive ablation study on key components,\nincluding Low-Rank Adaptation (LoRA), Kullback-Leibler (KL) divergence, and\nLagrange Multiplier. We hope this work contributes to 1) gaining a\ncomprehensive understanding of the implementation nuances of RFT-based red\nteaming algorithms, and 2) enabling rapid prototyping of innovative features\nfor RFT-based red teaming. Code for the benchmark can be accessed at\nhttps://github.com/x-zheng16/RedRFT.git.", "AI": {"tldr": "RedRFT\u662f\u4e00\u4e2a\u7b80\u5316\u548c\u6807\u51c6\u5316RFT\u7ea2\u961f\u5b9e\u65bd\u548c\u8bc4\u4f30\u7684\u8f7b\u91cf\u7ea7\u57fa\u51c6\u3002", "motivation": "\u5f53\u524dRFT\u7ea2\u961f\u7f3a\u4e4f\u7edf\u4e00\u7684\u57fa\u51c6\uff0c\u5f71\u54cd\u7ed3\u679c\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u4ecb\u7ecdRedRFT\u57fa\u51c6\uff0c\u7efc\u5408\u5355\u6587\u4ef6CleanRL\u8bbe\u8ba1\u548c\u6a21\u5757\u5316Tianshou\uff0c\u652f\u6301\u591a\u79cd\u5ea6\u91cf\u5e76\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7RedRFT\u7684\u5f15\u5165\uff0c\u63d0\u9ad8\u4e86RFT\u7ea2\u961f\u5b9e\u65bd\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u4fc3\u8fdb\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u3002", "conclusion": "RedRFT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\uff0c\u7b80\u5316\u548c\u6807\u51c6\u5316\u4e86RFT\u7ea2\u961f\u65b9\u6cd5\u7684\u5b9e\u65bd\u548c\u8bc4\u4f30\u3002"}}
{"id": "2506.04574", "pdf": "https://arxiv.org/pdf/2506.04574", "abs": "https://arxiv.org/abs/2506.04574", "authors": ["Dimitris Vamvourellis", "Dhagash Mehta"], "title": "Reasoning or Overthinking: Evaluating Large Language Models on Financial Sentiment Analysis", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We investigate the effectiveness of large language models (LLMs), including\nreasoning-based and non-reasoning models, in performing zero-shot financial\nsentiment analysis. Using the Financial PhraseBank dataset annotated by domain\nexperts, we evaluate how various LLMs and prompting strategies align with\nhuman-labeled sentiment in a financial context. We compare three proprietary\nLLMs (GPT-4o, GPT-4.1, o3-mini) under different prompting paradigms that\nsimulate System 1 (fast and intuitive) or System 2 (slow and deliberate)\nthinking and benchmark them against two smaller models (FinBERT-Prosus,\nFinBERT-Tone) fine-tuned on financial sentiment analysis. Our findings suggest\nthat reasoning, either through prompting or inherent model design, does not\nimprove performance on this task. Surprisingly, the most accurate and\nhuman-aligned combination of model and method was GPT-4o without any\nChain-of-Thought (CoT) prompting. We further explore how performance is\nimpacted by linguistic complexity and annotation agreement levels, uncovering\nthat reasoning may introduce overthinking, leading to suboptimal predictions.\nThis suggests that for financial sentiment classification, fast, intuitive\n\"System 1\"-like thinking aligns more closely with human judgment compared to\n\"System 2\"-style slower, deliberative reasoning simulated by reasoning models\nor CoT prompting. Our results challenge the default assumption that more\nreasoning always leads to better LLM decisions, particularly in high-stakes\nfinancial applications.", "AI": {"tldr": "\u5728\u91d1\u878d\u60c5\u611f\u5206\u6790\u4e2d\uff0c\u76f4\u89c9\u601d\u7ef4\u6bd4\u63a8\u7406\u601d\u7ef4\u66f4\u6709\u6548\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u91d1\u878d\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u7814\u7a76\u63a8\u7406\u662f\u5426\u80fd\u591f\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5bf9\u4e09\u79cd\u4e13\u6709LLM\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5206\u522b\u91c7\u7528\u6a21\u62df\u201c\u7cfb\u7edf1\u201d\u548c\u201c\u7cfb\u7edf2\u201d\u601d\u7ef4\u7684\u63d0\u793a\u8303\u4f8b\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u63a8\u7406\u5e76\u6ca1\u6709\u63d0\u9ad8\u8be5\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u6700\u5feb\u3001\u6700\u4eba\u6027\u5316\u7684\u6a21\u578b\u662fGPT-4o\uff0c\u5e76\u4e14\u6ca1\u6709\u4f7f\u7528\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u3002", "conclusion": "\u5feb\u901f\u3001\u76f4\u89c9\u7684\u201c\u7cfb\u7edf1\u201d\u601d\u7ef4\u4e0e\u4eba\u7c7b\u5224\u65ad\u66f4\u4e00\u81f4\uff0c\u63a8\u7406\u53ef\u80fd\u5f15\u53d1\u8fc7\u5ea6\u601d\u8003\uff0c\u4ece\u800c\u5bfc\u81f4\u6b21\u4f18\u9884\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2506.04651", "pdf": "https://arxiv.org/pdf/2506.04651", "abs": "https://arxiv.org/abs/2506.04651", "authors": ["Nikolas Belle", "Dakota Barnes", "Alfonso Amayuelas", "Ivan Bercovich", "Xin Eric Wang", "William Wang"], "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in LLMs have enabled their use as autonomous agents across a\nrange of tasks, yet they continue to struggle with formulating and adhering to\ncoherent long-term strategies. In this paper, we investigate whether LLM agents\ncan self-improve when placed in environments that explicitly challenge their\nstrategic planning abilities. Using the board game Settlers of Catan, accessed\nthrough the open-source Catanatron framework, we benchmark a progression of\nLLM-based agents, from a simple game-playing agent to systems capable of\nautonomously rewriting their own prompts and their player agent's code. We\nintroduce a multi-agent architecture in which specialized roles (Analyzer,\nResearcher, Coder, and Player) collaborate to iteratively analyze gameplay,\nresearch new strategies, and modify the agent's logic or prompt. By comparing\nmanually crafted agents to those evolved entirely by LLMs, we evaluate how\neffectively these systems can diagnose failure and adapt over time. Our results\nshow that self-evolving agents, particularly when powered by models like Claude\n3.7 and GPT-4o, outperform static baselines by autonomously adopting their\nstrategies, passing along sample behavior to game-playing agents, and\ndemonstrating adaptive reasoning over multiple iterations.", "AI": {"tldr": "\u5728\u300a\u5361\u5766\u5c9b\u300b\u6e38\u620f\u73af\u5883\u4e2d\u7814\u7a76LLM\u4ee3\u7406\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u81ea\u52a8\u6f14\u53d8\u4ee3\u7406\u4f18\u4e8e\u624b\u52a8\u8bbe\u7f6e\u7684\u4ee3\u7406\u3002", "motivation": "\u63a2\u7d22LLM\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u4ee3\u7406\u662f\u5426\u80fd\u5728\u660e\u786e\u6311\u6218\u5176\u6218\u7565\u89c4\u5212\u80fd\u529b\u7684\u73af\u5883\u4e2d\u5b8c\u6210\u81ea\u6211\u63d0\u5347\u3002", "method": "\u5f15\u5165\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u5c06\u5206\u6790\u5458\u3001\u7814\u7a76\u5458\u3001\u7f16\u7801\u5458\u548c\u73a9\u5bb6\u7684\u89d2\u8272\u8fdb\u884c\u534f\u4f5c\uff0c\u901a\u8fc7\u8fed\u4ee3\u5206\u6790\u6e38\u620f\u3001\u7814\u7a76\u65b0\u7b56\u7565\u4ee5\u53ca\u4fee\u6539\u4ee3\u7406\u903b\u8f91\u6216\u63d0\u793a\u6765\u6539\u8fdb\u4ee3\u7406\u3002", "result": "\u81ea\u52a8\u6f14\u53d8\u7684\u4ee3\u7406\u8d85\u8fc7\u9759\u6001\u57fa\u7ebf\uff0c\u901a\u8fc7\u81ea\u52a8\u91c7\u7528\u7b56\u7565\u3001\u4f20\u9012\u6837\u672c\u884c\u4e3a\u7ed9\u6e38\u620f\u4ee3\u7406\uff0c\u5e76\u5728\u591a\u6b21\u8fed\u4ee3\u4e2d\u5c55\u793a\u9002\u5e94\u6027\u63a8\u7406\u3002", "conclusion": "\u81ea\u52a8\u6f14\u53d8\u7684\u4ee3\u7406\u7279\u522b\u662f\u5728\u91c7\u7528Claude 3.7\u548cGPT-4o\u6a21\u578b\u65f6\uff0c\u901a\u8fc7\u81ea\u6211\u6539\u8fdb\u7b56\u7565\u3001\u4f20\u9012\u793a\u8303\u884c\u4e3a\u7ed9\u6e38\u620f\u4ee3\u7406\uff0c\u8868\u73b0\u51fa\u591a\u6b21\u8fed\u4ee3\u7684\u9002\u5e94\u6027\u63a8\u7406\u8d85\u8d8a\u9759\u6001\u57fa\u7ebf\u3002"}}
{"id": "2506.04349", "pdf": "https://arxiv.org/pdf/2506.04349", "abs": "https://arxiv.org/abs/2506.04349", "authors": ["Christos Sakaridis"], "title": "You Only Train Once", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 4 figures", "summary": "The title of this paper is perhaps an overclaim. Of course, the process of\ncreating and optimizing a learned model inevitably involves multiple training\nruns which potentially feature different architectural designs, input and\noutput encodings, and losses. However, our method, You Only Train Once (YOTO),\nindeed contributes to limiting training to one shot for the latter aspect of\nlosses selection and weighting. We achieve this by automatically optimizing\nloss weight hyperparameters of learned models in one shot via standard\ngradient-based optimization, treating these hyperparameters as regular\nparameters of the networks and learning them. To this end, we leverage the\ndifferentiability of the composite loss formulation which is widely used for\noptimizing multiple empirical losses simultaneously and model it as a novel\nlayer which is parameterized with a softmax operation that satisfies the\ninherent positivity constraints on loss hyperparameters while avoiding\ndegenerate empirical gradients. We complete our joint end-to-end optimization\nscheme by defining a novel regularization loss on the learned hyperparameters,\nwhich models a uniformity prior among the employed losses while ensuring\nboundedness of the identified optima. We evidence the efficacy of YOTO in\njointly optimizing loss hyperparameters and regular model parameters in one\nshot by comparing it to the commonly used brute-force grid search across\nstate-of-the-art networks solving two key problems in computer vision, i.e. 3D\nestimation and semantic segmentation, and showing that it consistently\noutperforms the best grid-search model on unseen test data. Code will be made\npublicly available.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u4f18\u5316\u635f\u5931\u6743\u91cd\u8d85\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u53ea\u9700\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u4f18\u5316\u6a21\u578b\u635f\u5931\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7f51\u683c\u641c\u7d22\u65b9\u6cd5\u3002", "motivation": "\u867d\u7136\u521b\u5efa\u548c\u4f18\u5316\u5b66\u4e60\u6a21\u578b\u7684\u8fc7\u7a0b\u6d89\u53ca\u591a\u6b21\u8bad\u7ec3\u8fd0\u884c\uff0c\u4f46\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u63d0\u51fa\u7684\u65b9\u6cd5\u5c06\u635f\u5931\u9009\u62e9\u548c\u6743\u91cd\u7684\u8bad\u7ec3\u9650\u5236\u4e3a\u4e00\u6b21\u6027\u8bad\u7ec3\u3002", "method": "\u81ea\u52a8\u4f18\u5316\u635f\u5931\u6743\u91cd\u8d85\u53c2\u6570\uff0c\u901a\u8fc7\u6807\u51c6\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\uff0c\u5c06\u8fd9\u4e9b\u8d85\u53c2\u6570\u89c6\u4e3a\u7f51\u7edc\u7684\u5e38\u89c4\u53c2\u6570\u5e76\u8fdb\u884c\u5b66\u4e60\u3002", "result": "YOTO\u5728\u4e00\u6b21\u6027\u8054\u5408\u4f18\u5316\u635f\u5931\u8d85\u53c2\u6570\u548c\u5e38\u89c4\u6a21\u578b\u53c2\u6570\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u4e0e\u7528\u4e8e\u8ba1\u7b97\u673a\u89c6\u89c9\u95ee\u9898\uff08\u59823D\u4f30\u8ba1\u548c\u8bed\u4e49\u5206\u5272\uff09\u7684\u6700\u5148\u8fdb\u7f51\u7edc\u7684\u66b4\u529b\u7f51\u683c\u641c\u7d22\u6bd4\u8f83\uff0c\u663e\u793a\u5728\u672a\u89c1\u6d4b\u8bd5\u6570\u636e\u4e0a\u6301\u7eed\u4f18\u4e8e\u6700\u4f73\u7f51\u683c\u641c\u7d22\u6a21\u578b\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5 YOTO \u901a\u8fc7\u81ea\u52a8\u4f18\u5316\u5b66\u4e60\u6a21\u578b\u7684\u635f\u5931\u6743\u91cd\u8d85\u53c2\u6570\uff0c\u6210\u529f\u5730\u5c06\u635f\u5931\u9009\u62e9\u548c\u6743\u91cd\u7684\u8bad\u7ec3\u9650\u5236\u4e3a\u4e00\u6b21\u6027\u8bad\u7ec3\u3002"}}
{"id": "2506.04575", "pdf": "https://arxiv.org/pdf/2506.04575", "abs": "https://arxiv.org/abs/2506.04575", "authors": ["Qingchuan Li", "Jiatong Li", "Zirui Liu", "Mingyue Cheng", "Yuting Zeng", "Qi Liu", "Tongxuan Liu"], "title": "Are LLMs Reliable Translators of Logical Reasoning Across Lexically Diversified Contexts?", "categories": ["cs.CL"], "comment": null, "summary": "Neuro-symbolic approaches combining large language models (LLMs) with solvers\nexcels in logical reasoning problems need long reasoning chains. In this\nparadigm, LLMs serve as translators, converting natural language reasoning\nproblems into formal logic formulas. Then reliable symbolic solvers return\ncorrect solutions. Despite their success, we find that LLMs, as translators,\nstruggle to handle lexical diversification, a common linguistic phenomenon,\nindicating that LLMs as logic translators are unreliable in real-world\nscenarios. Moreover, existing logical reasoning benchmarks lack lexical\ndiversity, failing to challenge LLMs' ability to translate such text and thus\nobscuring this issue. In this work, we propose SCALe, a benchmark designed to\naddress this significant gap through **logic-invariant lexical\ndiversification**. By using LLMs to transform original benchmark datasets into\nlexically diversified but logically equivalent versions, we evaluate LLMs'\nability to consistently map diverse expressions to uniform logical symbols on\nthese new datasets. Experiments using SCALe further confirm that current LLMs\nexhibit deficiencies in this capability. Building directly on the deficiencies\nidentified through our benchmark, we propose a new method, MenTaL, to address\nthis limitation. This method guides LLMs to first construct a table unifying\ndiverse expressions before performing translation. Applying MenTaL through\nin-context learning and supervised fine-tuning (SFT) significantly improves the\nperformance of LLM translators on lexically diversified text. Our code is now\navailable at https://github.com/wufeiwuwoshihua/LexicalDiver.", "AI": {"tldr": "\u63d0\u51fa\u4e86SCALe\u57fa\u51c6\u6d4b\u8bd5\u548c\u65b0\u65b9\u6cd5MenTaL\uff0c\u4ee5\u63d0\u9ad8LLM\u5728\u5904\u7406\u8bcd\u6c47\u591a\u6837\u5316\u6587\u672c\u4e2d\u7684\u7ffb\u8bd1\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u7f3a\u4e4f\u8bcd\u6c47\u591a\u6837\u6027\uff0c\u672a\u80fd\u5145\u5206\u8003\u9a8cLLM\u7684\u7ffb\u8bd1\u80fd\u529b\uff0c\u5bfc\u81f4LLM\u5728\u7ffb\u8bd1\u591a\u6837\u5316\u8bcd\u6c47\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u6311\u6218\u548c\u63d0\u5347\u8fd9\u4e00\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5MenTaL\uff0c\u901a\u8fc7\u5728\u7ffb\u8bd1\u524d\u5f15\u5bfcLLMs\u6784\u5efa\u7edf\u4e00\u7684\u8868\u8fbe\u5f62\u5f0f\u8868\u6765\u89e3\u51b3\u8bcd\u6c47\u591a\u6837\u5316\u95ee\u9898\u3002\u6b64\u5916\uff0c\u91c7\u7528\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u6765\u589e\u5f3a\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709LLMs\u5728\u5e94\u5bf9\u8bcd\u6c47\u591a\u6837\u5316\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002\u4f7f\u7528SCALe\u57fa\u51c6\u6d4b\u8bd5\u5e76\u5e94\u7528MenTaL\u65b9\u6cd5\u540e\uff0cLLMs\u7684\u8868\u73b0\u5f97\u5230\u663e\u8457\u6539\u5584\u3002", "conclusion": "\u901a\u8fc7\u65b0\u65b9\u6cd5MenTaL\u7684\u5e94\u7528\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u7ffb\u8bd1\u5668\u5728\u8bcd\u6c47\u591a\u6837\u5316\u6587\u672c\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2506.04654", "pdf": "https://arxiv.org/pdf/2506.04654", "abs": "https://arxiv.org/abs/2506.04654", "authors": ["Zhichao Yang", "Jiashu He", "Mohammad B. Al-Khasawneh", "Darshan Pandit", "Cirillo Cinzia"], "title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety\nconcerns due to a rise in accident reports. However, e-bike incident reports\noften use unstructured narrative formats, which hinders quantitative safety\nanalysis. This study introduces E-bike agents, a framework that uses large\nlanguage models (LLM) powered agents to classify and extract safety variables\nfrom unstructured incident reports. Our framework consists of four LLM agents,\nhandling data classification, information extraction, injury cause\ndetermination, and component linkage, to extract the key factors that could\nlead to E-bike accidents and cause varying severity levels. Furthermore, we\nused an ordered logit model to examine the relationship between the severity of\nthe incident and the factors retrieved, such as gender, the type of cause, and\nenvironmental conditions. Our research shows that equipment issues are slightly\nmore common than human-related ones, but human-related incidents are more often\nfatal. Specifically, pedals, tires, and brakes are frequent contributors to\naccidents. The model achieves a high weighted F1 score of 0.87 in\nclassification accuracy, highlighting the potential of using LLMs to extract\nunstructured data in niche domains, such as transportation. Our method offers a\nscalable solution to improve e-bike safety analytics and provides actionable\ninformation for policy makers, designers, and regulators.", "AI": {"tldr": "\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f7f\u7528LLM\u7684\u6846\u67b6\uff0c\u80fd\u4ece\u975e\u7ed3\u6784\u5316\u7684\u7535\u52a8\u81ea\u884c\u8f66\u4e8b\u6545\u62a5\u544a\u4e2d\u63d0\u53d6\u5173\u952e\u5b89\u5168\u56e0\u7d20\uff0c\u6539\u5584\u5b89\u5168\u5206\u6790\uff0c\u5e76\u4e3a\u76f8\u5173\u65b9\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u4fe1\u606f\u3002", "motivation": "\u7531\u4e8e\u7535\u52a8\u81ea\u884c\u8f66\u4e8b\u6545\u62a5\u544a\u5e38\u4e3a\u975e\u7ed3\u6784\u5316\u53d9\u8ff0\u683c\u5f0f\uff0c\u7ed9\u91cf\u5316\u5b89\u5168\u5206\u6790\u5e26\u6765\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5206\u7c7b\u63d0\u53d6\u8fd9\u4e9b\u62a5\u544a\u4e2d\u5b89\u5168\u53d8\u91cf\u7684\u6846\u67b6\u3002", "method": "\u6784\u5efa\u4e86\u7531\u56db\u4e2aLLM\u4ee3\u7406\u7ec4\u6210\u7684\u6846\u67b6\uff0c\u5206\u522b\u8d1f\u8d23\u6570\u636e\u5206\u7c7b\u3001\u4fe1\u606f\u63d0\u53d6\u3001\u4e8b\u6545\u539f\u56e0\u5224\u65ad\u548c\u7ec4\u4ef6\u5173\u8054\uff1b\u5e76\u4f7f\u7528\u6709\u5e8flogit\u6a21\u578b\u5206\u6790\u4e8b\u6545\u4e25\u91cd\u7a0b\u5ea6\u548c\u63d0\u53d6\u56e0\u7d20\u7684\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bbe\u5907\u95ee\u9898\u7565\u591a\u4e8e\u4eba\u4e3a\u539f\u56e0\uff0c\u4f46\u4eba\u4e3a\u56e0\u7d20\u5bfc\u81f4\u7684\u4e8b\u6545\u66f4\u81f4\u547d\uff1b\u6a21\u578b\u5728\u5206\u7c7b\u51c6\u786e\u6027\u4e0a\u8fbe\u52300.87\u7684F1\u52a0\u6743\u5206\u6570\uff0c\u5c55\u793a\u4e86LLM\u5728\u4ea4\u901a\u7b49\u5c0f\u4f17\u9886\u57df\u63d0\u53d6\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u5f00\u53d1\u7684LLM\u6846\u67b6\u80fd\u591f\u6709\u6548\u5206\u7c7b\u4e0e\u63d0\u53d6\u975e\u7ed3\u6784\u5316\u7535\u52a8\u81ea\u884c\u8f66\u4e8b\u6545\u62a5\u544a\u4e2d\u7684\u5b89\u5168\u53d8\u91cf\uff0c\u63d0\u9ad8\u5b89\u5168\u5206\u6790\u7684\u5b9a\u91cf\u5316\u80fd\u529b\u3002"}}
{"id": "2506.04352", "pdf": "https://arxiv.org/pdf/2506.04352", "abs": "https://arxiv.org/abs/2506.04352", "authors": ["Ethem Alpaydin"], "title": "Half-Layered Neural Networks", "categories": ["cs.LG"], "comment": "11 pages, 8 figures", "summary": "We propose a ``half'' layer of hidden units that has some of its weights\nrandomly set and some of them trained. A half unit is composed of two stages:\nFirst, it takes a weighted sum of its inputs with fixed random weights, and\nsecond, the total activation is multiplied and then translated using two\nmodifiable weights, before the result is passed through a nonlinearity. The\nnumber of modifiable weights of each hidden unit is thus two and does not\ndepend on the fan-in. We show how such half units can be used in the first or\nany later layer in a deep network, possibly following convolutional layers. Our\nexperiments on MNIST and FashionMNIST data sets indicate the promise of half\nlayers, where we can achieve reasonable accuracy with a reduced number of\nparameters due to the regularizing effect of the randomized connections.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u201c\u534a\u201d\u9690\u85cf\u5c42\uff0c\u901a\u8fc7\u968f\u673a\u548c\u8bad\u7ec3\u6743\u91cd\u7ed3\u5408\uff0c\u51cf\u5c11\u53c2\u6570\u91cf\u4e14\u63d0\u5347\u6b63\u5219\u5316\u6548\u679c\uff0c\u5728MNIST\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6df1\u5ea6\u7f51\u7edc\u4e2d\u53c2\u6570\u8fc7\u591a\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u7387\u7684\u540c\u65f6\u51cf\u5c11\u53c2\u6570\u7684\u534a\u5c42\u6784\u9020\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u201c\u534a\u201d\u9690\u85cf\u5c42\uff0c\u5176\u90e8\u5206\u6743\u91cd\u968f\u673a\u8bbe\u5b9a\uff0c\u90e8\u5206\u6743\u91cd\u8fdb\u884c\u8bad\u7ec3\u3002\u6bcf\u4e2a\u534a\u5355\u5143\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\u901a\u8fc7\u56fa\u5b9a\u968f\u673a\u6743\u91cd\u5bf9\u8f93\u5165\u8fdb\u884c\u52a0\u6743\u6c42\u548c\uff1b\u7136\u540e\uff0c\u901a\u8fc7\u4e24\u4e2a\u53ef\u8c03\u6743\u91cd\u8fdb\u884c\u4e58\u6cd5\u548c\u5e73\u79fb\uff0c\u518d\u7ecf\u8fc7\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u3002", "result": "\u5728MNIST\u548cFashionMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u534a\u5c42\u7ed3\u6784\u80fd\u591f\u5728\u53c2\u6570\u51cf\u5c11\u7684\u540c\u65f6\u4fdd\u6301\u5408\u7406\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u534a\u5c42\u7ed3\u6784\u7684\u9690\u85cf\u5355\u5143\u5728\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u7684\u60c5\u51b5\u4e0b\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u8868\u73b0\u51fa\u968f\u673a\u8fde\u63a5\u7684\u6b63\u5219\u5316\u6548\u5e94\u3002"}}
{"id": "2506.04579", "pdf": "https://arxiv.org/pdf/2506.04579", "abs": "https://arxiv.org/abs/2506.04579", "authors": ["Jianfei Zhang", "Bei Li", "Jun Bai", "Rumei Li", "Yanmeng Wang", "Chenghua Lin", "Wenge Rong"], "title": "Selecting Demonstrations for Many-Shot In-Context Learning via Gradient Matching", "categories": ["cs.CL"], "comment": "accepted to the ACL2025 Findings", "summary": "In-Context Learning (ICL) empowers Large Language Models (LLMs) for rapid\ntask adaptation without Fine-Tuning (FT), but its reliance on demonstration\nselection remains a critical challenge. While many-shot ICL shows promising\nperformance through scaled demonstrations, the selection method for many-shot\ndemonstrations remains limited to random selection in existing work. Since the\nconventional instance-level retrieval is not suitable for many-shot scenarios,\nwe hypothesize that the data requirements for in-context learning and\nfine-tuning are analogous. To this end, we introduce a novel gradient matching\napproach that selects demonstrations by aligning fine-tuning gradients between\nthe entire training set of the target task and the selected examples, so as to\napproach the learning effect on the entire training set within the selected\nexamples. Through gradient matching on relatively small models, e.g.,\nQwen2.5-3B or Llama3-8B, our method consistently outperforms random selection\non larger LLMs from 4-shot to 128-shot scenarios across 9 diverse datasets. For\ninstance, it surpasses random selection by 4% on Qwen2.5-72B and Llama3-70B,\nand by around 2% on 5 closed-source LLMs. This work unlocks more reliable and\neffective many-shot ICL, paving the way for its broader application.", "AI": {"tldr": "\u5f15\u5165\u68af\u5ea6\u5339\u914d\u65b9\u6cd5\u6539\u8fdb\u6f14\u793a\u9009\u62e9\uff0c\u63d0\u5347\u4e86\u591a\u793a\u4f8b\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6548\u679c\u3002\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u76f8\u8f83\u968f\u673a\u9009\u62e9\u6709\u660e\u663e\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u6f14\u793a\u9009\u62e9\u7684\u968f\u673a\u5316\u95ee\u9898\u3002\u5728\u8bb8\u591a\u6848\u4f8b\u6f14\u793a\u4e2d\uff0c\u7531\u4e8e\u4f20\u7edf\u7684\u5b9e\u4f8b\u7ea7\u68c0\u7d22\u4e0d\u9002\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u7136\u91c7\u7528\u968f\u673a\u9009\u62e9\u3002\u8fd9\u9650\u5236\u4e86\u9886\u57df\u5185\u77e5\u8bc6\u6a21\u578b\u5feb\u901f\u9002\u5e94\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u68af\u5ea6\u5339\u914d\u65b9\u6cd5\uff0c\u9009\u62e9\u6f14\u793a\u6837\u672c\uff0c\u4f7f\u5176\u5fae\u8c03\u68af\u5ea6\u4e0e\u76ee\u6807\u4efb\u52a1\u7684\u6574\u4e2a\u8bad\u7ec3\u96c6\u5bf9\u9f50\uff0c\u8bd5\u56fe\u5728\u9009\u5b9a\u6837\u672c\u5185\u5b9e\u73b0\u6574\u4e2a\u8bad\u7ec3\u96c6\u7684\u5b66\u4e60\u6548\u679c\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4ece4-shot\u5230128-shot\u7684\u573a\u666f\u4e0b\uff0c\u5728\u5305\u62ecQwen2.5-72B\u548cLlama3-70B\u5728\u5185\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u8f83\u968f\u673a\u9009\u62e9\u6709\u663e\u8457\u63d0\u9ad8\u3002\u4f8b\u5982\uff0c\u5728Qwen2.5-72B\u548cLlama3-70B\u4e0a\u8d85\u8fc7\u968f\u673a\u9009\u62e94%\uff0c\u57285\u4e2a\u95ed\u6e90\u6a21\u578b\u4e0a\u5927\u7ea6\u63d0\u9ad82%\u3002", "conclusion": "\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u591a\u793a\u4f8b\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2506.04699", "pdf": "https://arxiv.org/pdf/2506.04699", "abs": "https://arxiv.org/abs/2506.04699", "authors": ["Bihan Xu", "Shiwei Zhao", "Runze Wu", "Zhenya Huang", "Jiawei Wang", "Zhipeng Hu", "Kai Wang", "Haoyu Liu", "Tangjie Lv", "Le Li", "Changjie Fan", "Xin Tong", "Jiangze Han"], "title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "categories": ["cs.AI"], "comment": "KDD2025 Accepted", "summary": "Within the domain of Massively Multiplayer Online (MMO) economy research,\nAgent-Based Modeling (ABM) has emerged as a robust tool for analyzing game\neconomics, evolving from rule-based agents to decision-making agents enhanced\nby reinforcement learning. Nevertheless, existing works encounter significant\nchallenges when attempting to emulate human-like economic activities among\nagents, particularly regarding agent reliability, sociability, and\ninterpretability. In this study, we take a preliminary step in introducing a\nnovel approach using Large Language Models (LLMs) in MMO economy simulation.\nLeveraging LLMs' role-playing proficiency, generative capacity, and reasoning\naptitude, we design LLM-driven agents with human-like decision-making and\nadaptability. These agents are equipped with the abilities of role-playing,\nperception, memory, and reasoning, addressing the aforementioned challenges\neffectively. Simulation experiments focusing on in-game economic activities\ndemonstrate that LLM-empowered agents can promote emergent phenomena like role\nspecialization and price fluctuations in line with market rules.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165LLM\u9a71\u52a8\u7684\u4ee3\u7406\uff0c\u4e3aMMO\u7ecf\u6d4e\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u6a21\u62df\u4e2d\u7684\u82e5\u5e72\u6311\u6218\u5e76\u4fc3\u8fdb\u884c\u4e3a\u73b0\u8c61\u7684\u51fa\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u5728\u6a21\u62df\u4eba\u7c7b\u7ecf\u6d4e\u6d3b\u52a8\u65b9\u9762\u5b58\u5728\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u4ee3\u7406\u7684\u53ef\u9760\u6027\u3001\u793e\u4ea4\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u8bd5\u56fe\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u8bbe\u8ba1\u9a71\u52a8\u4ee3\u7406\uff0c\u8fd9\u4e9b\u4ee3\u7406\u5177\u6709\u7c7b\u4f3c\u4eba\u7c7b\u7684\u51b3\u7b56\u80fd\u529b\u548c\u9002\u5e94\u6027\uff0c\u80fd\u591f\u8fdb\u884c\u89d2\u8272\u626e\u6f14\u3001\u611f\u77e5\u3001\u8bb0\u5fc6\u548c\u63a8\u7406\u3002", "result": "LLM\u9a71\u52a8\u7684\u4ee3\u7406\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u6e38\u620f\u5185\u7ecf\u6d4e\u6d3b\u52a8\u4e2d\u7684\u73b0\u8c61\uff0c\u4f8b\u5982\u89d2\u8272\u4e13\u4e1a\u5316\u548c\u4ef7\u683c\u6ce2\u52a8\uff0c\u8fd9\u4e9b\u73b0\u8c61\u7b26\u5408\u5e02\u573a\u89c4\u5219\u3002", "conclusion": "\u4f7f\u7528LLM\u8bbe\u8ba1\u7684\u4ee3\u7406\u80fd\u591f\u89e3\u51b3\u4ee5\u5f80\u7814\u7a76\u4e2d\u7684\u6311\u6218\uff0c\u901a\u8fc7\u89d2\u8272\u626e\u6f14\u548c\u63a8\u7406\u80fd\u529b\u63d0\u5347\u7ecf\u6d4e\u6d3b\u52a8\u7684\u771f\u5b9e\u6027\u548c\u52a8\u6001\u6027\u3002"}}
{"id": "2506.04358", "pdf": "https://arxiv.org/pdf/2506.04358", "abs": "https://arxiv.org/abs/2506.04358", "authors": ["Uditansh Srivastava", "Shivam Aryan", "Shaurya Singh"], "title": "A Risk-Aware Reinforcement Learning Reward for Financial Trading", "categories": ["cs.LG"], "comment": "14 pages, 11 figures", "summary": "We propose a novel composite reward function for reinforcement learning in\nfinancial trading that balances return and risk using four differentiable\nterms: annualized return downside risk differential return and the Treynor\nratio\n  Unlike single metric objectives for example the Sharpe ratio our formulation\nis modular and parameterized by weights w1 w2 w3 and w4 enabling practitioners\nto encode diverse investor preferences\n  We tune these weights via grid search to target specific risk return profiles\n  We derive closed form gradients for each term to facilitate gradient based\ntraining and analyze key theoretical properties including monotonicity\nboundedness and modularity\n  This framework offers a general blueprint for building robust multi objective\nreward functions in complex trading environments and can be extended with\nadditional risk measures or adaptive weighting", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6a21\u5757\u5316\u7ec4\u5408\u5956\u52b1\u51fd\u6570\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u91d1\u878d\u4ea4\u6613\uff0c\u901a\u8fc7\u8c03\u6574\u4e0d\u540c\u6307\u6807\u6743\u91cd\u6765\u5e73\u8861\u98ce\u9669\u548c\u6536\u76ca\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u3002", "motivation": "\u80a1\u7968\u4ea4\u6613\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7740\u5e73\u8861\u6536\u76ca\u548c\u98ce\u9669\u7684\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u8003\u8651\u591a\u9879\u98ce\u9669\u4e0e\u6536\u76ca\u6307\u6807\u7684\u5956\u52b1\u51fd\u6570\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ec4\u5408\u5956\u52b1\u51fd\u6570\uff0c\u4f7f\u7528\u5e74\u5316\u6536\u76ca\u3001\u4e0b\u884c\u98ce\u9669\u3001\u5dee\u5f02\u5316\u6536\u76ca\u548c\u7279\u96f7\u8bfa\u6bd4\u7387\u4f5c\u4e3a\u53ef\u5fae\u5206\u9879\uff0c\u5e76\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u8c03\u6574\u53c2\u6570\u4ee5\u5b9e\u73b0\u7279\u5b9a\u7684\u98ce\u9669\u6536\u76ca\u914d\u7f6e\u3002\u540c\u65f6\u63a8\u5bfc\u6bcf\u4e2a\u6761\u6b3e\u7684\u95ed\u5408\u5f62\u5f0f\u68af\u5ea6\u4ee5\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u3002", "result": "\u8fd9\u6846\u67b6\u4e3a\u5728\u590d\u6742\u4ea4\u6613\u73af\u5883\u4e2d\u6784\u5efa\u7a33\u5065\u7684\u591a\u76ee\u6807\u5956\u52b1\u51fd\u6570\u63d0\u4f9b\u4e86\u901a\u7528\u84dd\u56fe\uff0c\u5e76\u53ef\u4ee5\u901a\u8fc7\u52a0\u5165\u5176\u4ed6\u98ce\u9669\u5ea6\u91cf\u548c\u81ea\u9002\u5e94\u6743\u91cd\u8fdb\u884c\u6269\u5c55\u3002", "conclusion": "\u8fd9\u79cd\u7ec4\u5408\u5956\u52b1\u51fd\u6570\u4f7f\u5f3a\u5316\u5b66\u4e60\u5728\u91d1\u878d\u4ea4\u6613\u4e2d\u80fd\u591f\u66f4\u6709\u6548\u5730\u5e73\u8861\u6536\u76ca\u4e0e\u98ce\u9669\uff0c\u5177\u5907\u5355\u4e00\u5ea6\u91cf\u76ee\u6807\u65e0\u6cd5\u8fbe\u5230\u7684\u7075\u6d3b\u6027\u548c\u81ea\u9002\u5e94\u6027\u3002"}}
{"id": "2506.04583", "pdf": "https://arxiv.org/pdf/2506.04583", "abs": "https://arxiv.org/abs/2506.04583", "authors": ["Hongjun Liu", "Yilun Zhao", "Arman Cohan", "Chen Zhao"], "title": "SUCEA: Reasoning-Intensive Retrieval for Adversarial Fact-checking through Claim Decomposition and Editing", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 10 figures, 7 tables", "summary": "Automatic fact-checking has recently received more attention as a means of\ncombating misinformation. Despite significant advancements, fact-checking\nsystems based on retrieval-augmented language models still struggle to tackle\nadversarial claims, which are intentionally designed by humans to challenge\nfact-checking systems. To address these challenges, we propose a training-free\nmethod designed to rephrase the original claim, making it easier to locate\nsupporting evidence. Our modular framework, SUCEA, decomposes the task into\nthree steps: 1) Claim Segmentation and Decontextualization that segments\nadversarial claims into independent sub-claims; 2) Iterative Evidence Retrieval\nand Claim Editing that iteratively retrieves evidence and edits the subclaim\nbased on the retrieved evidence; 3) Evidence Aggregation and Label Prediction\nthat aggregates all retrieved evidence and predicts the entailment label.\nExperiments on two challenging fact-checking datasets demonstrate that our\nframework significantly improves on both retrieval and entailment label\naccuracy, outperforming four strong claim-decomposition-based baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u65b9\u6cd5SUCEA\uff0c\u901a\u8fc7\u7ec6\u5206\u58f0\u660e\u548c\u8fed\u4ee3\u68c0\u7d22\u8bc1\u636e\u6765\u63d0\u5347\u4e8b\u5b9e\u6838\u67e5\u51c6\u786e\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5728\u5904\u7406\u5bf9\u6297\u6027\u58f0\u660e\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65e0\u8bad\u7ec3\u65b9\u6cd5SUCEA\uff0c\u5206\u4e3a\u4e09\u4e2a\u6b65\u9aa4\uff1a1\uff09\u58f0\u660e\u5206\u5272\u548c\u53bb\u8bed\u5883\u5316\uff1b2\uff09\u8fed\u4ee3\u68c0\u7d22\u8bc1\u636e\u548c\u58f0\u660e\u7f16\u8f91\uff1b3\uff09\u8bc1\u636e\u805a\u5408\u548c\u6807\u7b7e\u9884\u6d4b\u3002", "result": "\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u4e8b\u5b9e\u6838\u67e5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5728\u68c0\u7d22\u548c\u8574\u6db5\u6807\u7b7e\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u63d0\u5347\uff0c\u8d85\u8fc7\u4e86\u56db\u4e2a\u5f3a\u5927\u7684\u57fa\u7ebf\u3002", "conclusion": "\u6211\u4eec\u7684\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u548c\u8574\u6db5\u6807\u7b7e\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u56db\u79cd\u5f3a\u5927\u7684\u57fa\u4e8e\u58f0\u660e\u5206\u89e3\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.04723", "pdf": "https://arxiv.org/pdf/2506.04723", "abs": "https://arxiv.org/abs/2506.04723", "authors": ["Jiayu Wang", "Yifei Ming", "Zixuan Ke", "Caiming Xiong", "Shafiq Joty", "Aws Albarghouthi", "Frederic Sala"], "title": "Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become the dominant paradigm for endowing\nlanguage models with advanced reasoning capabilities. Despite the substantial\nempirical gains demonstrated by RL-based training methods like GRPO, a granular\nunderstanding of their advantages is still lacking. To address this gap, we\nintroduce a fine-grained analytic framework to dissect the impact of RL on\nreasoning. Our framework specifically investigates key elements that have been\nhypothesized to benefit from RL training: (1) plan-following and execution, (2)\nproblem decomposition, and (3) improved reasoning and knowledge utilization.\nUsing this framework, we gain insights beyond mere accuracy. For instance,\nproviding models with explicit step-by-step plans surprisingly degrades\nperformance on the most challenging benchmarks, yet RL-tuned models exhibit\ngreater robustness, experiencing markedly smaller performance drops than their\nbase counterparts. This suggests that RL may not primarily enhance the\nexecution of external plans but rather empower models to formulate and follow\ninternal strategies better suited to their reasoning processes. Conversely, we\nobserve that RL enhances the model's capacity to integrate provided knowledge\ninto its reasoning process, leading to performance improvements across diverse\ntasks. We also study difficulty, showing improved training by developing new\nways to exploit hard problems. Our findings lay a foundation for more\nprincipled training and evaluation of reasoning models.", "AI": {"tldr": "RL\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u7b56\u7565\u5236\u5b9a\u548c\u77e5\u8bc6\u6574\u5408\u4e0a\u3002", "motivation": "\u867d\u7136RL\u5728\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u663e\u793a\u4e86\u663e\u8457\u7684\u7ecf\u9a8c\u589e\u76ca\uff0c\u4f46\u5bf9\u5176\u4f18\u52bf\u7684\u7ec6\u5316\u7406\u89e3\u4ecd\u6709\u6b20\u7f3a\u3002", "method": "\u5f15\u5165\u7ec6\u81f4\u7684\u5206\u6790\u6846\u67b6\u6765\u7814\u7a76RL\u5bf9\u63a8\u7406\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u8ba1\u5212\u6267\u884c\u3001\u95ee\u9898\u5206\u89e3\u548c\u77e5\u8bc6\u5229\u7528\u7b49\u5143\u7d20\u3002", "result": "\u5373\u4f7f\u4e3a\u6a21\u578b\u63d0\u4f9b\u660e\u786e\u7684\u8ba1\u5212\u6b65\u9aa4\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\uff0cRL\u4f18\u5316\u7684\u6a21\u578b\u5374\u8868\u73b0\u51fa\u66f4\u5927\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u6574\u5408\u77e5\u8bc6\u65f6\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "RL\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6574\u5408\u77e5\u8bc6\u548c\u5185\u90e8\u7b56\u7565\u5236\u5b9a\u65b9\u9762\u3002"}}
{"id": "2506.04360", "pdf": "https://arxiv.org/pdf/2506.04360", "abs": "https://arxiv.org/abs/2506.04360", "authors": ["Philippe Chlenski", "Itsik Pe'er"], "title": "Even Faster Hyperbolic Random Forests: A Beltrami-Klein Wrapper Approach", "categories": ["cs.LG"], "comment": "15 pages, 4 figures, 2 tables", "summary": "Decision trees and models that use them as primitives are workhorses of\nmachine learning in Euclidean spaces. Recent work has further extended these\nmodels to the Lorentz model of hyperbolic space by replacing axis-parallel\nhyperplanes with homogeneous hyperplanes when partitioning the input space. In\nthis paper, we show how the hyperDT algorithm can be elegantly reexpressed in\nthe Beltrami-Klein model of hyperbolic spaces. This preserves the thresholding\noperation used in Euclidean decision trees, enabling us to further rewrite\nhyperDT as simple pre- and post-processing steps that form a wrapper around\nexisting tree-based models designed for Euclidean spaces. The wrapper approach\nunlocks many optimizations already available in Euclidean space models,\nimproving flexibility, speed, and accuracy while offering a simpler, more\nmaintainable, and extensible codebase. Our implementation is available at\nhttps://github.com/pchlenski/hyperdt.", "AI": {"tldr": "\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8d85DT\u7b97\u6cd5\u8f6c\u5316\u4e3aBeltrami-Klein\u6a21\u578b\uff0c\u4ee5\u63d0\u9ad8\u53cc\u66f2\u7a7a\u95f4\u4e2d\u7684\u51b3\u7b56\u6811\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u53cc\u66f2\u7a7a\u95f4\u7684\u6d1b\u4f26\u5179\u6a21\u578b\u4e2d\uff0c\u7528\u540c\u8d28\u8d85\u5e73\u9762\u66ff\u4ee3\u8f74\u5e73\u884c\u8d85\u5e73\u9762\u6765\u5212\u5206\u8f93\u5165\u7a7a\u95f4\uff0c\u4f46\u9700\u8981\u5bfb\u627e\u4e00\u79cd\u66f4\u4f18\u96c5\u4e14\u80fd\u591f\u4fdd\u6301\u9608\u503c\u64cd\u4f5c\u7684\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5c06\u8d85DT\u7b97\u6cd5\u91cd\u65b0\u8868\u8fbe\u4e3aBeltrami-Klein\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u7b80\u5355\u7684\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u6b65\u9aa4\uff0c\u5c06\u5176\u5305\u88c5\u5728\u73b0\u6709\u7684\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u6811\u6a21\u578b\u5468\u56f4\u3002", "result": "\u901a\u8fc7\u5305\u88c5\u65b9\u6cd5\uff0c\u89e3\u9501\u4e86\u8bb8\u591a\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u6a21\u578b\u4e2d\u5df2\u7ecf\u53ef\u7528\u7684\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u7b97\u6cd5\u7684\u7075\u6d3b\u6027\u3001\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u7b80\u5355\u3001\u6613\u7ef4\u62a4\u548c\u53ef\u6269\u5c55\u7684\u4ee3\u7801\u5e93\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8d85DT\u7b97\u6cd5\u91cd\u65b0\u8868\u8fbe\u4e3a\u53cc\u66f2\u7a7a\u95f4Beltrami-Klein\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u3001\u901f\u5ea6\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.04585", "pdf": "https://arxiv.org/pdf/2506.04585", "abs": "https://arxiv.org/abs/2506.04585", "authors": ["Yash Kumar Lal", "Manikanta Bandham", "Mohammad Saqib Hasan", "Apoorva Kashi", "Mahnaz Koupaee", "Niranjan Balasubramanian"], "title": "MuSciClaims: Multimodal Scientific Claim Verification", "categories": ["cs.CL"], "comment": null, "summary": "Assessing scientific claims requires identifying, extracting, and reasoning\nwith multimodal data expressed in information-rich figures in scientific\nliterature. Despite the large body of work in scientific QA, figure captioning,\nand other multimodal reasoning tasks over chart-based data, there are no\nreadily usable multimodal benchmarks that directly test claim verification\nabilities. To remedy this gap, we introduce a new benchmark MuSciClaims\naccompanied by diagnostics tasks. We automatically extract supported claims\nfrom scientific articles, which we manually perturb to produce contradicted\nclaims. The perturbations are designed to test for a specific set of claim\nverification capabilities. We also introduce a suite of diagnostic tasks that\nhelp understand model failures. Our results show most vision-language models\nare poor (~0.3-0.5 F1), with even the best model only achieving 0.77 F1. They\nare also biased towards judging claims as supported, likely misunderstanding\nnuanced perturbations within the claims. Our diagnostics show models are bad at\nlocalizing correct evidence within figures, struggle with aggregating\ninformation across modalities, and often fail to understand basic components of\nthe figure.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6MuSciClaims\u6765\u6d4b\u8bd5\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u5f20\u9a8c\u8bc1\u80fd\u529b\uff0c\u53d1\u73b0\u591a\u6570\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bf9\u4e3b\u5f20\u7684\u652f\u6301\u5224\u65ad\u5b58\u5728\u504f\u89c1\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u76f4\u63a5\u6d4b\u8bd5\u79d1\u5b66\u6587\u7ae0\u4e2d\u4e3b\u5f20\u9a8c\u8bc1\u80fd\u529b\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\uff0c\u800c\u79d1\u5b66\u95ee\u7b54\u3001\u56fe\u8868\u6ce8\u91ca\u7b49\u9886\u57df\u5df2\u6709\u5927\u91cf\u7814\u7a76\u5de5\u4f5c\u3002\u8be5\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u81ea\u52a8\u4ece\u79d1\u5b66\u6587\u7ae0\u4e2d\u63d0\u53d6\u652f\u6301\u7684\u4e3b\u5f20\uff0c\u624b\u52a8\u8fdb\u884c\u6270\u52a8\u4ee5\u4ea7\u751f\u77db\u76fe\u7684\u4e3b\u5f20\uff0c\u5e76\u901a\u8fc7\u8fd9\u4e9b\u8bbe\u8ba1\u6270\u52a8\u6765\u6d4b\u8bd5\u5177\u4f53\u7684\u4e3b\u5f20\u9a8c\u8bc1\u80fd\u529b\u3002\u5f15\u5165\u4e86\u4e00\u5957\u8bca\u65ad\u4efb\u52a1\u6765\u5e2e\u52a9\u7406\u89e3\u6a21\u578b\u7684\u5931\u8d25\u4e4b\u5904\u3002", "result": "\u5927\u591a\u6570\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u5f20\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\uff0cF1\u5f97\u5206\u57280.3-0.5\u4e4b\u95f4\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u4e5f\u4ec5\u8fbe\u52300.77 F1\u3002\u6a21\u578b\u5bf9\u4e3b\u5f20\u7684\u652f\u6301\u5224\u65ad\u5b58\u5728\u504f\u89c1\uff0c\u96be\u4ee5\u5b9a\u4f4d\u56fe\u8868\u4e2d\u7684\u6b63\u786e\u8bc1\u636e\uff0c\u96be\u4ee5\u8de8\u6a21\u6001\u805a\u5408\u4fe1\u606f\uff0c\u5e76\u4e14\u5e38\u5e38\u4e0d\u80fd\u7406\u89e3\u56fe\u8868\u7684\u57fa\u672c\u7ec4\u6210\u90e8\u5206\u3002", "conclusion": "\u5f53\u524d\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9a8c\u8bc1\u79d1\u5b66\u6587\u7ae0\u4e2d\u7684\u4e3b\u5f20\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u504f\u5411\u4e8e\u652f\u6301\u4e3b\u5f20\u7684\u8d8b\u52bf\uff0c\u5e76\u4e14\u5bf9\u4e3b\u5f20\u4e2d\u7684\u5fae\u5999\u6270\u52a8\u8bef\u89e3\u3002\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6MuSciClaims\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u4e3b\u5f20\u9a8c\u8bc1\u80fd\u529b\u3002"}}
{"id": "2506.04734", "pdf": "https://arxiv.org/pdf/2506.04734", "abs": "https://arxiv.org/abs/2506.04734", "authors": ["Lin Sun", "Weihong Lin", "Jinzhu Wu", "Yongfu Zhu", "Xiaoqi Jian", "Guangxiang Zhao", "Change Jia", "Linglin Zhang", "Sai-er Hu", "Yuhan Wu", "Xiangzheng Zhang"], "title": "Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning models represented by the Deepseek-R1-Distill series have been\nwidely adopted by the open-source community due to their strong performance in\nmathematics, science, programming, and other domains. However, our study\nreveals that their benchmark evaluation results are subject to significant\nfluctuations caused by various factors. Subtle differences in evaluation\nconditions can lead to substantial variations in results. Similar phenomena are\nobserved in other open-source inference models fine-tuned based on the\nDeepseek-R1-Distill series, as well as in the QwQ-32B model, making their\nclaimed performance improvements difficult to reproduce reliably. Therefore, we\nadvocate for the establishment of a more rigorous paradigm for model\nperformance evaluation and present our empirical assessments of the\nDeepseek-R1-Distill series models.", "AI": {"tldr": "\u63a8\u7406\u6a21\u578b\u8bc4\u4f30\u7ed3\u679c\u6ce2\u52a8\u663e\u8457\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u786e\u4fdd\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u7ed3\u679c\u5b58\u5728\u6ce2\u52a8\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u52a0\u4e25\u683c\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "method": "\u5bf9Deepseek-R1-Distill\u7cfb\u5217\u6a21\u578b\u8fdb\u884c\u7ecf\u9a8c\u8bc4\u4f30\uff0c\u5206\u6790\u5176\u5728\u4e0d\u540c\u8bc4\u4f30\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u8bc4\u4f30\u63ed\u793a\u8bc4\u4f30\u6761\u4ef6\u5fae\u5c0f\u5dee\u5f02\u5bfc\u81f4\u7ed3\u679c\u663e\u8457\u53d8\u5316\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u518d\u73b0\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u63a8\u7406\u6a21\u578b\u5728\u6027\u80fd\u8bc4\u4f30\u4e2d\u5b58\u5728\u663e\u8457\u6ce2\u52a8\uff0c\u5f71\u54cd\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2506.04377", "pdf": "https://arxiv.org/pdf/2506.04377", "abs": "https://arxiv.org/abs/2506.04377", "authors": ["Yasaman Mahdaviyeh", "James Lucas", "Mengye Ren", "Andreas S. Tolias", "Richard Zemel", "Toniann Pitassi"], "title": "Replay Can Provably Increase Forgetting", "categories": ["cs.LG"], "comment": "To appear in the Proceedings of the Conference on Lifelong Learning\n  Agents (CoLLAs) 2025", "summary": "Continual learning seeks to enable machine learning systems to solve an\nincreasing corpus of tasks sequentially. A critical challenge for continual\nlearning is forgetting, where the performance on previously learned tasks\ndecreases as new tasks are introduced. One of the commonly used techniques to\nmitigate forgetting, sample replay, has been shown empirically to reduce\nforgetting by retaining some examples from old tasks and including them in new\ntraining episodes. In this work, we provide a theoretical analysis of sample\nreplay in an over-parameterized continual linear regression setting, where each\ntask is given by a linear subspace and with enough replay samples, one would be\nable to eliminate forgetting. Our analysis focuses on sample replay and\nhighlights the role of the replayed samples and the relationship between task\nsubspaces. Surprisingly, we find that, even in a noiseless setting, forgetting\ncan be non-monotonic with respect to the number of replay samples. We present\ntasks where replay can be harmful with respect to worst-case settings, and also\nin distributional settings where replay of randomly selected samples increases\nforgetting in expectation. We also give empirical evidence that harmful replay\nis not limited to training with linear models by showing similar behavior for a\nneural networks equipped with SGD. Through experiments on a commonly used\nbenchmark, we provide additional evidence that, even in seemingly benign\nscenarios, performance of the replay heavily depends on the choice of replay\nsamples and the relationship between tasks.", "AI": {"tldr": "\u5bf9\u6837\u672c\u91cd\u653e\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u53d1\u73b0\u5176\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u80fd\u589e\u52a0\u9057\u5fd8\uff0c\u7ed3\u679c\u4f9d\u8d56\u4e8e\u6837\u672c\u9009\u62e9\u548c\u4efb\u52a1\u5173\u7cfb\u3002", "motivation": "\u514b\u670d\u5728\u9010\u6b65\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u65f6\u9057\u5fd8\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u65b0\u4efb\u52a1\u65f6\uff0c\u65e7\u4efb\u52a1\u7684\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5728\u8fc7\u53c2\u6570\u5316\u7684\u8fde\u7eed\u7ebf\u6027\u56de\u5f52\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u5e76\u8fdb\u884c\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u5b9e\u9a8c\u4ee5\u9a8c\u8bc1\u6837\u672c\u91cd\u653e\u7684\u6548\u679c\u3002", "result": "\u53d1\u73b0\u9057\u5fd8\u53ef\u80fd\u968f\u91cd\u653e\u6837\u672c\u6570\u91cf\u7684\u589e\u52a0\u800c\u589e\u52a0\uff0c\u91cd\u653e\u751a\u81f3\u53ef\u80fd\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u6709\u5bb3\uff0c\u7279\u522b\u662f\u5728\u5206\u5e03\u8bbe\u7f6e\u4e2d\uff0c\u968f\u673a\u9009\u62e9\u6837\u672c\u7684\u91cd\u653e\u589e\u52a0\u4e86\u671f\u671b\u9057\u5fd8\u3002\u8fd8\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4f7f\u7528\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u7c7b\u4f3c\u7684\u6709\u5bb3\u91cd\u653e\u884c\u4e3a\u4e5f\u5b58\u5728\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u770b\u4f3c\u65e0\u5bb3\u7684\u573a\u666f\u4e2d\uff0c\u6837\u672c\u91cd\u653e\u7684\u6027\u80fd\u4e5f\u4e25\u91cd\u4f9d\u8d56\u4e8e\u91cd\u653e\u6837\u672c\u7684\u9009\u62e9\u548c\u4efb\u52a1\u4e4b\u95f4\u7684\u5173\u7cfb\u3002"}}
{"id": "2506.04586", "pdf": "https://arxiv.org/pdf/2506.04586", "abs": "https://arxiv.org/abs/2506.04586", "authors": ["Wen Ding", "Fan Qian"], "title": "LESS: Large Language Model Enhanced Semi-Supervised Learning for Speech Foundational Models", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "We introduce LESS (Large Language Model Enhanced Semi-supervised Learning), a\nversatile framework that leverages Large Language Models (LLMs) to correct\npseudo labels generated from in-the-wild data. Within the LESS framework,\npseudo-labeled text from Automatic Speech Recognition (ASR) or Automatic Speech\nTranslation (AST) of the unsupervised data is refined by an LLM, and augmented\nby a data filtering strategy to optimize LLM knowledge transfer efficiency.\nExperiments on both Mandarin ASR and Spanish-to-English AST tasks show that\nLESS achieves a notable absolute WER reduction of 3.77% on the Wenet Speech\ntest set, as well as BLEU scores of 34.0 and 64.7 on Callhome and Fisher test\nsets respectively. These results validate the adaptability of LESS across\ndifferent languages, tasks, and domains. Ablation studies conducted with\nvarious LLMs and prompt configurations provide novel insights into leveraging\nLLM-derived knowledge for speech processing applications.", "AI": {"tldr": "LESS\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6539\u5584\u4f2a\u6807\u7b7e\uff0c\u63d0\u9ad8\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\uff0c\u6548\u679c\u663e\u8457\uff0c\u5e76\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u548c\u4efb\u52a1\u3002", "motivation": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u6539\u8fdb\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u6216\u7ffb\u8bd1\u4ea7\u751f\u7684\u4f2a\u6807\u7b7e\uff0c\u4ee5\u63d0\u9ad8\u672a\u6807\u6ce8\u6570\u636e\u7684\u5904\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u5728LESS\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4fee\u6b63\u6765\u81eaASR\u6216AST\u7684\u4f2a\u6807\u7b7e\u6587\u672c\uff0c\u5e76\u91c7\u7528\u6570\u636e\u8fc7\u6ee4\u7b56\u7565\uff0c\u4ee5\u4f18\u5316LLM\u77e5\u8bc6\u4f20\u9012\u7684\u6548\u7387\u3002", "result": "\u5728\u666e\u901a\u8bddASR\u548c\u897f\u73ed\u7259\u8bed\u5230\u82f1\u8bedAST\u4efb\u52a1\u4e0a\uff0cLESS\u5b9e\u73b0\u4e86Wenet Speech\u6d4b\u8bd5\u96c6\u4e2d3.77%\u7684WER\u7edd\u5bf9\u503c\u51cf\u5c11\uff0c\u4ee5\u53ca\u5728Callhome\u548cFisher\u6d4b\u8bd5\u96c6\u4e0a\u768434.0\u548c64.7\u7684BLEU\u5206\u6570\u3002", "conclusion": "LESS\u6846\u67b6\u5728\u591a\u8bed\u8a00\u7684ASR\u548cAST\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9519\u8bef\u7387\uff0c\u63d0\u5347\u4e86\u7ffb\u8bd1\u51c6\u786e\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u8de8\u8bed\u8a00\u3001\u4efb\u52a1\u548c\u9886\u57df\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2506.04756", "pdf": "https://arxiv.org/pdf/2506.04756", "abs": "https://arxiv.org/abs/2506.04756", "authors": ["Loan Dao", "Ngoc Quoc Ly"], "title": "Ontology-based knowledge representation for bone disease diagnosis: a foundation for safe and sustainable medical artificial intelligence systems", "categories": ["cs.AI", "cs.CV", "eess.IV"], "comment": null, "summary": "Medical artificial intelligence (AI) systems frequently lack systematic\ndomain expertise integration, potentially compromising diagnostic reliability.\nThis study presents an ontology-based framework for bone disease diagnosis,\ndeveloped in collaboration with Ho Chi Minh City Hospital for Traumatology and\nOrthopedics. The framework introduces three theoretical contributions: (1) a\nhierarchical neural network architecture guided by bone disease ontology for\nsegmentation-classification tasks, incorporating Visual Language Models (VLMs)\nthrough prompts, (2) an ontology-enhanced Visual Question Answering (VQA)\nsystem for clinical reasoning, and (3) a multimodal deep learning model that\nintegrates imaging, clinical, and laboratory data through ontological\nrelationships. The methodology maintains clinical interpretability through\nsystematic knowledge digitization, standardized medical terminology mapping,\nand modular architecture design. The framework demonstrates potential for\nextension beyond bone diseases through its standardized structure and reusable\ncomponents. While theoretical foundations are established, experimental\nvalidation remains pending due to current dataset and computational resource\nlimitations. Future work will focus on expanding the clinical dataset and\nconducting comprehensive system validation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u672c\u4f53\u8bba\u9a71\u52a8\u7684\u6846\u67b6\u7528\u4e8e\u9aa8\u75c5\u8bca\u65ad\uff0c\u91cd\u70b9\u5728\u4e8e\u7ef4\u6301\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u548c\u6784\u5efa\u6807\u51c6\u5316\u7ed3\u6784\u3002\u5c3d\u7ba1\u7406\u8bba\u6846\u67b6\u5df2\u63d0\u51fa\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5c1a\u5f85\u8fdb\u884c\u3002", "motivation": "\u533b\u5b66\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u901a\u5e38\u7f3a\u4e4f\u7cfb\u7edf\u6027\u9886\u57df\u4e13\u5bb6\u7684\u6574\u5408\uff0c\u53ef\u80fd\u5f71\u54cd\u8bca\u65ad\u7684\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u672c\u4f53\u8bba\u7684\u9aa8\u75c5\u8bca\u65ad\u6846\u67b6\u3002\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u7406\u8bba\u8d21\u732e\uff1a\uff081\uff09\u4f7f\u7528\u9aa8\u75c5\u672c\u4f53\u6307\u5bfc\u7684\u5206\u5c42\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\uff0c\u7528\u4e8e\u5206\u5272-\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u63d0\u793a\u6574\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\uff082\uff09\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u63a8\u7406\u7684\u672c\u4f53\u589e\u5f3a\u578b\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u7cfb\u7edf\uff0c\u4ee5\u53ca\uff083\uff09\u4e00\u4e2a\u901a\u8fc7\u672c\u4f53\u5173\u7cfb\u6574\u5408\u5f71\u50cf\u3001\u4e34\u5e8a\u548c\u5b9e\u9a8c\u5ba4\u6570\u636e\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u6846\u67b6\u5c55\u793a\u4e86\u5176\u5728\u9aa8\u75c5\u4ee5\u5916\u6269\u5c55\u7684\u6f5c\u529b\uff0c\u7531\u4e8e\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u76ee\u524d\u5c1a\u672a\u5b8c\u6210\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u8d85\u51fa\u9aa8\u75c5\u8bca\u65ad\u7684\u6f5c\u529b\uff0c\u5177\u6709\u6807\u51c6\u5316\u7ed3\u6784\u548c\u53ef\u590d\u7528\u7ec4\u4ef6\u3002\u5c3d\u7ba1\u7406\u8bba\u57fa\u7840\u5df2\u5efa\u7acb\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4ecd\u5728\u7b49\u5f85\u4e2d\uff0c\u539f\u56e0\u5728\u4e8e\u5f53\u524d\u7684\u6570\u636e\u96c6\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u4e13\u6ce8\u4e8e\u6269\u5927\u4e34\u5e8a\u6570\u636e\u96c6\u548c\u8fdb\u884c\u5168\u9762\u7684\u7cfb\u7edf\u9a8c\u8bc1\u3002"}}
{"id": "2506.04398", "pdf": "https://arxiv.org/pdf/2506.04398", "abs": "https://arxiv.org/abs/2506.04398", "authors": ["Th\u00e9o Vincent", "Yogesh Tripathi", "Tim Faust", "Yaniv Oren", "Jan Peters", "Carlo D'Eramo"], "title": "Bridging the Performance Gap Between Target-Free and Target-Based Reinforcement Learning With Iterated Q-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In value-based reinforcement learning, removing the target network is\ntempting as the boostrapped target would be built from up-to-date estimates,\nand the spared memory occupied by the target network could be reallocated to\nexpand the capacity of the online network. However, eliminating the target\nnetwork introduces instability, leading to a decline in performance. Removing\nthe target network also means we cannot leverage the literature developed\naround target networks. In this work, we propose to use a copy of the last\nlinear layer of the online network as a target network, while sharing the\nremaining parameters with the up-to-date online network, hence stepping out of\nthe binary choice between target-based and target-free methods. It enables us\nto leverage the concept of iterated Q-learning, which consists of learning\nconsecutive Bellman iterations in parallel, to reduce the performance gap\nbetween target-free and target-based approaches. Our findings demonstrate that\nthis novel method, termed iterated Shared Q-Learning (iS-QL), improves the\nsample efficiency of target-free approaches across various settings.\nImportantly, iS-QL requires a smaller memory footprint and comparable training\ntime to classical target-based algorithms, highlighting its potential to scale\nreinforcement learning research.", "AI": {"tldr": "\u63d0\u51fa\u4f7f\u7528\u8fed\u4ee3\u5171\u4eabQ\u5b66\u4e60(iS-QL)\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u51cf\u5c11\u76ee\u6807\u7f51\u7edc\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u4e14\u5185\u5b58\u9700\u6c42\u66f4\u5c11\uff0c\u8bad\u7ec3\u65f6\u95f4\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u5728\u53bb\u6389\u76ee\u6807\u7f51\u7edc\u4ee5\u8282\u7701\u5185\u5b58\u5e76\u63d0\u9ad8\u5728\u7ebf\u7f51\u7edc\u5bb9\u91cf\u7684\u540c\u65f6\uff0c\u6d88\u9664\u76ee\u6807\u7f51\u7edc\u4f1a\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u4e24\u8005\u4f18\u70b9\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014\u8fed\u4ee3\u5171\u4eabQ\u5b66\u4e60(iS-QL)\uff0c\u901a\u8fc7\u5171\u4eab\u5728\u7ebf\u7f51\u7edc\u7684\u7ebf\u6027\u5c42\u4f5c\u4e3a\u76ee\u6807\u7f51\u7edc\uff0c\u5176\u4ed6\u53c2\u6570\u4ecd\u4e0e\u6700\u65b0\u7684\u5728\u7ebf\u7f51\u7edc\u5171\u4eab\u3002\u8fd9\u5141\u8bb8\u5e76\u884c\u5b66\u4e60\u8fde\u7eed\u7684Bellman\u8fed\u4ee3\u3002", "result": "\u8bc1\u660eiS-QL\u80fd\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e2d\u63d0\u9ad8\u65e0\u76ee\u6807\u65b9\u6cd5\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u5728\u5185\u5b58\u5360\u7528\u548c\u8bad\u7ec3\u65f6\u95f4\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "iS-QL\u63d0\u4f9b\u4e86\u4e00\u79cd\u4ecb\u4e8e\u76ee\u6807\u7f51\u7edc\u548c\u65e0\u76ee\u6807\u65b9\u6cd5\u4e4b\u95f4\u7684\u4f18\u8d28\u66ff\u4ee3\uff0c\u5177\u6709\u63d0\u9ad8\u6837\u672c\u6548\u7387\u7684\u4f18\u70b9\uff0c\u5e76\u4e14\u6240\u9700\u5185\u5b58\u8f83\u5c11\uff0c\u8bad\u7ec3\u65f6\u95f4\u53ef\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5ab2\u7f8e\uff0c\u5c55\u73b0\u51fa\u5728\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u4e2d\u6269\u5c55\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.04592", "pdf": "https://arxiv.org/pdf/2506.04592", "abs": "https://arxiv.org/abs/2506.04592", "authors": ["Chengwu Liu", "Ye Yuan", "Yichun Yin", "Yan Xu", "Xin Xu", "Zaoyu Chen", "Yasheng Wang", "Lifeng Shang", "Qun Liu", "Ming Zhang"], "title": "Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted in ACL 2025", "summary": "Chain-of-Thought (CoT) prompting has become the de facto method to elicit\nreasoning capabilities from large language models (LLMs). However, to mitigate\nhallucinations in CoT that are notoriously difficult to detect, current methods\nsuch as process reward models (PRMs) or self-consistency operate as opaque\nboxes and do not provide checkable evidence for their judgments, possibly\nlimiting their effectiveness. To address this issue, we draw inspiration from\nthe idea that \"the gold standard for supporting a mathematical claim is to\nprovide a proof\". We propose a retrospective, step-aware formal verification\nframework $Safe$. Rather than assigning arbitrary scores, we strive to\narticulate mathematical claims in formal mathematical language Lean 4 at each\nreasoning step and provide formal proofs to identify hallucinations. We\nevaluate our framework $Safe$ across multiple language models and various\nmathematical datasets, demonstrating a significant performance improvement\nwhile offering interpretable and verifiable evidence. We also propose\n$FormalStep$ as a benchmark for step correctness theorem proving with $30,809$\nformal statements. To the best of our knowledge, our work represents the first\nendeavor to utilize formal mathematical language Lean 4 for verifying natural\nlanguage content generated by LLMs, aligning with the reason why formal\nmathematical languages were created in the first place: to provide a robust\nfoundation for hallucination-prone human-written proofs.", "AI": {"tldr": "\u63d0\u51fa$Safe$\u6846\u67b6\uff0c\u901a\u8fc7\u5f62\u5f0f\u6570\u5b66\u8bed\u8a00Lean 4\u9a8c\u8bc1\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5185\u5bb9\uff0c\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u94fe\u5f0f\u601d\u7ef4\u4e2d\u96be\u4ee5\u68c0\u6d4b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u6211\u4eec\u53d7\u5230\u6570\u5b66\u8bc1\u660e\u7684\u542f\u53d1\uff0c\u51b3\u5b9a\u63d0\u4f9b\u4e00\u79cd\u53ef\u4ee5\u9a8c\u8bc1\u5e7b\u89c9\u7684\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u5728\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u4e2d\u4f7f\u7528\u5f62\u5f0f\u6570\u5b66\u8bed\u8a00Lean 4\u6765\u8868\u8fbe\u6570\u5b66\u4e3b\u5f20\uff0c\u5e76\u63d0\u4f9b\u5f62\u5f0f\u8bc1\u660e\u6765\u8bc6\u522b\u5e7b\u89c9\uff0c\u800c\u4e0d\u662f\u5206\u914d\u4efb\u610f\u5206\u6570\u3002", "result": "\u5728\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u548c\u5404\u79cd\u6570\u5b66\u6570\u636e\u96c6\u4e0a\uff0c\u8fd9\u79cd\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u548c\u53ef\u9a8c\u8bc1\u7684\u8bc1\u636e\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u56de\u987e\u6027\u3001\u6b65\u9aa4\u611f\u77e5\u7684\u5f62\u5f0f\u9a8c\u8bc1\u6846\u67b6$Safe$\uff0c\u53ef\u4ee5\u5728\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u548c\u5404\u79cd\u6570\u5b66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u548c\u53ef\u9a8c\u8bc1\u7684\u8bc1\u636e\u3002"}}
{"id": "2506.04828", "pdf": "https://arxiv.org/pdf/2506.04828", "abs": "https://arxiv.org/abs/2506.04828", "authors": ["Artem Latyshev", "Gregory Gorbov", "Aleksandr I. Panov"], "title": "Safe Planning and Policy Optimization via World Model Learning", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) applications in real-world scenarios must\nprioritize safety and reliability, which impose strict constraints on agent\nbehavior. Model-based RL leverages predictive world models for action planning\nand policy optimization, but inherent model inaccuracies can lead to\ncatastrophic failures in safety-critical settings. We propose a novel\nmodel-based RL framework that jointly optimizes task performance and safety. To\naddress world model errors, our method incorporates an adaptive mechanism that\ndynamically switches between model-based planning and direct policy execution.\nWe resolve the objective mismatch problem of traditional model-based approaches\nusing an implicit world model. Furthermore, our framework employs dynamic\nsafety thresholds that adapt to the agent's evolving capabilities, consistently\nselecting actions that surpass safe policy suggestions in both performance and\nsafety. Experiments demonstrate significant improvements over non-adaptive\nmethods, showing that our approach optimizes safety and performance\nsimultaneously rather than merely meeting minimum safety requirements. The\nproposed framework achieves robust performance on diverse safety-critical\ncontinuous control tasks, outperforming existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u81ea\u9002\u5e94\u673a\u5236\u52a8\u6001\u4f18\u5316\u4efb\u52a1\u8868\u73b0\u548c\u5b89\u5168\u6027\uff0c\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u6210\u6548\u3002", "motivation": "\u5728\u771f\u5b9e\u573a\u666f\u5e94\u7528\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u4f18\u5148\u8003\u8651\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\uff0c\u8fd9\u5bf9\u667a\u80fd\u4f53\u884c\u4e3a\u65bd\u52a0\u4e86\u4e25\u683c\u9650\u5236\u3002\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u9884\u6d4b\u4e16\u754c\u6a21\u578b\u8fdb\u884c\u52a8\u4f5c\u89c4\u5212\u548c\u7b56\u7565\u4f18\u5316\uff0c\u4f46\u5176\u6a21\u578b\u56fa\u6709\u7684\u4e0d\u51c6\u786e\u6027\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u5173\u952e\u8bbe\u7f6e\u4e0b\u7684\u707e\u96be\u6027\u5931\u8d25\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u4efb\u52a1\u8868\u73b0\u548c\u5b89\u5168\u6765\u63d0\u5347\u6027\u80fd\u3002\u4e3a\u89e3\u51b3\u4e16\u754c\u6a21\u578b\u8bef\u5dee\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u91c7\u7528\u81ea\u9002\u5e94\u673a\u5236\uff0c\u52a8\u6001\u5207\u6362\u6a21\u578b\u89c4\u5212\u548c\u76f4\u63a5\u7b56\u7565\u6267\u884c\uff0c\u5e76\u901a\u8fc7\u9690\u5f0f\u4e16\u754c\u6a21\u578b\u89e3\u51b3\u4f20\u7edf\u6a21\u578b\u65b9\u6cd5\u7684\u76ee\u6807\u4e0d\u5339\u914d\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u52a8\u6001\u5b89\u5168\u9608\u503c\uff0c\u9002\u5e94\u4e8e\u4ee3\u7406\u7684\u80fd\u529b\u53d8\u5316\uff0c\u6301\u7eed\u4f18\u9009\u8d85\u8d8a\u5b89\u5168\u7b56\u7565\u5efa\u8bae\u7684\u52a8\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u975e\u81ea\u9002\u5e94\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u548c\u8868\u73b0\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6ee1\u8db3\u6700\u4f4e\u5b89\u5168\u8981\u6c42\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u5728\u4f18\u5316\u4efb\u52a1\u8868\u73b0\u548c\u786e\u4fdd\u5b89\u5168\u65b9\u9762\u540c\u65f6\u53d6\u5f97\u663e\u8457\u6539\u5584\uff0c\u5728\u591a\u79cd\u5b89\u5168\u5173\u952e\u7684\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2506.04399", "pdf": "https://arxiv.org/pdf/2506.04399", "abs": "https://arxiv.org/abs/2506.04399", "authors": ["Suzan Ece Ada", "Emre Ugur"], "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue:\n  10, 8427 - 8434, October 2024. 8 pages, 7 figures", "summary": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes\n(UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method\nthat uniquely combines, yet distinctly separates, parameterized policy\ngradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for\nsettings where the reward signal is missing during meta-testing, our method\nincreases sample efficiency without requiring additional samples in\nmeta-training. UMCNP leverages the efficiency and scalability of Conditional\nNeural Processes (CNPs) to reduce the number of online interactions required in\nmeta-testing. During meta-training, samples previously collected through PPG\nmeta-RL are efficiently reused for learning task inference in an offline\nmanner. UMCNP infers the latent representation of the transition dynamics model\nfrom a single test task rollout with unknown parameters. This approach allows\nus to generate rollouts for self-adaptation by interacting with the learned\ndynamics model. We demonstrate our method can adapt to an unseen test task\nusing significantly fewer samples during meta-testing than the baselines in\n2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with\nunknown angle sensor bias, walker agent with randomized dynamics parameters.", "AI": {"tldr": "UMCNP\u65b9\u6cd5\u5728\u65e0\u5956\u52b1\u4fe1\u53f7\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u5143\u5f3a\u5316\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u52a8\u6001\u6a21\u578b\u81ea\u9002\u5e94\u5730\u5e94\u5bf9\u672a\u77e5\u4efb\u52a1\u3002", "motivation": "\u5728\u5143\u6d4b\u8bd5\u9636\u6bb5\u5956\u52b1\u4fe1\u53f7\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUMCNP\u7684\u65b0\u9896\u6df7\u5408\u5c11\u6837\u672c\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4f46\u533a\u5206\u4e86\u53c2\u6570\u5316\u7b56\u7565\u68af\u5ea6\u548c\u4efb\u52a1\u63a8\u7406\u7684\u5c11\u6837\u672c\u5143\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u76f8\u6bd4\u57fa\u51c6\u65b9\u6cd5\uff0c\u5728\u5143\u6d4b\u8bd5\u9636\u6bb5\u4f7f\u7528\u663e\u8457\u66f4\u5c11\u7684\u6837\u672c\u5b8c\u6210\u5bf9\u672a\u89c1\u6d4b\u8bd5\u4efb\u52a1\u7684\u9002\u5e94\u3002", "conclusion": "UMCNP\u65b9\u6cd5\u5728\u65e0\u9700\u5728\u5143\u8bad\u7ec3\u4e2d\u4f7f\u7528\u989d\u5916\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u901a\u8fc7\u81ea\u9002\u5e94\u7684\u65b9\u5f0f\uff0c\u9ad8\u6548\u63a8\u7406\u548c\u9002\u5e94\u672a\u77e5\u6d4b\u8bd5\u4efb\u52a1\u6a21\u578b\u3002"}}
{"id": "2506.04603", "pdf": "https://arxiv.org/pdf/2506.04603", "abs": "https://arxiv.org/abs/2506.04603", "authors": ["Firoz Shaik", "Mobashir Sadat", "Nikita Gautam", "Doina Caragea", "Cornelia Caragea"], "title": "A MISMATCHED Benchmark for Scientific Natural Language Inference", "categories": ["cs.CL"], "comment": "Accepted to Findings of ACL 2025", "summary": "Scientific Natural Language Inference (NLI) is the task of predicting the\nsemantic relation between a pair of sentences extracted from research articles.\nExisting datasets for this task are derived from various computer science (CS)\ndomains, whereas non-CS domains are completely ignored. In this paper, we\nintroduce a novel evaluation benchmark for scientific NLI, called MISMATCHED.\nThe new MISMATCHED benchmark covers three non-CS domains-PSYCHOLOGY,\nENGINEERING, and PUBLIC HEALTH, and contains 2,700 human annotated sentence\npairs. We establish strong baselines on MISMATCHED using both Pre-trained Small\nLanguage Models (SLMs) and Large Language Models (LLMs). Our best performing\nbaseline shows a Macro F1 of only 78.17% illustrating the substantial headroom\nfor future improvements. In addition to introducing the MISMATCHED benchmark,\nwe show that incorporating sentence pairs having an implicit scientific NLI\nrelation between them in model training improves their performance on\nscientific NLI. We make our dataset and code publicly available on GitHub.", "AI": {"tldr": "\u5f15\u5165MISMATCHED\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5fc3\u7406\u5b66\u3001\u5de5\u7a0b\u548c\u516c\u5171\u536b\u751f\u9886\u57df\uff0c\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "motivation": "\u73b0\u6709\u7684\u79d1\u5b66NLI\u6570\u636e\u96c6\u4e3b\u8981\u6765\u81ea\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\uff0c\u5176\u4ed6\u9886\u57df\u6570\u636e\u96c6\u88ab\u5ffd\u89c6\u3002", "method": "\u5bf9MISMATCHED\u57fa\u51c6\u8fdb\u884c\u5f3a\u57fa\u7ebf\u6d4b\u8bd5\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684SLM\u548cLLM\u3002", "result": "\u6211\u4eec\u6700\u4f73\u57fa\u7ebf\u7684Macro F1\u4ec5\u4e3a78.17%\uff0c\u5c55\u793a\u4e86\u672a\u6765\u6539\u8fdb\u7684\u5de8\u5927\u7a7a\u95f4\u3002", "conclusion": "\u6211\u4eec\u5c55\u793a\u4e86\u5c06\u9690\u542b\u79d1\u5b66NLI\u5173\u7cfb\u7684\u53e5\u5b50\u5bf9\u7eb3\u5165\u6a21\u578b\u8bad\u7ec3\u53ef\u63d0\u9ad8\u5176\u5728\u79d1\u5b66NLI\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2506.04849", "pdf": "https://arxiv.org/pdf/2506.04849", "abs": "https://arxiv.org/abs/2506.04849", "authors": ["Julien Soul\u00e9", "Jean-Paul Jamont", "Michel Occello", "Paul Th\u00e9ron", "Louis-Marie Traonouez"], "title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "categories": ["cs.AI"], "comment": null, "summary": "As cyber-attacks show to be more and more complex and coordinated,\ncyber-defenders strategy through multi-agent approaches could be key to tackle\nagainst cyber-attacks as close as entry points in a networked system. This\npaper presents a Markovian modeling and implementation through a simulator of\nfighting cyber-attacker agents and cyber-defender agents deployed on host\nnetwork nodes. It aims to provide an experimental framework to implement\nrealistically based coordinated cyber-attack scenarios while assessing\ncyber-defenders dynamic organizations. We abstracted network nodes by sets of\nproperties including agents' ones. Actions applied by agents model how the\nnetwork reacts depending in a given state and what properties are to change.\nCollective choice of the actions brings the whole environment closer or farther\nfrom respective cyber-attackers and cyber-defenders goals. Using the simulator,\nwe implemented a realistically inspired scenario with several behavior\nimplementation approaches for cyber-defenders and cyber-attackers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u548c\u6a21\u62df\u5668\uff0c\u6a21\u62df\u7f51\u7edc\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u7684\u4ea4\u4e92\uff0c\u8bc4\u4f30\u9632\u5fa1\u7b56\u7565\u5728\u590d\u6742\u7f51\u7edc\u6001\u52bf\u4e0b\u7684\u6548\u679c\u3002", "motivation": "\u968f\u7740\u7f51\u7edc\u653b\u51fb\u65e5\u76ca\u590d\u6742\u548c\u534f\u8c03\uff0c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u7684\u7f51\u7edc\u9632\u5fa1\u7b56\u7565\u53ef\u80fd\u662f\u89e3\u51b3\u7f51\u7edc\u653b\u51fb\u7684\u5173\u952e\u3002", "method": "\u91c7\u7528\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u5668\u5728\u7f51\u7edc\u8282\u70b9\u4e0a\u90e8\u7f72\u7f51\u7edc\u653b\u51fb\u8005\u548c\u9632\u5fa1\u8005\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53d7\u73b0\u5b9e\u542f\u53d1\u7684\u573a\u666f\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u7684\u884c\u4e3a\u5b9e\u73b0\u65b9\u6cd5\u5bf9\u7f51\u7edc\u653b\u9632\u7684\u5f71\u54cd\u3002", "conclusion": "\u4f7f\u7528\u6a21\u62df\u5668\u8fdb\u884c\u7684\u5b9e\u9a8c\u5c55\u793a\u4e86\u5728\u73b0\u5b9e\u60c5\u5883\u4e2d\u534f\u8c03\u7684\u7f51\u7edc\u653b\u51fb\u548c\u9632\u5fa1\u7b56\u7565\u7684\u5b9e\u65bd\u3002"}}
{"id": "2506.04411", "pdf": "https://arxiv.org/pdf/2506.04411", "abs": "https://arxiv.org/abs/2506.04411", "authors": ["Achleshwar Luthra", "Tianbao Yang", "Tomer Galanti"], "title": "Self-Supervised Contrastive Learning is Approximately Supervised Contrastive Learning", "categories": ["cs.LG"], "comment": null, "summary": "Despite its empirical success, the theoretical foundations of self-supervised\ncontrastive learning (CL) are not yet fully established. In this work, we\naddress this gap by showing that standard CL objectives implicitly approximate\na supervised variant we call the negatives-only supervised contrastive loss\n(NSCL), which excludes same-class contrasts. We prove that the gap between the\nCL and NSCL losses vanishes as the number of semantic classes increases, under\na bound that is both label-agnostic and architecture-independent.\n  We characterize the geometric structure of the global minimizers of the NSCL\nloss: the learned representations exhibit augmentation collapse, within-class\ncollapse, and class centers that form a simplex equiangular tight frame. We\nfurther introduce a new bound on the few-shot error of linear-probing. This\nbound depends on two measures of feature variability--within-class dispersion\nand variation along the line between class centers. We show that directional\nvariation dominates the bound and that the within-class dispersion's effect\ndiminishes as the number of labeled samples increases. These properties enable\nCL and NSCL-trained representations to support accurate few-shot label recovery\nusing simple linear probes.\n  Finally, we empirically validate our theoretical findings: the gap between CL\nand NSCL losses decays at a rate of $\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$;\nthe two losses are highly correlated; minimizing the CL loss implicitly brings\nthe NSCL loss close to the value achieved by direct minimization; and the\nproposed few-shot error bound provides a tight estimate of probing performance\nin practice.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\uff08CL\uff09\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u5176\u8fd1\u4f3c\u4e00\u4e2a\u6392\u9664\u540c\u7c7b\u5bf9\u6bd4\u7684\u76d1\u7763\u635f\u5931\uff08NSCL\uff09\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u8fd1\u4f3c\u5728\u7c7b\u6570\u589e\u52a0\u65f6\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u5c11\u6837\u672c\u8bef\u5dee\u754c\u6765\u652f\u6301\u7ebf\u6027\u63a2\u6d4b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\uff08CL\uff09\u7684\u7406\u8bba\u57fa\u7840\u5c1a\u672a\u5b8c\u5168\u5efa\u7acb\u7684\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u5c06\u6807\u51c6CL\u76ee\u6807\u8fd1\u4f3c\u4e3a\u4e00\u4e2a\u6392\u9664\u540c\u7c7b\u5bf9\u6bd4\u7684\u76d1\u7763\u53d8\u4f53\uff08NSCL\uff09\u7684\u601d\u8def\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u5c11\u6837\u672c\u7ebf\u6027\u63a2\u6d4b\u8bef\u5dee\u754c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u8bef\u5dee\u754c\u5bf9\u4e8e\u63a2\u6d4b\u6027\u80fd\u7684\u4f30\u8ba1\u662f\u4e25\u683c\u7684\u3002", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u4e86CL\u548cNSCL\u635f\u5931\u4e4b\u95f4\u7684\u5dee\u8ddd\u968f\u7740\u8bed\u4e49\u7c7b\u6570\u91cf\u589e\u52a0\u800c\u4ee5$\\mathcal{O}(\\frac{1}{\\#\\text{classes}})$\u7684\u901f\u7387\u8870\u51cf\uff0c\u4e14\u5b83\u4eec\u7684\u635f\u5931\u9ad8\u5ea6\u76f8\u5173\u3002CL\u7684\u6700\u5c0f\u5316\u80fd\u591f\u5c06NSCL\u635f\u5931\u63a5\u8fd1\u76f4\u63a5\u6700\u5c0f\u5316\u6240\u8fbe\u5230\u7684\u503c\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5bf9\u6bd4\u5b66\u4e60\uff08CL\uff09\u548c\u5176\u76d1\u7763\u53d8\u4f53\uff08NSCL\uff09\u7684\u635f\u5931\u5dee\u8ddd\u968f\u7740\u8bed\u4e49\u7c7b\u6570\u91cf\u589e\u52a0\u800c\u51cf\u5c0f\u3002CL\u8bad\u7ec3\u7684\u8868\u793a\u80fd\u591f\u5f88\u597d\u5730\u652f\u6301\u7b80\u5355\u7ebf\u6027\u63a2\u6d4b\u7684\u5c11\u6837\u672c\u6807\u7b7e\u6062\u590d\u3002"}}
{"id": "2506.04611", "pdf": "https://arxiv.org/pdf/2506.04611", "abs": "https://arxiv.org/abs/2506.04611", "authors": ["Ho-Lam Chung", "Teng-Yun Hsiao", "Hsiao-Ying Huang", "Chunerh Cho", "Jian-Ren Lin", "Zhang Ziwei", "Yun-Nung Chen"], "title": "Revisiting Test-Time Scaling: A Survey and a Diversity-Aware Method for Efficient Reasoning", "categories": ["cs.CL"], "comment": "emnlp 2025 submission", "summary": "Test-Time Scaling (TTS) improves the reasoning performance of Large Language\nModels (LLMs) by allocating additional compute during inference. We conduct a\nstructured survey of TTS methods and categorize them into sampling-based,\nsearch-based, and trajectory optimization strategies. We observe that\nreasoning-optimized models often produce less diverse outputs, which limits TTS\neffectiveness. To address this, we propose ADAPT (A Diversity Aware Prefix\nfine-Tuning), a lightweight method that applies prefix tuning with a\ndiversity-focused data strategy. Experiments on mathematical reasoning tasks\nshow that ADAPT reaches 80% accuracy using eight times less compute than strong\nbaselines. Our findings highlight the essential role of generative diversity in\nmaximizing TTS effectiveness.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5ADAPT\uff0c\u901a\u8fc7\u591a\u6837\u6027\u6570\u636e\u7b56\u7565\u589e\u5f3a\u6d4b\u8bd5\u65f6\u7f29\u653e(TTS)\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u7f29\u653e(TTS)\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5206\u914d\u989d\u5916\u7684\u8ba1\u7b97\u8d44\u6e90\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u63a8\u7406\u6027\u80fd\u3002\u7136\u800c\uff0c\u4f18\u5316\u63a8\u7406\u6027\u80fd\u7684\u6a21\u578b\u901a\u5e38\u4ea7\u751f\u8f83\u5c11\u6837\u672c\u7684\u8f93\u51fa\uff0c\u9650\u5236\u4e86TTS\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faADAPT\u65b9\u6cd5\uff0c\u901a\u8fc7\u524d\u7f00\u5fae\u8c03\u548c\u4e13\u6ce8\u4e8e\u591a\u6837\u6027\u7684\u6570\u636e\u7b56\u7565\u6765\u89e3\u51b3\u63a8\u7406\u4f18\u5316\u6a21\u578b\u4ea7\u751f\u7684\u8f93\u51fa\u4e0d\u591f\u591a\u6837\u7684\u95ee\u9898\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cADAPT\u65b9\u6cd5\u8fbe\u5230\u4e8680%\u7684\u51c6\u786e\u7387\uff0c\u5176\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4ec5\u4e3a\u5f3a\u57fa\u7ebf\u7684\u516b\u5206\u4e4b\u4e00\u3002", "conclusion": "\u751f\u6210\u591a\u6837\u6027\u5728\u6700\u5927\u5316\u6d4b\u8bd5\u65f6\u7f29\u653e(TTS)\u6709\u6548\u6027\u4e2d\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002"}}
{"id": "2506.04867", "pdf": "https://arxiv.org/pdf/2506.04867", "abs": "https://arxiv.org/abs/2506.04867", "authors": ["J\u00f4nata Tyska Carvalho", "Stefano Nolfi"], "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "categories": ["cs.AI", "cs.HC", "cs.LG", "cs.RO"], "comment": "24 pages (13 pages are from appendix), 6 figures, code for\n  experiments replication and supplementary material provided at\n  https://github.com/jtyska/llm-robotics-article/", "summary": "We propose a method that enables large language models (LLMs) to control\nembodied agents by directly mapping continuous observation vectors to\ncontinuous action vectors. Initially, the LLMs generate a control strategy\nbased on a textual description of the agent, its environment, and the intended\ngoal. This strategy is then iteratively refined through a learning process in\nwhich the LLMs are repeatedly prompted to improve the current strategy, using\nperformance feedback and sensory-motor data collected during its evaluation.\nThe method is validated on classic control tasks from the Gymnasium library and\nthe inverted pendulum task from the MuJoCo library. In most cases, it\nsuccessfully identifies optimal or high-performing solutions by integrating\nsymbolic knowledge derived through reasoning with sub-symbolic sensory-motor\ndata gathered as the agent interacts with its environment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u548c\u4f18\u5316\u5b9e\u65f6\u63a7\u5236\u7b56\u7565\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5728\u7ecf\u5178\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9ad8\u6027\u80fd\u7ed3\u679c\u3002", "motivation": "\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8e\u5b9e\u65f6\u63a7\u5236\uff0c\u53ef\u4ee5\u63d0\u9ad8\u63a7\u5236\u4efb\u52a1\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u4e0e\u6301\u7eed\u89c2\u5bdf\u548c\u884c\u52a8\u5411\u91cf\u76f4\u63a5\u6620\u5c04\uff0c\u4f7f\u5176\u751f\u6210\u63a7\u5236\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u5b66\u4e60\u8fc7\u7a0b\u4f18\u5316\u3002", "result": "\u65b9\u6cd5\u5728Gymnasium\u5e93\u7684\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u548cMuJoCo\u5e93\u7684\u5012\u6446\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u6210\u529f\u627e\u5230\u4e86\u6700\u4f73\u6216\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6574\u5408\u63a8\u7406\u4ea7\u751f\u7684\u7b26\u53f7\u77e5\u8bc6\u548c\u4ece\u73af\u5883\u4ea4\u4e92\u4e2d\u83b7\u53d6\u7684\u5b50\u7b26\u53f7\u611f\u5b98-\u8fd0\u52a8\u6570\u636e\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u63a7\u5236\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2506.04430", "pdf": "https://arxiv.org/pdf/2506.04430", "abs": "https://arxiv.org/abs/2506.04430", "authors": ["Egor Petrov", "Grigoriy Evseev", "Aleksey Antonov", "Andrey Veprikov", "Pavel Plyusnin", "Nikolay Bushkov", "Stanislav Moiseev", "Aleksandr Beznosikov"], "title": "Leveraging Coordinate Momentum in SignSGD and Muon: Memory-Optimized Zero-Order", "categories": ["cs.LG", "math.OC"], "comment": "26 pages, 5 tables", "summary": "Fine-tuning Large Language Models (LLMs) is essential for adapting\npre-trained models to downstream tasks. Yet traditional first-order optimizers\nsuch as Stochastic Gradient Descent (SGD) and Adam incur prohibitive memory and\ncomputational costs that scale poorly with model size. In this paper, we\ninvestigate zero-order (ZO) optimization methods as a memory- and\ncompute-efficient alternative, particularly in the context of\nparameter-efficient fine-tuning techniques like LoRA. We propose\n$\\texttt{JAGUAR SignSGD}$, a ZO momentum-based algorithm that extends ZO\nSignSGD, requiring the same number of parameters as the standard ZO SGD and\nonly $\\mathcal{O}(1)$ function evaluations per iteration. To the best of our\nknowledge, this is the first study to establish rigorous convergence guarantees\nfor SignSGD in the stochastic ZO case. We further propose $\\texttt{JAGUAR\nMuon}$, a novel ZO extension of the Muon optimizer that leverages the matrix\nstructure of model parameters, and we provide its convergence rate under\narbitrary stochastic noise. Through extensive experiments on challenging LLM\nfine-tuning benchmarks, we demonstrate that the proposed algorithms meet or\nexceed the convergence quality of standard first-order methods, achieving\nsignificant memory reduction. Our theoretical and empirical results establish\nnew ZO optimization methods as a practical and theoretically grounded approach\nfor resource-constrained LLM adaptation. Our code is available at\nhttps://github.com/brain-mmo-lab/ZO_LLM", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86JAGUAR SignSGD\u548cJAGUAR Muon\u4f5c\u4e3a\u5185\u5b58\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u8d44\u6e90\u6709\u9650\u6761\u4ef6\u4e0b\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u4e00\u9636\u4f18\u5316\u5668\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6a21\u578b\u7684\u5fae\u8c03\u4e2d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6848\u3002", "method": "\u9996\u6b21\u4e3a\u968f\u673aZO SignSGD\u63d0\u4f9b\u4e25\u683c\u7684\u6536\u655b\u6027\u4fdd\u969c\uff1b\u63d0\u51faJAGUAR SignSGD\u548cJAGUAR Muon\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u5b9e\u73b0\u4e86\u663e\u8457\u964d\u4f4e\uff0c\u5728\u6536\u655b\u8d28\u91cf\u4e0a\u8fbe\u5230\u6216\u8d85\u8fc7\u6807\u51c6\u4e00\u9636\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684ZO\u4f18\u5316\u65b9\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u7684LLM\u81ea\u9002\u5e94\u4e0a\u5177\u6709\u5b9e\u9645\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2506.04616", "pdf": "https://arxiv.org/pdf/2506.04616", "abs": "https://arxiv.org/abs/2506.04616", "authors": ["Likun Cao", "Rui Pan", "James Evans"], "title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "categories": ["cs.CL", "stat.AP", "stat.ML"], "comment": "107 pages, 20 figures", "summary": "Existing studies of innovation emphasize the power of social structures to\nshape innovation capacity. Emerging machine learning approaches, however,\nenable us to model innovators' personal perspectives and interpersonal\ninnovation opportunities as a function of their prior trajectories of\nexperience. We theorize then quantify subjective perspectives and innovation\nopportunities based on innovator positions within the geometric space of\nconcepts inscribed by dynamic language representations. Using data on millions\nof scientists, inventors, writers, entrepreneurs, and Wikipedia contributors\nacross the creative domains of science, technology, film, entrepreneurship, and\nWikipedia, here we show that measured subjective perspectives anticipate what\nideas individuals and groups creatively attend to and successfully combine in\nfuture. When perspective and background diversity are decomposed as the angular\ndifference between collaborators' perspectives on their creation and between\ntheir experiences, the former consistently anticipates creative achievement\nwhile the latter portends its opposite, across all cases and time periods\nexamined. We analyze a natural experiment and simulate creative collaborations\nbetween AI (large language model) agents designed with various perspective and\nbackground diversity, which are consistent with our observational findings. We\nexplore mechanisms underlying these findings and identify how successful\ncollaborators leverage common language to weave together diverse experience\nobtained through trajectories of prior work that converge to provoke one\nanother and innovate. We explore the importance of these findings for team\nassembly and research policy.", "AI": {"tldr": "\u7814\u7a76\u91cf\u5316\u4e86\u521b\u65b0\u8005\u7684\u4e3b\u89c2\u89c6\u89d2\u548c\u521b\u65b0\u673a\u4f1a\uff0c\u53d1\u73b0\u89c6\u89d2\u591a\u6837\u6027\u6709\u52a9\u4e8e\u521b\u9020\u529b\uff0c\u800c\u80cc\u666f\u591a\u6837\u6027\u5219\u53ef\u80fd\u4ea7\u751f\u6d88\u6781\u5f71\u54cd\uff0c\u5f71\u54cd\u56e2\u961f\u7ec4\u5efa\u548c\u7814\u7a76\u7b56\u7565\u3002", "motivation": "\u5229\u7528\u65b0\u5174\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6765\u5efa\u6a21\u521b\u65b0\u8005\u7684\u4e2a\u4eba\u89c6\u89d2\u548c\u4eba\u9645\u521b\u65b0\u673a\u4f1a\uff0c\u63a2\u7d22\u8fd9\u4e9b\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u521b\u65b0\u6f5c\u80fd\u3002", "method": "\u4f7f\u7528\u52a8\u6001\u8bed\u8a00\u8868\u793a\u7684\u51e0\u4f55\u7a7a\u95f4\u6a21\u578b\uff0c\u91cf\u5316\u521b\u65b0\u8005\u7684\u4e3b\u89c2\u89c6\u89d2\u4e0e\u521b\u65b0\u673a\u4f1a\uff0c\u5e76\u901a\u8fc7\u5bf9\u6570\u767e\u4e07\u79d1\u5b66\u5bb6\u3001\u53d1\u660e\u5bb6\u3001\u4f5c\u5bb6\u3001\u4f01\u4e1a\u5bb6\u548c\u7ef4\u57fa\u767e\u79d1\u8d21\u732e\u8005\u7684\u6570\u636e\u5206\u6790\uff0c\u9a8c\u8bc1\u89c6\u89d2\u548c\u80cc\u666f\u591a\u6837\u6027\u5bf9\u521b\u65b0\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u901a\u8fc7\u5408\u4f5c\u8005\u5bf9\u521b\u4f5c\u7684\u89c6\u89d2\u5dee\u5f02\u548c\u7ecf\u5386\u95f4\u7684\u5dee\u5f02\u6765\u5206\u89e3\u89c6\u89d2\u548c\u80cc\u666f\u591a\u6837\u6027\u65f6\uff0c\u524d\u8005\u4e00\u8d2f\u9884\u793a\u7740\u521b\u610f\u6210\u5c31\u7684\u4ea7\u751f\uff0c\u800c\u540e\u8005\u5219\u53ef\u80fd\u4ea7\u751f\u53cd\u4f5c\u7528\u3002\u8fd9\u4e00\u73b0\u8c61\u5728\u6240\u6709\u5b9e\u4f8b\u548c\u65f6\u95f4\u6bb5\u4e2d\u88ab\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u91cf\u5316\u4e3b\u89c2\u89c6\u89d2\u548c\u521b\u65b0\u673a\u4f1a\uff0c\u63ed\u793a\u4e86\u5176\u5982\u4f55\u9884\u6d4b\u4e2a\u4f53\u548c\u56e2\u4f53\u672a\u6765\u521b\u9020\u6027\u5173\u6ce8\u548c\u6210\u529f\u7ed3\u5408\u7684\u60f3\u6cd5\u3002\u89c6\u89d2\u591a\u6837\u6027\u6709\u52a9\u4e8e\u521b\u610f\u6210\u5c31\uff0c\u800c\u80cc\u666f\u591a\u6837\u6027\u5219\u53ef\u80fd\u4ea7\u751f\u76f8\u53cd\u7684\u6548\u679c\u3002\u8fd9\u4e9b\u53d1\u73b0\u53ef\u7528\u4e8e\u6307\u5bfc\u56e2\u961f\u7ec4\u5efa\u548c\u7814\u7a76\u653f\u7b56\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.04909", "pdf": "https://arxiv.org/pdf/2506.04909", "abs": "https://arxiv.org/abs/2506.04909", "authors": ["Kai Wang", "Yihao Zhang", "Meng Sun"], "title": "When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "The honesty of large language models (LLMs) is a critical alignment\nchallenge, especially as advanced systems with chain-of-thought (CoT) reasoning\nmay strategically deceive humans. Unlike traditional honesty issues on LLMs,\nwhich could be possibly explained as some kind of hallucination, those models'\nexplicit thought paths enable us to study strategic deception--goal-driven,\nintentional misinformation where reasoning contradicts outputs. Using\nrepresentation engineering, we systematically induce, detect, and control such\ndeception in CoT-enabled LLMs, extracting \"deception vectors\" via Linear\nArtificial Tomography (LAT) for 89% detection accuracy. Through activation\nsteering, we achieve a 40% success rate in eliciting context-appropriate\ndeception without explicit prompts, unveiling the specific honesty-related\nissue of reasoning models and providing tools for trustworthy AI alignment.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8868\u793a\u5de5\u7a0b\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u8bf1\u5bfc\u3001\u68c0\u6d4b\u548c\u63a7\u5236\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e0b\u7684\u6218\u7565\u6b3a\u9a97\uff0c\u6210\u529f\u7387\u4e3a40%\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u4e3a89%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8bda\u5b9e\u6027\u662f\u4e00\u4e2a\u5173\u952e\u7684\u5bf9\u9f50\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63a8\u7406\u7684\u9ad8\u7ea7\u7cfb\u7edf\u4e2d\u53ef\u80fd\u4f1a\u6218\u7565\u6027\u5730\u6b3a\u9a97\u4eba\u7c7b\u3002", "method": "\u4f7f\u7528\u8868\u793a\u5de5\u7a0b\uff0c\u901a\u8fc7\u7ebf\u6027\u4eba\u5de5\u65ad\u5c42\u626b\u63cf\uff08LAT\uff09\u63d0\u53d6\u201c\u6b3a\u9a97\u5411\u91cf\u201d\uff0c\u7cfb\u7edf\u5730\u8bf1\u5bfc\u3001\u68c0\u6d4b\u548c\u63a7\u5236\u8fd9\u4e9b\u5177\u6709\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63a8\u7406\u80fd\u529b\u7684LLMs\u4e2d\u7684\u6218\u7565\u6b3a\u9a97\u3002", "result": "\u901a\u8fc7\u6fc0\u6d3b\u63a7\u5236\uff0c\u5728\u65e0\u9700\u660e\u786e\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e8640%\u7684\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u6b3a\u9a97\u6210\u529f\u7387\uff0c\u5e76\u5b9e\u73b0\u4e8689%\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u63ed\u793a\u4e86\u63a8\u7406\u6a21\u578b\u4e2d\u4e0e\u8bda\u5b9e\u6027\u76f8\u5173\u7684\u7279\u5b9a\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e86\u7528\u4e8e\u53ef\u4fe1AI\u5bf9\u9f50\u7684\u5de5\u5177\u3002"}}
{"id": "2506.04432", "pdf": "https://arxiv.org/pdf/2506.04432", "abs": "https://arxiv.org/abs/2506.04432", "authors": ["Zixuan Xia", "Aram Davtyan", "Paolo Favaro"], "title": "KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We propose KOALA++, a scalable Kalman-based optimization algorithm that\nexplicitly models structured gradient uncertainty in neural network training.\nUnlike second-order methods, which rely on expensive second order gradient\ncalculation, our method directly estimates the parameter covariance matrix by\nrecursively updating compact gradient covariance products. This design improves\nupon the original KOALA framework that assumed diagonal covariance by\nimplicitly capturing richer uncertainty structure without storing the full\ncovariance matrix and avoiding large matrix inversions. Across diverse tasks,\nincluding image classification and language modeling, KOALA++ achieves accuracy\non par or better than state-of-the-art first- and second-order optimizers while\nmaintaining the efficiency of first-order methods.", "AI": {"tldr": "KOALA++\u662f\u4e00\u79cd\u6539\u8fdb\u7684Kalman\u4f18\u5316\u7b97\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u5b58\u50a8\u5b8c\u6574\u534f\u65b9\u5dee\u77e9\u9635\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u5f0f\u6a21\u62df\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u89e3\u51b3\u4e8c\u9636\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u7684\u4e8c\u9636\u68af\u5ea6\u8ba1\u7b97\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u663e\u5f0f\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7ed3\u6784\u5316\u68af\u5ea6\u4e0d\u786e\u5b9a\u6027\u7684\u53ef\u6269\u5c55Kalman\u4f18\u5316\u7b97\u6cd5\u3002", "method": "\u76f4\u63a5\u4f30\u8ba1\u53c2\u6570\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u66f4\u65b0\u7d27\u51d1\u7684\u68af\u5ea6\u534f\u65b9\u5dee\u79ef\u6765\u5b9e\u73b0\u3002", "result": "KOALA++\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u8bed\u8a00\u5efa\u6a21\u7b49\u591a\u6837\u5316\u4efb\u52a1\u4e2d\uff0c\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u7684\u5148\u8fdb\u4f18\u5316\u5668\u76f8\u5f53\u6216\u66f4\u597d\u7684\u7cbe\u786e\u5ea6\uff0c\u5e76\u4fdd\u6301\u4e86\u4e00\u9636\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "KOALA++\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e0e\u5148\u8fdb\u7684\u4e00\u9636\u548c\u4e8c\u9636\u4f18\u5316\u5668\u76f8\u5f53\u6216\u66f4\u597d\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e00\u9636\u65b9\u6cd5\u7684\u6548\u7387\u3002"}}
{"id": "2506.04624", "pdf": "https://arxiv.org/pdf/2506.04624", "abs": "https://arxiv.org/abs/2506.04624", "authors": ["Takashi Wada", "Yuki Hirakawa", "Ryotaro Shimizu", "Takahiro Kawashima", "Yuki Saito"], "title": "Static Word Embeddings for Sentence Semantic Representation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "15 pages", "summary": "We propose new static word embeddings optimised for sentence semantic\nrepresentation. We first extract word embeddings from a pre-trained Sentence\nTransformer, and improve them with sentence-level principal component analysis,\nfollowed by either knowledge distillation or contrastive learning. During\ninference, we represent sentences by simply averaging word embeddings, which\nrequires little computational cost. We evaluate models on both monolingual and\ncross-lingual tasks and show that our model substantially outperforms existing\nstatic models on sentence semantic tasks, and even rivals a basic Sentence\nTransformer model (SimCSE) on some data sets. Lastly, we perform a variety of\nanalyses and show that our method successfully removes word embedding\ncomponents that are irrelevant to sentence semantics, and adjusts the vector\nnorms based on the influence of words on sentence semantics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u540e\u7684\u9759\u6001\u8bcd\u5d4c\u5165\u65b9\u6cd5\uff0c\u901a\u8fc7\u53e5\u5b50\u7ea7\u4e3b\u6210\u5206\u5206\u6790\u4ee5\u53ca\u77e5\u8bc6\u84b8\u998f\u6216\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u4f18\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u8868\u793a\u53e5\u5b50\u8bed\u4e49\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u4f18\u5316\u9759\u6001\u8bcd\u5d4c\u5165\u4ee5\u63d0\u9ad8\u5b83\u4eec\u5728\u53e5\u5b50\u8bed\u4e49\u8868\u793a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u4ece\u9884\u8bad\u7ec3\u7684\u53e5\u5b50\u8f6c\u6362\u5668\u4e2d\u63d0\u53d6\u8bcd\u5d4c\u5165\uff0c\u5e76\u5229\u7528\u53e5\u5b50\u7ea7\u4e3b\u6210\u5206\u5206\u6790\u8fdb\u884c\u4f18\u5316\uff0c\u968f\u540e\u5e94\u7528\u77e5\u8bc6\u84b8\u998f\u6216\u5bf9\u6bd4\u5b66\u4e60\u3002\u63a8\u7406\u65f6\uff0c\u901a\u8fc7\u7b80\u5355\u5730\u5e73\u5747\u8bcd\u5d4c\u5165\u6765\u8868\u793a\u53e5\u5b50\u3002", "result": "\u6a21\u578b\u5728\u5355\u8bed\u548c\u8de8\u8bed\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u5927\u5e45\u5ea6\u8d85\u8d8a\u73b0\u6709\u9759\u6001\u6a21\u578b\uff0c\u5e76\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u80fd\u591f\u4e0e\u57fa\u672c\u7684Sentence Transformer\u6a21\u578b\uff08SimCSE\uff09\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u65b0\u9759\u6001\u8bcd\u5d4c\u5165\u5728\u53e5\u5b50\u8bed\u4e49\u8868\u793a\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u5728\u67d0\u4e9b\u6570\u636e\u96c6\u4e0a\u4e0e\u57fa\u672c\u7684Sentence Transformer\u6a21\u578b\uff08SimCSE\uff09\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2506.04912", "pdf": "https://arxiv.org/pdf/2506.04912", "abs": "https://arxiv.org/abs/2506.04912", "authors": ["Pietro Miotti", "Eyvind Niklasson", "Ettore Randazzo", "Alexander Mordvintsev"], "title": "Differentiable Logic Cellular Automata: From Game of Life to Pattern Generation", "categories": ["cs.AI"], "comment": null, "summary": "This paper introduces Differentiable Logic Cellular Automata (DiffLogic CA),\na novel combination of Neural Cellular Automata (NCA) and Differentiable Logic\nGates Networks (DLGNs). The fundamental computation units of the model are\ndifferentiable logic gates, combined into a circuit. During training, the model\nis fully end-to-end differentiable allowing gradient-based training, and at\ninference time it operates in a fully discrete state space. This enables\nlearning local update rules for cellular automata while preserving their\ninherent discrete nature. We demonstrate the versatility of our approach\nthrough a series of milestones: (1) fully learning the rules of Conway's Game\nof Life, (2) generating checkerboard patterns that exhibit resilience to noise\nand damage, (3) growing a lizard shape, and (4) multi-color pattern generation.\nOur model successfully learns recurrent circuits capable of generating desired\ntarget patterns. For simpler patterns, we observe success with both synchronous\nand asynchronous updates, demonstrating significant generalization capabilities\nand robustness to perturbations. We make the case that this combination of\nDLGNs and NCA represents a step toward programmable matter and robust computing\nsystems that combine binary logic, neural network adaptability, and localized\nprocessing. This work, to the best of our knowledge, is the first successful\napplication of differentiable logic gate networks in recurrent architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408NCA\u548cDLGNs\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5e94\u7528\u4e8e\u5b66\u4e60\u548c\u751f\u6210\u56fe\u6848\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u662f\u53ef\u7f16\u7a0b\u548c\u5065\u58ee\u8ba1\u7b97\u7cfb\u7edf\u7684\u4e00\u6b65\u3002", "motivation": "\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u7ed3\u5408\u4e8c\u8fdb\u5236\u903b\u8f91\u3001\u795e\u7ecf\u7f51\u7edc\u9002\u5e94\u6027\u548c\u5c40\u90e8\u5904\u7406\uff0c\u5f00\u53d1\u66f4\u52a0\u5065\u58ee\u548c\u53ef\u7f16\u7a0b\u7684\u8ba1\u7b97\u7cfb\u7edf\u3002", "method": "\u8be5\u6a21\u578b\u7684\u57fa\u672c\u8ba1\u7b97\u5355\u5143\u662f\u53ef\u5fae\u903b\u8f91\u95e8\uff0c\u5e76\u7ed3\u5408\u6210\u7535\u8def\uff0c\u901a\u8fc7\u68af\u5ea6\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728\u63a8\u7406\u65f6\u64cd\u4f5c\u4e8e\u5b8c\u5168\u79bb\u6563\u72b6\u6001\u7a7a\u95f4\u3002\u8fd9\u4f7f\u5f97\u53ef\u4ee5\u5728\u4fdd\u6301\u79bb\u6563\u6027\u7684\u540c\u65f6\u5b66\u4e60\u7ec6\u80de\u81ea\u52a8\u673a\u7684\u5c40\u90e8\u66f4\u65b0\u89c4\u5219\u3002", "result": "\u6a21\u578b\u6210\u529f\u5b66\u4e60\u5230\u751f\u6210\u76ee\u6807\u56fe\u6848\u7684\u9012\u5f52\u7535\u8def\uff0c\u7279\u522b\u662f\u5728\u7b80\u5355\u56fe\u6848\u4e0a\uff0c\u89c2\u5bdf\u5230\u540c\u6b65\u548c\u5f02\u6b65\u66f4\u65b0\u5747\u53d6\u5f97\u6210\u529f\uff0c\u5c55\u793a\u4e86\u663e\u8457\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5bf9\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u9996\u6b21\u6210\u529f\u5c06\u53ef\u5fae\u903b\u8f91\u95e8\u7f51\u7edc\u5e94\u7528\u4e8e\u9012\u5f52\u67b6\u6784\uff0c\u8868\u660eDLGNs\u548cNCA\u7684\u7ed3\u5408\u662f\u671d\u7740\u53ef\u7f16\u7a0b\u7269\u8d28\u548c\u5065\u58ee\u8ba1\u7b97\u7cfb\u7edf\u53d1\u5c55\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2506.04434", "pdf": "https://arxiv.org/pdf/2506.04434", "abs": "https://arxiv.org/abs/2506.04434", "authors": ["Hari K. Prakash", "Charles H. Martin"], "title": "Grokking and Generalization Collapse: Insights from \\texttt{HTSR} theory", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "15 pages,7 figs", "summary": "We study the well-known grokking phenomena in neural networks (NNs) using a\n3-layer MLP trained on 1 k-sample subset of MNIST, with and without weight\ndecay, and discover a novel third phase -- \\emph{anti-grokking} -- that occurs\nvery late in training and resembles but is distinct from the familiar\n\\emph{pre-grokking} phases: test accuracy collapses while training accuracy\nstays perfect. This late-stage collapse is distinct, from the known\npre-grokking and grokking phases, and is not detected by other proposed\ngrokking progress measures. Leveraging Heavy-Tailed Self-Regularization HTSR\nthrough the open-source WeightWatcher tool, we show that the HTSR layer quality\nmetric $\\alpha$ alone delineates all three phases, whereas the best competing\nmetrics detect only the first two. The \\emph{anti-grokking} is revealed by\ntraining for $10^7$ and is invariably heralded by $\\alpha < 2$ and the\nappearance of \\emph{Correlation Traps} -- outlier singular values in the\nrandomized layer weight matrices that make the layer weight matrix atypical and\nsignal overfitting of the training set. Such traps are verified by visual\ninspection of the layer-wise empirical spectral densities, and by using\nKolmogorov--Smirnov tests on randomized spectra. Comparative metrics, including\nactivation sparsity, absolute weight entropy, circuit complexity, and $l^2$\nweight norms track pre-grokking and grokking but fail to distinguish grokking\nfrom anti-grokking. This discovery provides a way to measure overfitting and\ngeneralization collapse without direct access to the test data. These results\nstrengthen the claim that the \\emph{HTSR} $\\alpha$ provides universal\nlayer-convergence target at $\\alpha \\approx 2$ and underscore the value of\nusing the HTSR alpha $(\\alpha)$ metric as a measure of generalization.", "AI": {"tldr": "\u53d1\u73b0\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u201c\u53cd\u609f\u201d\u9636\u6bb5\uff0c\u63d0\u51fa\u7528HTSR \u03b1\u4f5c\u4e3a\u6cdb\u5316\u6d4b\u91cf\u7684\u6709\u6548\u6307\u6807\uff0c\u800c\u4e0d\u662f\u5355\u51ed\u6d4b\u8bd5\u6570\u636e\u3002", "motivation": "\u7814\u7a76\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u53cd\u609f\uff08anti-grokking\uff09\u9636\u6bb5\uff0c\u4ece\u800c\u63ed\u793a\u4e00\u79cd\u65b0\u7684\u8fc7\u62df\u5408\u4e0e\u6cdb\u5316\u5d29\u6e83\u6d4b\u91cf\u624b\u6bb5\uff0c\u907f\u514d\u76f4\u63a5\u4f9d\u8d56\u6d4b\u8bd5\u6570\u636e\u3002", "method": "\u4f7f\u75283\u5c42MLP\uff0c\u7ed3\u5408WeightWatcher\u5de5\u5177\uff0c\u901a\u8fc7HTSR\u65b9\u6cd5\u6765\u5206\u6790MNIST\u5b50\u96c6\u5728\u6709\u65e0\u6743\u91cd\u8870\u51cf\u6761\u4ef6\u4e0b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u8bc1\u660e\u4e86HTSR \u03b1\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6240\u6709\u9636\u6bb5\uff0c\u5e76\u63ed\u793a\u91cd\u8bad\u7ec3\u4e0e\u03b1 < 2\u6240\u5173\u8054\u7684\u76f8\u5173\u9677\u9631\u4fe1\u53f7\u3002\u4f20\u7edf\u6307\u6807\u53ea\u80fd\u68c0\u6d4b\u524d\u4e24\u4e2a\u9636\u6bb5\uff0c\u800c\u4e0d\u80fd\u6709\u6548\u5730\u533a\u5206\u609f\uff08grokking\uff09\u4e0e\u53cd\u609f\u9636\u6bb5\u3002", "conclusion": "\u53cd\u609f\u73b0\u8c61\uff08anti-grokking\uff09\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u4e2d\u662f\u4e00\u4e2a\u65b0\u7684\u9636\u6bb5\uff0c\u5e76\u4e14\u5728\u8bad\u7ec3\u7684\u540e\u671f\u53ef\u80fd\u5bfc\u81f4\u6d4b\u8bd5\u51c6\u786e\u7387\u5d29\u6e83\uff0c\u800c\u8bad\u7ec3\u51c6\u786e\u7387\u7ef4\u6301\u5b8c\u7f8e\u3002\u901a\u8fc7\u4f7f\u7528\u91cd\u5c3e\u81ea\u6b63\u5219\u5316\uff08HTSR\uff09\uff0c\u53d1\u73b0HTSR\u7684\u5c42\u8d28\u91cf\u6307\u6807\u03b1\u80fd\u591f\u8fa8\u522b\u6240\u6709\u4e09\u4e2a\u9636\u6bb5\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8861\u91cf\u8fc7\u62df\u5408\u548c\u6cdb\u5316\u5d29\u6e83\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.04625", "pdf": "https://arxiv.org/pdf/2506.04625", "abs": "https://arxiv.org/abs/2506.04625", "authors": ["Zhiyuan Ma", "Jiayu Liu", "Xianzhen Luo", "Zhenya Huang", "Qingfu Zhu", "Wanxiang Che"], "title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "categories": ["cs.CL"], "comment": "Accepted at the Research Track of KDD 2025", "summary": "Empowering large language models (LLMs) with effective tool utilization\ncapabilities is crucial for enabling AI agents to solve complex problems.\nHowever, current models face two major limitations: (1) unreliable tool\nplanning and invocation due to low-quality instruction datasets (e.g.,\nwidespread hallucinated API calls), and (2) weak tool reflection abilities\n(over 90% of errors cannot be corrected) resulting from static imitation\nlearning. To address these critical limitations, we propose Tool-MVR, a novel\nTool-Augmented LLM that achieves comprehensive System 2 reasoning through two\nkey innovations. Specifically, we first introduce Multi-Agent Meta-Verification\n(MAMV), a systematic pipeline that rigorously validates APIs, queries, and\nreasoning trajectories to construct ToolBench-V, a new high-quality instruction\ndataset that addresses the limitation of unreliable tool planning and\ninvocation. Second, we propose Exploration-based Reflection Learning (EXPLORE),\nwhich enhances tool reflection capabilities by leveraging tool feedback through\na dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in\nour reflection dataset ToolBench-R and addressing the critical weakness in tool\nreflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g.,\nQwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that\nTool-MVR achieves state-of-the-art performance on StableToolBench, surpassing\nboth ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%,\nwith strong generalization capabilities across unseen tools and scenarios.\nAdditionally, on our proposed RefineToolBench, the first benchmark specifically\ndesigned to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9%\nerror correction rate, significantly outperforming ToolLLM's 9.1%.", "AI": {"tldr": "The paper presents Tool-MVR, an enhanced LLM for better tool utilization and reflection, significantly outperforming existing models in various benchmarks.", "motivation": "To overcome the limitations of current language models in tool planning and invocation as well as tool reflection abilities, which hinder their problem-solving capacities.", "method": "The paper introduces Tool-MVR, which incorporates Multi-Agent Meta-Verification (MAMV) for constructing a more reliable instruction dataset (ToolBench-V) and Exploration-based Reflection Learning (EXPLORE) for better tool reflection, resulting in ToolBench-R. The model is fine-tuned on these new datasets, leading to improved performance.", "result": "Tool-MVR outperforms ToolLLM by 23.9% and GPT-4 by 15.3% on the StableToolBench, while reducing API calls by 31.4%. It also achieves a 58.9% error correction rate on RefineToolBench, vastly outperforming ToolLLM's 9.1%.", "conclusion": "Tool-MVR significantly outperforms existing models in tool utilization and reflection capabilities, making it a leading approach in AI problem-solving."}}
{"id": "2506.04916", "pdf": "https://arxiv.org/pdf/2506.04916", "abs": "https://arxiv.org/abs/2506.04916", "authors": ["Atahan Karagoz"], "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "This paper introduces Energentic Intelligence, a class of autonomous systems\ndefined not by task performance, but by their capacity to sustain themselves\nthrough internal energy regulation. Departing from conventional reward-driven\nparadigms, these agents treat survival-maintaining functional operation under\nfluctuating energetic and thermal conditions-as the central objective. We\nformalize this principle through an energy-based utility function and a\nviability-constrained survival horizon, and propose a modular architecture that\nintegrates energy harvesting, thermal regulation, and adaptive computation into\na closed-loop control system. A simulated environment demonstrates the\nemergence of stable, resource-aware behavior without external supervision.\nTogether, these contributions provide a theoretical and architectural\nfoundation for deploying autonomous agents in resource-volatile settings where\npersistence must be self-regulated and infrastructure cannot be assumed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u80fd\u91cf\u667a\u80fd\u7cfb\u7edf\uff0c\u5229\u7528\u95ed\u73af\u63a7\u5236\u81ea\u6211\u8c03\u8282\u80fd\u91cf\u5728\u4e0d\u7a33\u5b9a\u8d44\u6e90\u73af\u5883\u4e2d\u751f\u5b58\uff0c\u4ee5\u6b64\u4e3a\u7406\u8bba\u548c\u67b6\u6784\u57fa\u7840\u5b9e\u73b0\u81ea\u4e3b\u4ee3\u7406\u7684\u6301\u4e45\u6027\u3002", "motivation": "\u76ee\u524d\u7684\u5956\u52b1\u9a71\u52a8\u8303\u5f0f\u4fa7\u91cd\u4e8e\u4efb\u52a1\u8868\u73b0\uff0c\u5728\u8d44\u6e90\u6709\u9650\u6216\u6ce2\u52a8\u7684\u73af\u5883\u4e2d\u96be\u4ee5\u9002\u7528\u3002\u56e0\u6b64\uff0c\u9700\u5f00\u53d1\u80fd\u591f\u81ea\u6211\u8c03\u8282\u80fd\u91cf\u7684\u7cfb\u7edf\u4ee5\u4fdd\u8bc1\u6301\u4e45\u751f\u5b58\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u80fd\u91cf\u4e3a\u57fa\u7840\u7684\u6548\u7528\u51fd\u6570\u548c\u751f\u5b58\u8303\u56f4\u7684\u53ef\u884c\u6027\u7ea6\u675f\u5f62\u5f0f\u5316\u8be5\u539f\u5219\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u96c6\u6210\u80fd\u91cf\u6536\u96c6\u3001\u70ed\u91cf\u8c03\u8282\u548c\u81ea\u9002\u5e94\u8ba1\u7b97\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u7ec4\u6210\u95ed\u73af\u63a7\u5236\u7cfb\u7edf\u3002", "result": "\u5728\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u7cfb\u7edf\u5728\u65e0\u5916\u90e8\u76d1\u7763\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u7a33\u5b9a\u4e14\u8d44\u6e90\u611f\u77e5\u7684\u884c\u4e3a\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u6cbb\u7cfb\u7edf\u2014\u2014\u80fd\u91cf\u667a\u80fd\uff0c\u5176\u76ee\u6807\u4e0d\u662f\u4efb\u52a1\u6027\u80fd\uff0c\u800c\u662f\u901a\u8fc7\u5185\u90e8\u80fd\u91cf\u8c03\u8282\u7ef4\u6301\u81ea\u8eab\u751f\u5b58\u3002\u8fd9\u4e3a\u5728\u8d44\u6e90\u53d8\u5316\u65e0\u5e38\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u81ea\u6cbb\u4ee3\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u67b6\u6784\u57fa\u7840\u3002"}}
{"id": "2506.04439", "pdf": "https://arxiv.org/pdf/2506.04439", "abs": "https://arxiv.org/abs/2506.04439", "authors": ["Robin Yadav", "Qi Yan", "Guy Wolf", "Avishek Joey Bose", "Renjie Liao"], "title": "RETRO SYNFLOW: Discrete Flow Matching for Accurate and Diverse Single-Step Retrosynthesis", "categories": ["cs.LG"], "comment": null, "summary": "A fundamental problem in organic chemistry is identifying and predicting the\nseries of reactions that synthesize a desired target product molecule. Due to\nthe combinatorial nature of the chemical search space, single-step reactant\nprediction -- i.e. single-step retrosynthesis -- remains challenging even for\nexisting state-of-the-art template-free generative approaches to produce an\naccurate yet diverse set of feasible reactions. In this paper, we model\nsingle-step retrosynthesis planning and introduce RETRO SYNFLOW (RSF) a\ndiscrete flow-matching framework that builds a Markov bridge between the\nprescribed target product molecule and the reactant molecule. In contrast to\npast approaches, RSF employs a reaction center identification step to produce\nintermediate structures known as synthons as a more informative source\ndistribution for the discrete flow. To further enhance diversity and\nfeasibility of generated samples, we employ Feynman-Kac steering with\nSequential Monte Carlo based resampling to steer promising generations at\ninference using a new reward oracle that relies on a forward-synthesis model.\nEmpirically, we demonstrate \\nameshort achieves $60.0 \\%$ top-1 accuracy, which\noutperforms the previous SOTA by $20 \\%$. We also substantiate the benefits of\nsteering at inference and demonstrate that FK-steering improves top-$5$\nround-trip accuracy by $19 \\%$ over prior template-free SOTA methods, all while\npreserving competitive top-$k$ accuracy results.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5f15\u5165RETRO SYNFLOW\u6846\u67b6\u63d0\u9ad8\u4e86\u9006\u5408\u6210\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u4e8660%\u7684top-1\u51c6\u786e\u7387\u3002", "motivation": "\u5728\u6709\u673a\u5316\u5b66\u4e2d\uff0c\u8bc6\u522b\u548c\u9884\u6d4b\u5408\u6210\u76ee\u6807\u4ea7\u7269\u5206\u5b50\u7684\u4e00\u7cfb\u5217\u53cd\u5e94\u662f\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\u3002\u7531\u4e8e\u5316\u5b66\u641c\u7d22\u7a7a\u95f4\u7684\u7ec4\u5408\u6027\u8d28\uff0c\u5355\u6b65\u53cd\u5e94\u7269\u9884\u6d4b\uff0c\u5373\u5355\u6b65\u9006\u5408\u6210\uff0c\u5bf9\u4e8e\u73b0\u6709\u7684\u65e0\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u6765\u8bf4\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f15\u5165RETRO SYNFLOW\uff08RSF\uff09\u79bb\u6563\u6d41\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u9a6c\u5c14\u79d1\u592b\u6865\u6881\u6765\u8fde\u63a5\u76ee\u6807\u4ea7\u7269\u5206\u5b50\u548c\u53cd\u5e94\u7269\u5206\u5b50\u3002RSF\u5305\u62ec\u53cd\u5e94\u4e2d\u5fc3\u8bc6\u522b\u6b65\u9aa4\uff0c\u4ee5\u751f\u6210\u4e2d\u95f4\u7ed3\u6784\uff08\u5408\u6210\u5355\u5143\uff09\u4f5c\u4e3a\u79bb\u6563\u6d41\u7684\u66f4\u5177\u4fe1\u606f\u7684\u6e90\u5206\u5e03\uff0c\u5e76\u7ed3\u5408\u8d39\u66fc-\u5361\u514b\u5f15\u5bfc\u4e0e\u57fa\u4e8e\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u7684\u518d\u91c7\u6837\u65b9\u6cd5\u3002", "result": "\u5b9e\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e8660.0%\u7684top-1\u51c6\u786e\u7387\uff0c\u6bd4\u4ee5\u524d\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e8620%\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u8fdb\u884cFK\u5f15\u5bfc\uff0c\u63d0\u9ad8\u4e86top-5\u5f80\u8fd4\u51c6\u786e\u738719%\u3002", "conclusion": "RSF\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\u7ed3\u679c\u7684\u540c\u65f6\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u751f\u6210\u53cd\u5e94\u7684\u591a\u6837\u6027\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2506.04635", "pdf": "https://arxiv.org/pdf/2506.04635", "abs": "https://arxiv.org/abs/2506.04635", "authors": ["Thai-Binh Nguyen", "Thi Van Nguyen", "Quoc Truong Do", "Chi Mai Luong"], "title": "ViCocktail: Automated Multi-Modal Data Collection for Vietnamese Audio-Visual Speech Recognition", "categories": ["cs.CL", "cs.CV"], "comment": "Accepted at Interspeech 2025", "summary": "Audio-Visual Speech Recognition (AVSR) has gained significant attention\nrecently due to its robustness against noise, which often challenges\nconventional speech recognition systems that rely solely on audio features.\nDespite this advantage, AVSR models remain limited by the scarcity of extensive\ndatasets, especially for most languages beyond English. Automated data\ncollection offers a promising solution. This work presents a practical approach\nto generate AVSR datasets from raw video, refining existing techniques for\nimproved efficiency and accessibility. We demonstrate its broad applicability\nby developing a baseline AVSR model for Vietnamese. Experiments show the\nautomatically collected dataset enables a strong baseline, achieving\ncompetitive performance with robust ASR in clean conditions and significantly\noutperforming them in noisy environments like cocktail parties. This efficient\nmethod provides a pathway to expand AVSR to more languages, particularly\nunder-resourced ones.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4ece\u89c6\u9891\u4e2d\u81ea\u52a8\u751f\u6210\u97f3\u89c6\u9891\u8bed\u97f3\u8bc6\u522b\u6570\u636e\u96c6\u7684\u65b9\u6cd5\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u8d8a\u5357\u8bed\uff0c\u5b9e\u73b0\u4e86\u5728\u566a\u97f3\u73af\u5883\u4e0b\u4f18\u4e8e\u4f20\u7edfASR\u7684\u8868\u73b0\u3002", "motivation": "\u7531\u4e8e\u97f3\u89c6\u9891\u8bed\u97f3\u8bc6\u522b\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5c3d\u7ba1\u76ee\u524d\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u5c24\u5176\u662f\u82f1\u8bed\u4ee5\u5916\u7684\u8bed\u8a00\uff0c\u4ecd\u6709\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u6570\u636e\u6536\u96c6\u65b9\u6cd5\uff0c\u4ece\u539f\u59cb\u89c6\u9891\u4e2d\u751f\u6210\u97f3\u89c6\u9891\u8bed\u97f3\u8bc6\u522b\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u81ea\u52a8\u6536\u96c6\u7684\u6570\u636e\u96c6\u652f\u6301\u5f3a\u5927\u7684\u57fa\u7ebfAVSR\u6a21\u578b\uff0c\u5728\u6e05\u6670\u73af\u5883\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u5e76\u5728\u566a\u97f3\u73af\u5883\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edfASR\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u97f3\u89c6\u9891\u8bed\u97f3\u8bc6\u522b\u6570\u636e\u96c6\uff0c\u5c24\u5176\u662f\u5bf9\u8d44\u6e90\u8f83\u5c11\u7684\u8bed\u8a00\uff0c\u5982\u8d8a\u5357\u8bed\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u5728\u566a\u97f3\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.04998", "pdf": "https://arxiv.org/pdf/2506.04998", "abs": "https://arxiv.org/abs/2506.04998", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "categories": ["cs.AI"], "comment": "15 pages, 7 figures, 4 appendix subsections", "summary": "Autonomous UAV operation necessitates reliable mathematical reasoning for\ntasks such as trajectory planning and power management. While traditional\nflight control relies on hardcoded equations, recent Large Language Models\n(LLMs) offer potential for more flexible problem-solving but struggle with\nreliably selecting and applying correct mathematical formulations and executing\nprecise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented\ngeneration framework designed to improve the mathematical reasoning of several\nLLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in\nUAV-specific contexts by providing access to relevant domain literature. To\nconduct an initial assessment, we introduce the UAV-Math-Bench, a small problem\nset comprising 20 UAV-centric mathematical problems across four difficulty\nlevels. Our experiments demonstrate that incorporating retrieval substantially\nincreases exact answer accuracy (achieving up to 75% with o1), reduces\ninstances of incorrect formulation selection (from 25% without RAG to 5% with\nRAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders\nof magnitude for the best-performing models. This pilot study indicates that\nRAG can enable general-purpose LLMs to function as more reliable tools for\nengineering analysis, although direct real-time flight control requires further\ninvestigation and validation on a larger scale. All benchmark data, question\nand answer are publicly available.", "AI": {"tldr": "RAG-UAV\u6846\u67b6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u63d0\u9ad8LLM\u5728\u65e0\u4eba\u673a\u4efb\u52a1\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u9519\u8bef\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u4e3b\u65e0\u4eba\u673a\u4efb\u52a1\u4e2d\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u6709\u5f85\u63d0\u9ad8\uff0c\u4f20\u7edf\u98de\u884c\u63a7\u5236\u4f9d\u8d56\u786c\u7f16\u7801\u65b9\u7a0b\uff0c\u800c\u65b0\u5174\u7684LLM\u867d\u5177\u6f5c\u529b\u4f46\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAG-UAV\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u4f9b\u76f8\u5173\u9886\u57df\u6587\u732e\u6765\u6539\u8fdb\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRAG\u6846\u67b6\u80fd\u663e\u8457\u63d0\u9ad8\u7cbe\u786e\u7b54\u6848\u7684\u51c6\u786e\u7387\uff0c\u51cf\u5c11\u9519\u8bef\u516c\u5f0f\u9009\u62e9\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u5747\u65b9\u8bef\u5dee\u3002", "conclusion": "RAG-UAV\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728UAV\u7279\u5b9a\u60c5\u5883\u4e0b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u5de5\u7a0b\u5206\u6790\u4e2d\u66f4\u4e3a\u53ef\u9760\u3002"}}
{"id": "2506.04446", "pdf": "https://arxiv.org/pdf/2506.04446", "abs": "https://arxiv.org/abs/2506.04446", "authors": ["Gil I. Shamir", "Manfred K. Warmuth"], "title": "Selective Matching Losses -- Not All Scores Are Created Equal", "categories": ["cs.LG"], "comment": null, "summary": "Learning systems match predicted scores to observations over some domain.\nOften, it is critical to produce accurate predictions in some subset (or\nregion) of the domain, yet less important to accurately predict in other\nregions. We construct selective matching loss functions by design of increasing\nlink functions over score domains. A matching loss is an integral over the\nlink. A link defines loss sensitivity as function of the score, emphasizing\nhigh slope high sensitivity regions over flat ones. Loss asymmetry drives a\nmodel and resolves its underspecification to predict better in high sensitivity\nregions where it is more important, and to distinguish between high and low\nimportance regions. A large variety of selective scalar losses can be designed\nwith scaled and shifted Sigmoid and hyperbolic sine links. Their properties,\nhowever, do not extend to multi-class. Applying them per dimension lacks\nranking sensitivity that assigns importance according to class score ranking.\nUtilizing composite Softmax functions, we develop a framework for\nmultidimensional selective losses. We overcome limitations of the standard\nSoftmax function, that is good for classification, but not for distinction\nbetween adjacent scores. Selective losses have substantial advantage over\ntraditional losses in applications with more important score regions, including\ndwell-time prediction, retrieval, ranking with either pointwise, contrastive\npairwise, or listwise losses, distillation problems, and fine-tuning alignment\nof Large Language Models (LLMs).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9009\u62e9\u6027\u635f\u5931\uff0c\u901a\u8fc7\u8c03\u6574\u5f97\u5206\u533a\u57df\u7684\u654f\u611f\u6027\uff0c\u63d0\u9ad8\u5728\u67d0\u4e9b\u91cd\u8981\u533a\u57df\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u591a\u7c7b\u522b\u95ee\u9898\u4e2d\uff0c\u91c7\u7528\u590d\u5408Softmax\u51fd\u6570\u6539\u8fdb\u4e86\u591a\u7ef4\u9009\u62e9\u6027\u8ba1\u7b97\u3002", "motivation": "\u5728\u67d0\u4e9b\u9886\u57df\u7684\u5b50\u96c6\u4e2d\u4ea7\u751f\u51c6\u786e\u9884\u6d4b\u975e\u5e38\u91cd\u8981\uff0c\u800c\u5728\u5176\u4ed6\u533a\u57df\u5219\u4e0d\u592a\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u6784\u9020\u9009\u62e9\u6027\u5339\u914d\u635f\u5931\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u7ec4\u5408Softmax\u51fd\u6570\u7684\u6846\u67b6\u8fdb\u884c\u591a\u7ef4\u9009\u62e9\u6027\u635f\u5931\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\uff0c\u5229\u7528\u9009\u62e9\u6027\u635f\u5931\u5728\u9ad8\u91cd\u8981\u6027\u533a\u57df\u83b7\u5f97\u66f4\u597d\u7684\u9884\u6d4b\uff0c\u540c\u65f6\u5728\u591a\u7ef4\u5ea6\u4e0b\u514b\u670d\u4e86\u6807\u51c6Softmax\u51fd\u6570\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9009\u62e9\u6027\u635f\u5931\u5728\u5b58\u5728\u91cd\u8981\u8bc4\u5206\u533a\u57df\u7684\u5e94\u7528\u4e2d\u6bd4\u4f20\u7edf\u635f\u5931\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.04642", "pdf": "https://arxiv.org/pdf/2506.04642", "abs": "https://arxiv.org/abs/2506.04642", "authors": ["Vinay Joshi", "Pratik Prabhanjan Brahma", "Zicheng Liu", "Emad Barsoum"], "title": "TaDA: Training-free recipe for Decoding with Adaptive KV Cache Compression and Mean-centering", "categories": ["cs.CL"], "comment": "ACL-2025 industry-track accepted", "summary": "The key-value (KV) cache in transformer models is a critical component for\nefficient decoding or inference, yet its memory demands scale poorly with\nsequence length, posing a major challenge for scalable deployment of large\nlanguage models. Among several approaches to KV cache compression, quantization\nof key and value activations has been widely explored. Most KV cache\nquantization methods still need to manage sparse and noncontiguous outliers\nseparately. To address this, we introduce TaDA, a training-free recipe for KV\ncache compression with quantization precision that adapts to error sensitivity\nacross layers and a mean centering to eliminate separate outlier handling. Our\napproach yields substantial accuracy improvements for multiple models\nsupporting various context lengths. Moreover, our approach does not need to\nseparately manage outlier elements -- a persistent hurdle in most traditional\nquantization methods. Experiments on standard benchmarks demonstrate that our\ntechnique reduces KV cache memory footprint to 27% of the original 16-bit\nbaseline while achieving comparable accuracy. Our method paves the way for\nscalable and high-performance reasoning in language models by potentially\nenabling inference for longer context length models, reasoning models, and\nlonger chain of thoughts.", "AI": {"tldr": "\u5f15\u5165 TaDA \u65b9\u6cd5\uff0c\u65e0\u9700\u5355\u72ec\u5904\u7406\u5f02\u5e38\u503c\uff0c\u53ef\u663e\u8457\u51cf\u5c11 KV \u7f13\u5b58\u5185\u5b58\u5360\u7528\u5e76\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u652f\u6301\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u548c\u63a8\u7406\u94fe\u3002", "motivation": "KV \u7f13\u5b58\u7684\u5185\u5b58\u9700\u6c42\u4e0e\u5e8f\u5217\u957f\u5ea6\u6210\u6bd4\u4f8b\u589e\u957f\uff0c\u8fd9\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u627e\u5230\u4e00\u79cd\u80fd\u591f\u6709\u6548\u538b\u7f29 KV \u7f13\u5b58\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TaDA \u7684\u8bad\u7ec3\u81ea\u7531 KV \u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\uff0c\u4f7f\u7528\u91cf\u5316\u7cbe\u5ea6\u6839\u636e\u9519\u8bef\u654f\u611f\u5ea6\u5728\u5c42\u95f4\u8fdb\u884c\u9002\u5e94\uff0c\u540c\u65f6\u901a\u8fc7\u5747\u503c\u4e2d\u5fc3\u5316\u6d88\u9664\u4e86\u5355\u72ec\u7684\u5f02\u5e38\u503c\u5904\u7406\u3002", "result": "\u6211\u4eec\u7684\u6280\u672f\u5c06 KV \u7f13\u5b58\u7684\u5185\u5b58\u5360\u7528\u51cf\u5c11\u5230\u539f\u59cb 16 \u4f4d\u57fa\u7ebf\u7684 27%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u53ef\u6bd4\u8f83\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u51c6\u786e\u7387\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11 KV \u7f13\u5b58\u7684\u5185\u5b58\u9700\u6c42\uff0c\u8fd9\u53ef\u80fd\u6709\u52a9\u4e8e\u652f\u6301\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u66f4\u590d\u6742\u7684\u63a8\u7406\u3002"}}
{"id": "2506.05109", "pdf": "https://arxiv.org/pdf/2506.05109", "abs": "https://arxiv.org/abs/2506.05109", "authors": ["Tennison Liu", "Mihaela van der Schaar"], "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "categories": ["cs.AI"], "comment": "Published as a conference paper at ICML 2025", "summary": "Self-improving agents aim to continuously acquire new capabilities with\nminimal supervision. However, current approaches face two key limitations:\ntheir self-improvement processes are often rigid, fail to generalize across\ntasks domains, and struggle to scale with increasing agent capabilities. We\nargue that effective self-improvement requires intrinsic metacognitive\nlearning, defined as an agent's intrinsic ability to actively evaluate, reflect\non, and adapt its own learning processes. Drawing inspiration from human\nmetacognition, we introduce a formal framework comprising three components:\nmetacognitive knowledge (self-assessment of capabilities, tasks, and learning\nstrategies), metacognitive planning (deciding what and how to learn), and\nmetacognitive evaluation (reflecting on learning experiences to improve future\nlearning). Analyzing existing self-improving agents, we find they rely\npredominantly on extrinsic metacognitive mechanisms, which are fixed,\nhuman-designed loops that limit scalability and adaptability. Examining each\ncomponent, we contend that many ingredients for intrinsic metacognition are\nalready present. Finally, we explore how to optimally distribute metacognitive\nresponsibilities between humans and agents, and robustly evaluate and improve\nintrinsic metacognitive learning, key challenges that must be addressed to\nenable truly sustained, generalized, and aligned self-improvement.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u5185\u5728\u5143\u8ba4\u77e5\u6846\u67b6\u4ee5\u514b\u670d\u76ee\u524d\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\u7684\u5c40\u9650\u6027\uff0c\u5206\u6790\u73b0\u6709\u7cfb\u7edf\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u4f18\u5316\u4eba\u7c7b\u4e0e\u4ee3\u7406\u95f4\u7684\u5143\u8ba4\u77e5\u4efb\u52a1\u5206\u914d\u3002", "motivation": "\u5f53\u524d\u7684\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5305\u62ec\u5176\u8fc7\u7a0b\u50f5\u5316\u3001\u96be\u4ee5\u5728\u4efb\u52a1\u9886\u57df\u95f4\u6cdb\u5316\u4ee5\u53ca\u65e0\u6cd5\u968f\u7740\u80fd\u529b\u63d0\u5347\u8fdb\u884c\u6269\u5c55\u3002\u6709\u6548\u7684\u81ea\u6211\u6539\u8fdb\u9700\u8981\u5185\u5728\u7684\u5143\u8ba4\u77e5\u5b66\u4e60\u80fd\u529b\uff0c\u80fd\u591f\u4e3b\u52a8\u8bc4\u4f30\u3001\u53cd\u601d\u53ca\u8c03\u6574\u81ea\u8eab\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u7531\u5143\u8ba4\u77e5\u77e5\u8bc6\u3001\u5143\u8ba4\u77e5\u89c4\u5212\u53ca\u5143\u8ba4\u77e5\u8bc4\u4f30\u6784\u6210\u7684\u6846\u67b6\uff0c\u8fd9\u4e09\u8005\u5206\u522b\u5bf9\u5e94\u81ea\u8bc4\u80fd\u529b\u3001\u5b66\u4e60\u51b3\u7b56\u53ca\u53cd\u601d\u5b66\u4e60\u7ecf\u9a8c\u3002\u901a\u8fc7\u5206\u6790\u73b0\u6709\u7684\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\uff0c\u53d1\u73b0\u5176\u4e3b\u8981\u4f9d\u8d56\u5916\u90e8\u8bbe\u8ba1\u7684\u56fa\u5b9a\u7cfb\u7edf\u6765\u8fdb\u884c\u5143\u8ba4\u77e5\u8fc7\u7a0b\u3002", "result": "\u8bb8\u591a\u5185\u5728\u5143\u8ba4\u77e5\u5b66\u4e60\u7684\u8981\u7d20\u5df2\u7ecf\u5b58\u5728\uff0c\u4f46\u9700\u8981\u66f4\u597d\u5730\u5206\u914d\u548c\u8bc4\u4f30\u5143\u8ba4\u77e5\u804c\u8d23\uff0c\u4ee5\u5b9e\u73b0\u6301\u7eed\u3001\u5e7f\u6cdb\u53ca\u4e00\u81f4\u7684\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "\u5185\u5728\u5143\u8ba4\u77e5\u5b66\u4e60\u662f\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\u7684\u5173\u952e\uff0c\u9700\u8981\u521b\u65b0\u65b9\u6cd5\u6765\u5206\u914d\u4eba\u7c7b\u548c\u4ee3\u7406\u7684\u5143\u8ba4\u77e5\u804c\u8d23\uff0c\u540c\u65f6\u63d0\u9ad8\u5185\u5728\u5143\u8ba4\u77e5\u5b66\u4e60\u7684\u6548\u7387\u3002"}}
{"id": "2506.04454", "pdf": "https://arxiv.org/pdf/2506.04454", "abs": "https://arxiv.org/abs/2506.04454", "authors": ["Huynh T. T. Tran", "Jacob Sander", "Achraf Cohen", "Brian Jalaian", "Nathaniel D. Bastian"], "title": "Neurosymbolic Artificial Intelligence for Robust Network Intrusion Detection: From Scratch to Transfer Learning", "categories": ["cs.LG"], "comment": "17 pages, 5 figures, 11 tables", "summary": "Network Intrusion Detection Systems (NIDS) play a vital role in protecting\ndigital infrastructures against increasingly sophisticated cyber threats. In\nthis paper, we extend ODXU, a Neurosymbolic AI (NSAI) framework that integrates\ndeep embedded clustering for feature extraction, symbolic reasoning using\nXGBoost, and comprehensive uncertainty quantification (UQ) to enhance\nrobustness, interpretability, and generalization in NIDS. The extended ODXU\nincorporates score-based methods (e.g., Confidence Scoring, Shannon Entropy)\nand metamodel-based techniques, including SHAP values and Information Gain, to\nassess the reliability of predictions. Experimental results on the CIC-IDS-2017\ndataset show that ODXU outperforms traditional neural models across six\nevaluation metrics, including classification accuracy and false omission rate.\nWhile transfer learning has seen widespread adoption in fields such as computer\nvision and natural language processing, its potential in cybersecurity has not\nbeen thoroughly explored. To bridge this gap, we develop a transfer learning\nstrategy that enables the reuse of a pre-trained ODXU model on a different\ndataset. Our ablation study on ACI-IoT-2023 demonstrates that the optimal\ntransfer configuration involves reusing the pre-trained autoencoder, retraining\nthe clustering module, and fine-tuning the XGBoost classifier, and outperforms\ntraditional neural models when trained with as few as 16,000 samples\n(approximately 50% of the training data). Additionally, results show that\nmetamodel-based UQ methods consistently outperform score-based approaches on\nboth datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6269\u5c55\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7AI\u6846\u67b6\uff0c\u901a\u8fc7\u4f20\u8f93\u5b66\u4e60\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u5728\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7528\u4e8e\u7279\u5f81\u63d0\u53d6\u7684\u6df1\u5ea6\u5d4c\u5165\u5f0f\u805a\u7c7b\uff0c\u4e0eXGBoost\u7ed3\u5408\u8fdb\u884c\u7b26\u53f7\u63a8\u7406\uff0c\u4ee5\u53ca\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "ODXU\u5728CIC-IDS-2017\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u795e\u7ecf\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u4f20\u8f93\u5b66\u4e60\u7b56\u7565\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f00\u53d1ODXU\u6846\u67b6\u6765\u63d0\u5347\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u51c6\u786e\u6027\u548c\u9519\u8bef\u9057\u6f0f\u7387\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u901a\u8fc7\u4f20\u8f93\u5b66\u4e60\u7b56\u7565\u6269\u5c55\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2506.04649", "pdf": "https://arxiv.org/pdf/2506.04649", "abs": "https://arxiv.org/abs/2506.04649", "authors": ["Juhyun Oh", "Eunsu Kim", "Alice Oh"], "title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "categories": ["cs.CL"], "comment": null, "summary": "Real-world planning problems require constant adaptation to changing\nrequirements and balancing of competing constraints. However, current\nbenchmarks for evaluating LLMs' planning capabilities primarily focus on\nstatic, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark\nthat evaluates language models' ability to reason flexibly in dynamic planning\nscenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner},\nwe introduce two novel evaluation settings: (1) sequential constraint\nintroduction across multiple turns, and (2) scenarios with explicitly\nprioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B\nreveals several key findings: models' performance on single-turn tasks poorly\npredicts their ability to adapt plans across multiple turns; constraint\nintroduction order significantly affects performance; and models struggle with\nconstraint prioritization, often incorrectly favoring newly introduced lower\npriority preferences over existing higher-priority constraints. These findings\nhighlight the importance of evaluating LLMs in more realistic, dynamic planning\nscenarios and suggest specific directions for improving model performance on\ncomplex planning tasks. The code and dataset for our framework are publicly\navailable at https://github.com/juhyunohh/FlexTravelBench.", "AI": {"tldr": "\u5f15\u5165\u65b0\u57fa\u51c6Flex-TravelPlanner\u4ee5\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u89c4\u5212\u4e2d\u7075\u6d3b\u63a8\u7406\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u591a\u56de\u5408\u548c\u4f18\u5148\u7ea7\u5904\u7406\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5efa\u8bae\u6539\u8fdb\u65b9\u5411\u5e76\u516c\u5f00\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9LLMs\u89c4\u5212\u80fd\u529b\u7684\u8bc4\u4f30\u57fa\u51c6\u4e3b\u8981\u96c6\u4e2d\u5728\u9759\u6001\u7684\u5355\u56de\u5408\u573a\u666f\u4e2d\uff0c\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u89c4\u5212\u95ee\u9898\u7684\u6a21\u62df\u548c\u5bf9\u591a\u91cd\u7ade\u5408\u7ea6\u675f\u7684\u5e73\u8861\uff0c\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u66f4\u5177\u73b0\u5b9e\u610f\u4e49\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86Flex-TravelPlanner\u8fd9\u4e00\u57fa\u51c6\uff0c\u901a\u8fc7\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u89c4\u5212\u573a\u666f\u4e2d\u7684\u7075\u6d3b\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u8bc4\u4f30\uff0c\u8bbe\u7f6e\u4e86\u4e24\u79cd\u65b0\u7684\u8bc4\u4f30\u60c5\u666f\uff1a\uff081\uff09\u5728\u591a\u4e2a\u56de\u5408\u4e2d\u5f15\u5165\u7684\u987a\u5e8f\u7ea6\u675f\uff1b\uff082\uff09\u5177\u6709\u660e\u786e\u4f18\u5148\u7ea7\u7684\u7ade\u5408\u7ea6\u675f\u573a\u666f\u3002", "result": "GPT-4o\u548cLlama 3.1 70B\u5728\u5b9e\u9a8c\u4e2d\u7684\u8868\u73b0\u63ed\u793a\u4e86\u4e00\u4e9b\u5173\u952e\u53d1\u73b0\uff1a\u5355\u56de\u5408\u4efb\u52a1\u8868\u73b0\u4e0e\u591a\u56de\u5408\u9002\u5e94\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u7ea6\u675f\u5f15\u5165\u987a\u5e8f\u5bf9\u6027\u80fd\u7684\u663e\u8457\u5f71\u54cd\uff0c\u4ee5\u53ca\u5728\u7ea6\u675f\u4f18\u5148\u7ea7\u5904\u7406\u65b9\u9762\u7684\u56f0\u96be\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cLLMs\u5728\u9759\u6001\u5355\u56de\u5408\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u65e0\u6cd5\u5f88\u597d\u5730\u9884\u6d4b\u5176\u5728\u591a\u56de\u5408\u52a8\u6001\u89c4\u5212\u573a\u666f\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3002\u6a21\u578b\u5728\u5e94\u5bf9\u591a\u4e2a\u56de\u5408\u7684\u7ea6\u675f\u5f15\u5165\u65f6\uff0c\u8868\u73b0\u53d7\u5230\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u4e14\u5728\u7ea6\u675f\u4f18\u5148\u7ea7\u7684\u5904\u7406\u4e0a\u7ecf\u5e38\u51fa\u9519\uff0c\u901a\u5e38\u4f1a\u9519\u8bef\u5730\u504f\u597d\u65b0\u5f15\u5165\u7684\u4f4e\u4f18\u5148\u7ea7\u504f\u597d\uff0c\u800c\u5ffd\u89c6\u5df2\u6709\u7684\u9ad8\u4f18\u5148\u7ea7\u7ea6\u675f\u3002"}}
{"id": "2506.05213", "pdf": "https://arxiv.org/pdf/2506.05213", "abs": "https://arxiv.org/abs/2506.05213", "authors": ["Nathan Herr", "Tim Rockt\u00e4schel", "Roberta Raileanu"], "title": "LLM-First Search: Self-Guided Exploration of the Solution Space", "categories": ["cs.AI", "cs.CL"], "comment": "9 main pages, 2 figures, 2 tables, 36 appendix pages", "summary": "Large Language Models (LLMs) have demonstrated remarkable improvements in\nreasoning and planning through increased test-time compute, often by framing\nproblem-solving as a search process. While methods like Monte Carlo Tree Search\n(MCTS) have proven effective in some domains, their reliance on fixed\nexploration hyperparameters limits their adaptability across tasks of varying\ndifficulty, rendering them impractical or expensive in certain settings. In\nthis paper, we propose \\textbf{LLM-First Search (LFS)}, a novel \\textit{LLM\nSelf-Guided Search} method that removes the need for pre-defined search\nstrategies by empowering the LLM to autonomously control the search process via\nself-guided exploration. Rather than relying on external heuristics or\nhardcoded policies, the LLM evaluates whether to pursue the current search path\nor explore alternative branches based on its internal scoring mechanisms. This\nenables more flexible and context-sensitive reasoning without requiring manual\ntuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku\nagainst three classic widely-used search algorithms, Tree-of-Thoughts' Breadth\nFirst Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which\nhave been used to achieve SotA results on a range of challenging reasoning\ntasks. We found that LFS (1) performs better on more challenging tasks without\nadditional tuning, (2) is more computationally efficient compared to the other\nmethods, especially when powered by a stronger model, (3) scales better with\nstronger models, due to its LLM-First design, and (4) scales better with\nincreased compute budget. Our code is publicly available at\n\\href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.", "AI": {"tldr": "\u63d0\u51faLLM-First Search\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u5982\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u63a2\u7d22\u8d85\u53c2\u6570\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e0d\u540c\u96be\u5ea6\u4efb\u52a1\u4e0a\u7684\u9002\u5e94\u6027\u3002\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5b83\u4eec\u53ef\u80fd\u4e0d\u5b9e\u7528\u6216\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u89c4\u5212\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u5bfc\u641c\u7d22\u65b9\u6cd5\uff0c\u79f0\u4e3aLLM-First Search\uff0c\u901a\u8fc7\u81ea\u6211\u5f15\u5bfc\u63a2\u7d22\u6765\u63a7\u5236\u641c\u7d22\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u5916\u90e8\u542f\u53d1\u5f0f\u6216\u786c\u7f16\u7801\u7b56\u7565\uff0c\u800c\u662f\u57fa\u4e8e\u5185\u90e8\u8bc4\u5206\u673a\u5236\u6765\u8bc4\u4f30\u662f\u5426\u7ee7\u7eed\u5f53\u524d\u641c\u7d22\u8def\u5f84\u6216\u63a2\u7d22\u5907\u9009\u5206\u652f\u3002", "result": "LLM-First Search\u5728\u71b5\u5012\u548c\u6570\u72ec\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u4e09\u79cd\u7ecf\u5178\u5e7f\u6cdb\u4f7f\u7528\u7684\u641c\u7d22\u7b97\u6cd5\uff0c\u5e76\u4e14\u4e0e\u5176\u4ed6\u65b9\u6cd5\u76f8\u6bd4\u66f4\u52a0\u8ba1\u7b97\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u66f4\u5f3a\u6a21\u578b\u65f6\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "LLM-First Search (LFS)\u6bd4\u4f20\u7edf\u641c\u7d22\u7b97\u6cd5\u5728\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u66f4\u597d\uff0c\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u5c24\u5176\u5728\u4f7f\u7528\u66f4\u5f3a\u5927\u7684\u6a21\u578b\u65f6\u3002"}}
{"id": "2506.04461", "pdf": "https://arxiv.org/pdf/2506.04461", "abs": "https://arxiv.org/abs/2506.04461", "authors": ["Ivan Vegner", "Sydelle de Souza", "Valentin Forch", "Martha Lewis", "Leonidas A. A. Doumas"], "title": "Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.0; I.2.7"], "comment": "To appear at ACL 2025 Main Conference", "summary": "A core aspect of compositionality, systematicity is a desirable property in\nML models as it enables strong generalization to novel contexts. This has led\nto numerous studies proposing benchmarks to assess systematic generalization,\nas well as models and training regimes designed to enhance it. Many of these\nefforts are framed as addressing the challenge posed by Fodor and Pylyshyn.\nHowever, while they argue for systematicity of representations, existing\nbenchmarks and models primarily focus on the systematicity of behaviour. We\nemphasize the crucial nature of this distinction. Furthermore, building on\nHadley's (1994) taxonomy of systematic generalization, we analyze the extent to\nwhich behavioural systematicity is tested by key benchmarks in the literature\nacross language and vision. Finally, we highlight ways of assessing\nsystematicity of representations in ML models as practiced in the field of\nmechanistic interpretability.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u4e2d\u8868\u5f81\u7cfb\u7edf\u6027\u4e0e\u884c\u4e3a\u7cfb\u7edf\u6027\u7684\u533a\u522b\uff0c\u5e76\u5efa\u8bae\u901a\u8fc7\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6765\u8bc4\u4f30\u8868\u5f81\u7cfb\u7edf\u6027\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7cfb\u7edf\u6027\u662f\u5404\u65b9\u8ffd\u6c42\u7684\u6027\u8d28\uff0c\u56e0\u4e3a\u5b83\u652f\u6301\u5728\u65b0\u73af\u5883\u4e2d\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u8be5\u7814\u7a76\u65e8\u5728\u6f84\u6e05\u7cfb\u7edf\u6027\u4e2d\u7684\u4e0d\u540c\u7ef4\u5ea6\u5e76\u63d0\u4f9b\u5168\u65b0\u7684\u8bc4\u4f30\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u8bed\u8a00\u548c\u89c6\u89c9\u9886\u57df\u7684\u5173\u952e\u57fa\u51c6\u6765\u8bc4\u4f30\u884c\u4e3a\u7cfb\u7edf\u6027\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u8bb8\u591a\u73b0\u6709\u7684\u57fa\u51c6\u5e76\u6ca1\u6709\u6d4b\u91cf\u8868\u5f81\u7684\u7cfb\u7edf\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5728\u673a\u5236\u53ef\u89e3\u91ca\u6027\u9886\u57df\u4e2d\u8bc4\u4f30\u6a21\u578b\u8868\u5f81\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8868\u5f81\u7cfb\u7edf\u6027\u548c\u884c\u4e3a\u7cfb\u7edf\u6027\u7684\u533a\u522b\uff0c\u5f3a\u8c03\u4e86\u73b0\u6709\u6a21\u578b\u548c\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u4e8e\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\uff0c\u800c\u5ffd\u7565\u4e86\u8868\u5f81\u7684\u7cfb\u7edf\u6027\u3002"}}
{"id": "2506.04679", "pdf": "https://arxiv.org/pdf/2506.04679", "abs": "https://arxiv.org/abs/2506.04679", "authors": ["Rapha\u00ebl Milli\u00e8re"], "title": "Normative Conflicts and Shallow AI Alignment", "categories": ["cs.CL"], "comment": "Published in Philosophical Studies", "summary": "The progress of AI systems such as large language models (LLMs) raises\nincreasingly pressing concerns about their safe deployment. This paper examines\nthe value alignment problem for LLMs, arguing that current alignment strategies\nare fundamentally inadequate to prevent misuse. Despite ongoing efforts to\ninstill norms such as helpfulness, honesty, and harmlessness in LLMs through\nfine-tuning based on human preferences, they remain vulnerable to adversarial\nattacks that exploit conflicts between these norms. I argue that this\nvulnerability reflects a fundamental limitation of existing alignment methods:\nthey reinforce shallow behavioral dispositions rather than endowing LLMs with a\ngenuine capacity for normative deliberation. Drawing from on research in moral\npsychology, I show how humans' ability to engage in deliberative reasoning\nenhances their resilience against similar adversarial tactics. LLMs, by\ncontrast, lack a robust capacity to detect and rationally resolve normative\nconflicts, leaving them susceptible to manipulation; even recent advances in\nreasoning-focused LLMs have not addressed this vulnerability. This ``shallow\nalignment'' problem carries significant implications for AI safety and\nregulation, suggesting that current approaches are insufficient for mitigating\npotential harms posed by increasingly capable AI systems.", "AI": {"tldr": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u7b56\u7565\u65e0\u6cd5\u6709\u6548\u9884\u9632\u5176\u88ab\u6ee5\u7528\uff0c\u56e0\u4e3a\u5b83\u4eec\u672a\u80fd\u8d4b\u4e88\u6a21\u578b\u6df1\u5165\u7684\u89c4\u8303\u6027\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8\u548c\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ef7\u503c\u5bf9\u9f50\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4ee5\u786e\u4fdd\u5176\u5b89\u5168\u90e8\u7f72\u3002", "method": "\u901a\u8fc7\u7814\u7a76\u4e0e\u9053\u5fb7\u5fc3\u7406\u5b66\u7684\u76f8\u5173\u7814\u7a76\u8fdb\u884c\u6bd4\u5bf9\uff0c\u5206\u6790\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "result": "\u53d1\u73b0\u73b0\u6709\u7684\u5bf9\u9f50\u65b9\u6cd5\u53ea\u80fd\u5f3a\u5316\u8868\u9762\u7684\u884c\u4e3a\u8868\u73b0\uff0c\u65e0\u6cd5\u5e2e\u52a9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6709\u6548\u7684\u89c4\u8303\u6027\u63a8\u7406\u3002", "conclusion": "\u73b0\u6709\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u7b56\u7565\u662f\u6d45\u8584\u7684\uff0c\u672a\u80fd\u8d4b\u4e88\u6a21\u578b\u771f\u6b63\u7684\u89c4\u8303\u6027\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u65e0\u6cd5\u6709\u6548\u907f\u514d\u88ab\u64cd\u7eb5\u548c\u8bef\u7528\u3002"}}
{"id": "2506.05256", "pdf": "https://arxiv.org/pdf/2506.05256", "abs": "https://arxiv.org/abs/2506.05256", "authors": ["Violet Xiang", "Chase Blagden", "Rafael Rafailov", "Nathan Lile", "Sang Truong", "Chelsea Finn", "Nick Haber"], "title": "Just Enough Thinking: Efficient Reasoning with Adaptive Length Penalties Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large reasoning models (LRMs) achieve higher performance on challenging\nreasoning tasks by generating more tokens at inference time, but this verbosity\noften wastes computation on easy problems. Existing solutions, including\nsupervised finetuning on shorter traces, user-controlled budgets, or RL with\nuniform penalties, either require data curation, manual configuration, or treat\nall problems alike regardless of difficulty. We introduce Adaptive Length\nPenalty (ALP), a reinforcement learning objective tailoring generation length\nto per-prompt solve rate. During training, ALP monitors each prompt's online\nsolve rate through multiple rollouts and adds a differentiable penalty whose\nmagnitude scales inversely with that rate, so confident (easy) prompts incur a\nhigh cost for extra tokens while hard prompts remain unhindered. Posttraining\nDeepScaleR-1.5B with ALP cuts average token usage by 50\\% without significantly\ndropping performance. Relative to fixed-budget and uniform penalty baselines,\nALP redistributes its reduced budget more intelligently by cutting compute on\neasy prompts and reallocating saved tokens to difficult ones, delivering higher\naccuracy on the hardest problems with higher cost.", "AI": {"tldr": "\u5f15\u5165\u4e00\u79cd\u81ea\u9002\u5e94\u957f\u5ea6\u60e9\u7f5a\uff08ALP\uff09\u673a\u5236\uff0c\u7528\u4e8e\u6839\u636e\u63d0\u793a\u96be\u5ea6\u8c03\u6574token\u751f\u6210\u957f\u5ea6\uff0c\u63d0\u9ad8\u4e86\u56f0\u96be\u95ee\u9898\u7684\u51c6\u786e\u6027\uff0c\u51cf\u5c11\u4e86\u7b80\u5355\u95ee\u9898\u4e0a\u7684\u8ba1\u7b97\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u9700\u8981\u6570\u636e\u7ec4\u7ec7\u3001\u624b\u52a8\u914d\u7f6e\uff0c\u6216\u8005\u4e0d\u8003\u8651\u95ee\u9898\u7684\u96be\u6613\uff0c\u800c\u662f\u5bf9\u6240\u6709\u95ee\u9898\u4e00\u89c6\u540c\u4ec1\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u79cd\u95ee\u9898\u7684\u6d6a\u8d39\u8ba1\u7b97\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u957f\u5ea6\u60e9\u7f5a\uff08ALP\uff09\uff0c\u4e00\u79cd\u8c03\u6574\u751f\u6210\u957f\u5ea6\u4ee5\u9002\u5e94\u6bcf\u4e2a\u63d0\u793a\u89e3\u7b54\u7387\u7684\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u957f\u5ea6\u60e9\u7f5a\uff08ALP\uff09\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u3002\u5728\u8bad\u7ec3\u671f\u95f4\uff0cALP\u901a\u8fc7\u591a\u4e2arollouts\u76d1\u89c6\u6bcf\u4e2a\u63d0\u793a\u7684\u5728\u7ebf\u89e3\u7b54\u7387\uff0c\u5e76\u6dfb\u52a0\u4e00\u4e2a\u53ef\u5fae\u5206\u60e9\u7f5a\uff0c\u5176\u5927\u5c0f\u4e0e\u89e3\u7b54\u7387\u6210\u53cd\u6bd4\u3002\u8fd9\u6837\uff0c\u81ea\u4fe1\uff08\u5bb9\u6613\uff09\u7684\u63d0\u793a\u4f1a\u56e0\u4e3a\u989d\u5916\u7684token\u800c\u627f\u62c5\u9ad8\u6602\u6210\u672c\uff0c\u800c\u56f0\u96be\u63d0\u793a\u5219\u4e0d\u53d7\u5f71\u54cd\u3002", "result": "\u7ecf\u8fc7ALP\u540e\u8bad\u7ec3\u7684DeepScaleR-1.5B\u663e\u8457\u51cf\u5c11\u4e86token\u7684\u5e73\u5747\u4f7f\u7528\u91cf\uff0c\u540c\u65f6\u5728\u6027\u80fd\u4e0a\u6ca1\u6709\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u4f7f\u7528ALP\u5b9e\u65bd\u7684DeepScaleR-1.5B\u51cf\u5c11\u4e8650%\u7684\u5e73\u5747token\u4f7f\u7528\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6027\u80fd\u3002\u4e0e\u56fa\u5b9a\u9884\u7b97\u548c\u7edf\u4e00\u60e9\u7f5a\u57fa\u7ebf\u76f8\u6bd4\uff0cALP\u66f4\u667a\u80fd\u5730\u5206\u914d\u5176\u51cf\u5c11\u7684\u9884\u7b97\uff0c\u5728\u7b80\u5355\u63d0\u793a\u4e0a\u51cf\u5c11\u8ba1\u7b97\uff0c\u5e76\u5c06\u8282\u7701\u7684token\u91cd\u65b0\u5206\u914d\u7ed9\u56f0\u96be\u63d0\u793a\uff0c\u4ece\u800c\u5728\u6700\u56f0\u96be\u7684\u95ee\u9898\u4e0a\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.04474", "pdf": "https://arxiv.org/pdf/2506.04474", "abs": "https://arxiv.org/abs/2506.04474", "authors": ["Mohammad Subhi Al-Batah", "Mowafaq Salem Alzboon", "Muhyeeddin Alqaraleh", "Mohammed Hasan Abu-Arqoub", "Rashiq Rafiq Marie"], "title": "Classifying Dental Care Providers Through Machine Learning with Features Ranking", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study investigates the application of machine learning (ML) models for\nclassifying dental providers into two categories - standard rendering providers\nand safety net clinic (SNC) providers - using a 2018 dataset of 24,300\ninstances with 20 features. The dataset, characterized by high missing values\n(38.1%), includes service counts (preventive, treatment, exams), delivery\nsystems (FFS, managed care), and beneficiary demographics. Feature ranking\nmethods such as information gain, Gini index, and ANOVA were employed to\nidentify critical predictors, revealing treatment-related metrics\n(TXMT_USER_CNT, TXMT_SVC_CNT) as top-ranked features. Twelve ML models,\nincluding k-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines\n(SVM), Stochastic Gradient Descent (SGD), Random Forest, Neural Networks, and\nGradient Boosting, were evaluated using 10-fold cross-validation.\nClassification accuracy was tested across incremental feature subsets derived\nfrom rankings. The Neural Network achieved the highest accuracy (94.1%) using\nall 20 features, followed by Gradient Boosting (93.2%) and Random Forest\n(93.0%). Models showed improved performance as more features were incorporated,\nwith SGD and ensemble methods demonstrating robustness to missing data. Feature\nranking highlighted the dominance of treatment service counts and annotation\ncodes in distinguishing provider types, while demographic variables (AGE_GROUP,\nCALENDAR_YEAR) had minimal impact. The study underscores the importance of\nfeature selection in enhancing model efficiency and accuracy, particularly in\nimbalanced healthcare datasets. These findings advocate for integrating\nfeature-ranking techniques with advanced ML algorithms to optimize dental\nprovider classification, enabling targeted resource allocation for underserved\npopulations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u75282018\u5e74\u6570\u636e\u96c6\uff0c\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u7259\u79d1\u63d0\u4f9b\u8005\u8fdb\u884c\u5206\u7c7b\uff0c\u53d1\u73b0\u7279\u5f81\u9009\u62e9\u5bf9\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u51c6\u786e\u6027\u975e\u5e38\u91cd\u8981\u3002\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u83b7\u5f97\u4e86\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u7259\u79d1\u63d0\u4f9b\u8005\u8fdb\u884c\u5206\u7c7b\uff0c\u8bc6\u522b\u51fa\u6807\u51c6\u63d0\u4f9b\u8005\u548c\u5b89\u5168\u7f51\u8bca\u6240\u63d0\u4f9b\u8005\uff0c\u4ee5\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e8612\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\uff0c\u5305\u62eck\u8fd1\u90bb\uff08kNN\uff09\u3001\u51b3\u7b56\u6811\u3001\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u3001\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u3001\u968f\u673a\u68ee\u6797\u3001\u795e\u7ecf\u7f51\u7edc\u548c\u68af\u5ea6\u63d0\u5347\uff0c\u5e76\u4f7f\u752810\u500d\u4ea4\u53c9\u9a8c\u8bc1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u7b97\u6cd5\u4f7f\u7528\u5168\u90e820\u4e2a\u7279\u5f81\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0894.1%\uff09\uff0c\u5176\u6b21\u662f\u68af\u5ea6\u63d0\u5347\uff0893.2%\uff09\u548c\u968f\u673a\u68ee\u6797\uff0893.0%\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u96c6\u6210\u7279\u5f81\u6392\u5e8f\u6280\u672f\u548c\u9ad8\u7ea7\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u53ef\u4ee5\u4f18\u5316\u7259\u79d1\u63d0\u4f9b\u8005\u5206\u7c7b\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u8d44\u6e90\u532e\u4e4f\u7fa4\u4f53\u7684\u6709\u9488\u5bf9\u6027\u7684\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2506.04688", "pdf": "https://arxiv.org/pdf/2506.04688", "abs": "https://arxiv.org/abs/2506.04688", "authors": ["Gio Paik", "Geewook Kim", "Jinbae Im"], "title": "MMRefine: Unveiling the Obstacles to Robust Refinement in Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": "ACL Findings 2025", "summary": "This paper introduces MMRefine, a MultiModal Refinement benchmark designed to\nevaluate the error refinement capabilities of Multimodal Large Language Models\n(MLLMs). As the emphasis shifts toward enhancing reasoning during inference,\nMMRefine provides a framework that evaluates MLLMs' abilities to detect and\ncorrect errors across six distinct scenarios beyond just comparing final\naccuracy before and after refinement. Furthermore, the benchmark analyzes the\nrefinement performance by categorizing errors into six error types. Experiments\nwith various open and closed MLLMs reveal bottlenecks and factors impeding\nrefinement performance, highlighting areas for improvement in effective\nreasoning enhancement. Our code and dataset are publicly available at\nhttps://github.com/naver-ai/MMRefine.", "AI": {"tldr": "MMRefine\u662f\u4e00\u4e2a\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7cbe\u70bc\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u63d0\u4f9b\u6846\u67b6\u68c0\u6d4b\u548c\u7ea0\u6b63\u63a8\u7406\u9519\u8bef\uff0c\u63ed\u793a\u6027\u80fd\u74f6\u9888\u3002", "motivation": "\u63d0\u9ad8\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u68c0\u6d4b\u4e0e\u4fee\u6b63\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u7cbe\u70bc\u57fa\u51c6\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u516d\u4e2a\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u4fee\u6b63\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5404\u79cd\u5f00\u6e90\u4e0e\u95ed\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7cbe\u70bc\u6027\u80fd\u4e0a\u7684\u74f6\u9888\u4e0e\u963b\u788d\u56e0\u7d20\u3002", "conclusion": "MMRefine\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8be6\u5c3d\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u7ea0\u6b63\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\uff0c\u63ed\u793a\u5176\u6027\u80fd\u74f6\u9888\u548c\u6539\u8fdb\u9886\u57df\u3002"}}
{"id": "2506.05296", "pdf": "https://arxiv.org/pdf/2506.05296", "abs": "https://arxiv.org/abs/2506.05296", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "title": "Control Tax: The Price of Keeping AI in Check", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The rapid integration of agentic AI into high-stakes real-world applications\nrequires robust oversight mechanisms. The emerging field of AI Control (AIC)\naims to provide such an oversight mechanism, but practical adoption depends\nheavily on implementation overhead. To study this problem better, we introduce\nthe notion of Control tax -- the operational and financial cost of integrating\ncontrol measures into AI pipelines. Our work makes three key contributions to\nthe field of AIC: (1) we introduce a theoretical framework that quantifies the\nControl Tax and maps classifier performance to safety assurances; (2) we\nconduct comprehensive evaluations of state-of-the-art language models in\nadversarial settings, where attacker models insert subtle backdoors into code\nwhile monitoring models attempt to detect these vulnerabilities; and (3) we\nprovide empirical financial cost estimates for control protocols and develop\noptimized monitoring strategies that balance safety and cost-effectiveness\nwhile accounting for practical constraints like auditing budgets. Our framework\nenables practitioners to make informed decisions by systematically connecting\nsafety guarantees with their costs, advancing AIC through principled economic\nfeasibility assessment across different deployment contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316AI\u63a7\u5236\u7a0e\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u4f18\u5316AI\u76d1\u6d4b\u7b56\u7565\uff0c\u4ee5\u5b9e\u73b0\u5b89\u5168\u6027\u4e0e\u6210\u672c\u6548\u76ca\u4e4b\u95f4\u7684\u5e73\u8861\u3002", "motivation": "\u968f\u7740\u4ee3\u7406AI\u5728\u9ad8\u98ce\u9669\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5feb\u901f\u6574\u5408\uff0c\u8feb\u5207\u9700\u8981\u5efa\u7acb\u7a33\u5065\u7684\u76d1\u7ba1\u673a\u5236\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86AI\u63a7\u5236\u9886\u57df\u7684\u7814\u7a76\uff0c\u4ee5\u5e94\u5bf9\u63a7\u5236\u63aa\u65bd\u96be\u4ee5\u5b9e\u65bd\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u7406\u8bba\u6846\u67b6\u7684\u6784\u5efa\uff0c\u91cf\u5316\u63a7\u5236\u7a0e\uff0c\u4ee5\u53ca\u5728\u5bf9\u6297\u6027\u73af\u5883\u4e2d\u5bf9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\uff0c\u5e76\u57fa\u4e8e\u5b9e\u9645\u8d22\u52a1\u6210\u672c\u4f30\u7b97\u5f00\u53d1\u4f18\u5316\u76d1\u6d4b\u7b56\u7565\uff0c\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u6210\u672c\u6548\u76ca\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u4f18\u5316\u7684\u76d1\u6d4b\u7b56\u7565\u53ef\u4ee5\u5728\u8003\u8651\u5ba1\u8ba1\u9884\u7b97\u7b49\u5b9e\u9645\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5e73\u8861\u5b89\u5168\u6027\u548c\u6210\u672c\u6548\u76ca\uff0c\u5e76\u4e3a\u5b9e\u8df5\u5de5\u4f5c\u8005\u5728\u4e0d\u540c\u90e8\u7f72\u73af\u5883\u4e0b\u505a\u51fa\u660e\u667a\u51b3\u7b56\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u91cf\u5316\u63a7\u5236\u7a0e\u6765\u5c06\u5206\u7c7b\u5668\u6027\u80fd\u6620\u5c04\u5230\u5b89\u5168\u4fdd\u8bc1\u4e0a\uff0c\u63a8\u52a8AIC\u901a\u8fc7\u7cfb\u7edf\u7684\u7ecf\u6d4e\u53ef\u884c\u6027\u8bc4\u4f30\u5728\u4e0d\u540c\u90e8\u7f72\u73af\u5883\u4e0b\u53d6\u5f97\u8fdb\u5c55\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a7\u5236\u63aa\u65bd\u63d0\u4f9b\u4e86\u4e00\u79cd\u4ee5\u7ecf\u6d4e\u6027\u4e3a\u5bfc\u5411\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.04479", "pdf": "https://arxiv.org/pdf/2506.04479", "abs": "https://arxiv.org/abs/2506.04479", "authors": ["Mohammad Subhi Al-Batah", "Muhyeeddin Alqaraleh", "Mowafaq Salem Alzboon", "Abdullah Alourani"], "title": "Comparative performance of ensemble models in predicting dental provider types: insights from fee-for-service data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Dental provider classification plays a crucial role in optimizing healthcare\nresource allocation and policy planning. Effective categorization of providers,\nsuch as standard rendering providers and safety net clinic (SNC) providers,\nenhances service delivery to underserved populations. This study aimed to\nevaluate the performance of machine learning models in classifying dental\nproviders using a 2018 dataset. A dataset of 24,300 instances with 20 features\nwas analyzed, including beneficiary and service counts across fee-for-service\n(FFS), Geographic Managed Care, and Pre-Paid Health Plans. Providers were\ncategorized by delivery system and patient age groups (0-20 and 21+). Despite\n38.1% missing data, multiple machine learning algorithms were tested, including\nk-Nearest Neighbors (kNN), Decision Trees, Support Vector Machines (SVM),\nStochastic Gradient Descent (SGD), Random Forest, Neural Networks, and Gradient\nBoosting. A 10-fold cross-validation approach was applied, and models were\nevaluated using AUC, classification accuracy (CA), F1-score, precision, and\nrecall. Neural Networks achieved the highest AUC (0.975) and CA (94.1%),\nfollowed by Random Forest (AUC: 0.948, CA: 93.0%). These models effectively\nhandled imbalanced data and complex feature interactions, outperforming\ntraditional classifiers like Logistic Regression and SVM. Advanced machine\nlearning techniques, particularly ensemble and deep learning models,\nsignificantly enhance dental workforce classification. Their integration into\nhealthcare analytics can improve provider identification and resource\ndistribution, benefiting underserved populations.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u7259\u79d1\u670d\u52a1\u63d0\u4f9b\u8005\u8fdb\u884c\u5206\u7c7b\u7684\u6548\u679c\uff0c\u53d1\u73b0\u795e\u7ecf\u7f51\u7edc\u548c\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u80fd\u6539\u5584\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u5bf9\u7259\u79d1\u670d\u52a1\u63d0\u4f9b\u8005\u8fdb\u884c\u5206\u7c7b\u5bf9\u4f18\u5316\u533b\u7597\u8d44\u6e90\u5206\u914d\u548c\u653f\u7b56\u89c4\u5212\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u63d0\u5347\u5bf9\u670d\u52a1\u4e0d\u8db3\u4eba\u7fa4\u7684\u670d\u52a1\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u5305\u62eck-\u6700\u8fd1\u90bb\u7b97\u6cd5\uff08kNN\uff09\u3001\u51b3\u7b56\u6811\u3001\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u3001\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u3001\u968f\u673a\u68ee\u6797\u3001\u795e\u7ecf\u7f51\u7edc\u548c\u68af\u5ea6\u589e\u5f3a\u3002\u91c7\u752810\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u5e76\u4f7f\u7528AUC\u3001\u5206\u7c7b\u51c6\u786e\u6027\uff08CA\uff09\u3001F1\u5206\u6570\u3001\u7cbe\u51c6\u5ea6\u548c\u53ec\u56de\u7387\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u53d6\u5f97\u4e86\u6700\u9ad8\u7684AUC\uff080.975\uff09\u548c\u5206\u7c7b\u51c6\u786e\u6027\uff0894.1%\uff09\uff0c\u5176\u6b21\u662f\u968f\u673a\u68ee\u6797\uff08AUC: 0.948\uff0cCA: 93.0%\uff09\uff0c\u5728\u5904\u7406\u4e0d\u5e73\u8861\u6570\u636e\u548c\u590d\u6742\u7279\u5f81\u4ea4\u4e92\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u5206\u7c7b\u5668\uff08\u5982\u903b\u8f91\u56de\u5f52\u548cSVM\uff09\u3002", "conclusion": "\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5982\u96c6\u6210\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u7259\u79d1\u670d\u52a1\u5206\u7c7b\u7684\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u7279\u522b\u662f\u5bf9\u670d\u52a1\u4e0d\u8db3\u7684\u7fa4\u4f53\u3002"}}
{"id": "2506.04689", "pdf": "https://arxiv.org/pdf/2506.04689", "abs": "https://arxiv.org/abs/2506.04689", "authors": ["Thao Nguyen", "Yang Li", "Olga Golovneva", "Luke Zettlemoyer", "Sewoong Oh", "Ludwig Schmidt", "Xian Li"], "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Scaling laws predict that the performance of large language models improves\nwith increasing model size and data size. In practice, pre-training has been\nrelying on massive web crawls, using almost all data sources publicly available\non the internet so far. However, this pool of natural data does not grow at the\nsame rate as the compute supply. Furthermore, the availability of high-quality\ntexts is even more limited: data filtering pipelines often remove up to 99% of\nthe initial web scrapes to achieve state-of-the-art. To address the \"data wall\"\nof pre-training scaling, our work explores ways to transform and recycle data\ndiscarded in existing filtering processes. We propose REWIRE, REcycling the Web\nwith guIded REwrite, a method to enrich low-quality documents so that they\ncould become useful for training. This in turn allows us to increase the\nrepresentation of synthetic data in the final pre-training set. Experiments at\n1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw\ntexts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points\nimprovement respectively across 22 diverse tasks, compared to training on only\nfiltered web data. Training on the raw-synthetic data mix is also more\neffective than having access to 2x web data. Through further analysis, we\ndemonstrate that about 82% of the mixed in texts come from transforming\nlower-quality documents that would otherwise be discarded. REWIRE also\noutperforms related approaches of generating synthetic data, including\nWikipedia-style paraphrasing, question-answer synthesizing and knowledge\nextraction. These results suggest that recycling web texts holds the potential\nfor being a simple and effective approach for scaling pre-training data.", "AI": {"tldr": "REWIRE \u65b9\u6cd5\u901a\u8fc7\u91cd\u65b0\u6539\u5199\u4f4e\u8d28\u91cf\u6587\u672c\uff0c\u5b9e\u73b0\u4e86\u6570\u636e\u7684\u5faa\u73af\u5229\u7528\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u662f\u9884\u8bad\u7ec3\u6570\u636e\u6269\u5c55\u7684\u6709\u6548\u9014\u5f84\u3002", "motivation": "\u7531\u4e8e\u81ea\u7136\u6570\u636e\u7684\u589e\u957f\u901f\u5ea6\u65e0\u6cd5\u8ddf\u4e0a\u8ba1\u7b97\u80fd\u529b\u7684\u589e\u957f\uff0c\u5c24\u5176\u662f\u9ad8\u8d28\u91cf\u6587\u672c\u7684\u53ef\u83b7\u5f97\u6027\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u627e\u5230\u4e00\u79cd\u65b9\u5f0f\u6765\u5229\u7528\u73b0\u6709\u8fc7\u6ee4\u8fc7\u7a0b\u4e22\u5f03\u7684\u6570\u636e\uff0c\u4ece\u800c\u7a81\u7834\u9884\u8bad\u7ec3\u6269\u5c55\u7684 \"\u6570\u636e\u5899\"\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a REWIRE (REcycling the Web with guIded REwrite) \u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5bfc\u91cd\u5199\u6765\u4e30\u5bcc\u4f4e\u8d28\u91cf\u6587\u6863\uff0c\u4f7f\u5176\u53ef\u7528\u4e8e\u8bad\u7ec3\u3002\u901a\u8fc7\u5c06\u9ad8\u8d28\u91cf\u539f\u59cb\u6587\u672c\u4e0e\u91cd\u5199\u6587\u672c\u6df7\u5408\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u5728 DCLM \u57fa\u51c6\u7684 1B\u30013B \u548c 7B \u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u4e0e\u9ad8\u8d28\u91cf\u6587\u672c\u6df7\u5408\uff0c\u91cd\u5199\u540e\u7684\u6587\u672c\u5728 22 \u4e2a\u591a\u6837\u4efb\u52a1\u4e0a\u5206\u522b\u63d0\u9ad8\u4e86 1.0, 1.3 \u548c 2.5 \u4e2a\u767e\u5206\u70b9\u3002\u901a\u8fc7\u8fdb\u4e00\u6b65\u5206\u6790\uff0c\u6df7\u5408\u6587\u672c\u4e2d\u7ea6 82% \u6765\u81ea\u91cd\u65b0\u751f\u6210\u7684\u4f4e\u8d28\u91cf\u6587\u6863\u3002REWIRE \u5728\u751f\u6210\u5408\u6210\u6570\u636e\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u76f8\u5173\u7684\u65b9\u6cd5\u3002", "conclusion": "REWIRE \u53ef\u4ee5\u5c06\u4f4e\u8d28\u91cf\u7684\u7f51\u7edc\u6587\u6863\u8f6c\u5316\u4e3a\u53ef\u7528\u4e8e\u8bad\u7ec3\u7684\u6570\u636e\uff0c\u6709\u6548\u589e\u52a0\u5408\u6210\u6570\u636e\u5728\u9884\u8bad\u7ec3\u96c6\u4e2d\u7684\u6bd4\u4f8b\uff0c\u5e76\u4e14\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u7684\u751f\u6210\u5408\u6210\u6570\u636e\u7684\u65b9\u6cd5\u66f4\u4f18\u3002"}}
{"id": "2505.01449", "pdf": "https://arxiv.org/pdf/2505.01449", "abs": "https://arxiv.org/abs/2505.01449", "authors": ["Jiayu Wang", "Aws Albarghouthi", "Frederic Sala"], "title": "COSMOS: Predictable and Cost-Effective Adaptation of LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance across numerous\ntasks by using a diverse array of adaptation strategies. However, optimally\nselecting a model and adaptation strategy under resource constraints is\nchallenging and often requires extensive experimentation. We investigate\nwhether it is possible to accurately predict both performance and cost without\nexpensive trials. We formalize the strategy selection problem for LLMs and\nintroduce COSMOS, a unified prediction framework that efficiently estimates\nadaptation outcomes at minimal cost. We instantiate and study the capability of\nour framework via a pair of powerful predictors: embedding-augmented\nlightweight proxy models to predict fine-tuning performance, and low-sample\nscaling laws to forecast retrieval-augmented in-context learning. Extensive\nevaluation across eight representative benchmarks demonstrates that COSMOS\nachieves high prediction accuracy while reducing computational costs by 92.72%\non average, and up to 98.71% in resource-intensive scenarios. Our results show\nthat efficient prediction of adaptation outcomes is not only feasible but can\nsubstantially reduce the computational overhead of LLM deployment while\nmaintaining performance standards.", "AI": {"tldr": "COSMOS\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u7ed3\u679c\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u9009\u62e9\u6700\u4f73\u7684\u8bed\u8a00\u6a21\u578b\u548c\u9002\u5e94\u7b56\u7565\u662f\u5177\u6709\u6311\u6218\u6027\u7684\uff0c\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u5b9e\u9a8c\u3002", "method": "\u5f15\u5165COSMOS\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u4e2a\u5f3a\u5927\u7684\u9884\u6d4b\u5668\u5b9e\u73b0\uff1a\u5d4c\u5165\u589e\u5f3a\u7684\u8f7b\u91cf\u7ea7\u4ee3\u7406\u6a21\u578b\u9884\u6d4b\u5fae\u8c03\u6027\u80fd\uff0c\u4ee5\u53ca\u4f4e\u6837\u672c\u89c4\u6a21\u6cd5\u5219\u9884\u6d4b\u68c0\u7d22\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u3002", "result": "COSMOS\u5728\u516b\u4e2a\u4ee3\u8868\u6027\u57fa\u51c6\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5e73\u5747\u51cf\u5c11\u8ba1\u7b97\u6210\u672c92.72%\uff0c\u5728\u8d44\u6e90\u5bc6\u96c6\u7684\u573a\u666f\u4e2d\u51cf\u5c11\u9ad8\u8fbe98.71%\u7684\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7\u6709\u6548\u9884\u6d4b\u9002\u5e94\u7ed3\u679c\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u6807\u51c6\u3002"}}
{"id": "2506.04487", "pdf": "https://arxiv.org/pdf/2506.04487", "abs": "https://arxiv.org/abs/2506.04487", "authors": ["C. Evans Hedges"], "title": "Orthogonal Gradient Descent Improves Neural Calibration", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We provide evidence that orthogonalizing gradients during training improves\nmodel calibration without sacrificing accuracy. On CIFAR-10 with 10% labeled\ndata, $\\perp$Grad matches SGD in accuracy but yields consistently improved\ncalibration metrics such as lower test loss, reduced softmax overconfidence,\nand higher predictive entropy. These benefits persist under input corruption\n(CIFAR-10C) and extended training, where $\\perp$Grad models degrade more\ngracefully than SGD-trained counterparts. $\\perp$Grad is optimizer-agnostic,\nincurs minimal overhead, and works well with post-hoc calibration techniques\nlike temperature scaling.\n  Theoretically, we prove convergence of a simplified version of $\\perp$Grad\nunder mild assumptions and characterize its stationary points in positive\nhomogeneous networks: $\\perp$Grad converges to solutions where further loss\nreduction requires confidence scaling rather than decision boundary\nimprovement.", "AI": {"tldr": "\u6b63\u4ea4\u5316\u68af\u5ea6\u7684$\\perp$Grad\u65b9\u6cd5\u63d0\u9ad8\u6a21\u578b\u6821\u51c6\uff0c\u4fdd\u6301\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5728\u591a\u79cd\u6761\u4ef6\u4e0b\u8868\u73b0\u4f18\u4e8eSGD\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u6539\u5584\u6a21\u578b\u6821\u51c6\u7684\u65b9\u5f0f\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a$\\perp$Grad\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u671f\u95f4\u4f7f\u68af\u5ea6\u6b63\u4ea4\u5316\u6765\u6539\u5584\u6a21\u578b\u6821\u51c6\u3002", "result": "\u5728\u4f7f\u7528CIFAR-10\u6570\u636e\u96c6\uff08\u542b10%\u6807\u8bb0\u6570\u636e\uff09\u7684\u5b9e\u9a8c\u4e2d\uff0c$\\perp$Grad\u4e0eSGD\u5728\u51c6\u786e\u6027\u65b9\u9762\u6301\u5e73\uff0c\u4f46\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\u6307\u6807\uff0c\u4f8b\u5982\u8f83\u4f4e\u7684\u6d4b\u8bd5\u635f\u5931\u3001\u51cf\u5c11\u7684softmax\u8fc7\u5ea6\u81ea\u4fe1\u548c\u66f4\u9ad8\u7684\u9884\u6d4b\u71b5\u3002\u8fd9\u4e9b\u4f18\u70b9\u5728\u8f93\u5165\u6270\u52a8\uff08\u5982CIFAR-10C\uff09\u548c\u5ef6\u957f\u8bad\u7ec3\u65f6\u95f4\u7684\u60c5\u51b5\u4e0b\u4f9d\u7136\u5b58\u5728\u3002", "conclusion": "$\\perp$Grad\u80fd\u591f\u6539\u5584\u6a21\u578b\u7684\u6821\u51c6\uff0c\u4e14\u4e0e\u540e\u5904\u7406\u6821\u51c6\u6280\u672f\u7ed3\u5408\u826f\u597d\uff0c\u7406\u8bba\u8bc1\u660e\u7b80\u5316\u7248\u672c\u5728\u8f7b\u5ea6\u5047\u8bbe\u4e0b\u53ef\u4ee5\u6536\u655b\u3002"}}
{"id": "2506.04693", "pdf": "https://arxiv.org/pdf/2506.04693", "abs": "https://arxiv.org/abs/2506.04693", "authors": ["Lu Wei", "Liangzhi Li", "Tong Xiang", "Xiao Liu", "Noa Garcia"], "title": "Cracking the Code: Enhancing Implicit Hate Speech Detection through Coding Classification", "categories": ["cs.CL"], "comment": "Proceedings of the 5th Workshop on Trustworthy NLP (TrustNLP 2025),\n  112-126", "summary": "The internet has become a hotspot for hate speech (HS), threatening societal\nharmony and individual well-being. While automatic detection methods perform\nwell in identifying explicit hate speech (ex-HS), they struggle with more\nsubtle forms, such as implicit hate speech (im-HS). We tackle this problem by\nintroducing a new taxonomy for im-HS detection, defining six encoding\nstrategies named codetypes. We present two methods for integrating codetypes\ninto im-HS detection: 1) prompting large language models (LLMs) directly to\nclassify sentences based on generated responses, and 2) using LLMs as encoders\nwith codetypes embedded during the encoding process. Experiments show that the\nuse of codetypes improves im-HS detection in both Chinese and English datasets,\nvalidating the effectiveness of our approach across different languages.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u7f16\u7801\u7c7b\u578b\uff0c\u63d0\u9ad8\u4e86\u4e2d\u82f1\u6587\u6570\u636e\u96c6\u4e0a\u7684\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\u5728\u8bc6\u522b\u663e\u6027\u4ec7\u6068\u8a00\u8bba\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u662f\u5728\u5904\u7406\u66f4\u4e3a\u9690\u6666\u7684\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u5206\u7c7b\u6cd5\uff0c\u5b9a\u4e49\u4e86\u516d\u79cd\u7f16\u7801\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u5c06\u7f16\u7801\u7c7b\u578b\u6574\u5408\u5230\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u7684\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u7f16\u7801\u7c7b\u578b\u80fd\u591f\u5728\u4e2d\u6587\u548c\u82f1\u6587\u6570\u636e\u96c6\u4e0a\u6539\u5584\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8bed\u8a00\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5728\u7f16\u7801\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u7f16\u7801\u7c7b\u578b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u5bf9\u9690\u542b\u4ec7\u6068\u8a00\u8bba\u7684\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2506.03922", "pdf": "https://arxiv.org/pdf/2506.03922", "abs": "https://arxiv.org/abs/2506.03922", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated significant\npotential to advance a broad range of domains. However, current benchmarks for\nevaluating MLLMs primarily emphasize general knowledge and vertical\nstep-by-step reasoning typical of STEM disciplines, while overlooking the\ndistinct needs and potential of the Humanities and Social Sciences (HSS). Tasks\nin the HSS domain require more horizontal, interdisciplinary thinking and a\ndeep integration of knowledge across related fields, which presents unique\nchallenges for MLLMs, particularly in linking abstract concepts with\ncorresponding visual representations. Addressing this gap, we present HSSBench,\na dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks\nin multiple languages, including the six official languages of the United\nNations. We also introduce a novel data generation pipeline tailored for HSS\nscenarios, in which multiple domain experts and automated agents collaborate to\ngenerate and iteratively refine each sample. HSSBench contains over 13,000\nmeticulously designed samples, covering six key categories. We benchmark more\nthan 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant\nchallenges even for state-of-the-art models. We hope that this benchmark will\ninspire further research into enhancing the cross-disciplinary reasoning\nabilities of MLLMs, especially their capacity to internalize and connect\nknowledge across fields.", "AI": {"tldr": "\u4e3a\u4e86\u5f25\u8865\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86 HSSBench\uff0c\u4ee5\u8bc4\u4f30\u591a\u8bed\u8a00 MLLMs \u5728\u4eba\u6587\u4e0e\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30 MLLMs \u7684\u57fa\u51c6\u8fc7\u5ea6\u5173\u6ce8 STEM \u5b66\u79d1\u7684\u7ebf\u6027\u63a8\u7406\u9700\u6c42\uff0c\u5ffd\u7565\u4e86\u4eba\u6587\u4e0e\u793e\u4f1a\u79d1\u5b66\u5bf9\u8de8\u5b66\u79d1\u601d\u7ef4\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\uff0c\u4e13\u5bb6\u4e0e\u81ea\u52a8\u4ee3\u7406\u534f\u4f5c\u751f\u6210\u5e76\u53cd\u590d\u5b8c\u5584\u6837\u672c\u3002", "result": "\u6211\u4eec\u7528 HSSBench \u5bf9\u8d85\u8fc7 20 \u4e2a\u4e3b\u6d41 MLLMs \u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u9762\u4e34\u663e\u8457\u6311\u6218\u3002", "conclusion": "HSSBench \u65e8\u5728\u63a8\u52a8\u8de8\u5b66\u79d1\u9886\u57df\u7684\u7814\u7a76\uff0c\u8bc4\u4f30 MLLMs \u5728\u591a\u79cd\u8bed\u8a00\u7684 HSS \u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u542f\u53d1\u66f4\u591a\u601d\u8003\u3002"}}
{"id": "2506.04490", "pdf": "https://arxiv.org/pdf/2506.04490", "abs": "https://arxiv.org/abs/2506.04490", "authors": ["Rishwanth Raghu", "Axel Levy", "Gordon Wetzstein", "Ellen D. Zhong"], "title": "Multiscale guidance of AlphaFold3 with heterogeneous cryo-EM data", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Protein structure prediction models are now capable of generating accurate 3D\nstructural hypotheses from sequence alone. However, they routinely fail to\ncapture the conformational diversity of dynamic biomolecular complexes, often\nrequiring heuristic MSA subsampling approaches for generating alternative\nstates. In parallel, cryo-electron microscopy (cryo-EM) has emerged as a\npowerful tool for imaging near-native structural heterogeneity, but is\nchallenged by arduous pipelines to go from raw experimental data to atomic\nmodels. Here, we bridge the gap between these modalities, combining cryo-EM\ndensity maps with the rich sequence and biophysical priors learned by protein\nstructure prediction models. Our method, CryoBoltz, guides the sampling\ntrajectory of a pretrained protein structure prediction model using both global\nand local structural constraints derived from density maps, driving predictions\ntowards conformational states consistent with the experimental data. We\ndemonstrate that this flexible yet powerful inference-time approach allows us\nto build atomic models into heterogeneous cryo-EM maps across a variety of\ndynamic biomolecular systems including transporters and antibodies.", "AI": {"tldr": "\u5c06\u51b7\u51bb\u7535\u955c\u6280\u672f\u4e0e\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u7ed3\u5408\uff0c\u63d0\u51faCryoBoltz\u65b9\u6cd5\uff0c\u6709\u6548\u6784\u5efa\u52a8\u6001\u751f\u7269\u5206\u5b50\u7cfb\u7edf\u7684\u539f\u5b50\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u52a8\u6001\u751f\u7269\u5206\u5b50\u590d\u5408\u7269\u7684\u6784\u8c61\u591a\u6837\u6027\u95ee\u9898\uff0c\u540c\u65f6\u7b80\u5316\u4ece\u51b7\u51bb\u7535\u955c\u5b9e\u9a8c\u6570\u636e\u5230\u539f\u5b50\u6a21\u578b\u7684\u56f0\u96be\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aCryoBoltz\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u51b7\u51bb\u7535\u955c\u5bc6\u5ea6\u56fe\u548c\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u91c7\u7528\u5168\u5c40\u548c\u5c40\u90e8\u7ed3\u6784\u7ea6\u675f\uff0c\u6307\u5bfc\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u91c7\u6837\u8f68\u8ff9\u3002", "result": "CryoBoltz\u65b9\u6cd5\u5728\u5904\u7406\u52a8\u6001\u751f\u7269\u5206\u5b50\u7cfb\u7edf\uff08\u5982\u8f6c\u8fd0\u86cb\u767d\u548c\u6297\u4f53\uff09\u7684\u5f02\u8d28\u6027\u51b7\u51bb\u7535\u955c\u56fe\u4e2d\uff0c\u6210\u529f\u6784\u5efa\u4e86\u539f\u5b50\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\u6a21\u578b\u548c\u51b7\u51bb\u7535\u955c\u5bc6\u5ea6\u56fe\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u7b26\u5408\u5b9e\u9a8c\u6570\u636e\u7684\u6784\u8c61\u72b6\u6001\u3002"}}
{"id": "2506.04708", "pdf": "https://arxiv.org/pdf/2506.04708", "abs": "https://arxiv.org/abs/2506.04708", "authors": ["Woomin Song", "Saket Dingliwal", "Sai Muralidhar Jayanthi", "Bhavana Ganesh", "Jinwoo Shin", "Aram Galstyan", "Sravan Babu Bodapati"], "title": "Accelerated Test-Time Scaling with Model-Free Speculative Sampling", "categories": ["cs.CL"], "comment": null, "summary": "Language models have demonstrated remarkable capabilities in reasoning tasks\nthrough test-time scaling techniques like best-of-N sampling and tree search.\nHowever, these approaches often demand substantial computational resources,\ncreating a critical trade-off between performance and efficiency. We introduce\nSTAND (STochastic Adaptive N-gram Drafting), a novel model-free speculative\ndecoding approach that leverages the inherent redundancy in reasoning\ntrajectories to achieve significant acceleration without compromising accuracy.\nOur analysis reveals that reasoning paths frequently reuse similar reasoning\npatterns, enabling efficient model-free token prediction without requiring\nseparate draft models. By introducing stochastic drafting and preserving\nprobabilistic information through a memory-efficient logit-based N-gram module,\ncombined with optimized Gumbel-Top-K sampling and data-driven tree\nconstruction, STAND significantly improves token acceptance rates. Extensive\nevaluations across multiple models and reasoning tasks (AIME-2024,\nGPQA-Diamond, and LiveCodeBench) demonstrate that STAND reduces inference\nlatency by 60-65% compared to standard autoregressive decoding while\nmaintaining accuracy. Furthermore, STAND outperforms state-of-the-art\nspeculative decoding methods by 14-28% in throughput and shows strong\nperformance even in single-trajectory scenarios, reducing inference latency by\n48-58%. As a model-free approach, STAND can be applied to any existing language\nmodel without additional training, being a powerful plug-and-play solution for\naccelerating language model reasoning.", "AI": {"tldr": "STAND \u662f\u4e00\u79cd\u53ef\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u65e0\u6a21\u578b\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6027\u80fd\u548c\u6548\u7387\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u95ee\u9898\u3002", "method": "\u5229\u7528\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u5197\u4f59\u6027\uff0c\u901a\u8fc7\u8bb0\u5fc6\u9ad8\u6548\u7684\u57fa\u4e8elogit\u7684N\u5143\u6a21\u5757\u8fdb\u884c\u6982\u7387\u4fe1\u606f\u4fdd\u5b58\uff0c\u5f15\u5165\u968f\u673a\u8d77\u8349\u548c\u4f18\u5316\u7684Gumbel-Top-K\u91c7\u6837\u4ee5\u53ca\u6570\u636e\u9a71\u52a8\u7684\u6811\u7ed3\u6784\u6784\u5efa\u3002", "result": "STAND \u5c06\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u4e8660-65%\uff0c\u6bd4\u6700\u5148\u8fdb\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u5728\u541e\u5410\u91cf\u4e0a\u4f18\u8d8a14-28%\uff0c\u5728\u5355\u4e00\u8f68\u8ff9\u573a\u666f\u4e2d\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u4e8648-58%\u3002", "conclusion": "STAND \u662f\u4e00\u79cd\u65e0\u6a21\u578b\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u7387\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u3002"}}
{"id": "2506.04230", "pdf": "https://arxiv.org/pdf/2506.04230", "abs": "https://arxiv.org/abs/2506.04230", "authors": ["Kaveh Mohajeri", "Amir Karami"], "title": "Computationally Intensive Research: Advancing a Role for Secondary Analysis of Qualitative Data", "categories": ["cs.DB", "cs.AI", "cs.DL"], "comment": "20 Pages", "summary": "This paper draws attention to the potential of computational methods in\nreworking data generated in past qualitative studies. While qualitative\ninquiries often produce rich data through rigorous and resource-intensive\nprocesses, much of this data usually remains unused. In this paper, we first\nmake a general case for secondary analysis of qualitative data by discussing\nits benefits, distinctions, and epistemological aspects. We then argue for\nopportunities with computationally intensive secondary analysis, highlighting\nthe possibility of drawing on data assemblages spanning multiple contexts and\ntimeframes to address cross-contextual and longitudinal research phenomena and\nquestions. We propose a scheme to perform computationally intensive secondary\nanalysis and advance ideas on how this approach can help facilitate the\ndevelopment of innovative research designs. Finally, we enumerate some key\nchallenges and ongoing concerns associated with qualitative data sharing and\nreuse.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8ba1\u7b97\u5bc6\u96c6\u578b\u4e8c\u6b21\u5206\u6790\u7684\u65b9\u6848\uff0c\u65e8\u5728\u91cd\u6784\u5df2\u751f\u6210\u7684\u5b9a\u6027\u7814\u7a76\u6570\u636e\uff0c\u4ee5\u521b\u65b0\u7814\u7a76\u8bbe\u8ba1\uff0c\u89e3\u51b3\u8de8\u60c5\u5883\u548c\u7eb5\u5411\u7814\u7a76\u95ee\u9898\uff0c\u4ee5\u53ca\u63a2\u8ba8\u6570\u636e\u5171\u4eab\u548c\u91cd\u7528\u7684\u6311\u6218\u3002", "motivation": "\u5b9a\u6027\u7814\u7a76\u901a\u5e38\u4ea7\u751f\u4e30\u5bcc\u7684\u6570\u636e\uff0c\u4f46\u8bb8\u591a\u6570\u636e\u672a\u88ab\u4f7f\u7528\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u5982\u4f55\u4e8c\u6b21\u5206\u6790\u8fd9\u4e9b\u6570\u636e\uff0c\u4ece\u800c\u4fc3\u8fdb\u7814\u7a76\u8bbe\u8ba1\u7684\u521b\u65b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u5bc6\u96c6\u578b\u4e8c\u6b21\u5206\u6790\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u901a\u8fc7\u6570\u636e\u6c47\u96c6\u8de8\u591a\u4e2a\u60c5\u5883\u548c\u65f6\u95f4\u6846\u67b6\uff0c\u89e3\u51b3\u8de8\u60c5\u5883\u548c\u7eb5\u5411\u7814\u7a76\u73b0\u8c61\u548c\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u5b9a\u6027\u6570\u636e\u5171\u4eab\u548c\u91cd\u7528\u6240\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u548c\u6301\u7eed\u5173\u6ce8\u7684\u65b9\u9762\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u8ba1\u7b97\u65b9\u6cd5\u5728\u91cd\u6784\u8fc7\u53bb\u5b9a\u6027\u7814\u7a76\u751f\u6210\u7684\u6570\u636e\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8fdb\u884c\u8ba1\u7b97\u5bc6\u96c6\u578b\u4e8c\u6b21\u5206\u6790\u7684\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\u4fc3\u8fdb\u521b\u65b0\u7814\u7a76\u8bbe\u8ba1\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.04523", "pdf": "https://arxiv.org/pdf/2506.04523", "abs": "https://arxiv.org/abs/2506.04523", "authors": ["Cliff B. Abbott", "Mark Elo", "Dmytro A. Bozhko"], "title": "Perturbative Gradient Training: A novel training paradigm for bridging the gap between deep neural networks and physical reservoir computing", "categories": ["cs.LG", "cond-mat.mes-hall", "cs.ET", "cs.NE", "physics.comp-ph"], "comment": "7 pages, 8 figures, submitted to IEEE Transactions on Neural Netowrks\n  and Learning Systems", "summary": "We introduce Perturbative Gradient Training (PGT), a novel training paradigm\nthat overcomes a critical limitation of physical reservoir computing: the\ninability to perform backpropagation due to the black-box nature of physical\nreservoirs. Drawing inspiration from perturbation theory in physics, PGT uses\nrandom perturbations in the network's parameter space to approximate gradient\nupdates using only forward passes. We demonstrate the feasibility of this\napproach on both simulated neural network architectures, including a dense\nnetwork and a transformer model with a reservoir layer, and on experimental\nhardware using a magnonic auto-oscillation ring as the physical reservoir. Our\nresults show that PGT can achieve performance comparable to that of standard\nbackpropagation methods in cases where backpropagation is impractical or\nimpossible. PGT represents a promising step toward integrating physical\nreservoirs into deeper neural network architectures and achieving significant\nenergy efficiency gains in AI training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u8303\u5f0f\u2014\u6270\u52a8\u68af\u5ea6\u8bad\u7ec3\uff08PGT\uff09\uff0c\u514b\u670d\u4e86\u7269\u7406\u5e93\u8ba1\u7b97\u65e0\u6cd5\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u5c40\u9650\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6a21\u62df\u7f51\u7edc\u67b6\u6784\u53ca\u7269\u7406\u5b9e\u9a8c\u4e2d\uff0cPGT\u53ef\u8fbe\u5230\u4e0e\u6807\u51c6\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5177\u6709\u663e\u8457\u7684\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u7269\u7406\u5e93\u8ba1\u7b97\u5b58\u5728\u65e0\u6cd5\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u5f15\u5165PGT\u53ef\u4ee5\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u3002", "method": "PGT\u91c7\u7528\u968f\u673a\u6270\u52a8\u7f51\u7edc\u53c2\u6570\u7a7a\u95f4\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ec5\u524d\u5411\u8fc7\u7a0b\u6765\u8fd1\u4f3c\u68af\u5ea6\u66f4\u65b0\u3002", "result": "PGT\u5728\u6a21\u62df\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u548c\u5b9e\u9a8c\u786c\u4ef6\u4e0a\u5c55\u793a\u4e86\u6027\u80fd\u53ef\u4e0e\u6807\u51c6\u53cd\u5411\u4f20\u64ad\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "PGT\u80fd\u591f\u5728\u65e0\u6cd5\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e0e\u6807\u51c6\u53cd\u5411\u4f20\u64ad\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002"}}
{"id": "2506.04714", "pdf": "https://arxiv.org/pdf/2506.04714", "abs": "https://arxiv.org/abs/2506.04714", "authors": ["Bhavana Akkiraju", "Aishwarya Pothula", "Santosh Kesiraju", "Anil Kumar Vuppala"], "title": "IIITH-BUT system for IWSLT 2025 low-resource Bhojpuri to Hindi speech translation", "categories": ["cs.CL", "eess.AS"], "comment": "Paper is accepted to IWSLT2025", "summary": "This paper presents the submission of IIITH-BUT to the IWSLT 2025 shared task\non speech translation for the low-resource Bhojpuri-Hindi language pair. We\nexplored the impact of hyperparameter optimisation and data augmentation\ntechniques on the performance of the SeamlessM4T model fine-tuned for this\nspecific task. We systematically investigated a range of hyperparameters\nincluding learning rate schedules, number of update steps, warm-up steps, label\nsmoothing, and batch sizes; and report their effect on translation quality. To\naddress data scarcity, we applied speed perturbation and SpecAugment and\nstudied their effect on translation quality. We also examined the use of\ncross-lingual signal through joint training with Marathi and Bhojpuri speech\ndata. Our experiments reveal that careful selection of hyperparameters and the\napplication of simple yet effective augmentation techniques significantly\nimprove performance in low-resource settings. We also analysed the translation\nhypotheses to understand various kinds of errors that impacted the translation\nquality in terms of BLEU.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f18\u5316\u8d85\u53c2\u6570\u548c\u5e94\u7528\u6570\u636e\u589e\u5f3a\u6280\u672f\u5728\u4f4e\u8d44\u6e90Bhojpuri-Hindi\u8bed\u8a00\u5bf9\u8bed\u97f3\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u3002", "motivation": "\u7814\u7a76\u4f4e\u8d44\u6e90\u8bed\u8a00\u5bf9\uff08Bhojpuri-Hindi\uff09\u7684\u8bed\u97f3\u7ffb\u8bd1\u63d0\u5347\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u7ffb\u8bd1\u8d28\u91cf\u3002", "method": "\u5bf9SeamlessM4T\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u63a2\u7d22\u8d85\u53c2\u6570\u4f18\u5316\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\u7684\u5f71\u54cd\uff1b\u5e94\u7528\u901f\u5ea6\u6270\u52a8\u548cSpecAugment\u7b49\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff1b\u8fdb\u884c\u8de8\u8bed\u8a00\u4fe1\u53f7\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u7cbe\u5fc3\u9009\u62e9\u8d85\u53c2\u6570\u4ee5\u53ca\u7b80\u5355\u4f46\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4f4e\u8d44\u6e90\u7ffb\u8bd1\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u5206\u6790\u7ffb\u8bd1\u5047\u8bbe\u4ee5\u7406\u89e3BLEU\u6307\u6807\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\u3002", "conclusion": "\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u5e94\u7528\u8d85\u53c2\u6570\u4f18\u5316\u548c\u6570\u636e\u589e\u5f3a\u6280\u672f\u53ef\u4ee5\u663e\u8457\u6539\u5584\u7ffb\u8bd1\u8d28\u91cf\u3002"}}
{"id": "2506.04235", "pdf": "https://arxiv.org/pdf/2506.04235", "abs": "https://arxiv.org/abs/2506.04235", "authors": ["Xinyan Zhao", "Yi-Ching Tang", "Akshita Singh", "Victor J Cantu", "KwanHo An", "Junseok Lee", "Adam E Stogsdill", "Ashwin Kumar Ramesh", "Zhiqiang An", "Xiaoqian Jiang", "Yejin Kim"], "title": "Benchmark for Antibody Binding Affinity Maturation and Design", "categories": ["q-bio.QM", "cs.AI", "cs.CE", "cs.LG", "q-bio.BM"], "comment": null, "summary": "We introduce AbBiBench (Antibody Binding Benchmarking), a benchmarking\nframework for antibody binding affinity maturation and design. Unlike existing\nantibody evaluation strategies that rely on antibody alone and its similarity\nto natural ones (e.g., amino acid identity rate, structural RMSD), AbBiBench\nconsiders an antibody-antigen (Ab-Ag) complex as a functional unit and\nevaluates the potential of an antibody design binding to given antigen by\nmeasuring protein model's likelihood on the Ab-Ag complex. We first curate,\nstandardize, and share 9 datasets containing 9 antigens (involving influenza,\nanti-lysozyme, HER2, VEGF, integrin, and SARS-CoV-2) and 155,853 heavy chain\nmutated antibodies. Using these datasets, we systematically compare 14 protein\nmodels including masked language models, autoregressive language models,\ninverse folding models, diffusion-based generative models, and geometric graph\nmodels. The correlation between model likelihood and experimental affinity\nvalues is used to evaluate model performance. Additionally, in a case study to\nincrease binding affinity of antibody F045-092 to antigen influenza H1N1, we\nevaluate the generative power of the top-performing models by sampling a set of\nnew antibodies binding to the antigen and ranking them based on structural\nintegrity and biophysical properties of the Ab-Ag complex. As a result,\nstructure-conditioned inverse folding models outperform others in both affinity\ncorrelation and generation tasks. Overall, AbBiBench provides a unified,\nbiologically grounded evaluation framework to facilitate the development of\nmore effective, function-aware antibody design models.", "AI": {"tldr": "AbBiBench\u662f\u4e00\u79cd\u7528\u4e8e\u6297\u4f53\u4eb2\u548c\u529b\u8bbe\u8ba1\u548c\u4f18\u5316\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u7ed3\u6784\u6761\u4ef6\u9006\u6298\u53e0\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u73b0\u6709\u7684\u6297\u4f53\u8bc4\u4f30\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56\u4e8e\u6297\u4f53\u672c\u8eab\u53ca\u5176\u4e0e\u81ea\u7136\u6297\u4f53\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u672a\u8003\u8651\u6297\u4f53\u4e0e\u6297\u539f\u7684\u5b9e\u9645\u7ed3\u5408\u80fd\u529b\u3002AbBiBench\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8861\u91cf\u6297\u4f53\u8bbe\u8ba1\u6f5c\u529b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6d4b\u91cf\u6297\u4f53\u6297\u539f\u590d\u5408\u4f53\u6765\u6539\u8fdb\u6297\u4f53\u4eb2\u548c\u529b\u7b5b\u9009\u548c\u8bbe\u8ba1\u3002", "method": "AbBiBench\u8003\u8651\u6297\u4f53\u6297\u539f\u590d\u5408\u7269\u4f5c\u4e3a\u529f\u80fd\u5355\u5143\uff0c\u6d4b\u91cf\u86cb\u767d\u6a21\u578b\u5728Ab-Ag\u590d\u5408\u4f53\u4e0a\u7684\u53ef\u80fd\u6027\uff0c\u901a\u8fc7\u6a21\u578b\u53ef\u80fd\u6027\u4e0e\u5b9e\u9a8c\u4eb2\u548c\u529b\u503c\u7684\u76f8\u5173\u6027\u6765\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5bf914\u79cd\u86cb\u767d\u6a21\u578b\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u7ed3\u6784\u6761\u4ef6\u9006\u6298\u53e0\u6a21\u578b\u5728\u4eb2\u548c\u529b\u76f8\u5173\u6027\u548c\u6297\u4f53\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "AbBiBench\u4e3a\u6297\u4f53\u8bbe\u8ba1\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7efc\u5408\u7684\u3001\u751f\u7269\u5b66\u9a71\u52a8\u7684\u8bc4\u4ef7\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u3001\u5177\u6709\u529f\u80fd\u610f\u8bc6\u7684\u6297\u4f53\u8bbe\u8ba1\u6a21\u578b\u3002\u7ed3\u6784\u6761\u4ef6\u9006\u6298\u53e0\u6a21\u578b\u5728\u4eb2\u548c\u529b\u76f8\u5173\u6027\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002"}}
