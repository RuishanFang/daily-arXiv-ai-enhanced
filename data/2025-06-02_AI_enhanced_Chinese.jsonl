{"id": "2505.23985", "pdf": "https://arxiv.org/pdf/2505.23985", "abs": "https://arxiv.org/abs/2505.23985", "authors": ["Amalia Puente", "Diego Radillo-Ochoa", "C. A. Terrero-Escalante"], "title": "Rules, agents and order", "categories": ["nlin.AO", "physics.soc-ph"], "comment": "20 pages, 10 figures", "summary": "Complex systems often exhibit highly structured network topologies that\nreflect functional constraints. In this work, we investigate how, under varying\ncombinations of system-wide selection rules and special agents, different\nclasses of random processes give rise to global order, with a focus restricted\nto finite-size networks. Using the large-$N$ Erdos-Renyi model as a null\nbaseline, we contrast purely random link-adding processes with goal-directed\ndynamics, including variants of the chip-firing model and intracellular network\ngrowth, both driven by transport efficiency. Through simulations and structural\nprobes such as $k$-core decomposition and $HITS$ centrality, we show that\npurely stochastic processes can spontaneously generate modest functional\nstructures, but that significant departures from random behavior generically\nrequire two key conditions: critical topological complexity and dynamic\nalignment between topology and functionality. Our results suggest that the\nemergence of functional architectures depends not only on the presence of\nselection mechanisms or specialized roles, but also on the network's capacity\nto support differentiation and feedback. These findings provide insight into\nhow topology-functionality relationships emerge in natural and artificial\nsystems and offer a framework for using random graph baselines to diagnose the\nrise of global order in evolving finite-size networks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u6709\u9650\u89c4\u6a21\u7f51\u7edc\u4e2d\uff0c\u7cfb\u7edf\u9009\u62e9\u89c4\u5219\u548c\u529f\u80fd\u6027\u89d2\u8272\u5982\u4f55\u5f71\u54cd\u968f\u673a\u8fc7\u7a0b\u5f62\u6210\u7684\u5168\u5c40\u79e9\u5e8f\u3002", "motivation": "\u7814\u7a76\u5728\u4e0d\u540c\u7cfb\u7edf\u9009\u62e9\u89c4\u5219\u548c\u7279\u6b8a\u4ee3\u7406\u7684\u7ec4\u5408\u4e0b\uff0c\u968f\u673a\u8fc7\u7a0b\u5982\u4f55\u4ea7\u751f\u5168\u5c40\u79e9\u5e8f\uff0c\u7279\u522b\u5173\u6ce8\u6709\u9650\u89c4\u6a21\u7f51\u7edc\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u7684Erdos-Renyi\u6a21\u578b\u4f5c\u4e3a\u57fa\u51c6\uff0c\u6bd4\u8f83\u968f\u673a\u94fe\u63a5\u6dfb\u52a0\u8fc7\u7a0b\u4e0e\u76ee\u6807\u5bfc\u5411\u52a8\u6001\u8fc7\u7a0b\uff0c\u5305\u62ec\u82af\u7247\u6fc0\u53d1\u6a21\u578b\u548c\u7ec6\u80de\u5185\u7f51\u7edc\u751f\u957f\uff0c\u901a\u8fc7\u8fd0\u8f93\u6548\u7387\u9a71\u52a8\u3002\u901a\u8fc7\u4eff\u771f\u548c\u7ed3\u6784\u63a2\u6d4b\uff08\u5982k\u6838\u5206\u89e3\u548cHITS\u4e2d\u5fc3\u6027\uff09\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u7eaf\u7cb9\u7684\u968f\u673a\u8fc7\u7a0b\u53ef\u4ee5\u81ea\u53d1\u4ea7\u751f\u9002\u5ea6\u7684\u529f\u80fd\u7ed3\u6784\uff0c\u4f46\u663e\u8457\u504f\u79bb\u968f\u673a\u884c\u4e3a\u4e00\u822c\u9700\u8981\u4e24\u4e2a\u5173\u952e\u6761\u4ef6\uff1a\u4e34\u754c\u7684\u62d3\u6251\u590d\u6742\u6027\u4ee5\u53ca\u62d3\u6251\u4e0e\u529f\u80fd\u6027\u7684\u52a8\u6001\u5bf9\u9f50\u3002", "conclusion": "\u529f\u80fd\u6027\u67b6\u6784\u7684\u51fa\u73b0\u4e0d\u4ec5\u4f9d\u8d56\u4e8e\u9009\u62e9\u673a\u5236\u6216\u4e13\u4e1a\u89d2\u8272\u7684\u5b58\u5728\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u7f51\u7edc\u652f\u6301\u529f\u80fd\u5dee\u5f02\u4e0e\u53cd\u9988\u7684\u80fd\u529b\u3002"}}
{"id": "2505.24631", "pdf": "https://arxiv.org/pdf/2505.24631", "abs": "https://arxiv.org/abs/2505.24631", "authors": ["Christian Kluge", "Christian Kuehn"], "title": "Cascades on Constrained Multiplex Networks", "categories": ["nlin.AO", "cs.SI", "math.PR", "physics.soc-ph"], "comment": null, "summary": "We consider a version of the Watts cascade model on directed multiplex\nconfiguration model networks, and present a detailed analysis of the cascade\nsize, single-seed cascade probability and cascade condition. We then introduce\na smaller class of network models that we call constrained multiplex networks,\nwhich allows us to induce patterns in the node activity, i.e. in the\nparticipation of nodes on different layers. We find that the choice of induced\npatterns affects the phase transitions of the cascade model in a variety of\nways.", "AI": {"tldr": "\u7814\u7a76\u4e86Watts\u7ea7\u8054\u6a21\u578b\u5728\u591a\u8def\u590d\u7528\u7f51\u7edc\u4e0a\u7684\u884c\u4e3a\uff0c\u5f15\u5165\u4e86\u7ea6\u675f\u591a\u8def\u590d\u7528\u7f51\u7edc\uff0c\u5e76\u53d1\u73b0\u8bf1\u5bfc\u6a21\u5f0f\u7684\u9009\u62e9\u5f71\u54cd\u76f8\u53d8\u3002", "motivation": "\u7814\u7a76\u5728\u591a\u5c42\u7f51\u7edc\u4e2d\u8282\u70b9\u6d3b\u52a8\u7684\u8bf1\u5bfc\u6a21\u5f0f\u5982\u4f55\u5f71\u54cd\u7ea7\u8054\u6a21\u578b\u7684\u76f8\u53d8\u3002", "method": "\u4f7f\u7528\u65b9\u5411\u591a\u8def\u590d\u7528\u914d\u7f6e\u6a21\u578b\u7f51\u7edc\u7248\u672c\u7684Watts\u7ea7\u8054\u6a21\u578b\uff0c\u8be6\u7ec6\u5206\u6790\u4e86\u7ea7\u8054\u5927\u5c0f\u3001\u5355\u79cd\u5b50\u7ea7\u8054\u6982\u7387\u548c\u7ea7\u8054\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u7c7b\u66f4\u5c0f\u7684\u7f51\u7edc\u6a21\u578b\u2014\u2014\u7ea6\u675f\u591a\u8def\u590d\u7528\u7f51\u7edc\u3002", "result": "\u8bf1\u5bfc\u6a21\u5f0f\u7684\u9009\u62e9\u5f71\u54cd\u4e86\u7ea7\u8054\u6a21\u578b\u7684\u76f8\u53d8\u3002", "conclusion": "\u5728\u7ea6\u675f\u591a\u8def\u590d\u7528\u7f51\u7edc\u4e2d\u8bf1\u5bfc\u6a21\u5f0f\u7684\u9009\u62e9\u4f1a\u4ee5\u591a\u79cd\u65b9\u5f0f\u5f71\u54cd\u7ea7\u8054\u6a21\u578b\u7684\u76f8\u53d8\u3002"}}
{"id": "2505.24818", "pdf": "https://arxiv.org/pdf/2505.24818", "abs": "https://arxiv.org/abs/2505.24818", "authors": ["Aarathi Parameswaran", "Iva Ba\u010di\u0107", "Andrea Benigni", "Dirk Witthaut"], "title": "Symmetry breaking in minimum dissipation networks", "categories": ["nlin.AO", "physics.soc-ph"], "comment": "12 pages, 11 figures", "summary": "Both natural and man-made supply networks exhibit universal structural\npatterns, such as the formation of loops. These patterns can be understood in\nterms of optimization models, assuming that biological networks evolved to\noptimal states and technical networks are designed to function optimally. In\nthis article, we analyze networks that minimize dissipation under a research\nconstraint. We demonstrate spontaneous symmetry breaking in optimal network\nstructures as a function of resource scaling. We show that fluctuations\nintricately impact the structure and can lead to a reentrant transition from a\nsymmetry-broken state to a symmetric state and back again.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u4f9b\u7ed9\u7f51\u7edc\u7684\u4f18\u5316\u7ed3\u6784\u53d7\u5230\u6ce2\u52a8\u5f71\u54cd\uff0c\u53ef\u80fd\u7ecf\u5386\u5bf9\u79f0\u7834\u7f3a\u548c\u5bf9\u79f0\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u53d8\u3002", "motivation": "\u7406\u89e3\u4f9b\u7ed9\u7f51\u7edc\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7ed3\u6784\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u6a21\u578b\u5206\u6790\u751f\u7269\u7f51\u7edc\u548c\u6280\u672f\u7f51\u7edc\u7684\u6f14\u5316\u53ca\u8bbe\u8ba1\u3002", "method": "\u5206\u6790\u6700\u5c0f\u5316\u8017\u6563\u7f51\u7edc\u7ed3\u6784\u4e2d\u7684\u81ea\u53d1\u5bf9\u79f0\u7834\u7f3a\u73b0\u8c61\uff0c\u5e76\u7814\u7a76\u8d44\u6e90\u7f29\u653e\u7684\u5f71\u54cd\u3002", "result": "\u5c55\u793a\u4e86\u8d44\u6e90\u7f29\u653e\u5bf9\u7f51\u7edc\u7ed3\u6784\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u6ce2\u52a8\u5982\u4f55\u5bfc\u81f4\u590d\u6742\u7684\u7ed3\u6784\u53d8\u5316\u3002", "conclusion": "\u7f51\u7edc\u4e2d\u7684\u6ce2\u52a8\u4f1a\u5f71\u54cd\u7f51\u7edc\u7ed3\u6784\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u4ece\u5bf9\u79f0\u7834\u7f3a\u72b6\u6001\u5230\u5bf9\u79f0\u72b6\u6001\u7684\u91cd\u590d\u8f6c\u53d8\u3002"}}
{"id": "2505.23774", "pdf": "https://arxiv.org/pdf/2505.23774", "abs": "https://arxiv.org/abs/2505.23774", "authors": ["Zeki Doruk Erden", "Boi Faltings"], "title": "On the Parallels Between Evolutionary Theory and the State of AI", "categories": ["q-bio.NC", "cs.LG", "cs.NE", "nlin.AO"], "comment": "Published at the Evolving Self-Organization Workshop in GECCO 2025", "summary": "This article critically examines the foundational principles of contemporary\nAI methods, exploring the limitations that hinder its potential. We draw\nparallels between the modern AI landscape and the 20th-century Modern Synthesis\nin evolutionary biology, and highlight how advancements in evolutionary theory\nthat augmented the Modern Synthesis, particularly those of Evolutionary\nDevelopmental Biology, offer insights that can inform a new design paradigm for\nAI. By synthesizing findings across AI and evolutionary theory, we propose a\npathway to overcome existing limitations, enabling AI to achieve its\naspirational goals.", "AI": {"tldr": "\u6587\u7ae0\u63a2\u8ba8\u4e86\u73b0\u4ee3AI\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u7ed3\u5408\u8fdb\u5316\u7406\u8bba\u7684\u65b0\u89c1\u89e3\uff0c\u6765\u4e3aAI\u8bbe\u8ba1\u51fa\u65b0\u7684\u89e3\u51b3\u9014\u5f84\u3002", "motivation": "\u901a\u8fc7\u5c06\u73b0\u4ee3AI\u9886\u57df\u4e0e20\u4e16\u7eaa\u8fdb\u5316\u751f\u7269\u5b66\u7684\u73b0\u4ee3\u7efc\u5408\u4f53\u8fdb\u884c\u6bd4\u8f83\uff0c\u63ed\u793a\u8fdb\u5316\u7406\u8bba\u7684\u8fdb\u6b65\u5982\u4f55\u80fd\u591f\u4e3aAI\u7684\u65b0\u8bbe\u8ba1\u8303\u5f0f\u63d0\u4f9b\u542f\u793a\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u6279\u5224\u6027\u5730\u5ba1\u89c6\u73b0\u4ee3AI\u65b9\u6cd5\u7684\u57fa\u672c\u539f\u5219\uff0c\u63a2\u8ba8\u9650\u5236\u5176\u6f5c\u529b\u7684\u56e0\u7d20\u3002", "result": "\u901a\u8fc7\u7efc\u5408AI\u548c\u8fdb\u5316\u7406\u8bba\u7684\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u514b\u670d\u73b0\u6709\u5c40\u9650\u6027\u7684\u65b0\u9014\u5f84\uff0c\u4f7fAI\u80fd\u591f\u5b9e\u73b0\u5176\u62b1\u8d1f\u76ee\u6807\u3002", "conclusion": "\u73b0\u4ee3AI\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u501f\u9274\u8fdb\u5316\u53d1\u80b2\u751f\u7269\u5b66\u7684\u8fdb\u6b65\u53ef\u4ee5\u4e3aAI\u63d0\u4f9b\u65b0\u7684\u8bbe\u8ba1\u8303\u5f0f\uff0c\u4ece\u800c\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u6027\u3002"}}
{"id": "2505.24113", "pdf": "https://arxiv.org/pdf/2505.24113", "abs": "https://arxiv.org/abs/2505.24113", "authors": ["Pengcheng Dai", "Yuanqiu Mo", "Wenwu Yu", "Wei Ren"], "title": "Distributed Neural Policy Gradient Algorithm for Global Convergence of Networked Multi-Agent Reinforcement Learning", "categories": ["cs.MA"], "comment": null, "summary": "This paper studies the networked multi-agent reinforcement learning (NMARL)\nproblem, where the objective of agents is to collaboratively maximize the\ndiscounted average cumulative rewards. Different from the existing methods that\nsuffer from poor expression due to linear function approximation, we propose a\ndistributed neural policy gradient algorithm that features two innovatively\ndesigned neural networks, specifically for the approximate Q-functions and\npolicy functions of agents. This distributed neural policy gradient algorithm\nconsists of two key components: the distributed critic step and the\ndecentralized actor step. In the distributed critic step, agents receive the\napproximate Q-function parameters from their neighboring agents via a\ntime-varying communication networks to collaboratively evaluate the joint\npolicy. In contrast, in the decentralized actor step, each agent updates its\nlocal policy parameter solely based on its own approximate Q-function. In the\nconvergence analysis, we first establish the global convergence of agents for\nthe joint policy evaluation in the distributed critic step. Subsequently, we\nrigorously demonstrate the global convergence of the overall distributed neural\npolicy gradient algorithm with respect to the objective function. Finally, the\neffectiveness of the proposed algorithm is demonstrated by comparing it with a\ncentralized algorithm through simulation in the robot path planning\nenvironment.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u5e03\u5f0f\u795e\u7ecf\u653f\u7b56\u68af\u5ea6\u7b97\u6cd5\uff0c\u4ee5\u6539\u8fdb\u7f51\u7edc\u5316\u591a\u4ee3\u7406\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u679c\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u53d7\u9650\u4e8e\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u4f18\u79c0\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u795e\u7ecf\u653f\u7b56\u68af\u5ea6\u7b97\u6cd5\uff0c\u5305\u542b\u5206\u5e03\u5f0f\u8bc4\u8bba\u6b65\u9aa4\u548c\u5206\u6563\u7684\u8868\u6f14\u8005\u6b65\u9aa4\uff0c\u901a\u8fc7\u65f6\u95f4\u53d8\u5316\u7684\u901a\u4fe1\u7f51\u7edc\u8fdb\u884c\u53c2\u6570\u8bc4\u4f30\u548c\u66f4\u65b0\u3002", "result": "\u901a\u8fc7\u5168\u5c40\u6536\u655b\u6027\u8bc1\u660e\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u73af\u5883\u4e0b\u4e0e\u96c6\u4e2d\u7b97\u6cd5\u7684\u6bd4\u8f83\u4e2d\u5c55\u73b0\u4e86\u6709\u6548\u6027\u3002"}}
{"id": "2505.23881", "pdf": "https://arxiv.org/pdf/2505.23881", "abs": "https://arxiv.org/abs/2505.23881", "authors": ["Christopher D. Rosin"], "title": "Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems", "categories": ["cs.AI", "cs.CL", "math.CO"], "comment": "arXiv admin note: text overlap with arXiv:2501.17725", "summary": "Large Language Models (LLMs) with reasoning are trained to iteratively\ngenerate and refine their answers before finalizing them, which can help with\napplications to mathematics and code generation. We apply code generation with\nreasoning LLMs to a specific task in the mathematical field of combinatorial\ndesign. This field studies diverse types of combinatorial designs, many of\nwhich have lists of open instances for which existence has not yet been\ndetermined. The Constructive Protocol CPro1 uses LLMs to generate search\nheuristics that have the potential to construct solutions to small open\ninstances. Starting with a textual definition and a validity verifier for a\nparticular type of design, CPro1 guides LLMs to select and implement\nstrategies, while providing automated hyperparameter tuning and execution\nfeedback. CPro1 with reasoning LLMs successfully solves long-standing open\ninstances for 7 of 16 combinatorial design problems selected from the 2006\nHandbook of Combinatorial Designs, including new solved instances for 3 of\nthese (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary\nDesigns) that were unsolved by CPro1 with non-reasoning LLMs. It also solves\nopen instances for several problems from recent (2025) literature, generating\nnew Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform\nNested Steiner Quadruple System.", "AI": {"tldr": "\u6784\u5efa\u534f\u8baeCPro1\u4f7f\u7528\u5177\u6709\u63a8\u7406\u80fd\u529b\u7684LLM\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7ec4\u5408\u8bbe\u8ba1\u7814\u7a76\u9886\u57df\u4e2d\u591a\u4e2a\u957f\u671f\u672a\u89e3\u7684\u5b9e\u4f8b\uff0c\u663e\u793a\u51fa\u5176\u5728\u6570\u5b66\u548c\u4ee3\u7801\u751f\u6210\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5728\u7ec4\u5408\u8bbe\u8ba1\u9886\u57df\u4e2d\uff0c\u5b58\u5728\u8bb8\u591a\u6709\u5f85\u89e3\u51b3\u7684\u5f00\u653e\u5b9e\u4f8b\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u751f\u6210\u548c\u63a8\u7406\u53ef\u4ee5\u5e2e\u52a9\u5bfb\u627e\u8fd9\u4e9b\u5b9e\u4f8b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "Constructive Protocol CPro1 \u5229\u7528\u5e26\u6709\u63a8\u7406\u80fd\u529b\u7684LLM\u751f\u6210\u641c\u7d22\u542f\u53d1\u5f0f\uff0c\u4ee5\u6784\u5efa\u5c0f\u578b\u5f00\u653e\u5b9e\u4f8b\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ec\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u6574\u548c\u6267\u884c\u53cd\u9988\u3002", "result": "CPro1\u6210\u529f\u89e3\u51b3\u4e8616\u4e2a\u7ec4\u5408\u8bbe\u8ba1\u95ee\u9898\u4e2d\u76847\u4e2a\u957f\u671f\u672a\u89e3\u51b3\u7684\u5b9e\u4f8b\uff0c\u7279\u522b\u662f\u5728Bhaskar Rao Designs\u3001Symmetric Weighing Matrices\u3001Balanced Ternary Designs\u4e0a\u53d6\u5f97\u91cd\u5927\u8fdb\u5c55\uff0c\u5e76\u89e3\u51b3\u4e862025\u5e74\u8fd1\u671f\u6587\u732e\u4e2d\u7684\u591a\u4e2a\u95ee\u9898\u3002", "conclusion": "\u5e26\u6709\u63a8\u7406\u80fd\u529b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u7a0b\u5e8f\u751f\u6210\u548c\u6570\u5b66\u9886\u57df\u4e2d\u5b9e\u73b0\u663e\u8457\u6210\u679c\uff0c\u7279\u522b\u662f\u5728\u7ec4\u5408\u8bbe\u8ba1\u9886\u57df\u4e2d\u6210\u529f\u89e3\u5f00\u4e86\u591a\u4e2a\u957f\u671f\u672a\u89e3\u51b3\u7684\u5b9e\u4f8b\u3002"}}
{"id": "2505.23785", "pdf": "https://arxiv.org/pdf/2505.23785", "abs": "https://arxiv.org/abs/2505.23785", "authors": ["Cody Kommers", "Drew Hemment", "Maria Antoniak", "Joel Z. Leibo", "Hoyt Long", "Emily Robinson", "Adam Sobey"], "title": "Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Position paper", "summary": "This position paper argues that large language models (LLMs) can make\ncultural context, and therefore human meaning, legible at an unprecedented\nscale in AI-based sociotechnical systems. We argue that such systems have\npreviously been unable to represent human meaning because they rely on thin\ndescriptions: numerical representations that enforce standardization and\ntherefore strip human activity of the cultural context that gives it meaning.\nBy contrast, scholars in the humanities and qualitative social sciences have\ndeveloped frameworks for representing meaning through thick description: verbal\nrepresentations that accommodate heterogeneity and retain contextual\ninformation needed to represent human meaning. While these methods can\neffectively codify meaning, they are difficult to deploy at scale. However, the\nverbal capabilities of LLMs now provide a means of (at least partially)\nautomating the generation and processing of thick descriptions, potentially\novercoming this bottleneck. We argue that the problem of rendering human\nmeaning legible is not just about selecting better metrics, but about\ndeveloping new representational formats (based on thick description). We frame\nthis as a crucial direction for the application of generative AI and identify\nfive key challenges: preserving context, maintaining interpretive pluralism,\nintegrating perspectives based on lived experience and critical distance,\ndistinguishing qualitative content from quantitative magnitude, and\nacknowledging meaning as dynamic rather than static. Furthermore, we suggest\nthat thick description has the potential to serve as a unifying framework to\naddress a number of emerging concerns about the difficulties of representing\nculture in (or using) LLMs.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u901a\u8fc7\u539a\u63cf\u8ff0\u6355\u6349\u6587\u5316\u80cc\u666f\u7684\u4eba\u7c7b\u610f\u4e49\uff0c\u5728AI\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u89c4\u6a21\u5316\u7684\u610f\u4e49\u8868\u793a\u3002\u8fd9\u4e00\u8fc7\u7a0b\u9762\u4e34\u4e94\u5927\u6311\u6218\uff0c\u4f46\u6709\u6f5c\u529b\u6210\u4e3a\u89e3\u51b3\u6587\u5316\u8868\u793a\u96be\u9898\u7684\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3AI\u7cfb\u7edf\u4e2d\u56e0\u6807\u51c6\u5316\u9650\u5236\u65e0\u6cd5\u6709\u6548\u8868\u793a\u4eba\u7c7b\u542b\u4e49\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165\u539a\u63cf\u8ff0\uff0c\u4f7f\u7cfb\u7edf\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u6587\u5316\u80cc\u666f\u548c\u4eba\u7c7b\u6d3b\u52a8\u7684\u610f\u4e49\u3002", "method": "\u672c\u6587\u901a\u8fc7\u91c7\u7528\u201c\u539a\u63cf\u8ff0\u201d\u7684\u65b9\u6cd5\uff0c\u63a2\u8ba8\u5982\u4f55\u5728AI\u7cfb\u7edf\u4e2d\u6709\u6548\u8868\u793a\u6587\u5316\u80cc\u666f\u548c\u4eba\u7c7b\u610f\u4e49\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u7528\u8bed\u8a00\u80fd\u529b\u5f3a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u751f\u6210\u548c\u5904\u7406\u4fe1\u606f\uff0c\u4ee5\u5728\u89c4\u6a21\u4e0a\u5b9e\u73b0\u4eba\u7c7b\u610f\u4e49\u7684\u89e3\u7801\u3002", "result": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u8a00\u80fd\u529b\u4f7f\u5f97\u80fd\u591f\u5728\u89c4\u6a21\u4e0a\u5904\u7406\u539a\u63cf\u8ff0\uff0c\u8fd9\u53ef\u80fd\u89e3\u51b3\u4e86\u4eba\u7c7b\u610f\u4e49\u89e3\u7801\u7684\u96be\u9898\u3002\u672c\u7814\u7a76\u8fd8\u6307\u51fa\u5e94\u7528\u751f\u6210\u578bAI\u65f6\u9700\u89e3\u51b3\u7684\u4e94\u5927\u6311\u6218\uff0c\u5305\u62ec\u4fdd\u7559\u4e0a\u4e0b\u6587\u3001\u4fdd\u6301\u89e3\u8bfb\u7684\u591a\u5143\u6027\u3001\u6574\u5408\u57fa\u4e8e\u7ecf\u9a8c\u548c\u6279\u5224\u6027\u8ddd\u79bb\u7684\u89c2\u70b9\u3001\u533a\u5206\u5b9a\u6027\u5185\u5bb9\u548c\u5b9a\u91cf\u6570\u636e\u3001\u4ee5\u53ca\u8ba4\u8bc6\u5230\u610f\u4e49\u7684\u52a8\u6001\u7279\u5f81\u3002", "conclusion": "\u539a\u63cf\u8ff0\u8fd9\u4e00\u65b9\u6cd5\u53ef\u80fd\u6210\u4e3a\u89e3\u51b3\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8868\u793a\u6587\u5316\u96be\u9898\u7684\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2505.23857", "pdf": "https://arxiv.org/pdf/2505.23857", "abs": "https://arxiv.org/abs/2505.23857", "authors": ["Wuhao Wang", "Zhiyong Chen"], "title": "DATD3: Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient For Model Free Reinforcement Learning Under Output Feedback Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning in real-world applications often involves\noutput-feedback settings, where the agent receives only partial state\ninformation. To address this challenge, we propose the Output-Feedback Markov\nDecision Process (OPMDP), which extends the standard MDP formulation to\naccommodate decision-making based on observation histories. Building on this\nframework, we introduce Depthwise Attention Twin Delayed Deep Deterministic\nPolicy Gradient (DATD3), a novel actor-critic algorithm that employs depthwise\nseparable convolution and multi-head attention to encode historical\nobservations. DATD3 maintains policy expressiveness while avoiding the\ninstability of recurrent models. Extensive experiments on continuous control\ntasks demonstrate that DATD3 outperforms existing memory-based and recurrent\nbaselines under both partial and full observability.", "AI": {"tldr": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5DATD3\uff0c\u5728\u90e8\u5206\u548c\u5b8c\u5168\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u7684\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u5e38\u5e38\u9047\u5230\u8f93\u51fa\u53cd\u9988\u95ee\u9898\uff0c\u5373\u667a\u80fd\u4f53\u53ea\u80fd\u83b7\u5f97\u90e8\u5206\u72b6\u6001\u4fe1\u606f\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u8f93\u51fa\u53cd\u9988\u9a6c\u5c14\u79d1\u592b\u51b3\u7b56\u8fc7\u7a0b(OPMDP)\uff0c\u8be5\u8fc7\u7a0b\u57fa\u4e8e\u89c2\u6d4b\u5386\u53f2\u8fdb\u884c\u51b3\u7b56\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u65b0\u7684actor-critic\u7b97\u6cd5\uff1aDepthwise Attention Twin Delayed Deep Deterministic Policy Gradient (DATD3)\u3002\u8be5\u7b97\u6cd5\u4f7f\u7528\u6df1\u5ea6\u5206\u79bb\u5377\u79ef\u548c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u6765\u5bf9\u5386\u53f2\u89c2\u6d4b\u8fdb\u884c\u7f16\u7801\u3002", "result": "\u901a\u8fc7\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u6211\u4eec\u8bc1\u660e\u4e86DATD3\u5728\u90e8\u5206\u548c\u5b8c\u5168\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8bb0\u5fc6\u548c\u5faa\u73af\u7684\u57fa\u7ebf\u3002", "conclusion": "DATD3\u5728\u90e8\u5206\u548c\u5b8c\u5168\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\uff0c\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8bb0\u5fc6\u548c\u5faa\u73af\u7684\u57fa\u7ebf\u3002"}}
{"id": "2505.24673", "pdf": "https://arxiv.org/pdf/2505.24673", "abs": "https://arxiv.org/abs/2505.24673", "authors": ["Daniel A. Martin", "Qian-Yuan Tang", "Dante R. Chialvo"], "title": "Finite-time scaling on low-dimensional map bifurcations", "categories": ["cond-mat.dis-nn", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "Recent work has introduced the concept of finite-time scaling to characterize\nbifurcation diagrams at finite times in deterministic discrete dynamical\nsystems, drawing an analogy with finite-size scaling used to study critical\nbehavior in finite systems. In this work, we extend the finite-time scaling\napproach in several key directions. First, we present numerical results for 1D\nmaps exhibiting period-doubling bifurcations and discontinuous transitions,\nanalyzing selected paradigmatic examples. We then define two observables, the\nfinite-time susceptibility and the finite-time Lyapunov exponent, that also\ndisplay consistent scaling near bifurcation points. The method is further\ngeneralized to special cases of 2D maps including the 2D Chialvo map, capturing\nits bifurcation between a fixed point and a periodic orbit, while accounting\nfor discontinuities and asymmetric periodic orbits. These results underscore\nfundamental connections between temporal and spatial observables in complex\nsystems, suggesting new avenues for studying complex dynamical behavior.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u6709\u9650\u65f6\u95f4\u5c3a\u5ea6\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u503c\u5206\u6790\u9a8c\u8bc1\u4e861D\u548c2D\u6620\u5c04\u4e2d\u7684\u5206\u5c94\u884c\u4e3a\uff0c\u5b9a\u4e49\u65b0\u6307\u6807\u5e76\u63ed\u793a\u65f6\u95f4\u548c\u7a7a\u95f4\u89c2\u6d4b\u91cf\u7684\u8054\u7cfb\uff0c\u4e3a\u7814\u7a76\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "motivation": "\u4e3a\u4e86\u6269\u5c55\u6709\u9650\u65f6\u95f4\u5c3a\u5ea6\u5316\u65b9\u6cd5\u7684\u5e94\u7528\uff0c\u8be5\u65b9\u6cd5\u7c7b\u4f3c\u4e8e\u5728\u6709\u9650\u7cfb\u7edf\u4e2d\u7814\u7a76\u4e34\u754c\u884c\u4e3a\u7684\u6709\u9650\u5c3a\u5bf8\u5c3a\u5ea6\u5316\uff0c\u5e94\u7528\u4e8e\u786e\u5b9a\u6027\u79bb\u6563\u52a8\u529b\u7cfb\u7edf\u7684\u5206\u5c94\u56fe\u3002", "method": "\u6587\u7ae0\u9996\u5148\u5bf91D\u6620\u5c04\u8fdb\u884c\u6570\u503c\u5206\u6790\uff0c\u8fd9\u4e9b\u6620\u5c04\u5c55\u793a\u4e86\u5468\u671f\u52a0\u500d\u5206\u5c94\u548c\u4e0d\u8fde\u7eed\u7684\u8f6c\u53d8\u3002\u7136\u540e\uff0c\u5b9a\u4e49\u4e86\u6709\u9650\u65f6\u95f4\u6613\u611f\u6027\u548c\u6709\u9650\u65f6\u95f4Lyapunov\u6307\u6570\u4e24\u4e2a\u89c2\u6d4b\u91cf\u6765\u7814\u7a76\u5206\u5c94\u70b9\u9644\u8fd1\u7684\u7f29\u653e\u884c\u4e3a\u3002\u65b9\u6cd5\u8fd8\u88ab\u63a8\u5e7f\u5230\u5305\u62ec2D Chialvo\u6620\u5c04\u5728\u5185\u76842D\u6620\u5c04\u7684\u7279\u6b8a\u60c5\u51b5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8bc1\u660e\u4e861D\u6620\u5c04\u7684\u5468\u671f\u52a0\u500d\u5206\u5c94\u548c\u4e0d\u8fde\u7eed\u8f6c\u53d8\uff0c\u5e76\u5c55\u793a\u4e86\u6709\u9650\u65f6\u95f4\u6613\u611f\u6027\u548c\u6709\u9650\u65f6\u95f4Lyapunov\u6307\u6570\u5728\u5206\u5c94\u70b9\u9644\u8fd1\u7684\u4e00\u81f4\u7f29\u653e\u884c\u4e3a\u3002\u65b9\u6cd5\u4e5f\u6210\u529f\u5e94\u7528\u4e8e2D\u6620\u5c04\uff0c\u5305\u62ec\u6355\u83b72D Chialvo\u6620\u5c04\u4e2d\u5206\u5c94\u4ece\u4e00\u4e2a\u56fa\u5b9a\u70b9\u5230\u4e00\u4e2a\u5468\u671f\u8f68\u9053\u7684\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u6709\u9650\u65f6\u95f4\u5c3a\u5ea6\u5316\u65b9\u6cd5\uff0c\u6211\u4eec\u53d1\u73b0\u65f6\u95f4\u548c\u7a7a\u95f4\u89c2\u6d4b\u91cf\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u5b58\u5728\u57fa\u672c\u8054\u7cfb\uff0c\u8fd9\u4e3a\u7814\u7a76\u590d\u6742\u52a8\u6001\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2505.24239", "pdf": "https://arxiv.org/pdf/2505.24239", "abs": "https://arxiv.org/abs/2505.24239", "authors": ["Sana Ebrahimi", "Mohsen Dehghankar", "Abolfazl Asudeh"], "title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "While multi-agent LLM systems show strong capabilities in various domains,\nthey are highly vulnerable to adversarial and low-performing agents. To resolve\nthis issue, in this paper, we introduce a general and adversary-resistant\nmulti-agent LLM framework based on credibility scoring. We model the\ncollaborative query-answering process as an iterative game, where the agents\ncommunicate and contribute to a final system output. Our system associates a\ncredibility score that is used when aggregating the team outputs. The\ncredibility scores are learned gradually based on the past contributions of\neach agent in query answering. Our experiments across multiple tasks and\nsettings demonstrate our system's effectiveness in mitigating adversarial\ninfluence and enhancing the resilience of multi-agent cooperation, even in the\nadversary-majority settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u4fe1\u8bc4\u5206\u7684\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u4ee5\u589e\u5f3a\u7cfb\u7edf\u5bf9\u6297\u6027\u4ee3\u7406\u7684\u62b5\u6297\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u5404\u4e2a\u9886\u57df\u5c55\u73b0\u4e86\u5f3a\u5927\u80fd\u529b\uff0c\u4f46\u5bf9\u4e8e\u5bf9\u6297\u6027\u53ca\u4f4e\u6027\u80fd\u7684\u4ee3\u7406\u975e\u5e38\u8106\u5f31\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u4fe1\u8bc4\u5206\u7684\u901a\u7528\u4e14\u6297\u5bf9\u6297\u7684\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u3002", "method": "\u6211\u4eec\u5c06\u534f\u4f5c\u67e5\u8be2\u56de\u7b54\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u8fed\u4ee3\u6e38\u620f\uff0c\u4ee3\u7406\u4e4b\u95f4\u8fdb\u884c\u901a\u4fe1\u5e76\u8d21\u732e\u4e8e\u6700\u7ec8\u7684\u7cfb\u7edf\u8f93\u51fa\u3002\u7cfb\u7edf\u5f15\u5165\u4e86\u53ef\u4fe1\u8bc4\u5206\u673a\u5236\uff0c\u5728\u56e2\u961f\u8f93\u51fa\u805a\u5408\u65f6\u4f7f\u7528\u3002\u53ef\u4fe1\u8bc4\u5206\u662f\u57fa\u4e8e\u6bcf\u4e2a\u4ee3\u7406\u5728\u67e5\u8be2\u56de\u7b54\u4e2d\u8fc7\u53bb\u7684\u8d21\u732e\u9010\u6b65\u5b66\u4e60\u5f97\u51fa\u7684\u3002", "result": "\u6211\u4eec\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u591a\u4efb\u52a1\u548c\u591a\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\u6709\u6548\uff0c\u80fd\u591f\u51cf\u8f7b\u5bf9\u6297\u6027\u5f71\u54cd\uff0c\u5e76\u589e\u5f3a\u591a\u4ee3\u7406\u5408\u4f5c\u7684\u97e7\u6027\uff0c\u5373\u4f7f\u5728\u654c\u5bf9\u65b9\u5360\u591a\u6570\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u6211\u4eec\u7684\u7cfb\u7edf\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u8bbe\u7f6e\u4e2d\u90fd\u663e\u793a\u51fa\u4e86\u6709\u6548\u6027\uff0c\u4e0d\u4ec5\u80fd\u591f\u51cf\u8f7b\u5bf9\u6297\u6027\u4ee3\u7406\u7684\u5f71\u54cd\uff0c\u8fd8\u53ef\u4ee5\u589e\u5f3a\u591a\u4ee3\u7406\u5408\u4f5c\u7684\u97e7\u6027\uff0c\u5373\u4f7f\u662f\u5728\u654c\u5bf9\u65b9\u5360\u591a\u6570\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.23885", "pdf": "https://arxiv.org/pdf/2505.23885", "abs": "https://arxiv.org/abs/2505.23885", "authors": ["Mengkang Hu", "Yuhang Zhou", "Wendong Fan", "Yuzhou Nie", "Bowei Xia", "Tao Sun", "Ziyu Ye", "Zhaoxuan Jin", "Yingru Li", "Qiguang Chen", "Zeyu Zhang", "Yifeng Wang", "Qianshuo Ye", "Bernard Ghanem", "Ping Luo", "Guohao Li"], "title": "OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation", "categories": ["cs.AI", "cs.CL"], "comment": "Project Page: https://github.com/camel-ai/owl", "summary": "Large Language Model (LLM)-based multi-agent systems show promise for\nautomating real-world tasks but struggle to transfer across domains due to\ntheir domain-specific nature. Current approaches face two critical\nshortcomings: they require complete architectural redesign and full retraining\nof all components when applied to new domains. We introduce Workforce, a\nhierarchical multi-agent framework that decouples strategic planning from\nspecialized execution through a modular architecture comprising: (i) a\ndomain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask\nmanagement, and (iii) specialized Workers with domain-specific tool-calling\ncapabilities. This decoupling enables cross-domain transferability during both\ninference and training phases: During inference, Workforce seamlessly adapts to\nnew domains by adding or modifying worker agents; For training, we introduce\nOptimized Workforce Learning (OWL), which improves generalization across\ndomains by optimizing a domain-agnostic planner with reinforcement learning\nfrom real-world feedback. To validate our approach, we evaluate Workforce on\nthe GAIA benchmark, covering various realistic, multi-domain agentic tasks.\nExperimental results demonstrate Workforce achieves open-source\nstate-of-the-art performance (69.70%), outperforming commercial systems like\nOpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model\nachieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to\nGPT-4o on challenging tasks. To summarize, by enabling scalable generalization\nand modular domain transfer, our work establishes a foundation for the next\ngeneration of general-purpose AI assistants.", "AI": {"tldr": "Workforce\u662f\u4e00\u79cd\u6a21\u5757\u5316\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u6218\u7565\u89c4\u5212\u548c\u6267\u884c\u5b9e\u73b0\u8de8\u9886\u57df\u8fc1\u79fb\uff0c\u5e76\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u65e0\u6cd5\u8de8\u9886\u57df\u8fc1\u79fb\uff0c\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u67b6\u6784\u548c\u91cd\u65b0\u8bad\u7ec3\u7ec4\u4ef6\u3002", "method": "\u5f15\u5165Workforce\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u8de8\u9886\u57df\u8fc1\u79fb\uff1b\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u9886\u57df\u65e0\u5173\u7684\u89c4\u5212\u5668\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aWorkforce\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u5f00\u6e90\u9886\u57df\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0869.70%\uff09\uff0c\u8d85\u8fc7\u4e86OpenAI\u7684Deep Research 2.34%\u3002", "conclusion": "\u7814\u7a76\u901a\u8fc7\u6a21\u5757\u5316\u67b6\u6784\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u6cdb\u5316\u548c\u8de8\u9886\u57df\u8fc1\u79fb\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u901a\u7528\u4eba\u5de5\u667a\u80fd\u52a9\u624b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2505.23788", "pdf": "https://arxiv.org/pdf/2505.23788", "abs": "https://arxiv.org/abs/2505.23788", "authors": ["Aakash Sen Sharma", "Debdeep Sanyal", "Priyansh Srivastava", "Sundar Atreya H.", "Shirish Karande", "Mohan Kankanhalli", "Murari Mandal"], "title": "Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework", "categories": ["cs.CL", "cs.AI"], "comment": "30 Pages", "summary": "Large language models (LLMs) commonly risk copyright infringement by\nreproducing protected content verbatim or with insufficient transformative\nmodifications, posing significant ethical, legal, and practical concerns.\nCurrent inference-time safeguards predominantly rely on restrictive\nrefusal-based filters, often compromising the practical utility of these\nmodels. To address this, we collaborated closely with intellectual property\nexperts to develop FUA-LLM (Fair Use Aligned Language Models), a\nlegally-grounded framework explicitly designed to align LLM outputs with\nfair-use doctrine. Central to our method is FairUseDB, a carefully constructed\ndataset containing 18,000 expert-validated examples covering nine realistic\ninfringement scenarios. Leveraging this dataset, we apply Direct Preference\nOptimization (DPO) to fine-tune open-source LLMs, encouraging them to produce\nlegally compliant and practically useful alternatives rather than resorting to\nblunt refusal. Recognizing the shortcomings of traditional evaluation metrics,\nwe propose new measures: Weighted Penalty Utility and Compliance Aware Harmonic\nMean (CAH) to balance infringement risk against response utility. Extensive\nquantitative experiments coupled with expert evaluations confirm that FUA-LLM\nsubstantially reduces problematic outputs (up to 20\\%) compared to\nstate-of-the-art approaches, while preserving real-world usability.", "AI": {"tldr": "FUA-LLM framework aligns LLM outputs with fair-use doctrine using FairUseDB and DPO, leading to a 20% reduction in problematic outputs compared to existing methods.", "motivation": "The motivation is to address the ethical, legal, and practical concerns of copyright infringement by LLMs and to provide a solution that doesn't merely rely on refusal-based filters, which limit utility.", "method": "The paper introduces FUA-LLM, which leverages a legally grounded framework and FairUseDB for fine-tuning open-source LLMs using Direct Preference Optimization (DPO). New evaluation metrics, Weighted Penalty Utility, and Compliance Aware Harmonic Mean (CAH), are proposed.", "result": "FUA-LLM substantially reduces copyright infringement risks in LLM outputs while maintaining practical utility, as proven by extensive quantitative experiments and expert evaluations.", "conclusion": "FUA-LLM can reduce problematic outputs by up to 20% compared to current state-of-the-art approaches while maintaining usability."}}
{"id": "2505.23859", "pdf": "https://arxiv.org/pdf/2505.23859", "abs": "https://arxiv.org/abs/2505.23859", "authors": ["Wenju Sun", "Qingyong Li", "Wen Wang", "Yang Liu", "Yangli-ao Geng", "Boyang Li"], "title": "Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task model merging aims to consolidate knowledge from multiple\nfine-tuned task-specific experts into a unified model while minimizing\nperformance degradation. Existing methods primarily approach this by minimizing\ndifferences between task-specific experts and the unified model, either from a\nparameter-level or a task-loss perspective. However, parameter-level methods\nexhibit a significant performance gap compared to the upper bound, while\ntask-loss approaches entail costly secondary training procedures. In contrast,\nwe observe that performance degradation closely correlates with feature drift,\ni.e., differences in feature representations of the same sample caused by model\nmerging. Motivated by this observation, we propose Layer-wise Optimal Task\nVector Merging (LOT Merging), a technique that explicitly minimizes feature\ndrift between task-specific experts and the unified model in a layer-by-layer\nmanner. LOT Merging can be formulated as a convex quadratic optimization\nproblem, enabling us to analytically derive closed-form solutions for the\nparameters of linear and normalization layers. Consequently, LOT Merging\nachieves efficient model consolidation through basic matrix operations.\nExtensive experiments across vision and vision-language benchmarks demonstrate\nthat LOT Merging significantly outperforms baseline methods, achieving\nimprovements of up to 4.4% (ViT-B/32) over state-of-the-art approaches.", "AI": {"tldr": "\u5f15\u5165LOT Merging\u65b9\u6cd5\uff0c\u901a\u8fc7\u51cf\u5c11\u7279\u5f81\u6f02\u79fb\u4f18\u5316\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\uff0c\u6027\u80fd\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6574\u5408\u591a\u4e2a\u4efb\u52a1\u7279\u5b9a\u4e13\u5bb6\u4e3a\u7edf\u4e00\u6a21\u578b\u65f6\uff0c\u8981\u4e48\u5728\u53c2\u6570\u7ea7\u522b\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u8981\u4e48\u4ee3\u4ef7\u6602\u8d35\u3002\u9274\u4e8e\u6027\u80fd\u4e0b\u964d\u4e0e\u6a21\u578b\u5408\u5e76\u5f15\u8d77\u7684\u7279\u5f81\u6f02\u79fb\u5bc6\u5207\u76f8\u5173\uff0c\u6545\u800c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u6709\u6548\u51cf\u5c11\u7279\u5f81\u6f02\u79fb\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aLayer-wise Optimal Task Vector Merging\uff08LOT Merging\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u5206\u6790\u51cf\u5c11\u6a21\u578b\u5408\u5e76\u8fc7\u7a0b\u4e2d\u7684\u7279\u5f81\u6f02\u79fb\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u88ab\u8868\u8ff0\u4e3a\u51f8\u4e8c\u6b21\u4f18\u5316\u95ee\u9898\uff0c\u5141\u8bb8\u89e3\u6790\u5bfc\u51fa\u7ebf\u6027\u548c\u5f52\u4e00\u5316\u5c42\u7684\u53c2\u6570\u7684\u95ed\u5f0f\u89e3\u3002\u5408\u5e76\u901a\u8fc7\u57fa\u672c\u7684\u77e9\u9635\u8fd0\u7b97\u5b9e\u73b0\u9ad8\u6548\u7684\u6a21\u578b\u6574\u5408\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cLOT Merging\u5728\u89c6\u89c9\u548c\u89c6\u89c9-\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8868\u73b0\u63d0\u5347\u53ef\u8fbe4.4%\uff08ViT-B/32\uff09\u3002", "conclusion": "\u901a\u8fc7\u5206\u5c42\u4f18\u5316\u4efb\u52a1\u5411\u91cf\u5408\u5e76\uff08LOT Merging\uff09\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u8fc7\u7a0b\u4e2d\u7684\u7279\u5f81\u6f02\u79fb\u548c\u6027\u80fd\u4e0b\u964d\u3002\u5728\u591a\u4e2a\u89c6\u89c9\u548c\u89c6\u89c9-\u8bed\u8a00\u57fa\u51c6\u4e0a\uff0cLOT Merging\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u5347\u5e45\u5ea6\u53ef\u8fbe4.4%\u3002"}}
{"id": "2505.24686", "pdf": "https://arxiv.org/pdf/2505.24686", "abs": "https://arxiv.org/abs/2505.24686", "authors": ["Enrico Caprioglio", "Luc Berthouze"], "title": "Synergistic motifs in linear Gaussian systems", "categories": ["physics.soc-ph", "nlin.AO"], "comment": null, "summary": "Higher-order interdependencies are central features of complex systems, yet a\nmechanistic explanation for their emergence remains elusive. For linear\nGaussian systems of arbitrary dimension, we derive an expression for\nsynergy-dominance in terms of signed network motifs in the system's correlation\nmatrix. We prove that antibalanced correlational structures ensure\nsynergy-dominance and further show that antibalanced triads in the dyadic\ninteraction matrix of Ornstein-Uhlenbeck processes are necessary for\nsynergy-dominance. Our results demonstrate that pairwise interactions alone can\ngive rise to synergistic information in the absence of explicit higher-order\nmechanisms, and highlight structural balance theory as an instrumental\nconceptual framework to study higher-order interdependencies.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u6210\u5bf9\u4f5c\u7528\u5982\u4f55\u751f\u6210\u534f\u540c\u4fe1\u606f\uff0c\u7a81\u51fa\u7ed3\u6784\u5e73\u8861\u7406\u8bba\u5bf9\u9ad8\u9636\u4f9d\u8d56\u6027\u7814\u7a76\u7684\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u9ad8\u9636\u76f8\u4e92\u4f9d\u8d56\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u51fa\u73b0\u7684\u673a\u68b0\u89e3\u91ca\u4ecd\u4e0d\u660e\u786e\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u63a2\u7a76\u534f\u540c\u4f18\u52bf\u7684\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5bf9\u4efb\u610f\u7ef4\u5ea6\u7684\u7ebf\u6027\u9ad8\u65af\u7cfb\u7edf\uff0c\u63a8\u5bfc\u51fa\u5728\u7cfb\u7edf\u76f8\u5173\u77e9\u9635\u4e2d\u7684\u7b26\u53f7\u7f51\u7edc\u57fa\u5143\u65b9\u9762\u7684\u534f\u540c-\u4e3b\u5bfc\u8868\u8fbe\u5f0f\u3002", "result": "\u5728Ornstein-Uhlenbeck\u8fc7\u7a0b\u7684\u4e8c\u5143\u4ea4\u4e92\u77e9\u9635\u4e2d\uff0c\u8bc1\u660e\u4e86\u53cd\u5e73\u8861\u76f8\u5173\u7ed3\u6784\u786e\u4fdd\u534f\u540c-\u4e3b\u5bfc\uff0c\u5e76\u4e14\u53cd\u5e73\u8861\u4e09\u5143\u7ec4\u5bf9\u4e8e\u534f\u540c-\u4e3b\u5bfc\u662f\u5fc5\u8981\u7684\u3002", "conclusion": "\u6210\u5bf9\u7684\u76f8\u4e92\u4f5c\u7528\u53ef\u4ee5\u5728\u6ca1\u6709\u663e\u5f0f\u9ad8\u9636\u673a\u5236\u7684\u60c5\u51b5\u4e0b\u4ea7\u751f\u534f\u540c\u4fe1\u606f\uff0c\u7ed3\u6784\u5e73\u8861\u7406\u8bba\u662f\u7814\u7a76\u9ad8\u9636\u76f8\u4e92\u4f9d\u8d56\u6027\u7684\u91cd\u8981\u6982\u5ff5\u6846\u67b6\u3002"}}
{"id": "2505.24265", "pdf": "https://arxiv.org/pdf/2505.24265", "abs": "https://arxiv.org/abs/2505.24265", "authors": ["Harsh Goel", "Mohammad Omama", "Behdad Chalaki", "Vaishnav Tadiparthi", "Ehsan Moradi Pari", "Sandeep Chinchali"], "title": "R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning", "categories": ["cs.MA"], "comment": "21 pages, To appear in the International Conference of Machine\n  Learning (ICML 2025)", "summary": "Multi-agent reinforcement learning (MARL) has achieved significant progress\nin large-scale traffic control, autonomous vehicles, and robotics. Drawing\ninspiration from biological systems where roles naturally emerge to enable\ncoordination, role-based MARL methods have been proposed to enhance cooperation\nlearning for complex tasks. However, existing methods exclusively derive roles\nfrom an agent's past experience during training, neglecting their influence on\nits future trajectories. This paper introduces a key insight: an agent's role\nshould shape its future behavior to enable effective coordination. Hence, we\npropose Role Discovery and Diversity through Dynamics Models (R3DM), a novel\nrole-based MARL framework that learns emergent roles by maximizing the mutual\ninformation between agents' roles, observed trajectories, and expected future\nbehaviors. R3DM optimizes the proposed objective through contrastive learning\non past trajectories to first derive intermediate roles that shape intrinsic\nrewards to promote diversity in future behaviors across different roles through\na learned dynamics model. Benchmarking on SMAC and SMACv2 environments\ndemonstrates that R3DM outperforms state-of-the-art MARL approaches, improving\nmulti-agent coordination to increase win rates by up to 20%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u89d2\u8272\u57fa\u7840MARL\u6846\u67b6R3DM\uff0c\u901a\u8fc7\u4f18\u5316\u89d2\u8272\u548c\u8f68\u8ff9\u6765\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u80dc\u7387\u3002", "motivation": "\u73b0\u6709\u89d2\u8272\u57fa\u7840\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u4e8e\u667a\u80fd\u4f53\u7684\u8fc7\u5f80\u7ecf\u9a8c\u6765\u51b3\u5b9a\u89d2\u8272\uff0c\u5ffd\u89c6\u4e86\u89d2\u8272\u5bf9\u672a\u6765\u8f68\u8ff9\u7684\u5f71\u54cd\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u4f7f\u5f97\u667a\u80fd\u4f53\u7684\u89d2\u8272\u80fd\u591f\u6709\u6548\u5730\u5f71\u54cd\u5176\u672a\u6765\u884c\u4e3a\uff0c\u4fc3\u8fdb\u534f\u540c\u5de5\u4f5c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89d2\u8272\u57fa\u7840\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u79f0\u4e3aR3DM\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6700\u5927\u5316\u667a\u80fd\u4f53\u89d2\u8272\u3001\u89c2\u5bdf\u8f68\u8ff9\u548c\u9884\u671f\u672a\u6765\u884c\u4e3a\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u5b66\u4e60\u6d8c\u73b0\u89d2\u8272\u3002\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u76ee\u6807\uff0c\u4ee5\u8fc7\u53bb\u8f68\u8ff9\u4e3a\u57fa\u7840\u63a8\u5bfc\u4e2d\u95f4\u89d2\u8272\uff0c\u8fdb\u800c\u901a\u8fc7\u5b66\u4e60\u52a8\u6001\u6a21\u578b\u4fc3\u8fdb\u4e0d\u540c\u89d2\u8272\u7684\u672a\u6765\u884c\u4e3a\u591a\u6837\u6027\u3002", "result": "\u5728SMAC\u548cSMACv2\u73af\u5883\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cR3DM\u80fd\u591f\u8d85\u8d8a\u76ee\u524d\u6700\u5148\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u80dc\u7387\u63d0\u9ad8\u6700\u591a20%\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u65b0\u7684\u89d2\u8272\u57fa\u7840MARL\u6846\u67b6R3DM\u5b9e\u73b0\u4e86\u901a\u8fc7\u4f18\u5316\u667a\u80fd\u4f53\u89d2\u8272\u548c\u8f68\u8ff9\u6765\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6548\u679c\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u80dc\u7387\u3002"}}
{"id": "2505.23946", "pdf": "https://arxiv.org/pdf/2505.23946", "abs": "https://arxiv.org/abs/2505.23946", "authors": ["Yuanzhe Liu", "Ryan Deng", "Tim Kaler", "Xuhao Chen", "Charles E. Leiserson", "Yao Ma", "Jie Chen"], "title": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SE"], "comment": null, "summary": "Recent studies show that LLMs possess different skills and specialize in\ndifferent tasks. In fact, we observe that their varied performance occur in\nseveral levels of granularity. For example, in the code optimization task, code\nLLMs excel at different optimization categories and no one dominates others.\nThis observation prompts the question of how one leverages multiple LLM agents\nto solve a coding problem without knowing their complementary strengths a\npriori. We argue that a team of agents can learn from each other's successes\nand failures so as to improve their own performance. Thus, a lesson is the\nknowledge produced by an agent and passed on to other agents in the collective\nsolution process. We propose a lesson-based collaboration framework, design the\nlesson solicitation--banking--selection mechanism, and demonstrate that a team\nof small LLMs with lessons learned can outperform a much larger LLM and other\nmulti-LLM collaboration methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba9LLM\u76f8\u4e92\u5b66\u4e60\u4ee5\u63d0\u9ad8\u7f16\u7801\u4efb\u52a1\u8868\u73b0\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u5c0f\u578bLLM\u7ec4\u961f\u540e\u80dc\u8fc7\u5927\u578bLLM\u3002", "motivation": "\u4e0d\u540cLLM\u5728\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u63d0\u793a\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u591aLLM\u534f\u4f5c\u6765\u63d0\u5347\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5229\u7528\u672a\u660e\u786e\u77e5\u9053\u5b83\u4eec\u4e92\u8865\u4f18\u52bf\u7684\u591a\u4e2aLLM\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u8bfe\u7a0b\u5f81\u96c6\u3001\u50a8\u5b58\u548c\u9009\u62e9\u673a\u5236\u7684\u534f\u4f5c\u6846\u67b6\u6765\u5b9e\u73b0LLM\u7684\u534f\u4f5c\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u7684\u5c0f\u578bLLM\u56e2\u961f\u5728\u89e3\u51b3\u7f16\u7801\u95ee\u9898\u65f6\u80fd\u591f\u8d85\u8fc7\u4e00\u4e2a\u5927\u578b\u7684LLM\uff0c\u4ee5\u53ca\u5176\u4ed6\u591aLLM\u534f\u4f5c\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bfe\u7a0b\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u4f7f\u5f97\u591a\u4e2a\u5c0f\u578bLLM\u53ef\u4ee5\u901a\u8fc7\u76f8\u4e92\u5b66\u4e60\u5f7c\u6b64\u7684\u6210\u529f\u548c\u5931\u8d25\uff0c\u6700\u7ec8\u5728\u7f16\u7801\u95ee\u9898\u7684\u89e3\u51b3\u4e0a\u8d85\u8fc7\u5355\u4e00\u5927\u578bLLM\u548c\u5176\u4ed6\u591aLLM\u534f\u4f5c\u65b9\u6cd5\u3002"}}
{"id": "2505.23789", "pdf": "https://arxiv.org/pdf/2505.23789", "abs": "https://arxiv.org/abs/2505.23789", "authors": ["Mingyu Huang", "Shasha Zhou", "Yuxuan Chen", "Ke Li"], "title": "Conversational Exploration of Literature Landscape with LitChat", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "We are living in an era of \"big literature\", where the volume of digital\nscientific publications is growing exponentially. While offering new\nopportunities, this also poses challenges for understanding literature\nlandscapes, as traditional manual reviewing is no longer feasible. Recent large\nlanguage models (LLMs) have shown strong capabilities for literature\ncomprehension, yet they are incapable of offering \"comprehensive, objective,\nopen and transparent\" views desired by systematic reviews due to their limited\ncontext windows and trust issues like hallucinations. Here we present LitChat,\nan end-to-end, interactive and conversational literature agent that augments\nLLM agents with data-driven discovery tools to facilitate literature\nexploration. LitChat automatically interprets user queries, retrieves relevant\nsources, constructs knowledge graphs, and employs diverse data-mining\ntechniques to generate evidence-based insights addressing user needs. We\nillustrate the effectiveness of LitChat via a case study on AI4Health,\nhighlighting its capacity to quickly navigate the users through large-scale\nliterature landscape with data-based evidence that is otherwise infeasible with\ntraditional means.", "AI": {"tldr": "LitChat\u662f\u4e00\u4e2a\u589e\u5f3a\u7248\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\uff0c\u5229\u7528\u6570\u636e\u9a71\u52a8\u7684\u53d1\u73b0\u6280\u672f\u5e2e\u52a9\u7528\u6237\u9ad8\u6548\u63a2\u7d22\u5927\u91cf\u6587\u732e\u3002", "motivation": "\u5728\u6570\u5b57\u5316\u79d1\u5b66\u51fa\u7248\u7269\u7206\u70b8\u6027\u589e\u957f\u7684\u65f6\u4ee3\uff0c\u4f20\u7edf\u7684\u4eba\u5de5\u5ba1\u9605\u5df2\u4e0d\u518d\u53ef\u884c\uff0c\u4e14\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u6587\u732e\u7406\u89e3\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u53ca\u53ef\u4fe1\u5ea6\u95ee\u9898\uff08\u5982\u5e7b\u89c9\uff09\uff0c\u65e0\u6cd5\u63d0\u4f9b\u7cfb\u7edf\u7efc\u8ff0\u6240\u9700\u7684\u5168\u9762\u3001\u5ba2\u89c2\u3001\u5f00\u653e\u548c\u900f\u660e\u7684\u89c6\u89d2\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u578b\u4e92\u52a8\u5bf9\u8bdd\u6587\u732e\u4ee3\u7406\u5de5\u5177\u2014\u2014LitChat\u3002LitChat\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u80fd\u529b\uff0c\u5229\u7528\u6570\u636e\u9a71\u52a8\u7684\u53d1\u73b0\u5de5\u5177\u8fdb\u884c\u6587\u732e\u63a2\u7d22\u3002\u5b83\u80fd\u591f\u81ea\u52a8\u89e3\u91ca\u7528\u6237\u67e5\u8be2\u3001\u68c0\u7d22\u76f8\u5173\u6765\u6e90\u3001\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u8fd0\u7528\u591a\u79cd\u6570\u636e\u6316\u6398\u6280\u672f\u751f\u6210\u57fa\u4e8e\u8bc1\u636e\u7684\u6d1e\u5bdf\u3002", "result": "LitChat\u80fd\u591f\u81ea\u52a8\u89e3\u8bfb\u7528\u6237\u7684\u67e5\u8be2\u3001\u68c0\u7d22\u76f8\u5173\u6587\u732e\u3001\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u5e94\u7528\u591a\u79cd\u6570\u636e\u6316\u6398\u6280\u672f\uff0c\u63d0\u4f9b\u9488\u5bf9\u7528\u6237\u9700\u6c42\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u6d1e\u5bdf\u3002\u901a\u8fc7AI4Health\u7684\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\uff0cLitChat\u53ef\u4ee5\u6709\u6548\u5e2e\u52a9\u7528\u6237\u5728\u5e9e\u5927\u7684\u6587\u732e\u6d77\u6d0b\u4e2d\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u63a2\u7d22\u3002", "conclusion": "LitChat\u901a\u8fc7\u4e00\u4e2a\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5b83\u5728AI4Health\u9886\u57df\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u5176\u80fd\u591f\u5feb\u901f\u5f15\u5bfc\u7528\u6237\u5728\u5927\u89c4\u6a21\u6587\u732e\u73af\u5883\u4e2d\u627e\u5230\u57fa\u4e8e\u6570\u636e\u7684\u8bc1\u636e\uff0c\u8fd9\u5728\u4f20\u7edf\u65b9\u6cd5\u4e2d\u662f\u96be\u4ee5\u5b9e\u73b0\u7684\u3002"}}
{"id": "2505.23861", "pdf": "https://arxiv.org/pdf/2505.23861", "abs": "https://arxiv.org/abs/2505.23861", "authors": ["Renye Zhang", "Mengyun Yang", "Qichang Zhao", "Jianxin Wang"], "title": "BiBLDR: Bidirectional Behavior Learning for Drug Repositioning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Drug repositioning aims to identify potential new indications for existing\ndrugs to reduce the time and financial costs associated with developing new\ndrugs. Most existing deep learning-based drug repositioning methods\npredominantly utilize graph-based representations. However, graph-based drug\nrepositioning methods struggle to perform effective inference in cold-start\nscenarios involving novel drugs because of the lack of association information\nwith the diseases. Unlike traditional graph-based approaches, we propose a\nbidirectional behavior learning strategy for drug repositioning, known as\nBiBLDR. This innovative framework redefines drug repositioning as a behavior\nsequential learning task to capture drug-disease interaction patterns. First,\nwe construct bidirectional behavioral sequences based on drug and disease\nsides. The consideration of bidirectional information ensures a more meticulous\nand rigorous characterization of the behavioral sequences. Subsequently, we\npropose a two-stage strategy for drug repositioning. In the first stage, we\nconstruct prototype spaces to characterize the representational attributes of\ndrugs and diseases. In the second stage, these refined prototypes and\nbidirectional behavior sequence data are leveraged to predict potential\ndrug-disease associations. Based on this learning approach, the model can more\nrobustly and precisely capture the interactive relationships between drug and\ndisease features from bidirectional behavioral sequences. Extensive experiments\ndemonstrate that our method achieves state-of-the-art performance on benchmark\ndatasets. Meanwhile, BiBLDR demonstrates significantly superior performance\ncompared to previous methods in cold-start scenarios. Our code is published in\nhttps://github.com/Renyeeah/BiBLDR.", "AI": {"tldr": "\u63d0\u51faBiBLDR\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u5411\u884c\u4e3a\u5b66\u4e60\u7b56\u7565\uff0c\u63d0\u9ad8\u836f\u7269\u91cd\u65b0\u5b9a\u4f4d\u5728\u51b7\u542f\u52a8\u60c5\u5883\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u836f\u7269\u91cd\u65b0\u5b9a\u4f4d\u65b9\u6cd5\u5728\u5904\u7406\u65b0\u836f\u7269\u7684\u51b7\u542f\u52a8\u60c5\u5883\u65f6\u6548\u80fd\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6709\u6548\u6355\u6349\u836f\u7269-\u75be\u75c5\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5411\u884c\u4e3a\u5b66\u4e60\u7b56\u7565\uff0c\u79f0\u4e3aBiBLDR\u3002\u9996\u5148\u6784\u5efa\u53cc\u5411\u884c\u4e3a\u5e8f\u5217\uff0c\u7136\u540e\u901a\u8fc7\u53cc\u9636\u6bb5\u7b56\u7565\u9884\u6d4b\u6f5c\u5728\u7684\u836f\u7269-\u75be\u75c5\u5173\u8054\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff0cBiBLDR\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u9886\u5148\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u51b7\u542f\u52a8\u60c5\u5883\u4e2d\uff0c\u8868\u73b0\u51fa\u4e86\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "BiBLDR\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u51b7\u542f\u52a8\u60c5\u5883\u4e0b\uff0c\u6027\u80fd\u663e\u8457\u8d85\u8fc7\u4e4b\u524d\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.18334", "pdf": "https://arxiv.org/pdf/2505.18334", "abs": "https://arxiv.org/abs/2505.18334", "authors": ["Jiaxun Cui", "Chen Tang", "Jarrett Holtz", "Janice Nguyen", "Alessandro G. Allievi", "Hang Qiu", "Peter Stone"], "title": "Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "Past work has demonstrated that autonomous vehicles can drive more safely if\nthey communicate with one another than if they do not. However, their\ncommunication has often not been human-understandable. Using natural language\nas a vehicle-to-vehicle (V2V) communication protocol offers the potential for\nautonomous vehicles to drive cooperatively not only with each other but also\nwith human drivers. In this work, we propose a suite of traffic tasks in\nautonomous driving where vehicles in a traffic scenario need to communicate in\nnatural language to facilitate coordination in order to avoid an imminent\ncollision and/or support efficient traffic flow. To this end, this paper\nintroduces a novel method, LLM+Debrief, to learn a message generation and\nhigh-level decision-making policy for autonomous vehicles through multi-agent\ndiscussion. To evaluate LLM agents for driving, we developed a gym-like\nsimulation environment that contains a range of driving scenarios. Our\nexperimental results demonstrate that LLM+Debrief is more effective at\ngenerating meaningful and human-understandable natural language messages to\nfacilitate cooperation and coordination than a zero-shot LLM agent. Our code\nand demo videos are available at https://talking-vehicles.github.io/.", "AI": {"tldr": "The paper proposes LLM+Debrief method, enabling autonomous vehicles to communicate in natural language for better coordination. It outperforms zero-shot LLMs in generating human-understandable messages, improving cooperation in driving scenarios.", "motivation": "To facilitate autonomous vehicles in communicating in a human-understandable way, thus improving cooperative driving with both autonomous and human drivers.", "method": "Introduces LLM+Debrief, a novel method for learning message generation and high-level decision-making policy through multi-agent discussion.", "result": "LLM+Debrief outperforms zero-shot LLM agents in generating meaningful language messages for coordination among vehicles.", "conclusion": "LLM+Debrief is more effective at generating meaningful and human-understandable natural language messages for vehicle coordination than a zero-shot LLM agent."}}
{"id": "2505.23950", "pdf": "https://arxiv.org/pdf/2505.23950", "abs": "https://arxiv.org/abs/2505.23950", "authors": ["Boyuan Chen", "Donghai Hong", "Jiaming Ji", "Jiacheng Zheng", "Bowen Dong", "Jiayi Zhou", "Kaile Wang", "Juntao Dai", "Xuyao Wang", "Wenqi Chen", "Qirui Zheng", "Wenxin Li", "Sirui Han", "Yike Guo", "Yaodong Yang"], "title": "InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback", "categories": ["cs.AI"], "comment": null, "summary": "As multimodal large models (MLLMs) continue to advance across challenging\ntasks, a key question emerges: What essential capabilities are still missing? A\ncritical aspect of human learning is continuous interaction with the\nenvironment -- not limited to language, but also involving multimodal\nunderstanding and generation. To move closer to human-level intelligence,\nmodels must similarly support multi-turn, multimodal interaction. In\nparticular, they should comprehend interleaved multimodal contexts and respond\ncoherently in ongoing exchanges. In this work, we present an initial\nexploration through the InterMT -- the first preference dataset for multi-turn\nmultimodal interaction, grounded in real human feedback. In this exploration,\nwe particularly emphasize the importance of human oversight, introducing expert\nannotations to guide the process, motivated by the fact that current MLLMs lack\nsuch complex interactive capabilities. InterMT captures human preferences at\nboth global and local levels into nine sub-dimensions, consists of 15.6k\nprompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled\npreference pairs. To compensate for the lack of capability for multi-modal\nunderstanding and generation, we introduce an agentic workflow that leverages\ntool-augmented MLLMs to construct multi-turn QA instances. To further this\ngoal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting\njudges with multi-turn, multimodal tasks. We demonstrate the utility of\n\\InterMT through applications such as judge moderation and further reveal the\nmulti-turn scaling law of judge model. We hope the open-source of our data can\nhelp facilitate further research on aligning current MLLMs to the next step.\nOur project website can be found at https://pku-intermt.github.io .", "AI": {"tldr": "\u8bba\u6587\u63a2\u7d22\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u591a\u8f6e\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u7684MLLMs\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u57fa\u51c6\uff0c\u5f3a\u8c03\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u548c\u4e13\u5bb6\u6807\u6ce8\u6765\u63d0\u5347MLLMs\u7684\u4e92\u52a8\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u7f3a\u5c11\u4e0e\u73af\u5883\u8fdb\u884c\u591a\u8f6e\u3001\u591a\u6a21\u6001\u5bf9\u8bdd\u7684\u80fd\u529b\uff0c\u800c\u8fd9\u5bf9\u4e8e\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u667a\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5bf9\u8fd9\u9879\u80fd\u529b\u7684\u589e\u5f3a\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86InterMT\u6570\u636e\u96c6\u548cInterMT-Bench\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u5de5\u5177\u589e\u5f3a\u7684MLLMs\u6784\u9020\u591a\u8f6e\u95ee\u7b54\u5b9e\u4f8b\uff0c\u5e76\u7528\u4eba\u7c7b\u504f\u597d\u8fdb\u884c\u6807\u6ce8\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u591a\u8f6e\u591a\u6a21\u6001\u4efb\u52a1\u5904\u7406\u80fd\u529b\u3002", "result": "InterMT\u6570\u636e\u96c6\u5305\u542b15,600\u4e2a\u63d0\u793a\u300152,600\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u5b9e\u4f8b\u548c32,400\u4e2a\u4eba\u7c7b\u6807\u6ce8\u7684\u504f\u597d\u5bf9\uff0c\u4e14\u901a\u8fc7\u5de5\u5177\u589e\u5f3aMLLMs\u6784\u5efa\u591a\u8f6eQA\u5b9e\u4f8b\uff0c\u8bc1\u660e\u6570\u636e\u96c6\u5728\u6cd5\u5b98\u8c03\u8282\u7b49\u5e94\u7528\u4e2d\u7684\u6548\u7528\uff0c\u63ed\u793a\u6cd5\u5b98\u6a21\u578b\u7684\u591a\u8f6e\u6269\u5c55\u89c4\u5f8b\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u57fa\u51c6\u6765\u63a8\u52a8\u591a\u8f6e\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\u7684\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u4eba\u7c7b\u53cd\u9988\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4e13\u5bb6\u6807\u6ce8\uff0c\u5f3a\u8c03\u63d0\u5347MLLMs\u7684\u4e92\u52a8\u80fd\u529b\u3002"}}
{"id": "2505.23790", "pdf": "https://arxiv.org/pdf/2505.23790", "abs": "https://arxiv.org/abs/2505.23790", "authors": ["Shaojie Wang", "Sirui Ding", "Na Zou"], "title": "Rethinking the Understanding Ability across LLMs through Mutual Information", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have revolutionized natural\nlanguage processing, yet evaluating their intrinsic linguistic understanding\nremains challenging. Moving beyond specialized evaluation tasks, we propose an\ninformation-theoretic framework grounded in mutual information (MI) to achieve\nthis. We formalize the understanding as MI between an input sentence and its\nlatent representation (sentence-level MI), measuring how effectively input\ninformation is preserved in latent representation. Given that LLMs learn\nembeddings for individual tokens, we decompose sentence-level MI into\ntoken-level MI between tokens and sentence embeddings, establishing theoretical\nbounds connecting these measures. Based on this foundation, we theoretically\nderive a computable lower bound for token-level MI using Fano's inequality,\nwhich directly relates to token-level recoverability-the ability to predict\noriginal tokens from sentence embedding. We implement this recoverability task\nto comparatively measure MI across different LLMs, revealing that encoder-only\nmodels consistently maintain higher information fidelity than their\ndecoder-only counterparts, with the latter exhibiting a distinctive late-layer\n\"forgetting\" pattern where mutual information is first enhanced and then\ndiscarded. Moreover, fine-tuning to maximize token-level recoverability\nconsistently improves understanding ability of LLMs on tasks without\ntask-specific supervision, demonstrating that mutual information can serve as a\nfoundation for understanding and improving language model capabilities.", "AI": {"tldr": "\u4f7f\u7528\u4fe1\u606f\u8bba\u6846\u67b6\u901a\u8fc7\u4e92\u4fe1\u606f\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\uff0c\u7f16\u7801\u5668\u6a21\u578b\u4fdd\u6301\u8f83\u9ad8\u4fe1\u606f\u4fdd\u771f\u5ea6\uff0cfine-tuning\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u8be5\u7814\u7a76\u63d0\u51fa\u4ee5\u4e92\u4fe1\u606f\u4e3a\u57fa\u7840\u7684\u4fe1\u606f\u8bba\u6846\u67b6\u6765\u5b9e\u73b0\u3002", "method": "\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f(MI)\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u5185\u5728\u8bed\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u53ca\u57fa\u4e8eFano\u4e0d\u7b49\u5f0f\u7406\u8bba\u8ba1\u7b97token\u7ea7MI\u4e0b\u754c\uff0c\u901a\u8fc7\u5b9e\u65bd\u53ef\u6062\u590d\u6027\u4efb\u52a1\u6765\u6bd4\u8f83\u4e0d\u540cLLM\u7684MI\u3002", "result": "\u7f16\u7801\u5668\u6a21\u578b\u6bd4\u89e3\u7801\u5668\u6a21\u578b\u80fd\u4fdd\u6301\u66f4\u9ad8\u7684\u4fe1\u606f\u4fdd\u771f\u5ea6\uff0c\u800c\u540e\u8005\u8868\u73b0\u51fa\u72ec\u7279\u7684\u665a\u5c42\u201c\u9057\u5fd8\u201d\u6a21\u5f0f\uff1b\u8c03\u6574\u4ee5\u6700\u5927\u5316token\u7ea7\u53ef\u6062\u590d\u6027\u80fd\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "\u4e92\u4fe1\u606f\u53ef\u4ee5\u4f5c\u4e3a\u57fa\u7840\u6765\u7406\u89e3\u548c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002\u901a\u8fc7\u6700\u5927\u5316token\u7ea7\u53ef\u6062\u590d\u6027\uff0c\u5bf9LLM\u7684\u7406\u89e3\u80fd\u529b\u8fdb\u884c\u6539\u8fdb\uff0c\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u76d1\u7763\u3002"}}
{"id": "2505.23863", "pdf": "https://arxiv.org/pdf/2505.23863", "abs": "https://arxiv.org/abs/2505.23863", "authors": ["Chang Liu", "Bohao Zhao", "Jingtao Ding", "Huandong Wang", "Yong Li"], "title": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term forecasting of chaotic systems from short-term observations remains\na fundamental and underexplored challenge due to the intrinsic sensitivity to\ninitial conditions and the complex geometry of strange attractors. Existing\napproaches often rely on long-term training data or focus on short-term\nsequence correlations, struggling to maintain predictive stability and\ndynamical coherence over extended horizons. We propose PhyxMamba, a novel\nframework that integrates a Mamba-based state-space model with physics-informed\nprinciples to capture the underlying dynamics of chaotic systems. By\nreconstructing the attractor manifold from brief observations using time-delay\nembeddings, PhyxMamba extracts global dynamical features essential for accurate\nforecasting. Our generative training scheme enables Mamba to replicate the\nphysical process, augmented by multi-token prediction and attractor geometry\nregularization for physical constraints, enhancing prediction accuracy and\npreserving key statistical invariants. Extensive evaluations on diverse\nsimulated and real-world chaotic systems demonstrate that PhyxMamba delivers\nsuperior long-term forecasting and faithfully captures essential dynamical\ninvariants from short-term data. This framework opens new avenues for reliably\npredicting chaotic systems under observation-scarce conditions, with broad\nimplications across climate science, neuroscience, epidemiology, and beyond.\nOur code is open-source at https://github.com/tsinghua-fib-lab/PhyxMamba.", "AI": {"tldr": "PhyxMamba\u901a\u8fc7\u521b\u65b0\u7684\u6846\u67b6\u548c\u8bad\u7ec3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5728\u77ed\u671f\u89c2\u5bdf\u4e0b\u5bf9\u6df7\u6c8c\u7cfb\u7edf\u7684\u957f\u671f\u9884\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u957f\u65f6\u95f4\u8bad\u7ec3\u6570\u636e\u6216\u8005\u4e13\u6ce8\u4e8e\u77ed\u671f\u5e8f\u5217\u76f8\u5173\u6027\uff0c\u4f46\u96be\u4ee5\u5728\u957f\u671f\u9884\u6d4b\u4e2d\u4fdd\u6301\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u52a8\u6001\u4e00\u81f4\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPhyxMamba\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u57fa\u4e8eMamba\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e0e\u7269\u7406\u4fe1\u606f\u539f\u5219\uff0c\u4f7f\u7528\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u6765\u91cd\u5efa\u5438\u5f15\u5b50\u6d41\u5f62\uff0c\u4ece\u800c\u63d0\u53d6\u5168\u7403\u52a8\u6001\u7279\u5f81\u3002", "result": "\u5728\u591a\u79cd\u6a21\u62df\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cPhyxMamba\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u957f\u671f\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u80fd\u591f\u4ece\u77ed\u671f\u6570\u636e\u4e2d\u51c6\u786e\u6355\u6349\u52a8\u6001\u4e0d\u53d8\u91cf\u3002", "conclusion": "PhyxMamba\u80fd\u591f\u6709\u6548\u8fdb\u884c\u957f\u65f6\u95f4\u7684\u6df7\u6c8c\u7cfb\u7edf\u9884\u6d4b\uff0c\u5e76\u5728\u77ed\u671f\u6570\u636e\u4e0b\u5fe0\u5b9e\u6355\u6349\u52a8\u6001\u4e0d\u53d8\u91cf\u3002"}}
{"id": "2505.23846", "pdf": "https://arxiv.org/pdf/2505.23846", "abs": "https://arxiv.org/abs/2505.23846", "authors": ["Atanu Barai", "Stephan Eidenbenz", "Nandakishore Santhi"], "title": "Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations", "categories": ["cs.CL", "cs.MA"], "comment": null, "summary": "To fully leverage the potential of artificial intelligence (AI) systems in a\ntrustworthy manner, it is desirable to couple multiple AI and non-AI systems\ntogether seamlessly for constraining and ensuring correctness of the output.\nThis paper introduces a novel parallel discrete event simulation (PDES) based\nmethodology to combine multiple AI and non-AI agents in a causal, rule-based\nway. Our approach tightly integrates the concept of passage of time, with each\nagent considered as an entity in the PDES framework and responding to prior\nrequests from other agents. Such coupling mechanism enables the agents to work\nin a co-operative environment towards a common goal while many tasks run in\nparallel throughout the simulation. It further enables setting up boundaries to\nthe outputs of the AI agents by applying necessary dynamic constraints using\nnon-AI agents while allowing for scalability through deployment of hundreds of\nsuch agents in a larger compute cluster. Distributing smaller AI agents can\nenable extremely scalable simulations in the future, addressing local memory\nbottlenecks for model parameter storage. Within a PDES involving both AI and\nnon-AI agents, we break down the problem at hand into structured steps, when\nnecessary, providing a set of multiple choices to the AI agents, and then\nprogressively solve these steps towards a final goal. At each step, the non-AI\nagents act as unbiased auditors, verifying each action by the AI agents so that\ncertain rules of engagement are followed. We evaluate our approach by solving\nfour problems from four different domains and comparing the results with those\nfrom AI models alone. Our results show greater accuracy in solving problems\nfrom various domains where the AI models struggle to solve the problems solely\nby themselves. Results show that overall accuracy of our approach is 68% where\nas the accuracy of vanilla models is less than 23%.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7PDES\u65b9\u6cd5\uff0c\u5c06AI\u548c\u975eAI\u667a\u80fd\u4f53\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86\u89e3\u51b3\u5404\u79cd\u9886\u57df\u95ee\u9898\u7684\u51c6\u786e\u6027\uff0c\u8fbe\u523068%\uff0c\u800c\u5355\u7eafAI\u6a21\u578b\u4e0d\u8db323%\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u5229\u7528\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u6f5c\u529b\u5e76\u786e\u4fdd\u5176\u8f93\u51fa\u7684\u53ef\u4fe1\u5ea6\uff0c\u6709\u5fc5\u8981\u5c06\u591a\u91cdAI\u548c\u975eAI\u7cfb\u7edf\u65e0\u7f1d\u7ed3\u5408\uff0c\u4ee5\u7ea6\u675f\u548c\u4fdd\u8bc1\u8f93\u51fa\u7684\u6b63\u786e\u6027\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5e76\u884c\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\uff08PDES\uff09\u7684\u65b9\u6cd5\uff0c\u5c06\u591a\u4e2aAI\u548c\u975eAI\u7cfb\u7edf\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u4ee5\u56e0\u679c\u548c\u89c4\u5219\u4e3a\u57fa\u7840\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u65f6\u95f4\u7684\u6982\u5ff5\u7d27\u5bc6\u7ed3\u5408\u5230PDES\u6846\u67b6\u4e2d\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u88ab\u89c6\u4e3a\u5b9e\u4f53\u5e76\u54cd\u5e94\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u5148\u524d\u8bf7\u6c42\u3002", "result": "\u901a\u8fc7\u89e3\u51b3\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u95ee\u9898\u5e76\u5c06\u7ed3\u679c\u4e0e\u5355\u7eafAI\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8fbe\u523068%\uff0c\u800c\u5355\u7eafAI\u6a21\u578b\u7684\u51c6\u786e\u7387\u5219\u4f4e\u4e8e23%\u3002", "conclusion": "\u5728\u6d89\u53caAI\u548c\u975eAI\u667a\u80fd\u4f53\u7684PDES\u4e2d\uff0c\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u6b65\u9aa4\uff0c\u4e3aAI\u667a\u80fd\u4f53\u63d0\u4f9b\u591a\u79cd\u9009\u62e9\uff0c\u5e76\u901a\u8fc7\u975eAI\u667a\u80fd\u4f53\u4f5c\u4e3a\u516c\u6b63\u7684\u5ba1\u8ba1\u8005\uff0c\u68c0\u67e5AI\u667a\u80fd\u4f53\u7684\u6bcf\u4e00\u6b65\u64cd\u4f5c\uff0c\u4ece\u800c\u5728\u89e3\u51b3\u7279\u5b9a\u9886\u57df\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u51c6\u786e\u6027\u63d0\u5347\u3002"}}
{"id": "2505.23982", "pdf": "https://arxiv.org/pdf/2505.23982", "abs": "https://arxiv.org/abs/2505.23982", "authors": ["Jerry Junyang Cheung", "Shiyao Shen", "Yuchen Zhuang", "Yinghao Li", "Rampi Ramprasad", "Chao Zhang"], "title": "MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge", "categories": ["cs.AI"], "comment": null, "summary": "Despite recent advances in large language models (LLMs) for materials\nscience, there is a lack of benchmarks for evaluating their domain-specific\nknowledge and complex reasoning abilities. To bridge this gap, we introduce\nMSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials\nscience questions in two formats: detailed explanatory responses and binary\nTrue/False assessments. MSQA distinctively challenges LLMs by requiring both\nprecise factual knowledge and multi-step reasoning across seven materials\nscience sub-fields, such as structure-property relationships, synthesis\nprocesses, and computational modeling. Through experiments with 10\nstate-of-the-art LLMs, we identify significant gaps in current LLM performance.\nWhile API-based proprietary LLMs achieve up to 84.5% accuracy, open-source\n(OSS) LLMs peak around 60.5%, and domain-specific LLMs often underperform\nsignificantly due to overfitting and distributional shifts. MSQA represents the\nfirst benchmark to jointly evaluate the factual and reasoning capabilities of\nLLMs crucial for LLMs in advanced materials science.", "AI": {"tldr": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aMSQA\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u63ed\u793a\u4e86LLMs\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u6027\u80fd\u4e2d\u7684\u5dee\u8ddd\u3002", "motivation": "\u4e3a\u4e86\u586b\u8865\u6750\u6599\u79d1\u5b66\u9886\u57df\u4e2d\u8bc4\u4f30LLMs\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u5305\u542b1757\u9053\u7814\u7a76\u751f\u6c34\u5e73\u6750\u6599\u79d1\u5b66\u95ee\u9898\u7684\u8bc4\u4f30\u57fa\u51c6\u2014\u2014MSQA\uff0c\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7\u5bf910\u4e2a\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u5f53\u524dLLMs\u6027\u80fd\u4e2d\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0cAPI\u578b\u4e13\u6709LLMs\u8fbe\u523084.5%\u7684\u51c6\u786e\u7387\uff0c\u800c\u5f00\u6e90LLMs\u4ec5\u8fbe\u523060.5%\uff0c\u9886\u57df\u7279\u5b9aLLMs\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "MSQA\u662f\u9996\u4e2a\u8bc4\u4f30LLMs\u5728\u9ad8\u7ea7\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u4e8b\u5b9e\u548c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u3002"}}
{"id": "2505.23794", "pdf": "https://arxiv.org/pdf/2505.23794", "abs": "https://arxiv.org/abs/2505.23794", "authors": ["Yuan Li", "Qi Luo", "Xiaonan Li", "Bufan Li", "Qinyuan Cheng", "Bo Wang", "Yining Zheng", "Yuxin Wang", "Zhangyue Yin", "Xipeng Qiu"], "title": "R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge with Large\nLanguage Models (LLMs) to enhance factual correctness and mitigate\nhallucination. However, dense retrievers often become the bottleneck of RAG\nsystems due to their limited parameters compared to LLMs and their inability to\nperform step-by-step reasoning. While prompt-based iterative RAG attempts to\naddress these limitations, it is constrained by human-designed workflows. To\naddress these limitations, we propose $\\textbf{R3-RAG}$, which uses\n$\\textbf{R}$einforcement learning to make the LLM learn how to\n$\\textbf{R}$eason and $\\textbf{R}$etrieve step by step, thus retrieving\ncomprehensive external knowledge and leading to correct answers. R3-RAG is\ndivided into two stages. We first use cold start to make the model learn the\nmanner of iteratively interleaving reasoning and retrieval. Then we use\nreinforcement learning to further harness its ability to better explore the\nexternal retrieval environment. Specifically, we propose two rewards for\nR3-RAG: 1) answer correctness for outcome reward, which judges whether the\ntrajectory leads to a correct answer; 2) relevance-based document verification\nfor process reward, encouraging the model to retrieve documents that are\nrelevant to the user question, through which we can let the model learn how to\niteratively reason and retrieve relevant documents to get the correct answer.\nExperimental results show that R3-RAG significantly outperforms baselines and\ncan transfer well to different retrievers. We release R3-RAG at\nhttps://github.com/Yuan-Li-FNLP/R3-RAG.", "AI": {"tldr": "R3-RAG\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u63d0\u9ad8RAG\u7cfb\u7edf\u7684\u63a8\u7406\u548c\u68c0\u7d22\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u7a20\u5bc6\u68c0\u7d22\u5668\u5728RAG\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u9650\u5236\uff0c\u5982\u53c2\u6570\u6bd4LLMs\u5c11\u548c\u7f3a\u4e4f\u9010\u6b65\u63a8\u7406\u80fd\u529b\u3002", "method": "R3-RAG \u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u9996\u5148\uff0c\u4f7f\u7528\u51b7\u542f\u52a8\u8ba9\u6a21\u578b\u5b66\u4e60\u9010\u6b65\u63a8\u7406\u548c\u68c0\u7d22\u7684\u65b9\u5f0f\uff1b\u7136\u540e\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u5229\u7528\u5176\u80fd\u529b\u6765\u66f4\u597d\u5730\u63a2\u7d22\u5916\u90e8\u68c0\u7d22\u73af\u5883\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cR3-RAG\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u80fd\u591f\u5f88\u597d\u5730\u9002\u5e94\u4e0d\u540c\u7684\u68c0\u7d22\u5668\u3002", "conclusion": "R3-RAG\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5f88\u597d\u5730\u9002\u5e94\u4e0d\u540c\u7684\u68c0\u7d22\u5668\u3002"}}
{"id": "2505.23864", "pdf": "https://arxiv.org/pdf/2505.23864", "abs": "https://arxiv.org/abs/2505.23864", "authors": ["Wei Zhuo", "Zhaohuan Zhan", "Ziduo Yang", "Han Yu"], "title": "Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) on graph-structured data typically faces non-IID\nchallenges, particularly in scenarios where each client holds a distinct\nsubgraph sampled from a global graph. In this paper, we introduce Federated\nlearning with Auxiliary projections (FedAux), a personalized subgraph FL\nframework that learns to align, compare, and aggregate heterogeneously\ndistributed local models without sharing raw data or node embeddings. In\nFedAux, each client jointly trains (i) a local GNN and (ii) a learnable\nauxiliary projection vector (APV) that differentiably projects node embeddings\nonto a 1D space. A soft-sorting operation followed by a lightweight 1D\nconvolution refines these embeddings in the ordered space, enabling the APV to\neffectively capture client-specific information. After local training, these\nAPVs serve as compact signatures that the server uses to compute inter-client\nsimilarities and perform similarity-weighted parameter mixing, yielding\npersonalized models while preserving cross-client knowledge transfer. Moreover,\nwe provide rigorous theoretical analysis to establish the convergence and\nrationality of our design. Empirical evaluations across diverse graph\nbenchmarks demonstrate that FedAux substantially outperforms existing baselines\nin both accuracy and personalization performance.", "AI": {"tldr": "FedAux\u901a\u8fc7\u4e2a\u6027\u5316\u5b50\u56fe\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u975eIID\u95ee\u9898\uff0c\u5e76\u5728\u591a\u9879\u56fe\u57fa\u51c6\u4e0a\u5c55\u73b0\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7531\u4e8e\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6301\u6709\u4e0d\u540c\u5b50\u56fe\u800c\u5bfc\u81f4\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u95ee\u9898\uff0c\u63d0\u9ad8\u4e2a\u6027\u5316\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "FedAux\u901a\u8fc7\u5171\u540c\u8bad\u7ec3\u672c\u5730GNN\u548c\u53ef\u5b66\u4e60\u7684\u8f85\u52a9\u6295\u5f71\u5411\u91cf\uff0c\u4f7f\u5f97\u8282\u70b9\u5d4c\u5165\u80fd\u591f\u5728\u6709\u5e8f\u7a7a\u95f4\u4e2d\u8fdb\u884c1D\u5377\u79ef\u4f18\u5316\u3002", "result": "FedAux\u5728\u591a\u4e2a\u56fe\u6570\u636e\u57fa\u51c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u8868\u73b0\u4e0a\u90fd\u6709\u63d0\u5347\u3002", "conclusion": "FedAux\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u6295\u5f71\u548c\u8f6f\u6392\u5e8f\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u7ed3\u6784\u6570\u636e\u4e2d\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u4e2a\u6027\u5316\u8868\u73b0\u3002"}}
