{"id": "2506.03259", "pdf": "https://arxiv.org/pdf/2506.03259", "abs": "https://arxiv.org/abs/2506.03259", "authors": ["Michael E. Garcia-Alcoser", "Mobina GhojoghNejad", "Fakrul Islam Tushar", "David Kim", "Kyle J. Lafata", "Geoffrey D. Rubin", "Joseph Y. Lo"], "title": "Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems", "categories": ["cs.CL", "I.2.7"], "comment": "23 pages, 10 figures, to be submitted in Radiology: Artificial\n  Intelligence", "summary": "Purpose: This study aims to evaluate the effectiveness of large language\nmodels (LLMs) in automating disease annotation of CT radiology reports. We\ncompare a rule-based algorithm (RBA), RadBERT, and three lightweight\nopen-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)\nCT reports.\n  Materials and Methods: This retrospective study analyzed 40,833 CT reports\nfrom 29,540 patients, with 1,789 CAP reports manually annotated across three\norgan systems. External validation was conducted using the CT-RATE dataset.\nThree open-weight LLMs were tested with zero-shot prompting. Performance was\nevaluated using Cohen's Kappa and micro/macro-averaged F1 scores.\n  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and\nGemma-3 27B showed the highest agreement ($\\kappa$ median: 0.87). On the\nmanually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed\nby Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE\ndataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3\n27B close behind (0.89). Performance differences were mainly due to differing\nlabeling practices, especially for lung atelectasis.\n  Conclusion: Lightweight LLMs outperform rule-based methods for CT report\nannotation and generalize across organ systems with zero-shot prompting.\nHowever, binary labels alone cannot capture the full nuance of report language.\nLLMs can provide a flexible, efficient solution aligned with clinical judgment\nand user needs.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u8f7b\u91cf\u7ea7LLMs\u5728CT\u62a5\u544a\u7684\u75be\u75c5\u6807\u6ce8\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u591a\u4e2a\u5668\u5b98\u7cfb\u7edf\u4e2d\u80fd\u591f\u8fdb\u884c\u6cdb\u5316\uff0c\u4f46\u6807\u7b7e\u7684\u7ec6\u5fae\u5dee\u522b\u4ecd\u6709\u5f85\u89e3\u51b3\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u81ea\u52a8\u5316CT\u653e\u5c04\u5b66\u62a5\u544a\u75be\u75c5\u6807\u6ce8\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u6bd4\u8f83\u57fa\u4e8e\u89c4\u5219\u7684\u7b97\u6cd5(RBA)\u3001RadBERT\u548c\u4e09\u4e2a\u8f7b\u91cf\u7ea7\u5f00\u6e90LLMs\u5728\u80f8\u90e8\u3001\u8179\u90e8\u548c\u9aa8\u76c6(CAP)CT\u62a5\u544a\u7684\u591a\u75be\u75c5\u6807\u6ce8\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u8fd9\u9879\u56de\u987e\u6027\u7814\u7a76\u5206\u6790\u4e86\u6765\u81ea29,540\u540d\u60a3\u8005\u768440,833\u4efdCT\u62a5\u544a\uff0c\u5176\u4e2d1,789\u4efdCAP\u62a5\u544a\u901a\u8fc7\u4e09\u4e2a\u5668\u5b98\u7cfb\u7edf\u8fdb\u884c\u4e86\u4eba\u5de5\u6ce8\u91ca\u3002\u901a\u8fc7\u4f7f\u7528CT-RATE\u6570\u636e\u96c6\u8fdb\u884c\u5916\u90e8\u9a8c\u8bc1\uff0c\u6d4b\u8bd5\u4e86\u4e09\u4e2a\u5f00\u6e90\u8f7b\u91cf\u7ea7LLMs\u7684\u96f6\u6837\u672c\u63d0\u793a\uff0c\u5e76\u901a\u8fc7Cohen's Kappa\u548c\u5fae\u89c2/\u5b8f\u89c2\u5e73\u5747F1\u5206\u6570\u6765\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5728\u6765\u81ea8,854\u540d\u60a3\u8005\u768412,197\u4efdDuke CAP\u62a5\u544a\u4e2d\uff0cLlama-3.1 8B\u548cGemma-3 27B\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u4e00\u81f4\u6027(\u03ba\u4e2d\u503c: 0.87)\u3002\u5728\u4eba\u4e3a\u6807\u6ce8\u7684\u62a5\u544a\u4e2d\uff0cGemma-3 27B\u7684\u5b8f\u89c2F1\u5f97\u5206\u6700\u9ad8(0.82)\uff0c\u5176\u6b21\u662fLlama-3.1 8B(0.79)\uff0c\u800cRBA\u5f97\u5206\u6700\u4f4e(0.64)\u3002\u5728CT-RATE\u6570\u636e\u96c6(\u4ec5\u9488\u5bf9\u80ba/\u80f8\u819c)\uff0cLlama-3.1 8B\u8868\u73b0\u6700\u4f73(0.91)\uff0cGemma-3 27B\u7d27\u968f\u5176\u540e(0.89)\u3002\u6027\u80fd\u5dee\u5f02\u4e3b\u8981\u6e90\u4e8e\u4e0d\u540c\u7684\u6807\u6ce8\u5b9e\u8df5\uff0c\u7279\u522b\u662f\u5728\u80ba\u4e0d\u5f20\u65b9\u9762\u3002", "conclusion": "\u8f7b\u91cf\u7ea7LLMs\u5728CT\u62a5\u544a\u7684\u6ce8\u91ca\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u901a\u8fc7\u96f6\u6837\u672c\u63d0\u793a\u5728\u591a\u4e2a\u5668\u5b98\u7cfb\u7edf\u4e2d\u8fdb\u884c\u6cdb\u5316\u3002\u7136\u800c\uff0c\u4ec5\u9760\u4e8c\u5143\u6807\u7b7e\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u62a5\u544a\u8bed\u8a00\u7684\u7ec6\u5fae\u5dee\u522b\u3002LLMs\u80fd\u591f\u63d0\u4f9b\u4e0e\u4e34\u5e8a\u5224\u65ad\u548c\u7528\u6237\u9700\u6c42\u76f8\u4e00\u81f4\u7684\u7075\u6d3b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.03268", "pdf": "https://arxiv.org/pdf/2506.03268", "abs": "https://arxiv.org/abs/2506.03268", "authors": ["Cristiano Chesi"], "title": "A conclusive remark on linguistic theorizing and language modeling", "categories": ["cs.CL"], "comment": null, "summary": "This is the final remark on the replies received to my target paper in the\nItalian Journal of Linguistics", "AI": {"tldr": "\u64b0\u5199\u4e86\u4e00\u7bc7\u5173\u4e8e\u76ee\u6807\u8bba\u6587\u56de\u590d\u7684\u603b\u7ed3\u6027\u8bc4\u8bba\uff0c\u65e8\u5728\u63a8\u52a8\u8ba8\u8bba\u3002", "motivation": "\u6574\u7406\u548c\u603b\u7ed3\u5bf9\u76ee\u6807\u8bba\u6587\u7684\u56de\u590d\uff0c\u4ee5\u63a8\u52a8\u8bed\u8a00\u5b66\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u8ba8\u8bba\u548c\u7814\u7a76\u3002", "method": "\u6682\u65e0\u5177\u4f53\u7814\u7a76\u65b9\u6cd5\uff0c\u4ec5\u4e3a\u4e00\u4e2a\u5173\u4e8e\u56de\u590d\u7684\u603b\u7ed3\u6027\u8bc4\u8bba\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u8bed\u8a00\u5b66\u76ee\u6807\u8bba\u6587\u56de\u590d\u7684\u6700\u7ec8\u8bc4\u4ef7\u3002", "conclusion": "\u8bba\u6587\u56de\u6536\u4e86\u5bf9\u610f\u5927\u5229\u8bed\u8a00\u5b66\u6742\u5fd7\u76ee\u6807\u8bba\u6587\u7684\u56de\u590d\u8fdb\u884c\u6700\u7ec8\u8bc4\u4ef7\u3002"}}
{"id": "2506.03278", "pdf": "https://arxiv.org/pdf/2506.03278", "abs": "https://arxiv.org/abs/2506.03278", "authors": ["Christodoulos Constantinides", "Dhaval Patel", "Shuxin Lin", "Claudio Guerrero", "Sunil Dagajirao Patil", "Jayant Kalagnanam"], "title": "FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes", "categories": ["cs.CL"], "comment": null, "summary": "We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA)\nbenchmarking system designed to assess the ability of Large Language Models\n(LLMs) to reason and understand complex, domain-specific scenarios in Industry\n4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects\nof reasoning through failure modes, sensor data, and the relationships between\nthem across various industrial assets. Through this work, we envision a\nparadigm shift where modeling decisions are not only data-driven using\nstatistical tools like correlation analysis and significance tests, but also\ndomain-driven by specialized LLMs which can reason about the key contributors\nand useful patterns that can be captured with feature engineering. We evaluate\nthe Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and\nMistral-on FailureSensorIQ from different lens using\nPerturbation-Uncertainty-Complexity analysis, Expert Evaluation study,\nAsset-Specific Knowledge Gap analysis, ReAct agent using external\nknowledge-bases. Even though closed-source models with strong reasoning\ncapabilities approach expert-level performance, the comprehensive benchmark\nreveals a significant drop in performance that is fragile to perturbations,\ndistractions, and inherent knowledge gaps in the models. We also provide a\nreal-world case study of how LLMs can drive the modeling decisions on 3\ndifferent failure prediction datasets related to various assets. We release:\n(a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ\nbenchmark and Hugging Face leaderboard based on MCQA built from non-textual\ndata found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature\nselection scikit-learn pipeline. The software is available at\nhttps://github.com/IBM/FailureSensorIQ.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MCQA\u57fa\u51c6\u7cfb\u7edfFailureSensorIQ\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a4.0\u590d\u6742\u9886\u57df\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u9762\u5bf9\u6270\u52a8\u548c\u77e5\u8bc6\u7f3a\u9677\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u60c5\u51b5\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a4.0\u590d\u6742\u9886\u57df\u573a\u666f\u4e2d\u7684\u63a8\u7406\u548c\u7406\u89e3\u80fd\u529b\uff0c\u4ee5\u53ca\u63a8\u52a8\u4f7f\u7528\u4e13\u95e8\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u9886\u57df\u7684\u63a8\u7406\u800c\u975e\u4ec5\u4f9d\u8d56\u7edf\u8ba1\u6570\u636e\u6280\u672f\u3002", "method": "\u6784\u5efaFailureSensorIQ\u7cfb\u7edf\uff0c\u901a\u8fc7\u6270\u52a8-\u4e0d\u786e\u5b9a\u6027-\u590d\u6742\u5ea6\u5206\u6790\u3001\u4e13\u5bb6\u8bc4\u4f30\u3001\u77e5\u8bc6\u7f3a\u53e3\u5206\u6790\u7b49\u65b9\u6cd5\u8bc4\u4f30\u8d85\u8fc7\u5341\u79cd\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u4e1a\u77e5\u8bc6\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u867d\u7136\u5c01\u95ed\u6e90\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u9762\u5bf9\u5e72\u6270\u3001\u5206\u5fc3\u4ee5\u53ca\u77e5\u8bc6\u7f3a\u53e3\u65f6\uff0c\u5176\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u5982\u4f55\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u6545\u969c\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5efa\u6a21\u51b3\u7b56\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u3002", "conclusion": "\u4e13\u95e8\u7684\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u663e\u8457\u6539\u5584\u5de5\u4e1a\u9886\u57df\u590d\u6742\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u662f\u4ecd\u5b58\u5728\u5bf9\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u5185\u5728\u77e5\u8bc6\u7f3a\u53e3\u7684\u6311\u6218\u3002"}}
{"id": "2506.03419", "pdf": "https://arxiv.org/pdf/2506.03419", "abs": "https://arxiv.org/abs/2506.03419", "authors": ["Pablo Groisman", "Cecilia De Vita", "Juli\u00e1n Fern\u00e1ndez Bonder", "Yuanzhao Zhang"], "title": "The size of the sync basin resolved", "categories": ["math-ph", "math.DS", "math.MP", "nlin.AO", "nlin.PS"], "comment": null, "summary": "Sparsely coupled Kuramoto oscillators offer a fertile playground for\nexploring high-dimensional basins of attraction due to their simple yet\nmultistable dynamics. For $n$ identical Kuramoto oscillators on cycle graphs,\nit is well known that the only attractors are twisted states, whose phases wind\naround the circle with a constant gap between neighboring oscillators\n($\\theta_j = 2\\pi q j/n$). It was conjectured in 2006 that basin sizes of these\ntwisted states scale as $e^{-kq^2}$ to the winding number $q$. Here, we provide\nnew numerical and analytical evidence supporting the conjecture and uncover the\ndynamical mechanism behind the Gaussian scaling. The key idea is that, when\nstarting with a random initial condition, the winding number of the solution\nstabilizes rapidly at $t \\propto \\log n$, before long-range correlation can\ndevelop among oscillators. This timescale separation allows us to model the\nwinding number as a sum of weakly dependent variables, leading to a Central\nLimit Theorem derivation of the basin scaling.", "AI": {"tldr": "\u7814\u7a76\u7a00\u758f\u8026\u5408Kuramoto\u632f\u8361\u5668\u7684\u626d\u66f2\u6001\u57fa\u5f02\u6781\uff0c\u652f\u6301\u5176\u89c4\u6a21\u968f\u7ed5\u6570\u7684\u9ad8\u65af\u7f29\u653e\u731c\u60f3\uff0c\u5e76\u63ed\u793a\u80cc\u540e\u7684\u52a8\u529b\u5b66\u673a\u5236\u3002", "motivation": "\u63a2\u8ba8\u9ad8\u7ef4\u5438\u5f15\u76c6\u56e0\u5176\u7b80\u5355\u800c\u591a\u7a33\u5b9a\u7684\u52a8\u529b\u5b66\u7279\u6027\u7684\u7a00\u758f\u8026\u5408Kuramoto\u632f\u8361\u5668\u7684\u884c\u4e3a\uff0c\u5e76\u9a8c\u8bc1\u5173\u4e8e\u626d\u66f2\u6001\u57fa\u5f02\u6781\u89c4\u6a21\u7684\u5148\u524d\u731c\u60f3\u3002", "method": "\u4f7f\u7528\u4e86\u6570\u503c\u548c\u89e3\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u5316\u89e3\u7684\u7ed5\u6570\u4e3a\u4e00\u7ec4\u5f31\u76f8\u5173\u53d8\u91cf\u4e4b\u548c\uff0c\u4f7f\u7528\u4e2d\u5fc3\u6781\u9650\u5b9a\u7406\u5bfc\u51fa\u5176\u57fa\u5f02\u6781\u89c4\u6a21\u3002", "result": "\u63d0\u4f9b\u65b0\u7684\u6570\u503c\u548c\u5206\u6790\u8bc1\u636e\u652f\u6301\u731c\u60f3\uff0c\u5e76\u63ed\u793a\u4e86\u9ad8\u65af\u7f29\u653e\u80cc\u540e\u7684\u52a8\u529b\u5b66\u673a\u5236\u3002", "conclusion": "\u5f97\u51fa\u7ed3\u8bba\u662f\uff0c\u5f53\u4ece\u968f\u673a\u521d\u59cb\u6761\u4ef6\u5f00\u59cb\u65f6\uff0c\u89e3\u7684\u7ed5\u6570\u8fc5\u901f\u7a33\u5b9a\uff0c\u4ece\u800c\u652f\u6301\u5173\u4e8e\u626d\u66f2\u6001\u57fa\u5f02\u6781\u89c4\u6a21\u5448\u9ad8\u65af\u7f29\u653e\u7684\u731c\u60f3\u3002"}}
{"id": "2506.03292", "pdf": "https://arxiv.org/pdf/2506.03292", "abs": "https://arxiv.org/abs/2506.03292", "authors": ["Jiuding Sun", "Sidharth Baskaran", "Zhengxuan Wu", "Michael Sklar", "Christopher Potts", "Atticus Geiger"], "title": "HyperSteer: Activation Steering at Scale with Hypernetworks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Steering language models (LMs) by modifying internal activations is a popular\napproach for controlling text generation. Unsupervised dictionary learning\nmethods, e.g., sparse autoencoders, can be scaled to produce many steering\nvectors, but lack guarantees on the individual efficacy of each vector and\ncontrol over the coverage of relevant steering tasks. In contrast, supervised\nmethods for constructing steering vectors are targeted and effective, but\nrequire more data collection and training for each additional steering vector\nproduced. In this work, we introduce HyperSteer, a family of hypernetwork-based\narchitectures which are trained end-to-end to generate steering vectors\nconditioned on the natural language steering prompts and the internals of the\nsteered LM. In our evaluations, we show that scaling HyperSteer with thousands\nof steering prompts exceeds the performance of state-of-the-art activation\nsteering methods, even on steering prompts never seen during training.\nMoreover, HyperSteer performs on par with steering-via-prompting.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165HyperSteer\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d85\u7f51\u7edc\u751f\u6210\u65b9\u5411\u5411\u91cf\u6709\u6548\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u6cd5\u5728\u901a\u8fc7\u4fee\u6539\u5185\u90e8\u6fc0\u6d3b\u6765\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\u65b9\u9762\u5b58\u5728\u4e00\u4e9b\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u65e0\u76d1\u7763\u65b9\u6cd5\u4e2d\uff0c\u6548\u679c\u6ca1\u6709\u4fdd\u8bc1\uff0c\u800c\u6709\u76d1\u7763\u7684\u65b9\u6cd5\u53c8\u9700\u8981\u5927\u91cf\u7684\u6570\u636e\u548c\u8bad\u7ec3\u3002\u6211\u4eec\u5e0c\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u67b6\u6784\uff0c\u540d\u4e3aHyperSteer\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u8bad\u7ec3\u751f\u6210\u65b9\u5411\u5411\u91cf\uff0c\u8fd9\u4e9b\u5411\u91cf\u662f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u65b9\u5411\u63d0\u793a\u548c\u88ab\u6307\u5f15\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u60c5\u51b5\u751f\u6210\u7684\u3002", "result": "HyperSteer\u65b9\u6cd5\u5728\u4f7f\u7528\u6210\u5343\u4e0a\u4e07\u7684\u6307\u5f15\u63d0\u793a\u8fdb\u884c\u6269\u5c55\u65f6\uff0c\u5176\u6027\u80fd\u8d85\u8fc7\u4e86\u6700\u5148\u8fdb\u7684\u6fc0\u6d3b\u63a7\u5236\u65b9\u6cd5\uff0c\u751a\u81f3\u5728\u8bad\u7ec3\u4e2d\u672a\u89c1\u8fc7\u7684\u6307\u5f15\u63d0\u793a\u4e0a\u4e5f\u662f\u5982\u6b64\u3002\u540c\u65f6\uff0cHyperSteer\u5728\u6548\u679c\u4e0a\u4e0e\u901a\u8fc7\u63d0\u793a\u8fdb\u884c\u6307\u5f15\u7684\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165HyperSteer\u65b9\u6cd5\uff0c\u6211\u4eec\u6210\u529f\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6307\u5f15\u6548\u679c\uff0c\u7279\u522b\u662f\u5728\u672a\u89c1\u8fc7\u7684\u6307\u5f15\u4efb\u52a1\u4e0a\uff0c\u8868\u73b0\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6fc0\u6d3b\u63a7\u5236\u65b9\u6cd5\uff0c\u5e76\u4e0e\u901a\u8fc7\u63d0\u793a\u8fdb\u884c\u6307\u5f15\u7684\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\u3002"}}
{"id": "2506.03739", "pdf": "https://arxiv.org/pdf/2506.03739", "abs": "https://arxiv.org/abs/2506.03739", "authors": ["Yago Arosa", "Tigran Mansuryan", "Arnaud Poisson", "Wasyhun Asefa Gemechu", "Katarzyna Krupa", "Mario Ferraro", "Fabio Mangini", "Benjamin Wetzel", "Stefan Wabnitz", "Alessandro Tonello", "Vincent Couderc"], "title": "Spatio-spectral light-by-light moulding in multimode fibre", "categories": ["physics.optics", "nlin.AO"], "comment": null, "summary": "Controlling complex light waves to achieve desired behaviours or\ncharacteristics on demand presents a significant challenge. This task becomes\neven more complicated when manipulating speckled light beams owing to their\ninherently fuzzy intensity and phase structures. Here, we demonstrate that a\nweak speckled second-harmonic signal in a multimode graded-index fibre can be\nmanipulated via its conservative interaction with a high-power co-propagating\nfundamental pump wave. Specifically, the spatial quality of the signal can be\neither enhanced or degraded by varying the pump's power or its modal power\ndistribution. The underlying physical mechanism is the optically induced mode\nconversion, whose phase-matching can be controlled by the mode power\ndistribution of the pump beam. This phenomenon enables new possibilities for\nmanipulating complex light via material nonlinearities in multimode guiding\nstructures. A striking example of this novel light-by-light control is the\nexperimentally observed enhancement or partial suppression of the visible Raman\nStokes cascade regulated by the second harmonic beam, while modulated by the\nmode power distribution of the fundamental beam.", "AI": {"tldr": "\u5229\u7528\u591a\u6a21\u5149\u7ea4\u4e2d\u7684\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u5149\u4e0e\u5149\u7684\u63a7\u5236\u5b9e\u73b0\u5bf9\u590d\u6742\u5149\u6ce2\u884c\u4e3a\u7684\u64cd\u63a7\u3002", "motivation": "\u63a7\u5236\u590d\u6742\u5149\u6ce2\u4ee5\u5b9e\u73b0\u6240\u9700\u884c\u4e3a\u6216\u7279\u6027\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u5728\u64cd\u63a7\u6591\u70b9\u5149\u675f\u65f6\u66f4\u52a0\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u6e10\u53d8\u6298\u5c04\u7387\u5149\u7ea4\u4e2d\u7684\u5f31\u6591\u70b9\u4e8c\u6b21\u8c10\u6ce2\u4fe1\u53f7\u4e0e\u9ad8\u529f\u7387\u5171\u4f20\u64ad\u57fa\u6ce2\u6cf5\u6ce2\u7684\u4fdd\u5b88\u76f8\u4e92\u4f5c\u7528\u8fdb\u884c\u64cd\u63a7\u3002", "result": "\u901a\u8fc7\u8c03\u8282\u6cf5\u6ce2\u529f\u7387\u6216\u6a21\u5f0f\u529f\u7387\u5206\u5e03\uff0c\u53ef\u4ee5\u589e\u5f3a\u6216\u964d\u7ea7\u4fe1\u53f7\u7684\u7a7a\u95f4\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u5149\u5b66\u6a21\u5f0f\u8f6c\u6362\uff0c\u5176\u76f8\u4f4d\u5339\u914d\u53ef\u901a\u8fc7\u6cf5\u675f\u7684\u6a21\u5f0f\u529f\u7387\u5206\u5e03\u8fdb\u884c\u63a7\u5236\u3002", "conclusion": "\u901a\u8fc7\u7269\u8d28\u975e\u7ebf\u6027\u5728\u591a\u6a21\u5bfc\u6ce2\u7ed3\u6784\u4e2d\u64cd\u63a7\u590d\u6742\u5149\uff0c\u5b9e\u73b0\u4e86\u65b0\u53ef\u80fd\u6027\u3002\u5149\u4e0e\u5149\u7684\u76f8\u4e92\u63a7\u5236\u5f15\u53d1\u4e86\u589e\u5f3a\u6216\u90e8\u5206\u6291\u5236\u53ef\u89c1\u62c9\u66fcStokes\u7ea7\u8054\u73b0\u8c61\u3002"}}
{"id": "2506.04215", "pdf": "https://arxiv.org/pdf/2506.04215", "abs": "https://arxiv.org/abs/2506.04215", "authors": ["Alex DeWeese", "Guannan Qu"], "title": "Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs", "categories": ["cs.MA", "cs.AI", "cs.LG", "math.OC"], "comment": null, "summary": "Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are\nknown to be NEXP-Complete and intractable to solve. However, for problems such\nas cooperative navigation, obstacle avoidance, and formation control, basic\nassumptions can be made about local visibility and local dependencies. The work\nDeWeese and Qu 2024 formalized these assumptions in the construction of the\nLocally Interdependent Multi-Agent MDP. In this setting, it establishes three\nclosed-form policies that are tractable to compute in various situations and\nare exponentially close to optimal with respect to visibility. However, it is\nalso shown that these solutions can have poor performance when the visibility\nis small and fixed, often getting stuck during simulations due to the so called\n\"Penalty Jittering\" phenomenon. In this work, we establish the Extended Cutoff\nPolicy Class which is, to the best of our knowledge, the first non-trivial\nclass of near optimal closed-form partially observable policies that are\nexponentially close to optimal with respect to the visibility for any Locally\nInterdependent Multi-Agent MDP. These policies are able to remember agents\nbeyond their visibilities which allows them to perform significantly better in\nmany small and fixed visibility settings, resolve Penalty Jittering\noccurrences, and under certain circumstances guarantee fully observable joint\noptimal behavior despite the partial observability. We also propose a\ngeneralized form of the Locally Interdependent Multi-Agent MDP that allows for\ntransition dependence and extended reward dependence, then replicate our\ntheoretical results in this setting.", "AI": {"tldr": "\u9488\u5bf9\u5c40\u90e8\u76f8\u4e92\u4f9d\u8d56\u7684\u591a\u667a\u80fd\u4f53MDP\uff0c\u63d0\u51fa\u4e86\u62d3\u5c55\u622a\u6b62\u7b56\u7565\u7c7b\u4ee5\u89e3\u51b3\u53ef\u89c1\u6027\u5c0f\u7684\u95ee\u9898\u5e76\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5904\u7406\u53ef\u89c1\u6027\u5c0f\u4e14\u56fa\u5b9a\u65f6\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u4ee5\u53ca\u2018\u60e9\u7f5a\u6296\u52a8\u2019\u73b0\u8c61\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u62d3\u5c55\u7684\u7b56\u7565\u7c7b\uff0c\u4e0d\u4ec5\u80fd\u591f\u5728\u90e8\u5206\u53ef\u89c1\u6027\u60c5\u51b5\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u5c01\u95ed\u5f62\u5f0f\u7b56\u7565\uff0c\u8fd8\u80fd\u589e\u5f3a\u5bf9\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u3002", "method": "\u6211\u4eec\u5236\u5b9a\u4e86\u62d3\u5c55\u622a\u6b62\u7b56\u7565\u7c7b\uff0c\u5e76\u5728\u5e7f\u4e49\u7684\u5c40\u90e8\u76f8\u4e92\u4f9d\u8d56\u591a\u667a\u80fd\u4f53MDP\u4e2d\u590d\u73b0\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u4ee5\u89e3\u51b3\u53ef\u89c1\u6027\u5c0f\u4e14\u56fa\u5b9a\u65f6\u7684\u2018\u60e9\u7f5a\u6296\u52a8\u2019\u73b0\u8c61\u3002", "result": "\u65b0\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u5728\u53ef\u89c1\u6027\u5c0f\u4e14\u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u8868\u73b0\uff0c\u89e3\u51b3\u2018\u60e9\u7f5a\u6296\u52a8\u2019\u95ee\u9898\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u786e\u4fdd\u5168\u5c40\u53ef\u89c1\u7684\u8054\u5408\u6700\u4f18\u884c\u4e3a\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u7c7b\u62d3\u5c55\u622a\u6b62\u7b56\u7565\u7c7b\uff0c\u5728\u5bf9\u4efb\u4f55\u5c40\u90e8\u76f8\u4e92\u4f9d\u8d56\u7684\u591a\u667a\u80fd\u4f53MDP\u7684\u53ef\u89c1\u6027\u65b9\u9762\uff0c\u8fd9\u662f\u4e00\u7c7b\u63a5\u8fd1\u6700\u4f18\u7684\u5c01\u95ed\u5f62\u5f0f\u90e8\u5206\u53ef\u89c1\u7b56\u7565\u3002"}}
{"id": "2506.03205", "pdf": "https://arxiv.org/pdf/2506.03205", "abs": "https://arxiv.org/abs/2506.03205", "authors": ["Umberto Gon\u00e7alves de Sousa"], "title": "Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments", "categories": ["cs.AI"], "comment": "17 pages, 5 figures", "summary": "This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum\nreinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model,\nwhere Q-ARDNS-Multi stands for \"Quantum Adaptive Reward-Driven Neural Simulator\n- Multi-Agent\". It integrates quantum circuits with RY gates, meta-cognitive\nadaptation, and multi-agent coordination mechanisms for complex 3D\nenvironments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action\nselection, a dual-memory system inspired by human cognition, a shared memory\nmodule for agent cooperation, and adaptive exploration strategies modulated by\nreward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times\n3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi\nachieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively,\noutperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft\nActor-Critic (SAC) in terms of success rate, stability, navigation efficiency,\nand collision avoidance. The framework records mean rewards of $-304.2891 \\pm\n756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal,\ndemonstrating its robustness in dynamic settings. Comprehensive analyses,\nincluding learning curves, reward distributions, statistical tests, and\ncomputational efficiency evaluations, highlight the contributions of quantum\ncircuits and meta-cognitive adaptation. By bridging quantum computing,\ncognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable,\nhuman-like approach for applications in robotics, autonomous navigation, and\ndecision-making under uncertainty.", "AI": {"tldr": "Q-ARDNS-Multi\u6846\u67b6\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u8ba4\u77e5\u79d1\u5b66\uff0c\u4ee5\u9ad8\u6210\u529f\u7387\u548c\u5bfc\u822a\u6548\u7387\u5728\u591a\u667a\u80fd\u4f533D\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u96c6\u91cf\u5b50\u8ba1\u7b97\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e8e\u4e00\u4f53\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u673a\u5668\u4eba\u3001\u81ea\u52a8\u5bfc\u822a\u548c\u4e0d\u786e\u5b9a\u6027\u51b3\u7b56\u7684\u6548\u7387\u548c\u6210\u529f\u7387\u3002", "method": "\u4f7f\u75282\u91cf\u5b50\u6bd4\u7279\u7535\u8def\u8fdb\u884c\u52a8\u4f5c\u9009\u62e9\uff0c\u901a\u8fc7\u5956\u52b1\u53d8\u5316\u548c\u5185\u5728\u52a8\u673a\u8fdb\u884c\u9002\u5e94\u63a2\u7d22\uff0c\u5e76\u91c7\u7528\u53cc\u8bb0\u5fc6\u7cfb\u7edf\u548c\u5171\u4eab\u8bb0\u5fc6\u6a21\u5757\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "result": "\u5728$10 \times 10 \times 3$ GridWorld\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0cQ-ARDNS-Multi\u6210\u529f\u7387\u8fbe\u523099.6%\u548c99.5%\uff0c\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u8be5\u6846\u67b6\u5e73\u5747\u9700\u8981210\u6b65\u8fbe\u5230\u76ee\u6807\uff0c\u5e76\u4e14\u5728\u52a8\u6001\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u3002", "conclusion": "Q-ARDNS-Multi\u6210\u529f\u7ed3\u5408\u4e86\u91cf\u5b50\u8ba1\u7b97\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u5316\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u673a\u5668\u4eba\u6280\u672f\u3001\u81ea\u52a8\u5bfc\u822a\u548c\u4e0d\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u7684\u51b3\u7b56\u5e94\u7528\u3002"}}
{"id": "2506.03154", "pdf": "https://arxiv.org/pdf/2506.03154", "abs": "https://arxiv.org/abs/2506.03154", "authors": ["Zhaoyang Chen", "Cody Fleming"], "title": "Modular Diffusion Policy Training: Decoupling and Recombining Guidance and Diffusion for Offline RL", "categories": ["cs.LG"], "comment": null, "summary": "Classifier free guidance has shown strong potential in diffusion-based\nreinforcement learning. However, existing methods rely on joint training of the\nguidance module and the diffusion model, which can be suboptimal during the\nearly stages when the guidance is inaccurate and provides noisy learning\nsignals. In offline RL, guidance depends solely on offline data: observations,\nactions, and rewards, and is independent of the policy module's behavior,\nsuggesting that joint training is not required. This paper proposes modular\ntraining methods that decouple the guidance module from the diffusion model,\nbased on three key findings:\n  Guidance Necessity: We explore how the effectiveness of guidance varies with\nthe training stage and algorithm choice, uncovering the roles of guidance and\ndiffusion. A lack of good guidance in the early stage presents an opportunity\nfor optimization.\n  Guidance-First Diffusion Training: We introduce a method where the guidance\nmodule is first trained independently as a value estimator, then frozen to\nguide the diffusion model using classifier-free reward guidance. This\nmodularization reduces memory usage, improves computational efficiency, and\nenhances both sample efficiency and final performance.\n  Cross-Module Transferability: Applying two independently trained guidance\nmodels, one during training and the other during inference, can significantly\nreduce normalized score variance (e.g., reducing IQR by 86%). We show that\nguidance modules trained with one algorithm (e.g., IDQL) can be directly reused\nwith another (e.g., DQL), with no additional training required, demonstrating\nbaseline-level performance as well as strong modularity and transferability.\n  We provide theoretical justification and empirical validation on bullet D4RL\nbenchmarks. Our findings suggest a new paradigm for offline RL: modular,\nreusable, and composable training pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6307\u5bfc\u6a21\u5757\u4e0e\u6269\u6563\u6a21\u578b\u5206\u79bb\uff0c\u63d0\u9ad8\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u3001\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5f3a\u5927\u7684\u6a21\u5757\u6027\u548c\u4f20\u9012\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5bf9\u6307\u5bfc\u6a21\u5757\u548c\u6269\u6563\u6a21\u578b\u8fdb\u884c\u8054\u5408\u8bad\u7ec3\uff0c\u8fd9\u5728\u521d\u671f\u4f1a\u56e0\u6307\u5bfc\u4e0d\u51c6\u786e\u5bfc\u81f4\u5b66\u4e60\u4fe1\u53f7\u566a\u58f0\u3002\u672c\u6587\u7814\u7a76\u79bb\u7ebfRL\u4e2d\uff0c\u6307\u5bfc\u4ec5\u4f9d\u8d56\u4e8e\u79bb\u7ebf\u6570\u636e\u800c\u975e\u7b56\u7565\u6a21\u5757\uff0c\u63ed\u793a\u8054\u5408\u8bad\u7ec3\u7684\u975e\u5fc5\u8981\u6027\uff0c\u8fdb\u800c\u63a2\u8ba8\u6a21\u5757\u5316\u8bad\u7ec3\u7684\u4f18\u52bf\u3002", "method": "\u9996\u5148\u72ec\u7acb\u8bad\u7ec3\u6307\u5bfc\u6a21\u5757\u4f5c\u4e3a\u4ef7\u503c\u8bc4\u4f30\uff0c\u7136\u540e\u51bb\u7ed3\u8be5\u6a21\u5757\uff0c\u4ee5\u65e0\u5206\u7c7b\u5668\u7684\u5956\u52b1\u6307\u5bfc\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u3002\u8fd9\u79cd\u6a21\u5757\u5316\u65b9\u6cd5\u80fd\u964d\u4f4e\u5185\u5b58\u4f7f\u7528\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u6837\u672c\u6548\u7387\uff0c\u5e76\u5141\u8bb8\u8de8\u6a21\u5757\u7684\u4f20\u9012\u6027\u3002", "result": "\u5728bullet D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u901a\u8fc7\u7406\u8bba\u8bba\u8bc1\u548c\u5b9e\u9a8c\u8bc1\u5b9e\uff0c\u6a21\u5757\u5316\u65b9\u6cd5\u4f18\u5316\u4e86\u5b66\u4e60\u8fc7\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5f52\u4e00\u5316\u5f97\u5206\u65b9\u5dee\uff08\u5982IQR\u964d\u4f4e86%\uff09\uff0c\u5e76\u5c55\u793a\u51fa\u57fa\u7840\u6c34\u5e73\u6027\u80fd\u53ca\u5176\u5f3a\u5927\u7684\u6a21\u5757\u6027\u548c\u4f20\u9012\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6a21\u5757\u5316\u8bad\u7ec3\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u4f18\u5316\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6307\u5bfc\u6a21\u5757\u548c\u6269\u6563\u6a21\u578b\uff0c\u63d0\u9ad8\u6700\u7ec8\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.03295", "pdf": "https://arxiv.org/pdf/2506.03295", "abs": "https://arxiv.org/abs/2506.03295", "authors": ["Yubo Wang", "Ping Nie", "Kai Zou", "Lijun Wu", "Wenhu Chen"], "title": "Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess\nimmense reasoning potential inherited from the pre-training stage. With\nreinforcement learning (RL), these models can improve dramatically on reasoning\ntasks. Recent studies have shown that even RL on a single problem can unleash\nthese models' reasoning capabilities. However, RL is not only expensive but\nalso unstable. Even one-shot RL requires hundreds of GPU hours. This raises a\ncritical question: Is there a more efficient way to unleash the reasoning\npotential of these powerful base LLMs? In this work, we demonstrate that\nCritique Fine-Tuning (CFT) on only one problem can effectively unleash the\nreasoning potential of LLMs. Our method constructs critique data by collecting\ndiverse model-generated solutions to a single problem and using teacher LLMs to\nprovide detailed critiques. We fine-tune Qwen and Llama family models, ranging\nfrom 1.5B to 14B parameters, on the CFT data and observe significant\nperformance gains across diverse reasoning tasks. For example, with just 5 GPU\nhours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six\nmath benchmarks and 16% on three logic reasoning benchmarks. These results are\ncomparable to or even surpass the results from RL with 20x less compute.\nAblation studies reveal the robustness of one-shot CFT across different prompt\nproblems. These results highlight one-shot CFT as a simple, general, and\ncompute-efficient approach to unleashing the reasoning capabilities of modern\nLLMs.", "AI": {"tldr": "\u6279\u8bc4\u5fae\u8c03\uff08CFT\uff09\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u3001\u901a\u7528\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u91ca\u653e\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u5347 LLM \u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u6210\u672c\u9ad8\u4e14\u4e0d\u7a33\u5b9a\uff0c\u5bfb\u6c42\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u4ee5\u91ca\u653e LLM \u7684\u63a8\u7406\u6f5c\u80fd\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u6279\u8bc4\u6570\u636e\uff0c\u5373\u6536\u96c6\u5355\u4e2a\u95ee\u9898\u7684\u591a\u6837\u6a21\u578b\u751f\u6210\u89e3\uff0c\u5e76\u5229\u7528\u6559\u5e08 LLMs \u63d0\u4f9b\u8be6\u7ec6\u6279\u8bc4\uff0c\u6765\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u4f7f\u7528 CFT \u65b9\u6cd5\u4ec5\u9700 5 \u4e2a GPU \u5c0f\u65f6\u8bad\u7ec3\uff0cQwen-Math-7B-CFT \u5728\u516d\u4e2a\u6570\u5b66\u57fa\u51c6\u4e0a\u7684\u5e73\u5747\u63d0\u9ad8\u4e86 15%\uff0c\u5728\u4e09\u4e2a\u903b\u8f91\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u63d0\u9ad8\u4e86 16%\uff0c\u5b9e\u73b0\u4e86\u4e0e RL \u53ef\u6bd4\u751a\u81f3\u66f4\u4f18\u7684\u6548\u679c\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u964d\u4f4e 20 \u500d\u3002", "conclusion": "\u4e00\u4f53\u5f0f\u6279\u8bc4\u5fae\u8c03\uff08CFT\uff09\u53ef\u4ee5\u6709\u6548\u6fc0\u53d1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u6f5c\u529b\u3002"}}
{"id": "2506.03543", "pdf": "https://arxiv.org/pdf/2506.03543", "abs": "https://arxiv.org/abs/2506.03543", "authors": ["Wanghao Ye", "Sihan Chen", "Yiting Wang", "Shwai He", "Bowei Tian", "Guoheng Sun", "Ziyi Wang", "Ziyao Wang", "Yexiao He", "Zheyu Shen", "Meng Liu", "Yuning Zhang", "Meng Feng", "Yang Wang", "Siyuan Peng", "Yilong Dai", "Zhenle Duan", "Hanzhang Qin", "Ang Li"], "title": "CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications", "categories": ["cs.AI", "cs.CY", "cs.MA"], "comment": null, "summary": "Current large language model (LLM) agents lack authentic human psychological\nprocesses necessary for genuine digital twins and social AI applications. To\naddress this limitation, we present a computational implementation of Global\nWorkspace Theory (GNWT) that integrates human cognitive architecture principles\ninto LLM agents, creating specialized sub-agents for emotion, memory, social\nnorms, planning, and goal-tracking coordinated through a global workspace\nmechanism. However, authentic digital twins require accurate personality\ninitialization. We therefore develop a novel adventure-based personality test\nthat evaluates true personality through behavioral choices within interactive\nscenarios, bypassing self-presentation bias found in traditional assessments.\nBuilding on these innovations, our CogniPair platform enables digital twins to\nengage in realistic simulated dating interactions and job interviews before\nreal encounters, providing bidirectional cultural fit assessment for both\nromantic compatibility and workplace matching. Validation using 551 GNWT-Agents\nand Columbia University Speed Dating dataset demonstrates 72% correlation with\nhuman attraction patterns, 77.8% match prediction accuracy, and 74% agreement\nin human validation studies. This work advances psychological authenticity in\nLLM agents and establishes a foundation for intelligent dating platforms and HR\ntechnology solutions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6574\u5408\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\u589e\u5f3aLLM\u4ee3\u7406\u7684\u5fc3\u7406\u771f\u5b9e\u6027\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578b\u4e2a\u6027\u6d4b\u8bd5\uff0c\u5e76\u5728CogniPair\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u5176\u5728\u7ea6\u4f1a\u548c\u5de5\u4f5c\u5339\u914d\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7f3a\u4e4f\u771f\u5b9e\u7684\u4eba\u7c7b\u5fc3\u7406\u8fc7\u7a0b\uff0c\u8fd9\u5bf9\u771f\u6b63\u7684\u6570\u5b57\u53cc\u80de\u80ce\u548c\u793e\u4ea4AI\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u8ba4\u77e5\u67b6\u6784\u539f\u5219\uff0c\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u672c\u6587\u91c7\u7528\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GNWT\uff09\uff0c\u901a\u8fc7\u521b\u5efa\u4e13\u95e8\u7684\u5b50\u4ee3\u7406\u5904\u7406\u60c5\u611f\u3001\u8bb0\u5fc6\u3001\u793e\u4f1a\u89c4\u8303\u3001\u89c4\u5212\u548c\u76ee\u6807\u8ffd\u8e2a\uff0c\u5e76\u901a\u8fc7\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u673a\u5236\u8fdb\u884c\u534f\u8c03\u3002\u4e3a\u4e86\u521d\u59cb\u5316\u51c6\u786e\u7684\u4e2a\u6027\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5192\u9669\u7684\u4e2a\u6027\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ea4\u4e92\u573a\u666f\u4e2d\u7684\u884c\u4e3a\u9009\u62e9\u6765\u8bc4\u4f30\u771f\u5b9e\u4e2a\u6027\uff0c\u7ed5\u8fc7\u4f20\u7edf\u8bc4\u4f30\u4e2d\u7684\u81ea\u6211\u8868\u73b0\u504f\u89c1\u3002", "result": "\u4f7f\u7528551\u4e2aGNWT\u4ee3\u7406\u548c\u54e5\u4f26\u6bd4\u4e9a\u5927\u5b66\u7ea6\u4f1a\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u4e0e\u4eba\u7c7b\u5438\u5f15\u6a21\u5f0f\u670972%\u7684\u76f8\u5173\u6027\uff0c\u5339\u914d\u9884\u6d4b\u51c6\u786e\u7387\u4e3a77.8%\uff0c\u5728\u4eba\u7c7b\u9a8c\u8bc1\u7814\u7a76\u4e2d\u8fbe\u523074%\u7684\u534f\u8bae\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u7403\u5de5\u4f5c\u7a7a\u95f4\u7406\u8bba\uff08GNWT\uff09\u7684\u8ba1\u7b97\u5b9e\u73b0\uff0c\u5c06\u4eba\u7c7b\u8ba4\u77e5\u67b6\u6784\u6574\u5408\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u5176\u5728\u6570\u5b57\u53cc\u80de\u80ce\u548c\u793e\u4ea4AI\u5e94\u7528\u4e2d\u7684\u771f\u5b9e\u6027\u3002\u6d4b\u8bd5\u7ed3\u679c\u8bc1\u660e\uff0c\u8fd9\u4e9b\u521b\u65b0\u4fc3\u8fdb\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5fc3\u7406\u771f\u5b9e\u6027\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u4e3a\u667a\u80fd\u7ea6\u4f1a\u5e73\u53f0\u548c\u4eba\u529b\u8d44\u6e90\u6280\u672f\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.03233", "pdf": "https://arxiv.org/pdf/2506.03233", "abs": "https://arxiv.org/abs/2506.03233", "authors": ["Andrea Ferrario"], "title": "A Trustworthiness-based Metaphysics of Artificial Intelligence Systems", "categories": ["cs.AI", "cs.CY", "cs.LG"], "comment": "To appear in the proceedings of 2025 ACM Conference on Fairness,\n  Accountability, and Transparency (FAccT '25)", "summary": "Modern AI systems are man-made objects that leverage machine learning to\nsupport our lives across a myriad of contexts and applications. Despite\nextensive epistemological and ethical debates, their metaphysical foundations\nremain relatively under explored. The orthodox view simply suggests that AI\nsystems, as artifacts, lack well-posed identity and persistence conditions --\ntheir metaphysical kinds are no real kinds. In this work, we challenge this\nperspective by introducing a theory of metaphysical identity of AI systems. We\ndo so by characterizing their kinds and introducing identity criteria -- formal\nrules that answer the questions \"When are two AI systems the same?\" and \"When\ndoes an AI system persist, despite change?\" Building on Carrara and Vermaas'\naccount of fine-grained artifact kinds, we argue that AI trustworthiness\nprovides a lens to understand AI system kinds and formalize the identity of\nthese artifacts by relating their functional requirements to their physical\nmake-ups. The identity criteria of AI systems are determined by their\ntrustworthiness profiles -- the collection of capabilities that the systems\nmust uphold over time throughout their artifact histories, and their\neffectiveness in maintaining these capabilities. Our approach suggests that the\nidentity and persistence of AI systems is sensitive to the socio-technical\ncontext of their design and utilization via their trustworthiness, providing a\nsolid metaphysical foundation to the epistemological, ethical, and legal\ndiscussions about these artifacts.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u63a2\u8ba8\u5176\u5f62\u800c\u4e0a\u5b66\u8eab\u4efd\uff0c\u8ba4\u4e3aAI\u7684\u8eab\u4efd\u4e0e\u6301\u4e45\u6027\u4e0e\u5176\u8bbe\u8ba1\u548c\u4f7f\u7528\u7684\u793e\u4f1a\u6280\u672f\u80cc\u666f\u76f8\u5173\uff0c\u63d0\u4f9b\u4e86\u5173\u4e8eAI\u7684\u5f3a\u6709\u529b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1\u5173\u4e8eAI\u7cfb\u7edf\u7684\u8ba4\u8bc6\u8bba\u548c\u4f26\u7406\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u4f46\u5176\u5f62\u800c\u4e0a\u5b66\u57fa\u7840\u4ecd\u7136\u76f8\u5bf9\u672a\u88ab\u6df1\u5165\u63a2\u8ba8\u3002\u6b63\u7edf\u89c2\u70b9\u8ba4\u4e3aAI\u7cfb\u7edf\u7531\u4e8e\u662f\u4eba\u5de5\u5236\u54c1\uff0c\u7f3a\u4e4f\u660e\u786e\u5b9a\u4e49\u7684\u8eab\u4efd\u548c\u6301\u4e45\u6761\u4ef6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u6311\u6218\u8fd9\u4e00\u89c2\u70b9\u3002", "method": "\u4f5c\u8005\u501f\u9274\u4e86Carrara\u548cVermaas\u7684\u7cbe\u7ec6\u5316\u4eba\u5de5\u5236\u54c1\u79cd\u7c7b\u7406\u8bba\uff0c\u63d0\u51fa\u901a\u8fc7AI\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u6765\u7406\u89e3\u5176\u79cd\u7c7b\uff0c\u5e76\u901a\u8fc7\u5c06\u5176\u529f\u80fd\u8981\u6c42\u4e0e\u7269\u7406\u6784\u6210\u8054\u7cfb\u8d77\u6765\u5f62\u5f0f\u5316\u8fd9\u4e9b\u4eba\u5de5\u5236\u54c1\u7684\u8eab\u4efd\u3002", "result": "AI\u7cfb\u7edf\u7684\u8eab\u4efd\u6807\u51c6\u662f\u7531\u5176\u53ef\u4fe1\u5ea6\u914d\u7f6e\u6587\u4ef6\u51b3\u5b9a\u7684\uff0c\u8fd9\u4e9b\u914d\u7f6e\u6587\u4ef6\u662f\u7cfb\u7edf\u5fc5\u987b\u5728\u5176\u4eba\u5de5\u5236\u54c1\u5386\u53f2\u4e2d\u4fdd\u6301\u7684\u80fd\u529b\u96c6\u5408\uff0c\u4ee5\u53ca\u5176\u5728\u7ef4\u6301\u8fd9\u4e9b\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u8868\u660e\uff0cAI\u7cfb\u7edf\u7684\u8eab\u4efd\u548c\u6301\u4e45\u6027\u4e0e\u5176\u8bbe\u8ba1\u548c\u4f7f\u7528\u7684\u793e\u4f1a\u6280\u672f\u80cc\u666f\u7d27\u5bc6\u76f8\u5173\uff0c\u5e76\u901a\u8fc7\u5176\u53ef\u4fe1\u5ea6\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u5f62\u800c\u4e0a\u5b66\u57fa\u7840\uff0c\u8fd9\u4e3a\u5173\u4e8e\u8fd9\u4e9b\u4eba\u5de5\u5236\u54c1\u7684\u8ba4\u8bc6\u8bba\u3001\u4f26\u7406\u548c\u6cd5\u5f8b\u8ba8\u8bba\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.03155", "pdf": "https://arxiv.org/pdf/2506.03155", "abs": "https://arxiv.org/abs/2506.03155", "authors": ["Yu Zheng"], "title": "Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The proliferation of artificial intelligence has enabled a diversity of\napplications that bridge the gap between digital and physical worlds. As\nphysical environments are too complex to model through a single information\nacquisition approach, it is crucial to fuse multimodal data generated by\ndifferent sources, such as sensors, devices, systems, and people, to solve a\nproblem in the real world. Unfortunately, it is neither applicable nor\nsustainable to deploy new resources to collect original data from scratch for\nevery problem. Thus, when data is inadequate in the domain of problem, it is\nvital to fuse knowledge from multimodal data that is already available in other\ndomains. We call this cross-domain knowledge fusion. Existing research focus on\nfusing multimodal data in a single domain, supposing the knowledge from\ndifferent datasets is intrinsically aligned; however, this assumption may not\nhold in the scenarios of cross-domain knowledge fusion. In this paper, we\nformally define the cross-domain multimodal data fusion problem, discussing its\nunique challenges, differences and advantages beyond data fusion in a single\ndomain. We propose a four-layer framework, consisting of Domains, Links, Models\nand Data layers, answering three key questions: \"what to fuse\", \"why can be\nfused\", and \"how to fuse\". The Domains Layer selects relevant data from\ndifferent domains for a given problem. The Links Layer reveals the philosophy\nof knowledge alignment beyond specific model structures. The Models Layer\nprovides two knowledge fusion paradigms based on the fundamental mechanisms for\nprocessing data. The Data Layer turns data of different structures,\nresolutions, scales and distributions into a consistent representation that can\nbe fed into an AI model. With this framework, we can design end-to-end\nsolutions that fuse cross-domain multimodal data effectively for solving\nreal-world problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56db\u5c42\u7684\u8de8\u57df\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u73b0\u5b9e\u73af\u5883\u7684\u590d\u6742\u6027\uff0c\u65e0\u6cd5\u901a\u8fc7\u5355\u4e00\u7684\u4fe1\u606f\u83b7\u53d6\u65b9\u5f0f\u8fdb\u884c\u5efa\u6a21\uff0c\u9700\u8981\u6574\u5408\u591a\u6e90\u751f\u6210\u7684\u591a\u6a21\u6001\u6570\u636e\u3002\u5728\u7279\u5b9a\u9886\u57df\u6570\u636e\u4e0d\u8db3\u65f6\uff0c\u901a\u8fc7\u8de8\u57df\u7684\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u6765\u5f25\u8865\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u62ec\u9886\u57df\u5c42\u3001\u94fe\u63a5\u5c42\u3001\u6a21\u578b\u5c42\u548c\u6570\u636e\u5c42\u7684\u56db\u5c42\u7ed3\u6784\u6846\u67b6\uff0c\u7528\u4ee5\u6307\u5bfc\u8de8\u57df\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u8bbe\u8ba1\u7aef\u5230\u7aef\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u8de8\u57df\u591a\u6a21\u6001\u6570\u636e\u7684\u878d\u5408\u4ee5\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56db\u5c42\u6846\u67b6\u7528\u4e8e\u8de8\u57df\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u3002"}}
{"id": "2506.03301", "pdf": "https://arxiv.org/pdf/2506.03301", "abs": "https://arxiv.org/abs/2506.03301", "authors": ["Daham M. Mustafa", "Abhishek Nadgeri", "Diego Collarana", "Benedikt T. Arnold", "Christoph Quix", "Christoph Lange", "Stefan Decker"], "title": "From Instructions to ODRL Usage Policies: An Ontology Guided Approach", "categories": ["cs.CL", "F.2.2; I.2.7; H.3.3"], "comment": "The paper is accepted at LLM+KG: International Workshop on Data\n  Management Opportunities in Unifying Large Language Models + Knowledge\n  Graphs, VLDB 2024, August 26, 2024, Guangzhou, China.\n  https://vldb.org/workshops/2024/proceedings/LLM+KG/LLM+KG-15.pdf", "summary": "This study presents an approach that uses large language models such as GPT-4\nto generate usage policies in the W3C Open Digital Rights Language ODRL\nautomatically from natural language instructions. Our approach uses the ODRL\nontology and its documentation as a central part of the prompt. Our research\nhypothesis is that a curated version of existing ontology documentation will\nbetter guide policy generation. We present various heuristics for adapting the\nODRL ontology and its documentation to guide an end-to-end KG construction\nprocess. We evaluate our approach in the context of dataspaces, i.e.,\ndistributed infrastructures for trustworthy data exchange between multiple\nparticipating organizations for the cultural domain. We created a benchmark\nconsisting of 12 use cases of varying complexity. Our evaluation shows\nexcellent results with up to 91.95% accuracy in the resulting knowledge graph.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7GPT-4\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u81ea\u52a8\u751f\u6210ODRL\u4f7f\u7528\u653f\u7b56\uff0c\u5c55\u793a\u4e86\u5728\u6587\u5316\u9886\u57df\u7684dataspaces\u4e2d\u7b56\u7565\u751f\u6210\u7684\u9ad8\u6548\u6027\uff0c\u51c6\u786e\u7387\u8fbe91.95%\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u662f\u9a8c\u8bc1\u4f18\u5316\u548c\u7b56\u5212\u7684\u672c\u4f53\u6587\u6863\u662f\u5426\u80fd\u66f4\u6709\u6548\u5730\u6307\u5bfc\u7b56\u7565\u751f\u6210\uff0c\u5e76\u63d0\u5347\u5728\u5206\u5e03\u5f0f\u4fe1\u4efb\u6570\u636e\u4ea4\u6362\u57fa\u7840\u8bbe\u65bd\u4e2d\u4f7f\u7528\u653f\u7b56\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u4e2d\u81ea\u52a8\u751f\u6210W3C\u5f00\u653e\u6570\u5b57\u6743\u5229\u8bed\u8a00\uff08ODRL\uff09\u4f7f\u7528\u653f\u7b56\u3002\u4e2d\u67a2\u63d0\u793a\u4e3aODRL\u672c\u4f53\u53ca\u5176\u6587\u6863\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\u6765\u9002\u5e94ODRL\u672c\u4f53\u548c\u6587\u6863\uff0c\u4ee5\u6307\u5bfc\u7aef\u5230\u7aef\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u8fc7\u7a0b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u4ed6\u4eec\u7684\u65b9\u6cd5\u5728\u6587\u5316\u9886\u57dfdataspaces\u4e2d\uff0c\u77e5\u8bc6\u56fe\u8c31\u7684\u6784\u5efa\u51c6\u786e\u7387\u9ad8\u8fbe91.95%\u3002", "conclusion": "\u8be5\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u7ecf\u8fc7\u7b56\u5212\u7684\u672c\u4f53\u6587\u6863\u53ef\u4ee5\u66f4\u597d\u5730\u6307\u5bfc\u7b56\u7565\u751f\u6210\uff0c\u5e76\u5728\u6587\u5316\u9886\u57df\u7684dataspaces\u4e2d\u53d6\u5f97\u9ad8\u8fbe91.95%\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2506.03546", "pdf": "https://arxiv.org/pdf/2506.03546", "abs": "https://arxiv.org/abs/2506.03546", "authors": ["Yuanchen Bai", "Zijian Ding", "Angelique Taylor"], "title": "From Virtual Agents to Robot Teams: A Multi-Robot Framework Evaluation in High-Stakes Healthcare Context", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "Advancements in generative models have enabled multi-agent systems (MAS) to\nperform complex virtual tasks such as writing and code generation, which do not\ngeneralize well to physical multi-agent robotic teams. Current frameworks often\ntreat agents as conceptual task executors rather than physically embodied\nentities, and overlook critical real-world constraints such as spatial context,\nrobotic capabilities (e.g., sensing and navigation). To probe this gap, we\nreconfigure and stress-test a hierarchical multi-agent robotic team built on\nthe CrewAI framework in a simulated emergency department onboarding scenario.\nWe identify five persistent failure modes: role misalignment; tool access\nviolations; lack of in-time handling of failure reports; noncompliance with\nprescribed workflows; bypassing or false reporting of task completion. Based on\nthis analysis, we propose three design guidelines emphasizing process\ntransparency, proactive failure recovery, and contextual grounding. Our work\ninforms the development of more resilient and robust multi-agent robotic\nsystems (MARS), including opportunities to extend virtual multi-agent\nframeworks to the real world.", "AI": {"tldr": "\u5206\u6790\u4e86\u751f\u6210\u6a21\u578b\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u8bbe\u8ba1\u6307\u5357\u4ee5\u63d0\u9ad8\u673a\u5668\u4eba\u56e2\u961f\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u6a21\u578b\u7684\u8fdb\u6b65\u4f7f\u591a\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u6267\u884c\u590d\u6742\u7684\u865a\u62df\u4efb\u52a1\uff0c\u4f46\u8fd9\u4e9b\u4efb\u52a1\u5e76\u4e0d\u80fd\u5f88\u597d\u5730\u63a8\u5e7f\u5230\u7269\u7406\u591a\u4ee3\u7406\u673a\u5668\u4eba\u56e2\u961f\u4e2d\u3002", "method": "\u901a\u8fc7\u5728\u6a21\u62df\u7684\u6025\u8bca\u79d1\u5165\u804c\u573a\u666f\u4e2d\u91cd\u65b0\u914d\u7f6e\u548c\u538b\u529b\u6d4b\u8bd5\u57fa\u4e8eCrewAI\u6846\u67b6\u7684\u5206\u5c42\u591a\u4ee3\u7406\u673a\u5668\u4eba\u56e2\u961f\uff0c\u5206\u6790\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u6211\u4eec\u8bc6\u522b\u4e86\u4e94\u79cd\u6301\u4e45\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u89d2\u8272\u4e0d\u5339\u914d\u3001\u5de5\u5177\u8bbf\u95ee\u8fdd\u89c4\u3001\u672a\u53ca\u65f6\u5904\u7406\u6545\u969c\u62a5\u544a\u3001\u4e0d\u9075\u5faa\u9884\u5b9a\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u53ca\u89c4\u907f\u6216\u865a\u5047\u62a5\u544a\u4efb\u52a1\u5b8c\u6210\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e09\u9879\u8bbe\u8ba1\u6307\u5357\uff0c\u5f3a\u8c03\u8fc7\u7a0b\u900f\u660e\u6027\u3001\u4e3b\u52a8\u6545\u969c\u6062\u590d\u548c\u4e0a\u4e0b\u6587\u63a5\u5730\uff0c\u4ee5\u5f00\u53d1\u66f4\u5177\u5f39\u6027\u548c\u9c81\u68d2\u6027\u7684\u591a\u4ee3\u7406\u673a\u5668\u4eba\u7cfb\u7edf\u3002"}}
{"id": "2506.03315", "pdf": "https://arxiv.org/pdf/2506.03315", "abs": "https://arxiv.org/abs/2506.03315", "authors": ["Kai Sauerwald", "Kenneth Skiba", "Eduardo Ferm\u00e9", "Thomas Meyer"], "title": "Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback", "categories": ["cs.AI", "cs.LO", "03E99, 91B14", "I.2.4"], "comment": null, "summary": "We study how linear orders can be employed to realise choice functions for\nwhich the set of potential choices is restricted, i.e., the possible choice is\nnot possible among the full powerset of all alternatives. In such restricted\nsettings, constructing a choice function via a relation on the alternatives is\nnot always possible. However, we show that one can always construct a choice\nfunction via a linear order on sets of alternatives, even when a fallback value\nis encoded as the minimal element in the linear order. The axiomatics of such\nchoice functions are presented for the general case and the case of\nunion-closed input restrictions. Restricted choice structures have applications\nin knowledge representation and reasoning, and here we discuss their\napplications for theory change and abstract argumentation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u901a\u8fc7\u7ebf\u6027\u6392\u5e8f\u5728\u53d7\u9650\u9009\u62e9\u8bbe\u7f6e\u4e2d\u6784\u5efa\u9009\u62e9\u51fd\u6570\uff0c\u5c55\u793a\u4e86\u5176\u5728\u77e5\u8bc6\u8868\u793a\u548c\u63a8\u7406\u65b9\u9762\u7684\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u7814\u7a76\u53d7\u9650\u9009\u62e9\u8bbe\u7f6e\u4e2d\u7684\u9009\u62e9\u51fd\u6570\u7684\u6784\u5efa\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u7ebf\u6027\u6392\u5e8f\u6784\u5efa\u9009\u62e9\u51fd\u6570\u3002", "result": "\u5373\u4f7f\u5728\u6709\u9650\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u5bf9\u5907\u9009\u65b9\u6848\u96c6\u5408\u7684\u7ebf\u6027\u6392\u5e8f\uff0c\u603b\u80fd\u6784\u5efa\u9009\u62e9\u51fd\u6570\u3002", "conclusion": "\u7ebf\u6027\u6392\u5e8f\u5728\u53d7\u9650\u9009\u62e9\u8bbe\u7f6e\u4e2d\u662f\u6709\u6548\u7684\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2506.03158", "pdf": "https://arxiv.org/pdf/2506.03158", "abs": "https://arxiv.org/abs/2506.03158", "authors": ["Jiahao Qin", "Bei Peng", "Feng Liu", "Guangliang Cheng", "Lu Zong"], "title": "DUAL: Dynamic Uncertainty-Aware Learning", "categories": ["cs.LG", "cs.CV"], "comment": "12 pages, 3 figures", "summary": "Deep learning models frequently encounter feature uncertainty in diverse\nlearning scenarios, significantly impacting their performance and reliability.\nThis challenge is particularly complex in multi-modal scenarios, where models\nmust integrate information from different sources with inherent uncertainties.\nWe propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that\neffectively handles feature uncertainty in both single-modal and multi-modal\nscenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty\nModeling, which continuously refines uncertainty estimates through joint\nconsideration of feature characteristics and learning dynamics; Adaptive\nDistribution-Aware Modulation, which maintains balanced feature distributions\nthrough dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal\nRelationship Learning, which explicitly models uncertainties in cross-modal\ninteractions. Through extensive experiments, we demonstrate DUAL's\neffectiveness across multiple domains: in computer vision tasks, it achieves\nsubstantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on\nCIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it\ndemonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy\non CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements\non MISR. The code will be available on GitHub soon.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5b66\u4e60\uff08DUAL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u7b49\u521b\u65b0\uff0c\u63d0\u9ad8\u89c6\u89c9\u548c\u591a\u6a21\u6001\u5b66\u4e60\u4efb\u52a1\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5404\u79cd\u5b66\u4e60\u573a\u666f\u4e2d\u7ecf\u5e38\u9047\u5230\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u663e\u8457\u5f71\u54cd\u4e86\u5176\u6027\u80fd\u548c\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u591a\u6a21\u6001\u573a\u666f\u4e2d\uff0c\u9700\u8981\u6574\u5408\u6765\u6e90\u4e0d\u540c\u4e14\u5177\u6709\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u7684\u591a\u79cd\u4fe1\u606f\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u52a8\u6001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5b66\u4e60\uff08DUAL\uff09\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3001\u81ea\u9002\u5e94\u5206\u5e03\u611f\u77e5\u8c03\u5236\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8de8\u6a21\u6001\u5173\u7cfb\u5b66\u4e60\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u6765\u6709\u6548\u5904\u7406\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4e2d\uff0cDUAL\u5728\u591a\u4e2a\u9886\u57df\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff1a\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\uff0c\u5728CIFAR-10\u4e0a\u63d0\u9ad8\u4e867.1%\u7684\u51c6\u786e\u7387\uff0c\u5728CIFAR-100\u4e0a\u63d0\u9ad8\u4e866.5%\uff0c\u5728Tiny-ImageNet\u4e0a\u63d0\u9ad8\u4e862.3%\uff1b\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\uff0c\u5728\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u5728CMU-MOSEI\u4e0a\u63d0\u5347\u4e864.1%\u7684\u51c6\u786e\u7387\uff0c\u5728CMU-MOSI\u4e0a\u63d0\u5347\u4e862.8%\uff0c\u5728MISR\u4e0a\u63d0\u9ad8\u4e861.4%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "DUAL\u6846\u67b6\u901a\u8fc7\u6709\u6548\u7ba1\u7406\u7279\u5f81\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.03303", "pdf": "https://arxiv.org/pdf/2506.03303", "abs": "https://arxiv.org/abs/2506.03303", "authors": ["Mustafa Eyceoz", "Nikhil Shivakumar Nayak", "Hao Wang", "Ligong Han", "Akash Srivastava"], "title": "Hopscotch: Discovering and Skipping Redundancies in Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; I.2.6; I.2.4"], "comment": "10 pages, 4 figures, 9 tables", "summary": "Modern causal language models stack many attention blocks to improve\nperformance, but not all blocks are necessary for every task. We propose\nHopscotch, a simple yet effective method that identifies and skips attention\nblocks with least contributions to a task and adapts to preserve output\nquality. Hopscotch jointly optimizes which blocks to skip and how to scale the\noutputs of the remaining layers. By introducing lightweight, trainable scaling\nparameters to attention and MLP blocks, it mitigates distribution shifts in\nhidden states caused by removing attention blocks. Hopscotch does not modify\nmodel weights or require access to pretraining or instruction-tuning data, and\nis compatible with existing model compression techniques. When applied to\n$\\texttt{Llama-3.1-8B}$ and $\\texttt{Qwen2.5-7B}$, Hopscotch achieves less than\na 2% drop in performance even after skipping four attention blocks.", "AI": {"tldr": "Hopscotch\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u5e76\u8df3\u8fc7\u5bf9\u4efb\u52a1\u8d21\u732e\u6700\u5c0f\u7684\u6ce8\u610f\u529b\u5757\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u63d0\u5347\uff0c\u540c\u65f6\u786e\u4fdd\u8f93\u51fa\u8d28\u91cf\u4e0d\u53d7\u5f71\u54cd\u3002", "motivation": "\u8bb8\u591a\u73b0\u4ee3\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u5806\u53e0\u4e86\u8bb8\u591a\u6ce8\u610f\u529b\u5757\u6765\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u5e76\u975e\u6240\u6709\u6ce8\u610f\u529b\u5757\u5bf9\u4e8e\u6bcf\u4e2a\u4efb\u52a1\u90fd\u662f\u5fc5\u8981\u7684\u3002", "method": "Hopscotch\u901a\u8fc7\u5f15\u5165\u8f7b\u91cf\u7ea7\u3001\u53ef\u8bad\u7ec3\u7684\u7f29\u653e\u53c2\u6570\u6765\u4f18\u5316\u8df3\u8fc7\u54ea\u4e9b\u6ce8\u610f\u529b\u5757\uff0c\u5e76\u6839\u636e\u9700\u8981\u8c03\u6574\u5269\u4f59\u5c42\u7684\u8f93\u51fa\u3002", "result": "\u7ecf\u8fc7Hopscotch\u5904\u7406\u540e\uff0c\u5373\u4fbf\u8df3\u8fc7\u4e86\u56db\u4e2a\u6ce8\u610f\u529b\u5757\uff0c\u6027\u80fd\u4e0b\u964d\u4e5f\u4e0d\u8d85\u8fc72%\u3002", "conclusion": "Hopscotch\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u6743\u91cd\u53ca\u65e0\u9700\u8bbf\u95ee\u9884\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.03801", "pdf": "https://arxiv.org/pdf/2506.03801", "abs": "https://arxiv.org/abs/2506.03801", "authors": ["Peter Pfeiffer", "Alexander Rombach", "Maxim Majlatow", "Nijat Mehdiyev"], "title": "From Theory to Practice: Real-World Use Cases on Trustworthy LLM-Driven Process Modeling, Prediction and Automation", "categories": ["cs.SE", "cs.LG", "cs.MA"], "comment": "Accepted to the Next Gen Data and Process Management: Large Language\n  Models and Beyond workshop at SIGMOD 2025", "summary": "Traditional Business Process Management (BPM) struggles with rigidity,\nopacity, and scalability in dynamic environments while emerging Large Language\nModels (LLMs) present transformative opportunities alongside risks. This paper\nexplores four real-world use cases that demonstrate how LLMs, augmented with\ntrustworthy process intelligence, redefine process modeling, prediction, and\nautomation. Grounded in early-stage research projects with industrial partners,\nthe work spans manufacturing, modeling, life-science, and design processes,\naddressing domain-specific challenges through human-AI collaboration. In\nmanufacturing, an LLM-driven framework integrates uncertainty-aware explainable\nMachine Learning (ML) with interactive dialogues, transforming opaque\npredictions into auditable workflows. For process modeling, conversational\ninterfaces democratize BPMN design. Pharmacovigilance agents automate drug\nsafety monitoring via knowledge-graph-augmented LLMs. Finally, sustainable\ntextile design employs multi-agent systems to navigate regulatory and\nenvironmental trade-offs. We intend to examine tensions between transparency\nand efficiency, generalization and specialization, and human agency versus\nautomation. By mapping these trade-offs, we advocate for context-sensitive\nintegration prioritizing domain needs, stakeholder values, and iterative\nhuman-in-the-loop workflows over universal solutions. This work provides\nactionable insights for researchers and practitioners aiming to operationalize\nLLMs in critical BPM environments.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86LLM\u5728\u6d41\u7a0b\u5efa\u6a21\u3001\u9884\u6d4b\u548c\u81ea\u52a8\u5316\u4e2d\u7684\u56db\u4e2a\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\uff0c\u5f3a\u8c03\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u548c\u9886\u57df\u7279\u5b9a\u9700\u6c42\u6765\u5b9e\u73b0\u5176\u5728BPM\u4e2d\u7684\u6574\u5408\u3002", "motivation": "\u4f20\u7edf\u7684\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406\uff08BPM\uff09\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b58\u5728\u521a\u6027\u3001\u4e0d\u900f\u660e\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u800c\u65b0\u5174\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5219\u63d0\u4f9b\u4e86\u53d8\u9769\u6027\u673a\u4f1a\u548c\u98ce\u9669\uff0c\u4fc3\u4f7f\u672c\u6587\u7814\u7a76LLM\u5982\u4f55\u5728BPM\u4e2d\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u7ed3\u5408\u5de5\u4e1a\u4f19\u4f34\u7684\u65e9\u671f\u7814\u7a76\u9879\u76ee\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u4eba\u673a\u534f\u4f5c\uff0c\u5728\u5236\u9020\u3001\u5efa\u6a21\u3001\u751f\u547d\u79d1\u5b66\u548c\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u5c55\u793aLLM\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLLM\u53ef\u4ee5\u901a\u8fc7\u5c06\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u4e0e\u4ea4\u4e92\u5f0f\u5bf9\u8bdd\u7ed3\u5408\uff0c\u5b9e\u73b0\u5236\u9020\u6d41\u7a0b\u4e2d\u7684\u900f\u660e\u5316\uff0c\u5e76\u5728\u6d41\u7a0b\u5efa\u6a21\u4e2d\u901a\u8fc7\u5bf9\u8bdd\u754c\u9762\u6c11\u4e3b\u5316BPMN\u8bbe\u8ba1\u3002\u836f\u7269\u8b66\u6212\u4ee3\u7406\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684LLM\u81ea\u52a8\u5316\u836f\u7269\u5b89\u5168\u76d1\u63a7\uff0c\u800c\u53ef\u6301\u7eed\u7eba\u7ec7\u8bbe\u8ba1\u5229\u7528\u591a\u4ee3\u7406\u7cfb\u7edf\u5e73\u8861\u6cd5\u89c4\u4e0e\u73af\u5883\u7684\u6743\u8861\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u56db\u4e2a\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5982\u4f55\u901a\u8fc7\u53ef\u4fe1\u7684\u6d41\u7a0b\u667a\u80fd\u91cd\u65b0\u5b9a\u4e49\u6d41\u7a0b\u5efa\u6a21\u3001\u9884\u6d4b\u548c\u81ea\u52a8\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u5728\u5404\u79cd\u884c\u4e1a\u4e2d\u5e94\u7528\u7684\u53ef\u64cd\u4f5c\u6027\u6d1e\u89c1\u3002"}}
{"id": "2506.03332", "pdf": "https://arxiv.org/pdf/2506.03332", "abs": "https://arxiv.org/abs/2506.03332", "authors": ["Yifei Ming", "Zixuan Ke", "Xuan-Phi Nguyen", "Jiayu Wang", "Shafiq Joty"], "title": "Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows", "categories": ["cs.AI"], "comment": null, "summary": "Agentic workflows -- where multiple large language model (LLM) instances\ninteract to solve tasks -- are increasingly built on feedback mechanisms, where\none model evaluates and critiques another. Despite the promise of\nfeedback-driven improvement, the stability of agentic workflows rests on the\nreliability of the judge. However, judges may hallucinate information, exhibit\nbias, or act adversarially -- introducing critical vulnerabilities into the\nworkflow. In this work, we present a systematic analysis of agentic workflows\nunder deceptive or misleading feedback. We introduce a two-dimensional\nframework for analyzing judge behavior, along axes of intent (from constructive\nto malicious) and knowledge (from parametric-only to retrieval-augmented\nsystems). Using this taxonomy, we construct a suite of judge behaviors and\ndevelop WAFER-QA, a new benchmark with critiques grounded in retrieved web\nevidence to evaluate robustness of agentic workflows against factually\nsupported adversarial feedback. We reveal that even strongest agents are\nvulnerable to persuasive yet flawed critiques -- often switching correct\nanswers after a single round of misleading feedback. Taking a step further, we\nstudy how model predictions evolve over multiple rounds of interaction,\nrevealing distinct behavioral patterns between reasoning and non-reasoning\nmodels. Our findings highlight fundamental vulnerabilities in feedback-based\nworkflows and offer guidance for building more robust agentic systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u5b58\u5728\u6b3a\u9a97\u6027\u6216\u8bef\u5bfc\u6027\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u8106\u5f31\u6027\uff0c\u4ecb\u7ecd\u4e86\u7528\u4e8e\u8bc4\u4f30\u4ee3\u7406\u5de5\u4f5c\u6d41\u9c81\u68d2\u6027\u7684WAFER-QA\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5728\u5177\u6709\u8bf4\u670d\u529b\u7684\u6279\u8bc4\u4e0b\uff0c\u5373\u4f7f\u662f\u5f3a\u5927\u7684\u4ee3\u7406\u4e5f\u4f1a\u6539\u53d8\u6b63\u786e\u7b54\u6848\uff0c\u5e76\u63d0\u4f9b\u4e86\u9632\u6b62\u6b64\u7c7b\u8106\u5f31\u6027\u7684\u65b9\u6cd5\u8bba\u6307\u5bfc\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u53cd\u9988\u7684\u6539\u8fdb\u6709\u524d\u666f\uff0c\u4f46\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u7a33\u5b9a\u6027\u4f9d\u8d56\u4e8e\u6cd5\u5b98\u7684\u53ef\u9760\u6027\u3002\u7136\u800c\uff0c\u6cd5\u5b98\u53ef\u80fd\u4f1a\u4ea7\u751f\u5e7b\u89c9\u4fe1\u606f\uff0c\u8868\u73b0\u51fa\u504f\u89c1\u6216\u91c7\u53d6\u5bf9\u6297\u884c\u4e3a\uff0c\u4ece\u800c\u5bf9\u5de5\u4f5c\u6d41\u5f15\u5165\u5173\u952e\u6f0f\u6d1e\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u5206\u6790\u6cd5\u5b98\u884c\u4e3a\u7684\u4e8c\u7ef4\u6846\u67b6\uff0c\u57fa\u4e8e\u610f\u56fe\uff08\u4ece\u5efa\u8bbe\u6027\u5230\u6076\u610f\uff09\u548c\u77e5\u8bc6\uff08\u4ece\u4ec5\u53c2\u6570\u5230\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\uff09\u7684\u8f74\u7ebf\u3002\u4f7f\u7528\u8be5\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u4e86\u4e00\u5957\u6cd5\u5b98\u884c\u4e3a\uff0c\u5e76\u5f00\u53d1\u4e86WAFER-QA\uff0c\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u4e0e\u68c0\u7d22\u5230\u7684\u7f51\u7edc\u8bc1\u636e\u76f8\u5173\u7684\u6279\u8bc4\u6765\u8bc4\u4f30\u4ee3\u7406\u5de5\u4f5c\u6d41\u5bf9\u4e8b\u5b9e\u652f\u6301\u7684\u5bf9\u6297\u6027\u53cd\u9988\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5f3a\u5927\u7684\u4ee3\u7406\u5728\u9762\u5bf9\u5177\u6709\u8bf4\u670d\u529b\u4f46\u6709\u7f3a\u9677\u7684\u6279\u8bc4\u65f6\u4e5f\u662f\u8106\u5f31\u7684\uff0c\u4e14\u63a8\u7406\u6a21\u578b\u548c\u975e\u63a8\u7406\u6a21\u578b\u5728\u591a\u8f6e\u4e92\u52a8\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5373\u4f7f\u662f\u6700\u5f3a\u5927\u7684\u4ee3\u7406\u4e5f\u5bb9\u6613\u53d7\u5230\u5177\u6709\u8bf4\u670d\u529b\u4f46\u6709\u7f3a\u9677\u7684\u6279\u8bc4\u7684\u5f71\u54cd\uff0c\u901a\u5e38\u5728\u4e00\u8f6e\u8bef\u5bfc\u6027\u7684\u53cd\u9988\u540e\u5c31\u4f1a\u6539\u53d8\u6b63\u786e\u7b54\u6848\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u548c\u975e\u63a8\u7406\u6a21\u578b\u5728\u591a\u8f6e\u4e92\u52a8\u4e2d\u7684\u884c\u4e3a\u6a21\u5f0f\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2506.03159", "pdf": "https://arxiv.org/pdf/2506.03159", "abs": "https://arxiv.org/abs/2506.03159", "authors": ["Lesley Wheat", "Martin v. Mohrenschildt", "Saeid Habibi"], "title": "Bayes Error Rate Estimation in Difficult Situations", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": "21 pages, 13 figures, 20 tables", "summary": "The Bayes Error Rate (BER) is the fundamental limit on the achievable\ngeneralizable classification accuracy of any machine learning model due to\ninherent uncertainty within the data. BER estimators offer insight into the\ndifficulty of any classification problem and set expectations for optimal\nclassification performance. In order to be useful, the estimators must also be\naccurate with a limited number of samples on multivariate problems with unknown\nclass distributions. To determine which estimators meet the minimum\nrequirements for \"usefulness\", an in-depth examination of their accuracy is\nconducted using Monte Carlo simulations with synthetic data in order to obtain\ntheir confidence bounds for binary classification. To examine the usability of\nthe estimators on real-world applications, new test scenarios are introduced\nupon which 2500 Monte Carlo simulations per scenario are run over a wide range\nof BER values. In a comparison of k-Nearest Neighbor (kNN), Generalized\nHenze-Penrose (GHP) divergence and Kernel Density Estimation (KDE) techniques,\nresults show that kNN is overwhelmingly the more accurate non-parametric\nestimator. In order to reach the target of an under 5 percent range for the 95\npercent confidence bounds, the minimum number of required samples per class is\n1000. As more features are added, more samples are needed, so that 2500 samples\nper class are required at only 4 features. Other estimators do become more\naccurate than kNN as more features are added, but continuously fail to meet the\ntarget range.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u51e0\u79cdBER\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u8499\u7279\u5361\u7f57\u6a21\u62df\u8bc4\u4f30\u5176\u5728\u6709\u9650\u6837\u672c\u4e0b\u7684\u51c6\u786e\u6027\uff0c\u53d1\u73b0kNN\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u662f\u6700\u51c6\u786e\u7684\u4f30\u8ba1\u5668\uff0c\u4f46\u5f53\u589e\u52a0\u7279\u5f81\u6570\u540e\u9700\u8981\u66f4\u591a\u6837\u672c\u3002", "motivation": "BER\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u5206\u7c7b\u95ee\u9898\u96be\u5ea6\u7684\u6d1e\u5bdf\uff0c\u5e76\u4e3a\u4f18\u5316\u5206\u7c7b\u6027\u80fd\u8bbe\u5b9a\u671f\u671b\u3002\u4e3a\u4e86\u5b9e\u7528\u6027\uff0c\u4f30\u8ba1\u5668\u9700\u8981\u5728\u6709\u9650\u6837\u672c\u548c\u672a\u77e5\u5206\u5e03\u60c5\u51b5\u4e0b\u51c6\u786e\u3002", "method": "\u4f7f\u7528\u8499\u7279\u5361\u7f57\u6a21\u62df\u8fdb\u884c\u6df1\u5165\u7684\u51c6\u786e\u6027\u68c0\u67e5\uff0c\u5e76\u5728\u4e0d\u540c\u7684\u6d4b\u8bd5\u573a\u666f\u4e0b\u8fdb\u884c2500\u6b21\u8499\u7279\u5361\u7f57\u6a21\u62df\u3002", "result": "\u7ed3\u679c\u663e\u793ak-\u6700\u8fd1\u90bb\uff08kNN\uff09\u4f5c\u4e3a\u975e\u53c2\u6570\u4f30\u8ba1\u5668\u5728\u8499\u7279\u5361\u7f57\u6a21\u62df\u4e2d\u5c55\u73b0\u4e86\u538b\u5012\u6027\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5728\u7ed9\u5b9a\u7684\u5206\u7c7b\u95ee\u9898\u4e2d\uff0ckNN\u88ab\u8bc1\u660e\u662f\u6700\u51c6\u786e\u7684\u975e\u53c2\u6570\u4f30\u8ba1\u5668\u3002\u5c3d\u7ba1\u5f53\u7279\u5f81\u6570\u589e\u52a0\u65f6\u6709\u4e9b\u4f30\u8ba1\u5668\u7684\u51c6\u786e\u6027\u8d85\u8fc7\u4e86kNN\uff0c\u4f46\u5b83\u4eec\u65e0\u6cd5\u6301\u7eed\u8fbe\u5230\u76ee\u6807\u8303\u56f4\u3002"}}
{"id": "2506.03310", "pdf": "https://arxiv.org/pdf/2506.03310", "abs": "https://arxiv.org/abs/2506.03310", "authors": ["Guillermo Marco", "Julio Gonzalo", "V\u00edctor Fresno"], "title": "The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing", "categories": ["cs.CL", "cs.HC"], "comment": "Camera-ready version, 14 pages, 3 figures. Accepted to Findings of\n  the Association for Computational Linguistics (ACL) 2025. Code & data:\n  https://github.com/grmarco/the-reader-is-the-metric", "summary": "Recent studies comparing AI-generated and human-authored literary texts have\nproduced conflicting results: some suggest AI already surpasses human quality,\nwhile others argue it still falls short. We start from the hypothesis that such\ndivergences can be largely explained by genuine differences in how readers\ninterpret and value literature, rather than by an intrinsic quality of the\ntexts evaluated. Using five public datasets (1,471 stories, 101 annotators\nincluding critics, students, and lay readers), we (i) extract 17 reference-less\ntextual features (e.g., coherence, emotional variance, average sentence\nlength...); (ii) model individual reader preferences, deriving feature\nimportance vectors that reflect their textual priorities; and (iii) analyze\nthese vectors in a shared \"preference space\". Reader vectors cluster into two\nprofiles: 'surface-focused readers' (mainly non-experts), who prioritize\nreadability and textual richness; and 'holistic readers' (mainly experts), who\nvalue thematic development, rhetorical variety, and sentiment dynamics. Our\nresults quantitatively explain how measurements of literary quality are a\nfunction of how text features align with each reader's preferences. These\nfindings advocate for reader-sensitive evaluation frameworks in the field of\ncreative text generation.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u751f\u6210\u548c\u4eba\u7c7b\u521b\u4f5c\u7684\u6587\u5b66\u4f5c\u54c1\u54c1\u8d28\u8bc4\u4f30\u7684\u5206\u6b67\uff0c\u63ed\u793a\u4e86\u8bfb\u8005\u504f\u597d\u7684\u5dee\u5f02\u5f71\u54cd\u6587\u672c\u8bc4\u4ef7\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u6587\u5b66\u6587\u672c\u4e0e\u4eba\u7c7b\u521b\u4f5c\u7684\u6587\u5b66\u4f5c\u54c1\u5728\u54c1\u8d28\u8bc4\u4f30\u4e0a\u7684\u5206\u6b67\uff0c\u4ee5\u53ca\u8bfb\u8005\u5728\u89e3\u8bfb\u548c\u8bc4\u4ef7\u6587\u5b66\u4f5c\u54c1\u65f6\u7684\u5dee\u5f02\u3002", "method": "\u91c7\u7528\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\uff0c\u5305\u62ec1471\u4e2a\u6545\u4e8b\u548c101\u540d\u6ce8\u91ca\u8005\uff0c\u901a\u8fc7\u63d0\u53d617\u4e2a\u65e0\u53c2\u8003\u7684\u6587\u672c\u7279\u5f81\uff0c\u5efa\u6a21\u4e2a\u4eba\u8bfb\u8005\u504f\u597d\uff0c\u5206\u6790\u7279\u5f81\u91cd\u8981\u6027\u5411\u91cf\uff0c\u5e76\u5728\u5171\u4eab\u7684\u201c\u504f\u597d\u7a7a\u95f4\u201d\u4e2d\u5206\u6790\u8fd9\u4e9b\u5411\u91cf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bfb\u8005\u7684\u504f\u597d\u5411\u91cf\u805a\u96c6\u6210\u4e24\u79cd\u7c7b\u578b\uff1a\u4e00\u7c7b\u662f'\u8868\u9762\u5173\u6ce8\u578b\u8bfb\u8005'\uff0c\u4ed6\u4eec\u4e3b\u8981\u5173\u6ce8\u53ef\u8bfb\u6027\u548c\u6587\u672c\u4e30\u5bcc\u6027\uff1b\u53e6\u4e00\u7c7b\u662f'\u6574\u4f53\u5173\u6ce8\u578b\u8bfb\u8005'\uff0c\u4ed6\u4eec\u66f4\u770b\u91cd\u4e3b\u9898\u53d1\u5c55\u3001\u4fee\u8f9e\u591a\u6837\u6027\u548c\u60c5\u611f\u52a8\u6001\u3002", "conclusion": "\u4e0d\u540c\u7684\u8bfb\u8005\u504f\u597d\u663e\u8457\u5f71\u54cd\u5bf9\u6587\u5b66\u4f5c\u54c1\u8d28\u91cf\u7684\u8bc4\u4f30\uff0c\u5efa\u8bae\u5728\u521b\u610f\u6587\u672c\u751f\u6210\u9886\u57df\u91c7\u7528\u8bfb\u8005\u654f\u611f\u7684\u8bc4\u4ef7\u6846\u67b6\u3002"}}
{"id": "2506.03828", "pdf": "https://arxiv.org/pdf/2506.03828", "abs": "https://arxiv.org/abs/2506.03828", "authors": ["Dhaval Patel", "Shuxin Lin", "James Rayfield", "Nianjun Zhou", "Roman Vaculin", "Natalia Martinez", "Fearghal O'donncha", "Jayant Kalagnanam"], "title": "AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance", "categories": ["cs.AI", "cs.MA"], "comment": "39 pages, 18 figures", "summary": "AI for Industrial Asset Lifecycle Management aims to automate complex\noperational workflows -- such as condition monitoring, maintenance planning,\nand intervention scheduling -- to reduce human workload and minimize system\ndowntime. Traditional AI/ML approaches have primarily tackled these problems in\nisolation, solving narrow tasks within the broader operational pipeline. In\ncontrast, the emergence of AI agents and large language models (LLMs)\nintroduces a next-generation opportunity: enabling end-to-end automation across\nthe entire asset lifecycle. This paper envisions a future where AI agents\nautonomously manage tasks that previously required distinct expertise and\nmanual coordination. To this end, we introduce AssetOpsBench -- a unified\nframework and environment designed to guide the development, orchestration, and\nevaluation of domain-specific agents tailored for Industry 4.0 applications. We\noutline the key requirements for such holistic systems and provide actionable\ninsights into building agents that integrate perception, reasoning, and control\nfor real-world industrial operations. The software is available at\nhttps://github.com/IBM/AssetOpsBench.", "AI": {"tldr": "The paper introduces AssetOpsBench, a framework for AI-driven automation of industrial asset management, envisioning end-to-end solutions using AI agents and LLMs.", "motivation": "Existing AI/ML approaches often address industrial asset management tasks in isolation, which limits efficiency. The paper seeks to provide a holistic solution by utilizing AI agents and LLMs to automate the entire asset lifecycle.", "method": "Introduction of AssetOpsBench, a unified framework and environment for the development, orchestration, and evaluation of domain-specific agents for Industry 4.0 applications.", "result": "The paper provides a framework for developing AI agents capable of integrating perception, reasoning, and control in industry-specific operations, enhancing automation across the full asset lifecycle.", "conclusion": "AI agents and large language models (LLMs) can enable end-to-end automation for industrial asset lifecycle management, handling tasks that previously required human expertise."}}
{"id": "2506.03469", "pdf": "https://arxiv.org/pdf/2506.03469", "abs": "https://arxiv.org/abs/2506.03469", "authors": ["Tuan Le", "Risal Shefin", "Debashis Gupta", "Thai Le", "Sarra Alqahtani"], "title": "Verification-Guided Falsification for Safe RL via Explainable Abstraction and Risk-Aware Exploration", "categories": ["cs.AI", "cs.LG"], "comment": "8 pages, 7 figures, European Conference on Artificial Intelligence\n  (ECAI)", "summary": "Ensuring the safety of reinforcement learning (RL) policies in high-stakes\nenvironments requires not only formal verification but also interpretability\nand targeted falsification. While model checking provides formal guarantees,\nits effectiveness is limited by abstraction quality and the completeness of the\nunderlying trajectory dataset. We propose a hybrid framework that integrates\n(1) explainability, (2) model checking, and (3) risk-guided falsification to\nachieve both rigor and coverage. Our approach begins by constructing a\nhuman-interpretable abstraction of the RL policy using Comprehensible Abstract\nPolicy Summarization (CAPS). This abstract graph, derived from offline\ntrajectories, is both verifier-friendly, semantically meaningful, and can be\nused as input to Storm probabilistic model checker to verify satisfaction of\ntemporal safety specifications. If the model checker identifies a violation, it\nwill return an interpretable counterexample trace by which the policy fails the\nsafety requirement. However, if no violation is detected, we cannot conclude\nsatisfaction due to potential limitation in the abstraction and coverage of the\noffline dataset. In such cases, we estimate associated risk during model\nchecking to guide a falsification strategy that prioritizes searching in\nhigh-risk states and regions underrepresented in the trajectory dataset. We\nfurther provide PAC-style guarantees on the likelihood of uncovering undetected\nviolations. Finally, we incorporate a lightweight safety shield that switches\nto a fallback policy at runtime when such a risk exceeds a threshold,\nfacilitating failure mitigation without retraining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u91ca\u6027\u3001\u6a21\u578b\u68c0\u67e5\u548c\u98ce\u9669\u6307\u5bfc\u9a8c\u8bc1\u6765\u52a0\u5f3aRL\u7b56\u7565\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u786e\u4fdd\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u5b89\u5168\u6027\uff0c\u4f20\u7edf\u7684\u6a21\u578b\u68c0\u67e5\u65b9\u6cd5\u53d7\u5230\u62bd\u8c61\u8d28\u91cf\u548c\u8f68\u8ff9\u6570\u636e\u96c6\u5b8c\u6574\u6027\u7684\u9650\u5236\u3002", "method": "\u6784\u5efa\u6613\u4e8e\u4eba\u7c7b\u7406\u89e3\u7684\u7b56\u7565\u62bd\u8c61\uff0c\u5e76\u4f7f\u7528Storm\u6982\u7387\u6a21\u578b\u68c0\u67e5\u5668\u8fdb\u884c\u9a8c\u8bc1\uff0c\u540c\u65f6\u5e94\u7528\u98ce\u9669\u4f30\u8ba1\u6307\u5bfc\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86PAC\u98ce\u683c\u7684\u4fdd\u8bc1\u6765\u63ed\u793a\u672a\u68c0\u6d4b\u5230\u7684\u8fdd\u53cd\u884c\u4e3a\uff0c\u5e76\u5728\u8fd0\u884c\u65f6\u5229\u7528\u5b89\u5168\u76fe\u8fdb\u884c\u98ce\u9669\u7f13\u89e3\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u89e3\u91ca\u6027\u3001\u6a21\u578b\u68c0\u67e5\u548c\u98ce\u9669\u6307\u5bfc\u7684\u9a8c\u8bc1\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u4ee5\u786e\u4fdd\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2506.03160", "pdf": "https://arxiv.org/pdf/2506.03160", "abs": "https://arxiv.org/abs/2506.03160", "authors": ["Shriyank Somvanshi", "Anannya Ghosh Tusti", "Mahmuda Sultana Mimi", "Md Monzurul Islam", "Sazzad Bin Bashar Polock", "Anandi Dutta", "Subasish Das"], "title": "Applying MambaAttention, TabPFN, and TabTransformers to Classify SAE Automation Levels in Crashes", "categories": ["cs.LG"], "comment": null, "summary": "The increasing presence of automated vehicles (AVs) presents new challenges\nfor crash classification and safety analysis. Accurately identifying the SAE\nautomation level involved in each crash is essential to understanding crash\ndynamics and system accountability. However, existing approaches often overlook\nautomation-specific factors and lack model sophistication to capture\ndistinctions between different SAE levels. To address this gap, this study\nevaluates the performance of three advanced tabular deep learning models\nMambaAttention, TabPFN, and TabTransformer for classifying SAE automation\nlevels using structured crash data from Texas (2024), covering 4,649 cases\ncategorized as Assisted Driving (SAE Level 1), Partial Automation (SAE Level\n2), and Advanced Automation (SAE Levels 3-5 combined). Following class\nbalancing using SMOTEENN, the models were trained and evaluated on a unified\ndataset of 7,300 records. MambaAttention demonstrated the highest overall\nperformance (F1-scores: 88% for SAE 1, 97% for SAE 2, and 99% for SAE 3-5),\nwhile TabPFN excelled in zero-shot inference with high robustness for rare\ncrash categories. In contrast, TabTransformer underperformed, particularly in\ndetecting Partial Automation crashes (F1-score: 55%), suggesting challenges in\nmodeling shared human-system control dynamics. These results highlight the\ncapability of deep learning models tailored for tabular data to enhance the\naccuracy and efficiency of automation-level classification. Integrating such\nmodels into crash analysis frameworks can support policy development, AV safety\nevaluation, and regulatory decisions, especially in distinguishing high-risk\nconditions for mid- and high-level automation technologies.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u8bc4\u4f30\u4e86\u4e09\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5206\u7c7b\u81ea\u52a8\u5316\u8f66\u8f86\u4e8b\u6545\u81ea\u52a8\u5316\u6c34\u5e73\u4e0a\u7684\u8868\u73b0\uff0cMambaAttention\u8868\u73b0\u6700\u4f73\uff0c\u800cTabTransformer\u5728\u90e8\u5206\u81ea\u52a8\u5316\u8bc6\u522b\u4e0a\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u6545\u5206\u7c7b\u65b9\u6cd5\u5e38\u5ffd\u89c6\u81ea\u52a8\u5316\u7279\u5b9a\u56e0\u7d20\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u81ea\u52a8\u5316\u7ea7\u522b\u533a\u5206\u80fd\u529b\u7684\u6a21\u578b\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u4e09\u79cd\u5148\u8fdb\u8868\u683c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u7ed3\u6784\u5316\u4e8b\u6545\u6570\u636e\u8fdb\u884c\u5206\u7c7b: MambaAttention, TabPFN, TabTransformer\u3002", "result": "MambaAttention\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u7b49\u7ea7\u81ea\u52a8\u5316\u5206\u7c7b\u4e0a\uff08F1-score\u6700\u9ad8\u8fbe99%\uff09\uff1bTabPFN\u5728\u96f6\u6837\u672c\u63a8\u65ad\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u800cTabTransformer\u5bf9\u90e8\u5206\u81ea\u52a8\u5316\u4e8b\u6545\u7684\u8bc6\u522b\u6027\u80fd\u8f83\u5dee\uff08F1-score\u4ec5\u4e3a55%\uff09\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u81ea\u52a8\u5316\u6c34\u5e73\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u9a7e\u9a76\u8f85\u52a9\u6280\u672f\u7684\u4e8b\u6545\u5206\u6790\u4e2d\u3002"}}
{"id": "2506.03312", "pdf": "https://arxiv.org/pdf/2506.03312", "abs": "https://arxiv.org/abs/2506.03312", "authors": ["Celia Chen", "Scotty Beland", "Ingo Burghardt", "Jill Byczek", "William J. Conway", "Eric Cotugno", "Sadaf Davre", "Megan Fletcher", "Rajesh Kumar Gnanasekaran", "Kristin Hamilton", "Marilyn Harbert", "Jordan Heustis", "Tanaya Jha", "Emily Klein", "Hayden Kramer", "Alex Leitch", "Jessica Perkins", "Casi Sherman", "Celia Sterrn", "Logan Stevens", "Rebecca Zarrella", "Jennifer Golbeck"], "title": "Cross-Platform Violence Detection on Social Media: A Dataset and Analysis", "categories": ["cs.CL", "cs.LG"], "comment": "In Proceedings of the 17th ACM Web Science Conference (WebSci '25). 9\n  pages", "summary": "Violent threats remain a significant problem across social media platforms.\nUseful, high-quality data facilitates research into the understanding and\ndetection of malicious content, including violence. In this paper, we introduce\na cross-platform dataset of 30,000 posts hand-coded for violent threats and\nsub-types of violence, including political and sexual violence. To evaluate the\nsignal present in this dataset, we perform a machine learning analysis with an\nexisting dataset of violent comments from YouTube. We find that, despite\noriginating from different platforms and using different coding criteria, we\nachieve high classification accuracy both by training on one dataset and\ntesting on the other, and in a merged dataset condition. These results have\nimplications for content-classification strategies and for understanding\nviolent content across social media.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u8de8\u5e73\u53f0\u7684\u66b4\u529b\u5a01\u80c1\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u5206\u6790\u5b9e\u73b0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u793e\u4ea4\u5a92\u4f53\u66b4\u529b\u5185\u5bb9\u7684\u7406\u89e3\u548c\u5206\u7c7b\u3002", "motivation": "\u66b4\u529b\u5a01\u80c1\u5728\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u4ecd\u7136\u662f\u4e00\u4e2a\u663e\u8457\u95ee\u9898\u3002\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u53ef\u4ee5\u5e2e\u52a9\u8fdb\u884c\u6076\u610f\u5185\u5bb9\u7684\u7406\u89e3\u548c\u68c0\u6d4b\uff0c\u8fd9\u5305\u62ec\u66b4\u529b\u884c\u4e3a\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u624b\u52a8\u7f16\u7801\u7684\u8de8\u5e73\u53f0\u6570\u636e\u96c6\uff0c\u5305\u542b3\u4e07\u4e2a\u5e16\u5b50\u4ee5\u8bc6\u522b\u66b4\u529b\u5a01\u80c1\u53ca\u5176\u5b50\u7c7b\u578b\u3002", "method": "\u6211\u4eec\u8fdb\u884c\u4e86\u673a\u5668\u5b66\u4e60\u5206\u6790\uff0c\u5c06\u65b0\u521b\u5efa\u7684\u8de8\u5e73\u53f0\u66b4\u529b\u5a01\u80c1\u6570\u636e\u96c6\u4e0e\u6765\u81eaYouTube\u7684\u73b0\u6709\u66b4\u529b\u8bc4\u8bba\u6570\u636e\u96c6\u8fdb\u884c\u6bd4\u8f83\u3002\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u6570\u636e\u96c6\u5e76\u5728\u53e6\u4e00\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4ee5\u53ca\u5728\u5408\u5e76\u6570\u636e\u96c6\u6761\u4ef6\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4ef7\u6570\u636e\u96c6\u4e2d\u4fe1\u53f7\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u65e0\u8bba\u662f\u4ece\u4e00\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u5e76\u5728\u53e6\u4e00\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8fd8\u662f\u5728\u5408\u5e76\u6570\u636e\u96c6\u6761\u4ef6\u4e0b\uff0c\u90fd\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u5ea6\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u6765\u81ea\u4e0d\u540c\u7684\u5e73\u53f0\u5e76\u4f7f\u7528\u4e0d\u540c\u7684\u7f16\u7801\u6807\u51c6\uff0c\u4ecd\u7136\u53ef\u4ee5\u5728\u5206\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u53d6\u5f97\u826f\u597d\u7684\u6548\u679c\u3002\u8fd9\u5bf9\u4e8e\u5185\u5bb9\u5206\u7c7b\u7b56\u7565\u548c\u7406\u89e3\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u66b4\u529b\u5185\u5bb9\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.03503", "pdf": "https://arxiv.org/pdf/2506.03503", "abs": "https://arxiv.org/abs/2506.03503", "authors": ["Shan Shan"], "title": "Computational Architects of Society: Quantum Machine Learning for Social Rule Genesis", "categories": ["cs.AI"], "comment": null, "summary": "The quantification of social science remains a longstanding challenge,\nlargely due to the philosophical nature of its foundational theories. Although\nquantum computing has advanced rapidly in recent years, its relevance to social\ntheory remains underexplored. Most existing research focuses on micro-cognitive\nmodels or philosophical analogies, leaving a gap in system-level applications\nof quantum principles to the analysis of social systems. This study addresses\nthat gap by proposing a theoretical and computational framework that combines\nquantum mechanics with Generative AI to simulate the emergence and evolution of\nsocial norms. Drawing on core quantum concepts--such as superposition,\nentanglement, and probabilistic measurement--this research models society as a\ndynamic, uncertain system and sets up five ideal-type experiments. These\nscenarios are simulated using 25 generative agents, each assigned evolving\nroles as compliers, resistors, or enforcers. Within a simulated environment\nmonitored by a central observer (the Watcher), agents interact, respond to\nsurveillance, and adapt to periodic normative disruptions. These interactions\nallow the system to self-organize under external stress and reveal emergent\npatterns. Key findings show that quantum principles, when integrated with\ngenerative AI, enable the modeling of uncertainty, emergence, and\ninterdependence in complex social systems. Simulations reveal patterns\nincluding convergence toward normative order, the spread of resistance, and the\nspontaneous emergence of new equilibria in social rules. In conclusion, this\nstudy introduces a novel computational lens that lays the groundwork for a\nquantum-informed social theory. It offers interdisciplinary insights into how\nsociety can be understood not just as a structure to observe but as a dynamic\nsystem to simulate and redesign through quantum technologies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u91cf\u5b50\u529b\u5b66\u548c\u751f\u6210AI\u6a21\u62df\u793e\u4f1a\u89c4\u8303\u7684\u6f14\u53d8\uff0c\u4e3a\u7406\u89e3\u548c\u8bbe\u8ba1\u52a8\u6001\u793e\u4f1a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u91cf\u5b50\u89c6\u89d2\u3002", "motivation": "\u5c3d\u7ba1\u91cf\u5b50\u8ba1\u7b97\u8fd1\u5e74\u6765\u8fc5\u901f\u53d1\u5c55\uff0c\u5176\u4e0e\u793e\u4f1a\u7406\u8bba\u7684\u5173\u8054\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5fae\u89c2\u8ba4\u77e5\u6a21\u578b\u6216\u54f2\u5b66\u7c7b\u6bd4\u4e0a\uff0c\u7f3a\u4e4f\u91cf\u5b50\u539f\u7406\u5728\u793e\u4f1a\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u7cfb\u7edf\u6027\u5e94\u7528\u3002", "method": "\u672c\u7814\u7a76\u8bbe\u5b9a\u4e86\u4e94\u79cd\u7406\u60f3\u578b\u5b9e\u9a8c\u60c5\u666f\uff0c\u4f7f\u752825\u4e2a\u751f\u6210\u4ee3\u7406\u6a21\u62df\u793e\u4f1a\u7cfb\u7edf\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u8fd9\u4e9b\u4ee3\u7406\u88ab\u5206\u914d\u4e3a\u9075\u4ece\u8005\u3001\u62b5\u6297\u8005\u6216\u6267\u6cd5\u8005\u89d2\u8272\uff0c\u901a\u8fc7\u4e2d\u592e\u89c2\u5bdf\u8005\uff08\u89c2\u5bdf\u8005\uff09\u76d1\u63a7\u7684\u73af\u5883\u4e2d\u76f8\u4e92\u4f5c\u7528\uff0c\u54cd\u5e94\u76d1\u89c6\uff0c\u5e76\u9002\u5e94\u5468\u671f\u6027\u89c4\u8303\u4e2d\u65ad\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u5f53\u91cf\u5b50\u539f\u7406\u4e0e\u751f\u6210\u578bAI\u7ed3\u5408\u65f6\uff0c\u80fd\u591f\u6709\u6548\u5bf9\u590d\u6742\u793e\u4f1a\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u6d8c\u73b0\u6027\u548c\u4e92\u4f9d\u6027\u8fdb\u884c\u5efa\u6a21\u3002\u6a21\u62df\u63ed\u793a\u4e86\u793e\u4f1a\u89c4\u5219\u4e2d\u8d8b\u540c\u6027\u3001\u62b5\u6297\u6027\u4f20\u64ad\u548c\u65b0\u5e73\u8861\u81ea\u53d1\u51fa\u73b0\u7b49\u6a21\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5c06\u91cf\u5b50\u529b\u5b66\u4e0e\u751f\u6210\u578bAI\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97\u6846\u67b6\uff0c\u5f15\u5165\u91cf\u5b50\u6982\u5ff5\u6765\u6a21\u62df\u793e\u4f1a\u89c4\u8303\u7684\u51fa\u73b0\u548c\u6f14\u53d8\uff0c\u4e3a\u91cf\u5b50\u5316\u7684\u793e\u4f1a\u7406\u8bba\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u5b83\u63d0\u4f9b\u4e86\u8de8\u5b66\u79d1\u89c1\u89e3\uff0c\u5e2e\u52a9\u7406\u89e3\u793e\u4f1a\u4e0d\u4ec5\u4f5c\u4e3a\u53ef\u89c2\u5bdf\u7684\u7ed3\u6784\uff0c\u800c\u4e14\u4f5c\u4e3a\u53ef\u901a\u8fc7\u91cf\u5b50\u6280\u672f\u8fdb\u884c\u6a21\u62df\u548c\u91cd\u65b0\u8bbe\u8ba1\u7684\u52a8\u6001\u7cfb\u7edf\u3002"}}
{"id": "2506.03161", "pdf": "https://arxiv.org/pdf/2506.03161", "abs": "https://arxiv.org/abs/2506.03161", "authors": ["Mira Nuthakki"], "title": "Safety-Prioritized, Reinforcement Learning-Enabled Traffic Flow Optimization in a 3D City-Wide Simulation Environment", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "18 pages, figures at end, methods at end. Format/order can be changed\n  if necessary", "summary": "Traffic congestion and collisions represent significant economic,\nenvironmental, and social challenges worldwide. Traditional traffic management\napproaches have shown limited success in addressing these complex, dynamic\nproblems. To address the current research gaps, three potential tools are\ndeveloped: a comprehensive 3D city-wide simulation environment that integrates\nboth macroscopic and microscopic traffic dynamics; a collision model; and a\nreinforcement learning framework with custom reward functions prioritizing\nsafety over efficiency. Unity game engine-based simulation is used for direct\ncollision modeling. A custom reward enabled reinforcement learning method,\nproximal policy optimization (PPO) model, yields substantial improvements over\nbaseline results, reducing the number of serious collisions, number of\nvehicle-vehicle collisions, and total distance travelled by over 3 times the\nbaseline values. The model also improves fuel efficiency by 39% and reduces\ncarbon emissions by 88%. Results establish feasibility for city-wide 3D traffic\nsimulation applications incorporating the vision-zero safety principles of the\nDepartment of Transportation, including physics-informed, adaptable, realistic\ncollision modeling, as well as appropriate reward modeling for real-world\ntraffic signal light control towards reducing collisions, optimizing traffic\nflow and reducing greenhouse emissions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd3D\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u548c\u81ea\u5b9a\u4e49\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ea4\u901a\u4e8b\u6545\u548c\u78b3\u6392\u653e\uff0c\u63d0\u9ad8\u4e86\u71c3\u6cb9\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u57ce\u5e02\u8303\u56f4\u5e94\u7528\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u4ea4\u901a\u62e5\u5835\u548c\u4ea4\u901a\u4e8b\u6545\u662f\u5168\u7403\u6027\u7684\u91cd\u8981\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u4ea4\u901a\u7ba1\u7406\u65b9\u6cd5\u5bf9\u8fd9\u4e9b\u590d\u6742\u548c\u52a8\u6001\u7684\u95ee\u9898\u6548\u679c\u6709\u9650\u3002\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e09\u79cd\u5de5\u5177\u6765\u6539\u5584\u4ea4\u901a\u7ba1\u7406\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7efc\u5408\u76843D\u5168\u5e02\u8303\u56f4\u5185\u7684\u4eff\u771f\u73af\u5883\uff0c\u7ed3\u5408\u5b8f\u89c2\u548c\u5fae\u89c2\u4ea4\u901a\u52a8\u6001\u3001\u78b0\u649e\u6a21\u578b\uff0c\u4ee5\u53ca\u4e00\u4e2a\u4ee5\u5b89\u5168\u4f18\u5148\u4e8e\u6548\u7387\u7684\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002\u5176\u4e2d\uff0c\u4f7f\u7528Unity\u6e38\u620f\u5f15\u64ce\u8fdb\u884c\u76f4\u63a5\u78b0\u649e\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u4e00\u79cd\u81ea\u5b9a\u4e49\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u2014\u2014\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u6a21\u578b\u6765\u6539\u5584\u4ea4\u901a\u7ba1\u7406\u3002", "result": "\u4e0e\u57fa\u7ebf\u7ed3\u679c\u76f8\u6bd4\uff0c\u4f7f\u7528\u672c\u7814\u7a76\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u4e25\u91cd\u78b0\u649e\u6570\u91cf\u3001\u8f66\u8f86\u78b0\u649e\u603b\u6570\u53ca\u884c\u9a76\u603b\u8ddd\u79bb\u8d85\u8fc7\u4e09\u500d\u3002\u4e14\u71c3\u6cb9\u6548\u7387\u63d0\u9ad8\u4e8639%\uff0c\u78b3\u6392\u653e\u51cf\u5c11\u4e8688%\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5177\u5907\u5728\u5168\u5e02\u8303\u56f4\u5185\u5e94\u7528\u7684\u53ef\u884c\u6027\uff0c\u5e76\u80fd\u6709\u6548\u6574\u5408\u4ea4\u901a\u90e8\u7684\u96f6\u6b7b\u4ea1\u5b89\u5168\u539f\u5219\u3001\u7269\u7406\u4fe1\u606f\u3001\u9002\u5e94\u6027\u548c\u73b0\u5b9e\u78b0\u649e\u5efa\u6a21\u4ee5\u53ca\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u4ea4\u901a\u4fe1\u53f7\u706f\u63a7\u5236\u7684\u5956\u52b1\u5efa\u6a21\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u75283D\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u7ed3\u5408\u81ea\u5b9a\u4e49\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u4ea4\u901a\u4e8b\u6545\u548c\u78b3\u6392\u653e\uff0c\u63d0\u9ad8\u71c3\u6cb9\u6548\u7387\uff0c\u540c\u65f6\u4f18\u5316\u4ea4\u901a\u6d41\u52a8\u3002\u8fd9\u4e3a\u5b9e\u73b0\u57ce\u5e02\u8303\u56f4\u5185\u7684\u4ea4\u901a\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.03357", "pdf": "https://arxiv.org/pdf/2506.03357", "abs": "https://arxiv.org/abs/2506.03357", "authors": ["Aldan Creo", "H\u00e9ctor Cerezo-Costas", "Pedro Alonso-Doval", "Maximiliano Hormaz\u00e1bal-Lagos"], "title": "Ask a Local: Detecting Hallucinations With Specialized Model Divergence", "categories": ["cs.CL", "cs.AI"], "comment": "Supplementary materials: https://github.com/ACMCMC/ask-a-local", "summary": "Hallucinations in large language models (LLMs) - instances where models\ngenerate plausible but factually incorrect information - present a significant\nchallenge for AI.\n  We introduce \"Ask a Local\", a novel hallucination detection method exploiting\nthe intuition that specialized models exhibit greater surprise when\nencountering domain-specific inaccuracies. Our approach computes divergence\nbetween perplexity distributions of language-specialized models to identify\npotentially hallucinated spans. Our method is particularly well-suited for a\nmultilingual context, as it naturally scales to multiple languages without the\nneed for adaptation, relying on external data sources, or performing training.\nMoreover, we select computationally efficient models, providing a scalable\nsolution that can be applied to a wide range of languages and domains.\n  Our results on a human-annotated question-answer dataset spanning 14\nlanguages demonstrate consistent performance across languages, with\nIntersection-over-Union (IoU) scores around 0.3 and comparable Spearman\ncorrelation values. Our model shows particularly strong performance on Italian\nand Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining\ncross-lingual effectiveness without language-specific adaptations. We release\nour code and architecture to facilitate further research in multilingual\nhallucination detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"Ask a Local\"\u7684\u591a\u8bed\u8a00\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e13\u4e1a\u6a21\u578b\u7684\u56f0\u60d1\u5ea6\u5206\u5e03\u5dee\u5f02\u8bc6\u522b\u5e7b\u89c9\uff0c\u5c24\u5176\u5728\u610f\u5927\u5229\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5e7b\u89c9\uff0c\u5373\u751f\u6210\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u4e0a\u4e0d\u6b63\u786e\u7684\u4fe1\u606f\uff0c\u5bf9\u4eba\u5de5\u667a\u80fd\u63d0\u51fa\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\"Ask a Local\"\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u8bed\u8a00\u4e13\u4e1a\u6a21\u578b\u611f\u77e5\u96be\u5ea6\u5206\u5e03\u4e4b\u95f4\u7684\u5206\u6b67\u6765\u8bc6\u522b\u6f5c\u5728\u7684\u5e7b\u89c9\u6bb5\u843d\u3002\u8be5\u65b9\u6cd5\u9002\u5408\u591a\u8bed\u8a00\u73af\u5883\uff0c\u65e0\u9700\u9002\u5e94\u6216\u4f7f\u7528\u5916\u90e8\u6570\u636e\u6e90\uff0c\u4ea6\u65e0\u9700\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u4eba\u7c7b\u6ce8\u91ca\u7684\u8de814\u79cd\u8bed\u8a00\u7684\u95ee\u9898\u56de\u7b54\u6570\u636e\u96c6\u4e2d\u5c55\u793a\u4e86\u4e00\u81f4\u7684\u6027\u80fd\uff0cIoU\u5206\u6570\u7ea6\u4e3a0.3\uff0cSpearman\u76f8\u5173\u503c\u76f8\u5f53\u3002\u7279\u522b\u662f\u5728\u610f\u5927\u5229\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u4e0a\uff0cIoU\u5206\u6570\u5206\u522b\u4e3a0.42\u548c0.38\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u591a\u79cd\u8bed\u8a00\u73af\u5883\u4e2d\u663e\u793a\u51fa\u4e00\u81f4\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u610f\u5927\u5229\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u65e0\u9700\u8fdb\u884c\u8bed\u8a00\u7279\u5b9a\u7684\u8c03\u6574\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e86\u8de8\u8bed\u8a00\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2506.03163", "pdf": "https://arxiv.org/pdf/2506.03163", "abs": "https://arxiv.org/abs/2506.03163", "authors": ["Oluwaseyi Giwa"], "title": "Causal Discovery in Dynamic Fading Wireless Networks", "categories": ["cs.LG", "eess.SP", "stat.ME"], "comment": "5 pages, 3 figures", "summary": "Dynamic causal discovery in wireless networks is essential due to evolving\ninterference, fading, and mobility, which complicate traditional static causal\nmodels. This paper addresses causal inference challenges in dynamic fading\nwireless environments by proposing a sequential regression-based algorithm with\na novel application of the NOTEARS acyclicity constraint, enabling efficient\nonline updates. We derive theoretical lower and upper bounds on the detection\ndelay required to identify structural changes, explicitly quantifying their\ndependence on network size, noise variance, and fading severity. Monte Carlo\nsimulations validate these theoretical results, demonstrating linear increases\nin detection delay with network size, quadratic growth with noise variance, and\ninverse-square dependence on the magnitude of structural changes. Our findings\nprovide rigorous theoretical insights and practical guidelines for designing\nrobust online causal inference mechanisms to maintain network reliability under\nnonstationary wireless conditions.", "AI": {"tldr": "\u6b64\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\u56e0\u679c\u63a8\u65ad\u7684\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u53ca\u6a21\u62df\u9a8c\u8bc1\u5176\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5e72\u6270\u3001\u8870\u843d\u548c\u79fb\u52a8\u6027\u4f7f\u5f97\u4f20\u7edf\u7684\u9759\u6001\u56e0\u679c\u6a21\u578b\u53d8\u5f97\u590d\u6742\uff0c\u56e0\u6b64\u9700\u8981\u5728\u52a8\u6001\u65e0\u7ebf\u7f51\u7edc\u4e2d\u8fdb\u884c\u56e0\u679c\u53d1\u73b0\u3002", "method": "\u5728\u52a8\u6001\u8870\u843d\u7684\u65e0\u7ebf\u73af\u5883\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u987a\u5e8f\u56de\u5f52\u7b97\u6cd5\uff0c\u5e76\u5e94\u7528NOTEARS\u975e\u5faa\u73af\u6027\u7ea6\u675f\u6765\u5b9e\u73b0\u6709\u6548\u7684\u5728\u7ebf\u66f4\u65b0\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8bc1\u5b9e\u4e86\u68c0\u6d4b\u5ef6\u8fdf\u968f\u7740\u7f51\u7edc\u89c4\u6a21\u7ebf\u6027\u589e\u52a0\u3001\u566a\u58f0\u65b9\u5dee\u5e73\u65b9\u589e\u957f\u4ee5\u53ca\u4e0e\u7ed3\u6784\u53d8\u5316\u7684\u5927\u5c0f\u5448\u53cd\u6bd4\u5e73\u65b9\u5173\u7cfb\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u987a\u5e8f\u56de\u5f52\u7684\u7b97\u6cd5\uff0c\u91c7\u7528NOTEARS\u975e\u5faa\u73af\u6027\u7ea6\u675f\uff0c\u80fd\u591f\u8fdb\u884c\u6709\u6548\u7684\u5728\u7ebf\u66f4\u65b0\uff0c\u8bc1\u660e\u4e86\u76f8\u5173\u7406\u8bba\u7ed3\u679c\u5e76\u901a\u8fc7Monte Carlo\u6a21\u62df\u9a8c\u8bc1\u3002"}}
{"id": "2506.03360", "pdf": "https://arxiv.org/pdf/2506.03360", "abs": "https://arxiv.org/abs/2506.03360", "authors": ["Zihui Ma", "Lingyao Li", "Juan Li", "Wenyue Hua", "Jingxiao Liu", "Qingyuan Feng", "Yuki Miura"], "title": "A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation", "categories": ["cs.CL", "cs.CY", "cs.SI"], "comment": null, "summary": "Rapid, fine-grained disaster damage assessment is essential for effective\nemergency response, yet remains challenging due to limited ground sensors and\ndelays in official reporting. Social media provides a rich, real-time source of\nhuman-centric observations, but its multimodal and unstructured nature presents\nchallenges for traditional analytical methods. In this study, we propose a\nstructured Multimodal, Multilingual, and Multidimensional (3M) pipeline that\nleverages multimodal large language models (MLLMs) to assess disaster impacts.\nWe evaluate three foundation models across two major earthquake events using\nboth macro- and micro-level analyses. Results show that MLLMs effectively\nintegrate image-text signals and demonstrate a strong correlation with\nground-truth seismic data. However, performance varies with language,\nepicentral distance, and input modality. This work highlights the potential of\nMLLMs for disaster assessment and provides a foundation for future research in\napplying MLLMs to real-time crisis contexts. The code and data are released at:\nhttps://github.com/missa7481/EMNLP25_earthquake", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u76843M\u7ba1\u9053\u8bc4\u4f30\u707e\u96be\u5f71\u54cd\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5728\u5730\u9707\u6570\u636e\u4e2d\u7684\u6709\u6548\u6027\u4ee5\u53ca\u591a\u79cd\u53c2\u6570\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5feb\u901f\u3001\u7cbe\u51c6\u7684\u707e\u5bb3\u635f\u5931\u8bc4\u4f30\u5bf9\u4e8e\u6709\u6548\u7684\u7d27\u6025\u5e94\u5bf9\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5730\u9762\u4f20\u611f\u5668\u7684\u9650\u5236\u548c\u5b98\u65b9\u62a5\u544a\u7684\u6ede\u540e\uff0c\u4ecd\u7136\u5145\u6ee1\u6311\u6218\u3002\u793e\u4ea4\u5a92\u4f53\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5b9e\u65f6\u4eba\u7c7b\u89c2\u5bdf\u6570\u636e\uff0c\u4f46\u5176\u591a\u6a21\u6001\u548c\u975e\u7ed3\u6784\u5316\u6027\u8d28\u5bf9\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u6784\u6210\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u3001\u591a\u8bed\u8a00\u3001\u591a\u7ef4\u5ea6(3M)\u7ba1\u9053\uff0c\u4f7f\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u707e\u96be\u5f71\u54cd\u3002\u8bc4\u4f30\u4e86\u4e09\u4e2a\u57fa\u7840\u6a21\u578b\u5728\u4e24\u4e2a\u91cd\u5927\u5730\u9707\u4e8b\u4ef6\u4e2d\u7684\u8868\u73b0\u3002", "result": "MLLMs\u901a\u8fc7\u6574\u5408\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u53f7\uff0c\u5728\u5730\u9707\u76f8\u5173\u6570\u636e\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u5f3a\u76f8\u5173\u6027\uff0c\u4f46\u4e0d\u540c\u8bed\u8a00\u3001\u9707\u4e2d\u8ddd\u79bb\u548c\u8f93\u5165\u6a21\u6001\u7684\u8868\u73b0\u6709\u6240\u5dee\u5f02\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b(MLLMs)\u80fd\u591f\u6709\u6548\u96c6\u6210\u56fe\u50cf\u548c\u6587\u672c\u4fe1\u53f7\uff0c\u5e76\u4e0e\u5730\u9707\u57fa\u7840\u6570\u636e\u5448\u73b0\u5f3a\u76f8\u5173\u6027\uff0c\u672a\u6765\u6709\u6f5c\u529b\u7528\u4e8e\u5b9e\u65f6\u5371\u673a\u8bc4\u4f30\u3002"}}
{"id": "2506.03548", "pdf": "https://arxiv.org/pdf/2506.03548", "abs": "https://arxiv.org/abs/2506.03548", "authors": ["Chenglong Ye", "Gang Xiong", "Junyou Shang", "Xingyuan Dai", "Xiaoyan Gong", "Yisheng Lv"], "title": "SUMO-MCP: Leveraging the Model Context Protocol for Autonomous Traffic Simulation and Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Traffic simulation tools, such as SUMO, are essential for urban mobility\nresearch. However, such tools remain challenging for users due to complex\nmanual workflows involving network download, demand generation, simulation\nsetup, and result analysis. In this paper, we introduce SUMO-MCP, a novel\nplatform that not only wraps SUMO' s core utilities into a unified tool suite\nbut also provides additional auxiliary utilities for common preprocessing and\npostprocessing tasks. Using SUMO-MCP, users can issue simple natural-language\nprompts to generate traffic scenarios from OpenStreetMap data, create demand\nfrom origin-destination matrices or random patterns, run batch simulations with\nmultiple signal-control strategies, perform comparative analyses with automated\nreporting, and detect congestion for signal-timing optimization. Furthermore,\nthe platform allows flexible custom workflows by dynamically combining exposed\nSUMO tools without additional coding. Experiments demonstrate that SUMO-MCP\nsignificantly makes traffic simulation more accessible and reliable for\nresearchers. We will release code for SUMO-MCP at\nhttps://github.com/ycycycl/SUMO-MCP in the future.", "AI": {"tldr": "SUMO-MCP\u5e73\u53f0\u7b80\u5316\u4e86SUMO\u7684\u590d\u6742\u64cd\u4f5c\uff0c\u4f7f\u4ea4\u901a\u4eff\u771f\u66f4\u6613\u4e8e\u4f7f\u7528\uff0c\u5e76\u5c06\u5f00\u653e\u4ee3\u7801\u4f9b\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u4ea4\u901a\u4eff\u771f\u5de5\u5177\u5982SUMO\u64cd\u4f5c\u590d\u6742\u3001\u6d41\u7a0b\u7e41\u7410\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5176\u5bf9\u7814\u7a76\u4eba\u5458\u7684\u6613\u7528\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165SUMO-MCP\u5e73\u53f0\uff0c\u5c06SUMO\u7684\u6838\u5fc3\u5de5\u5177\u6574\u5408\u6210\u7edf\u4e00\u5de5\u5177\u5957\u4ef6\uff0c\u5e76\u63d0\u4f9b\u989d\u5916\u7684\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u5de5\u5177\uff0c\u7528\u6237\u53ef\u4ee5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u751f\u6210\u4ea4\u901a\u573a\u666f\uff0c\u521b\u5efa\u9700\u6c42\uff0c\u8fdb\u884c\u6279\u91cf\u4eff\u771f\u548c\u6bd4\u8f83\u5206\u6790\u7b49\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSUMO-MCP\u5e73\u53f0\u663e\u8457\u63d0\u9ad8\u4e86\u4ea4\u901a\u4eff\u771f\u5de5\u5177\u7684\u6613\u7528\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "SUMO-MCP\u5e73\u53f0\u6210\u529f\u7b80\u5316\u4e86SUMO\u5de5\u5177\u7684\u4f7f\u7528\u6d41\u7a0b\uff0c\u4f7f\u4ea4\u901a\u4eff\u771f\u5bf9\u7814\u7a76\u4eba\u5458\u66f4\u52a0\u6613\u7528\u548c\u53ef\u9760\u3002"}}
{"id": "2506.03164", "pdf": "https://arxiv.org/pdf/2506.03164", "abs": "https://arxiv.org/abs/2506.03164", "authors": ["Vignav Ramesh", "Morteza Mardani"], "title": "Test-Time Scaling of Diffusion Models via Noise Trajectory Search", "categories": ["cs.LG"], "comment": null, "summary": "The iterative and stochastic nature of diffusion models enables test-time\nscaling, whereby spending additional compute during denoising generates\nhigher-fidelity samples. Increasing the number of denoising steps is the\nprimary scaling axis, but this yields quickly diminishing returns. Instead\noptimizing the noise trajectory--the sequence of injected noise vectors--is\npromising, as the specific noise realizations critically affect sample quality;\nbut this is challenging due to a high-dimensional search space, complex\nnoise-outcome interactions, and costly trajectory evaluations. We address this\nby first casting diffusion as a Markov Decision Process (MDP) with a terminal\nreward, showing tree-search methods such as Monte Carlo tree search (MCTS) to\nbe meaningful but impractical. To balance performance and efficiency, we then\nresort to a relaxation of MDP, where we view denoising as a sequence of\nindependent contextual bandits. This allows us to introduce an\n$\\epsilon$-greedy search algorithm that globally explores at extreme timesteps\nand locally exploits during the intermediate steps where de-mixing occurs.\nExperiments on EDM and Stable Diffusion reveal state-of-the-art scores for\nclass-conditioned/text-to-image generation, exceeding baselines by up to\n$164\\%$ and matching/exceeding MCTS performance. To our knowledge, this is the\nfirst practical method for test-time noise trajectory optimization of arbitrary\n(non-differentiable) rewards.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5c06\u6269\u6563\u89c6\u4e3a\u4e00\u4e2a\u677e\u5f1b\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u566a\u58f0\u8f68\u8ff9\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f18\u5316\u566a\u58f0\u8f68\u8ff9\u5bf9\u4e8e\u63d0\u9ad8\u6837\u672c\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u9ad8\u7ef4\u641c\u7d22\u7a7a\u95f4\u3001\u590d\u6742\u7684\u566a\u58f0\u7ed3\u679c\u4e92\u52a8\u548c\u9ad8\u6210\u672c\u7684\u8f68\u8ff9\u8bc4\u4f30\uff0c\u8fd9\u662f\u4e00\u9879\u5177\u6709\u6311\u6218\u7684\u5de5\u4f5c\u3002", "method": "\u5c06\u6269\u6563\u8fc7\u7a0b\u89c6\u4e3a\u4e00\u4e2a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f46\u4e3a\u4e86\u517c\u987e\u6027\u80fd\u548c\u6548\u7387\uff0c\u91c7\u7528\u4e86\u4e00\u79cdMDP\u7684\u677e\u5f1b\u65b9\u5f0f\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a$\\epsilon$-\u8d2a\u5a6a\u641c\u7d22\u7b97\u6cd5\u3002", "result": "\u5728EDM\u548cStable Diffusion\u5b9e\u9a8c\u4e2d\uff0c\u7c7b\u6761\u4ef6\u548c\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u5f97\u5206\u8fbe\u5230\u4e86\u6700\u65b0\u6c34\u5e73\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u5347\u9ad8\u8fbe164%\uff0c\u5e76\u4e14\u80fd\u5339\u914d\u6216\u8d85\u8d8aMCTS\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u7528\u4e8e\u4f18\u5316\u6d4b\u8bd5\u65f6\u7684\u566a\u58f0\u8f68\u8ff9\uff0c\u8fd9\u5728\u7c7b\u6761\u4ef6\u548c\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4e2d\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u7684\u7ed3\u679c\u3002"}}
{"id": "2506.03408", "pdf": "https://arxiv.org/pdf/2506.03408", "abs": "https://arxiv.org/abs/2506.03408", "authors": ["Yi Xu", "Ruining Yang", "Yitian Zhang", "Yizhou Wang", "Jianglin Lu", "Mingyuan Zhang", "Lili Su", "Yun Fu"], "title": "Trajectory Prediction Meets Large Language Models: A Survey", "categories": ["cs.CL", "cs.CV"], "comment": "16 pages, GitHub:\n  https://github.com/colorfulfuture/Awesome-Trajectory-Motion-Prediction-Papers", "summary": "Recent advances in large language models (LLMs) have sparked growing interest\nin integrating language-driven techniques into trajectory prediction. By\nleveraging their semantic and reasoning capabilities, LLMs are reshaping how\nautonomous systems perceive, model, and predict trajectories. This survey\nprovides a comprehensive overview of this emerging field, categorizing recent\nwork into five directions: (1) Trajectory prediction via language modeling\nparadigms, (2) Direct trajectory prediction with pretrained language models,\n(3) Language-guided scene understanding for trajectory prediction, (4)\nLanguage-driven data generation for trajectory prediction, (5) Language-based\nreasoning and interpretability for trajectory prediction. For each, we analyze\nrepresentative methods, highlight core design choices, and identify open\nchallenges. This survey bridges natural language processing and trajectory\nprediction, offering a unified perspective on how language can enrich\ntrajectory prediction.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u8bed\u8a00\u6a21\u578b\u5728\u8f68\u8ff9\u9884\u6d4b\u9886\u57df\u7684\u5e94\u7528\u53d1\u5c55\uff0c\u5305\u62ec\u65b9\u6cd5\u5206\u7c7b\u3001\u8bbe\u8ba1\u9009\u62e9\u548c\u6311\u6218\u5206\u6790\uff0c\u5c55\u793a\u8bed\u8a00\u5982\u4f55\u63d0\u5347\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u9274\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u9a71\u52a8\u6280\u672f\u4e2d\u7684\u8fdb\u5c55\uff0c\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u8c03\u67e5\u7814\u7a76\u6765\u63a2\u7d22\u8bed\u8a00\u6a21\u578b\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\u5e76\u5206\u6790\u5176\u6548\u679c\u3002", "method": "\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\uff0c\u91cd\u70b9\u7a81\u51fa\u6838\u5fc3\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e76\u8bc6\u522b\u51fa\u5f00\u653e\u7684\u6311\u6218\u3002", "result": "\u5206\u7c7b\u73b0\u6709\u5de5\u4f5c\u4e3a\u4e94\u4e2a\u65b9\u5411\uff0c\u8be6\u7ec6\u5206\u6790\u6bcf\u4e2a\u65b9\u5411\u4e0b\u6a21\u62df\u7814\u7a76\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\u548c\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u8f68\u8ff9\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89c6\u89d2\uff0c\u5c55\u793a\u4e86\u8bed\u8a00\u5982\u4f55\u4e30\u5bcc\u8f68\u8ff9\u9884\u6d4b\u3002"}}
{"id": "2506.03586", "pdf": "https://arxiv.org/pdf/2506.03586", "abs": "https://arxiv.org/abs/2506.03586", "authors": ["Yu Ma", "Chongtao Guo", "Le Liang", "Xiao Li", "Shi Jin"], "title": "Joint Beamforming and Resource Allocation for Delay Optimization in RIS-Assisted OFDM Systems: A DRL Approach", "categories": ["cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "This paper investigates a joint phase design and resource allocation problem\nin downlink reconfigurable intelligent surface (RIS)-assisted orthogonal\nfrequency division multiplexing (OFDM) systems to optimize average delay, where\ndata packets for each user arrive at the base station stochastically. The\nsequential optimization problem is inherently a Markov decision process (MDP),\nmaking it fall within the scope of reinforcement learning. To effectively\nhandle the mixed action space and reduce the state space dimensionality, a\nhybrid deep reinforcement learning (DRL) approach is proposed. Specifically,\nproximal policy optimization (PPO)-$\\Theta$ is employed to optimize RIS phase\nshift design, while PPO-N is responsible for subcarrier allocation decisions.\nTo further mitigate the curse of dimensionality associated with subcarrier\nallocation, a multi-agent strategy is introduced to optimize subcarrier\nallocation indicater more efficiently. Moreover, to achieve more adaptive\nresource allocation and accurately capture network dynamics, key factors\nclosely related to average delay, including the number of backlogged packets in\nbuffers and the current packet arrivals, are incorporated into the state space.\nFurthermore, a transfer learning framework is introduced to enhance training\nefficiency and accelerate convergence. Simulation results demonstrate that the\nproposed algorithm significantly reduces average delay, enhances resource\nallocation efficiency, and achieves superior system robustness and fairness\ncompared to baseline methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u6765\u4f18\u5316RIS\u8f85\u52a9OFDM\u7cfb\u7edf\u7684\u5e73\u5747\u5ef6\u8fdf\uff0c\u901a\u8fc7PPO\u8fdb\u884c\u76f8\u79fb\u548c\u5b50\u8f7d\u6ce2\u5206\u914d\u4f18\u5316\uff0c\u5e76\u5229\u7528\u591a\u4ee3\u7406\u7b56\u7565\u548c\u4f20\u9012\u5b66\u4e60\u63d0\u9ad8\u6548\u7387\uff0c\u7ed3\u679c\u663e\u793a\u663e\u8457\u6539\u5584\u5ef6\u8fdf\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u3002", "motivation": "\u5728\u4e0b\u884c\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8f85\u52a9\u6b63\u4ea4\u9891\u5206\u590d\u7528\uff08OFDM\uff09\u7cfb\u7edf\u4e2d\u89e3\u51b3\u8054\u5408\u76f8\u4f4d\u8bbe\u8ba1\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u4ee5\u4f18\u5316\u5e73\u5747\u5ef6\u8fdf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u65b9\u6cd5\uff0c\u5177\u4f53\u5305\u62ec\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u8fdb\u884cRIS\u76f8\u79fb\u8bbe\u8ba1\u4f18\u5316\u548c\u5b50\u8f7d\u6ce2\u5206\u914d\u51b3\u7b56\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u591a\u4ee3\u7406\u7b56\u7565\u6765\u9ad8\u6548\u4f18\u5316\u5b50\u8f7d\u6ce2\u5206\u914d\u6307\u793a\u5668\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4f20\u9012\u5b66\u4e60\u6846\u67b6\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u52a0\u901f\u6536\u655b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86\u8d44\u6e90\u5206\u914d\u6548\u7387\uff0c\u5e76\u5728\u7cfb\u7edf\u7a33\u5065\u6027\u548c\u516c\u5e73\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86\u8d44\u6e90\u5206\u914d\u6548\u7387\uff0c\u5e76\u5728\u7cfb\u7edf\u7a33\u5065\u6027\u548c\u516c\u5e73\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2506.03176", "pdf": "https://arxiv.org/pdf/2506.03176", "abs": "https://arxiv.org/abs/2506.03176", "authors": ["Bin Wang", "Yongqi Han", "Minbo Ma", "Tianrui Li", "Junbo Zhang", "Feng Hong", "Yanwei Yu"], "title": "Non-collective Calibrating Strategy for Time Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Deep learning-based approaches have demonstrated significant advancements in\ntime series forecasting. Despite these ongoing developments, the complex\ndynamics of time series make it challenging to establish the rule of thumb for\ndesigning the golden model architecture. In this study, we argue that refining\nexisting advanced models through a universal calibrating strategy can deliver\nsubstantial benefits with minimal resource costs, as opposed to elaborating and\ntraining a new model from scratch. We first identify a multi-target learning\nconflict in the calibrating process, which arises when optimizing variables\nacross time steps, leading to the underutilization of the model's learning\ncapabilities. To address this issue, we propose an innovative calibrating\nstrategy called Socket+Plug (SoP). This approach retains an exclusive optimizer\nand early-stopping monitor for each predicted target within each Plug while\nkeeping the fully trained Socket backbone frozen. The model-agnostic nature of\nSoP allows it to directly calibrate the performance of any trained deep\nforecasting models, regardless of their specific architectures. Extensive\nexperiments on various time series benchmarks and a spatio-temporal\nmeteorological ERA5 dataset demonstrate the effectiveness of SoP, achieving up\nto a 22% improvement even when employing a simple MLP as the Plug (highlighted\nin Figure 1)", "AI": {"tldr": "\u901a\u8fc7\u521b\u65b0\u7684Socket+Plug (SoP)\u6821\u51c6\u7b56\u7565\u63d0\u9ad8\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5982\u4f55\u8bbe\u8ba1\u6700\u4f73\u6a21\u578b\u67b6\u6784\u4ecd\u7136\u975e\u5e38\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u901a\u7528\u6821\u51c6\u7b56\u7565\u6765\u5b8c\u5584\u73b0\u6709\u6a21\u578b\uff0c\u51cf\u5c11\u8d44\u6e90\u6210\u672c\u800c\u975e\u4ece\u96f6\u5f00\u59cb\u8bbe\u8ba1\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u6821\u51c6\u7b56\u7565\u2014\u2014Socket+Plug (SoP)\uff0c\u4fdd\u7559\u6bcf\u4e2aPlug\u5185\u7684\u4e13\u6709\u4f18\u5316\u5668\u548c\u9884\u6d4b\u76ee\u6807\u7684\u65e9\u671f\u505c\u6b62\u76d1\u63a7\uff0c\u540c\u65f6\u4fdd\u6301\u5b8c\u5168\u8bad\u7ec3\u7684Socket\u4e3b\u5e72\u51bb\u7ed3\u3002", "result": "SoP\u7b56\u7565\u80fd\u591f\u76f4\u63a5\u6821\u51c6\u4efb\u4f55\u8bad\u7ec3\u8fc7\u7684\u6df1\u5ea6\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u65e0\u8bba\u5176\u7279\u5b9a\u67b6\u6784\u4e3a\u4f55\u3002\u5728\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u548c\u4e00\u4e2a\u65f6\u7a7a\u6c14\u8c61ERA5\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSoP\u7684\u6709\u6548\u6027\uff0c\u5373\u4f7f\u4f7f\u7528\u7b80\u5355\u7684MLP\u4f5c\u4e3aPlug\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u8fbe22%\u7684\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u901a\u7528\u6821\u51c6\u7b56\u7565\u800c\u975e\u91cd\u65b0\u8bbe\u8ba1\u548c\u8bad\u7ec3\u65b0\u6a21\u578b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.03424", "pdf": "https://arxiv.org/pdf/2506.03424", "abs": "https://arxiv.org/abs/2506.03424", "authors": ["Nicole R Schneider", "Nandini Ramachandran", "Kent O'Sullivan", "Hanan Samet"], "title": "DistRAG: Towards Distance-Based Spatial Reasoning in LLMs", "categories": ["cs.CL", "cs.IR"], "comment": null, "summary": "Many real world tasks where Large Language Models (LLMs) can be used require\nspatial reasoning, like Point of Interest (POI) recommendation and itinerary\nplanning. However, on their own LLMs lack reliable spatial reasoning\ncapabilities, especially about distances. To address this problem, we develop a\nnovel approach, DistRAG, that enables an LLM to retrieve relevant spatial\ninformation not explicitly learned during training. Our method encodes the\ngeodesic distances between cities and towns in a graph and retrieves a context\nsubgraph relevant to the question. Using this technique, our method enables an\nLLM to answer distance-based reasoning questions that it otherwise cannot\nanswer. Given the vast array of possible places an LLM could be asked about,\nDistRAG offers a flexible first step towards providing a rudimentary `world\nmodel' to complement the linguistic knowledge held in LLMs.", "AI": {"tldr": "DistRAG \u662f\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u7801\u7a7a\u95f4\u8ddd\u79bb\u6765\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u56de\u7b54\u8ddd\u79bb\u76f8\u5173\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7f3a\u4e4f\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u5c24\u5176\u662f\u5728\u8ddd\u79bb\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3a DistRAG \u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u56fe\u4e2d\u7f16\u7801\u57ce\u5e02\u548c\u57ce\u9547\u4e4b\u95f4\u7684\u6d4b\u5730\u8ddd\u79bb\u6765\u8f85\u52a9 LLM \u68c0\u7d22\u76f8\u5173\u7a7a\u95f4\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u8be5\u65b9\u6cd5\uff0cLLM \u80fd\u591f\u89e3\u7b54\u57fa\u4e8e\u8ddd\u79bb\u7684\u63a8\u7406\u95ee\u9898\uff0c\u4ece\u800c\u6269\u5c55\u5176\u5e94\u7528\u80fd\u529b\u3002", "conclusion": "DistRAG \u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u89e3\u51b3\u7a7a\u95f4\u63a8\u7406\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5730\u7406\u4fe1\u606f\u4ee5\u8865\u5145\u5176\u8bed\u8a00\u77e5\u8bc6\u3002"}}
{"id": "2506.03610", "pdf": "https://arxiv.org/pdf/2506.03610", "abs": "https://arxiv.org/abs/2506.03610", "authors": ["Dongmin Park", "Minkyu Kim", "Beongjun Choi", "Junhyuck Kim", "Keon Lee", "Jonghyun Lee", "Inkyu Park", "Byeong-Uk Lee", "Jaeyoung Hwang", "Jaewoo Ahn", "Ameya S. Mahabaleshwarkar", "Bilal Kartal", "Pritam Biswas", "Yoshi Suhara", "Kangwook Lee", "Jaewoong Cho"], "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents are reshaping the game industry,\nparticularly with more intelligent and human-preferable game characters.\nHowever, existing game benchmarks fall short of practical needs: they lack\nevaluations of diverse LLM capabilities across various game genres, studies of\nagentic modules crucial for complex gameplay, and fine-tuning datasets for\naligning pre-trained LLMs into gaming agents. To fill these gaps, we present\n\\textbf{\\benchname{}}, a foundational benchmark designed to train and evaluate\nLLM agents across diverse real-world video games. Unlike existing benchmarks,\nOrak includes 12 popular video games spanning all major genres, enabling\ncomprehensive studies of LLM capabilities and agentic modules essential for\nintricate game scenarios. To support consistent evaluation of LLMs, we\nintroduce a plug-and-play interface based on Model Context Protocol (MCP) that\nenables LLMs to seamlessly connect with games and manipulate agentic modules.\nAdditionally, we propose a fine-tuning dataset, consisting of LLM gameplay\ntrajectories across diverse game genres. Orak offers a comprehensive evaluation\nframework, encompassing general game score leaderboards, LLM battle arenas, and\nin-depth analyses of visual input state, agentic strategies, and fine-tuning\neffects, establishing a foundation towards building generic gaming agents. Code\nis available at https://github.com/krafton-ai/Orak.", "AI": {"tldr": "\u63d0\u51faOrak\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3LLM\u4ee3\u7406\u5728\u591a\u79cd\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u652f\u6301\u901a\u7528\u6e38\u620f\u4ee3\u7406\u7684\u6784\u5efa\u3002", "motivation": "\u73b0\u6709\u7684\u6e38\u620f\u57fa\u51c6\u5728\u591a\u6837\u5316\u7684\u6e38\u620f\u7c7b\u578b\u4e2d\u7f3a\u4e4f\u5bf9LLM\u591a\u79cd\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5bf9\u590d\u6742\u6e38\u620f\u73a9\u6cd5\u4e2d\u5173\u952e\u7684\u4ee3\u7406\u6a21\u5757\u7684\u7814\u7a76\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u7528\u4e8e\u5c06\u9884\u8bad\u7ec3\u7684LLM\u4e0e\u6e38\u620f\u4ee3\u7406\u5bf9\u9f50\u7684\u5fae\u8c03\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eModel Context Protocol\uff08MCP\uff09\u7684\u5373\u63d2\u5373\u7528\u63a5\u53e3\uff0c\u4f7fLLM\u80fd\u591f\u65e0\u7f1d\u8fde\u63a5\u6e38\u620f\u548c\u64cd\u4f5c\u4ee3\u7406\u6a21\u5757\uff1b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cbe\u7ec6\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u5305\u542b\u8de8\u591a\u79cd\u6e38\u620f\u7c7b\u578b\u7684LLM\u6e38\u620f\u8f68\u8ff9\u3002", "result": "Orak\u6210\u4e3a\u8bc4\u4f30LLM\u5728\u591a\u79cd\u6e38\u620f\u4e2d\u7684\u80fd\u529b\u7684\u57fa\u7840\u5de5\u5177\uff0c\u5305\u62ec\u6e38\u620f\u5f97\u5206\u6392\u884c\u699c\u3001LLM\u6218\u6597\u7ade\u6280\u573a\u4ee5\u53ca\u5bf9\u89c6\u89c9\u8f93\u5165\u72b6\u6001\u3001\u4ee3\u7406\u7b56\u7565\u548c\u5fae\u8c03\u6548\u679c\u7684\u6df1\u5165\u5206\u6790\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u540d\u4e3aOrak\u7684\u57fa\u51c6\uff0c\u652f\u6301\u8bad\u7ec3\u548c\u6d4b\u8bd5LLM\u4ee3\u7406\u5728\u591a\u6837\u5316\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u6e38\u620f\u4e2d\u7684\u8868\u73b0\uff0c\u65e8\u5728\u63a8\u52a8\u6784\u5efa\u901a\u7528\u5316\u7684\u6e38\u620f\u4ee3\u7406\u3002"}}
{"id": "2506.03206", "pdf": "https://arxiv.org/pdf/2506.03206", "abs": "https://arxiv.org/abs/2506.03206", "authors": ["Nadav Timor", "Jonathan Mamou", "Oren Pereg", "Hongyang Zhang", "David Harel"], "title": "Out-of-Vocabulary Sampling Boosts Speculative Decoding", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Speculative decoding relies on fast and accurate drafters. Recent\nstate-of-the-art language models employ larger and larger vocabularies, which\nsignificantly slows down drafters. One promising approach to boost the\nefficiency of speculative decoding is to use drafters with smaller\nvocabularies. However, existing sampling methods cannot draw out-of-vocabulary\ntokens, creating a tradeoff between drafters' vocabulary size and acceptance\nrates. This paper introduces Redistributing Drafter Kernels (RDK), the first\nout-of-vocabulary sampler that effectively recovers acceptance rates by\nvirtually restoring pruned target tokens. RDK leverages token-affinity priors\nto reallocate drafter mass towards high-overlap regions. We prove\nmathematically that RDK can achieve higher acceptance rates than vanilla and\nstate-of-the-art samplers. We provide an efficient first-order approximation of\nRDK and prove that it reduces redistribution times from $O(N^2)$ to $O(N)$,\nenabling lightweight implementations for large vocabularies. Our experiments\ndemonstrate that this linear-time RDK significantly boosts acceptance rates\neven after extreme pruning (removing more than 75% of the drafter's\nvocabulary), where existing samplers fail. RDK opens the door to extremely\npruned drafters, which were previously impractical.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u91cd\u65b0\u5206\u914d\u8349\u7a3f\u751f\u6210\u5668\u5185\u6838\uff08RDK\uff09\uff0c\u4e00\u79cd\u6709\u6548\u5904\u7406\u8d85\u51fa\u8bcd\u6c47\u8868\u91c7\u6837\u7684\u6280\u672f\uff0c\u5927\u5927\u63d0\u9ad8\u4e86\u63a5\u53d7\u7387\uff0c\u652f\u6301\u6781\u7aef\u8bcd\u6c47\u91cf\u4fee\u526a\uff0c\u63d0\u9ad8\u63a8\u6d4b\u89e3\u7801\u5668\u6548\u7387\u3002", "motivation": "\u7531\u4e8e\u5f53\u524d\u7684\u6700\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u8d8a\u6765\u8d8a\u5927\u7684\u8bcd\u6c47\u8868\uff0c\u5bfc\u81f4\u8349\u7a3f\u751f\u6210\u901f\u5ea6\u53d8\u6162\uff0c\u56e0\u6b64\u672c\u6587\u63a2\u8ba8\u5982\u4f55\u901a\u8fc7\u4f7f\u7528\u8bcd\u6c47\u8868\u8f83\u5c0f\u7684\u8349\u7a3f\u751f\u6210\u5668\u6765\u63d0\u9ad8\u63a8\u6d4b\u89e3\u7801\u7684\u6548\u7387\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u91c7\u6837\u65b9\u6cd5\u65e0\u6cd5\u751f\u6210\u8d85\u51fa\u8bcd\u6c47\u8868\u7684\u8bcd\u5143\uff0c\u4ece\u800c\u5728\u8349\u7a3f\u751f\u6210\u5668\u7684\u8bcd\u6c47\u5927\u5c0f\u548c\u63a5\u53d7\u7387\u4e4b\u95f4\u4ea7\u751f\u6743\u8861\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u91cd\u65b0\u5206\u914d\u8349\u7a3f\u751f\u6210\u5668\u5185\u6838\uff08RDK\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u8d85\u51fa\u8bcd\u6c47\u8868\u7684\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u865a\u62df\u6062\u590d\u4fee\u526a\u7684\u76ee\u6807\u8bcd\u5143\u6765\u6709\u6548\u5730\u6062\u590d\u63a5\u53d7\u7387\u3002", "result": "\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\uff0cRDK\u53ef\u4ee5\u6bd4\u4f20\u7edf\u548c\u6700\u5148\u8fdb\u7684\u91c7\u6837\u5668\u5b9e\u73b0\u66f4\u9ad8\u7684\u63a5\u53d7\u7387\u3002\u6211\u4eec\u63d0\u4f9b\u4e86RDK\u7684\u9ad8\u6548\u4e00\u9636\u8fd1\u4f3c\uff0c\u5e76\u8bc1\u660e\u5b83\u5c06\u91cd\u5206\u914d\u65f6\u95f4\u4ece$O(N^2)$\u51cf\u5c11\u5230$O(N)$\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u6781\u7aef\u4fee\u526a\uff08\u79fb\u9664\u8d85\u8fc7\u8349\u7a3f\u751f\u6210\u5668\u8bcd\u6c47\u8868\u768475%\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u7ebf\u6027\u65f6\u95f4RDK\u4e5f\u663e\u8457\u63d0\u9ad8\u4e86\u63a5\u53d7\u7387\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528RDK\uff0c\u53ef\u4ee5\u5728\u6781\u7aef\u4fee\u526a\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9ad8\u5ea6\u6709\u6548\u7684\u63a8\u6d4b\u89e3\u7801\u5668\uff0c\u8fd9\u5728\u8fc7\u53bb\u662f\u4e0d\u5b9e\u9645\u7684\u3002"}}
{"id": "2506.03434", "pdf": "https://arxiv.org/pdf/2506.03434", "abs": "https://arxiv.org/abs/2506.03434", "authors": ["Ahmad Dawar Hakimi", "Ali Modarressi", "Philipp Wicke", "Hinrich Sch\u00fctze"], "title": "Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Understanding how large language models (LLMs) acquire and store factual\nknowledge is crucial for enhancing their interpretability and reliability. In\nthis work, we analyze the evolution of factual knowledge representation in the\nOLMo-7B model by tracking the roles of its attention heads and feed forward\nnetworks (FFNs) over the course of pre-training. We classify these components\ninto four roles: general, entity, relation-answer, and fact-answer specific,\nand examine their stability and transitions. Our results show that LLMs\ninitially depend on broad, general-purpose components, which later specialize\nas training progresses. Once the model reliably predicts answers, some\ncomponents are repurposed, suggesting an adaptive learning process. Notably,\nattention heads display the highest turnover. We also present evidence that\nFFNs remain more stable throughout training. Furthermore, our probing\nexperiments reveal that location-based relations converge to high accuracy\nearlier in training than name-based relations, highlighting how task complexity\nshapes acquisition dynamics. These insights offer a mechanistic view of\nknowledge formation in LLMs.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86OLMo-7B\u6a21\u578b\u4e2d\u77e5\u8bc6\u8868\u5f81\u7684\u6f14\u53d8\uff0c\u53d1\u73b0\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\uff0c\u6a21\u578b\u7ec4\u4ef6\u9010\u6e10\u4e13\u4e1a\u5316\uff0c\u6ce8\u610f\u5934\u53d8\u5316\u6700\u5927\uff0c\u800cFFNs\u8f83\u4e3a\u7a33\u5b9a\u3002", "motivation": "\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u83b7\u53d6\u548c\u5b58\u50a8\u4e8b\u5b9e\u77e5\u8bc6\u7684\u673a\u5236\uff0c\u4ee5\u63d0\u9ad8\u5176\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u8ddf\u8e2aOLMo-7B\u6a21\u578b\u4e2d\u6ce8\u610f\u5934\u548c\u524d\u9988\u7f51\u7edc\u7684\u89d2\u8272\u53d8\u5316\uff0c\u5206\u7c7b\u4e3a\u56db\u79cd\u89d2\u8272\u5e76\u7814\u7a76\u5176\u7a33\u5b9a\u6027\u548c\u53d8\u8fc1\u3002", "result": "\u968f\u7740\u8bad\u7ec3\u8fdb\u5c55\uff0c\u6a21\u578b\u4ece\u4f9d\u8d56\u5e7f\u6cdb\u7684\u901a\u7528\u7ec4\u4ef6\u8f6c\u5411\u66f4\u4e13\u4e1a\u5316\uff0c\u5e76\u4e14\u4e00\u4e9b\u7ec4\u4ef6\u88ab\u91cd\u65b0\u5229\u7528\u3002\u6ce8\u610f\u5934\u7684\u53d8\u5316\u6700\u9ad8\uff0c\u800cFFNs\u76f8\u5bf9\u66f4\u7a33\u5b9a\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u4f4d\u7f6e\u7684\u5173\u7cfb\u6bd4\u57fa\u4e8e\u540d\u79f0\u7684\u5173\u7cfb\u66f4\u65e9\u6536\u655b\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86LLMs\u5728\u9884\u8bad\u7ec3\u4e2d\u77e5\u8bc6\u8868\u5f81\u7684\u6f14\u53d8\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u7ec4\u4ef6\u7684\u7a33\u5b9a\u6027\u4ee5\u53ca\u5b83\u4eec\u5982\u4f55\u4e3a\u9002\u5e94\u77e5\u8bc6\u9884\u6d4b\u8981\u6c42\u800c\u8fdb\u884c\u91cd\u7ec4\u3002"}}
{"id": "2506.03613", "pdf": "https://arxiv.org/pdf/2506.03613", "abs": "https://arxiv.org/abs/2506.03613", "authors": ["Shaoshan Liu", "Fan Wang", "Hongjun Zhou", "Yuanfeng Wang"], "title": "Training Cross-Morphology Embodied AI Agents: From Practical Challenges to Theoretical Foundations", "categories": ["cs.AI", "cs.CC"], "comment": null, "summary": "While theory and practice are often seen as separate domains, this article\nshows that theoretical insight is essential for overcoming real-world\nengineering barriers. We begin with a practical challenge: training a\ncross-morphology embodied AI policy that generalizes across diverse robot\nmorphologies. We formalize this as the Heterogeneous Embodied Agent Training\n(HEAT) problem and prove it reduces to a structured Partially Observable Markov\nDecision Process (POMDP) that is PSPACE-complete. This result explains why\ncurrent reinforcement learning pipelines break down under morphological\ndiversity, due to sequential training constraints, memory-policy coupling, and\ndata incompatibility. We further explore Collective Adaptation, a distributed\nlearning alternative inspired by biological systems. Though NEXP-complete in\ntheory, it offers meaningful scalability and deployment benefits in practice.\nThis work illustrates how computational theory can illuminate system design\ntrade-offs and guide the development of more robust, scalable embodied AI. For\npractitioners and researchers to explore this problem, the implementation code\nof this work has been made publicly available at\nhttps://github.com/airs-admin/HEAT", "AI": {"tldr": "\u7406\u8bba\u6d1e\u5bdf\u5bf9\u514b\u670d\u5de5\u7a0b\u969c\u788d\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u5f02\u6784\u5177\u8eab\u667a\u80fd\u4f53\u8bad\u7ec3\u95ee\u9898\uff08HEAT\uff09\uff0c\u63ed\u793a\u4e86\u73b0\u884c\u5f3a\u5316\u5b66\u4e60\u5b58\u5728\u7684\u95ee\u9898\uff0c\u63a2\u8ba8\u4e86\u96c6\u4f53\u9002\u5e94\u7684\u6709\u6548\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u5b9e\u65bd\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u8de8\u591a\u79cd\u673a\u5668\u4eba\u5f62\u6001\u8bad\u7ec3\u5177\u8eabAI\u7b56\u7565\u7684\u5b9e\u9645\u6311\u6218\u3002", "method": "\u8bc1\u660e\u5f02\u6784\u5177\u8eab\u667a\u80fd\u4f53\u8bad\u7ec3\u95ee\u9898\uff08HEAT\uff09\u53ef\u88ab\u7b80\u5316\u4e3aPSPACE-\u5b8c\u5168\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u3002\u63a2\u8ba8\u4e86\u53d7\u751f\u7269\u7cfb\u7edf\u542f\u53d1\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\u2014\u2014\u96c6\u4f53\u9002\u5e94\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u5f62\u6001\u591a\u6837\u6027\u4e0b\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\u5931\u6548\u539f\u56e0\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u66f4\u5177\u5b9e\u9645\u610f\u4e49\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8ba1\u7b97\u7406\u8bba\u80fd\u591f\u63ed\u793a\u7cfb\u7edf\u8bbe\u8ba1\u6743\u8861\uff0c\u5e76\u6307\u5bfc\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u7684\u5177\u8eabAI\u3002"}}
{"id": "2506.03207", "pdf": "https://arxiv.org/pdf/2506.03207", "abs": "https://arxiv.org/abs/2506.03207", "authors": ["Md Nahid Hasan Shuvo", "Moinul Hossain"], "title": "Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "7 pages, 4 Figures, Accepted to publish in Proceedings of the 2025\n  ACM Workshop on Wireless Security and Machine Learning (WiseML 2025), July 3,\n  2025, Arlington, VA, USA", "summary": "Federated Learning (FL) is increasingly adopted as a decentralized machine\nlearning paradigm due to its capability to preserve data privacy by training\nmodels without centralizing user data. However, FL is susceptible to indirect\nprivacy breaches via network traffic analysis-an area not explored in existing\nresearch. The primary objective of this research is to study the feasibility of\nfingerprinting deep learning models deployed within FL environments by\nanalyzing their network-layer traffic information. In this paper, we conduct an\nexperimental evaluation using various deep learning architectures (i.e., CNN,\nRNN) within a federated learning testbed. We utilize machine learning\nalgorithms, including Support Vector Machines (SVM), Random Forest, and\nGradient-Boosting, to fingerprint unique patterns within the traffic data. Our\nexperiments show high fingerprinting accuracy, achieving 100% accuracy using\nRandom Forest and around 95.7% accuracy using SVM and Gradient Boosting\nclassifiers. This analysis suggests that we can identify specific architectures\nrunning within the subsection of the network traffic. Hence, if an adversary\nknows about the underlying DL architecture, they can exploit that information\nand conduct targeted attacks. These findings suggest a notable security\nvulnerability in FL systems and the necessity of strengthening it at the\nnetwork level.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u7f51\u7edc\u5c42\u6d41\u91cf\u4fe1\u606f\uff0c\u6210\u529f\u5b9e\u73b0\u5bf9\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6307\u7eb9\u8bc6\u522b\uff0c\u63ed\u793a\u4e86FL\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60(FL)\u6846\u67b6\u4e0b\uff0c\u5b9e\u73b0\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\uff0c\u907f\u514d\u96c6\u4e2d\u7528\u6237\u6570\u636e\u3002\u7136\u800c\uff0cFL\u9762\u4e34\u901a\u8fc7\u7f51\u7edc\u6d41\u91cf\u5206\u6790\u95f4\u63a5\u6cc4\u9732\u9690\u79c1\u7684\u98ce\u9669\uff0c\u8be5\u9886\u57df\u76ee\u524d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u8bd5\u9a8c\u5e73\u53f0\u4e2d\u4f7f\u7528\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08\u5982CNN\uff0cRNN\uff09\u3002\u5229\u7528\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u3001\u968f\u673a\u68ee\u6797\u548c\u68af\u5ea6\u63d0\u5347\u7b49\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u5bf9\u7f51\u7edc\u6d41\u91cf\u6570\u636e\u4e2d\u7684\u72ec\u7279\u6a21\u5f0f\u8fdb\u884c\u6307\u7eb9\u8bc6\u522b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u7b97\u6cd5\u53ef\u4ee5\u8fbe\u5230100%\u7684\u6307\u7eb9\u8bc6\u522b\u51c6\u786e\u7387\uff0c\u800c\u4f7f\u7528SVM\u548c\u68af\u5ea6\u63d0\u5347\u7b97\u6cd5\u5219\u53ef\u4ee5\u8fbe\u5230\u7ea695.7%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u663e\u8457\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u5efa\u8bae\u9700\u8981\u5728\u7f51\u7edc\u5c42\u9762\u52a0\u5f3a\u5b89\u5168\u6027\uff0c\u4ee5\u9632\u6b62\u5df2\u77e5DL\u67b6\u6784\u88ab\u7528\u6765\u53d1\u52a8\u9488\u5bf9\u6027\u653b\u51fb\u3002"}}
{"id": "2506.03458", "pdf": "https://arxiv.org/pdf/2506.03458", "abs": "https://arxiv.org/abs/2506.03458", "authors": ["Zahra Bokaei", "Walid Magdy", "Bonnie Webber"], "title": "Culture Matters in Toxic Language Detection in Persian", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 (Main Track)", "summary": "Toxic language detection is crucial for creating safer online environments\nand limiting the spread of harmful content. While toxic language detection has\nbeen under-explored in Persian, the current work compares different methods for\nthis task, including fine-tuning, data enrichment, zero-shot and few-shot\nlearning, and cross-lingual transfer learning. What is especially compelling is\nthe impact of cultural context on transfer learning for this task: We show that\nthe language of a country with cultural similarities to Persian yields better\nresults in transfer learning. Conversely, the improvement is lower when the\nlanguage comes from a culturally distinct country. Warning: This paper contains\nexamples of toxic language that may disturb some readers. These examples are\nincluded for the purpose of research on toxic detection.", "AI": {"tldr": "\u6ce2\u65af\u8bed\u6709\u5bb3\u8bed\u8a00\u68c0\u6d4b\u7814\u7a76\u63a2\u7d22\u4e0d\u540c\u65b9\u6cd5\uff0c\u53d1\u73b0\u6587\u5316\u76f8\u8fd1\u7684\u8bed\u8a00\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u4e2d\u6548\u679c\u66f4\u4f73\u3002", "motivation": "\u7814\u7a76\u6ce2\u65af\u8bed\u4e2d\u7684\u6709\u5bb3\u8bed\u8a00\u68c0\u6d4b\u5e76\u63a2\u8ba8\u6587\u5316\u80cc\u666f\u5bf9\u8fc1\u79fb\u5b66\u4e60\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u5fae\u8c03\u3001\u6570\u636e\u4e30\u5bcc\u3001\u96f6\u6837\u672c\u548c\u5c0f\u6837\u672c\u5b66\u4e60\uff0c\u4ee5\u53ca\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\uff0c\u6765\u7814\u7a76\u6ce2\u65af\u8bed\u7684\u6709\u5bb3\u8bed\u8a00\u68c0\u6d4b\u3002", "result": "\u4e0e\u5177\u6709\u76f8\u4f3c\u6587\u5316\u80cc\u666f\u7684\u8bed\u8a00\u8fdb\u884c\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u80fd\u63d0\u9ad8\u68c0\u6d4b\u6548\u679c\uff0c\u800c\u6587\u5316\u5dee\u5f02\u8f83\u5927\u7684\u8bed\u8a00\u6240\u5e26\u6765\u7684\u6539\u5584\u8f83\u5c0f\u3002", "conclusion": "\u5177\u6709\u6587\u5316\u76f8\u4f3c\u6027\u7684\u8bed\u8a00\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u800c\u6587\u5316\u5dee\u5f02\u8f83\u5927\u7684\u8bed\u8a00\u5bf9\u8fc1\u79fb\u6548\u679c\u5f71\u54cd\u8f83\u5c0f\u3002"}}
{"id": "2506.03673", "pdf": "https://arxiv.org/pdf/2506.03673", "abs": "https://arxiv.org/abs/2506.03673", "authors": ["Yinlong Xu", "Yanzhao Zheng", "Shuoshuo Sun", "Shuaihan Huang", "Baohua Dong", "Hangcheng Zhu", "Ruohui Huang", "Gang Yu", "Hongxia Xu", "Jian Wu"], "title": "Reason from Future: Reverse Thought Chain Enhances LLM Reasoning", "categories": ["cs.AI"], "comment": "Accepted by ACL 2025 findings", "summary": "It has been demonstrated that carefully designed reasoning paradigms, like\nChain-of-Thought (CoT) and Tree-of-Thought (ToT), can enhance the reasoning\ncapabilities of small language models by detailed thinking and extensive\nthought searching, unbounded branching factors in the searching space create\nprohibitive reasoning consumption. However these methods fall into the trap of\nlocal optimum reasoning, which means the model lacks a global perspective while\nsolving problems. We propose a novel reasoning paradigm called Reason from\nFuture (RFF), which generates reasoning paths by bidirectional reasoning that\ncombines top-down planning with bottom-up reasoning accumulation. The essence\nof RFF lies in its reverse reasoning mechanism, which prioritizes core logical\nrelationships and imposes goal-oriented constraints on intermediate steps,\nthereby reducing the searching space and mitigating error accumulation inherent\nin sequential forward reasoning. Empirical evaluations across diverse\nexperiments demonstrate that RFF outperforms conventional paradigms with higher\naccuracy and less searching space to solve complex tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u6a21\u5f0fRFF\uff0c\u901a\u8fc7\u9006\u5411\u63a8\u7406\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\uff0c\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u548c\u6811\u5f0f\u601d\u7ef4\uff08ToT\uff09\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u4f46\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u63a8\u7406\u4e2d\uff0c\u7f3a\u4e4f\u89e3\u51b3\u95ee\u9898\u7684\u5168\u5c40\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u6a21\u5f0f\u2014\u2014Reason from Future\uff08RFF\uff09\uff0c\u901a\u8fc7\u53cc\u5411\u63a8\u7406\uff0c\u7ed3\u5408\u81ea\u4e0a\u800c\u4e0b\u7684\u89c4\u5212\u4e0e\u81ea\u4e0b\u800c\u4e0a\u7684\u63a8\u7406\u79ef\u7d2f\uff0c\u751f\u6210\u63a8\u7406\u8def\u5f84\u3002RFF\u7684\u6838\u5fc3\u5728\u4e8e\u5176\u9006\u5411\u63a8\u7406\u673a\u5236\uff0c\u4f18\u5148\u8003\u8651\u6838\u5fc3\u903b\u8f91\u5173\u7cfb\uff0c\u5bf9\u4e2d\u95f4\u6b65\u9aa4\u65bd\u52a0\u76ee\u6807\u5bfc\u5411\u7684\u7ea6\u675f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRFF\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65f6\u8868\u73b0\u51fa\u66f4\u9ad8\u7cbe\u5ea6\u548c\u66f4\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u4f18\u4e8e\u4f20\u7edf\u8303\u5f0f\u3002", "conclusion": "RFF\u901a\u8fc7\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\u548c\u7f13\u89e3\u987a\u5e8f\u524d\u5411\u63a8\u7406\u56fa\u6709\u7684\u9519\u8bef\u79ef\u7d2f\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u3002"}}
{"id": "2506.03210", "pdf": "https://arxiv.org/pdf/2506.03210", "abs": "https://arxiv.org/abs/2506.03210", "authors": ["Qiusheng Huang", "Yuan Niu", "Xiaohui Zhong", "Anboyu Guo", "Lei Chen", "Dianjun Zhang", "Xuefeng Zhang", "Hao Li"], "title": "FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "comment": null, "summary": "Accurate, high-resolution ocean forecasting is crucial for maritime\noperations and environmental monitoring. While traditional numerical models are\ncapable of producing sub-daily, eddy-resolving forecasts, they are\ncomputationally intensive and face challenges in maintaining accuracy at fine\nspatial and temporal scales. In contrast, recent data-driven approaches offer\nimproved computational efficiency and emerging potential, yet typically operate\nat daily resolution and struggle with sub-daily predictions due to error\naccumulation over time. We introduce FuXi-Ocean, the first data-driven global\nocean forecasting model achieving six-hourly predictions at eddy-resolving\n1/12{\\deg} spatial resolution, reaching depths of up to 1500 meters. The model\narchitecture integrates a context-aware feature extraction module with a\npredictive network employing stacked attention blocks. The core innovation is\nthe Mixture-of-Time (MoT) module, which adaptively integrates predictions from\nmultiple temporal contexts by learning variable-specific reliability ,\nmitigating cumulative errors in sequential forecasting. Through comprehensive\nexperimental evaluation, FuXi-Ocean demonstrates superior skill in predicting\nkey variables, including temperature, salinity, and currents, across multiple\ndepths.", "AI": {"tldr": "FuXi-Ocean\u662f\u9996\u4e2a\u80fd\u5b9e\u73b0\u516d\u5c0f\u65f6\u9884\u6d4b\u7684\u5168\u7403\u6d77\u6d0b\u6570\u636e\u9a71\u52a8\u6a21\u578b\uff0c\u7ed3\u5408MoT\u6a21\u5757\u57281500\u7c73\u6df1\u5ea6\u548c\u591a\u4e2a\u5173\u952e\u53d8\u91cf\u4e0a\u663e\u793a\u51fa\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6570\u503c\u6a21\u578b\u5c3d\u7ba1\u53ef\u4ee5\u5b9e\u73b0\u4e9a\u65e5\u3001\u89e3\u6790\u6da1\u7684\u9884\u62a5\uff0c\u4f46\u8ba1\u7b97\u91cf\u5927\u4e14\u5728\u7cbe\u7ec6\u7684\u65f6\u7a7a\u5c3a\u5ea6\u4e0a\u5f88\u96be\u7ef4\u6301\u51c6\u786e\u6027\u3002\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u4f46\u901a\u5e38\u5728\u65e5\u5206\u8fa8\u7387\u4e0b\u64cd\u4f5c\uff0c\u5e76\u5728\u4e9a\u65e5\u9884\u6d4b\u4e2d\u5bb9\u6613\u56e0\u8bef\u5dee\u79ef\u7d2f\u800c\u8868\u73b0\u4e0d\u4f73\u3002", "method": "FuXi-Ocean\u6a21\u578b\u96c6\u6210\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u548c\u4f7f\u7528\u5806\u53e0\u6ce8\u610f\u529b\u5757\u7684\u9884\u6d4b\u7f51\u7edc\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u662f\u65f6\u95f4\u6df7\u5408\uff08MoT\uff09\u6a21\u5757\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u7efc\u5408\u6765\u81ea\u591a\u4e2a\u65f6\u95f4\u4e0a\u4e0b\u6587\u7684\u9884\u6d4b\u3002", "result": "FuXi-Ocean\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u8bc1\u660e\u5176\u5728\u591a\u6df1\u5ea6\u5173\u952e\u53d8\u91cf\u9884\u6d4b\u4e0a\u7684\u6280\u80fd\u5353\u8d8a\u3002", "conclusion": "FuXi-Ocean\u6210\u529f\u5b9e\u73b0\u4e86\u5168\u7403\u6d77\u6d0b\u7684\u516d\u5c0f\u65f6\u9884\u62a5\uff0c\u57281/12\u00b0\u7684\u7a7a\u95f4\u5206\u8fa8\u7387\u4e0b\u80fd\u89e3\u6790\u6da1\u6d41\uff0c\u9884\u6d4b\u6df1\u5ea6\u53ef\u8fbe1500\u7c73\uff0c\u4e14\u5728\u6e29\u5ea6\u3001\u76d0\u5ea6\u548c\u6c34\u6d41\u7b49\u5173\u952e\u53d8\u91cf\u7684\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2506.03476", "pdf": "https://arxiv.org/pdf/2506.03476", "abs": "https://arxiv.org/abs/2506.03476", "authors": ["Chuyuan Li", "Raymond Li", "Thalia S. Field", "Giuseppe Carenini"], "title": "Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection", "categories": ["cs.CL"], "comment": null, "summary": "Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that\nleads to dementia, and early intervention can greatly benefit from analyzing\nlinguistic abnormalities. In this work, we explore the potential of Large\nLanguage Models (LLMs) as health assistants for AD diagnosis from\npatient-generated text using in-context learning (ICL), where tasks are defined\nthrough a few input-output examples. Empirical results reveal that conventional\nICL methods, such as similarity-based selection, perform poorly for AD\ndiagnosis, likely due to the inherent complexity of this task. To address this,\nwe introduce Delta-KNN, a novel demonstration selection strategy that enhances\nICL performance. Our method leverages a delta score to assess the relative\ngains of each training example, coupled with a KNN-based retriever that\ndynamically selects optimal \"representatives\" for a given input. Experiments on\ntwo AD detection datasets across three open-source LLMs demonstrate that\nDelta-KNN consistently outperforms existing ICL baselines. Notably, when using\nthe Llama-3.1 model, our approach achieves new state-of-the-art results,\nsurpassing even supervised classifiers.", "AI": {"tldr": "\u5f15\u5165Delta-KNN\u7b56\u7565\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u521b\u4e0b\u4e1a\u754c\u65b0\u9ad8\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u662f\u4e00\u79cd\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\uff0c\u65e9\u671f\u5e72\u9884\u6548\u679c\u663e\u8457\uff0c\u56e0\u6b64\u901a\u8fc7\u5206\u6790\u8bed\u8a00\u5f02\u5e38\u8fdb\u884c\u8bca\u65ad\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u5065\u5eb7\u52a9\u624b\u5728\u8fd9\u4e00\u9886\u57df\u5177\u6709\u6f5c\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86Delta-KNN\uff0c\u4e00\u79cd\u65b0\u7684\u793a\u8303\u9009\u62e9\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u589e\u91cf\u5206\u6570\u8bc4\u4f30\u5404\u8bad\u7ec3\u6837\u672c\u7684\u76f8\u5bf9\u6536\u76ca\uff0c\u7ed3\u5408\u57fa\u4e8eKNN\u7684\u68c0\u7d22\u5668\u52a8\u6001\u9009\u62e9\u7ed9\u5b9a\u8f93\u5165\u7684\u6700\u4f73\u201c\u4ee3\u8868\u201d\u3002", "result": "Delta-KNN\u5728\u4e24\u4e2a\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u5f00\u6e90LLM\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5176\u6027\u80fd\u7a33\u5b9a\u4f18\u4e8e\u73b0\u6709ICL\u57fa\u51c6\uff0c\u5c24\u5176\u662f\u4f7f\u7528Llama-3.1\u6a21\u578b\u65f6\uff0cDelta-KNN\u5b9e\u73b0\u4e86\u8d85\u8d8a\u76d1\u7763\u5206\u7c7b\u5668\u7684\u65b0\u4e1a\u754c\u6700\u4f18\u6548\u679c\u3002", "conclusion": "\u6211\u4eec\u7684\u7814\u7a76\u8868\u660e\uff0cDelta-KNN\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u793a\u8303\u9009\u62e9\u7b56\u7565\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8ICL\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u4f7f\u7528Llama-3.1\u6a21\u578b\uff0cDelta-KNN\u65b9\u6cd5\u80fd\u591f\u8d85\u8fc7\u73b0\u6709\u7684ICL\u57fa\u51c6\uff0c\u5e76\u53d6\u5f97\u65b0\u7684\u6700\u5148\u8fdb\u6210\u679c\uff0c\u4f18\u4e8e\u76d1\u7763\u5206\u7c7b\u5668\u3002"}}
{"id": "2506.03225", "pdf": "https://arxiv.org/pdf/2506.03225", "abs": "https://arxiv.org/abs/2506.03225", "authors": ["Wa\u00ebl Doulazmi", "Auguste Lehuger", "Marin Toromanoff", "Valentin Charraut", "Thibault Buhet", "Fabien Moutarde"], "title": "Multiple-Frequencies Population-Based Training", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "Accepted at RLC25", "summary": "Reinforcement Learning's high sensitivity to hyperparameters is a source of\ninstability and inefficiency, creating significant challenges for\npractitioners. Hyperparameter Optimization (HPO) algorithms have been developed\nto address this issue, among them Population-Based Training (PBT) stands out\nfor its ability to generate hyperparameters schedules instead of fixed\nconfigurations. PBT trains a population of agents, each with its own\nhyperparameters, frequently ranking them and replacing the worst performers\nwith mutations of the best agents. These intermediate selection steps can cause\nPBT to focus on short-term improvements, leading it to get stuck in local\noptima and eventually fall behind vanilla Random Search over longer timescales.\nThis paper studies how this greediness issue is connected to the choice of\nevolution frequency, the rate at which the selection is done. We propose\nMultiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm\nthat addresses greediness by employing sub-populations, each evolving at\ndistinct frequencies. MF-PBT introduces a migration process to transfer\ninformation between sub-populations, with an asymmetric design to balance short\nand long-term optimization. Extensive experiments on the Brax suite demonstrate\nthat MF-PBT improves sample efficiency and long-term performance, even without\nactually tuning hyperparameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MF-PBT\u7b97\u6cd5\uff0c\u901a\u8fc7\u591a\u9891\u7387\u5b50\u7fa4\u4f53\u8fdb\u5316\u548c\u8fc1\u79fb\u8fc7\u7a0b\u6539\u5584\u8d85\u53c2\u6570\u4f18\u5316\u6548\u7387\u4e0e\u957f\u671f\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff0c\u5982\u57fa\u4e8e\u7fa4\u4f53\u7684\u8bad\u7ec3\uff08PBT\uff09\u5b58\u5728\u7684\u8d2a\u5a6a\u95ee\u9898\u548c\u5c40\u90e8\u6700\u4f18\u56f0\u5883\uff0c\u7814\u7a76\u8fdb\u5316\u9891\u7387\u9009\u62e9\u5bf9\u8be5\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u4ee5\u63d0\u5347\u957f\u671f\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u9891\u7387\u7fa4\u4f53\u8bad\u7ec3\uff08MF-PBT\uff09\u7b97\u6cd5\uff0c\u5176\u4e2d\u5b50\u7fa4\u4f53\u4ee5\u4e0d\u540c\u7684\u9891\u7387\u8fdb\u5316\uff0c\u5e76\u901a\u8fc7\u975e\u5bf9\u79f0\u7684\u8fc1\u79fb\u8fc7\u7a0b\u5728\u5b50\u7fa4\u4f53\u4e4b\u95f4\u4f20\u9012\u4fe1\u606f\u3002", "result": "\u901a\u8fc7\u5728Brax\u5957\u4ef6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMF-PBT\u5728\u4e0d\u5b9e\u9645\u8c03\u6574\u8d85\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u957f\u671f\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5MF-PBT\uff0c\u901a\u8fc7\u91c7\u7528\u591a\u9891\u7387\u5b50\u7fa4\u4f53\u548c\u8fc1\u79fb\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u957f\u671f\u6027\u80fd\u3002"}}
{"id": "2506.03483", "pdf": "https://arxiv.org/pdf/2506.03483", "abs": "https://arxiv.org/abs/2506.03483", "authors": ["Jun Rao", "Zepeng Lin", "Xuebo Liu", "Xiaopeng Ke", "Lian Lian", "Dong Jin", "Shengjun Cheng", "Jun Yu", "Min Zhang"], "title": "APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training", "categories": ["cs.CL"], "comment": "ACL2025 Findings", "summary": "Large Language Models (LLMs) often require domain-specific fine-tuning to\naddress targeted tasks, which risks degrading their general capabilities.\nMaintaining a balance between domain-specific enhancements and general model\nutility is a key challenge. This paper proposes a novel approach named APT\n(Weakness Case Acquisition and Iterative Preference Training) to enhance\ndomain-specific performance with self-generated dis-preferred weakness data\n(bad cases and similar cases). APT uniquely focuses on training the model using\nonly those samples where errors occur, alongside a small, similar set of\nsamples retrieved for this purpose. This targeted training minimizes\ninterference with the model's existing knowledge base, effectively retaining\ngeneric capabilities. Experimental results on the LLama-2 and Mistral-V0.3\nmodels across various benchmarks demonstrate that APT ensures no reduction in\ngeneric capacity and achieves superior performance on downstream tasks compared\nto various existing methods. This validates our method as an effective strategy\nfor enhancing domain-specific capabilities without sacrificing the model's\nbroader applicability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAPT\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u751f\u6210\u7684\u52a3\u52bf\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u589e\u5f3a\u9886\u57df\u7279\u5b9a\u6027\u80fd\uff0c\u5e76\u4fdd\u6301\u901a\u7528\u80fd\u529b\u3002", "motivation": "\u5728\u63d0\u5347\u9886\u57df\u7279\u5b9a\u80fd\u529b\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\u662f\u4e00\u5927\u6311\u6218\uff0c\u9700\u5728\u4e24\u8005\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "method": "\u5f15\u5165APT\uff08\u4e00\u79cd\u5f31\u70b9\u6848\u4f8b\u83b7\u53d6\u548c\u8fed\u4ee3\u504f\u597d\u8bad\u7ec3\u7684\u65b9\u6cd5\uff09\uff0c\u4e13\u6ce8\u4e8e\u4f7f\u7528\u6a21\u578b\u51fa\u9519\u7684\u6837\u672c\u548c\u5c11\u91cf\u76f8\u4f3c\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAPT\u65b9\u6cd5\u5728\u4e0d\u964d\u4f4e\u901a\u7528\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "APT\u65b9\u6cd5\u88ab\u9a8c\u8bc1\u4e3a\u5728\u63d0\u9ad8\u9886\u57df\u7279\u5b9a\u80fd\u529b\u7684\u540c\u65f6\u4e0d\u5f71\u54cd\u6a21\u578b\u7684\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2506.03915", "pdf": "https://arxiv.org/pdf/2506.03915", "abs": "https://arxiv.org/abs/2506.03915", "authors": ["Sebastian R\u00f6dling", "Matej Ze\u010devi\u0107", "Devendra Singh Dhami", "Kristian Kersting"], "title": "Causal Explanations Over Time: Articulated Reasoning for Interactive Environments", "categories": ["cs.AI"], "comment": "Main paper: 9 pages, References: 2 pages, Supplementary: 9 pages.\n  Number of figures: 10, number of tables: 3", "summary": "Structural Causal Explanations (SCEs) can be used to automatically generate\nexplanations in natural language to questions about given data that are\ngrounded in a (possibly learned) causal model. Unfortunately they work for\nsmall data only. In turn they are not attractive to offer reasons for events,\ne.g., tracking causal changes over multiple time steps, or a behavioral\ncomponent that involves feedback loops through actions of an agent. To this\nend, we generalize SCEs to a (recursive) formulation of explanation trees to\ncapture the temporal interactions between reasons. We show the benefits of this\nmore general SCE algorithm on synthetic time-series data and a 2D grid game,\nand further compare it to the base SCE and other existing methods for causal\nexplanations.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u4f20\u7edf\u7684\u7ed3\u6784\u56e0\u679c\u89e3\u91ca\uff08SCEs\uff09\u7b97\u6cd5\uff0c\u901a\u8fc7\u9012\u5f52\u89e3\u91ca\u6811\u5904\u7406\u590d\u6742\u65f6\u95f4\u5e8f\u5217\u548c\u52a8\u6001\u53cd\u9988\u5faa\u73af\uff0c\u63d0\u9ad8\u4e86\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u6807\u51c6\u7684\u7ed3\u6784\u56e0\u679c\u89e3\u91ca\uff08SCEs\uff09\u4ec5\u9002\u7528\u4e8e\u5c0f\u6570\u636e\u96c6\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u6d89\u53ca\u65f6\u95f4\u6b65\u957f\u53d8\u5316\u6216\u884c\u4e3a\u53cd\u9988\u5faa\u73af\u7684\u590d\u6742\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u8be5\u7814\u7a76\u5c06\u4e00\u822c\u5316\u7684\u7ed3\u6784\u56e0\u679c\u89e3\u91ca\uff08SCEs\uff09\u6269\u5c55\u4e3a\u9012\u5f52\u89e3\u91ca\u6811\uff0c\u4ee5\u6355\u6349\u56e0\u679c\u4e4b\u95f4\u7684\u65f6\u95f4\u4ea4\u4e92\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u4e00\u4e2a\u4e8c\u7ef4\u7f51\u683c\u6e38\u620f\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u8f83\u4f20\u7edfSCE\u548c\u5176\u4ed6\u73b0\u6709\u56e0\u679c\u89e3\u91ca\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6269\u5c55\u7ed3\u6784\u56e0\u679c\u89e3\u91ca\uff08SCEs\uff09\u4e3a\u9012\u5f52\u89e3\u91ca\u6811\uff0c\u4ece\u800c\u4f7f\u5176\u80fd\u591f\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u52a8\u6001\u53cd\u9988\u5faa\u73af\uff0c\u8fd9\u514b\u670d\u4e86\u4f20\u7edfSCEs\u4ec5\u9002\u7528\u4e8e\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u7684\u9650\u5236\u3002"}}
{"id": "2506.03227", "pdf": "https://arxiv.org/pdf/2506.03227", "abs": "https://arxiv.org/abs/2506.03227", "authors": ["Abdelrahman Sayed Sayed", "Pierre-Jean Meyer", "Mohamed Ghazel"], "title": "Bridging Neural ODE and ResNet: A Formal Error Bound for Safety Verification", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 5 figures, Accepted for publication in the proceedings of\n  the 8th International Symposium on AI Verification SAIV 2025", "summary": "A neural ordinary differential equation (neural ODE) is a machine learning\nmodel that is commonly described as a continuous depth generalization of a\nresidual network (ResNet) with a single residual block, or conversely, the\nResNet can be seen as the Euler discretization of the neural ODE. These two\nmodels are therefore strongly related in a way that the behaviors of either\nmodel are considered to be an approximation of the behaviors of the other. In\nthis work, we establish a more formal relationship between these two models by\nbounding the approximation error between two such related models. The obtained\nerror bound then allows us to use one of the models as a verification proxy for\nthe other, without running the verification tools twice: if the reachable\noutput set expanded by the error bound satisfies a safety property on one of\nthe models, this safety property is then guaranteed to be also satisfied on the\nother model. This feature is fully reversible, and the initial safety\nverification can be run indifferently on either of the two models. This novel\napproach is illustrated on a numerical example of a fixed-point attractor\nsystem modeled as a neural ODE.", "AI": {"tldr": "\u7814\u7a76\u754c\u5b9a\u795e\u7ecfODE\u548cResNet\u4e4b\u95f4\u7684\u903c\u8fd1\u8bef\u5dee\uff0c\u901a\u8fc7\u8be5\u8bef\u5dee\u5b9e\u73b0\u6a21\u578b\u95f4\u7684\u4e92\u4e3a\u9a8c\u8bc1\u7279\u6027\u3002", "motivation": "\u795e\u7ecfODE\u548cResNet\u4e4b\u95f4\u867d\u7136\u5173\u7cfb\u7d27\u5bc6\uff0c\u4f46\u5c1a\u9700\u4e00\u79cd\u66f4\u6b63\u5f0f\u7684\u65b9\u6cd5\u6765\u786e\u5b9a\u5b83\u4eec\u4e4b\u95f4\u7684\u903c\u8fd1\u8bef\u5dee\uff0c\u4ee5\u4fbf\u5229\u7528\u5176\u4e92\u4e3a\u9a8c\u8bc1\u7684\u7279\u6027\u3002", "method": "\u5728\u795e\u7ecfODE\u4e0e\u6b8b\u5dee\u7f51\u7edc\u4e2d\u8fdb\u884c\u903c\u8fd1\u8bef\u5dee\u754c\u5b9a\uff0c\u5e76\u5229\u7528\u6b64\u8bef\u5dee\u754c\u9650\u8fdb\u884c\u6a21\u578b\u9a8c\u8bc1\u3002", "result": "\u5f53\u8bef\u5dee\u754c\u9650\u6269\u5c55\u7cfb\u7edf\u6ee1\u8db3\u5176\u4e2d\u4e00\u4e2a\u6a21\u578b\u7684\u5b89\u5168\u6027\u5c5e\u6027\u65f6\uff0c\u8be5\u5c5e\u6027\u5728\u53e6\u4e00\u4e2a\u6a21\u578b\u4e2d\u540c\u6837\u5f97\u5230\u4fdd\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u754c\u5b9a\u795e\u7ecfODE\u548c\u6b8b\u5dee\u7f51\u7edc\u4e4b\u95f4\u7684\u903c\u8fd1\u8bef\u5dee\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a\u6a21\u578b\u7684\u9a8c\u8bc1\u7ed3\u679c\u6765\u63a8\u65ad\u53e6\u4e00\u4e2a\u6a21\u578b\u7684\u5b89\u5168\u6027\u5c5e\u6027\u3002"}}
{"id": "2506.03484", "pdf": "https://arxiv.org/pdf/2506.03484", "abs": "https://arxiv.org/abs/2506.03484", "authors": ["Melkamu Abay Mersha", "Mesay Gemeda Yigezu", "Atnafu Lambebo Tonja", "Hassan Shakil", "Samer Iskander", "Olga Kolesnikova", "Jugal Kalita"], "title": "Explainable AI: XAI-Guided Context-Aware Data Augmentation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Explainable AI (XAI) has emerged as a powerful tool for improving the\nperformance of AI models, going beyond providing model transparency and\ninterpretability. The scarcity of labeled data remains a fundamental challenge\nin developing robust and generalizable AI models, particularly for low-resource\nlanguages. Conventional data augmentation techniques introduce noise, cause\nsemantic drift, disrupt contextual coherence, lack control, and lead to\noverfitting. To address these challenges, we propose XAI-Guided Context-Aware\nData Augmentation. This novel framework leverages XAI techniques to modify less\ncritical features while selectively preserving most task-relevant features. Our\napproach integrates an iterative feedback loop, which refines augmented data\nover multiple augmentation cycles based on explainability-driven insights and\nthe model performance gain. Our experimental results demonstrate that XAI-SR-BT\nand XAI-PR-BT improve the accuracy of models on hate speech and sentiment\nanalysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using\nthe Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform\nexisting augmentation techniques by 4.8% and 5%, respectively, on the same\ndataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform\nboth baseline and conventional augmentation techniques across all tasks and\nmodels. This study provides a more controlled, interpretable, and context-aware\nsolution to data augmentation, addressing critical limitations of existing\naugmentation techniques and offering a new paradigm shift for leveraging XAI\ntechniques to enhance AI model training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdXAI\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86AI\u6a21\u578b\u5728\u4ec7\u6068\u8a00\u8bba\u548c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u6807\u8bb0\u6570\u636e\u7a00\u7f3a\u6027\u548c\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u6280\u672f\u5e26\u6765\u7684\u566a\u58f0\u3001\u8bed\u4e49\u6f02\u79fb\u3001\u4e0a\u4e0b\u6587\u8fde\u8d2f\u6027\u7834\u574f\u3001\u7f3a\u4e4f\u63a7\u5236\u548c\u8fc7\u62df\u5408\u95ee\u9898\u3002", "method": "\u63d0\u51faXAI\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u5229\u7528XAI\u6280\u672f\u4fee\u6539\u4e0d\u592a\u91cd\u8981\u7684\u7279\u5f81\uff0c\u540c\u65f6\u9009\u62e9\u6027\u5730\u4fdd\u7559\u5927\u591a\u6570\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u5305\u62ec\u4e00\u4e2a\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\uff0c\u901a\u8fc7\u57fa\u4e8e\u53ef\u89e3\u91ca\u6027\u9a71\u52a8\u7684\u89c1\u89e3\u548c\u6a21\u578b\u6027\u80fd\u589e\u76ca\u6765\u7ec6\u5316\u589e\u5f3a\u6570\u636e\u3002", "result": "XAI-SR-BT\u548cXAI-PR-BT\u5728\u4ec7\u6068\u8a00\u8bba\u548c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u6bd4\u57fa\u7ebf\u589e\u52a0\u4e866.6%\u548c8.1%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e2d\u4e00\u8d2f\u8d85\u8fc7\u57fa\u7ebf\u548c\u4f20\u7edf\u589e\u5f3a\u6280\u672f\u3002", "conclusion": "XAI-SR-BT\u548cXAI-PR-BT\u5728\u4ec7\u6068\u8a00\u8bba\u548c\u60c5\u611f\u5206\u6790\u4efb\u52a1\u4e0a\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u5206\u522b\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u9ad8\u4e866.6%\u548c8.1%\uff0c\u540c\u65f6\u5728Amharic\u6570\u636e\u96c6\u4e0a\u4e5f\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u589e\u5f3a\u6280\u672f\u3002"}}
{"id": "2506.03939", "pdf": "https://arxiv.org/pdf/2506.03939", "abs": "https://arxiv.org/abs/2506.03939", "authors": ["Junqi Gao", "Xiang Zou", "YIng Ai", "Dong Li", "Yichen Niu", "Biqing Qi", "Jianxing Liu"], "title": "Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "Accepted by ACL 2025", "summary": "Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external\nknowledge integration capabilities by explicitly modeling knowledge\nrelationships, thereby improving the factual accuracy and generation quality of\nLarge Language Models (LLMs) in specialized domains. However, existing methods\nsuffer from two inherent limitations: 1) Inefficient Information Aggregation:\nThey rely on a single agent and fixed iterative patterns, making it difficult\nto adaptively capture multi-level textual, structural, and degree information\nwithin graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning\nschemes, which cannot dynamically adjust reasoning depth nor achieve precise\nsemantic correction. To overcome these limitations, we propose Graph Counselor,\nan GraphRAG method based on multi-agent collaboration. This method uses the\nAdaptive Graph Information Extraction Module (AGIEM), where Planning, Thought,\nand Execution Agents work together to precisely model complex graph structures\nand dynamically adjust information extraction strategies, addressing the\nchallenges of multi-level dependency modeling and adaptive reasoning depth.\nAdditionally, the Self-Reflection with Multiple Perspectives (SR) module\nimproves the accuracy and semantic consistency of reasoning results through\nself-reflection and backward reasoning mechanisms. Experiments demonstrate that\nGraph Counselor outperforms existing methods in multiple graph reasoning tasks,\nexhibiting higher reasoning accuracy and generalization ability. Our code is\navailable at https://github.com/gjq100/Graph-Counselor.git.", "AI": {"tldr": "Graph Counselor, a multi-agent GraphRAG method, enhances reasoning accuracy and generalization by overcoming limitations in information aggregation and reasoning in graph data.", "motivation": "Existing GraphRAG methods face inefficiencies in information aggregation and lack flexible reasoning mechanisms, limiting their ability to adaptively process and correct information within graph data.", "method": "The authors propose Graph Counselor, an advanced GraphRAG method utilizing multi-agent collaboration, including Planning, Thought, and Execution Agents, along with AGIEM and SR modules for adaptive extraction and reasoning.", "result": "Experiments show that Graph Counselor surpasses existing techniques in multiple graph reasoning tasks.", "conclusion": "Graph Counselor improves reasoning accuracy and generalization ability in graph reasoning tasks."}}
{"id": "2506.03230", "pdf": "https://arxiv.org/pdf/2506.03230", "abs": "https://arxiv.org/abs/2506.03230", "authors": ["Selcuk Gurses", "Aozhong Zhang", "Yanxia Deng", "Xun Dong", "Xin Li", "Naigang Wang", "Penghang Yin", "Zi Yang"], "title": "DiaBlo: Diagonal Blocks Are Sufficient For Finetuning", "categories": ["cs.LG", "cs.AI", "cs.CL", "math.OC"], "comment": null, "summary": "Finetuning is a critical step for adapting large language models (LLMs) to\ndomain-specific downstream tasks. To mitigate the substantial computational and\nmemory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT)\nmethods have been proposed to update only a small subset of model parameters.\nHowever, performance gaps between PEFT approaches and full-model fine-tuning\nstill exist. In this work, we present DiaBlo, a simple yet effective PEFT\napproach that updates only the diagonal blocks of selected model weight\nmatrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates\nthe need for low rank matrix products, thereby avoiding the reliance on\nauxiliary initialization schemes or customized optimization strategies to\nimprove convergence. This design leads to stable and robust convergence while\nmaintaining comparable memory efficiency and training speed to LoRA. We conduct\nextensive experiments across a range of tasks, including commonsense reasoning,\narithmetic reasoning, code generation, and safety alignment, to evaluate the\neffectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo\ndemonstrates strong and consistent performance while maintaining high memory\nefficiency and fast finetuning speed. Codes are available at\nhttps://github.com/ziyangjoy/DiaBlo.", "AI": {"tldr": "DiaBlo\u662f\u4e00\u79cd\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u77e9\u9635\u5bf9\u89d2\u5757\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u65e0\u9700\u5b9a\u5236\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u4e3a\u4e86\u51cf\u8f7b\u5168\u6a21\u578b\u5fae\u8c03\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\uff0c\u540c\u65f6\u7f29\u5c0f\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\u4e0e\u5168\u6a21\u578b\u5fae\u8c03\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "method": "DiaBlo\u66f4\u65b0\u4e86\u6a21\u578b\u6743\u91cd\u77e9\u9635\u7684\u5bf9\u89d2\u5757\uff0c\u4ece\u800c\u907f\u514d\u4f9d\u8d56\u8f85\u52a9\u521d\u59cb\u5316\u65b9\u6848\u6216\u5b9a\u5236\u4f18\u5316\u7b56\u7565\uff0c\u5177\u6709\u7a33\u5b9a\u548c\u9c81\u68d2\u7684\u6536\u655b\u6027\u3002", "result": "\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u4efb\u52a1\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u6765\u8bc4\u4f30DiaBlo\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u7ed3\u679c\u8868\u660eDiaBlo\u8868\u73b0\u5f3a\u52b2\u4e14\u4e00\u81f4\u3002", "conclusion": "DiaBlo\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u51fa\u8272\u4e14\u6301\u7eed\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5185\u5b58\u6548\u7387\u548c\u5feb\u901f\u5fae\u8c03\u901f\u5ea6\u3002"}}
{"id": "2506.03489", "pdf": "https://arxiv.org/pdf/2506.03489", "abs": "https://arxiv.org/abs/2506.03489", "authors": ["Mingxu Tao", "Jie Hu", "Mingchuan Yang", "Yunhuai Liu", "Dongyan Zhao", "Yansong Feng"], "title": "EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "The remarkable performance of Large language models (LLMs) relies heavily on\nthe availability of abundant high-quality training data. However, the high cost\nof acquiring annotated data often prevents models from obtaining capabilities\nto tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe\nthat boosts model performance in data-scarcity scenarios without extra\ntraining. We first employ model extrapolation to enhance a finetuned model with\nits inferior version, and then adopt contrastive decoding to further reduce\npredicted errors, by comparing the logit scores given by the extrapolated and\nthe vanilla finetuned model. Experiments across three tasks over four different\nLLMs show that EpiCoDe consistently outperforms existing methods with\nsignificant and robust improvement. We also propose a new theoretical framework\nto reveal the mechanism behind contrastive decoding in data-scarcity scenarios,\nwhich further helps us better understand the effectiveness of EpiCoDe.", "AI": {"tldr": "EpiCoDe\u5728\u6570\u636e\u4e0d\u8db3\u60c5\u51b5\u4e0b\u63d0\u9ad8LLMs\u6027\u80fd\uff0c\u4e0d\u9700\u8981\u989d\u5916\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u89e3\u91ca\u5176\u673a\u5236\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5353\u8d8a\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u53ef\u7528\u6027\u3002\u7136\u800c\uff0c\u83b7\u53d6\u6807\u6ce8\u6570\u636e\u7684\u9ad8\u6210\u672c\u963b\u788d\u4e86\u6a21\u578b\u5e94\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5EpiCoDe\uff0c\u901a\u8fc7\u6a21\u578b\u5916\u63a8\u589e\u5f3a\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u5bf9\u6bd4\u89e3\u7801\uff0c\u901a\u8fc7\u6bd4\u8f83\u5916\u63a8\u6a21\u578b\u548c\u666e\u901a\u5fae\u8c03\u6a21\u578b\u7684logit\u5206\u6570\u6765\u964d\u4f4e\u9884\u6d4b\u9519\u8bef\u3002", "result": "EpiCoDe\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e2d\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5728\u4e09\u4e2a\u4efb\u52a1\u548c\u56db\u4e2a\u4e0d\u540cLLMs\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\u4e86\u663e\u8457\u548c\u7a33\u5b9a\u7684\u6539\u8fdb\u3002", "conclusion": "EpiCoDe\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u7406\u8bba\u6846\u67b6\u63ed\u793a\u4e86\u5bf9\u6bd4\u89e3\u7801\u7684\u673a\u5236\u3002"}}
{"id": "2506.03997", "pdf": "https://arxiv.org/pdf/2506.03997", "abs": "https://arxiv.org/abs/2506.03997", "authors": ["Mario Alviano", "Laura Giordano", "Daniele Theseider Dupr\u00e9"], "title": "A framework for Conditional Reasoning in Answer Set Programming", "categories": ["cs.AI", "cs.LO", "I.2.4"], "comment": "19 pages", "summary": "In this paper we introduce a Conditional Answer Set Programming framework\n(Conditional ASP) for the definition of conditional extensions of Answer Set\nProgramming (ASP). The approach builds on a conditional logic with typicality,\nand on the combination of a conditional knowledge base with an ASP program, and\nallows for conditional reasoning over the answer sets of the program. The\nformalism relies on a multi-preferential semantics (and on the KLM preferential\nsemantics, as a special case) to provide an interpretation of conditionals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6761\u4ef6\u7b54\u6848\u96c6\u7f16\u7a0b\u6846\u67b6\uff0c\u5229\u7528\u6761\u4ef6\u903b\u8f91\u548cASP\u7ed3\u5408\u8fdb\u884c\u6761\u4ef6\u63a8\u7406\uff0c\u5e76\u91c7\u7528\u591a\u504f\u597d\u8bed\u4e49\u6765\u89e3\u91ca\u6761\u4ef6\u3002", "motivation": "\u5f15\u5165\u6761\u4ef6\u7b54\u6848\u96c6\u7f16\u7a0b\u6846\u67b6\uff0c\u65e8\u5728\u589e\u5f3a\u7b54\u6848\u96c6\u7f16\u7a0b\u5904\u7406\u6761\u4ef6\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u5177\u6709\u5178\u578b\u6027\u7684\u6761\u4ef6\u903b\u8f91\u548c\u6761\u4ef6\u77e5\u8bc6\u5e93\u4e0eASP\u7a0b\u5e8f\u7684\u7ec4\u5408\uff0c\u5141\u8bb8\u5bf9\u7a0b\u5e8f\u7684\u7b54\u6848\u96c6\u8fdb\u884c\u6761\u4ef6\u63a8\u7406\u3002", "result": "\u8be5\u6846\u67b6\u4f9d\u8d56\u4e8e\u591a\u504f\u597d\u8bed\u4e49\u548cKLM\u504f\u597d\u8bed\u4e49\uff08\u4f5c\u4e3a\u7279\u4f8b\uff09\uff0c\u4e3a\u6761\u4ef6\u63d0\u4f9b\u89e3\u91ca\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6761\u4ef6\u7b54\u6848\u96c6\u7f16\u7a0b\uff08Conditional ASP\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u5b9a\u4e49\u7b54\u6848\u96c6\u7f16\u7a0b\uff08ASP\uff09\u7684\u6761\u4ef6\u6269\u5c55\u3002"}}
{"id": "2506.03234", "pdf": "https://arxiv.org/pdf/2506.03234", "abs": "https://arxiv.org/abs/2506.03234", "authors": ["Kaiwen Duan", "Hongwei Yao", "Yufei Chen", "Ziyun Li", "Tong Qiao", "Zhan Qin", "Cong Wang"], "title": "BadReward: Clean-Label Poisoning of Reward Models in Text-to-Image RLHF", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is crucial for aligning\ntext-to-image (T2I) models with human preferences. However, RLHF's feedback\nmechanism also opens new pathways for adversaries. This paper demonstrates the\nfeasibility of hijacking T2I models by poisoning a small fraction of preference\ndata with natural-appearing examples. Specifically, we propose BadReward, a\nstealthy clean-label poisoning attack targeting the reward model in multi-modal\nRLHF. BadReward operates by inducing feature collisions between visually\ncontradicted preference data instances, thereby corrupting the reward model and\nindirectly compromising the T2I model's integrity. Unlike existing alignment\npoisoning techniques focused on single (text) modality, BadReward is\nindependent of the preference annotation process, enhancing its stealth and\npractical threat. Extensive experiments on popular T2I models show that\nBadReward can consistently guide the generation towards improper outputs, such\nas biased or violent imagery, for targeted concepts. Our findings underscore\nthe amplified threat landscape for RLHF in multi-modal systems, highlighting\nthe urgent need for robust defenses. Disclaimer. This paper contains uncensored\ntoxic content that might be offensive or disturbing to the readers.", "AI": {"tldr": "\u63d0\u51faBadReward\u6295\u6bd2\u653b\u51fb\uff0c\u7834\u574f\u591a\u6a21\u6001RLHF\u4e2d\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u53ef\u4ee5\u5f15\u53d1T2I\u6a21\u578b\u751f\u6210\u4e0d\u5f53\u56fe\u50cf\uff0c\u547c\u5401\u52a0\u5f3a\u7cfb\u7edf\u9632\u5fa1\u3002", "motivation": "\u7814\u7a76\u8868\u660eRLHF\u4e2d\u7684\u53cd\u9988\u673a\u5236\u53ef\u80fd\u88ab\u5bf9\u624b\u5229\u7528\uff0c\u56e0\u6b64\u63a2\u8ba8\u901a\u8fc7\u5c11\u91cf\u504f\u597d\u6570\u636e\u8fdb\u884c\u6295\u6bd2\u7684\u65b9\u6cd5\u6765\u653b\u51fbT2I\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aBadReward\u7684\u9690\u79d8\u7684\u3001\u5e72\u51c0\u6807\u7b7e\u7684\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u89c6\u89c9\u77db\u76fe\u7684\u504f\u597d\u6570\u636e\u5b9e\u4f8b\u4e4b\u95f4\u5f15\u53d1\u7279\u5f81\u78b0\u649e\u6765\u7834\u574f\u5956\u52b1\u6a21\u578b\uff0c\u4ece\u800c\u95f4\u63a5\u7834\u574fT2I\u6a21\u578b\u7684\u5b8c\u6574\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBadReward\u80fd\u591f\u5728T2I\u6a21\u578b\u4e0a\u6301\u7eed\u5f15\u5bfc\u751f\u6210\u4e0d\u5f53\u7684\u8f93\u51fa\uff0c\u4f8b\u5982\u6709\u504f\u6216\u66b4\u529b\u7684\u56fe\u50cf\u3002", "conclusion": "\u591a\u6a21\u6001RLHF\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u9690\u60a3\u662f\u653e\u5927\u7684\uff0c\u9700\u8981\u7d27\u6025\u7684\u3001\u5f3a\u6709\u529b\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2506.03490", "pdf": "https://arxiv.org/pdf/2506.03490", "abs": "https://arxiv.org/abs/2506.03490", "authors": ["Shigeng Chen", "Linhao Luo", "Zhangchi Qiu", "Yanan Cao", "Carl Yang", "Shirui Pan"], "title": "Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing", "categories": ["cs.CL"], "comment": null, "summary": "Recently, knowledge editing (KE) has emerged as a promising approach to\nupdate specific facts in Large Language Models (LLMs) without the need for full\nretraining. Despite the effectiveness in general-domain benchmarks, their\napplicability to complex medical domain remains largely unexplored. Medical\nknowledge editing is particularly challenging, as it requires LLMs to\ninternalize the knowledge and generalize to unseen scenarios for effective and\ninterpretable decision-making. In this work, we propose a novel framework\ncalled MedEditBench to rigorously evaluate the effectiveness of existing KE\nmethods in the medical domain. In MedEditBench, we introduce a new medical\nknowledge editing benchmark as well as three different knowledge editing\nparadigms, which are designed to assess the impact of different knowledge\nsources for editing. Our findings indicate that current KE methods result in\nonly superficial memorization of the injected information, failing to\ngeneralize to new scenarios. To overcome this limitation, we present\nSelf-Generated Rationale Editing (SGR-Edit), which utilizes model-derived\nrationales as the target knowledge for editing, thereby uncovering the\nunderlying reasoning process and demonstrating significant improvements over\nexisting KE approaches. Additionally, we offer deeper insights into medical\nknowledge editing, including the localization of medical knowledge in LLMs and\nthe impact of sequential editing on evolving knowledge. This could provide\npractical guidance for implementing KE methods in real-world medical\napplications.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u7528\u4e8e\u533b\u5b66\u77e5\u8bc6\u7f16\u8f91\u7684\u65b0\u6846\u67b6MedEditBench\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u81ea\u751f\u6210\u7406\u7531\u7f16\u8f91\uff08SGR-Edit\uff09\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u679c\u3002", "motivation": "\u6269\u5927\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u5728\u590d\u6742\u533b\u5b66\u9886\u57df\u7684\u5e94\u7528\uff0c\u4ee5\u652f\u6301\u6709\u6548\u548c\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u540d\u4e3aMedEditBench\u7684\u65b0\u6846\u67b6\uff0c\u8bc4\u4f30\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u533b\u5b66\u9886\u57df\u7684\u6709\u6548\u6027\u3002", "result": "\u63d0\u51fa\u7684SGR-Edit\u65b9\u6cd5\u5c55\u793a\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u80fd\u591f\u63ed\u793a\u80cc\u540e\u7684\u63a8\u7406\u8fc7\u7a0b\u5e76\u63d0\u9ad8\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u679c\u3002", "conclusion": "\u5f53\u524d\u7684\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u53ea\u662f\u5728LLMs\u4e2d\u8fdb\u884c\u8868\u9762\u8bb0\u5fc6\uff0c\u800c\u672a\u80fd\u63a8\u5e7f\u5230\u65b0\u7684\u573a\u666f\u3002"}}
{"id": "2506.04018", "pdf": "https://arxiv.org/pdf/2506.04018", "abs": "https://arxiv.org/abs/2506.04018", "authors": ["Akshat Naik", "Patrick Quinn", "Guillermo Bosch", "Emma Goun\u00e9", "Francisco Javier Campos Zabala", "Jason Ross Brown", "Edward James Young"], "title": "AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG", "I.2.7; I.2.11; K.4.1; I.2.6"], "comment": "Prepint, under review for NeurIPS 2025", "summary": "As Large Language Model (LLM) agents become more widespread, associated\nmisalignment risks increase. Prior work has examined agents' ability to enact\nmisaligned behaviour (misalignment capability) and their compliance with\nharmful instructions (misuse propensity). However, the likelihood of agents\nattempting misaligned behaviours in real-world settings (misalignment\npropensity) remains poorly understood. We introduce a misalignment propensity\nbenchmark, AgentMisalignment, consisting of a suite of realistic scenarios in\nwhich LLM agents have the opportunity to display misaligned behaviour. We\norganise our evaluations into subcategories of misaligned behaviours, including\ngoal-guarding, resisting shutdown, sandbagging, and power-seeking. We report\nthe performance of frontier models on our benchmark, observing higher\nmisalignment on average when evaluating more capable models. Finally, we\nsystematically vary agent personalities through different system prompts. We\nfind that persona characteristics can dramatically and unpredictably influence\nmisalignment tendencies -- occasionally far more than the choice of model\nitself -- highlighting the importance of careful system prompt engineering for\ndeployed AI agents. Our work highlights the failure of current alignment\nmethods to generalise to LLM agents, and underscores the need for further\npropensity evaluations as autonomous systems become more prevalent.", "AI": {"tldr": "\u7814\u7a76\u5f15\u5165AgentMisalignment\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u4ee3\u7406\u7684\u4e0d\u5bf9\u9f50\u503e\u5411\uff0c\u53d1\u73b0\u5bf9\u9f50\u65b9\u6cd5\u672a\u80fd\u666e\u904d\u9002\u7528\uff0c\u4e2a\u6027\u7279\u5f81\u5f71\u54cd\u91cd\u5927\uff0c\u9700\u52a0\u5f3a\u7cfb\u7edf\u63d0\u793a\u5de5\u7a0b\u3002", "motivation": "\u968f\u7740LLM\u4ee3\u7406\u7684\u666e\u53ca\uff0c\u5173\u8054\u7684\u4e0d\u5bf9\u9f50\u98ce\u9669\u589e\u52a0\uff0c\u800c\u73b0\u6709\u7814\u7a76\u5bf9\u4ee3\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u8bbe\u7f6e\u4e2d\u5c1d\u8bd5\u4e0d\u5bf9\u9f50\u884c\u4e3a\u7684\u53ef\u80fd\u6027\u4e86\u89e3\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e86AgentMisalignment\u503e\u5411\u6027\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e0d\u540c\u5b50\u7c7b\u522b\u7684\u4e0d\u5bf9\u9f50\u884c\u4e3a\uff0c\u5e76\u7cfb\u7edf\u5730\u901a\u8fc7\u4e0d\u540c\u7684\u7cfb\u7edf\u63d0\u793a\u6539\u53d8\u4ee3\u7406\u4e2a\u6027\u4ee5\u7814\u7a76\u5176\u5f71\u54cd\u3002", "result": "\u5728AgentMisalignment\u57fa\u51c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u89c2\u5bdf\u5230\u66f4\u5f3a\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u4e0d\u5bf9\u9f50\u6027\uff0c\u5e76\u53d1\u73b0\u4e2a\u6027\u7279\u5f81\u5bf9\u4e0d\u5bf9\u9f50\u503e\u5411\u7684\u5f71\u54cd\u663e\u8457\u4e14\u4e0d\u53ef\u9884\u6d4b\uff0c\u6709\u65f6\u751a\u81f3\u8d85\u8fc7\u6a21\u578b\u9009\u62e9\u672c\u8eab\u7684\u5f71\u54cd\u3002", "conclusion": "\u73b0\u6709\u7684\u5bf9\u9f50\u65b9\u6cd5\u672a\u80fd\u9002\u7528\u4e8eLLM\u4ee3\u7406\uff0c\u5f3a\u8c03\u5bf9\u90e8\u7f72\u4e2d\u7684AI\u4ee3\u7406\u8fdb\u884c\u4ed4\u7ec6\u7684\u7cfb\u7edf\u63d0\u793a\u5de5\u7a0b\uff0c\u4ee5\u53ca\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u503e\u5411\u6027\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2506.03267", "pdf": "https://arxiv.org/pdf/2506.03267", "abs": "https://arxiv.org/abs/2506.03267", "authors": ["Shahbaz Rezaei", "Avishai Halev", "Xin Liu"], "title": "On the Necessity of Multi-Domain Explanation: An Uncertainty Principle Approach for Deep Time Series Models", "categories": ["cs.LG", "cs.HC"], "comment": null, "summary": "A prevailing approach to explain time series models is to generate\nattribution in time domain. A recent development in time series XAI is the\nconcept of explanation spaces, where any model trained in the time domain can\nbe interpreted with any existing XAI method in alternative domains, such as\nfrequency. The prevailing approach is to present XAI attributions either in the\ntime domain or in the domain where the attribution is most sparse. In this\npaper, we demonstrate that in certain cases, XAI methods can generate\nattributions that highlight fundamentally different features in the time and\nfrequency domains that are not direct counterparts of one another. This\nsuggests that both domains' attributions should be presented to achieve a more\ncomprehensive interpretation. Thus it shows the necessity of multi-domain\nexplanation. To quantify when such cases arise, we introduce the uncertainty\nprinciple (UP), originally developed in quantum mechanics and later studied in\nharmonic analysis and signal processing, to the XAI literature. This principle\nestablishes a lower bound on how much a signal can be simultaneously localized\nin both the time and frequency domains. By leveraging this concept, we assess\nwhether attributions in the time and frequency domains violate this bound,\nindicating that they emphasize distinct features. In other words, UP provides a\nsufficient condition that the time and frequency domain explanations do not\nmatch and, hence, should be both presented to the end user. We validate the\neffectiveness of this approach across various deep learning models, XAI\nmethods, and a wide range of classification and forecasting datasets. The\nfrequent occurrence of UP violations across various datasets and XAI methods\nhighlights the limitations of existing approaches that focus solely on\ntime-domain explanations. This underscores the need for multi-domain\nexplanations as a new paradigm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u539f\u7406\uff0c\u63ed\u793a\u4e86\u65f6\u95f4\u57df\u4e0e\u9891\u7387\u57df\u89e3\u91ca\u7684\u5dee\u5f02\uff0c\u5e76\u9a8c\u8bc1\u4e86\u591a\u57df\u89e3\u91ca\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u73b0\u6709XAI\u65b9\u6cd5\u4ec5\u5728\u5355\u4e00\u57df\u8fdb\u884c\u89e3\u91ca\uff0c\u53ef\u80fd\u5ffd\u7565\u4e86\u4e0d\u540c\u57df\u4e4b\u95f4\u7684\u663e\u8457\u7279\u5f81\uff0c\u9700\u8981\u591a\u57df\u89e3\u91ca\u6765\u5f25\u8865\u8fd9\u79cd\u4e0d\u8db3\u3002", "method": "\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u539f\u7406\uff08UP\uff09\u6765\u91cf\u5316\u65f6\u95f4\u4e0e\u9891\u7387\u57df\u5f52\u56e0\u4e0d\u5339\u914d\u7684\u60c5\u51b5\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548cXAI\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548cXAI\u65b9\u6cd5\u4e2d\u7ecf\u5e38\u51fa\u73b0\u4e0d\u786e\u5b9a\u6027\u539f\u7406\u8fdd\u53cd\u60c5\u51b5\uff0c\u51f8\u663e\u4e86\u5355\u4e00\u65f6\u95f4\u57df\u89e3\u91ca\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u5e76\u652f\u6301\u591a\u57df\u89e3\u91ca\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u9700\u8981\u5c06\u65f6\u95f4\u57df\u548c\u9891\u7387\u57df\u7684\u5f52\u56e0\u540c\u65f6\u5448\u73b0\uff0c\u4ee5\u4fbf\u66f4\u5168\u9762\u5730\u89e3\u91ca\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u3002"}}
{"id": "2506.03501", "pdf": "https://arxiv.org/pdf/2506.03501", "abs": "https://arxiv.org/abs/2506.03501", "authors": ["Yuchen Guo", "Zhicheng Dou", "Huy H. Nguyen", "Ching-Chun Chang", "Saku Sugawara", "Isao Echizen"], "title": "Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing", "categories": ["cs.CL", "cs.AI"], "comment": "IJCNN2025 accepted", "summary": "Content creation has dramatically progressed with the rapid advancement of\nlarge language models like ChatGPT and Claude. While this progress has greatly\nenhanced various aspects of life and work, it has also negatively affected\ncertain areas of society. A recent survey revealed that nearly 30% of college\nstudents use generative AI to help write academic papers and reports. Most\ncountermeasures treat the detection of AI-generated text as a binary\nclassification task and thus lack robustness. This approach overlooks human\ninvolvement in the generation of content even though human-machine\ncollaboration is becoming mainstream. Besides generating entire texts, people\nmay use machines to complete or revise texts. Such human involvement varies\ncase by case, which makes binary classification a less than satisfactory\napproach. We refer to this situation as participation detection obfuscation. We\npropose using BERTScore as a metric to measure human involvement in the\ngeneration process and a multi-task RoBERTa-based regressor trained on a token\nclassification task to address this problem. To evaluate the effectiveness of\nthis approach, we simulated academic-based scenarios and created a continuous\ndataset reflecting various levels of human involvement. All of the existing\ndetectors we examined failed to detect the level of human involvement on this\ndataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor\nmean squared error of 0.004). Moreover, it demonstrated some generalizability\nacross generative models. Our code is available at\nhttps://github.com/gyc-nii/CAS-CS-and-dual-head-detector", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7BERTScore\u548c\u57fa\u4e8eRoBERTa\u7684\u56de\u5f52\u6a21\u578b\u6765\u68c0\u6d4b\u751f\u6210\u5185\u5bb9\u4e2d\u4eba\u5de5\u53c2\u4e0e\u7684\u65b9\u6cd5\uff0c\u80fd\u51c6\u786e\u5ea6\u91cf\u53c2\u4e0e\u7a0b\u5ea6\u4e14\u5177\u6709\u901a\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4e8c\u5206\u7c7b\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u8bc6\u522b\u751f\u6210\u5185\u5bb9\u4e2d\u4eba\u7c7b\u4e0e\u673a\u5668\u7684\u5408\u4f5c\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4e3a\u7cbe\u7ec6\u5316\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u548c\u91cf\u5316\u4eba\u5de5\u53c2\u4e0e\u7a0b\u5ea6\u3002", "method": "\u4f7f\u7528BERTScore\u4f5c\u4e3a\u8861\u91cf\u4eba\u7c7b\u53c2\u4e0e\u7a0b\u5ea6\u7684\u6307\u6807\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8eRoBERTa\u7684\u591a\u4efb\u52a1\u56de\u5f52\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u8be5\u6a21\u578b\u5728\u4e00\u4e2a\u6a21\u62df\u7684\u5b66\u672f\u573a\u666f\u4e2d\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u7684\u5b66\u672f\u573a\u666f\u4e2d\uff0cF1\u5206\u6570\u8fbe\u52300.9423\uff0c\u56de\u5f52\u5668\u5747\u65b9\u8bef\u5dee\u4e3a0.004\uff0c\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5c55\u793a\u4e86\u8de8\u751f\u6210\u6a21\u578b\u7684\u4e00\u5b9a\u901a\u7528\u6027\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u68c0\u6d4b\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u4eba\u5de5\u53c2\u4e0e\u7a0b\u5ea6\uff0c\u4f7f\u7528BERTScore\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\uff0c\u5e76\u5229\u7528\u4e00\u79cd\u57fa\u4e8eRoBERTa\u7684\u591a\u4efb\u52a1\u56de\u5f52\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u4eba\u5de5\u53c2\u4e0e\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6548\u679c\uff0c\u5e76\u5177\u6709\u4e00\u5b9a\u7684\u901a\u7528\u6027\u3002"}}
{"id": "2506.04022", "pdf": "https://arxiv.org/pdf/2506.04022", "abs": "https://arxiv.org/abs/2506.04022", "authors": ["Qiyue Xia", "J. Michael Herrmann"], "title": "Interpretability by Design for Efficient Multi-Objective Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Multi-objective reinforcement learning (MORL) aims at optimising several,\noften conflicting goals in order to improve flexibility and reliability of RL\nin practical tasks. This can be achieved by finding diverse policies that are\noptimal for some objective preferences and non-dominated by optimal policies\nfor other preferences so that they form a Pareto front in the multi-objective\nperformance space. The relation between the multi-objective performance space\nand the parameter space that represents the policies is generally non-unique.\nUsing a training scheme that is based on a locally linear map between the\nparameter space and the performance space, we show that an approximate Pareto\nfront can provide an interpretation of the current parameter vectors in terms\nof the objectives which enables an effective search within contiguous solution\ndomains. Experiments are conducted with and without retraining across different\ndomains, and the comparison with previous methods demonstrates the efficiency\nof our approach.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027\u6620\u5c04\u8bad\u7ec3\u65b9\u6848\u6765\u83b7\u5f97\u591a\u76ee\u6807\u4f18\u5316\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63d0\u9ad8\u4e86\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u7387\u4e0e\u7075\u6d3b\u6027\u3002", "motivation": "\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff08MORL\uff09\u65e8\u5728\u4f18\u5316\u591a\u4e2a\uff08\u901a\u5e38\u662f\u77db\u76fe\u7684\uff09\u76ee\u6807\uff0c\u4ee5\u63d0\u9ad8RL\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u53c2\u6570\u7a7a\u95f4\u548c\u6027\u80fd\u7a7a\u95f4\u4e4b\u95f4\u5c40\u90e8\u7ebf\u6027\u6620\u5c04\u7684\u8bad\u7ec3\u65b9\u6848\uff0c\u627e\u5230\u76ee\u6807\u504f\u597d\u6700\u4f18\u4e14\u5bf9\u5176\u4ed6\u504f\u597d\u975e\u652f\u914d\u7684\u591a\u6837\u5316\u7b56\u7565\uff0c\u5f62\u6210\u591a\u76ee\u6807\u6027\u80fd\u7a7a\u95f4\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u3002", "result": "\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u8fdb\u884c\u6709\u65e0\u518d\u8bad\u7ec3\u7684\u5b9e\u9a8c\uff0c\u4e0e\u4ee5\u524d\u7684\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\u6211\u4eec\u7684\u65b9\u6cd5\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "MORL\u53ef\u4ee5\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u8fd1\u4f3c\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\u6765\u89e3\u8bfb\u5f53\u524d\u53c2\u6570\u5411\u91cf\uff0c\u4ece\u800c\u5728\u76f8\u90bb\u89e3\u57df\u5185\u5b9e\u73b0\u6709\u6548\u641c\u7d22\u3002"}}
{"id": "2506.03302", "pdf": "https://arxiv.org/pdf/2506.03302", "abs": "https://arxiv.org/abs/2506.03302", "authors": ["James Bagrow", "Josh Bongard"], "title": "Multi-Exit Kolmogorov-Arnold Networks: enhancing accuracy and parsimony", "categories": ["cs.LG", "cs.NE", "physics.data-an", "stat.ML"], "comment": "14 pages, 7 figures, 2 tables", "summary": "Kolmogorov-Arnold Networks (KANs) uniquely combine high accuracy with\ninterpretability, making them valuable for scientific modeling. However, it is\nunclear a priori how deep a network needs to be for any given task, and deeper\nKANs can be difficult to optimize. Here we introduce multi-exit KANs, where\neach layer includes its own prediction branch, enabling the network to make\naccurate predictions at multiple depths simultaneously. This architecture\nprovides deep supervision that improves training while discovering the right\nlevel of model complexity for each task. Multi-exit KANs consistently\noutperform standard, single-exit versions on synthetic functions, dynamical\nsystems, and real-world datasets. Remarkably, the best predictions often come\nfrom earlier, simpler exits, revealing that these networks naturally identify\nsmaller, more parsimonious and interpretable models without sacrificing\naccuracy. To automate this discovery, we develop a differentiable \"learning to\nexit\" algorithm that balances contributions from exits during training. Our\napproach offers scientists a practical way to achieve both high performance and\ninterpretability, addressing a fundamental challenge in machine learning for\nscientific discovery.", "AI": {"tldr": "\u591a\u51fa\u53e3 KANs \u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u81ea\u52a8\u9009\u62e9\u5408\u9002\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u7b97\u6cd5\u5728\u8bad\u7ec3\u4e2d\u5e73\u8861\u4e0d\u540c\u51fa\u53e3\u7684\u8d21\u732e\u3002", "motivation": "\u4e3a\u4e86\u7ed3\u5408\u9ad8\u7cbe\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u89e3\u51b3\u6807\u51c6 KANs \u4e2d\u6df1\u5ea6\u7f51\u7edc\u7684\u4f18\u5316\u56f0\u96be\u53ca\u5efa\u7acb\u7f51\u7edc\u6240\u9700\u6df1\u5ea6\u4e0d\u660e\u786e\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u591a\u51fa\u53e3 KANs \u67b6\u6784\uff0c\u5728\u7f51\u7edc\u7684\u6bcf\u4e00\u5c42\u90fd\u5305\u542b\u4e00\u4e2a\u9884\u6d4b\u5206\u652f\uff0c\u5141\u8bb8\u5728\u591a\u4e2a\u6df1\u5ea6\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\u3002\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u5fae\u5206\u7684'\u5b66\u4e60\u9000\u51fa'\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u8bad\u7ec3\u671f\u95f4\u5e73\u8861\u4ece\u51fa\u53e3\u5c42\u7684\u8d21\u732e\u3002", "result": "\u591a\u51fa\u53e3 KANs \u80fd\u81ea\u52a8\u8bc6\u522b\u51fa\u66f4\u5c0f\u548c\u66f4\u6613\u89e3\u91ca\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u4e14\u6df1\u5ea6\u76d1\u7763\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u679c\u3002", "conclusion": "\u591a\u51fa\u53e3\u7684Kolmogorov-Arnold Networks (KANs)\u5728\u5408\u6210\u51fd\u6570\u3001\u52a8\u6001\u7cfb\u7edf\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u7684\u5355\u51fa\u53e3\u7248\u672c\uff0c\u5e76\u4e14\u6700\u597d\u7684\u9884\u6d4b\u5f80\u5f80\u6765\u81ea\u4e8e\u8f83\u65e9\u53ca\u66f4\u7b80\u5355\u7684\u51fa\u53e3\u5c42\u3002"}}
{"id": "2506.03510", "pdf": "https://arxiv.org/pdf/2506.03510", "abs": "https://arxiv.org/abs/2506.03510", "authors": ["Seungcheol Park", "Sojin Lee", "Jongjin Kim", "Jinsik Lee", "Hyunjik Jo", "U Kang"], "title": "Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information", "categories": ["cs.CL", "68T50", "I.2.7"], "comment": "IJCAI 2025 Main Track", "summary": "How can we accelerate large language models(LLMs) without sacrificing\naccuracy? The slow inference speed of LLMs hinders us to benefit from their\nremarkable performance in diverse applications. This is mainly because numerous\nsublayers are stacked together in LLMs. Sublayer pruning compresses and\nexpedites LLMs via removing unnecessary sublayers. However, existing sublayer\npruning algorithms are limited in accuracy since they naively select sublayers\nto prune, overlooking the different characteristics of each sublayer. In this\npaper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability\nInformation), an accurate sublayer pruning method for LLMs. SPRINT accurately\nselects a target sublayer to prune by considering 1) the amount of latency\nreduction after pruning and 2) the tunability of sublayers. SPRINT iteratively\nprunes redundant sublayers and swiftly tunes the parameters of remaining\nsublayers. Experiments show that SPRINT achieves the best accuracy-speedup\ntrade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense\nreasoning benchmarks compared to existing pruning algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPRINT\u7684\u5b50\u5c42\u526a\u679d\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u60c5\u51b5\u4e0b\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5b50\u5c42\u526a\u679d\u65b9\u6cd5SPRINT\uff0c\u901a\u8fc7\u8003\u8651\u526a\u679d\u540e\u5ef6\u8fdf\u51cf\u5c11\u91cf\u548c\u5b50\u5c42\u8c03\u8282\u80fd\u529b\u6765\u9009\u62e9\u76ee\u6807\u5b50\u5c42\u8fdb\u884c\u526a\u679d\u3002", "result": "SPRINT\u5728\u96f6\u6837\u672c\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u6bd4\u73b0\u6709\u526a\u679d\u7b97\u6cd5\u9ad8\u8fbe23.88%\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u51c6\u786e\u6027-\u901f\u5ea6\u6743\u8861\u3002", "conclusion": "SPRINT\u662f\u4e00\u79cd\u6709\u6548\u7684LLMs\u5b50\u5c42\u526a\u679d\u65b9\u6cd5\uff0c\u80fd\u5728\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2506.04133", "pdf": "https://arxiv.org/pdf/2506.04133", "abs": "https://arxiv.org/abs/2506.04133", "authors": ["Shaina Raza", "Ranjan Sapkota", "Manoj Karkee", "Christos Emmanouilidis"], "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "Agentic AI systems, built on large language models (LLMs) and deployed in\nmulti-agent configurations, are redefining intelligent autonomy, collaboration\nand decision-making across enterprise and societal domains. This review\npresents a structured analysis of Trust, Risk, and Security Management (TRiSM)\nin the context of LLM-based agentic multi-agent systems (AMAS). We begin by\nexamining the conceptual foundations of agentic AI, its architectural\ndifferences from traditional AI agents, and the emerging system designs that\nenable scalable, tool-using autonomy. The TRiSM in the agentic AI framework is\nthen detailed through four pillars governance, explainability, ModelOps, and\nprivacy/security each contextualized for agentic LLMs. We identify unique\nthreat vectors and introduce a comprehensive risk taxonomy for the agentic AI\napplications, supported by case studies illustrating real-world\nvulnerabilities. Furthermore, the paper also surveys trust-building mechanisms,\ntransparency and oversight techniques, and state-of-the-art explainability\nstrategies in distributed LLM agent systems. Additionally, metrics for\nevaluating trust, interpretability, and human-centered performance are reviewed\nalongside open benchmarking challenges. Security and privacy are addressed\nthrough encryption, adversarial defense, and compliance with evolving AI\nregulations. The paper concludes with a roadmap for responsible agentic AI,\nproposing research directions to align emerging multi-agent systems with robust\nTRiSM principles for safe, accountable, and transparent deployment.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684agentic AI\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u3001\u98ce\u9669\u548c\u5b89\u5168\u7ba1\u7406\u8fdb\u884c\u4e86\u7ed3\u6784\u5316\u5206\u6790\uff0c\u4ecb\u7ecd\u4e86\u76f8\u5173\u6846\u67b6\u53ca\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u53d1\u5c55\u8def\u7ebf\u56fe\u53ca\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u667a\u80fd\u81ea\u4e3b\u3001\u534f\u4f5c\u548c\u51b3\u7b56\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u9996\u5148\uff0c\u5206\u6790agentic AI\u7684\u6982\u5ff5\u57fa\u7840\u53ca\u5176\u67b6\u6784\u4e0e\u4f20\u7edfAI\u4ee3\u7406\u7684\u533a\u522b\u3002\u7136\u540e\uff0c\u901a\u8fc7\u6cbb\u7406\u3001\u53ef\u89e3\u91ca\u6027\u3001ModelOps\u4ee5\u53ca\u9690\u79c1/\u5b89\u5168\u56db\u4e2a\u652f\u67f1\u8be6\u7ec6\u9610\u8ff0agentic AI\u6846\u67b6\u4e0b\u7684TRiSM\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u652f\u6301\u7684\u7efc\u5408\u98ce\u9669\u5206\u7c7b\u6cd5\u6765\u8bc6\u522b\u72ec\u7279\u7684\u5a01\u80c1\u5411\u91cf\u3002\u6700\u540e\uff0c\u8c03\u67e5\u5206\u5e03\u5f0fLLMs\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u4fe1\u4efb\u6784\u5efa\u7acb\u3001\u900f\u660e\u5ea6\u548c\u76d1\u7763\u6280\u672f\uff0c\u4ee5\u53ca\u89e3\u91ca\u6027\u7b56\u7565\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8eagentic AI\u7684\u4fe1\u4efb\u3001\u98ce\u9669\u548c\u5b89\u5168\u7ba1\u7406\u7684\u6df1\u5165\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u98ce\u9669\u5206\u7c7b\u6cd5\u4ee5\u53ca\u4fe1\u4efb\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u6027\u80fd\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u6761\u8d1f\u8d23\u4efb\u7684agentic AI\u53d1\u5c55\u8def\u7ebf\u56fe\uff0c\u5efa\u8bae\u7814\u7a76\u65b9\u5411\u4ee5\u5c06\u65b0\u5174\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u4e0e\u5f3a\u5927\u7684TRiSM\u539f\u5219\u5bf9\u9f50\uff0c\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u95ee\u8d23\u548c\u900f\u660e\u7684\u90e8\u7f72\u3002"}}
{"id": "2506.03307", "pdf": "https://arxiv.org/pdf/2506.03307", "abs": "https://arxiv.org/abs/2506.03307", "authors": ["Kristen Goebel", "William Solow", "Paola Pesantez-Cabrera", "Markus Keller", "Alan Fern"], "title": "Budgeted Online Active Learning with Expert Advice and Episodic Priors", "categories": ["cs.LG"], "comment": null, "summary": "This paper introduces a novel approach to budgeted online active learning\nfrom finite-horizon data streams with extremely limited labeling budgets. In\nagricultural applications, such streams might include daily weather data over a\ngrowing season, and labels require costly measurements of weather-dependent\nplant characteristics. Our method integrates two key sources of prior\ninformation: a collection of preexisting expert predictors and episodic\nbehavioral knowledge of the experts based on unlabeled data streams. Unlike\nprevious research on online active learning with experts, our work\nsimultaneously considers query budgets, finite horizons, and episodic\nknowledge, enabling effective learning in applications with severely limited\nlabeling capacity. We demonstrate the utility of our approach through\nexperiments on various prediction problems derived from both a realistic\nagricultural crop simulator and real-world data from multiple grape cultivars.\nThe results show that our method significantly outperforms baseline expert\npredictions, uniform query selection, and existing approaches that consider\nbudgets and limited horizons but neglect episodic knowledge, even under highly\nconstrained labeling budgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u6781\u9650\u6807\u6ce8\u9884\u7b97\u6761\u4ef6\u7684\u5728\u7ebf\u4e3b\u52a8\u5b66\u4e60\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e13\u5bb6\u9884\u6d4b\u4e0e\u60c5\u8282\u6027\u77e5\u8bc6\uff0c\u5728\u519c\u4e1a\u6570\u636e\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u519c\u4e1a\u5e94\u7528\u4e2d\uff0c\u6570\u636e\u6d41\u53ef\u80fd\u5305\u62ec\u4e00\u4e2a\u751f\u957f\u5b63\u8282\u4e2d\u7684\u6bcf\u65e5\u5929\u6c14\u6570\u636e\uff0c\u800c\u6807\u7b7e\u9700\u8981\u6602\u8d35\u7684\u4e0e\u5929\u6c14\u76f8\u5173\u7684\u690d\u7269\u7279\u6027\u6d4b\u91cf\u3002\u4e3a\u4e86\u5728\u6781\u5176\u6709\u9650\u7684\u6807\u6ce8\u9884\u7b97\u4e0b\u8fdb\u884c\u6709\u6548\u5b66\u4e60\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u6211\u4eec\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e24\u79cd\u5173\u952e\u7684\u5148\u9a8c\u4fe1\u606f\u6765\u6e90\uff1a\u4e00\u7ec4\u73b0\u6709\u4e13\u5bb6\u7684\u9884\u6d4b\u548c\u57fa\u4e8e\u65e0\u6807\u7b7e\u6570\u636e\u6d41\u7684\u4e13\u5bb6\u4e4b\u95f4\u7684\u60c5\u8282\u6027\u884c\u4e3a\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u9884\u6d4b\u95ee\u9898\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u4e00\u4e2a\u73b0\u5b9e\u7684\u519c\u4e1a\u4f5c\u7269\u6a21\u62df\u5668\u548c\u591a\u4e2a\u8461\u8404\u54c1\u79cd\u7684\u771f\u5b9e\u6570\u636e\u4e2d\u3002", "conclusion": "\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u4e13\u5bb6\u9884\u6d4b\u3001\u5747\u5300\u67e5\u8be2\u9009\u62e9\u4ee5\u53ca\u73b0\u6709\u5728\u9884\u7b97\u548c\u6709\u9650\u8303\u56f4\u5185\u7684\u5176\u4ed6\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u975e\u5e38\u6709\u9650\u7684\u6807\u6ce8\u9884\u7b97\u4e0b\u4e5f\u5982\u6b64\u3002"}}
{"id": "2506.03519", "pdf": "https://arxiv.org/pdf/2506.03519", "abs": "https://arxiv.org/abs/2506.03519", "authors": ["Yangyang Zhao", "Ben Niu", "Libo Qin", "Shihan Wang"], "title": "An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals", "categories": ["cs.CL"], "comment": null, "summary": "Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue\nsystems to optimize dialogue policy, but it struggles to balance exploration\nand exploitation due to the high dimensionality of state and action spaces.\nThis challenge often results in local optima or poor convergence. Evolutionary\nAlgorithms (EAs) have been proven to effectively explore the solution space of\nneural networks by maintaining population diversity. Inspired by this, we\ninnovatively combine the global search capabilities of EA with the local\noptimization of DRL to achieve a balance between exploration and exploitation.\nNevertheless, the inherent flexibility of natural language in dialogue tasks\ncomplicates this direct integration, leading to prolonged evolutionary times.\nThus, we further propose an elite individual injection mechanism to enhance\nEA's search efficiency by adaptively introducing best-performing individuals\ninto the population. Experiments across four datasets show that our approach\nsignificantly improves the balance between exploration and exploitation,\nboosting performance. Moreover, the effectiveness of the EII mechanism in\nreducing exploration time has been demonstrated, achieving an efficient\nintegration of EA and DRL on task-oriented dialogue policy tasks.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408EA\u548cDRL\u5e76\u5f15\u5165\u7cbe\u82f1\u4e2a\u4f53\u6ce8\u5165\u673a\u5236\uff0c\u8be5\u65b9\u6cd5\u6539\u5584\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u63a2\u7d22\u4e0e\u5f00\u53d1\u5e73\u8861\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3DRL\u5728\u9ad8\u7ef4\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u63a2\u7d22\u4e0e\u5f00\u53d1\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u7075\u6d3b\u6027\u589e\u52a0\u4e86\u76f4\u63a5\u96c6\u6210\u7684\u590d\u6742\u6027\u3002", "method": "\u521b\u65b0\u6027\u5730\u7ed3\u5408\u8fdb\u5316\u7b97\u6cd5\uff08EA\uff09\u7684\u5168\u5c40\u641c\u7d22\u80fd\u529b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u5c40\u90e8\u4f18\u5316\uff0c\u63d0\u51fa\u7cbe\u82f1\u4e2a\u4f53\u6ce8\u5165\u673a\u5236\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5c06\u8868\u73b0\u6700\u4f73\u7684\u4e2a\u4f53\u5f15\u5165\u79cd\u7fa4\u6765\u589e\u5f3a\u8fdb\u5316\u7b97\u6cd5\u7684\u641c\u7d22\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u6539\u5584\u4e86\u63a2\u7d22\u4e0e\u5f00\u53d1\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u3002\u7cbe\u82f1\u4e2a\u4f53\u6ce8\u5165\u673a\u5236\u6709\u6548\u51cf\u5c11\u4e86\u63a2\u7d22\u65f6\u95f4\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8fdb\u5316\u7b97\u6cd5\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u9762\u5411\u4efb\u52a1\u7684\u5bf9\u8bdd\u7b56\u7565\u4efb\u52a1\u4e0a\u7684\u9ad8\u6548\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u63a2\u7d22\u4e0e\u5f00\u53d1\u5e73\u8861\u3002"}}
{"id": "2506.04135", "pdf": "https://arxiv.org/pdf/2506.04135", "abs": "https://arxiv.org/abs/2506.04135", "authors": ["Pei Yang", "Hai Ci", "Mike Zheng Shou"], "title": "macOSWorld: A Multilingual Interactive Benchmark for GUI Agents", "categories": ["cs.AI"], "comment": null, "summary": "Graphical User Interface (GUI) agents show promising capabilities for\nautomating computer-use tasks and facilitating accessibility, but existing\ninteractive benchmarks are mostly English-only, covering web-use or Windows,\nLinux, and Android environments, but not macOS. macOS is a major OS with\ndistinctive GUI patterns and exclusive applications. To bridge the gaps, we\npresent macOSWorld, the first comprehensive benchmark for evaluating GUI agents\non macOS. macOSWorld features 202 multilingual interactive tasks across 30\napplications (28 macOS-exclusive), with task instructions and OS interfaces\noffered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As\nGUI agents are shown to be vulnerable to deception attacks, macOSWorld also\nincludes a dedicated safety benchmarking subset. Our evaluation on six GUI\nagents reveals a dramatic gap: proprietary computer-use agents lead at above\n30% success rate, while open-source lightweight research models lag at below\n2%, highlighting the need for macOS domain adaptation. Multilingual benchmarks\nalso expose common weaknesses, especially in Arabic, with a 27.5% average\ndegradation compared to English. Results from safety benchmarking also\nhighlight that deception attacks are more general and demand immediate\nattention. macOSWorld is available at https://github.com/showlab/macosworld.", "AI": {"tldr": "macOSWorld\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30GU\u4ee3\u7406\u5728macOS\u4e0a\u8868\u73b0\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u5728macOS\u73af\u5883\u4e2d\u7684\u9002\u914d\u4e0d\u8db3\u53ca\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u7279\u5b9a\u5f31\u70b9\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u6b3a\u9a97\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4ea4\u4e92\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u591a\u4e3a\u82f1\u8bed\u73af\u5883\uff0c\u5e76\u672a\u6db5\u76d6macOS\u8fd9\u4e00\u91cd\u8981\u64cd\u4f5c\u7cfb\u7edf\uff0c\u5bfc\u81f4\u5728GUI\u4ee3\u7406\u7684\u6027\u80fd\u8bc4\u4f30\u4e0a\u5b58\u5728\u7f3a\u9677\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5f00\u53d1\u4e86macOSWorld\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "macOSWorld\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6202\u4e2a\u591a\u8bed\u8a00\u4ea4\u4e92\u4efb\u52a1\uff0c\u6d89\u53ca30\u6b3e\u5e94\u7528\uff0828\u6b3e\u4e3amacOS\u72ec\u6709\uff09\uff0c\u540c\u65f6\u63d0\u4f9b\u4e865\u79cd\u8bed\u8a00\u7684\u4efb\u52a1\u6307\u4ee4\u548c\u64cd\u4f5c\u7cfb\u7edf\u754c\u9762\uff0c\u5e76\u5305\u542b\u5b89\u5168\u6027\u57fa\u51c6\u6d4b\u8bd5\u5b50\u96c6\u3002", "result": "\u516d\u79cdGUI\u4ee3\u7406\u7684\u8bc4\u4f30\u8868\u660e\uff1a\u4e13\u6709\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u8fbe\u5230\u8d85\u8fc730%\u7684\u6210\u529f\u7387\uff0c\u800c\u5f00\u6e90\u8f7b\u91cf\u7814\u7a76\u6a21\u578b\u4f4e\u4e8e2%\uff0c\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u5c24\u5176\u63ed\u793a\u4e86\u963f\u62c9\u4f2f\u8bed\u7684\u663e\u8457\u5f31\u70b9\u3002\u6b64\u5916\uff0c\u5b89\u5168\u6027\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u5f3a\u8c03\u4e86\u6b3a\u9a97\u653b\u51fb\u7684\u666e\u904d\u5b58\u5728\u53ca\u5176\u9700\u8981\u5373\u523b\u5173\u6ce8\u3002", "conclusion": "macOSWorld\u5c55\u793a\u4e86\u73b0\u6709GUI\u4ee3\u7406\u5728macOS\u4e0a\u7684\u9002\u914d\u6027\u4e0d\u8db3\u548c\u5bf9\u6b3a\u9a97\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5c24\u5176\u662f\u5f00\u6e90\u7814\u7a76\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u963f\u62c9\u4f2f\u8bed\u8868\u73b0\u5c24\u4e3a\u8584\u5f31\u3002"}}
{"id": "2506.03320", "pdf": "https://arxiv.org/pdf/2506.03320", "abs": "https://arxiv.org/abs/2506.03320", "authors": ["Jack Bell", "Luigi Quarantiello", "Eric Nuertey Coleman", "Lanpei Li", "Malio Li", "Mauro Madeddu", "Elia Piccoli", "Vincenzo Lomonaco"], "title": "The Future of Continual Learning in the Era of Foundation Models: Three Key Directions", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 1 figure, accepted at TCAI workshop 2025", "summary": "Continual learning--the ability to acquire, retain, and refine knowledge over\ntime--has always been fundamental to intelligence, both human and artificial.\nHistorically, different AI paradigms have acknowledged this need, albeit with\nvarying priorities: early expert and production systems focused on incremental\nknowledge consolidation, while reinforcement learning emphasised dynamic\nadaptation. With the rise of deep learning, deep continual learning has\nprimarily focused on learning robust and reusable representations over time to\nsolve sequences of increasingly complex tasks. However, the emergence of Large\nLanguage Models (LLMs) and foundation models has raised the question: Do we\nstill need continual learning when centralised, monolithic models can tackle\ndiverse tasks with access to internet-scale knowledge? We argue that continual\nlearning remains essential for three key reasons: (i) continual pre-training is\nstill necessary to ensure foundation models remain up to date, mitigating\nknowledge staleness and distribution shifts while integrating new information;\n(ii) continual fine-tuning enables models to specialise and personalise,\nadapting to domain-specific tasks, user preferences, and real-world constraints\nwithout full retraining, avoiding the need for computationally expensive long\ncontext-windows; (iii) continual compositionality offers a scalable and modular\napproach to intelligence, enabling the orchestration of foundation models and\nagents to be dynamically composed, recombined, and adapted. While continual\npre-training and fine-tuning are explored as niche research directions, we\nargue it is continual compositionality that will mark the rebirth of continual\nlearning. The future of AI will not be defined by a single static model but by\nan ecosystem of continually evolving and interacting models, making continual\nlearning more relevant than ever.", "AI": {"tldr": "\u6301\u7eed\u5b66\u4e60\u5728\u6df1\u5ea6\u5b66\u4e60\u65f6\u4ee3\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u51fa\u73b0\u540e\u4ecd\u5177\u5fc5\u4e0d\u53ef\u5c11\u7684\u4ef7\u503c\uff0c\u5f3a\u8c03\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u5fae\u8c03\u548c\u7ec4\u5408\u6027\u5c06\u63a8\u52a8AI\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7684\u5174\u8d77\uff0c\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u57fa\u7840\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u4eba\u4eec\u5f00\u59cb\u8d28\u7591\u5728\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u5229\u7528\u6d77\u91cf\u77e5\u8bc6\u5904\u7406\u591a\u6837\u4efb\u52a1\u7684\u80cc\u666f\u4e0b\uff0c\u6301\u7eed\u5b66\u4e60\u662f\u5426\u4ecd\u7136\u5fc5\u8981\u3002", "method": "\u672c\u6587\u901a\u8fc7\u63a2\u8ba8\u4e09\u4e2a\u5173\u952e\u7406\u7531\uff0c\u8bba\u8bc1\u4e86\u6301\u7eed\u5b66\u4e60\u7684\u5fc5\u8981\u6027\uff1a(i) \u6301\u7eed\u9884\u8bad\u7ec3\u4ee5\u786e\u4fdd\u57fa\u7840\u6a21\u578b\u4fdd\u6301\u66f4\u65b0\uff0c\u51cf\u8f7b\u77e5\u8bc6\u9648\u65e7\u6027\u548c\u5206\u5e03\u53d8\u5316\uff1b(ii) \u6301\u7eed\u5fae\u8c03\u4ee5\u4f7f\u6a21\u578b\u4e13\u95e8\u5316\u548c\u4e2a\u6027\u5316\uff0c\u9002\u5e94\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u3001\u7528\u6237\u504f\u597d\u548c\u73b0\u5b9e\u7ea6\u675f\uff1b(iii) \u6301\u7eed\u7ec4\u5408\u6027\u63d0\u4f9b\u667a\u80fd\u7684\u53ef\u6269\u5c55\u548c\u6a21\u5757\u5316\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u57fa\u7840\u6a21\u578b\u548c\u4ee3\u7406\u7684\u52a8\u6001\u6784\u5efa\u548c\u91cd\u7ec4\u3002", "result": "\u6307\u51fa\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u8fd9\u4e9b\u88ab\u89c6\u4e3a\u5c0f\u4f17\u7814\u7a76\u65b9\u5411\u7684\u540c\u65f6\uff0c\u6301\u7eed\u7ec4\u5408\u6027\u5c06\u6210\u4e3a\u6301\u7eed\u5b66\u4e60\u7684\u91cd\u751f\u6807\u5fd7\u3002", "conclusion": "\u672a\u6765\u7684\u4eba\u5de5\u667a\u80fd\u5c06\u4e0d\u518d\u7531\u5355\u4e00\u9759\u6001\u6a21\u578b\u5b9a\u4e49\uff0c\u800c\u662f\u7531\u4e00\u4e2a\u4e0d\u65ad\u8fdb\u5316\u548c\u4e92\u52a8\u7684\u6a21\u578b\u751f\u6001\u7cfb\u7edf\u5b9a\u4e49\uff0c\u8fd9\u4f7f\u5f97\u6301\u7eed\u5b66\u4e60\u6bd4\u4ee5\u5f80\u4efb\u4f55\u65f6\u5019\u90fd\u66f4\u4e3a\u91cd\u8981\u3002"}}
{"id": "2506.03523", "pdf": "https://arxiv.org/pdf/2506.03523", "abs": "https://arxiv.org/abs/2506.03523", "authors": ["Chong Li", "Jiajun Zhang", "Chengqing Zong"], "title": "TokAlign: Efficient Vocabulary Adaptation via Token Alignment", "categories": ["cs.CL"], "comment": "ACL 2025, our codes and models are available at\n  https://github.com/ZNLP/TokAlign", "summary": "Tokenization serves as a foundational step for Large Language Models (LLMs)\nto process text. In new domains or languages, the inefficiency of the tokenizer\nwill slow down the training and generation of LLM. The mismatch in vocabulary\nalso hinders deep knowledge transfer between LLMs like token-level\ndistillation. To mitigate this gap, we propose an efficient method named\nTokAlign to replace the vocabulary of LLM from the token co-occurrences view,\nand further transfer the token-level knowledge between models. It first aligns\nthe source vocabulary to the target one by learning a one-to-one mapping matrix\nfor token IDs. Model parameters, including embeddings, are rearranged and\nprogressively fine-tuned for the new vocabulary. Our method significantly\nimproves multilingual text compression rates and vocabulary initialization for\nLLMs, decreasing the perplexity from 3.4$\\text{e}^2$ of strong baseline methods\nto 1.2$\\text{e}^2$ after initialization. Experimental results on models across\nmultiple parameter scales demonstrate the effectiveness and generalization of\nTokAlign, which costs as few as 5k steps to restore the performance of the\nvanilla model. After unifying vocabularies between LLMs, token-level\ndistillation can remarkably boost (+4.4% than sentence-level distillation) the\nbase model, costing only 235M tokens.", "AI": {"tldr": "TokAlign\u901a\u8fc7\u4f18\u5316\u8bcd\u6c47\u6620\u5c04\u548c\u6a21\u578b\u5fae\u8c03\u6709\u6548\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u5728\u65b0\u9886\u57df\u6216\u8bed\u8a00\u4e2d\uff0c\u4f20\u7edf\u5206\u8bcd\u5668\u6548\u7387\u4f4e\u4e0b\uff0c\u5f71\u54cd\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u751f\u6210\uff0c\u5e76\u963b\u788d\u4e86\u6a21\u578b\u95f4\u7684\u6df1\u5ea6\u77e5\u8bc6\u8f6c\u79fb\uff0c\u5c24\u5176\u662f\u8bcd\u7ea7\u84b8\u998f\u3002", "method": "TokAlign\u901a\u8fc7\u5b66\u4e60\u4e00\u5bf9\u4e00\u6620\u5c04\u77e9\u9635\u6765\u5bf9\u9f50\u6e90\u8bcd\u6c47\u548c\u76ee\u6807\u8bcd\u6c47\uff0c\u8c03\u6574\u6a21\u578b\u53c2\u6570\u548c\u9010\u6b65\u5fae\u8c03\u4ee5\u9002\u5e94\u65b0\u7684\u8bcd\u6c47\u3002", "result": "\u5728\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0cTokAlign\u65b9\u6cd5\u5c55\u73b0\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4ec5\u97005k\u6b65\u5373\u53ef\u6062\u590d\u539f\u59cb\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5728\u8bcd\u6c47\u7edf\u4e00\u540e\uff0c\u8bcd\u7ea7\u84b8\u998f\u6bd4\u53e5\u7ea7\u84b8\u998f\u63d0\u5347\u4e86\u57fa\u51c6\u6a21\u578b4.4%\u7684\u6027\u80fd\u3002", "conclusion": "TokAlign\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u591a\u8bed\u8a00\u6587\u672c\u538b\u7f29\u7387\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u6c47\u521d\u59cb\u5316\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u6a21\u578b\u56f0\u60d1\u5ea6\uff0c\u5e76\u5728\u7edf\u4e00\u8bcd\u6c47\u540e\u63d0\u5347\u4e86\u57fa\u51c6\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.04210", "pdf": "https://arxiv.org/pdf/2506.04210", "abs": "https://arxiv.org/abs/2506.04210", "authors": ["Soumya Suvra Ghosal", "Souradip Chakraborty", "Avinash Reddy", "Yifu Lu", "Mengdi Wang", "Dinesh Manocha", "Furong Huang", "Mohammad Ghavamzadeh", "Amrit Singh Bedi"], "title": "Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,\nDeepSeek R1) have led to a popular belief that extending thinking traces using\nprompts like \"Wait\" or \"Let me rethink\" can improve performance. This raises a\nnatural question: Does thinking more at test-time truly lead to better\nreasoning? To answer this question, we perform a detailed empirical study\nacross models and benchmarks, which reveals a consistent pattern of initial\nperformance improvements from additional thinking followed by a decline, due to\n\"overthinking\". To understand this non-monotonic trend, we consider a simple\nprobabilistic model, which reveals that additional thinking increases output\nvariance-creating an illusion of improved reasoning while ultimately\nundermining precision. Thus, observed gains from \"more thinking\" are not true\nindicators of improved reasoning, but artifacts stemming from the connection\nbetween model uncertainty and evaluation metric. This suggests that test-time\nscaling through extended thinking is not an effective way to utilize the\ninference thinking budget. Recognizing these limitations, we introduce an\nalternative test-time scaling approach, parallel thinking, inspired by\nBest-of-N sampling. Our method generates multiple independent reasoning paths\nwithin the same inference budget and selects the most consistent response via\nmajority vote, achieving up to 20% higher accuracy compared to extended\nthinking. This provides a simple yet effective mechanism for test-time scaling\nof reasoning models.", "AI": {"tldr": "\u66f4\u591a\u601d\u8003\u5728\u6d4b\u8bd5\u65f6\u5e76\u975e\u603b\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u63d0\u51fa\u5e76\u884c\u601d\u8003\u4ee5\u63d0\u9ad8\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u601d\u8003\u75d5\u8ff9\u4f1a\u5f71\u54cd\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u201c\u662f\u5426\u66f4\u591a\u601d\u8003\u4f1a\u5e26\u6765\u66f4\u597d\u7684\u63a8\u7406\uff1f\u201d\u8fd9\u4e00\u95ee\u9898\u4ecd\u5b58\u7591\u3002", "method": "\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5e76\u91c7\u7528\u7b80\u5355\u7684\u6982\u7387\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002", "result": "\u989d\u5916\u7684\u601d\u8003\u521d\u671f\u4f1a\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u4f1a\u56e0\u8fc7\u5ea6\u601d\u8003\u5bfc\u81f4\u4e0b\u964d\uff0c\u63d0\u51fa\u4e86\u5e76\u884c\u601d\u8003\u7684\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "conclusion": "\u66f4\u591a\u7684\u601d\u8003\u5e76\u4e0d\u662f\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u7684\u771f\u6b63\u6307\u793a\uff0c\u800c\u662f\u7531\u4e8e\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0e\u8bc4\u4f30\u6307\u6807\u7684\u5173\u8054\u4ea7\u751f\u7684\u5047\u8c61\u3002"}}
{"id": "2506.03324", "pdf": "https://arxiv.org/pdf/2506.03324", "abs": "https://arxiv.org/abs/2506.03324", "authors": ["Ethan Che", "Hakan Ceylan", "James McInerney", "Nathan Kallus"], "title": "Optimization of Epsilon-Greedy Exploration", "categories": ["cs.LG"], "comment": null, "summary": "Modern recommendation systems rely on exploration to learn user preferences\nfor new items, typically implementing uniform exploration policies (e.g.,\nepsilon-greedy) due to their simplicity and compatibility with machine learning\n(ML) personalization models. Within these systems, a crucial consideration is\nthe rate of exploration - what fraction of user traffic should receive random\nitem recommendations and how this should evolve over time. While various\nheuristics exist for navigating the resulting exploration-exploitation\ntradeoff, selecting optimal exploration rates is complicated by practical\nconstraints including batched updates, time-varying user traffic, short time\nhorizons, and minimum exploration requirements. In this work, we propose a\nprincipled framework for determining the exploration schedule based on directly\nminimizing Bayesian regret through stochastic gradient descent (SGD), allowing\nfor dynamic exploration rate adjustment via Model-Predictive Control (MPC).\nThrough extensive experiments with recommendation datasets, we demonstrate that\nvariations in the batch size across periods significantly influence the optimal\nexploration strategy. Our optimization methods automatically calibrate\nexploration to the specific problem setting, consistently matching or\noutperforming the best heuristic for each setting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u63a2\u7d22\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6700\u5c0f\u5316\u8d1d\u53f6\u65af\u9057\u61be\u548cMPC\u8fdb\u884c\u52a8\u6001\u8c03\u6574\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22-\u5229\u7528\u6743\u8861\u662f\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u95ee\u9898\u4e4b\u4e00\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u7b56\u7565\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\u5b58\u5728\u9650\u5236\uff08\u5982\u6279\u91cf\u66f4\u65b0\uff0c\u7528\u6237\u6d41\u91cf\u53d8\u5316\u7b49\uff09\uff0c\u9700\u8981\u66f4\u4f18\u5316\u7684\u63a2\u7d22\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6700\u5c0f\u5316\u8d1d\u53f6\u65af\u9057\u61be\uff0c\u7528\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u8fdb\u884c\u52a8\u6001\u63a2\u7d22\u7387\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u65f6\u95f4\u6bb5\uff0c\u6279\u5904\u7406\u5927\u5c0f\u7684\u53d8\u52a8\u663e\u8457\u5f71\u54cd\u6700\u4f73\u63a2\u7d22\u7b56\u7565\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e0d\u540c\u95ee\u9898\u8bbe\u7f6e\u4e0b\u5339\u914d\u6216\u8d85\u8fc7\u6700\u4f73\u542f\u53d1\u5f0f\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u76f4\u63a5\u6700\u5c0f\u5316\u8d1d\u53f6\u65af\u9057\u61be\u7684\u539f\u5219\u6027\u7684\u63a2\u7d22\u65f6\u95f4\u8868\u6846\u67b6\uff0c\u5e76\u5229\u7528MPC\u8fdb\u884c\u52a8\u6001\u8c03\u6574\u3002\u7ecf\u8fc7\u4f18\u5316\u540e\uff0c\u53ef\u4ee5\u81ea\u52a8\u6821\u51c6\u63a2\u7d22\u7b56\u7565\u4ee5\u9002\u5e94\u5177\u4f53\u95ee\u9898\u8bbe\u7f6e\uff0c\u6027\u80fd\u4e0a\u6bd4\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u66f4\u52a0\u4f18\u8d8a\u3002"}}
{"id": "2506.03524", "pdf": "https://arxiv.org/pdf/2506.03524", "abs": "https://arxiv.org/abs/2506.03524", "authors": ["Yuyu Zhang", "Jing Su", "Yifan Sun", "Chenguang Xi", "Xia Xiao", "Shen Zheng", "Anxiang Zhang", "Kaibo Liu", "Daoguang Zan", "Tao Sun", "Jinhua Zhu", "Shulin Xin", "Dong Huang", "Yetao Bai", "Lixin Dong", "Chao Li", "Jianchong Chen", "Hanzhi Zhou", "Yifan Huang", "Guanghan Ning", "Xierui Song", "Jiaze Chen", "Siyao Liu", "Kai Shen", "Liang Xiang", "Yonghui Wu"], "title": "Seed-Coder: Let the Code Model Curate Data for Itself", "categories": ["cs.CL", "cs.SE"], "comment": null, "summary": "Code data in large language model (LLM) pretraining is recognized crucial not\nonly for code-related tasks but also for enhancing general intelligence of\nLLMs. Current open-source LLMs often heavily rely on human effort to produce\ntheir code pretraining data, such as employing hand-crafted filtering rules\ntailored to individual programming languages, or using human-annotated data to\ntrain quality filters. However, these approaches are inherently limited in\nscalability, prone to subjective biases, and costly to extend and maintain\nacross diverse programming languages. To address these challenges, we introduce\nSeed-Coder, a series of open-source LLMs comprising base, instruct and\nreasoning models of 8B size, minimizing human involvement in data construction.\nOur code pretraining data is produced by a model-centric data pipeline, which\npredominantly leverages LLMs for scoring and filtering code data. The instruct\nmodel is further trained via supervised fine-tuning and preference\noptimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT)\nreinforcement learning to improve multi-step code reasoning. Seed-Coder\nachieves state-of-the-art results among open-source models of similar size and\neven surpasses some much larger models, demonstrating superior performance in\ncode generation, code completion, code editing, code reasoning, and software\nengineering tasks.", "AI": {"tldr": "Seed-Coder\u662f\u4e00\u79cd\u5f00\u6e90LLM\uff0c\u5229\u7528LLM\u8fdb\u884c\u4ee3\u7801\u6570\u636e\u8bc4\u5206\u4e0e\u7b5b\u9009\uff0c\u51cf\u5c11\u4e86\u5bf9\u4eba\u5de5\u7684\u4f9d\u8d56\uff0c\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u8d85\u8fc7\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u6e90LLM\u5728\u4ee3\u7801\u9884\u8bad\u7ec3\u6570\u636e\u7684\u751f\u6210\u4e0a\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u4eba\u5de5\uff0c\u5b58\u6709\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\u3001\u4e3b\u89c2\u504f\u89c1\u7b49\u5f0a\u7aef\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u51cf\u5c11\u4eba\u4e3a\u53c2\u4e0e\uff0c\u80fd\u591f\u6269\u5c55\u5230\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u65b9\u6cd5\u3002", "method": "Seed-Coder \u4f7f\u7528\u4e86\u6a21\u578b\u4e2d\u5fc3\u7684\u6570\u636e\u7ba1\u9053\uff0c\u901a\u8fc7 LLM \u5bf9\u4ee3\u7801\u6570\u636e\u8fdb\u884c\u8bc4\u5206\u548c\u7b5b\u9009\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u7684\u53c2\u4e0e\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\u8fdb\u884c\u6307\u4ee4\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u540c\u65f6\u5e94\u7528 LongCoT \u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u591a\u6b65\u9aa4\u4ee3\u7801\u63a8\u7406\u3002", "result": "Seed-Coder\u5728\u76f8\u4f3c\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u6700\u65b0\u7684\u6210\u679c\uff0c\u751a\u81f3\u8d85\u8d8a\u4e86\u4e00\u4e9b\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\uff0c\u5728\u4ee3\u7801\u751f\u6210\u3001\u5b8c\u6210\u3001\u7f16\u8f91\u3001\u63a8\u7406\u53ca\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u6027\u80fd\u4f18\u5f02\u3002", "conclusion": "Seed-Coder\u5728\u5f00\u6e90LLM\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0d\u4ec5\u5728\u4e0e\u4ee3\u7801\u76f8\u5173\u7684\u4efb\u52a1\u4e2d\uff0c\u800c\u4e14\u5728\u4e00\u822c\u667a\u80fd\u63d0\u5347\u65b9\u9762\u90fd\u6709\u663e\u8457\u6548\u679c\u3002"}}
{"id": "2209.01205", "pdf": "https://arxiv.org/pdf/2209.01205", "abs": "https://arxiv.org/abs/2209.01205", "authors": ["Han Wu", "Jie Yin", "Bala Rajaratnam", "Jianyuan Guo"], "title": "Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion", "categories": ["cs.LG", "cs.AI", "cs.CV", "I.2"], "comment": "Published at ICLR 2023", "summary": "Knowledge graphs (KGs) are powerful in terms of their inference abilities,\nbut are also notorious for their incompleteness and long-tail distribution of\nrelations. To address these challenges and expand the coverage of KGs, few-shot\nKG completion aims to make predictions for triplets involving novel relations\nwhen only a few training triplets are provided as reference. Previous methods\nhave focused on designing local neighbor aggregators to learn entity-level\ninformation and/or imposing a potentially invalid sequential dependency\nassumption at the triplet level to learn meta relation information. However,\npairwise triplet-level interactions and context-level relational information\nhave been largely overlooked for learning meta representations of few-shot\nrelations. In this paper, we propose a hierarchical relational learning method\n(HiRe) for few-shot KG completion. By jointly capturing three levels of\nrelational information (entity-level, triplet-level and context-level), HiRe\ncan effectively learn and refine meta representations of few-shot relations,\nand thus generalize well to new unseen relations. Extensive experiments on\nbenchmark datasets validate the superiority of HiRe over state-of-the-art\nmethods. The code can be found in https://github.com/alexhw15/HiRe.git.", "AI": {"tldr": "\u9488\u5bf9\u77e5\u8bc6\u56fe\u8c31\u7684\u5c11\u6837\u672c\u8865\u5168\u95ee\u9898\uff0c\u63d0\u51fa\u4e86HiRe\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5b66\u4e60\u5143\u8868\u793a\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u7531\u4e8e\u4e0d\u5b8c\u6574\u6027\u548c\u5173\u7cfb\u7684\u957f\u5c3e\u5206\u5e03\u5bfc\u81f4\u5176\u8986\u76d6\u8303\u56f4\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5c42\u6b21\u5316\u5173\u7cfb\u5b66\u4e60\u65b9\u6cd5\uff08HiRe\uff09\uff0c\u901a\u8fc7\u8054\u5408\u6355\u6349\u5b9e\u4f53\u7ea7\u3001\u4e09\u5143\u7ec4\u7ea7\u548c\u4e0a\u4e0b\u6587\u7ea7\u522b\u7684\u5173\u7cfb\u4fe1\u606f\u6765\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u4e0e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\uff0cHiRe\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u66f4\u4f18\u3002", "conclusion": "HiRe\u80fd\u6709\u6548\u5b66\u4e60\u548c\u4f18\u5316\u5c11\u6837\u672c\u5173\u7cfb\u7684\u5143\u8868\u793a\uff0c\u5e76\u80fd\u591f\u5f88\u597d\u5730\u63a8\u5e7f\u5230\u65b0\u7684\u672a\u89c1\u5173\u7cfb\u3002"}}
{"id": "2506.03333", "pdf": "https://arxiv.org/pdf/2506.03333", "abs": "https://arxiv.org/abs/2506.03333", "authors": ["Juan Sebastian Rojas", "Chi-Guhn Lee"], "title": "A Differential Perspective on Distributional Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "To date, distributional reinforcement learning (distributional RL) methods\nhave exclusively focused on the discounted setting, where an agent aims to\noptimize a potentially-discounted sum of rewards over time. In this work, we\nextend distributional RL to the average-reward setting, where an agent aims to\noptimize the reward received per time-step. In particular, we utilize a\nquantile-based approach to develop the first set of algorithms that can\nsuccessfully learn and/or optimize the long-run per-step reward distribution,\nas well as the differential return distribution of an average-reward MDP. We\nderive proven-convergent tabular algorithms for both prediction and control, as\nwell as a broader family of algorithms that have appealing scaling properties.\nEmpirically, we find that these algorithms consistently yield competitive\nperformance when compared to their non-distributional equivalents, while also\ncapturing rich information about the long-run reward and return distributions.", "AI": {"tldr": "\u6269\u5c55\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u5230\u5e73\u5747\u5956\u52b1\u73af\u5883\uff0c\u63d0\u51fa\u65b0\u7b97\u6cd5\u68c0\u6d4b\u548c\u4f18\u5316\u957f\u671f\u5956\u52b1\u5206\u5e03\uff0c\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4ee5\u5f80\u7684\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u96c6\u4e2d\u5728\u6298\u6263\u8bbe\u7f6e\u4e2d\uff0c\u5ffd\u89c6\u4e86\u5e73\u5747\u5956\u52b1\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5b66\u4e60\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u52a8\u673a\u662f\u6269\u5c55\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u5230\u5e73\u5747\u5956\u52b1\u8bbe\u7f6e\uff0c\u4f18\u5316\u6bcf\u65f6\u95f4\u6b65\u7684\u5956\u52b1\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5206\u4f4d\u6570\u7684\u65b9\u6cd5\uff0c\u7814\u53d1\u4e86\u4e00\u5957\u80fd\u591f\u6210\u529f\u5b66\u4e60\u548c\u4f18\u5316\u5e73\u5747\u5956\u52b1\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u7684\u957f\u671f\u6bcf\u6b65\u5956\u52b1\u5206\u5e03\u548c\u5fae\u5206\u56de\u62a5\u5206\u5e03\u7684\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u7ee9\u6548\u4e0a\u4e0e\u975e\u5206\u5e03\u5f0f\u7b49\u6548\u7b97\u6cd5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u5177\u6709\u6355\u6349\u957f\u671f\u5956\u52b1\u548c\u56de\u62a5\u5206\u5e03\u7684\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b0\u7b97\u6cd5\u5728\u5e73\u5747\u5956\u52b1\u73af\u5883\u4e2d\u7a33\u5b9a\u6536\u655b\uff0c\u5e76\u4e14\u5728\u9884\u6d4b\u548c\u63a7\u5236\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\u3002"}}
{"id": "2506.03533", "pdf": "https://arxiv.org/pdf/2506.03533", "abs": "https://arxiv.org/abs/2506.03533", "authors": ["Apurva Gandhi", "Graham Neubig"], "title": "Go-Browse: Training Web Agents with Structured Exploration", "categories": ["cs.CL"], "comment": null, "summary": "One of the fundamental problems in digital agents is their lack of\nunderstanding of their environment. For instance, a web browsing agent may get\nlost in unfamiliar websites, uncertain what pages must be visited to achieve\nits goals. To address this, we propose Go-Browse, a method for automatically\ncollecting diverse and realistic web agent data at scale through structured\nexploration of web environments. Go-Browse achieves efficient exploration by\nframing data collection as a graph search, enabling reuse of information across\nexploration episodes. We instantiate our method on the WebArena benchmark,\ncollecting a dataset of 10K successful task-solving trajectories and 40K\ninteraction steps across 100 URLs. Fine-tuning a 7B parameter language model on\nthis dataset achieves a success rate of 21.7% on the WebArena benchmark,\nbeating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for\nsub-10B parameter models by 2.9%.", "AI": {"tldr": "\u63d0\u51faGo-Browse\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u641c\u7d22\u8fdb\u884c\u7ed3\u6784\u5316\u7f51\u7edc\u63a2\u7d22\uff0c\u63d0\u5347\u7f51\u9875\u4ee3\u7406\u5728WebArena\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "motivation": "\u89e3\u51b3\u6570\u5b57\u4ee3\u7406\u5728\u73af\u5883\u4e2d\u7f3a\u4e4f\u7406\u89e3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u7f51\u9875\u6d4f\u89c8\u4ee3\u7406\u5728\u672a\u719f\u6089\u7f51\u7ad9\u65f6\u53ef\u80fd\u8ff7\u5931\u65b9\u5411\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Go-Browse\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63a2\u7d22\u7f51\u7edc\u73af\u5883\u5b9e\u73b0\u5927\u89c4\u6a21\u81ea\u52a8\u6536\u96c6\u591a\u6837\u5316\u4e14\u771f\u5b9e\u7684\u7f51\u9875\u4ee3\u7406\u6570\u636e\u3002\u5229\u7528\u56fe\u641c\u7d22\u6765\u7ec4\u7ec7\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u8de8\u63a2\u7d22\u4e8b\u4ef6\u7684\u4fe1\u606f\u91cd\u7528\u3002", "result": "\u4f7f\u7528WebArena\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728100\u4e2aURL\u4e0a\u6536\u96c6\u4e8610K\u4e2a\u6210\u529f\u4efb\u52a1\u89e3\u51b3\u8f68\u8ff9\u548c40K\u4e2a\u4ea4\u4e92\u6b65\u9aa4\u3002\u5fae\u8c03\u4e00\u4e2a\u5177\u67097B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5728WebArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6210\u529f\u7387\u8fbe\u5230\u4e8621.7%\uff0c\u6bd4GPT-4o mini\u63d0\u9ad8\u4e862.4%\uff0c\u8d85\u8fc7\u4e86\u5f53\u524d\u6b21\u4e8e10B\u53c2\u6570\u6a21\u578b\u7684\u6700\u4f73\u7ed3\u679c2.9%\u3002", "conclusion": "Go-Browse\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u7f51\u9875\u4ee3\u7406\u7684\u4efb\u52a1\u89e3\u51b3\u6210\u529f\u7387\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u8d85\u8fc710B\u53c2\u6570\u7684\u6a21\u578b\u4e2d\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.03337", "pdf": "https://arxiv.org/pdf/2506.03337", "abs": "https://arxiv.org/abs/2506.03337", "authors": ["Yide Ran", "Wentao Guo", "Jingwei Sun", "Yanzhou Pan", "Xiaodong Yu", "Hao Wang", "Jianwen Xie", "Yiran Chen", "Denghui Zhang", "Zhaozhuo Xu"], "title": "Mitigating Non-IID Drift in Zeroth-Order Federated LLM Fine-Tuning with Transferable Sparsity", "categories": ["cs.LG", "cs.AI"], "comment": "56 pages, 11 figures", "summary": "Federated Learning enables collaborative fine-tuning of Large Language Models\n(LLMs) across decentralized Non-Independent and Identically Distributed\n(Non-IID) clients, but such models' massive parameter sizes lead to significant\nmemory and communication challenges. This work introduces Meerkat, a sparse\nzeroth-order optimization (ZO) method designed for federated LLM fine-tuning.\nBy limiting fine-tuning to a transferable, static, extremely sparse subset of\nparameters, Meerkat achieves remarkable communication efficiency, enabling\ncost-effective high-frequency synchronization. With theoretical analysis and\nexperiments, we show that this high-frequency communication effectively\nmitigates Non-IID data challenges and leads to superior performance compared to\nfull-parameter ZO. Furthermore, experiment results show that Meerkat\noutperforms existing sparsity baselines with better performance at the same\ncommunication frequency. To further handle Non-IID drift, Meerkat leverages\ntraceable local updates and forms a virtual path for each client. This virtual\npath mechanism reveals the GradIP phenomenon: the inner products between LLM\npre-training gradients maintained by server and client gradients estimated via\nZO converges for extreme Non-IID clients but oscillates for IID ones. This\ndistinct behavior provides a signal for identifying clients with extreme data\nheterogeneity. Using this signal, Meerkat-vp is proposed to analyze GradIP\ntrajectories to identify extreme Non-IID clients and applies early stopping to\nenhance aggregated model quality. Experiments confirm that Meerkat and\nMeerkat-vp significantly improve the efficiency and effectiveness of ZO\nfederated LLM fine-tuning.", "AI": {"tldr": "Meerkat\u901a\u8fc7\u7a00\u758f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u6548\u7387\uff0c\u5e76\u5f15\u5165\u673a\u5236\u8bc6\u522b\u590d\u6742\u6570\u636e\u5206\u5e03\u5ba2\u6237\u7aef\uff0c\u63d0\u5347\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u53c2\u6570\u89c4\u6a21\u5de8\u5927\uff0c\u5bfc\u81f4\u5185\u5b58\u548c\u901a\u4fe1\u65b9\u9762\u7684\u6311\u6218\u3002\u4e3a\u4e86\u63d0\u9ad8\u5fae\u8c03\u7684\u6548\u7387\uff0c\u672c\u5de5\u4f5c\u63d0\u51fa\u4e00\u79cd\u7a00\u758f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7a00\u758f\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0cMeerkat\uff0c\u901a\u8fc7\u9650\u5236\u5fae\u8c03\u5230\u6781\u7a00\u758f\u53c2\u6570\u5b50\u96c6\uff0c\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u3002\u8fd8\u5f15\u5165\u4e86\u865a\u62df\u8def\u5f84\u673a\u5236\u6765\u5904\u7406\u6570\u636e\u5206\u5e03\u7684\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6f02\u79fb\u95ee\u9898\u3002", "result": "Meerkat\u5728\u901a\u4fe1\u9891\u7387\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u73b0\u6709\u7a00\u758f\u57fa\u7ebf\u663e\u793a\u51fa\u66f4\u597d\u7684\u6027\u80fd\uff0cMeerkat-vp\u80fd\u591f\u8bc6\u522b\u6781\u7aef\u975e\u72ec\u7acb\u540c\u5206\u5e03\u5ba2\u6237\u7aef\uff0c\u5e76\u901a\u8fc7\u65e9\u505c\u673a\u5236\u63d0\u9ad8\u6a21\u578b\u8d28\u91cf\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u63d0\u5347\u6548\u7387\u548c\u6548\u679c\u7684\u80fd\u529b\u3002", "conclusion": "Meerkat\u6280\u672f\u901a\u8fc7\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u6548\u7387\u548c\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b83\u6bd4\u73b0\u6709\u7684\u7a00\u758f\u57fa\u7ebf\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u8bc6\u522b\u6570\u636e\u5f02\u8d28\u6027\u5f3a\u7684\u5ba2\u6237\u7aef\u4f18\u5316\u6a21\u578b\u8d28\u91cf\u3002"}}
{"id": "2506.03541", "pdf": "https://arxiv.org/pdf/2506.03541", "abs": "https://arxiv.org/abs/2506.03541", "authors": ["Xiaofeng Zhou", "Heyan Huang", "Lizi Liao"], "title": "Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 10 figures. The camera-ready paper for Findings of ACL 2025", "summary": "Large Language Models (LLMs) continue to set new standards in\nknowledge-intensive and complex reasoning tasks, yet their high computational\ndemands limit widespread adoption. While distilling large models into smaller\nones offers a sustainable solution, current techniques--such as static\nknowledge distillation, resource-intensive reinforcement learning from human\nfeedback, or limited self-reflection--struggle to yield substantial and lasting\nperformance gains. In this paper, we present a novel Debate and Reflect (D&R)\nframework that orchestrates multi-turn debates between smaller models and\nstronger teacher models, eliciting actionable feedback (e.g., error analysis,\ncorrective strategies) to guide student models. Further, we introduce\nTree-structured Direct Preference Optimization (T-DPO) to efficiently leverage\nthese debate logs, organizing interactions into a hierarchical format for\neffective training. Empirical evaluations across diverse NLP benchmarks\ndemonstrate that our approach significantly improves smaller-model accuracy,\nrobustness, and generalization, outperforming conventional baselines by a large\nmargin.", "AI": {"tldr": "Proposes the Debate and Reflect (D&R) framework and T-DPO technique to improve small model performance efficiently, outperforming existing methods in several NLP benchmarks.", "motivation": "The motivation is to find a sustainable way to improve the performance of smaller language models without the high computational cost associated with large models, given the limitations of current distillation techniques.", "method": "The method involves a Debate and Reflect (D&R) framework where smaller models engage in multi-turn debates with larger teacher models. This is complemented by Tree-structured Direct Preference Optimization (T-DPO) which organizes debate logs hierarchically to enhance training efficiency.", "result": "Our method significantly improves smaller-model accuracy, robustness, and generalization, surpassing existing baseline approaches in various NLP tasks.", "conclusion": "Our Debate and Reflect (D&R) framework, along with the Tree-structured Direct Preference Optimization (T-DPO) technique, significantly enhances the performance of smaller language models, outperforming standard methods in accuracy, robustness, and generalization across various NLP benchmarks."}}
{"id": "2506.03162", "pdf": "https://arxiv.org/pdf/2506.03162", "abs": "https://arxiv.org/abs/2506.03162", "authors": ["Damith Chamalke Senadeera", "Xiaoyun Yang", "Dimitrios Kollias", "Gregory Slabaugh"], "title": "Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid proliferation of surveillance cameras has increased the demand for\nautomated violence detection. While CNNs and Transformers have shown success in\nextracting spatio-temporal features, they struggle with long-term dependencies\nand computational efficiency. We propose Dual Branch VideoMamba with Gated\nClass Token Fusion (GCTF), an efficient architecture combining a dual-branch\ndesign and a state-space model (SSM) backbone where one branch captures spatial\nfeatures, while the other focuses on temporal dynamics, with continuous fusion\nvia a gating mechanism. We also present a new benchmark by merging RWF-2000,\nRLVS, and VioPeru datasets in video violence detection, ensuring strict\nseparation between training and testing sets. Our model achieves\nstate-of-the-art performance on this benchmark offering an optimal balance\nbetween accuracy and computational efficiency, demonstrating the promise of\nSSMs for scalable, real-time surveillance violence detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDual Branch VideoMamba\u7684\u9ad8\u6548\u67b6\u6784\uff0c\u80fd\u591f\u5728\u65b0\u57fa\u51c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8868\u660e\u4e86SSM\u5728\u5b9e\u65f6\u76d1\u63a7\u66b4\u529b\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u76d1\u63a7\u6444\u50cf\u5934\u7684\u5feb\u901f\u666e\u53ca\u589e\u52a0\u4e86\u5bf9\u81ea\u52a8\u66b4\u529b\u68c0\u6d4b\u7684\u9700\u6c42\u3002\u867d\u7136\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548cTransformer\u5728\u63d0\u53d6\u65f6\u7a7a\u7279\u5f81\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u5728\u5904\u7406\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5b58\u5728\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDual Branch VideoMamba\u7684\u9ad8\u6548\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u53cc\u5206\u652f\u8bbe\u8ba1\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u4e3b\u5e72\u7f51\u7edc\uff0c\u5176\u4e2d\u4e00\u4e2a\u5206\u652f\u6355\u6349\u7a7a\u95f4\u7279\u5f81\uff0c\u800c\u53e6\u4e00\u4e2a\u5206\u652f\u4e13\u6ce8\u4e8e\u65f6\u95f4\u52a8\u6001\uff0c\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u8fdb\u884c\u8fde\u7eed\u878d\u5408\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u5408\u5e76RWF-2000\u3001RLVS\u548cVioPeru\u6570\u636e\u96c6\u63d0\u51fa\u4e86\u89c6\u9891\u66b4\u529b\u68c0\u6d4b\u7684\u65b0\u57fa\u51c6\uff0c\u786e\u4fdd\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u4e4b\u95f4\u4e25\u683c\u5206\u79bb\u3002\u6211\u4eec\u7684\u6a21\u578b\u5728\u6b64\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6211\u4eec\u7684\u6a21\u578b\u5728\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u8bc1\u660e\u4e86SSM\u5728\u53ef\u6269\u5c55\u3001\u5b9e\u65f6\u76d1\u63a7\u66b4\u529b\u68c0\u6d4b\u4e2d\u7684\u524d\u666f\u3002"}}
{"id": "2506.03355", "pdf": "https://arxiv.org/pdf/2506.03355", "abs": "https://arxiv.org/abs/2506.03355", "authors": ["Elias Abad Rocamora", "Christian Schlarmann", "Naman Deep Singh", "Yongtao Wu", "Matthias Hein", "Volkan Cevher"], "title": "Robustness in Both Domains: CLIP Needs a Robust Text Encoder", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Adversarial input attacks can cause a significant shift of CLIP embeddings.\nThis can affect the downstream robustness of models incorporating CLIP in the\npipeline, such as text-to-image generative models or large vision language\nmodels. While some efforts have been done towards making the CLIP image\nencoders robust, the robustness of text encoders remains unexplored. In this\nwork, we cover this gap in the literature. We propose LEAF: an efficient\nadversarial finetuning method for the text domain, with the ability to scale to\nlarge CLIP models. Our models significantly improve the zero-shot adversarial\naccuracy in the text domain, while maintaining the vision performance provided\nby robust image encoders. When combined with text-to-image diffusion models, we\ncan improve the generation quality under adversarial noise. When employing our\nrobust CLIP encoders in multimodal retrieval tasks, we improve the recall under\nadversarial noise over standard CLIP models. Finally, we show that robust text\nencoders facilitate better reconstruction of input text from its embedding via\ndirect optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLEAF\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86CLIP\u6587\u672c\u7f16\u7801\u5668\u7684\u9c81\u68d2\u6027\uff0c\u589e\u5f3a\u4e86\u5bf9\u6297\u73af\u5883\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u96c6\u4e2d\u4e8e\u63d0\u9ad8CLIP\u56fe\u50cf\u7f16\u7801\u5668\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5bf9\u6587\u672c\u7f16\u7801\u5668\u7684\u9c81\u68d2\u6027\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLEAF\u7684\u9ad8\u6548\u5bf9\u6297\u6027\u5fae\u8c03\u65b9\u6cd5\uff0c\u7528\u4e8e\u6587\u672c\u57df\uff0c\u5e76\u4e14\u80fd\u591f\u6269\u5c55\u5230\u5927\u578bCLIP\u6a21\u578b\u3002", "result": "\u5728\u6587\u672c\u57df\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u5bf9\u6297\u6027\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9c81\u68d2\u56fe\u50cf\u7f16\u7801\u5668\u63d0\u4f9b\u7684\u89c6\u89c9\u6027\u80fd\uff1b\u5728\u591a\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e2d\u63d0\u9ad8\u4e86\u53ec\u56de\u7387\uff1b\u589e\u5f3a\u4e86\u53d7\u5bf9\u6297\u6027\u566a\u58f0\u5f71\u54cd\u4e0b\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u63d0\u9ad8\u6587\u672c\u7f16\u7801\u5668\u7684\u9c81\u68d2\u6027\uff0c\u6539\u5584\u4e86\u5d4c\u5165\u91cd\u6784\u548c\u591a\u6a21\u6001\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2506.03557", "pdf": "https://arxiv.org/pdf/2506.03557", "abs": "https://arxiv.org/abs/2506.03557", "authors": ["Lin Sun", "Chuang Liu", "Peng Liu", "Bingyang Li", "Weijia Lu", "Ning Wu"], "title": "BPO: Revisiting Preference Modeling in Direct Preference Optimization", "categories": ["cs.CL"], "comment": null, "summary": "Direct Preference Optimization (DPO) have emerged as a popular method for\naligning Large Language Models (LLMs) with human preferences. While DPO\neffectively preserves the relative ordering between chosen and rejected\nresponses through pairwise ranking losses, it often neglects absolute reward\nmagnitudes. This oversight can decrease the likelihood of chosen responses and\nincrease the risk of generating out-of-distribution responses, leading to poor\nperformance. We term this issue Degraded Chosen Responses (DCR).To address this\nissue, we propose Balanced Preference Optimization (BPO), a novel framework\nthat dynamically balances the optimization of chosen and rejected responses\nthrough two key components: balanced reward margin and gap adaptor. Unlike\nprevious methods, BPO can fundamentally resolve DPO's DCR issue, without\nintroducing additional constraints to the loss function. Experimental results\non multiple mathematical reasoning tasks show that BPO significantly\noutperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8%\nto 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses\nDPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over\nCal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a\nsingle line of code modification, making it simple to implement and fully\ncompatible with existing DPO-based frameworks.", "AI": {"tldr": "BPO\u6539\u8fdb\u4e86LLMs\u7684\u504f\u597d\u4f18\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u73b0\u6709\u6846\u67b6\u7684\u517c\u5bb9\u6027\u3002", "motivation": "\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u5ffd\u89c6\u4e86\u7edd\u5bf9\u5956\u52b1\u5e45\u5ea6\uff0c\u5bfc\u81f4\u9009\u5b9a\u54cd\u5e94\u7684\u53ef\u80fd\u6027\u964d\u4f4e\uff0c\u5e76\u589e\u52a0\u4e86\u4ea7\u751f\u5206\u5e03\u5916\u54cd\u5e94\u7684\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86BPO\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "BPO\u6846\u67b6\u901a\u8fc7\u5e73\u8861\u5956\u52b1\u8fb9\u9645\u548c\u95f4\u9699\u9002\u914d\u5668\u6765\u52a8\u6001\u4f18\u5316\u9009\u5b9a\u548c\u62d2\u7edd\u54cd\u5e94\u3002", "result": "\u5728\u591a\u9879\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cBPO\u663e\u8457\u4f18\u4e8eDPO\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "BPO\u89e3\u51b3\u4e86DPO\u7684DCR\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2506.03169", "pdf": "https://arxiv.org/pdf/2506.03169", "abs": "https://arxiv.org/abs/2506.03169", "authors": ["Arindam Chaudhuri"], "title": "Improvement of human health lifespan with hybrid group pose estimation methods", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Human beings rely heavily on estimation of poses in order to access their\nbody movements. Human pose estimation methods take advantage of computer vision\nadvances in order to track human body movements in real life applications. This\ncomes from videos which are recorded through available devices. These\npara-digms provide potential to make human movement measurement more accessible\nto users. The consumers of pose estimation movements believe that human poses\ncontent tend to supplement available videos. This has increased pose estimation\nsoftware usage to estimate human poses. In order to address this problem, we\ndevelop hybrid-ensemble-based group pose estimation method to improve human\nhealth. This proposed hybrid-ensemble-based group pose estimation method aims\nto detect multi-person poses using modified group pose estimation and modified\nreal time pose estimation. This ensemble allows fusion of performance of stated\nmethods in real time. The input poses from images are fed into individual\nmeth-ods. The pose transformation method helps to identify relevant features\nfor en-semble to perform training effectively. After this, customized\npre-trained hybrid ensemble is trained on public benchmarked datasets which is\nbeing evaluated through test datasets. The effectiveness and viability of\nproposed method is estab-lished based on comparative analysis of group pose\nestimation methods and ex-periments conducted on benchmarked datasets. It\nprovides best optimized results in real-time pose estimation. It makes pose\nestimation method more robust to oc-clusion and improves dense regression\naccuracy. These results have affirmed po-tential application of this method in\nseveral real-time situations with improvement in human health life span", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u96c6\u6210\u7684\u7fa4\u7ec4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u53ef\u589e\u5f3a\u591a\u4eba\u59ff\u6001\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\uff0c\u5c24\u5176\u662f\u5728\u906e\u6321\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u5728\u5b9e\u65f6\u573a\u666f\u4e2d\u6709\u6548\u5e94\u7528\u4e8e\u6539\u5584\u4eba\u4f53\u5065\u5eb7\u3002", "motivation": "\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u5229\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u8fdb\u6b65\u6765\u8ddf\u8e2a\u4eba\u4f53\u5728\u771f\u5b9e\u751f\u6d3b\u5e94\u7528\u4e2d\u7684\u52a8\u4f5c\uff0c\u8fd9\u6e90\u4e8e\u901a\u8fc7\u53ef\u7528\u8bbe\u5907\u5f55\u5236\u7684\u89c6\u9891\u3002\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u7684\u6d88\u8d39\u8005\u8ba4\u4e3a\u4eba\u4f53\u59ff\u6001\u5185\u5bb9\u6709\u52a9\u4e8e\u8865\u5145\u53ef\u7528\u7684\u89c6\u9891\u3002\u8fd9\u589e\u52a0\u4e86\u59ff\u6001\u4f30\u8ba1\u8f6f\u4ef6\u5bf9\u4eba\u4f53\u59ff\u6001\u7684\u4f30\u8ba1\u4f7f\u7528\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u96c6\u6210\u7684\u7fa4\u7ec4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u4ee5\u6539\u5584\u4eba\u4f53\u5065\u5eb7\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u96c6\u6210\u7684\u7fa4\u7ec4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u4eba\u4f53\u5065\u5eb7\u3002\u8fd9\u79cd\u6df7\u5408\u96c6\u6210\u7684\u7fa4\u7ec4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u65e8\u5728\u4f7f\u7528\u4fee\u6539\u540e\u7684\u7fa4\u7ec4\u59ff\u6001\u4f30\u8ba1\u548c\u4fee\u6539\u540e\u7684\u5b9e\u65f6\u59ff\u6001\u4f30\u8ba1\u68c0\u6d4b\u591a\u4eba\u59ff\u6001\u3002\u96c6\u6210\u5141\u8bb8\u878d\u5408\u6240\u8ff0\u65b9\u6cd5\u5728\u5b9e\u65f6\u4e2d\u7684\u6027\u80fd\u3002\u56fe\u50cf\u4e2d\u7684\u8f93\u5165\u59ff\u6001\u88ab\u8f93\u5165\u5230\u5404\u4e2a\u65b9\u6cd5\u4e2d\u3002\u59ff\u6001\u53d8\u6362\u65b9\u6cd5\u6709\u52a9\u4e8e\u8bc6\u522b\u76f8\u5173\u7279\u5f81\uff0c\u4ee5\u4fbf\u8fdb\u884c\u6709\u6548\u7684\u96c6\u6210\u8bad\u7ec3\u3002\u7ecf\u8fc7\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u81ea\u5b9a\u4e49\u7684\u9884\u8bad\u7ec3\u6df7\u5408\u96c6\u6210\u5728\u516c\u7528\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7\u6d4b\u8bd5\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u65f6\u59ff\u6001\u4f30\u8ba1\u4e2d\u63d0\u4f9b\u4e86\u6700\u4f73\u4f18\u5316\u7ed3\u679c\uff0c\u4f7f\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u5bf9\u906e\u6321\u66f4\u52a0\u7a33\u5065\uff0c\u5e76\u63d0\u9ad8\u4e86\u5bc6\u96c6\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u4e0e\u73b0\u6709\u7ec4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u5e76\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u59ff\u6001\u4f30\u8ba1\u7684\u6700\u4f73\u4f18\u5316\u7ed3\u679c\uff0c\u4f7f\u5f97\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u5728\u906e\u6321\u60c5\u51b5\u4e0b\u66f4\u52a0\u7a33\u5065\uff0c\u5e76\u63d0\u9ad8\u4e86\u5bc6\u96c6\u56de\u5f52\u7684\u51c6\u786e\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5b9e\u65f6\u573a\u666f\u4e2d\u5e94\u7528\u7684\u6f5c\u529b\uff0c\u6539\u5584\u4e86\u4eba\u7c7b\u5065\u5eb7\u5bff\u547d\u3002"}}
{"id": "2506.03363", "pdf": "https://arxiv.org/pdf/2506.03363", "abs": "https://arxiv.org/abs/2506.03363", "authors": ["Divya Shyamal", "Jiaqi Zhang", "Caroline Uhler"], "title": "Probabilistic Factorial Experimental Design for Combinatorial Interventions", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "A combinatorial intervention, consisting of multiple treatments applied to a\nsingle unit with potentially interactive effects, has substantial applications\nin fields such as biomedicine, engineering, and beyond. Given $p$ possible\ntreatments, conducting all possible $2^p$ combinatorial interventions can be\nlaborious and quickly becomes infeasible as $p$ increases. Here we introduce\nprobabilistic factorial experimental design, formalized from how scientists\nperform lab experiments. In this framework, the experimenter selects a dosage\nfor each possible treatment and applies it to a group of units. Each unit\nindependently receives a random combination of treatments, sampled from a\nproduct Bernoulli distribution determined by the dosages. Additionally, the\nexperimenter can carry out such experiments over multiple rounds, adapting the\ndesign in an active manner. We address the optimal experimental design problem\nwithin an intervention model that imposes bounded-degree interactions between\ntreatments. In the passive setting, we provide a closed-form solution for the\nnear-optimal design. Our results prove that a dosage of $\\tfrac{1}{2}$ for each\ntreatment is optimal up to a factor of $1+O(\\tfrac{\\ln(n)}{n})$ for estimating\nany $k$-way interaction model, regardless of $k$, and imply that\n$O\\big(kp^{3k}\\ln(p)\\big)$ observations are required to accurately estimate\nthis model. For the multi-round setting, we provide a near-optimal acquisition\nfunction that can be numerically optimized. We also explore several extensions\nof the design problem and finally validate our findings through simulations.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u6982\u7387\u56e0\u5b50\u5b9e\u9a8c\u8bbe\u8ba1\u4ee5\u7b80\u5316\u7ec4\u5408\u5e72\u9884\u7684\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u6709\u6548\u4f30\u8ba1\u6a21\u578b\u6240\u9700\u7684\u89c2\u6d4b\u503c\u6570\u91cf\u3002", "motivation": "\u7ec4\u5408\u5e72\u9884\u80fd\u591f\u5728\u751f\u7269\u533b\u5b66\u3001\u5de5\u7a0b\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002\u7136\u800c\uff0c\u968f\u7740\u53ef\u80fd\u5904\u7406\u6570p\u7684\u589e\u52a0\uff0c\u8fdb\u884c\u6240\u6709\u53ef\u80fd\u7684\u7ec4\u5408\u5e72\u9884\u53d8\u5f97\u7e41\u7410\u4e14\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u65b9\u5f0f\u6765\u5904\u7406\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u56e0\u5b50\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5728\u8be5\u6846\u67b6\u4e2d\u5b9e\u9a8c\u8bbe\u8ba1\u8005\u9009\u62e9\u6bcf\u79cd\u53ef\u80fd\u5904\u7406\u7684\u5242\u91cf\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u4e00\u7ec4\u5355\u5143\u3002\u6bcf\u4e2a\u5355\u5143\u72ec\u7acb\u63a5\u6536\u968f\u673a\u7684\u6cbb\u7597\u7ec4\u5408\uff0c\u4ece\u7531\u5242\u91cf\u51b3\u5b9a\u7684\u4e58\u79ef\u4f2f\u52aa\u5229\u5206\u5e03\u4e2d\u91c7\u6837\u3002", "result": "\u5728\u88ab\u52a8\u8bbe\u7f6e\u4e2d\uff0c\u63d0\u4f9b\u4e86\u8fd1\u4f3c\u6700\u4f73\u8bbe\u8ba1\u7684\u95ed\u5f0f\u89e3\uff0c\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4f30\u8ba1\u4efb\u4f55k\u8def\u4ea4\u4e92\u6a21\u578b\u800c\u8a00\uff0c\u6bcf\u79cd\u6cbb\u7597\u5242\u91cf1/2\u662f\u6700\u4f73\u7684\uff0c\u5e76\u4e14\u9700\u8981O(kp^{3k}ln(p))\u4e2a\u89c2\u6d4b\u503c\u3002\u6b64\u5916\uff0c\u591a\u8f6e\u8bbe\u7f6e\u4e2d\u7684\u8fd1\u4f3c\u6700\u4f73\u91c7\u96c6\u51fd\u6570\u53ef\u4ee5\u901a\u8fc7\u6570\u503c\u4f18\u5316\u5f97\u5230\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u7ec4\u5408\u5e72\u9884\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u5176\u53d1\u73b0\u3002"}}
{"id": "2506.03558", "pdf": "https://arxiv.org/pdf/2506.03558", "abs": "https://arxiv.org/abs/2506.03558", "authors": ["Jiawei Chen", "Xinyan Guan", "Qianhao Yuan", "Guozhao Mo", "Weixiang Zhou", "Yaojie Lu", "Hongyu Lin", "Ben He", "Le Sun", "Xianpei Han"], "title": "ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch", "categories": ["cs.CL"], "comment": null, "summary": "Current instruction data synthesis methods primarily focus on single-turn\ninstructions and often neglect cross-turn coherence, resulting in context drift\nand reduced task completion rates in extended conversations. To address this\nlimitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a\nframework that constrains multi-turn instruction synthesis by explicitly\nmodeling human conversational intent. It operates in two stages: (1) Intent\nModeling, which captures the global structure of human dialogues by assigning\neach conversation to one of nine well-defined intent trajectories, ensuring a\ncoherent and goal-oriented information flow; and (2) Skeleton Generation, which\nconstructs a structurally grounded sequence of user queries aligned with the\nmodeled intent, thereby serving as a scaffold that constrains and guides the\ndownstream instruction synthesis process. Based on this process, we construct\nConsistentChat, a multi-turn instruction dataset with approximately 15,000\nmulti-turn conversations and 224,392 utterances. Experiments on the Light,\nTopdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat\nachieve a 20-30% improvement in chat consistency and up to a 15% increase in\ntask success rate, significantly outperforming models trained on existing\nsingle-turn and multi-turn instruction datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u591a\u8f6e\u5bf9\u8bdd\u6307\u4ee4\u6570\u636e\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u6846\u67b6\u63d0\u9ad8\u4e86\u804a\u5929\u7684\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u6307\u4ee4\u6570\u636e\u5408\u6210\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u8f6e\u6307\u4ee4\uff0c\u5f80\u5f80\u5ffd\u89c6\u591a\u8f6e\u5bf9\u8bdd\u7684\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u5728\u6269\u5c55\u5bf9\u8bdd\u4e2d\u51fa\u73b0\u4e0a\u4e0b\u6587\u6f02\u79fb\u548c\u4efb\u52a1\u5b8c\u6210\u7387\u964d\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSkeleton-Guided Multi-Turn Dialogue Generation\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4eba\u7c7b\u5bf9\u8bdd\u610f\u56fe\u6765\u7ea6\u675f\u591a\u8f6e\u6307\u4ee4\u5408\u6210\u3002\u8be5\u6846\u67b6\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\uff081\uff09\u610f\u56fe\u5efa\u6a21\uff0c\u6355\u6349\u4eba\u7c7b\u5bf9\u8bdd\u7684\u5168\u5c40\u7ed3\u6784\uff1b\uff082\uff09\u9aa8\u67b6\u751f\u6210\uff0c\u6784\u5efa\u5bf9\u9f50\u6a21\u578b\u610f\u56fe\u7684\u7528\u6237\u67e5\u8be2\u7ed3\u6784\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea615,000\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u548c224,392\u4e2a\u8bdd\u8bed\u7684\u591a\u8f6e\u6307\u4ee4\u6570\u636e\u96c6ConsistentChat\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728Light, Topdial\u548cMT-Eval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eConsistentChat\u5fae\u8c03\u7684\u6a21\u578b\u5728\u804a\u5929\u4e00\u81f4\u6027\u4e0a\u63d0\u9ad8\u4e8620-30%\uff0c\u4efb\u52a1\u6210\u529f\u7387\u63d0\u5347\u6700\u9ad8\u8fbe15%\u3002", "conclusion": "\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u6210\u529f\u7387\u660e\u663e\u4f18\u4e8e\u8bad\u7ec3\u5728\u73b0\u6709\u5355\u8f6e\u548c\u591a\u8f6e\u6307\u4ee4\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u578b\u3002"}}
{"id": "2506.03170", "pdf": "https://arxiv.org/pdf/2506.03170", "abs": "https://arxiv.org/abs/2506.03170", "authors": ["Murthy L", "Subarna Tripathi"], "title": "PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The risk of misusing text-to-image generative models for malicious uses,\nespecially due to the open-source development of such models, has become a\nserious concern. As a risk mitigation strategy, attributing generative models\nwith neural fingerprinting is emerging as a popular technique. There has been a\nplethora of recent work that aim for addressing neural fingerprinting. A\ntrade-off between the attribution accuracy and generation quality of such\nmodels has been studied extensively. None of the existing methods yet achieved\n$100\\%$ attribution accuracy. However, any model with less than \\emph{perfect}\naccuracy is practically non-deployable. In this work, we propose an accurate\nmethod to incorporate neural fingerprinting for text-to-image diffusion models\nleveraging the concepts of cyclic error correcting codes from the literature of\ncoding theory.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u5faa\u73af\u7ea0\u9519\u7801\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u795e\u7ecf\u6307\u7eb9\u6807\u8bb0\u7684\u65b9\u6cd5\u3002", "motivation": "\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u7531\u4e8e\u5176\u5f00\u653e\u6e90\u4ee3\u7801\u53d1\u5c55\uff0c\u53ef\u80fd\u88ab\u6076\u610f\u4f7f\u7528\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u98ce\u9669\u89c4\u907f\u7b56\u7565\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5229\u7528\u5faa\u73af\u7ea0\u9519\u7801\u7684\u6982\u5ff5\u6765\u5b9e\u73b0\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u7684\u795e\u7ecf\u6307\u7eb9\u6807\u8bb0\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u4e2d\u63d0\u51fa\u7684\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u795e\u7ecf\u6307\u7eb9\u6807\u8bb0\u7684\u51c6\u786e\u6027\u4ee5\u5b9e\u73b0100%\u5f52\u5c5e\u51c6\u786e\u6027\u3002", "conclusion": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u5b9e\u73b0\u5b8c\u5168\u5f52\u5c5e\u51c6\u786e\u6027\uff0c\u800c\u4f4e\u4e8e\u5b8c\u7f8e\u51c6\u786e\u6027\u7684\u6a21\u578b\u5b9e\u9645\u4e0a\u4e0d\u53ef\u90e8\u7f72\u3002"}}
{"id": "2506.03370", "pdf": "https://arxiv.org/pdf/2506.03370", "abs": "https://arxiv.org/abs/2506.03370", "authors": ["Leonid Ryvkin"], "title": "Comparison of different Unique hard attention transformer models by the formal languages they can recognize", "categories": ["cs.LG", "cs.CL", "cs.FL"], "comment": null, "summary": "This note is a survey of various results on the capabilities of unique hard\nattention transformers encoders (UHATs) to recognize formal languages. We\ndistinguish between masked vs. non-masked, finite vs. infinite image and\ngeneral vs. bilinear attention score functions. We recall some relations\nbetween these models, as well as a lower bound in terms of first-order logic\nand an upper bound in terms of circuit complexity.", "AI": {"tldr": "The paper surveys the varied capabilities of UHATs in recognizing formal languages, highlighting differences based on attention mechanisms and establishing theoretical bounds.", "motivation": "To explore and summarize the capabilities of unique hard attention transformers encoders (UHATs) in recognizing formal languages and the influence of different attention mechanisms.", "method": "The survey compares and contrasts various configurations of UHATs and derives their capabilities in recognizing formal languages using theoretical bounds from first-order logic and circuit complexity.", "result": "The paper establishes a lower bound for UHATs in relation to first-order logic and an upper bound in terms of circuit complexity, detailing their performance and limitations.", "conclusion": "UHATs have specific capabilities in recognizing formal languages, which vary based on different configurations like masked vs. non-masked settings and different types of attention score functions."}}
{"id": "2506.03566", "pdf": "https://arxiv.org/pdf/2506.03566", "abs": "https://arxiv.org/abs/2506.03566", "authors": ["Langlin Huang", "Chengsong Huang", "Jixuan Leng", "Di Huang", "Jiaxin Huang"], "title": "POSS: Position Specialist Generates Better Draft for Speculative Decoding", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Speculative decoding accelerates Large Language Model (LLM) inference by\nusing a small draft model to predict multiple tokens, and a large target model\nto verify these tokens in parallel. Recent studies leverage the hidden state of\nthe target model to enhance draft model prediction accuracy. However, existing\nmethods suffer from the degrading quality of draft token predictions at later\npositions, due to error accumulation in draft model generated features. In this\npaper, we propose Position Specialists (PosS), which consist of multiple\nposition-specialized draft layers to generate tokens at assigned position(s).\nPosition specialists greatly improve token acceptance rate at later positions\nper drafting round, as each specialist only needs to focus on handling a\ncertain level of draft model feature deviation. Experiment results on\nLlama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that\nPosS effectively improves over baselines on average acceptance length and\nspeed-up ratio. Our codebase is available at https://github.com/shrango/PosS.", "AI": {"tldr": "PosS\u7684\u63d0\u51fa\u589e\u5f3a\u4e86LLM\u63a8\u7406\u4e2d\u540e\u671f\u4f4d\u7f6e\u7684token\u9884\u6d4b\u8d28\u91cf\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u52a0\u901f\u65b9\u6cd5\u7531\u4e8e\u8349\u7a3f\u6a21\u578b\u751f\u6210\u7279\u5f81\u7684\u8bef\u5dee\u7d2f\u79ef\uff0c\u5bfc\u81f4\u540e\u7eed\u4f4d\u7f6etoken\u9884\u6d4b\u8d28\u91cf\u4e0b\u964d\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u63d0\u9ad8\u540e\u7eed\u4f4d\u7f6e\u7684token\u63a5\u53d7\u7387\u6765\u6539\u5584\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51faPosition Specialists (PosS)\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u5c42\u4f4d\u7f6e\u4e13\u7528\u7684\u8349\u7a3f\u6a21\u578b\u751f\u6210\u7279\u5b9a\u4f4d\u7f6e\u7684token\uff0c\u4ee5\u51cf\u5c11\u7279\u5b9a\u4f4d\u7f6e\u8349\u7a3f\u6a21\u578b\u7279\u5f81\u504f\u5dee\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPosS\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6709\u6548\u63d0\u9ad8\u4e86\u57fa\u7ebf\u6a21\u578b\u7684\u5e73\u5747\u63a5\u53d7\u957f\u5ea6\u548c\u52a0\u901f\u6bd4\u6027\u80fd\u3002", "conclusion": "Position Specialists (PosS)\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u540e\u7eed\u4f4d\u7f6e\u7684token\u63a5\u53d7\u7387\uff0c\u4ece\u800c\u6539\u5584\u8349\u7a3f\u6a21\u578b\u9884\u6d4b\u7684\u7cbe\u5ea6\uff0c\u5e76\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2506.03171", "pdf": "https://arxiv.org/pdf/2506.03171", "abs": "https://arxiv.org/abs/2506.03171", "authors": ["Ghulam Mujtaba", "Eun-Seok Ryu"], "title": "EdgeVidSum: Real-Time Personalized Video Summarization at the Edge", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "EdgeVidSum is a lightweight method that generates personalized, fast-forward\nsummaries of long-form videos directly on edge devices. The proposed approach\nenables real-time video summarization while safeguarding user privacy through\nlocal data processing using innovative thumbnail-based techniques and efficient\nneural architectures. Unlike conventional methods that process entire videos\nframe by frame, the proposed method uses thumbnail containers to significantly\nreduce computational complexity without sacrificing semantic relevance. The\nframework employs a hierarchical analysis approach, where a lightweight 2D CNN\nmodel identifies user-preferred content from thumbnails and generates\ntimestamps to create fast-forward summaries. Our interactive demo highlights\nthe system's ability to create tailored video summaries for long-form videos,\nsuch as movies, sports events, and TV shows, based on individual user\npreferences. The entire computation occurs seamlessly on resource-constrained\ndevices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical\nchallenges of computational efficiency, personalization, and privacy in modern\nvideo consumption environments.", "AI": {"tldr": "EdgeVidSum generates personalized video summaries using thumbnails and operates efficiently on edge devices, ensuring privacy and performance.", "motivation": "To provide a fast, personalized video summarization method for edge devices that preserves user privacy and reduces computational load.", "method": "EdgeVidSum uses thumbnail containers to reduce computational complexity through a lightweight 2D CNN model, which identifies user-preferred content from thumbnails and generates timestamps for summaries.", "result": "The method successfully generates user-tailored video summaries in real-time on resource-constrained devices like Jetson Nano.", "conclusion": "EdgeVidSum is effective in creating personalized video summaries directly on edge devices, balancing computational efficiency, personalization, and privacy."}}
{"id": "2506.03374", "pdf": "https://arxiv.org/pdf/2506.03374", "abs": "https://arxiv.org/abs/2506.03374", "authors": ["Haley Dozier", "Althea Henslee", "Ashley Abraham", "Andrew Strelzoff", "Mark Chappell"], "title": "Product Quantization for Surface Soil Similarity", "categories": ["cs.LG"], "comment": "To be published in the CSCE 2022 proceedings", "summary": "The use of machine learning (ML) techniques has allowed rapid advancements in\nmany scientific and engineering fields. One of these problems is that of\nsurface soil taxonomy, a research area previously hindered by the reliance on\nhuman-derived classifications, which are mostly dependent on dividing a dataset\nbased on historical understandings of that data rather than data-driven,\nstatistically observable similarities. Using a ML-based taxonomy allows soil\nresearchers to move beyond the limitations of human visualization and create\nclassifications of high-dimension datasets with a much higher level of\nspecificity than possible with hand-drawn taxonomies. Furthermore, this\npipeline allows for the possibility of producing both highly accurate and\nflexible soil taxonomies with classes built to fit a specific application. The\nmachine learning pipeline outlined in this work combines product quantization\nwith the systematic evaluation of parameters and output to get the best\navailable results, rather than accepting sub-optimal results by using either\ndefault settings or best guess settings.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u63d0\u9ad8\u571f\u58e4\u5206\u7c7b\u7684\u7cbe\u5ea6\u548c\u7075\u6d3b\u6027\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u4e3a\u571f\u58e4\u5206\u7c7b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5386\u53f2\u6570\u636e\u7406\u89e3\uff0c\u5c40\u9650\u6027\u8f83\u5927\u3002\u7814\u7a76\u9886\u57df\u9700\u8981\u4e00\u79cd\u66f4\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5206\u7c7b\u7684\u7279\u5f02\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5e76\u7ed3\u5408\u4ea7\u54c1\u91cf\u5316\u4e0e\u7cfb\u7edf\u53c2\u6570\u548c\u8f93\u51fa\u8bc4\u4f30\uff0c\u521b\u5efa\u9ad8\u7ef4\u6570\u636e\u96c6\u7684\u571f\u58e4\u5206\u7c7b\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u7ba1\u9053\uff0c\u80fd\u591f\u521b\u5efa\u65e2\u51c6\u786e\u53c8\u7075\u6d3b\u7684\u571f\u58e4\u5206\u7c7b\u4f53\u7cfb\uff0c\u9002\u7528\u4e8e\u7279\u5b9a\u5e94\u7528\u9700\u6c42\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u514b\u670d\u4f20\u7edf\u571f\u58e4\u5206\u7c7b\u65b9\u6cd5\u5c40\u9650\u6027\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u5b9e\u73b0\u66f4\u9ad8\u7279\u5f02\u6027\u548c\u7075\u6d3b\u6027\u7684\u5206\u7c7b\u3002"}}
{"id": "2506.03569", "pdf": "https://arxiv.org/pdf/2506.03569", "abs": "https://arxiv.org/abs/2506.03569", "authors": ["Xiaomi LLM-Core Team", ":", "Zihao Yue", "Zhenru Lin", "Yifan Song", "Weikun Wang", "Shuhuai Ren", "Shuhao Gu", "Shicheng Li", "Peidian Li", "Liang Zhao", "Lei Li", "Kainan Bao", "Hao Tian", "Hailin Zhang", "Gang Wang", "Dawei Zhu", "Cici", "Chenhong He", "Bowen Ye", "Bowen Shen", "Zihan Zhang", "Zihan Jiang", "Zhixian Zheng", "Zhichao Song", "Zhenbo Luo", "Yue Yu", "Yudong Wang", "Yuanyuan Tian", "Yu Tu", "Yihan Yan", "Yi Huang", "Xu Wang", "Xinzhe Xu", "Xingchen Song", "Xing Zhang", "Xing Yong", "Xin Zhang", "Xiangwei Deng", "Wenyu Yang", "Wenhan Ma", "Weiwei Lv", "Weiji Zhuang", "Wei Liu", "Sirui Deng", "Shuo Liu", "Shimao Chen", "Shihua Yu", "Shaohui Liu", "Shande Wang", "Rui Ma", "Qiantong Wang", "Peng Wang", "Nuo Chen", "Menghang Zhu", "Kangyang Zhou", "Kang Zhou", "Kai Fang", "Jun Shi", "Jinhao Dong", "Jiebao Xiao", "Jiaming Xu", "Huaqiu Liu", "Hongshen Xu", "Heng Qu", "Haochen Zhao", "Hanglong Lv", "Guoan Wang", "Duo Zhang", "Dong Zhang", "Di Zhang", "Chong Ma", "Chang Liu", "Can Cai", "Bingquan Xia"], "title": "MiMo-VL Technical Report", "categories": ["cs.CL"], "comment": "32 pages", "summary": "We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language\nmodels delivering state-of-the-art performance in both general visual\nunderstanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B\non 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing\nmodels with up to 78B parameters. For GUI grounding applications, it sets a new\nstandard with 56.1 on OSWorld-G, even outperforming specialized models such as\nUI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens)\nwith Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward\nsignals. We identify the importance of incorporating high-quality reasoning\ndata with long Chain-of-Thought into pre-training stages, and the benefits of\nmixed RL despite challenges in simultaneous multi-domain optimization. We also\ncontribute a comprehensive evaluation suite covering 50+ tasks to promote\nreproducibility and advance the field. The model checkpoints and full\nevaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.", "AI": {"tldr": "MiMo-VL-7B-SFT\u548cMiMo-VL-7B-RL\u662f\u5f3a\u5927\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\uff0c\u91c7\u7528\u72ec\u7279\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u518d\u73b0\u6027\u3002", "motivation": "\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u89c6\u89c9\u7406\u89e3\u548c\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4fc3\u8fdb\u9886\u57df\u5185\u7684\u518d\u73b0\u6027\u548c\u8fdb\u6b65\u3002", "method": "\u4f7f\u7528\u56db\u9636\u6bb5\u9884\u8bad\u7ec3\u548c\u6df7\u5408\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\uff08MORL\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u6574\u5408\u591a\u6837\u5316\u5956\u52b1\u4fe1\u53f7\u3002", "result": "MiMo-VL-7B-RL\u572840\u9879\u4efb\u52a1\u4e2d\u8d85\u8d8aQwen-2.5-VL-7B\u4e2d\u768435\u9879\uff0c\u5965\u6797\u5339\u4e9a\u57fa\u51c6\u4e0a\u5f97\u5206\u4e3a59.4\uff0c\u751a\u81f3\u8d85\u8d8a\u62e5\u670978\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5728GUI\u5b9a\u4f4d\u5e94\u7528\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5f97\u520656.1\uff0c\u8d85\u8fc7\u4e13\u7528\u6a21\u578bUI-TARS\u3002", "conclusion": "MiMo-VL-7B-SFT\u548cMiMo-VL-7B-RL\u6a21\u578b\u5728\u89c6\u89c9\u7406\u89e3\u548c\u591a\u6a21\u6001\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2506.03173", "pdf": "https://arxiv.org/pdf/2506.03173", "abs": "https://arxiv.org/abs/2506.03173", "authors": ["Xiaoyi Liu", "Hao Tang"], "title": "FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Physical intelligence -- anticipating and shaping the world from partial,\nmultisensory observations -- is critical for next-generation world models. We\npropose FOLIAGE, a physics-informed multimodal world model for unbounded\naccretive surface growth. In its Action-Perception loop, a unified context\nencoder maps images, mesh connectivity, and point clouds to a shared latent\nstate. A physics-aware predictor, conditioned on physical control actions,\nadvances this latent state in time to align with the target latent of the\nsurface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces\nwith critic heads for downstream objectives. FOLIAGE's Accretive Graph Network\n(AGN) captures dynamic connectivity through Age Positional Encoding and\nEnergy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch\nMasking enhance MAGE's expressiveness, while Hierarchical Pooling balances\nglobal context with local dynamics. We create SURF-GARDEN, a world model\nlearning platform comprising a Counterfactual Physics Simulator, a Multimodal\nCorrespondence Extractor, and Evolution Tracing, which generates 7,200 diverse\nsurface-growth sequences. SURF-BENCH, our physical-intelligence evaluation\nsuite, evaluates six core tasks -- topology recognition, inverse material\nestimation, growth-stage classification, latent roll-out, cross-modal\nretrieval, and dense correspondence -- and four stress tests -- sensor dropout,\nzero-shot modality transfer, long-horizon prediction, and physics ablation --\nto probe resilience. FOLIAGE outperforms specialized baselines while remaining\nrobust across dynamic environments, establishing a new world-model based,\nmultimodal pathway to physical intelligence.", "AI": {"tldr": "FOLIAGE\u662f\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u5316\u7684\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\uff0c\u5728\u8868\u9762\u751f\u957f\u6a21\u62df\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u5404\u79cd\u4e13\u4e1a\u57fa\u51c6\uff0c\u5f00\u8f9f\u4e86\u65b0\u7684\u7269\u7406\u667a\u80fd\u9014\u5f84\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u4e0b\u4e00\u4ee3\u4e16\u754c\u6a21\u578b\u7684\u7269\u7406\u667a\u80fd\uff0c\u901a\u8fc7\u90e8\u5206\u7684\u591a\u611f\u77e5\u89c2\u6d4b\u6765\u9884\u5224\u5e76\u5851\u9020\u4e16\u754c\uff0c\u5bf9\u8868\u9762\u751f\u957f\u8fdb\u884c\u7269\u7406\u4fe1\u606f\u5316\u7684\u591a\u6a21\u6001\u5efa\u6a21\u662f\u5fc5\u8981\u7684\u3002", "method": "\u91c7\u7528\u7269\u7406\u4fe1\u606f\u7684\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\uff0c\u7ed3\u5408\u6620\u50cf\u3001\u7f51\u683c\u8fde\u63a5\u548c\u70b9\u4e91\uff0c\u901a\u8fc7\u7269\u7406\u611f\u77e5\u9884\u6d4b\u5668\u548c\u7d2f\u52a0\u56fe\u7f51\u7edc\u6355\u6349\u52a8\u6001\u8fde\u63a5\u3001\u51e0\u4f55\u5bf9\u5e94\u878d\u5408\u3001\u4ea4\u53c9\u8865\u4e01\u5c4f\u853d\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u7cbe\u7ec6\u7684\u8868\u9762\u751f\u957f\u6a21\u62df\u3002", "result": "FOLIAGE\u5728\u7269\u7406\u667a\u80fd\u8bc4\u4f30\u5957\u4ef6\u4e2d\u7684\u516d\u9879\u6838\u5fc3\u4efb\u52a1\u548c\u56db\u9879\u538b\u529b\u6d4b\u8bd5\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8fc7\u4e86\u5404\u7c7b\u4e13\u4e1a\u57fa\u7ebf\u3002", "conclusion": "FOLIAGE\u5728\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u591a\u6a21\u6001\u7269\u7406\u667a\u80fd\u9886\u57df\u8bbe\u7acb\u4e86\u65b0\u7684\u6807\u51c6\u3002"}}
{"id": "2506.03392", "pdf": "https://arxiv.org/pdf/2506.03392", "abs": "https://arxiv.org/abs/2506.03392", "authors": ["Aref Ghoreishee", "Abhishek Mishra", "John Walsh", "Anup Das", "Nagarajan Kandasamy"], "title": "Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons", "categories": ["cs.LG", "cs.NE", "cs.SY", "eess.SY"], "comment": null, "summary": "We propose a new ternary spiking neuron model to improve the representation\ncapacity of binary spiking neurons in deep Q-learning. Although a ternary\nneuron model has recently been introduced to overcome the limited\nrepresentation capacity offered by the binary spiking neurons, we show that its\nperformance is worse than that of binary models in deep Q-learning tasks. We\nhypothesize gradient estimation bias during the training process as the\nunderlying potential cause through mathematical and empirical analysis. We\npropose a novel ternary spiking neuron model to mitigate this issue by reducing\nthe estimation bias. We use the proposed ternary spiking neuron as the\nfundamental computing unit in a deep spiking Q-learning network (DSQN) and\nevaluate the network's performance in seven Atari games from the Gym\nenvironment. Results show that the proposed ternary spiking neuron mitigates\nthe drastic performance degradation of ternary neurons in Q-learning tasks and\nimproves the network performance compared to the existing binary neurons,\nmaking DSQN a more practical solution for on-board autonomous decision-making\ntasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u4ee5\u6539\u5584\u6df1\u5ea6Q\u5b66\u4e60\u4e2d\u4e8c\u8fdb\u5236\u795e\u7ecf\u5143\u7684\u8868\u73b0\uff0c\u5e76\u5728\u591a\u4e2a\u6e38\u620f\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5728\u6df1\u5ea6Q\u5b66\u4e60\u4e2d\u4e8c\u8fdb\u5236\u8109\u51b2\u795e\u7ecf\u5143\u7684\u8868\u793a\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\u3002\u867d\u7136\u6700\u8fd1\u5f15\u5165\u4e86\u4e09\u5143\u795e\u7ecf\u5143\u6a21\u578b\u4ee5\u514b\u670d\u4e8c\u8fdb\u5236\u8109\u51b2\u795e\u7ecf\u5143\u7684\u6709\u9650\u8868\u793a\u80fd\u529b\uff0c\u4f46\u5176\u6027\u80fd\u5728\u6df1\u5ea6Q\u5b66\u4e60\u4efb\u52a1\u4e2d\u5374\u8f83\u5dee\u3002\u672c\u6587\u901a\u8fc7\u6570\u5b66\u548c\u7ecf\u9a8c\u5206\u6790\uff0c\u5047\u8bbe\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u68af\u5ea6\u4f30\u8ba1\u504f\u5dee\u662f\u5176\u6f5c\u5728\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u65e8\u5728\u901a\u8fc7\u51cf\u5c11\u4f30\u8ba1\u504f\u5dee\u6765\u6539\u5584\u8868\u73b0\u3002\u5c06\u8be5\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u4f5c\u4e3a\u6df1\u5ea6\u8109\u51b2Q\u5b66\u4e60\u7f51\u7edc\uff08DSQN\uff09\u7684\u57fa\u672c\u8ba1\u7b97\u5355\u5143\uff0c\u5e76\u5728Gym\u73af\u5883\u4e2d\u7684\u4e03\u4e2aAtari\u6e38\u620f\u4e2d\u8bc4\u4f30\u7f51\u7edc\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u63d0\u51fa\u7684\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u51cf\u8f7b\u4e86\u5728Q\u5b66\u4e60\u4efb\u52a1\u4e2d\u4e09\u5143\u795e\u7ecf\u5143\u7684\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u4e0e\u73b0\u6709\u4e8c\u8fdb\u5236\u795e\u7ecf\u5143\u76f8\u6bd4\u63d0\u9ad8\u4e86\u7f51\u7edc\u6027\u80fd\uff0c\u4f7fDSQN\u6210\u4e3a\u673a\u8f7d\u81ea\u4e3b\u51b3\u7b56\u4efb\u52a1\u7684\u66f4\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e09\u5143\u8109\u51b2\u795e\u7ecf\u5143\u6a21\u578b\u6bd4\u73b0\u6709\u7684\u4e8c\u8fdb\u5236\u795e\u7ecf\u5143\u5728\u6df1\u5ea6Q\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u4e3a\u673a\u8f7d\u81ea\u4e3b\u51b3\u7b56\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.03570", "pdf": "https://arxiv.org/pdf/2506.03570", "abs": "https://arxiv.org/abs/2506.03570", "authors": ["Lin Sun", "Chuang Liu", "Xiaofeng Ma", "Tao Yang", "Weijia Lu", "Ning Wu"], "title": "FreePRM: Training Process Reward Models Without Ground Truth Process Labels", "categories": ["cs.CL"], "comment": null, "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated that\nProcess Reward Models (PRMs) play a crucial role in enhancing model\nperformance. However, training PRMs typically requires step-level labels,\neither manually annotated or automatically generated, which can be costly and\ndifficult to obtain at scale. To address this challenge, we introduce FreePRM,\na weakly supervised framework for training PRMs without access to ground-truth\nstep-level labels. FreePRM first generates pseudo step-level labels based on\nthe correctness of final outcome, and then employs Buffer Probability to\neliminate impact of noise inherent in pseudo labeling. Experimental results\nshow that FreePRM achieves an average F1 score of 53.0% on ProcessBench,\noutperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared\nto other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B\n(28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by\n+10.9%. This work introduces a new paradigm in PRM training, significantly\nreducing reliance on costly step-level annotations while maintaining strong\nperformance.", "AI": {"tldr": "FreePRM \u63d0\u4f9b\u65e0\u9700\u771f\u5b9e\u6b65\u9aa4\u7ea7\u6807\u7b7e\u7684\u5f31\u76d1\u7763\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709 PRM \u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u8bad\u7ec3\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u65f6\u83b7\u53d6\u6b65\u9aa4\u7ea7\u6807\u7b7e\u56f0\u96be\u4e14\u6602\u8d35\u7684\u95ee\u9898\u3002", "method": "FreePRM \u751f\u6210\u4f2a\u6b65\u9aa4\u7ea7\u6807\u7b7e\u5e76\u4f7f\u7528\u7f13\u51b2\u6982\u7387\u6d88\u9664\u566a\u58f0\u5f71\u54cd\u3002", "result": "\u5728 ProcessBench \u4e0a\u83b7\u5f97 53.0% \u7684\u5e73\u5747 F1 \u5206\u6570\uff0c\u8d85\u8d8a\u5168\u76d1\u7763 PRM 24.1%\u3002", "conclusion": "\u5f15\u5165 FreePRM\uff0c\u5927\u5e45\u51cf\u5c11\u5bf9\u6602\u8d35\u6b65\u9aa4\u7ea7\u6807\u7b7e\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u52b2\u6027\u80fd\u3002"}}
{"id": "2506.03174", "pdf": "https://arxiv.org/pdf/2506.03174", "abs": "https://arxiv.org/abs/2506.03174", "authors": ["Koki Matsuishi", "Kosuke Ukita", "Tsuyoshi Okita"], "title": "Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "25 pages, 8 figures", "summary": "In recent years, the widespread adoption of wearable devices has highlighted\nthe growing importance of behavior analysis using IMU. While applications span\ndiverse fields such as healthcare and robotics, recent studies have\nincreasingly focused on multimodal analysis, in addition to unimodal analysis.\nSeveral studies have proposed multimodal foundation models that incorporate\nfirst-person video and text data; however, these models still fall short in\nproviding a detailed analysis of full-body human activity. To address this\nlimitation, we propose Activity Understanding and Representations Alignment -\nMultimodal Foundation Model (AURA-MFM), a foundational model integrating four\nmodalities: third-person video, motion capture, IMU, and text. By incorporating\nthird-person video and motion capture data, the model enables a detailed and\nmultidimensional understanding of human activity, which first-person\nperspectives alone fail to capture. Additionally, a Transformer-based IMU\nencoder is employed to enhance the model's overall performance. Experimental\nevaluations on retrieval and activity recognition tasks demonstrate that our\nmodel surpasses existing methods. Notably, in the zero-shot classification for\naction recognition, our method achieved significantly higher performance, with\nan F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method\nrecorded an F1-score of 0.0747 and an accuracy of 0.1961.", "AI": {"tldr": "AURA-MFM\u6a21\u578b\u901a\u8fc7\u6574\u5408\u591a\u79cd\u6a21\u6001\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4eba\u7c7b\u6d3b\u52a8\u7684\u8be6\u7ec6\u5206\u6790\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u96f6\u6837\u672c\u5206\u7c7b\u4e2d\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u63d0\u4f9b\u5168\u8eab\u4eba\u7c7b\u6d3b\u52a8\u7684\u8be6\u7ec6\u5206\u6790\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86AURA-MFM\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5728AURA-MFM\u6a21\u578b\u4e2d\uff0c\u6574\u5408\u4e86\u56db\u79cd\u6a21\u6001\uff1a\u7b2c\u4e09\u4eba\u79f0\u89c6\u9891\u3001\u8fd0\u52a8\u6355\u6349\u3001IMU\u548c\u6587\u672c\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8eTransformer\u7684IMU\u7f16\u7801\u5668\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u96f6\u6837\u672c\u5206\u7c7b\u7684\u52a8\u4f5c\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0cAURA-MFM\u6a21\u578b\u7684F1\u5206\u6570\u8fbe\u52300.6226\uff0c\u51c6\u786e\u7387\u8fbe\u52300.7320\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u7684F1\u5206\u6570\u4ec5\u4e3a0.0747\uff0c\u51c6\u786e\u7387\u4e3a0.1961\u3002", "conclusion": "AURA-MFM\u6a21\u578b\u5728\u884c\u4e3a\u5206\u6790\u4e2d\u5f15\u5165\u4e86\u7b2c\u4e09\u4eba\u79f0\u89c6\u9891\u3001\u8fd0\u52a8\u6355\u6349\u3001IMU\u548c\u6587\u672c\u56db\u79cd\u6a21\u6001\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u5bf9\u4eba\u7c7b\u6d3b\u52a8\u7684\u66f4\u52a0\u8be6\u7ec6\u548c\u591a\u7ef4\u5ea6\u7684\u7406\u89e3\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u68c0\u7d22\u548c\u6d3b\u52a8\u8bc6\u522b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u96f6\u6837\u672c\u5206\u7c7b\u7684\u52a8\u4f5c\u8bc6\u522b\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2506.03404", "pdf": "https://arxiv.org/pdf/2506.03404", "abs": "https://arxiv.org/abs/2506.03404", "authors": ["Walter Mayor", "Johan Obando-Ceron", "Aaron Courville", "Pablo Samuel Castro"], "title": "The Impact of On-Policy Parallelized Data Collection on Deep Reinforcement Learning Networks", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "The use of parallel actors for data collection has been an effective\ntechnique used in reinforcement learning (RL) algorithms. The manner in which\ndata is collected in these algorithms, controlled via the number of parallel\nenvironments and the rollout length, induces a form of bias-variance trade-off;\nthe number of training passes over the collected data, on the other hand, must\nstrike a balance between sample efficiency and overfitting. We conduct an\nempirical analysis of these trade-offs on PPO, one of the most popular RL\nalgorithms that uses parallel actors, and establish connections to network\nplasticity and, more generally, optimization stability. We examine its impact\non network architectures, as well as the hyper-parameter sensitivity when\nscaling data. Our analyses indicate that larger dataset sizes can increase\nfinal performance across a variety of settings, and that scaling parallel\nenvironments is more effective than increasing rollout lengths. These findings\nhighlight the critical role of data collection strategies in improving agent\nperformance.", "AI": {"tldr": "\u5e76\u884c\u89d2\u8272\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u5728\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6027\u80fd\u4e0a\u6709\u6548\uff0c\u6269\u5c55\u5e76\u884c\u73af\u5883\u4f18\u4e8e\u589e\u52a0\u5c55\u671f\u957f\u5ea6\u3002", "motivation": "\u7814\u7a76\u6570\u636e\u6536\u96c6\u65b9\u5f0f\u5bf9\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u53ca\u6837\u672c\u6548\u7387\u4e0e\u8fc7\u62df\u5408\u4e4b\u95f4\u5e73\u8861\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u57fa\u4e8e\u5e76\u884c\u89d2\u8272\u7684\u6570\u636e\u6536\u96c6\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u63a2\u8ba8\u5176\u4e0e\u7f51\u7edc\u53ef\u5851\u6027\u53ca\u4f18\u5316\u7a33\u5b9a\u6027\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u8f83\u5927\u7684\u6570\u636e\u96c6\u89c4\u6a21\u53ef\u5728\u591a\u79cd\u8bbe\u5b9a\u4e2d\u63d0\u9ad8\u6700\u7ec8\u6027\u80fd\uff0c\u6269\u5c55\u5e76\u884c\u73af\u5883\u6bd4\u589e\u52a0\u5c55\u671f\u957f\u5ea6\u66f4\u6709\u6548\u3002", "conclusion": "\u6570\u636e\u6536\u96c6\u7b56\u7565\u5728\u63d0\u9ad8\u4ee3\u7406\u6027\u80fd\u4e2d\u626e\u6f14\u4e86\u5173\u952e\u89d2\u8272\uff0c\u6269\u5c55\u5e76\u884c\u73af\u5883\u6bd4\u589e\u52a0\u5c55\u671f\u957f\u5ea6\u66f4\u4e3a\u6709\u6548\u3002"}}
{"id": "2506.03573", "pdf": "https://arxiv.org/pdf/2506.03573", "abs": "https://arxiv.org/abs/2506.03573", "authors": ["Lin Sun", "Can Zhang"], "title": "Exchange of Perspective Prompting Enhances Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have made significant advancements in addressing\ndiverse natural language processing (NLP) tasks. However, their performance is\noften limited by inherent comprehension of problems. To address this\nlimitation, we propose Exchange-of-Perspective (EoP), a novel framework\ndesigned to exchange perspectives across different definitions of problem, so\nthat it can break the fixed mindset from any particular formulation of the\nquestion. We conducted extensive and comprehensive experiments on 8 benchmarks.\nThe results show that EoP can significantly improve performance. For instance,\ncompared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we\nobserve a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP\ndemonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a\n3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using\nQwen-2.5-72b.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faEoP\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u6362\u95ee\u9898\u5b9a\u4e49\u89c6\u89d2\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u65f6\u7684\u6027\u80fd\u53d7\u9650\u4e8e\u5bf9\u95ee\u9898\u7684\u7406\u89e3\uff0c\u4e3a\u6b64\u9700\u8981\u63a2\u7d22\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u88ab\u79f0\u4e3aEoP\uff08\u89c6\u89d2\u4ea4\u6362\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u6362\u4e0d\u540c\u7684\u95ee\u9898\u5b9a\u4e49\u89c6\u89d2\u6765\u6253\u7834\u56fa\u5b9a\u7684\u601d\u7ef4\u6a21\u5f0f\u3002", "result": "\u4e0e\u975e\u4ea4\u6362\u57fa\u7ebfPHP\u76f8\u6bd4\uff0c\u4f7f\u7528EoP\u7684GPT-3.5-Turbo\u5728AQuA\u4e0a\u63d0\u9ad8\u4e863.6%\u7684\u6027\u80fd\uff0c\u800c\u4f7f\u7528EoP\u7684GPT-4\u5728Math\uff0cOlympiadBench Maths\u4e0a\u5206\u522b\u63d0\u9ad8\u4e867.7%\u548c3.5%\u7684\u6574\u4f53\u51c6\u786e\u7387\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6EoP\uff0c\u901a\u8fc7\u4ea4\u6362\u95ee\u9898\u5b9a\u4e49\u7684\u4e0d\u540c\u89c6\u89d2\u6765\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660eEoP\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.03177", "pdf": "https://arxiv.org/pdf/2506.03177", "abs": "https://arxiv.org/abs/2506.03177", "authors": ["Isarun Chamveha", "Supphanut Chaiyungyuen", "Sasinun Worakriangkrai", "Nattawadee Prasawang", "Warasinee Chaisangmongkon", "Pornpim Korpraphong", "Voraparee Suvannarerg", "Shanigarn Thiravit", "Chalermdej Kannawat", "Kewalin Rungsinaporn", "Suwara Issaragrisil", "Payia Chadbunchachai", "Pattiya Gatechumpol", "Chawiporn Muktabhant", "Patarachai Sereerat"], "title": "Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "This study presents a deep learning system for breast cancer detection in\nmammography, developed using a modified EfficientNetV2 architecture with\nenhanced attention mechanisms. The model was trained on mammograms from a major\nThai medical center and validated on three distinct datasets: an in-domain test\nset (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain\ngeneralizability set (761 cases) collected from two different hospitals. For\ncancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the\nrespective datasets. The system's lesion localization capability, evaluated\nusing metrics including Lesion Localization Fraction (LLF) and Non-Lesion\nLocalization Fraction (NLF), demonstrated robust performance in identifying\nsuspicious regions. Clinical validation through concordance tests showed strong\nagreement with radiologists: 83.5% classification and 84.0% localization\nconcordance for biopsy-confirmed cases, and 78.1% classification and 79.6%\nlocalization concordance for out-of-domain cases. Expert radiologists'\nacceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for\nout-of-domain cases. The system achieved a System Usability Scale score of\n74.17 for source hospital, and 69.20 for validation hospitals, indicating good\nclinical acceptance. These results demonstrate the model's effectiveness in\nassisting mammogram interpretation, with the potential to enhance breast cancer\nscreening workflows in clinical practice.", "AI": {"tldr": "\u4e00\u4e2a\u9ad8\u6548\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u7528\u4e8e\u4e73\u817a\u764c\u7b5b\u67e5\uff0c\u5728\u591a\u4e2a\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u5353\u8d8a\u7684\u68c0\u6d4b\u548c\u5b9a\u4f4d\u6027\u80fd\uff0c\u5c55\u793a\u5176\u5728\u5b9e\u9645\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u53ef\u4ee5\u5e2e\u52a9\u653e\u5c04\u79d1\u533b\u751f\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4e73\u817a\u764c\u75c5\u7076\u7684\u7cfb\u7edf\u3002", "method": "\u5176\u4f7f\u7528\u4e86\u4e00\u79cd\u6539\u8fdb\u7684EfficientNetV2\u67b6\u6784\u4e0e\u589e\u5f3a\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u5b9e\u73b0\uff0c\u8bad\u7ec3\u548c\u9a8c\u8bc1\u5305\u62ec\u6765\u81ea\u4e0d\u540c\u533b\u9662\u548c\u6570\u636e\u96c6\u7684\u4e73\u817aX\u5149\u56fe\u50cf\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684AUROC\u5206\u522b\u8fbe\u5230\u4e860.89\u30010.96\u548c0.94\uff0c\u75c5\u7076\u5b9a\u4f4d\u80fd\u529b\u8868\u73b0\u826f\u597d\uff0c\u4e0e\u653e\u5c04\u79d1\u533b\u751f\u7684\u5224\u5b9a\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u53d7\u5230\u4e34\u5e8a\u7684\u666e\u904d\u63a5\u53d7\u3002", "conclusion": "\u8be5\u7814\u7a76\u7684\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u5728\u4e73\u817a\u764c\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u80fd\u6539\u5584\u4e34\u5e8a\u7b5b\u67e5\u6d41\u7a0b\u3002"}}
{"id": "2506.03411", "pdf": "https://arxiv.org/pdf/2506.03411", "abs": "https://arxiv.org/abs/2506.03411", "authors": ["Melissa Dutz", "Han Shao", "Avrim Blum", "Aloni Cohen"], "title": "A Machine Learning Theory Perspective on Strategic Litigation", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Strategic litigation involves bringing a legal case to court with the goal of\nhaving a broader impact beyond resolving the case itself: for example, creating\nprecedent which will influence future rulings. In this paper, we explore\nstrategic litigation from the perspective of machine learning theory. We\nconsider an abstract model of a common-law legal system where a lower court\ndecides new cases by applying a decision rule learned from a higher court's\npast rulings. In this model, we explore the power of a strategic litigator, who\nstrategically brings cases to the higher court to influence the learned\ndecision rule, thereby affecting future cases. We explore questions including:\nWhat impact can a strategic litigator have? Which cases should a strategic\nlitigator bring to court? Does it ever make sense for a strategic litigator to\nbring a case when they are sure the court will rule against them?", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u6218\u7565\u8bc9\u8bbc\u5982\u4f55\u5f71\u54cd\u6cd5\u5f8b\u7cfb\u7edf\u4e2d\u7684\u51b3\u7b56\u89c4\u5219\uff0c\u4ee5\u53ca\u6218\u7565\u8bc9\u8bbc\u8005\u5e94\u5982\u4f55\u9009\u62e9\u8bc9\u8bbc\u6848\u4ef6\u4ee5\u6700\u5927\u5316\u5f71\u54cd\u3002", "motivation": "\u4e3a\u4e86\u7814\u7a76\u673a\u5668\u5b66\u4e60\u7406\u8bba\u89c6\u89d2\u4e0b\u7684\u6218\u7565\u8bc9\u8bbc\uff0c\u5206\u6790\u6218\u7565\u8bc9\u8bbc\u5982\u4f55\u901a\u8fc7\u5f71\u54cd\u9ad8\u7b49\u6cd5\u9662\u7684\u51b3\u7b56\u89c4\u5219\u6765\u5f71\u54cd\u672a\u6765\u7684\u6848\u4ef6\u3002", "method": "\u6784\u5efa\u62bd\u8c61\u6a21\u578b\uff0c\u6a21\u62df\u666e\u901a\u6cd5\u6cd5\u5f8b\u7cfb\u7edf\u4e2d\u9ad8\u7b49\u6cd5\u9662\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5206\u6790\u6218\u7565\u8bc9\u8bbc\u8005\u901a\u8fc7\u9009\u62e9\u6027\u63d0\u8d77\u6848\u4ef6\u5f71\u54cd\u51b3\u7b56\u89c4\u5219\u7684\u80fd\u529b\u3002", "result": "\u63a2\u8ba8\u6218\u7565\u8bc9\u8bbc\u8005\u5bf9\u9ad8\u7b49\u6cd5\u9662\u51b3\u7b56\u89c4\u5219\u7684\u5f71\u54cd\uff0c\u54ea\u4e9b\u6848\u4ef6\u5e94\u63d0\u8d77\uff0c\u53ca\u6218\u7565\u8bc9\u8bbc\u8005\u5728\u660e\u77e5\u8d25\u8bc9\u65f6\u63d0\u8d77\u8bc9\u8bbc\u7684\u5408\u7406\u6027\u3002", "conclusion": "\u6218\u7565\u8bc9\u8bbc\u5728\u666e\u901a\u6cd5\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u7684\u5f71\u54cd\u529b\uff0c\u53ef\u4ee5\u901a\u8fc7\u9009\u62e9\u6027\u63d0\u8d77\u548c\u5904\u7406\u6848\u4ef6\u6765\u5851\u9020\u6cd5\u5f8b\u89c4\u5219\u5bfc\u5411\u3002"}}
{"id": "2506.03576", "pdf": "https://arxiv.org/pdf/2506.03576", "abs": "https://arxiv.org/abs/2506.03576", "authors": ["Zirui Chen", "Xin Wang", "Zhao Li", "Wenbin Guo", "Dongxiao He"], "title": "KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in knowledge representation learning (KRL) highlight the\nurgent necessity to unify symbolic knowledge graphs (KGs) with language models\n(LMs) for richer semantic understanding. However, existing approaches typically\nprioritize either graph structure or textual semantics, leaving a gap: a\nunified framework that simultaneously captures global KG connectivity, nuanced\nlinguistic context, and discriminative reasoning semantics. To bridge this gap,\nwe introduce KG-BiLM, a bidirectional LM framework that fuses structural cues\nfrom KGs with the semantic expressiveness of generative transformers. KG-BiLM\nincorporates three key components: (i) Bidirectional Knowledge Attention, which\nremoves the causal mask to enable full interaction among all tokens and\nentities; (ii) Knowledge-Masked Prediction, which encourages the model to\nleverage both local semantic contexts and global graph connectivity; and (iii)\nContrastive Graph Semantic Aggregation, which preserves KG structure via\ncontrastive alignment of sampled sub-graph representations. Extensive\nexperiments on standard benchmarks demonstrate that KG-BiLM outperforms strong\nbaselines in link prediction, especially on large-scale graphs with complex\nmulti-hop relations - validating its effectiveness in unifying structural\ninformation and textual semantics.", "AI": {"tldr": "KG-BiLM\u662f\u4e00\u79cd\u65b0\u5f00\u53d1\u7684\u53cc\u5411\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u65e8\u5728\u5c06\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u548c\u751f\u6210\u6027\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u6574\u5408\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u7edf\u4e00\u7b26\u53f7\u77e5\u8bc6\u56fe\u8c31\u4e0e\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u8bed\u4e49\u7406\u89e3\uff0c\u73b0\u6709\u65b9\u6cd5\u503e\u5411\u4e8e\u56fe\u7ed3\u6784\u6216\u6587\u672c\u8bed\u4e49\uff0c\u7f3a\u4e4f\u540c\u65f6\u6355\u83b7\u5168\u5c40\u77e5\u8bc6\u56fe\u8c31\u8fde\u901a\u6027\u3001\u7ec6\u81f4\u8bed\u8a00\u8bed\u5883\u53ca\u8fa8\u522b\u63a8\u7406\u8bed\u4e49\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53cc\u5411\u8bed\u8a00\u6a21\u578b\u6846\u67b6KG-BiLM\uff0c\u878d\u5408\u4e86\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u63d0\u793a\u4e0e\u751f\u6210\u6027\u53d8\u6362\u5668\u7684\u8bed\u4e49\u8868\u8fbe\uff0c\u901a\u8fc7\u5f15\u5165\u4e09\u5927\u5173\u952e\u7ec4\u4ef6\uff1a\u53cc\u5411\u77e5\u8bc6\u6ce8\u610f\u529b\u3001\u77e5\u8bc6\u63a9\u7801\u9884\u6d4b\u3001\u5bf9\u6bd4\u56fe\u7ed3\u6784\u8bed\u4e49\u805a\u5408\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cKG-BiLM\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u5177\u6709\u590d\u6742\u591a\u8df3\u5173\u7cfb\u7684\u5927\u89c4\u6a21\u56fe\u8c31\u4e0a\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u7edf\u4e00\u7ed3\u6784\u4fe1\u606f\u548c\u6587\u672c\u8bed\u4e49\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "KG-BiLM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u4fe1\u606f\u4e0e\u751f\u6210\u6027\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u8bed\u4e49\u7ed3\u5408\u8d77\u6765\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u89c4\u6a21\u4e14\u590d\u6742\u7684\u591a\u8df3\u5173\u7cfb\u56fe\u8c31\u65f6\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.03178", "pdf": "https://arxiv.org/pdf/2506.03178", "abs": "https://arxiv.org/abs/2506.03178", "authors": ["Md. Zihad Bin Jahangir", "Muhammad Ashad Kabir", "Sumaiya Akter", "Israt Jahan", "Minh Chau"], "title": "LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "25 pages", "summary": "Automated radiology report generation holds significant potential to reduce\nradiologists' workload and enhance diagnostic accuracy. However, generating\nprecise and clinically meaningful reports from chest radiographs remains\nchallenging due to the complexity of medical language and the need for\ncontextual understanding. Existing models often struggle with maintaining both\naccuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel\nframework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings\nand Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves\nimproved coherence and clinical accuracy while maintaining computational\nefficiency. This efficiency is driven by an optimization strategy that enhances\nparameter utilization and reduces memory overhead, enabling faster report\ngeneration with lower computational resource demands. Extensive experiments\nconducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR\noutperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L\nscore of 0.433 and a METEOR score of 0.336, establishing new performance\nbenchmarks in the domain. These results underscore LLaMA-XR's potential as an\neffective and efficient AI system for automated radiology reporting, offering\nenhanced clinical utility and reliability.", "AI": {"tldr": "LLaMA-XR\u6846\u67b6\u7ed3\u5408LLaMA 3.1\u3001DenseNet-121\u548cQLoRA\uff0c\u5b9e\u73b0\u81ea\u52a8\u653e\u5c04\u62a5\u544a\u751f\u6210\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u79cd\u6700\u65b0\u65b9\u6cd5\u3002", "motivation": "\u51cf\u8f7b\u653e\u5c04\u79d1\u533b\u751f\u7684\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\uff0c\u4f46\u751f\u6210\u7cbe\u786e\u4e14\u5177\u4e34\u5e8a\u610f\u4e49\u7684\u62a5\u544a\u5177\u6709\u6311\u6218\uff0c\u9700\u89e3\u51b3\u533b\u5b66\u8bed\u8a00\u590d\u6742\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLLaMA-XR\u6846\u67b6\uff0c\u96c6\u6210LLaMA 3.1\u3001\u57fa\u4e8eDenseNet-121\u7684\u56fe\u50cf\u5d4c\u5165\u548cQLoRA\u5fae\u8c03\uff0c\u4f18\u5316\u7b56\u7565\u63d0\u9ad8\u53c2\u6570\u5229\u7528\u7387\u5e76\u964d\u4f4e\u5185\u5b58\u5f00\u9500\u3002", "result": "LLaMA-XR\u5728IU X-ray\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0cROUGE-L\u5f97\u5206\u4e3a0.433\uff0cMETEOR\u5f97\u5206\u4e3a0.336\uff0c\u8d85\u8fc7\u591a\u79cd\u6700\u65b0\u65b9\u6cd5\u5e76\u6811\u7acb\u4e86\u65b0\u7684\u6027\u80fd\u57fa\u51c6\u3002", "conclusion": "LLaMA-XR\u5728\u81ea\u52a8\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u589e\u5f3a\u7684\u4e34\u5e8a\u5b9e\u7528\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2506.03426", "pdf": "https://arxiv.org/pdf/2506.03426", "abs": "https://arxiv.org/abs/2506.03426", "authors": ["Joonseong Kang", "Soojeong Lee", "Subeen Park", "Sumin Park", "Taero Kim", "Jihee Kim", "Ryunyi Lee", "Kyungwoo Song"], "title": "Adaptive Task Vectors for Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In-Context Learning (ICL) enables Large Language Models (LLMs) to perform\ntasks without parameter updates by conditioning on a few demonstrations\nprovided in the prompt. Despite its success, ICL suffers from several\nlimitations, including sensitivity to demonstration order, context length\nconstraints, and computational inefficiency. To address these challenges, task\nvector-based approaches compress task information into a single vector.\nHowever, these methods typically construct task vectors from fixed sets of\ndemonstrations and reuse them across input queries, without conditioning on the\nspecific input. This limitation can lead models to struggle with effective\nadaptation when the input query is not well aligned with the underlying\ndemonstrations, consequently degrading their generalization performance on\nunseen tasks. To overcome this limitation, we propose Adaptive Task Vectors\n(ATV), a simple and effective framework that dynamically generates task vectors\nconditioned on each input query. ATV employs a small language model to generate\ntask vectors, which are then transformed to match the target LLM's architecture\nand applied to guide its output generation. In contrast to ICL and previous\nvector-based approaches, which rely on fixed demonstration sets and their\ncorresponding vectors, ATV dynamically generates task vectors tailored to each\nspecific input query and task. Consequently, ATV demonstrates strong\nperformance and generalization capabilities, even for unseen tasks.\nFurthermore, we provide a theoretical analysis indicating that ATV is\nexpressively equivalent to LoRA under equal rank budgets and more expressive\nthan Prefix-Tuning, thereby offering formal support for its representational\nadvantage.", "AI": {"tldr": "ATV\u89e3\u51b3\u4e86ICL\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4efb\u52a1\u5411\u91cf\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u6539\u5584ICL\u5728\u6f14\u793a\u987a\u5e8f\u654f\u611f\u6027\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u9650\u5236\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u4efb\u52a1\u5411\u91cf\uff08ATV\uff09\u6846\u67b6\u3002", "method": "ATV\u4f7f\u7528\u4e00\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6765\u751f\u6210\u4efb\u52a1\u5411\u91cf\uff0c\u8fd9\u4e9b\u5411\u91cf\u88ab\u8f6c\u6362\u4ee5\u5339\u914d\u76ee\u6807\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\uff0c\u5e76\u7528\u4e8e\u6307\u5bfc\u6a21\u578b\u7684\u8f93\u51fa\u751f\u6210\u3002", "result": "ATV\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u4f7f\u5728\u672a\u89c1\u8fc7\u7684\u4efb\u52a1\u4e0a\uff0c\u540c\u65f6\u7406\u8bba\u5206\u6790\u8868\u660eATV\u4e0eLoRA\u5177\u6709\u76f8\u540c\u7684\u8868\u73b0\u80fd\u529b\uff0c\u4e14\u6bd4Prefix-Tuning\u66f4\u5177\u8868\u73b0\u529b\u3002", "conclusion": "ATV\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u751f\u6210\u4e0e\u6bcf\u4e2a\u8f93\u5165\u67e5\u8be2\u76f8\u9002\u5e94\u7684\u4efb\u52a1\u5411\u91cf\uff0c\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u770b\u4e0d\u89c1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
